nohup: ignoring input
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:02:00.0
Total memory: 11.90GiB
Free memory: 11.76GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0)
epoch: 0, train precision: 0.481468, train loss: 182.921585, valid precision: 0.458203, valid loss: 183.180862
epoch: 1, train precision: 0.627113, train loss: 134.436783, valid precision: 0.593359, valid loss: 141.295197
epoch: 2, train precision: 0.708247, train loss: 107.341499, valid precision: 0.659766, valid loss: 121.537766
epoch: 3, train precision: 0.746848, train loss: 94.160271, valid precision: 0.678906, valid loss: 120.969772
epoch: 4, train precision: 0.783050, train loss: 79.717514, valid precision: 0.684766, valid loss: 122.289085
epoch: 5, train precision: 0.798054, train loss: 73.514671, valid precision: 0.680078, valid loss: 139.600220
epoch: 6, train precision: 0.834492, train loss: 61.895462, valid precision: 0.689062, valid loss: 148.675842
epoch: 7, train precision: 0.838404, train loss: 61.091652, valid precision: 0.678711, valid loss: 177.405304
epoch: 8, train precision: 0.824840, train loss: 70.932922, valid precision: 0.660352, valid loss: 201.133926
epoch: 9, train precision: 0.848561, train loss: 58.376171, valid precision: 0.658594, valid loss: 204.671463
epoch: 10, train precision: 0.868983, train loss: 50.424740, valid precision: 0.658008, valid loss: 209.114105
epoch: 11, train precision: 0.885508, train loss: 46.202560, valid precision: 0.669141, valid loss: 233.998093
epoch: 12, train precision: 0.898536, train loss: 40.058880, valid precision: 0.668555, valid loss: 239.593964
epoch: 13, train precision: 0.915515, train loss: 33.073975, valid precision: 0.674609, valid loss: 244.885162
epoch: 14, train precision: 0.930008, train loss: 28.794939, valid precision: 0.674219, valid loss: 264.125305
epoch: 15, train precision: 0.928814, train loss: 29.356670, valid precision: 0.667383, valid loss: 276.307526
epoch: 16, train precision: 0.924938, train loss: 32.892693, valid precision: 0.661719, valid loss: 311.762299
epoch: 17, train precision: 0.916958, train loss: 36.260777, valid precision: 0.659961, valid loss: 318.875488
epoch: 18, train precision: 0.916159, train loss: 36.384548, valid precision: 0.665820, valid loss: 301.672455
epoch: 19, train precision: 0.929426, train loss: 32.537292, valid precision: 0.666992, valid loss: 325.852600
epoch: 20, train precision: 0.916487, train loss: 39.629147, valid precision: 0.659766, valid loss: 338.626038
epoch: 21, train precision: 0.938881, train loss: 29.431887, valid precision: 0.672461, valid loss: 366.197754
epoch: 22, train precision: 0.936928, train loss: 30.727093, valid precision: 0.669922, valid loss: 354.056702
epoch: 23, train precision: 0.944563, train loss: 27.551031, valid precision: 0.677344, valid loss: 377.680176
epoch: 24, train precision: 0.945845, train loss: 26.968534, valid precision: 0.676367, valid loss: 404.149475
epoch: 25, train precision: 0.956232, train loss: 22.077660, valid precision: 0.671680, valid loss: 386.405701
epoch: 26, train precision: 0.956121, train loss: 22.384972, valid precision: 0.677734, valid loss: 401.514771
epoch: 27, train precision: 0.949019, train loss: 24.343794, valid precision: 0.674023, valid loss: 368.643707
epoch: 28, train precision: 0.949690, train loss: 25.673456, valid precision: 0.668555, valid loss: 406.552155
epoch: 29, train precision: 0.957164, train loss: 22.328697, valid precision: 0.676562, valid loss: 417.426666
epoch: 30, train precision: 0.950817, train loss: 26.297585, valid precision: 0.674219, valid loss: 447.647522
epoch: 31, train precision: 0.965066, train loss: 17.130621, valid precision: 0.673437, valid loss: 422.777161
epoch: 32, train precision: 0.949729, train loss: 27.749420, valid precision: 0.676953, valid loss: 461.503815
epoch: 33, train precision: 0.968018, train loss: 15.513708, valid precision: 0.672461, valid loss: 443.948578
epoch: 34, train precision: 0.954812, train loss: 24.805023, valid precision: 0.664453, valid loss: 473.782074
epoch: 35, train precision: 0.956942, train loss: 22.074781, valid precision: 0.653125, valid loss: 478.005188
epoch: 36, train precision: 0.957263, train loss: 22.737690, valid precision: 0.665430, valid loss: 495.564606
epoch: 37, train precision: 0.949645, train loss: 27.993298, valid precision: 0.667578, valid loss: 508.893372
epoch: 38, train precision: 0.965648, train loss: 18.472038, valid precision: 0.675391, valid loss: 472.768951
epoch: 39, train precision: 0.962536, train loss: 20.474184, valid precision: 0.664258, valid loss: 522.565308
epoch: 40, train precision: 0.953525, train loss: 25.961342, valid precision: 0.658984, valid loss: 517.102295
epoch: 41, train precision: 0.954501, train loss: 27.135778, valid precision: 0.664062, valid loss: 521.858765
epoch: 42, train precision: 0.957835, train loss: 24.220142, valid precision: 0.662109, valid loss: 525.559387
epoch: 43, train precision: 0.949818, train loss: 32.196152, valid precision: 0.662891, valid loss: 587.185913
epoch: 44, train precision: 0.961847, train loss: 23.378716, valid precision: 0.657812, valid loss: 561.085999
epoch: 45, train precision: 0.958496, train loss: 23.896986, valid precision: 0.658789, valid loss: 528.962769
epoch: 46, train precision: 0.970947, train loss: 16.807373, valid precision: 0.674219, valid loss: 539.635864
epoch: 47, train precision: 0.959073, train loss: 26.799791, valid precision: 0.664062, valid loss: 599.557007
epoch: 48, train precision: 0.964289, train loss: 20.594809, valid precision: 0.655078, valid loss: 571.101990
epoch: 49, train precision: 0.971391, train loss: 15.895636, valid precision: 0.674023, valid loss: 578.546875
epoch: 50, train precision: 0.963561, train loss: 21.626270, valid precision: 0.664258, valid loss: 616.560242
epoch: 51, train precision: 0.967374, train loss: 19.967758, valid precision: 0.680273, valid loss: 593.408081
epoch: 52, train precision: 0.972750, train loss: 17.124245, valid precision: 0.680469, valid loss: 641.130432
epoch: 53, train precision: 0.967201, train loss: 21.329628, valid precision: 0.671484, valid loss: 623.609558
epoch: 54, train precision: 0.978582, train loss: 12.938923, valid precision: 0.664062, valid loss: 646.543579
epoch: 55, train precision: 0.971635, train loss: 18.821400, valid precision: 0.673828, valid loss: 679.175659
epoch: 56, train precision: 0.979159, train loss: 12.690298, valid precision: 0.671680, valid loss: 642.723267
epoch: 57, train precision: 0.952531, train loss: 34.985985, valid precision: 0.651563, valid loss: 685.384277
epoch: 58, train precision: 0.977783, train loss: 15.361844, valid precision: 0.671680, valid loss: 688.035889
epoch: 59, train precision: 0.967135, train loss: 23.538313, valid precision: 0.671289, valid loss: 718.486572
epoch: 60, train precision: 0.972190, train loss: 19.745493, valid precision: 0.657422, valid loss: 725.903992
epoch: 61, train precision: 0.970681, train loss: 22.053423, valid precision: 0.663672, valid loss: 677.262207
epoch: 62, train precision: 0.964955, train loss: 25.154083, valid precision: 0.657422, valid loss: 753.224609
epoch: 63, train precision: 0.980202, train loss: 14.497036, valid precision: 0.669531, valid loss: 756.208130
epoch: 64, train precision: 0.979359, train loss: 15.203982, valid precision: 0.674023, valid loss: 767.058716
epoch: 65, train precision: 0.977406, train loss: 18.305925, valid precision: 0.678125, valid loss: 825.338379
epoch: 66, train precision: 0.982893, train loss: 11.557471, valid precision: 0.675195, valid loss: 770.166626
epoch: 67, train precision: 0.973056, train loss: 21.195339, valid precision: 0.653125, valid loss: 870.391479
epoch: 68, train precision: 0.973438, train loss: 19.185921, valid precision: 0.660937, valid loss: 777.079041
epoch: 69, train precision: 0.975142, train loss: 19.871141, valid precision: 0.666797, valid loss: 837.400757
epoch: 70, train precision: 0.976096, train loss: 19.584690, valid precision: 0.666797, valid loss: 881.995972
epoch: 71, train precision: 0.984064, train loss: 10.703333, valid precision: 0.669727, valid loss: 781.524658
epoch: 72, train precision: 0.986222, train loss: 10.731760, valid precision: 0.670117, valid loss: 823.646118
epoch: 73, train precision: 0.984242, train loss: 12.351296, valid precision: 0.682031, valid loss: 894.998657
epoch: 74, train precision: 0.979581, train loss: 15.087811, valid precision: 0.679688, valid loss: 824.114868
epoch: 75, train precision: 0.974165, train loss: 19.730515, valid precision: 0.673828, valid loss: 824.752258
epoch: 76, train precision: 0.979226, train loss: 15.770524, valid precision: 0.667773, valid loss: 805.600464
epoch: 77, train precision: 0.986084, train loss: 9.853225, valid precision: 0.675977, valid loss: 824.274536
epoch: 78, train precision: 0.980136, train loss: 15.577686, valid precision: 0.659570, valid loss: 936.877319
epoch: 79, train precision: 0.983487, train loss: 13.616733, valid precision: 0.665039, valid loss: 986.735229
epoch: 80, train precision: 0.965226, train loss: 31.964766, valid precision: 0.665039, valid loss: 929.442993
epoch: 81, train precision: 0.979559, train loss: 16.390646, valid precision: 0.667383, valid loss: 926.192871
epoch: 82, train precision: 0.985263, train loss: 11.527230, valid precision: 0.668945, valid loss: 941.149719
epoch: 83, train precision: 0.977850, train loss: 22.144213, valid precision: 0.673047, valid loss: 1042.760986
epoch: 84, train precision: 0.982910, train loss: 15.565757, valid precision: 0.669141, valid loss: 1000.053101
epoch: 85, train precision: 0.981783, train loss: 15.348548, valid precision: 0.669922, valid loss: 982.599792
epoch: 86, train precision: 0.987216, train loss: 11.426538, valid precision: 0.676953, valid loss: 1093.370483
epoch: 87, train precision: 0.988792, train loss: 10.050892, valid precision: 0.682422, valid loss: 1056.703857
epoch: 88, train precision: 0.981024, train loss: 18.559319, valid precision: 0.671875, valid loss: 1079.618408
epoch: 89, train precision: 0.986195, train loss: 12.554571, valid precision: 0.671875, valid loss: 1073.896484
epoch: 90, train precision: 0.981911, train loss: 18.416140, valid precision: 0.668555, valid loss: 1138.025757
epoch: 91, train precision: 0.982533, train loss: 16.888006, valid precision: 0.662305, valid loss: 1153.539917
epoch: 92, train precision: 0.982511, train loss: 15.821351, valid precision: 0.661328, valid loss: 1039.286377
epoch: 93, train precision: 0.980158, train loss: 20.711214, valid precision: 0.666992, valid loss: 1105.531128
epoch: 94, train precision: 0.983088, train loss: 16.518461, valid precision: 0.667578, valid loss: 1188.856201
epoch: 95, train precision: 0.982688, train loss: 17.009022, valid precision: 0.670898, valid loss: 1148.555908
epoch: 96, train precision: 0.989968, train loss: 9.072576, valid precision: 0.680078, valid loss: 1163.855469
epoch: 97, train precision: 0.976074, train loss: 26.490345, valid precision: 0.661719, valid loss: 1273.464844
epoch: 98, train precision: 0.983559, train loss: 18.199080, valid precision: 0.672070, valid loss: 1240.384766
epoch: 99, train precision: 0.982422, train loss: 21.553263, valid precision: 0.670703, valid loss: 1277.474365
epoch: 100, train precision: 0.987260, train loss: 13.707539, valid precision: 0.672461, valid loss: 1301.533203
epoch: 101, train precision: 0.981228, train loss: 21.335009, valid precision: 0.675391, valid loss: 1421.538330
epoch: 102, train precision: 0.990301, train loss: 10.084852, valid precision: 0.686133, valid loss: 1321.156982
epoch: 103, train precision: 0.969697, train loss: 35.761227, valid precision: 0.660937, valid loss: 1371.861938
epoch: 104, train precision: 0.983066, train loss: 18.485638, valid precision: 0.671094, valid loss: 1245.645508
epoch: 105, train precision: 0.985551, train loss: 15.602448, valid precision: 0.676562, valid loss: 1288.405273
epoch: 106, train precision: 0.986927, train loss: 12.474942, valid precision: 0.672461, valid loss: 1289.413818
epoch: 107, train precision: 0.983532, train loss: 20.737083, valid precision: 0.666406, valid loss: 1406.954346
epoch: 108, train precision: 0.978826, train loss: 24.847801, valid precision: 0.659766, valid loss: 1409.129517
epoch: 109, train precision: 0.985019, train loss: 18.601900, valid precision: 0.674219, valid loss: 1491.099854
epoch: 110, train precision: 0.987971, train loss: 12.541854, valid precision: 0.685156, valid loss: 1377.367798
epoch: 111, train precision: 0.984042, train loss: 20.568010, valid precision: 0.665234, valid loss: 1514.963135
epoch: 112, train precision: 0.988774, train loss: 12.974814, valid precision: 0.677539, valid loss: 1474.074463
epoch: 113, train precision: 0.989280, train loss: 13.775249, valid precision: 0.669727, valid loss: 1577.932617
epoch: 114, train precision: 0.982244, train loss: 22.273714, valid precision: 0.677539, valid loss: 1632.743652
epoch: 115, train precision: 0.985418, train loss: 17.877422, valid precision: 0.677734, valid loss: 1601.648804
epoch: 116, train precision: 0.981534, train loss: 29.004057, valid precision: 0.669727, valid loss: 1828.545532
epoch: 117, train precision: 0.990612, train loss: 12.151015, valid precision: 0.676367, valid loss: 1568.036743
epoch: 118, train precision: 0.987837, train loss: 14.361938, valid precision: 0.671484, valid loss: 1575.224365
epoch: 119, train precision: 0.981689, train loss: 24.351152, valid precision: 0.660352, valid loss: 1540.158936
epoch: 120, train precision: 0.982156, train loss: 23.674868, valid precision: 0.670703, valid loss: 1652.387939
epoch: 121, train precision: 0.984242, train loss: 22.212250, valid precision: 0.675781, valid loss: 1783.095337
epoch: 122, train precision: 0.990839, train loss: 13.561947, valid precision: 0.679688, valid loss: 1756.656860
epoch: 123, train precision: 0.985551, train loss: 18.546124, valid precision: 0.662695, valid loss: 1686.166016
epoch: 124, train precision: 0.979692, train loss: 28.423109, valid precision: 0.659375, valid loss: 1803.924805
epoch: 125, train precision: 0.990589, train loss: 11.319128, valid precision: 0.668555, valid loss: 1763.754883
epoch: 126, train precision: 0.981384, train loss: 28.878370, valid precision: 0.670898, valid loss: 1791.507812
epoch: 127, train precision: 0.984175, train loss: 22.965300, valid precision: 0.675781, valid loss: 1812.370361
epoch: 128, train precision: 0.986173, train loss: 19.022154, valid precision: 0.664062, valid loss: 1818.289307
epoch: 129, train precision: 0.990035, train loss: 13.865423, valid precision: 0.669922, valid loss: 1890.784424
epoch: 130, train precision: 0.987149, train loss: 21.185469, valid precision: 0.657617, valid loss: 1973.977173
epoch: 131, train precision: 0.987860, train loss: 22.327152, valid precision: 0.673633, valid loss: 2087.464600
epoch: 132, train precision: 0.983798, train loss: 27.426241, valid precision: 0.665430, valid loss: 1951.063110
epoch: 133, train precision: 0.988991, train loss: 15.695172, valid precision: 0.667383, valid loss: 2025.751953
epoch: 134, train precision: 0.983731, train loss: 30.155830, valid precision: 0.672266, valid loss: 2123.263672
epoch: 135, train precision: 0.991499, train loss: 14.955005, valid precision: 0.660352, valid loss: 2081.676025
epoch: 136, train precision: 0.988392, train loss: 21.579611, valid precision: 0.674805, valid loss: 2237.746094
epoch: 137, train precision: 0.988437, train loss: 19.342064, valid precision: 0.661914, valid loss: 2258.539307
epoch: 138, train precision: 0.990967, train loss: 16.842766, valid precision: 0.671289, valid loss: 2338.885254
epoch: 139, train precision: 0.988858, train loss: 19.672785, valid precision: 0.669922, valid loss: 2300.800537
epoch: 140, train precision: 0.983709, train loss: 30.507219, valid precision: 0.656055, valid loss: 2240.389160
epoch: 141, train precision: 0.992853, train loss: 13.189404, valid precision: 0.677344, valid loss: 2204.569824
epoch: 142, train precision: 0.980158, train loss: 36.995705, valid precision: 0.658984, valid loss: 2255.742432
epoch: 143, train precision: 0.985751, train loss: 26.395378, valid precision: 0.674219, valid loss: 2239.789062
epoch: 144, train precision: 0.987460, train loss: 24.467731, valid precision: 0.671484, valid loss: 2176.604980
epoch: 145, train precision: 0.991233, train loss: 14.315632, valid precision: 0.682422, valid loss: 2227.248779
epoch: 146, train precision: 0.988392, train loss: 21.577703, valid precision: 0.676172, valid loss: 2514.238037
epoch: 147, train precision: 0.985618, train loss: 32.405315, valid precision: 0.679688, valid loss: 2431.200684
epoch: 148, train precision: 0.988659, train loss: 24.766521, valid precision: 0.667383, valid loss: 2539.231689
epoch: 149, train precision: 0.991033, train loss: 17.820024, valid precision: 0.680469, valid loss: 2507.764160
epoch: 150, train precision: 0.988126, train loss: 22.259813, valid precision: 0.672656, valid loss: 2536.321533
epoch: 151, train precision: 0.980646, train loss: 42.003368, valid precision: 0.657227, valid loss: 2653.970215
epoch: 152, train precision: 0.986111, train loss: 29.022249, valid precision: 0.660742, valid loss: 2820.052246
epoch: 153, train precision: 0.992099, train loss: 15.803250, valid precision: 0.672266, valid loss: 2519.336670
epoch: 154, train precision: 0.981739, train loss: 42.473328, valid precision: 0.666406, valid loss: 2951.962891
epoch: 155, train precision: 0.989684, train loss: 18.335106, valid precision: 0.667969, valid loss: 2637.071777
epoch: 156, train precision: 0.986439, train loss: 28.625277, valid precision: 0.667773, valid loss: 2665.547607
epoch: 157, train precision: 0.993009, train loss: 11.972885, valid precision: 0.675000, valid loss: 2801.561279
epoch: 158, train precision: 0.991011, train loss: 18.764088, valid precision: 0.679883, valid loss: 2822.698730
epoch: 159, train precision: 0.994007, train loss: 11.629741, valid precision: 0.671680, valid loss: 2806.374023
epoch: 160, train precision: 0.982377, train loss: 42.741550, valid precision: 0.659766, valid loss: 3103.437988
epoch: 161, train precision: 0.985263, train loss: 32.057285, valid precision: 0.654492, valid loss: 2987.960205
epoch: 162, train precision: 0.991144, train loss: 16.087959, valid precision: 0.667578, valid loss: 2776.813232
epoch: 163, train precision: 0.989924, train loss: 22.266304, valid precision: 0.671094, valid loss: 2948.184326
epoch: 164, train precision: 0.989458, train loss: 21.561316, valid precision: 0.663867, valid loss: 3015.596680
epoch: 165, train precision: 0.989524, train loss: 27.331896, valid precision: 0.679688, valid loss: 3069.072266
epoch: 166, train precision: 0.991544, train loss: 19.149462, valid precision: 0.683984, valid loss: 3293.181152
epoch: 167, train precision: 0.993985, train loss: 14.168826, valid precision: 0.679883, valid loss: 3279.662109
epoch: 168, train precision: 0.986794, train loss: 34.208408, valid precision: 0.680664, valid loss: 3211.410645
epoch: 169, train precision: 0.981534, train loss: 50.241772, valid precision: 0.673242, valid loss: 3196.308105
epoch: 170, train precision: 0.986883, train loss: 31.889948, valid precision: 0.660352, valid loss: 3160.379639
epoch: 171, train precision: 0.993808, train loss: 13.852805, valid precision: 0.676953, valid loss: 3224.455811
epoch: 172, train precision: 0.989702, train loss: 28.365692, valid precision: 0.671875, valid loss: 3438.832764
epoch: 173, train precision: 0.990390, train loss: 24.496361, valid precision: 0.685742, valid loss: 3474.216309
epoch: 174, train precision: 0.993075, train loss: 16.944094, valid precision: 0.677539, valid loss: 3513.144043
epoch: 175, train precision: 0.993874, train loss: 16.253992, valid precision: 0.678125, valid loss: 3727.494873
epoch: 176, train precision: 0.978760, train loss: 72.132523, valid precision: 0.653906, valid loss: 3894.753906
epoch: 177, train precision: 0.990234, train loss: 28.204395, valid precision: 0.672852, valid loss: 3478.906738
epoch: 178, train precision: 0.988969, train loss: 31.315386, valid precision: 0.675781, valid loss: 3676.899170
epoch: 179, train precision: 0.992454, train loss: 21.060568, valid precision: 0.671289, valid loss: 3820.044189
epoch: 180, train precision: 0.991943, train loss: 25.006927, valid precision: 0.679688, valid loss: 3840.453613
epoch: 181, train precision: 0.981712, train loss: 57.025467, valid precision: 0.671094, valid loss: 3813.221924
epoch: 182, train precision: 0.994740, train loss: 13.761634, valid precision: 0.682227, valid loss: 3648.821045
epoch: 183, train precision: 0.984375, train loss: 62.542957, valid precision: 0.670703, valid loss: 4029.634277
epoch: 184, train precision: 0.988991, train loss: 33.350697, valid precision: 0.668359, valid loss: 3904.979736
epoch: 185, train precision: 0.988459, train loss: 37.455631, valid precision: 0.667383, valid loss: 3935.638184
epoch: 186, train precision: 0.995317, train loss: 11.636319, valid precision: 0.679688, valid loss: 3980.116699
epoch: 187, train precision: 0.993386, train loss: 18.056482, valid precision: 0.674805, valid loss: 3755.247559
epoch: 188, train precision: 0.994607, train loss: 13.223557, valid precision: 0.686523, valid loss: 3844.656250
epoch: 189, train precision: 0.990234, train loss: 29.644318, valid precision: 0.677148, valid loss: 3901.278809
epoch: 190, train precision: 0.994962, train loss: 13.404339, valid precision: 0.686914, valid loss: 3856.809814
epoch: 191, train precision: 0.991255, train loss: 24.557024, valid precision: 0.680664, valid loss: 4041.139893
epoch: 192, train precision: 0.989347, train loss: 39.760132, valid precision: 0.680469, valid loss: 4762.532715
epoch: 193, train precision: 0.990656, train loss: 31.329418, valid precision: 0.663672, valid loss: 4825.524902
epoch: 194, train precision: 0.988259, train loss: 43.715702, valid precision: 0.664844, valid loss: 4629.446289
epoch: 195, train precision: 0.992543, train loss: 26.325090, valid precision: 0.675000, valid loss: 4887.040527
epoch: 196, train precision: 0.989702, train loss: 36.880131, valid precision: 0.673242, valid loss: 4936.074219
epoch: 197, train precision: 0.985756, train loss: 50.809872, valid precision: 0.671094, valid loss: 4733.609863
epoch: 198, train precision: 0.994163, train loss: 18.144478, valid precision: 0.673047, valid loss: 4855.370605
epoch: 199, train precision: 0.995783, train loss: 12.952871, valid precision: 0.661133, valid loss: 4770.992188
epoch: 200, train precision: 0.994673, train loss: 15.197577, valid precision: 0.681641, valid loss: 4614.511230
epoch: 201, train precision: 0.988104, train loss: 44.718578, valid precision: 0.664062, valid loss: 4674.425781
epoch: 202, train precision: 0.993319, train loss: 19.909607, valid precision: 0.673828, valid loss: 4843.435059
epoch: 203, train precision: 0.992676, train loss: 25.623510, valid precision: 0.670508, valid loss: 4860.407227
epoch: 204, train precision: 0.988548, train loss: 53.216286, valid precision: 0.674023, valid loss: 5370.954102
epoch: 205, train precision: 0.986572, train loss: 56.517078, valid precision: 0.675781, valid loss: 5270.541992
epoch: 206, train precision: 0.992631, train loss: 25.455738, valid precision: 0.674023, valid loss: 4868.664062
epoch: 207, train precision: 0.992876, train loss: 25.574165, valid precision: 0.671680, valid loss: 4904.865234
epoch: 208, train precision: 0.994895, train loss: 16.783270, valid precision: 0.685547, valid loss: 5157.809570
epoch: 209, train precision: 0.993142, train loss: 29.535694, valid precision: 0.676172, valid loss: 5723.282227
epoch: 210, train precision: 0.993408, train loss: 23.593395, valid precision: 0.675781, valid loss: 5303.098633
epoch: 211, train precision: 0.987909, train loss: 49.625248, valid precision: 0.664062, valid loss: 5687.630859
epoch: 212, train precision: 0.986972, train loss: 57.591721, valid precision: 0.681836, valid loss: 5497.128906
epoch: 213, train precision: 0.995117, train loss: 18.393425, valid precision: 0.677539, valid loss: 5673.403809
epoch: 214, train precision: 0.992143, train loss: 34.036869, valid precision: 0.680078, valid loss: 5884.494629
epoch: 215, train precision: 0.994829, train loss: 16.961206, valid precision: 0.679688, valid loss: 5262.057617
epoch: 216, train precision: 0.995295, train loss: 18.145678, valid precision: 0.683789, valid loss: 5886.321777
epoch: 217, train precision: 0.992765, train loss: 33.849133, valid precision: 0.676172, valid loss: 5908.754883
epoch: 218, train precision: 0.994540, train loss: 20.026396, valid precision: 0.673633, valid loss: 5928.791992
epoch: 219, train precision: 0.990146, train loss: 47.818897, valid precision: 0.669922, valid loss: 6182.430664
epoch: 220, train precision: 0.994917, train loss: 21.194649, valid precision: 0.684375, valid loss: 5980.803223
epoch: 221, train precision: 0.995139, train loss: 16.823946, valid precision: 0.678125, valid loss: 5850.592773
epoch: 222, train precision: 0.993075, train loss: 31.932812, valid precision: 0.677344, valid loss: 5569.723633
epoch: 223, train precision: 0.995716, train loss: 22.579279, valid precision: 0.676367, valid loss: 6337.085938
epoch: 224, train precision: 0.991877, train loss: 39.041931, valid precision: 0.674219, valid loss: 6032.385254
epoch: 225, train precision: 0.994651, train loss: 21.220671, valid precision: 0.669922, valid loss: 6053.497559
epoch: 226, train precision: 0.995184, train loss: 23.318048, valid precision: 0.683008, valid loss: 6720.756348
epoch: 227, train precision: 0.991171, train loss: 35.184250, valid precision: 0.666016, valid loss: 6116.122070
epoch: 228, train precision: 0.994407, train loss: 24.274391, valid precision: 0.673633, valid loss: 6600.968750
epoch: 229, train precision: 0.992520, train loss: 39.836193, valid precision: 0.667969, valid loss: 6727.209961
epoch: 230, train precision: 0.991322, train loss: 40.834278, valid precision: 0.683594, valid loss: 6707.315430
epoch: 231, train precision: 0.995783, train loss: 16.717669, valid precision: 0.679297, valid loss: 6325.530273
epoch: 232, train precision: 0.995561, train loss: 21.658028, valid precision: 0.697656, valid loss: 6841.005371
epoch: 233, train precision: 0.993719, train loss: 26.046282, valid precision: 0.673437, valid loss: 6554.576660
epoch: 234, train precision: 0.993786, train loss: 30.185131, valid precision: 0.677344, valid loss: 6571.442871
epoch: 235, train precision: 0.992765, train loss: 38.320065, valid precision: 0.678320, valid loss: 6798.454590
epoch: 236, train precision: 0.994851, train loss: 26.371889, valid precision: 0.671484, valid loss: 7076.162598
epoch: 237, train precision: 0.997070, train loss: 12.769599, valid precision: 0.675977, valid loss: 6642.411133
epoch: 238, train precision: 0.992232, train loss: 38.065895, valid precision: 0.678125, valid loss: 6684.606934
epoch: 239, train precision: 0.994917, train loss: 21.761009, valid precision: 0.670898, valid loss: 7151.334961
epoch: 240, train precision: 0.993586, train loss: 33.523365, valid precision: 0.673047, valid loss: 7291.817383
epoch: 241, train precision: 0.994074, train loss: 30.281771, valid precision: 0.671875, valid loss: 6823.144531
epoch: 242, train precision: 0.991544, train loss: 40.557755, valid precision: 0.668359, valid loss: 6899.289062
epoch: 243, train precision: 0.994629, train loss: 27.143089, valid precision: 0.677734, valid loss: 7155.546875
epoch: 244, train precision: 0.995783, train loss: 19.719568, valid precision: 0.675781, valid loss: 7431.872559
epoch: 245, train precision: 0.995139, train loss: 26.034637, valid precision: 0.680859, valid loss: 7529.137695
epoch: 246, train precision: 0.995850, train loss: 19.419350, valid precision: 0.685352, valid loss: 6899.293945
epoch: 247, train precision: 0.994745, train loss: 27.470613, valid precision: 0.679688, valid loss: 7832.937500
epoch: 248, train precision: 0.995628, train loss: 22.022547, valid precision: 0.683008, valid loss: 7789.769531
epoch: 249, train precision: 0.987754, train loss: 70.302635, valid precision: 0.668945, valid loss: 7682.834473
epoch: 250, train precision: 0.992765, train loss: 38.166153, valid precision: 0.681250, valid loss: 7851.071289
epoch: 251, train precision: 0.994629, train loss: 29.471252, valid precision: 0.674023, valid loss: 8141.682617
epoch: 252, train precision: 0.995162, train loss: 30.064257, valid precision: 0.676562, valid loss: 8688.392578
epoch: 253, train precision: 0.991766, train loss: 54.594540, valid precision: 0.670898, valid loss: 8492.704102
epoch: 254, train precision: 0.995850, train loss: 27.341492, valid precision: 0.671289, valid loss: 8261.998047
epoch: 255, train precision: 0.996760, train loss: 17.434885, valid precision: 0.683594, valid loss: 8262.716797
epoch: 256, train precision: 0.996560, train loss: 21.364008, valid precision: 0.683594, valid loss: 8763.802734
epoch: 257, train precision: 0.995805, train loss: 23.850513, valid precision: 0.682422, valid loss: 8939.201172
epoch: 258, train precision: 0.990501, train loss: 65.651062, valid precision: 0.672852, valid loss: 8976.198242
epoch: 259, train precision: 0.995655, train loss: 25.453339, valid precision: 0.670117, valid loss: 8581.937500
epoch: 260, train precision: 0.994540, train loss: 31.270758, valid precision: 0.673633, valid loss: 9364.845703
epoch: 261, train precision: 0.996160, train loss: 27.431080, valid precision: 0.679492, valid loss: 9917.791016
epoch: 262, train precision: 0.993408, train loss: 43.068619, valid precision: 0.678516, valid loss: 9926.124023
epoch: 263, train precision: 0.996382, train loss: 25.907293, valid precision: 0.677344, valid loss: 9570.080078
epoch: 264, train precision: 0.994829, train loss: 33.597664, valid precision: 0.683984, valid loss: 9504.904297
epoch: 265, train precision: 0.993408, train loss: 46.076473, valid precision: 0.671680, valid loss: 9556.228516
epoch: 266, train precision: 0.993630, train loss: 42.857418, valid precision: 0.674414, valid loss: 9669.548828
epoch: 267, train precision: 0.993164, train loss: 59.094303, valid precision: 0.674609, valid loss: 10614.482422
epoch: 268, train precision: 0.994673, train loss: 40.903511, valid precision: 0.673633, valid loss: 9664.518555
epoch: 269, train precision: 0.992809, train loss: 59.480225, valid precision: 0.669336, valid loss: 10997.736328
epoch: 270, train precision: 0.989835, train loss: 65.604012, valid precision: 0.665039, valid loss: 9833.454102
epoch: 271, train precision: 0.995472, train loss: 34.383495, valid precision: 0.673242, valid loss: 10348.975586
epoch: 272, train precision: 0.997137, train loss: 19.344793, valid precision: 0.674805, valid loss: 9898.052734
epoch: 273, train precision: 0.996649, train loss: 21.555220, valid precision: 0.676953, valid loss: 10357.112305
epoch: 274, train precision: 0.994673, train loss: 42.141567, valid precision: 0.676172, valid loss: 10646.884766
epoch: 275, train precision: 0.993319, train loss: 52.576305, valid precision: 0.684961, valid loss: 10955.599609
epoch: 276, train precision: 0.990301, train loss: 83.185593, valid precision: 0.656641, valid loss: 11644.771484
epoch: 277, train precision: 0.988414, train loss: 99.287109, valid precision: 0.665430, valid loss: 12374.599609
epoch: 278, train precision: 0.996316, train loss: 28.933832, valid precision: 0.675000, valid loss: 11643.316406
epoch: 279, train precision: 0.997270, train loss: 22.562279, valid precision: 0.676367, valid loss: 11619.643555
epoch: 280, train precision: 0.992143, train loss: 62.536240, valid precision: 0.675391, valid loss: 12278.735352
epoch: 281, train precision: 0.992720, train loss: 66.470482, valid precision: 0.667578, valid loss: 12122.317383
epoch: 282, train precision: 0.993630, train loss: 45.520775, valid precision: 0.675586, valid loss: 11795.412109
epoch: 283, train precision: 0.996187, train loss: 35.339169, valid precision: 0.684570, valid loss: 12279.416016
epoch: 284, train precision: 0.995073, train loss: 46.905918, valid precision: 0.668164, valid loss: 12146.397461
epoch: 285, train precision: 0.998313, train loss: 9.926400, valid precision: 0.680078, valid loss: 11852.010742
epoch: 286, train precision: 0.994207, train loss: 49.533985, valid precision: 0.675000, valid loss: 12288.742188
epoch: 287, train precision: 0.996493, train loss: 26.450232, valid precision: 0.676953, valid loss: 11169.949219
epoch: 288, train precision: 0.993697, train loss: 52.729763, valid precision: 0.673437, valid loss: 12323.945312
epoch: 289, train precision: 0.995761, train loss: 36.831009, valid precision: 0.681250, valid loss: 12245.901367
epoch: 290, train precision: 0.992121, train loss: 76.970016, valid precision: 0.674219, valid loss: 13262.831055
epoch: 291, train precision: 0.995450, train loss: 40.939617, valid precision: 0.678906, valid loss: 12581.125000
epoch: 292, train precision: 0.994318, train loss: 44.259827, valid precision: 0.674609, valid loss: 13355.900391
epoch: 293, train precision: 0.995317, train loss: 39.879513, valid precision: 0.668945, valid loss: 12610.643555
epoch: 294, train precision: 0.996027, train loss: 31.489691, valid precision: 0.673633, valid loss: 12682.090820
epoch: 295, train precision: 0.996560, train loss: 21.879591, valid precision: 0.669922, valid loss: 12720.383789
epoch: 296, train precision: 0.992853, train loss: 62.072861, valid precision: 0.662695, valid loss: 13269.395508
epoch: 297, train precision: 0.995983, train loss: 33.949398, valid precision: 0.671484, valid loss: 13064.201172
epoch: 298, train precision: 0.995295, train loss: 45.926334, valid precision: 0.670117, valid loss: 13430.853516
epoch: 299, train precision: 0.992765, train loss: 63.852062, valid precision: 0.675000, valid loss: 13740.500000
epoch: 300, train precision: 0.994296, train loss: 48.742996, valid precision: 0.673242, valid loss: 13598.659180
epoch: 301, train precision: 0.994274, train loss: 57.752487, valid precision: 0.676953, valid loss: 14198.465820
epoch: 302, train precision: 0.994385, train loss: 53.021606, valid precision: 0.683594, valid loss: 13298.317383
epoch: 303, train precision: 0.995894, train loss: 32.399246, valid precision: 0.673047, valid loss: 13278.409180
epoch: 304, train precision: 0.993741, train loss: 57.775097, valid precision: 0.674219, valid loss: 14478.498047
epoch: 305, train precision: 0.990789, train loss: 94.369286, valid precision: 0.671094, valid loss: 14153.726562
epoch: 306, train precision: 0.996782, train loss: 23.013502, valid precision: 0.681250, valid loss: 14143.340820
epoch: 307, train precision: 0.995339, train loss: 41.987217, valid precision: 0.680273, valid loss: 14202.463867
epoch: 308, train precision: 0.996049, train loss: 36.886047, valid precision: 0.675586, valid loss: 14499.593750
epoch: 309, train precision: 0.995716, train loss: 43.291500, valid precision: 0.667383, valid loss: 14793.533203
epoch: 310, train precision: 0.996538, train loss: 38.887230, valid precision: 0.681836, valid loss: 14884.119141
epoch: 311, train precision: 0.993874, train loss: 65.552032, valid precision: 0.674609, valid loss: 14548.971680
epoch: 312, train precision: 0.996360, train loss: 31.968203, valid precision: 0.676758, valid loss: 14447.462891
epoch: 313, train precision: 0.996649, train loss: 31.431566, valid precision: 0.681250, valid loss: 14379.981445
epoch: 314, train precision: 0.991060, train loss: 107.944580, valid precision: 0.674609, valid loss: 15913.252930
epoch: 315, train precision: 0.994207, train loss: 63.378147, valid precision: 0.671484, valid loss: 15986.656250
epoch: 316, train precision: 0.990856, train loss: 101.446945, valid precision: 0.671484, valid loss: 15968.849609
epoch: 317, train precision: 0.994429, train loss: 76.119171, valid precision: 0.679297, valid loss: 15921.846680
epoch: 318, train precision: 0.997159, train loss: 30.018496, valid precision: 0.691016, valid loss: 16401.253906
epoch: 319, train precision: 0.997514, train loss: 25.271025, valid precision: 0.691211, valid loss: 15993.087891
epoch: 320, train precision: 0.995339, train loss: 56.748997, valid precision: 0.677344, valid loss: 17043.994141
epoch: 321, train precision: 0.994185, train loss: 74.183098, valid precision: 0.669922, valid loss: 17620.800781
epoch: 322, train precision: 0.996982, train loss: 27.946051, valid precision: 0.683203, valid loss: 16883.875000
epoch: 323, train precision: 0.994252, train loss: 72.705910, valid precision: 0.678125, valid loss: 18094.117188
epoch: 324, train precision: 0.980358, train loss: 322.877930, valid precision: 0.664648, valid loss: 19054.250000
epoch: 325, train precision: 0.996382, train loss: 39.878357, valid precision: 0.686719, valid loss: 18028.830078
epoch: 326, train precision: 0.991877, train loss: 114.763763, valid precision: 0.668555, valid loss: 18707.750000
epoch: 327, train precision: 0.989324, train loss: 161.646729, valid precision: 0.675781, valid loss: 17853.503906
epoch: 328, train precision: 0.998446, train loss: 14.067114, valid precision: 0.687109, valid loss: 17655.890625
epoch: 329, train precision: 0.995250, train loss: 57.520626, valid precision: 0.673242, valid loss: 18492.666016
epoch: 330, train precision: 0.996316, train loss: 44.477108, valid precision: 0.690039, valid loss: 17589.875000
epoch: 331, train precision: 0.996671, train loss: 49.114651, valid precision: 0.687891, valid loss: 19214.171875
epoch: 332, train precision: 0.997270, train loss: 33.809238, valid precision: 0.692969, valid loss: 19042.640625
epoch: 333, train precision: 0.996116, train loss: 51.971119, valid precision: 0.691406, valid loss: 18715.687500
epoch: 334, train precision: 0.995916, train loss: 55.074772, valid precision: 0.685938, valid loss: 17578.667969
epoch: 335, train precision: 0.997448, train loss: 27.820068, valid precision: 0.687500, valid loss: 19048.183594
epoch: 336, train precision: 0.994629, train loss: 73.250290, valid precision: 0.672070, valid loss: 19586.783203
epoch: 337, train precision: 0.995938, train loss: 54.974308, valid precision: 0.684961, valid loss: 18185.605469
epoch: 338, train precision: 0.995028, train loss: 77.043434, valid precision: 0.685742, valid loss: 19697.888672
epoch: 339, train precision: 0.997337, train loss: 34.697895, valid precision: 0.688086, valid loss: 20025.636719
epoch: 340, train precision: 0.995139, train loss: 61.714451, valid precision: 0.684180, valid loss: 19938.066406
epoch: 341, train precision: 0.993985, train loss: 91.061005, valid precision: 0.684766, valid loss: 19227.675781
epoch: 342, train precision: 0.996205, train loss: 50.968784, valid precision: 0.679102, valid loss: 20114.865234
epoch: 343, train precision: 0.995961, train loss: 47.489307, valid precision: 0.683008, valid loss: 20023.804688
epoch: 344, train precision: 0.995295, train loss: 64.413429, valid precision: 0.677539, valid loss: 21285.183594
epoch: 345, train precision: 0.997381, train loss: 30.333263, valid precision: 0.678320, valid loss: 19502.789062
epoch: 346, train precision: 0.998025, train loss: 18.219542, valid precision: 0.688281, valid loss: 19994.410156
epoch: 347, train precision: 0.995228, train loss: 54.682682, valid precision: 0.679297, valid loss: 20083.281250
epoch: 348, train precision: 0.997137, train loss: 40.497227, valid precision: 0.689062, valid loss: 21070.697266
epoch: 349, train precision: 0.996848, train loss: 47.128403, valid precision: 0.685547, valid loss: 21465.316406
epoch: 350, train precision: 0.996493, train loss: 47.340775, valid precision: 0.685156, valid loss: 21532.765625
epoch: 351, train precision: 0.996276, train loss: 70.808525, valid precision: 0.689648, valid loss: 21992.550781
epoch: 352, train precision: 0.998025, train loss: 30.733892, valid precision: 0.686328, valid loss: 21877.244141
epoch: 353, train precision: 0.996560, train loss: 40.696819, valid precision: 0.686914, valid loss: 21739.019531
epoch: 354, train precision: 0.997026, train loss: 42.034950, valid precision: 0.695117, valid loss: 21824.511719
epoch: 355, train precision: 0.996893, train loss: 52.171902, valid precision: 0.684961, valid loss: 21570.941406
epoch: 356, train precision: 0.994895, train loss: 81.051941, valid precision: 0.679102, valid loss: 22347.144531
epoch: 357, train precision: 0.995250, train loss: 67.523468, valid precision: 0.673828, valid loss: 21384.562500
epoch: 358, train precision: 0.995716, train loss: 72.829109, valid precision: 0.680859, valid loss: 23721.927734
epoch: 359, train precision: 0.996893, train loss: 45.356186, valid precision: 0.690234, valid loss: 21976.714844
epoch: 360, train precision: 0.996782, train loss: 34.854221, valid precision: 0.688672, valid loss: 21524.757812
epoch: 361, train precision: 0.995250, train loss: 81.147675, valid precision: 0.681445, valid loss: 22454.667969
epoch: 362, train precision: 0.996848, train loss: 44.458408, valid precision: 0.686328, valid loss: 21876.843750
epoch: 363, train precision: 0.998580, train loss: 20.323305, valid precision: 0.682422, valid loss: 22579.210938
epoch: 364, train precision: 0.997958, train loss: 36.175419, valid precision: 0.688477, valid loss: 24238.724609
epoch: 365, train precision: 0.997159, train loss: 42.118313, valid precision: 0.688477, valid loss: 23231.441406
epoch: 366, train precision: 0.998002, train loss: 29.695555, valid precision: 0.690820, valid loss: 23430.437500
epoch: 367, train precision: 0.997786, train loss: 31.099829, valid precision: 0.686914, valid loss: 23287.785156
epoch: 368, train precision: 0.994207, train loss: 96.648140, valid precision: 0.681250, valid loss: 23069.984375
epoch: 369, train precision: 0.996249, train loss: 61.563660, valid precision: 0.674414, valid loss: 25007.628906
epoch: 370, train precision: 0.997470, train loss: 38.303600, valid precision: 0.679492, valid loss: 24399.283203
epoch: 371, train precision: 0.995610, train loss: 72.126755, valid precision: 0.684961, valid loss: 25537.910156
epoch: 372, train precision: 0.996760, train loss: 51.332520, valid precision: 0.688672, valid loss: 24468.972656
epoch: 373, train precision: 0.996005, train loss: 72.502609, valid precision: 0.687891, valid loss: 24605.232422
epoch: 374, train precision: 0.996560, train loss: 55.198498, valid precision: 0.677930, valid loss: 23766.767578
epoch: 375, train precision: 0.995650, train loss: 63.052135, valid precision: 0.680859, valid loss: 23497.050781
epoch: 376, train precision: 0.996959, train loss: 41.869198, valid precision: 0.686719, valid loss: 23774.876953
epoch: 377, train precision: 0.994540, train loss: 98.240578, valid precision: 0.680469, valid loss: 25034.224609
epoch: 378, train precision: 0.996072, train loss: 66.992027, valid precision: 0.687695, valid loss: 24660.232422
epoch: 379, train precision: 0.996316, train loss: 55.438709, valid precision: 0.682813, valid loss: 24147.925781
epoch: 380, train precision: 0.997514, train loss: 39.787422, valid precision: 0.683984, valid loss: 25255.128906
epoch: 381, train precision: 0.997914, train loss: 31.978228, valid precision: 0.685938, valid loss: 27459.068359
epoch: 382, train precision: 0.994789, train loss: 97.740608, valid precision: 0.675977, valid loss: 27192.988281
epoch: 383, train precision: 0.997314, train loss: 39.332516, valid precision: 0.675391, valid loss: 27628.222656
epoch: 384, train precision: 0.991660, train loss: 139.643021, valid precision: 0.675195, valid loss: 28305.203125
epoch: 385, train precision: 0.996871, train loss: 45.896000, valid precision: 0.676953, valid loss: 26415.937500
epoch: 386, train precision: 0.997004, train loss: 54.528442, valid precision: 0.681250, valid loss: 26885.386719
epoch: 387, train precision: 0.997803, train loss: 34.755314, valid precision: 0.680078, valid loss: 25614.019531
epoch: 388, train precision: 0.997670, train loss: 44.179935, valid precision: 0.693750, valid loss: 25621.013672
epoch: 389, train precision: 0.997115, train loss: 46.451870, valid precision: 0.691406, valid loss: 28366.113281
epoch: 390, train precision: 0.997181, train loss: 40.159153, valid precision: 0.685547, valid loss: 27690.587891
epoch: 391, train precision: 0.996693, train loss: 67.309319, valid precision: 0.675391, valid loss: 28377.746094
epoch: 392, train precision: 0.997692, train loss: 34.527393, valid precision: 0.686133, valid loss: 27502.587891
epoch: 393, train precision: 0.998313, train loss: 25.600466, valid precision: 0.690039, valid loss: 27737.212891
epoch: 394, train precision: 0.997625, train loss: 38.561481, valid precision: 0.684180, valid loss: 29166.542969
epoch: 395, train precision: 0.995628, train loss: 87.084671, valid precision: 0.686328, valid loss: 30820.437500
epoch: 396, train precision: 0.996804, train loss: 66.259575, valid precision: 0.683398, valid loss: 30871.230469
epoch: 397, train precision: 0.996715, train loss: 67.248917, valid precision: 0.682227, valid loss: 30424.558594
epoch: 398, train precision: 0.997492, train loss: 48.850513, valid precision: 0.691016, valid loss: 28512.744141
epoch: 399, train precision: 0.997736, train loss: 31.481468, valid precision: 0.689062, valid loss: 29509.355469
epoch: 400, train precision: 0.996338, train loss: 74.914223, valid precision: 0.686719, valid loss: 30232.568359
epoch: 401, train precision: 0.995011, train loss: 110.034889, valid precision: 0.687695, valid loss: 29668.175781
epoch: 402, train precision: 0.996160, train loss: 81.502907, valid precision: 0.685156, valid loss: 29597.871094
epoch: 403, train precision: 0.997181, train loss: 48.868961, valid precision: 0.688672, valid loss: 30443.246094
epoch: 404, train precision: 0.995872, train loss: 70.236961, valid precision: 0.690820, valid loss: 28969.015625
epoch: 405, train precision: 0.996471, train loss: 60.860550, valid precision: 0.686523, valid loss: 30271.880859
epoch: 406, train precision: 0.994984, train loss: 93.693352, valid precision: 0.682422, valid loss: 31595.656250
epoch: 407, train precision: 0.997536, train loss: 37.020126, valid precision: 0.686914, valid loss: 31804.769531
epoch: 408, train precision: 0.993120, train loss: 162.701996, valid precision: 0.677930, valid loss: 33279.480469
epoch: 409, train precision: 0.995938, train loss: 100.527100, valid precision: 0.687891, valid loss: 31939.744141
epoch: 410, train precision: 0.994895, train loss: 123.232307, valid precision: 0.682031, valid loss: 32325.568359
epoch: 411, train precision: 0.996782, train loss: 56.260616, valid precision: 0.685938, valid loss: 31750.005859
epoch: 412, train precision: 0.996205, train loss: 80.108772, valid precision: 0.690039, valid loss: 31801.093750
epoch: 413, train precision: 0.996404, train loss: 74.381714, valid precision: 0.684961, valid loss: 33986.859375
epoch: 414, train precision: 0.998779, train loss: 23.687866, valid precision: 0.695898, valid loss: 31246.988281
epoch: 415, train precision: 0.994429, train loss: 129.064590, valid precision: 0.694336, valid loss: 33150.851562
epoch: 416, train precision: 0.997891, train loss: 35.571144, valid precision: 0.694531, valid loss: 31094.431641
epoch: 417, train precision: 0.997470, train loss: 50.481277, valid precision: 0.691992, valid loss: 33860.390625
epoch: 418, train precision: 0.996982, train loss: 58.950241, valid precision: 0.686133, valid loss: 34094.492188
epoch: 419, train precision: 0.990412, train loss: 268.259399, valid precision: 0.673047, valid loss: 37391.367188
epoch: 420, train precision: 0.998136, train loss: 40.040062, valid precision: 0.690430, valid loss: 35093.976562
epoch: 421, train precision: 0.997425, train loss: 59.078823, valid precision: 0.682422, valid loss: 34369.496094
epoch: 422, train precision: 0.995650, train loss: 87.346069, valid precision: 0.693750, valid loss: 33673.226562
epoch: 423, train precision: 0.996649, train loss: 67.956451, valid precision: 0.692383, valid loss: 33220.093750
epoch: 424, train precision: 0.997159, train loss: 67.849335, valid precision: 0.697070, valid loss: 34673.613281
epoch: 425, train precision: 0.998513, train loss: 30.467039, valid precision: 0.692773, valid loss: 34516.070312
epoch: 426, train precision: 0.998668, train loss: 28.283258, valid precision: 0.695508, valid loss: 34467.894531
epoch: 427, train precision: 0.998402, train loss: 27.295702, valid precision: 0.693359, valid loss: 37111.507812
epoch: 428, train precision: 0.998025, train loss: 42.903961, valid precision: 0.690430, valid loss: 34393.347656
epoch: 429, train precision: 0.997337, train loss: 66.995811, valid precision: 0.695312, valid loss: 34858.582031
epoch: 430, train precision: 0.997581, train loss: 43.384895, valid precision: 0.690234, valid loss: 34443.957031
epoch: 431, train precision: 0.996183, train loss: 92.220062, valid precision: 0.685547, valid loss: 36033.480469
epoch: 432, train precision: 0.997647, train loss: 67.920464, valid precision: 0.692383, valid loss: 37056.554688
epoch: 433, train precision: 0.997092, train loss: 68.781181, valid precision: 0.690625, valid loss: 36647.757812
epoch: 434, train precision: 0.997181, train loss: 74.322472, valid precision: 0.695703, valid loss: 38273.425781
epoch: 435, train precision: 0.995983, train loss: 119.210350, valid precision: 0.689844, valid loss: 37159.164062
epoch: 436, train precision: 0.997736, train loss: 50.873642, valid precision: 0.689258, valid loss: 40267.121094
epoch: 437, train precision: 0.998091, train loss: 34.999149, valid precision: 0.689453, valid loss: 37343.832031
epoch: 438, train precision: 0.996560, train loss: 86.471733, valid precision: 0.690234, valid loss: 41373.648438
epoch: 439, train precision: 0.995783, train loss: 111.072800, valid precision: 0.692969, valid loss: 39576.855469
epoch: 440, train precision: 0.995694, train loss: 125.816460, valid precision: 0.692187, valid loss: 41897.898438
epoch: 441, train precision: 0.998113, train loss: 48.639866, valid precision: 0.697656, valid loss: 39792.464844
epoch: 442, train precision: 0.996404, train loss: 95.454010, valid precision: 0.683789, valid loss: 40267.687500
epoch: 443, train precision: 0.996471, train loss: 90.356064, valid precision: 0.695312, valid loss: 40774.429688
epoch: 444, train precision: 0.995494, train loss: 137.127747, valid precision: 0.691211, valid loss: 40143.207031
epoch: 445, train precision: 0.997181, train loss: 72.523232, valid precision: 0.699414, valid loss: 41927.648438
epoch: 446, train precision: 0.997337, train loss: 72.418571, valid precision: 0.686133, valid loss: 39175.125000
epoch: 447, train precision: 0.998025, train loss: 56.226219, valid precision: 0.691016, valid loss: 40906.566406
epoch: 448, train precision: 0.999068, train loss: 26.578493, valid precision: 0.697070, valid loss: 41985.449219
epoch: 449, train precision: 0.998380, train loss: 39.850224, valid precision: 0.691992, valid loss: 43416.859375
epoch: 450, train precision: 0.997536, train loss: 60.824623, valid precision: 0.695703, valid loss: 43415.320312
epoch: 451, train precision: 0.997714, train loss: 58.204666, valid precision: 0.692383, valid loss: 43349.542969
epoch: 452, train precision: 0.997581, train loss: 54.843288, valid precision: 0.701563, valid loss: 43337.730469
epoch: 453, train precision: 0.997314, train loss: 89.443130, valid precision: 0.692187, valid loss: 44665.085938
epoch: 454, train precision: 0.997470, train loss: 81.616219, valid precision: 0.689844, valid loss: 41029.914062
epoch: 455, train precision: 0.998424, train loss: 36.883133, valid precision: 0.694727, valid loss: 44264.406250
epoch: 456, train precision: 0.997647, train loss: 63.510403, valid precision: 0.686328, valid loss: 45729.824219
epoch: 457, train precision: 0.998136, train loss: 46.702648, valid precision: 0.686523, valid loss: 43147.277344
epoch: 458, train precision: 0.998180, train loss: 48.355724, valid precision: 0.700391, valid loss: 47220.003906
epoch: 459, train precision: 0.997403, train loss: 55.365231, valid precision: 0.690430, valid loss: 45427.554688
epoch: 460, train precision: 0.996227, train loss: 121.422478, valid precision: 0.688672, valid loss: 44419.335938
epoch: 461, train precision: 0.997603, train loss: 86.611069, valid precision: 0.692773, valid loss: 46310.589844
epoch: 462, train precision: 0.998646, train loss: 32.700436, valid precision: 0.688086, valid loss: 46831.128906
epoch: 463, train precision: 0.995850, train loss: 129.129623, valid precision: 0.683203, valid loss: 46262.132812
epoch: 464, train precision: 0.996054, train loss: 104.874756, valid precision: 0.679102, valid loss: 50432.273438
epoch: 465, train precision: 0.993453, train loss: 219.084320, valid precision: 0.683008, valid loss: 48131.023438
epoch: 466, train precision: 0.998402, train loss: 46.108646, valid precision: 0.693164, valid loss: 47453.433594
epoch: 467, train precision: 0.997448, train loss: 95.474167, valid precision: 0.687695, valid loss: 46998.332031
epoch: 468, train precision: 0.998358, train loss: 43.532177, valid precision: 0.689258, valid loss: 46231.953125
epoch: 469, train precision: 0.995605, train loss: 131.853317, valid precision: 0.682422, valid loss: 48818.851562
epoch: 470, train precision: 0.998269, train loss: 50.784733, valid precision: 0.690039, valid loss: 48405.605469
epoch: 471, train precision: 0.995228, train loss: 154.759918, valid precision: 0.679102, valid loss: 47362.175781
epoch: 472, train precision: 0.996538, train loss: 123.319832, valid precision: 0.687500, valid loss: 49099.093750
epoch: 473, train precision: 0.997359, train loss: 76.491234, valid precision: 0.689648, valid loss: 51035.488281
epoch: 474, train precision: 0.998002, train loss: 61.911755, valid precision: 0.684961, valid loss: 49550.953125
epoch: 475, train precision: 0.997448, train loss: 80.269798, valid precision: 0.693945, valid loss: 51548.093750
epoch: 476, train precision: 0.998025, train loss: 58.381901, valid precision: 0.678906, valid loss: 51460.679688
epoch: 477, train precision: 0.998091, train loss: 50.008801, valid precision: 0.684766, valid loss: 50717.835938
epoch: 478, train precision: 0.998646, train loss: 42.282665, valid precision: 0.683203, valid loss: 51756.769531
epoch: 479, train precision: 0.996671, train loss: 112.772652, valid precision: 0.683984, valid loss: 51750.570312
epoch: 480, train precision: 0.998691, train loss: 42.778011, valid precision: 0.690820, valid loss: 51233.023438
epoch: 481, train precision: 0.997803, train loss: 62.939575, valid precision: 0.680859, valid loss: 51892.593750
epoch: 482, train precision: 0.994385, train loss: 239.588333, valid precision: 0.683984, valid loss: 53422.335938
epoch: 483, train precision: 0.997803, train loss: 60.757641, valid precision: 0.690234, valid loss: 51890.351562
epoch: 484, train precision: 0.998491, train loss: 48.932983, valid precision: 0.692969, valid loss: 52191.347656
epoch: 485, train precision: 0.997958, train loss: 58.860497, valid precision: 0.691406, valid loss: 51547.640625
epoch: 486, train precision: 0.995206, train loss: 172.473923, valid precision: 0.690039, valid loss: 54407.175781
epoch: 487, train precision: 0.998313, train loss: 57.745670, valid precision: 0.697461, valid loss: 53161.949219
epoch: 488, train precision: 0.998202, train loss: 46.861057, valid precision: 0.688477, valid loss: 53839.605469
epoch: 489, train precision: 0.997048, train loss: 104.785164, valid precision: 0.680664, valid loss: 55095.992188
epoch: 490, train precision: 0.997803, train loss: 87.103668, valid precision: 0.683594, valid loss: 51015.011719
epoch: 491, train precision: 0.998136, train loss: 71.561066, valid precision: 0.686719, valid loss: 51461.449219
epoch: 492, train precision: 0.998557, train loss: 45.209957, valid precision: 0.684570, valid loss: 51388.800781
epoch: 493, train precision: 0.996471, train loss: 116.335472, valid precision: 0.686914, valid loss: 54869.492188
epoch: 494, train precision: 0.998047, train loss: 65.338966, valid precision: 0.688281, valid loss: 53775.523438
epoch: 495, train precision: 0.998602, train loss: 42.116245, valid precision: 0.688867, valid loss: 54572.230469
epoch: 496, train precision: 0.997403, train loss: 76.640068, valid precision: 0.682031, valid loss: 56776.187500
epoch: 497, train precision: 0.997181, train loss: 96.945244, valid precision: 0.684570, valid loss: 58735.175781
epoch: 498, train precision: 0.998757, train loss: 41.785519, valid precision: 0.688281, valid loss: 54737.312500
epoch: 499, train precision: 0.996404, train loss: 160.873856, valid precision: 0.684180, valid loss: 62328.835938
epoch: 500, train precision: 0.996116, train loss: 159.924454, valid precision: 0.688867, valid loss: 61833.937500
epoch: 501, train precision: 0.997714, train loss: 109.062088, valid precision: 0.689453, valid loss: 59386.648438
epoch: 502, train precision: 0.998335, train loss: 57.512852, valid precision: 0.691406, valid loss: 58848.675781
epoch: 503, train precision: 0.998580, train loss: 50.146591, valid precision: 0.688281, valid loss: 58701.625000
epoch: 504, train precision: 0.998380, train loss: 41.531799, valid precision: 0.688867, valid loss: 56007.937500
epoch: 505, train precision: 0.998668, train loss: 40.304897, valid precision: 0.684961, valid loss: 57000.781250
epoch: 506, train precision: 0.992991, train loss: 342.802032, valid precision: 0.681055, valid loss: 63800.476562
epoch: 507, train precision: 0.998091, train loss: 77.239876, valid precision: 0.688477, valid loss: 59838.976562
epoch: 508, train precision: 0.999046, train loss: 28.883215, valid precision: 0.697070, valid loss: 56844.781250
epoch: 509, train precision: 0.998912, train loss: 28.832165, valid precision: 0.695898, valid loss: 59259.414062
epoch: 510, train precision: 0.997070, train loss: 100.801193, valid precision: 0.692383, valid loss: 58208.062500
epoch: 511, train precision: 0.995938, train loss: 183.359268, valid precision: 0.691406, valid loss: 61593.257812
epoch: 512, train precision: 0.997181, train loss: 110.361687, valid precision: 0.684375, valid loss: 61803.304688
epoch: 513, train precision: 0.996338, train loss: 196.162155, valid precision: 0.680664, valid loss: 62180.000000
epoch: 514, train precision: 0.998091, train loss: 67.218109, valid precision: 0.692578, valid loss: 58179.144531
epoch: 515, train precision: 0.996671, train loss: 136.813782, valid precision: 0.682031, valid loss: 63593.699219
epoch: 516, train precision: 0.998491, train loss: 45.863377, valid precision: 0.688281, valid loss: 58924.554688
epoch: 517, train precision: 0.999046, train loss: 33.617775, valid precision: 0.687109, valid loss: 60883.476562
epoch: 518, train precision: 0.997181, train loss: 109.132149, valid precision: 0.684180, valid loss: 62467.539062
epoch: 519, train precision: 0.998291, train loss: 56.102150, valid precision: 0.690820, valid loss: 60702.382812
epoch: 520, train precision: 0.998491, train loss: 67.147629, valid precision: 0.690039, valid loss: 63601.949219
epoch: 521, train precision: 0.996049, train loss: 181.210144, valid precision: 0.686523, valid loss: 62938.460938
epoch: 522, train precision: 0.997803, train loss: 98.512115, valid precision: 0.690234, valid loss: 61834.351562
epoch: 523, train precision: 0.998491, train loss: 57.248123, valid precision: 0.686914, valid loss: 62867.031250
epoch: 524, train precision: 0.998047, train loss: 73.072479, valid precision: 0.690039, valid loss: 62226.511719
epoch: 525, train precision: 0.997137, train loss: 136.270248, valid precision: 0.683203, valid loss: 67459.710938
epoch: 526, train precision: 0.997692, train loss: 97.034691, valid precision: 0.694141, valid loss: 65187.074219
epoch: 527, train precision: 0.998935, train loss: 43.508316, valid precision: 0.698828, valid loss: 64987.523438
epoch: 528, train precision: 0.998469, train loss: 59.254299, valid precision: 0.691797, valid loss: 64377.300781
epoch: 529, train precision: 0.998424, train loss: 60.133846, valid precision: 0.687500, valid loss: 62219.773438
epoch: 530, train precision: 0.998025, train loss: 92.890388, valid precision: 0.683203, valid loss: 70024.265625
epoch: 531, train precision: 0.997314, train loss: 122.109489, valid precision: 0.686719, valid loss: 67451.835938
epoch: 532, train precision: 0.997159, train loss: 121.675224, valid precision: 0.683008, valid loss: 69834.953125
epoch: 533, train precision: 0.998313, train loss: 73.536995, valid precision: 0.690234, valid loss: 72694.367188
epoch: 534, train precision: 0.998801, train loss: 64.749275, valid precision: 0.693555, valid loss: 68740.742188
epoch: 535, train precision: 0.997159, train loss: 113.466576, valid precision: 0.685352, valid loss: 68759.640625
epoch: 536, train precision: 0.998735, train loss: 56.664810, valid precision: 0.694727, valid loss: 71128.968750
epoch: 537, train precision: 0.998025, train loss: 75.027763, valid precision: 0.698828, valid loss: 72328.109375
epoch: 538, train precision: 0.997714, train loss: 82.364899, valid precision: 0.685156, valid loss: 70580.617188
epoch: 539, train precision: 0.996077, train loss: 190.850983, valid precision: 0.685547, valid loss: 75257.000000
epoch: 540, train precision: 0.998113, train loss: 71.607574, valid precision: 0.692578, valid loss: 71682.046875
epoch: 541, train precision: 0.997359, train loss: 117.862679, valid precision: 0.694922, valid loss: 74878.312500
epoch: 542, train precision: 0.997736, train loss: 101.709663, valid precision: 0.690234, valid loss: 73882.437500
epoch: 543, train precision: 0.998269, train loss: 77.833618, valid precision: 0.696289, valid loss: 73145.437500
epoch: 544, train precision: 0.998025, train loss: 91.108551, valid precision: 0.696875, valid loss: 77539.921875
epoch: 545, train precision: 0.998291, train loss: 78.599236, valid precision: 0.691211, valid loss: 73400.140625
epoch: 546, train precision: 0.996005, train loss: 248.223724, valid precision: 0.696289, valid loss: 75199.187500
epoch: 547, train precision: 0.998136, train loss: 115.024529, valid precision: 0.689062, valid loss: 73528.546875
epoch: 548, train precision: 0.998535, train loss: 70.408958, valid precision: 0.693555, valid loss: 73546.757812
epoch: 549, train precision: 0.996094, train loss: 168.476303, valid precision: 0.691602, valid loss: 74381.539062
epoch: 550, train precision: 0.998335, train loss: 65.021553, valid precision: 0.693750, valid loss: 69524.265625
epoch: 551, train precision: 0.996449, train loss: 205.970703, valid precision: 0.690625, valid loss: 76998.039062
epoch: 552, train precision: 0.996715, train loss: 147.101990, valid precision: 0.681836, valid loss: 75342.484375
epoch: 553, train precision: 0.997603, train loss: 110.559059, valid precision: 0.688086, valid loss: 76417.625000
epoch: 554, train precision: 0.996848, train loss: 196.254883, valid precision: 0.683789, valid loss: 78937.226562
epoch: 555, train precision: 0.995095, train loss: 284.097534, valid precision: 0.683203, valid loss: 75926.617188
epoch: 556, train precision: 0.998491, train loss: 70.768387, valid precision: 0.691992, valid loss: 78415.617188
epoch: 557, train precision: 0.998602, train loss: 48.795265, valid precision: 0.687109, valid loss: 75905.867188
epoch: 558, train precision: 0.998757, train loss: 46.096584, valid precision: 0.681250, valid loss: 77218.828125
epoch: 559, train precision: 0.998535, train loss: 85.013924, valid precision: 0.691016, valid loss: 79180.812500
epoch: 560, train precision: 0.996316, train loss: 191.757904, valid precision: 0.683594, valid loss: 78360.875000
epoch: 561, train precision: 0.998580, train loss: 52.367477, valid precision: 0.693555, valid loss: 75743.835938
epoch: 562, train precision: 0.997803, train loss: 109.535652, valid precision: 0.687500, valid loss: 77495.421875
epoch: 563, train precision: 0.997203, train loss: 140.345139, valid precision: 0.676758, valid loss: 79266.796875
epoch: 564, train precision: 0.998713, train loss: 61.425438, valid precision: 0.682422, valid loss: 79810.960938
epoch: 565, train precision: 0.997115, train loss: 149.998276, valid precision: 0.686914, valid loss: 75715.390625
epoch: 566, train precision: 0.995051, train loss: 295.829315, valid precision: 0.684180, valid loss: 81727.375000
epoch: 567, train precision: 0.998113, train loss: 112.730904, valid precision: 0.697266, valid loss: 81590.640625
epoch: 568, train precision: 0.996782, train loss: 165.686737, valid precision: 0.681250, valid loss: 81201.976562
epoch: 569, train precision: 0.998912, train loss: 37.864414, valid precision: 0.701953, valid loss: 79541.609375
epoch: 570, train precision: 0.998935, train loss: 63.266972, valid precision: 0.700781, valid loss: 79715.859375
epoch: 571, train precision: 0.995295, train loss: 333.648193, valid precision: 0.691797, valid loss: 86632.539062
epoch: 572, train precision: 0.997736, train loss: 121.900726, valid precision: 0.686914, valid loss: 86685.203125
epoch: 573, train precision: 0.996848, train loss: 156.869766, valid precision: 0.686133, valid loss: 80237.476562
epoch: 574, train precision: 0.997248, train loss: 127.118965, valid precision: 0.680664, valid loss: 75263.125000
epoch: 575, train precision: 0.997958, train loss: 95.397316, valid precision: 0.687500, valid loss: 81645.875000
epoch: 576, train precision: 0.998890, train loss: 53.480431, valid precision: 0.686914, valid loss: 83861.164062
epoch: 577, train precision: 0.997714, train loss: 139.047012, valid precision: 0.684961, valid loss: 85675.625000
epoch: 578, train precision: 0.998469, train loss: 78.969513, valid precision: 0.690625, valid loss: 81042.429688
epoch: 579, train precision: 0.997159, train loss: 176.188507, valid precision: 0.690820, valid loss: 84563.507812
epoch: 580, train precision: 0.998868, train loss: 47.287231, valid precision: 0.689258, valid loss: 84596.273438
epoch: 581, train precision: 0.997758, train loss: 110.280251, valid precision: 0.686914, valid loss: 91055.890625
epoch: 582, train precision: 0.996804, train loss: 169.310638, valid precision: 0.691211, valid loss: 85492.203125
epoch: 583, train precision: 0.998757, train loss: 63.093361, valid precision: 0.685938, valid loss: 82570.937500
epoch: 584, train precision: 0.998469, train loss: 67.244064, valid precision: 0.691406, valid loss: 86330.367188
epoch: 585, train precision: 0.994296, train loss: 373.399017, valid precision: 0.682813, valid loss: 94847.875000
epoch: 586, train precision: 0.998469, train loss: 74.425240, valid precision: 0.692773, valid loss: 85293.671875
epoch: 587, train precision: 0.998979, train loss: 52.426071, valid precision: 0.693555, valid loss: 86857.781250
epoch: 588, train precision: 0.997891, train loss: 112.687347, valid precision: 0.686133, valid loss: 84709.125000
epoch: 589, train precision: 0.998402, train loss: 91.144737, valid precision: 0.693555, valid loss: 87903.460938
epoch: 590, train precision: 0.998025, train loss: 110.213432, valid precision: 0.691016, valid loss: 87467.210938
epoch: 591, train precision: 0.998801, train loss: 53.851147, valid precision: 0.694531, valid loss: 88504.039062
epoch: 592, train precision: 0.998491, train loss: 82.044426, valid precision: 0.687891, valid loss: 93120.070312
epoch: 593, train precision: 0.998580, train loss: 68.577034, valid precision: 0.694922, valid loss: 90996.906250
epoch: 594, train precision: 0.998180, train loss: 136.936722, valid precision: 0.686328, valid loss: 95915.671875
epoch: 595, train precision: 0.999157, train loss: 40.216984, valid precision: 0.694336, valid loss: 91557.085938
epoch: 596, train precision: 0.997448, train loss: 154.091064, valid precision: 0.678125, valid loss: 92268.515625
epoch: 597, train precision: 0.997803, train loss: 115.886383, valid precision: 0.680859, valid loss: 93936.914062
epoch: 598, train precision: 0.997869, train loss: 119.932663, valid precision: 0.690820, valid loss: 91735.625000
epoch: 599, train precision: 0.998269, train loss: 89.851494, valid precision: 0.684570, valid loss: 95147.390625
epoch: 600, train precision: 0.998646, train loss: 68.527794, valid precision: 0.690430, valid loss: 92983.304688
epoch: 601, train precision: 0.998757, train loss: 57.952213, valid precision: 0.682813, valid loss: 90937.101562
epoch: 602, train precision: 0.999401, train loss: 22.534924, valid precision: 0.691211, valid loss: 91726.429688
epoch: 603, train precision: 0.997337, train loss: 163.434387, valid precision: 0.686133, valid loss: 95740.578125
epoch: 604, train precision: 0.997492, train loss: 149.176498, valid precision: 0.697461, valid loss: 99526.898438
epoch: 605, train precision: 0.998646, train loss: 61.821041, valid precision: 0.691602, valid loss: 97358.062500
epoch: 606, train precision: 0.998713, train loss: 68.179802, valid precision: 0.698633, valid loss: 101138.851562
epoch: 607, train precision: 0.998624, train loss: 62.933372, valid precision: 0.695703, valid loss: 97435.648438
epoch: 608, train precision: 0.997736, train loss: 121.584663, valid precision: 0.690625, valid loss: 94954.203125
epoch: 609, train precision: 0.998002, train loss: 120.369652, valid precision: 0.701563, valid loss: 94856.960938
epoch: 610, train precision: 0.998580, train loss: 83.938698, valid precision: 0.700781, valid loss: 100011.687500
epoch: 611, train precision: 0.998580, train loss: 74.431953, valid precision: 0.692578, valid loss: 100288.273438
epoch: 612, train precision: 0.997337, train loss: 182.321869, valid precision: 0.681250, valid loss: 101370.328125
epoch: 613, train precision: 0.998335, train loss: 106.586052, valid precision: 0.697852, valid loss: 100068.250000
epoch: 614, train precision: 0.999023, train loss: 59.577831, valid precision: 0.691992, valid loss: 93076.851562
epoch: 615, train precision: 0.997559, train loss: 126.356621, valid precision: 0.692578, valid loss: 99712.296875
epoch: 616, train precision: 0.996604, train loss: 206.014343, valid precision: 0.683984, valid loss: 98926.484375
epoch: 617, train precision: 0.998424, train loss: 103.477295, valid precision: 0.693750, valid loss: 100980.609375
epoch: 618, train precision: 0.998491, train loss: 77.665222, valid precision: 0.697852, valid loss: 102496.640625
epoch: 619, train precision: 0.998735, train loss: 87.493156, valid precision: 0.694531, valid loss: 102236.523438
epoch: 620, train precision: 0.997536, train loss: 178.320938, valid precision: 0.690820, valid loss: 103147.390625
epoch: 621, train precision: 0.999023, train loss: 51.609043, valid precision: 0.691992, valid loss: 104410.789062
epoch: 622, train precision: 0.997914, train loss: 143.414291, valid precision: 0.692187, valid loss: 105186.437500
epoch: 623, train precision: 0.998957, train loss: 56.923183, valid precision: 0.698047, valid loss: 106149.289062
epoch: 624, train precision: 0.998402, train loss: 90.366096, valid precision: 0.692578, valid loss: 104507.101562
epoch: 625, train precision: 0.998335, train loss: 149.441513, valid precision: 0.692773, valid loss: 116977.765625
epoch: 626, train precision: 0.997270, train loss: 176.888214, valid precision: 0.696875, valid loss: 107385.203125
epoch: 627, train precision: 0.998424, train loss: 92.640213, valid precision: 0.686133, valid loss: 104442.734375
epoch: 628, train precision: 0.998535, train loss: 103.093880, valid precision: 0.697656, valid loss: 108893.125000
epoch: 629, train precision: 0.997159, train loss: 191.512985, valid precision: 0.686914, valid loss: 106732.171875
epoch: 630, train precision: 0.997914, train loss: 124.908012, valid precision: 0.697656, valid loss: 107952.976562
epoch: 631, train precision: 0.998646, train loss: 81.416351, valid precision: 0.691992, valid loss: 102796.500000
epoch: 632, train precision: 0.997980, train loss: 138.150101, valid precision: 0.691211, valid loss: 102952.132812
epoch: 633, train precision: 0.998269, train loss: 127.491608, valid precision: 0.704102, valid loss: 109316.796875
epoch: 634, train precision: 0.999112, train loss: 58.434383, valid precision: 0.699219, valid loss: 113274.046875
epoch: 635, train precision: 0.998624, train loss: 86.233185, valid precision: 0.686914, valid loss: 106697.875000
epoch: 636, train precision: 0.998713, train loss: 97.237053, valid precision: 0.688086, valid loss: 117322.351562
epoch: 637, train precision: 0.998646, train loss: 100.033638, valid precision: 0.693750, valid loss: 118385.851562
epoch: 638, train precision: 0.998979, train loss: 70.516136, valid precision: 0.697656, valid loss: 109430.062500
epoch: 639, train precision: 0.996671, train loss: 244.574753, valid precision: 0.692187, valid loss: 114034.296875
epoch: 640, train precision: 0.997914, train loss: 160.595016, valid precision: 0.696484, valid loss: 119229.851562
epoch: 641, train precision: 0.996404, train loss: 288.763397, valid precision: 0.693555, valid loss: 117209.671875
epoch: 642, train precision: 0.998624, train loss: 99.143646, valid precision: 0.688281, valid loss: 122615.375000
epoch: 643, train precision: 0.999534, train loss: 22.888674, valid precision: 0.704883, valid loss: 118595.851562
epoch: 644, train precision: 0.998668, train loss: 102.895050, valid precision: 0.699023, valid loss: 125939.640625
epoch: 645, train precision: 0.998691, train loss: 127.837837, valid precision: 0.693945, valid loss: 128267.609375
epoch: 646, train precision: 0.997359, train loss: 252.697403, valid precision: 0.687305, valid loss: 128354.890625
epoch: 647, train precision: 0.998313, train loss: 156.167419, valid precision: 0.690039, valid loss: 127063.601562
epoch: 648, train precision: 0.997470, train loss: 236.176575, valid precision: 0.688477, valid loss: 133900.203125
epoch: 649, train precision: 0.998291, train loss: 120.322777, valid precision: 0.703320, valid loss: 126525.523438
epoch: 650, train precision: 0.998868, train loss: 71.244438, valid precision: 0.691016, valid loss: 124742.976562
epoch: 651, train precision: 0.997092, train loss: 259.507355, valid precision: 0.682617, valid loss: 132399.359375
epoch: 652, train precision: 0.998202, train loss: 154.955261, valid precision: 0.700000, valid loss: 133809.671875
epoch: 653, train precision: 0.997847, train loss: 150.522659, valid precision: 0.690430, valid loss: 125522.859375
epoch: 654, train precision: 0.996493, train loss: 296.349304, valid precision: 0.690039, valid loss: 130588.078125
epoch: 655, train precision: 0.998979, train loss: 83.364388, valid precision: 0.696484, valid loss: 125744.703125
epoch: 656, train precision: 0.999046, train loss: 54.168056, valid precision: 0.704102, valid loss: 125204.773438
epoch: 657, train precision: 0.997297, train loss: 208.435852, valid precision: 0.697070, valid loss: 125912.750000
epoch: 658, train precision: 0.998491, train loss: 87.103737, valid precision: 0.691602, valid loss: 125457.523438
epoch: 659, train precision: 0.999179, train loss: 44.199757, valid precision: 0.695703, valid loss: 122049.328125
epoch: 660, train precision: 0.999445, train loss: 23.324909, valid precision: 0.698242, valid loss: 124087.078125
epoch: 661, train precision: 0.997115, train loss: 233.593170, valid precision: 0.695703, valid loss: 126600.375000
epoch: 662, train precision: 0.998957, train loss: 67.494644, valid precision: 0.698438, valid loss: 120371.046875
epoch: 663, train precision: 0.998868, train loss: 81.515167, valid precision: 0.694727, valid loss: 124905.140625
epoch: 664, train precision: 0.998363, train loss: 179.820587, valid precision: 0.697461, valid loss: 135105.906250
epoch: 665, train precision: 0.998424, train loss: 110.018730, valid precision: 0.694922, valid loss: 136260.562500
epoch: 666, train precision: 0.998691, train loss: 91.893272, valid precision: 0.693945, valid loss: 133348.234375
epoch: 667, train precision: 0.998002, train loss: 149.806534, valid precision: 0.696680, valid loss: 132451.828125
epoch: 668, train precision: 0.999445, train loss: 46.150528, valid precision: 0.700391, valid loss: 134459.671875
epoch: 669, train precision: 0.998713, train loss: 87.079582, valid precision: 0.697852, valid loss: 138974.875000
epoch: 670, train precision: 0.998269, train loss: 98.270622, valid precision: 0.694141, valid loss: 142152.656250
epoch: 671, train precision: 0.997536, train loss: 212.716354, valid precision: 0.690625, valid loss: 131812.484375
epoch: 672, train precision: 0.998713, train loss: 73.194702, valid precision: 0.691602, valid loss: 140268.468750
epoch: 673, train precision: 0.998424, train loss: 151.535248, valid precision: 0.695117, valid loss: 134483.281250
epoch: 674, train precision: 0.998691, train loss: 107.051003, valid precision: 0.702930, valid loss: 139206.843750
epoch: 675, train precision: 0.998580, train loss: 91.568542, valid precision: 0.689062, valid loss: 136594.671875
epoch: 676, train precision: 0.998735, train loss: 120.367828, valid precision: 0.693359, valid loss: 135081.656250
epoch: 677, train precision: 0.999112, train loss: 61.624733, valid precision: 0.698828, valid loss: 136369.468750
epoch: 678, train precision: 0.998469, train loss: 166.628220, valid precision: 0.694141, valid loss: 136411.406250
epoch: 679, train precision: 0.999490, train loss: 25.752312, valid precision: 0.696289, valid loss: 134823.250000
epoch: 680, train precision: 0.998602, train loss: 103.619942, valid precision: 0.701563, valid loss: 139105.296875
epoch: 681, train precision: 0.997581, train loss: 233.451920, valid precision: 0.679492, valid loss: 134162.000000
epoch: 682, train precision: 0.997203, train loss: 203.360703, valid precision: 0.684180, valid loss: 140151.703125
epoch: 683, train precision: 0.999157, train loss: 66.773140, valid precision: 0.691992, valid loss: 141793.343750
epoch: 684, train precision: 0.998779, train loss: 121.226608, valid precision: 0.684766, valid loss: 146386.406250
epoch: 685, train precision: 0.999023, train loss: 68.438065, valid precision: 0.694922, valid loss: 146531.140625
epoch: 686, train precision: 0.997825, train loss: 171.036453, valid precision: 0.689648, valid loss: 149261.468750
epoch: 687, train precision: 0.997203, train loss: 257.117279, valid precision: 0.691797, valid loss: 148194.609375
epoch: 688, train precision: 0.998890, train loss: 85.775780, valid precision: 0.698828, valid loss: 143926.750000
epoch: 689, train precision: 0.997758, train loss: 207.375916, valid precision: 0.688086, valid loss: 143024.421875
epoch: 690, train precision: 0.998824, train loss: 96.263542, valid precision: 0.695508, valid loss: 145339.343750
epoch: 691, train precision: 0.998979, train loss: 75.982727, valid precision: 0.695117, valid loss: 144106.125000
epoch: 692, train precision: 0.998136, train loss: 161.129303, valid precision: 0.691992, valid loss: 145792.218750
epoch: 693, train precision: 0.997337, train loss: 226.928223, valid precision: 0.680273, valid loss: 153436.531250
epoch: 694, train precision: 0.998535, train loss: 98.291115, valid precision: 0.687109, valid loss: 149286.484375
epoch: 695, train precision: 0.999334, train loss: 76.919785, valid precision: 0.695508, valid loss: 142938.093750
epoch: 696, train precision: 0.999401, train loss: 49.521572, valid precision: 0.692969, valid loss: 145656.250000
epoch: 697, train precision: 0.998269, train loss: 160.857361, valid precision: 0.694922, valid loss: 151880.468750
epoch: 698, train precision: 0.998469, train loss: 152.125671, valid precision: 0.688477, valid loss: 144630.187500
epoch: 699, train precision: 0.998002, train loss: 221.492172, valid precision: 0.690430, valid loss: 151319.171875
epoch: 700, train precision: 0.998624, train loss: 103.910378, valid precision: 0.688867, valid loss: 143264.046875
epoch: 701, train precision: 0.998491, train loss: 153.593277, valid precision: 0.698828, valid loss: 150284.250000
epoch: 702, train precision: 0.998491, train loss: 123.115898, valid precision: 0.688477, valid loss: 160556.828125
epoch: 703, train precision: 0.999290, train loss: 69.499161, valid precision: 0.698047, valid loss: 154120.328125
epoch: 704, train precision: 0.998691, train loss: 92.199226, valid precision: 0.685156, valid loss: 147785.640625
epoch: 705, train precision: 0.999001, train loss: 87.292114, valid precision: 0.688867, valid loss: 154729.718750
epoch: 706, train precision: 0.998291, train loss: 140.882156, valid precision: 0.685742, valid loss: 155121.875000
epoch: 707, train precision: 0.997714, train loss: 186.274643, valid precision: 0.687305, valid loss: 155725.968750
epoch: 708, train precision: 0.996848, train loss: 315.337860, valid precision: 0.682422, valid loss: 166468.640625
epoch: 709, train precision: 0.998402, train loss: 168.867874, valid precision: 0.690039, valid loss: 163529.375000
epoch: 710, train precision: 0.998824, train loss: 109.258675, valid precision: 0.692383, valid loss: 156430.218750
epoch: 711, train precision: 0.998380, train loss: 149.808014, valid precision: 0.691992, valid loss: 154002.234375
epoch: 712, train precision: 0.998580, train loss: 110.919968, valid precision: 0.686523, valid loss: 154692.468750
epoch: 713, train precision: 0.998979, train loss: 86.681465, valid precision: 0.696484, valid loss: 156075.765625
epoch: 714, train precision: 0.997958, train loss: 239.457870, valid precision: 0.703125, valid loss: 157613.281250
epoch: 715, train precision: 0.998779, train loss: 104.693756, valid precision: 0.699023, valid loss: 156798.093750
epoch: 716, train precision: 0.998247, train loss: 198.921524, valid precision: 0.693945, valid loss: 159193.796875
epoch: 717, train precision: 0.997825, train loss: 258.752655, valid precision: 0.685547, valid loss: 161109.015625
epoch: 718, train precision: 0.998580, train loss: 118.716454, valid precision: 0.693945, valid loss: 160614.218750
epoch: 719, train precision: 0.998846, train loss: 115.048805, valid precision: 0.689453, valid loss: 164292.593750
epoch: 720, train precision: 0.999001, train loss: 92.894646, valid precision: 0.692578, valid loss: 164254.546875
epoch: 721, train precision: 0.998713, train loss: 178.063583, valid precision: 0.685156, valid loss: 161230.718750
epoch: 722, train precision: 0.998602, train loss: 98.896515, valid precision: 0.687891, valid loss: 167675.703125
epoch: 723, train precision: 0.998691, train loss: 151.784622, valid precision: 0.691016, valid loss: 165658.421875
epoch: 724, train precision: 0.998535, train loss: 164.838181, valid precision: 0.692969, valid loss: 172739.921875
epoch: 725, train precision: 0.998469, train loss: 136.942398, valid precision: 0.685547, valid loss: 171375.656250
epoch: 726, train precision: 0.998491, train loss: 142.370331, valid precision: 0.685742, valid loss: 170865.531250
epoch: 727, train precision: 0.999134, train loss: 82.519218, valid precision: 0.694531, valid loss: 172530.437500
epoch: 728, train precision: 0.998202, train loss: 127.201271, valid precision: 0.680664, valid loss: 172294.750000
epoch: 729, train precision: 0.999134, train loss: 92.805252, valid precision: 0.694531, valid loss: 168021.296875
epoch: 730, train precision: 0.998602, train loss: 151.619247, valid precision: 0.696680, valid loss: 166330.093750
epoch: 731, train precision: 0.998335, train loss: 166.472900, valid precision: 0.692578, valid loss: 163982.187500
epoch: 732, train precision: 0.998801, train loss: 85.977570, valid precision: 0.690234, valid loss: 165673.000000
epoch: 733, train precision: 0.998224, train loss: 241.027542, valid precision: 0.688477, valid loss: 172790.843750
epoch: 734, train precision: 0.998691, train loss: 121.224197, valid precision: 0.680078, valid loss: 166961.265625
epoch: 735, train precision: 0.999112, train loss: 76.171822, valid precision: 0.693750, valid loss: 169815.343750
epoch: 736, train precision: 0.999090, train loss: 99.742584, valid precision: 0.696484, valid loss: 172458.031250
epoch: 737, train precision: 0.998291, train loss: 193.173645, valid precision: 0.690625, valid loss: 176362.781250
epoch: 738, train precision: 0.998757, train loss: 98.387848, valid precision: 0.694531, valid loss: 165403.281250
epoch: 739, train precision: 0.998446, train loss: 141.356750, valid precision: 0.691797, valid loss: 166747.625000
epoch: 740, train precision: 0.999068, train loss: 95.595428, valid precision: 0.692773, valid loss: 166130.750000
epoch: 741, train precision: 0.998580, train loss: 134.932877, valid precision: 0.696289, valid loss: 170804.203125
epoch: 742, train precision: 0.997403, train loss: 254.060196, valid precision: 0.685352, valid loss: 169844.593750
epoch: 743, train precision: 0.998513, train loss: 130.348160, valid precision: 0.691016, valid loss: 173341.968750
epoch: 744, train precision: 0.998136, train loss: 211.739609, valid precision: 0.693945, valid loss: 186973.625000
epoch: 745, train precision: 0.999090, train loss: 83.993355, valid precision: 0.694141, valid loss: 181274.125000
epoch: 746, train precision: 0.998602, train loss: 125.683464, valid precision: 0.689648, valid loss: 185560.468750
epoch: 747, train precision: 0.997936, train loss: 264.879517, valid precision: 0.692383, valid loss: 180427.671875
epoch: 748, train precision: 0.998136, train loss: 212.238419, valid precision: 0.686523, valid loss: 190121.906250
epoch: 749, train precision: 0.997470, train loss: 327.273315, valid precision: 0.677148, valid loss: 182903.171875
epoch: 750, train precision: 0.998247, train loss: 175.268021, valid precision: 0.685742, valid loss: 180757.906250
epoch: 751, train precision: 0.999334, train loss: 65.352913, valid precision: 0.685938, valid loss: 181080.343750
epoch: 752, train precision: 0.999001, train loss: 173.174774, valid precision: 0.683984, valid loss: 174786.171875
epoch: 753, train precision: 0.998180, train loss: 202.917252, valid precision: 0.684766, valid loss: 178934.812500
epoch: 754, train precision: 0.999401, train loss: 57.871792, valid precision: 0.691992, valid loss: 178965.328125
epoch: 755, train precision: 0.998824, train loss: 88.710121, valid precision: 0.689844, valid loss: 181251.968750
epoch: 756, train precision: 0.999046, train loss: 86.992805, valid precision: 0.689648, valid loss: 178570.656250
epoch: 757, train precision: 0.998846, train loss: 123.555466, valid precision: 0.689062, valid loss: 194695.828125
epoch: 758, train precision: 0.998291, train loss: 227.132507, valid precision: 0.689844, valid loss: 186777.500000
epoch: 759, train precision: 0.998979, train loss: 80.307602, valid precision: 0.691992, valid loss: 184503.406250
epoch: 760, train precision: 0.999223, train loss: 91.245316, valid precision: 0.690625, valid loss: 184836.453125
epoch: 761, train precision: 0.998912, train loss: 107.882820, valid precision: 0.693945, valid loss: 178612.343750
epoch: 762, train precision: 0.997581, train loss: 281.708984, valid precision: 0.678125, valid loss: 189753.000000
epoch: 763, train precision: 0.998624, train loss: 160.795898, valid precision: 0.684375, valid loss: 183222.781250
epoch: 764, train precision: 0.999134, train loss: 69.008842, valid precision: 0.689062, valid loss: 189707.828125
epoch: 765, train precision: 0.999157, train loss: 84.467209, valid precision: 0.690430, valid loss: 191789.859375
epoch: 766, train precision: 0.998868, train loss: 98.509270, valid precision: 0.694336, valid loss: 189851.093750
epoch: 767, train precision: 0.997070, train loss: 379.807526, valid precision: 0.682422, valid loss: 207612.156250
epoch: 768, train precision: 0.998846, train loss: 130.735748, valid precision: 0.694922, valid loss: 204877.671875
epoch: 769, train precision: 0.997825, train loss: 239.615097, valid precision: 0.680273, valid loss: 196984.531250
epoch: 770, train precision: 0.999290, train loss: 67.387260, valid precision: 0.683789, valid loss: 194641.546875
epoch: 771, train precision: 0.998557, train loss: 166.346054, valid precision: 0.687109, valid loss: 196960.968750
epoch: 772, train precision: 0.997891, train loss: 282.129425, valid precision: 0.684375, valid loss: 195639.234375
epoch: 773, train precision: 0.999068, train loss: 106.403175, valid precision: 0.688086, valid loss: 199137.171875
epoch: 774, train precision: 0.999023, train loss: 92.725510, valid precision: 0.691016, valid loss: 201568.015625
epoch: 775, train precision: 0.998513, train loss: 180.226227, valid precision: 0.692578, valid loss: 202472.046875
epoch: 776, train precision: 0.997337, train loss: 323.289429, valid precision: 0.680859, valid loss: 205011.062500
epoch: 777, train precision: 0.998846, train loss: 142.604828, valid precision: 0.690820, valid loss: 211303.968750
epoch: 778, train precision: 0.998491, train loss: 181.134293, valid precision: 0.691016, valid loss: 206725.093750
epoch: 779, train precision: 0.998757, train loss: 159.368439, valid precision: 0.688477, valid loss: 197237.046875
epoch: 780, train precision: 0.999290, train loss: 69.874611, valid precision: 0.699219, valid loss: 201007.093750
epoch: 781, train precision: 0.999512, train loss: 64.634880, valid precision: 0.689062, valid loss: 197337.781250
epoch: 782, train precision: 0.999157, train loss: 85.273651, valid precision: 0.683594, valid loss: 201595.390625
epoch: 783, train precision: 0.998801, train loss: 151.561310, valid precision: 0.693359, valid loss: 212600.421875
epoch: 784, train precision: 0.998469, train loss: 199.095032, valid precision: 0.685156, valid loss: 207514.156250
epoch: 785, train precision: 0.998957, train loss: 106.628792, valid precision: 0.686914, valid loss: 195730.140625
epoch: 786, train precision: 0.998291, train loss: 199.541321, valid precision: 0.686523, valid loss: 214929.593750
epoch: 787, train precision: 0.998580, train loss: 128.199768, valid precision: 0.691406, valid loss: 209260.796875
epoch: 788, train precision: 0.997425, train loss: 326.855530, valid precision: 0.684570, valid loss: 213483.343750
epoch: 789, train precision: 0.999157, train loss: 93.346283, valid precision: 0.690430, valid loss: 213525.546875
epoch: 790, train precision: 0.998491, train loss: 168.892517, valid precision: 0.681836, valid loss: 202601.828125
epoch: 791, train precision: 0.998957, train loss: 145.137161, valid precision: 0.687109, valid loss: 219020.796875
epoch: 792, train precision: 0.998446, train loss: 236.283157, valid precision: 0.683594, valid loss: 224322.578125
epoch: 793, train precision: 0.998491, train loss: 145.084167, valid precision: 0.689844, valid loss: 214683.750000
epoch: 794, train precision: 0.998846, train loss: 144.582718, valid precision: 0.682617, valid loss: 217773.328125
epoch: 795, train precision: 0.998779, train loss: 134.660324, valid precision: 0.688281, valid loss: 215949.500000
epoch: 796, train precision: 0.999201, train loss: 97.309296, valid precision: 0.696094, valid loss: 227190.953125
epoch: 797, train precision: 0.997958, train loss: 292.629761, valid precision: 0.687695, valid loss: 225536.250000
epoch: 798, train precision: 0.998580, train loss: 203.714752, valid precision: 0.683789, valid loss: 220242.796875
epoch: 799, train precision: 0.999334, train loss: 60.896057, valid precision: 0.690625, valid loss: 215496.250000
epoch: 800, train precision: 0.997159, train loss: 318.898529, valid precision: 0.679688, valid loss: 226101.156250
epoch: 801, train precision: 0.998801, train loss: 240.207474, valid precision: 0.694336, valid loss: 229222.531250
epoch: 802, train precision: 0.998247, train loss: 245.383728, valid precision: 0.698438, valid loss: 213936.281250
epoch: 803, train precision: 0.998557, train loss: 182.069229, valid precision: 0.686914, valid loss: 222377.093750
epoch: 804, train precision: 0.998535, train loss: 166.674622, valid precision: 0.690039, valid loss: 218546.750000
epoch: 805, train precision: 0.999512, train loss: 57.701038, valid precision: 0.692969, valid loss: 220625.500000
epoch: 806, train precision: 0.998446, train loss: 318.392456, valid precision: 0.699023, valid loss: 228968.906250
epoch: 807, train precision: 0.998113, train loss: 233.925522, valid precision: 0.693555, valid loss: 230740.718750
epoch: 808, train precision: 0.999157, train loss: 96.101898, valid precision: 0.700781, valid loss: 218169.406250
epoch: 809, train precision: 0.999490, train loss: 45.935627, valid precision: 0.693359, valid loss: 220829.328125
epoch: 810, train precision: 0.999268, train loss: 79.123909, valid precision: 0.698828, valid loss: 219710.750000
epoch: 811, train precision: 0.998535, train loss: 188.717636, valid precision: 0.690430, valid loss: 229661.500000
epoch: 812, train precision: 0.998646, train loss: 185.708313, valid precision: 0.696484, valid loss: 231515.593750
epoch: 813, train precision: 0.998513, train loss: 195.122513, valid precision: 0.695703, valid loss: 242898.953125
epoch: 814, train precision: 0.999023, train loss: 125.897293, valid precision: 0.695703, valid loss: 232658.203125
epoch: 815, train precision: 0.996959, train loss: 472.014557, valid precision: 0.689062, valid loss: 236383.343750
epoch: 816, train precision: 0.999112, train loss: 163.024796, valid precision: 0.683594, valid loss: 234038.578125
epoch: 817, train precision: 0.997647, train loss: 362.183075, valid precision: 0.688672, valid loss: 237202.406250
epoch: 818, train precision: 0.999157, train loss: 77.573433, valid precision: 0.690820, valid loss: 230996.531250
epoch: 819, train precision: 0.999356, train loss: 98.412041, valid precision: 0.699609, valid loss: 235729.953125
epoch: 820, train precision: 0.999179, train loss: 108.019775, valid precision: 0.694336, valid loss: 237670.546875
epoch: 821, train precision: 0.999157, train loss: 86.726814, valid precision: 0.696289, valid loss: 229858.000000
epoch: 822, train precision: 0.997781, train loss: 379.476440, valid precision: 0.688867, valid loss: 234276.593750
epoch: 823, train precision: 0.999134, train loss: 113.145409, valid precision: 0.699023, valid loss: 226169.171875
epoch: 824, train precision: 0.999445, train loss: 50.883495, valid precision: 0.693750, valid loss: 233718.281250
epoch: 825, train precision: 0.999334, train loss: 95.134911, valid precision: 0.699805, valid loss: 236550.796875
epoch: 826, train precision: 0.998846, train loss: 174.275421, valid precision: 0.692187, valid loss: 234017.796875
epoch: 827, train precision: 0.998779, train loss: 140.828247, valid precision: 0.688672, valid loss: 229858.781250
epoch: 828, train precision: 0.998935, train loss: 120.085442, valid precision: 0.696875, valid loss: 239918.218750
epoch: 829, train precision: 0.998890, train loss: 163.190872, valid precision: 0.693945, valid loss: 235397.203125
epoch: 830, train precision: 0.998291, train loss: 307.860870, valid precision: 0.689844, valid loss: 248198.125000
epoch: 831, train precision: 0.998358, train loss: 322.913910, valid precision: 0.683398, valid loss: 244331.906250
epoch: 832, train precision: 0.998735, train loss: 191.931503, valid precision: 0.687695, valid loss: 230670.703125
epoch: 833, train precision: 0.999179, train loss: 94.796562, valid precision: 0.688086, valid loss: 235209.531250
epoch: 834, train precision: 0.999157, train loss: 91.610229, valid precision: 0.698828, valid loss: 236907.125000
epoch: 835, train precision: 0.996848, train loss: 563.799072, valid precision: 0.687500, valid loss: 258502.703125
epoch: 836, train precision: 0.998313, train loss: 266.304077, valid precision: 0.692187, valid loss: 249995.406250
epoch: 837, train precision: 0.999046, train loss: 129.142334, valid precision: 0.696680, valid loss: 239937.281250
epoch: 838, train precision: 0.998469, train loss: 228.269043, valid precision: 0.689844, valid loss: 255102.078125
epoch: 839, train precision: 0.999134, train loss: 97.280952, valid precision: 0.691406, valid loss: 251130.921875
epoch: 840, train precision: 0.997292, train loss: 518.729614, valid precision: 0.683594, valid loss: 250188.625000
epoch: 841, train precision: 0.998979, train loss: 164.920670, valid precision: 0.690039, valid loss: 248734.171875
epoch: 842, train precision: 0.999179, train loss: 114.031670, valid precision: 0.693750, valid loss: 245251.453125
epoch: 843, train precision: 0.999134, train loss: 105.456978, valid precision: 0.693750, valid loss: 255012.218750
epoch: 844, train precision: 0.998646, train loss: 136.916275, valid precision: 0.697461, valid loss: 245501.093750
epoch: 845, train precision: 0.997914, train loss: 449.558685, valid precision: 0.699805, valid loss: 250964.125000
epoch: 846, train precision: 0.998890, train loss: 192.447998, valid precision: 0.699219, valid loss: 252042.906250
epoch: 847, train precision: 0.996893, train loss: 625.764587, valid precision: 0.687305, valid loss: 261947.593750
epoch: 848, train precision: 0.999134, train loss: 116.438431, valid precision: 0.696094, valid loss: 256102.046875
epoch: 849, train precision: 0.999179, train loss: 106.249313, valid precision: 0.701172, valid loss: 257066.406250
epoch: 850, train precision: 0.999245, train loss: 100.336594, valid precision: 0.696875, valid loss: 256984.593750
epoch: 851, train precision: 0.998979, train loss: 157.072220, valid precision: 0.699414, valid loss: 253391.796875
epoch: 852, train precision: 0.998535, train loss: 160.969055, valid precision: 0.695117, valid loss: 251462.296875
epoch: 853, train precision: 0.999334, train loss: 79.358528, valid precision: 0.693359, valid loss: 257207.000000
epoch: 854, train precision: 0.999312, train loss: 95.742805, valid precision: 0.698242, valid loss: 251876.250000
epoch: 855, train precision: 0.996982, train loss: 479.981659, valid precision: 0.691797, valid loss: 265535.937500
epoch: 856, train precision: 0.999512, train loss: 58.257126, valid precision: 0.693555, valid loss: 255351.718750
epoch: 857, train precision: 0.999112, train loss: 124.075043, valid precision: 0.693750, valid loss: 246038.968750
epoch: 858, train precision: 0.999445, train loss: 57.634693, valid precision: 0.697656, valid loss: 255851.593750
epoch: 859, train precision: 0.999023, train loss: 141.386414, valid precision: 0.690820, valid loss: 264995.937500
epoch: 860, train precision: 0.999512, train loss: 49.430103, valid precision: 0.700781, valid loss: 268429.687500
epoch: 861, train precision: 0.998313, train loss: 220.125534, valid precision: 0.689453, valid loss: 258283.296875
epoch: 862, train precision: 0.998868, train loss: 201.713196, valid precision: 0.691211, valid loss: 269908.437500
epoch: 863, train precision: 0.998002, train loss: 410.368195, valid precision: 0.691797, valid loss: 279008.187500
epoch: 864, train precision: 0.998912, train loss: 178.316360, valid precision: 0.689453, valid loss: 263439.562500
epoch: 865, train precision: 0.998624, train loss: 242.527039, valid precision: 0.688867, valid loss: 261579.843750
epoch: 866, train precision: 0.998557, train loss: 224.568619, valid precision: 0.694531, valid loss: 261760.453125
epoch: 867, train precision: 0.998557, train loss: 279.978729, valid precision: 0.694922, valid loss: 266016.312500
epoch: 868, train precision: 0.999490, train loss: 53.158241, valid precision: 0.696875, valid loss: 257552.796875
epoch: 869, train precision: 0.998047, train loss: 277.553009, valid precision: 0.686914, valid loss: 261300.093750
epoch: 870, train precision: 0.999001, train loss: 175.618103, valid precision: 0.703516, valid loss: 268447.843750
epoch: 871, train precision: 0.998801, train loss: 169.792023, valid precision: 0.694922, valid loss: 280509.000000
epoch: 872, train precision: 0.998912, train loss: 188.294388, valid precision: 0.702344, valid loss: 278102.968750
epoch: 873, train precision: 0.998868, train loss: 172.148270, valid precision: 0.693945, valid loss: 263771.906250
epoch: 874, train precision: 0.999179, train loss: 106.910133, valid precision: 0.692578, valid loss: 272554.687500
epoch: 875, train precision: 0.998935, train loss: 210.030762, valid precision: 0.693555, valid loss: 275315.906250
epoch: 876, train precision: 0.999423, train loss: 75.592903, valid precision: 0.700195, valid loss: 263769.343750
epoch: 877, train precision: 0.999223, train loss: 125.050583, valid precision: 0.700195, valid loss: 266722.187500
epoch: 878, train precision: 0.998801, train loss: 238.547668, valid precision: 0.701367, valid loss: 271950.343750
epoch: 879, train precision: 0.998247, train loss: 304.100403, valid precision: 0.696289, valid loss: 283342.500000
epoch: 880, train precision: 0.999467, train loss: 61.364475, valid precision: 0.698828, valid loss: 284165.343750
epoch: 881, train precision: 0.997425, train loss: 598.958130, valid precision: 0.688477, valid loss: 302281.937500
epoch: 882, train precision: 0.999467, train loss: 79.521133, valid precision: 0.699805, valid loss: 285574.187500
epoch: 883, train precision: 0.999023, train loss: 131.507477, valid precision: 0.694336, valid loss: 278525.937500
epoch: 884, train precision: 0.998846, train loss: 223.730484, valid precision: 0.698438, valid loss: 284215.406250
epoch: 885, train precision: 0.999090, train loss: 181.862381, valid precision: 0.698633, valid loss: 295239.062500
epoch: 886, train precision: 0.999223, train loss: 207.130508, valid precision: 0.695508, valid loss: 288351.000000
epoch: 887, train precision: 0.997825, train loss: 385.703613, valid precision: 0.697461, valid loss: 288484.156250
epoch: 888, train precision: 0.998868, train loss: 151.158951, valid precision: 0.699609, valid loss: 282809.437500
epoch: 889, train precision: 0.999201, train loss: 122.165382, valid precision: 0.703320, valid loss: 292834.406250
epoch: 890, train precision: 0.997381, train loss: 505.846191, valid precision: 0.691602, valid loss: 284554.062500
epoch: 891, train precision: 0.999490, train loss: 53.424183, valid precision: 0.693359, valid loss: 283088.843750
epoch: 892, train precision: 0.999001, train loss: 209.890808, valid precision: 0.698828, valid loss: 299355.500000
epoch: 893, train precision: 0.999268, train loss: 84.198898, valid precision: 0.700195, valid loss: 291496.937500
epoch: 894, train precision: 0.998979, train loss: 175.764801, valid precision: 0.697461, valid loss: 297680.156250
epoch: 895, train precision: 0.999467, train loss: 114.129593, valid precision: 0.704687, valid loss: 290862.343750
epoch: 896, train precision: 0.999001, train loss: 161.248230, valid precision: 0.698047, valid loss: 312647.156250
epoch: 897, train precision: 0.998646, train loss: 202.029968, valid precision: 0.697070, valid loss: 306673.937500
epoch: 898, train precision: 0.999467, train loss: 80.434235, valid precision: 0.704492, valid loss: 304750.093750
epoch: 899, train precision: 0.999157, train loss: 181.514786, valid precision: 0.692187, valid loss: 303371.625000
epoch: 900, train precision: 0.998935, train loss: 150.738846, valid precision: 0.692187, valid loss: 300585.906250
epoch: 901, train precision: 0.998646, train loss: 267.128326, valid precision: 0.696484, valid loss: 308882.906250
epoch: 902, train precision: 0.997958, train loss: 364.375793, valid precision: 0.692187, valid loss: 309472.937500
epoch: 903, train precision: 0.999223, train loss: 152.400894, valid precision: 0.694336, valid loss: 301685.750000
epoch: 904, train precision: 0.999512, train loss: 54.537319, valid precision: 0.698047, valid loss: 301101.343750
epoch: 905, train precision: 0.998113, train loss: 313.123383, valid precision: 0.689062, valid loss: 304534.812500
epoch: 906, train precision: 0.999290, train loss: 164.466217, valid precision: 0.705078, valid loss: 309724.062500
epoch: 907, train precision: 0.997958, train loss: 327.140839, valid precision: 0.699414, valid loss: 317460.062500
epoch: 908, train precision: 0.998691, train loss: 247.121979, valid precision: 0.700000, valid loss: 321582.218750
epoch: 909, train precision: 0.996826, train loss: 880.030212, valid precision: 0.694531, valid loss: 341639.312500
epoch: 910, train precision: 0.999268, train loss: 159.874908, valid precision: 0.702344, valid loss: 330763.062500
epoch: 911, train precision: 0.998691, train loss: 284.635742, valid precision: 0.700000, valid loss: 318708.156250
epoch: 912, train precision: 0.999268, train loss: 102.370872, valid precision: 0.695703, valid loss: 309537.656250
epoch: 913, train precision: 0.999467, train loss: 98.726631, valid precision: 0.701563, valid loss: 317642.906250
epoch: 914, train precision: 0.999001, train loss: 124.777107, valid precision: 0.700586, valid loss: 321445.375000
epoch: 915, train precision: 0.999334, train loss: 103.784279, valid precision: 0.706250, valid loss: 330080.093750
epoch: 916, train precision: 0.999134, train loss: 158.083801, valid precision: 0.696094, valid loss: 320328.687500
epoch: 917, train precision: 0.999179, train loss: 196.921783, valid precision: 0.695312, valid loss: 311278.562500
epoch: 918, train precision: 0.999090, train loss: 202.407227, valid precision: 0.698828, valid loss: 311237.812500
epoch: 919, train precision: 0.998557, train loss: 248.824280, valid precision: 0.696680, valid loss: 323073.218750
epoch: 920, train precision: 0.998979, train loss: 172.188568, valid precision: 0.696875, valid loss: 335774.062500
epoch: 921, train precision: 0.999401, train loss: 185.940521, valid precision: 0.698633, valid loss: 346924.937500
epoch: 922, train precision: 0.998402, train loss: 280.735229, valid precision: 0.697656, valid loss: 353483.937500
epoch: 923, train precision: 0.998069, train loss: 430.566437, valid precision: 0.694727, valid loss: 337411.687500
epoch: 924, train precision: 0.998624, train loss: 302.468933, valid precision: 0.699023, valid loss: 336897.875000
epoch: 925, train precision: 0.998801, train loss: 236.085785, valid precision: 0.703516, valid loss: 326642.250000
epoch: 926, train precision: 0.998624, train loss: 231.447662, valid precision: 0.703711, valid loss: 334796.687500
epoch: 927, train precision: 0.999290, train loss: 146.233032, valid precision: 0.704297, valid loss: 334315.937500
epoch: 928, train precision: 0.999667, train loss: 42.678421, valid precision: 0.702734, valid loss: 315505.312500
epoch: 929, train precision: 0.999223, train loss: 137.077866, valid precision: 0.695508, valid loss: 320098.562500
epoch: 930, train precision: 0.997758, train loss: 475.812683, valid precision: 0.695898, valid loss: 321713.531250
epoch: 931, train precision: 0.997980, train loss: 457.257233, valid precision: 0.697852, valid loss: 333624.062500
epoch: 932, train precision: 0.998979, train loss: 168.223343, valid precision: 0.694727, valid loss: 308269.562500
epoch: 933, train precision: 0.998535, train loss: 298.833801, valid precision: 0.696094, valid loss: 329532.250000
epoch: 934, train precision: 0.997492, train loss: 586.250732, valid precision: 0.695508, valid loss: 343704.562500
epoch: 935, train precision: 0.999023, train loss: 163.355865, valid precision: 0.693945, valid loss: 346183.437500
epoch: 936, train precision: 0.997914, train loss: 353.381958, valid precision: 0.693750, valid loss: 338163.062500
epoch: 937, train precision: 0.999023, train loss: 149.034576, valid precision: 0.693750, valid loss: 342476.593750
epoch: 938, train precision: 0.998535, train loss: 310.512939, valid precision: 0.694336, valid loss: 348251.406250
epoch: 939, train precision: 0.998912, train loss: 205.233246, valid precision: 0.696484, valid loss: 334500.718750
epoch: 940, train precision: 0.999467, train loss: 155.260971, valid precision: 0.699414, valid loss: 339077.312500
epoch: 941, train precision: 0.997603, train loss: 482.501740, valid precision: 0.696680, valid loss: 345510.093750
epoch: 942, train precision: 0.998646, train loss: 218.389160, valid precision: 0.695703, valid loss: 349735.218750
epoch: 943, train precision: 0.999556, train loss: 41.596130, valid precision: 0.700391, valid loss: 341323.406250
epoch: 944, train precision: 0.999490, train loss: 91.043549, valid precision: 0.703125, valid loss: 355437.531250
epoch: 945, train precision: 0.998557, train loss: 246.984039, valid precision: 0.697852, valid loss: 343720.875000
epoch: 946, train precision: 0.999645, train loss: 38.993843, valid precision: 0.702539, valid loss: 355135.937500
epoch: 947, train precision: 0.999223, train loss: 128.086868, valid precision: 0.698438, valid loss: 360358.000000
epoch: 948, train precision: 0.999201, train loss: 151.556549, valid precision: 0.705273, valid loss: 349733.437500
epoch: 949, train precision: 0.999179, train loss: 215.560638, valid precision: 0.694141, valid loss: 357327.625000
epoch: 950, train precision: 0.999445, train loss: 116.532295, valid precision: 0.696484, valid loss: 346205.250000
epoch: 951, train precision: 0.999090, train loss: 142.758728, valid precision: 0.699805, valid loss: 351125.625000
epoch: 952, train precision: 0.999534, train loss: 86.654572, valid precision: 0.702344, valid loss: 347147.562500
epoch: 953, train precision: 0.999667, train loss: 62.043575, valid precision: 0.705078, valid loss: 352398.312500
epoch: 954, train precision: 0.999112, train loss: 131.829193, valid precision: 0.696680, valid loss: 355176.125000
epoch: 955, train precision: 0.998136, train loss: 409.510834, valid precision: 0.700586, valid loss: 359974.000000
epoch: 956, train precision: 0.998757, train loss: 301.811554, valid precision: 0.701172, valid loss: 362468.281250
epoch: 957, train precision: 0.999512, train loss: 85.491608, valid precision: 0.701367, valid loss: 360907.656250
epoch: 958, train precision: 0.998535, train loss: 251.103363, valid precision: 0.695898, valid loss: 358856.093750
epoch: 959, train precision: 0.998624, train loss: 214.208267, valid precision: 0.696484, valid loss: 344476.093750
epoch: 960, train precision: 0.998890, train loss: 267.358704, valid precision: 0.703906, valid loss: 366124.531250
epoch: 961, train precision: 0.999711, train loss: 54.751205, valid precision: 0.704297, valid loss: 366223.093750
epoch: 962, train precision: 0.999334, train loss: 124.860832, valid precision: 0.706641, valid loss: 375182.062500
epoch: 963, train precision: 0.999134, train loss: 207.629379, valid precision: 0.703125, valid loss: 376249.218750
epoch: 964, train precision: 0.998446, train loss: 403.214874, valid precision: 0.701758, valid loss: 361160.000000
epoch: 965, train precision: 0.998469, train loss: 390.378723, valid precision: 0.703516, valid loss: 368155.125000
epoch: 966, train precision: 0.999445, train loss: 94.811180, valid precision: 0.700195, valid loss: 369257.687500
epoch: 967, train precision: 0.999334, train loss: 93.096634, valid precision: 0.703320, valid loss: 374775.593750
epoch: 968, train precision: 0.998646, train loss: 226.680801, valid precision: 0.698438, valid loss: 374209.500000
epoch: 969, train precision: 0.999112, train loss: 168.320862, valid precision: 0.702734, valid loss: 378796.406250
epoch: 970, train precision: 0.998535, train loss: 298.375031, valid precision: 0.695312, valid loss: 373885.312500
epoch: 971, train precision: 0.998469, train loss: 330.945282, valid precision: 0.693359, valid loss: 381149.593750
epoch: 972, train precision: 0.998002, train loss: 421.212280, valid precision: 0.694727, valid loss: 357310.406250
epoch: 973, train precision: 0.999290, train loss: 137.397110, valid precision: 0.696680, valid loss: 376446.656250
epoch: 974, train precision: 0.999001, train loss: 116.733353, valid precision: 0.698242, valid loss: 367228.062500
epoch: 975, train precision: 0.998935, train loss: 227.748093, valid precision: 0.697656, valid loss: 373317.062500
epoch: 976, train precision: 0.998979, train loss: 230.398697, valid precision: 0.701172, valid loss: 362580.187500
epoch: 977, train precision: 0.998735, train loss: 285.141113, valid precision: 0.695508, valid loss: 365320.281250
epoch: 978, train precision: 0.998335, train loss: 344.354614, valid precision: 0.698047, valid loss: 375376.031250
epoch: 979, train precision: 0.999512, train loss: 95.516609, valid precision: 0.694336, valid loss: 364996.406250
epoch: 980, train precision: 0.999290, train loss: 124.275215, valid precision: 0.694727, valid loss: 366659.062500
epoch: 981, train precision: 0.998779, train loss: 245.951477, valid precision: 0.694922, valid loss: 374419.406250
epoch: 982, train precision: 0.998096, train loss: 457.842255, valid precision: 0.689453, valid loss: 370187.781250
epoch: 983, train precision: 0.999445, train loss: 107.447395, valid precision: 0.697461, valid loss: 379440.031250
epoch: 984, train precision: 0.998358, train loss: 478.984772, valid precision: 0.693164, valid loss: 406743.500000
epoch: 985, train precision: 0.999023, train loss: 215.479889, valid precision: 0.699023, valid loss: 389538.937500
epoch: 986, train precision: 0.999600, train loss: 75.121292, valid precision: 0.701172, valid loss: 392454.000000
epoch: 987, train precision: 0.999356, train loss: 166.021225, valid precision: 0.699023, valid loss: 398284.187500
epoch: 988, train precision: 0.999112, train loss: 193.438034, valid precision: 0.703320, valid loss: 386493.156250
epoch: 989, train precision: 0.999667, train loss: 77.756355, valid precision: 0.696875, valid loss: 384481.468750
epoch: 990, train precision: 0.998912, train loss: 218.460403, valid precision: 0.697852, valid loss: 408678.250000
epoch: 991, train precision: 0.998868, train loss: 244.565033, valid precision: 0.708398, valid loss: 390717.687500
epoch: 992, train precision: 0.997692, train loss: 573.169495, valid precision: 0.687109, valid loss: 420003.437500
epoch: 993, train precision: 0.998002, train loss: 415.329315, valid precision: 0.693750, valid loss: 400295.125000
epoch: 994, train precision: 0.999578, train loss: 50.945400, valid precision: 0.696680, valid loss: 406379.812500
epoch: 995, train precision: 0.999756, train loss: 26.834261, valid precision: 0.700000, valid loss: 409954.250000
epoch: 996, train precision: 0.998025, train loss: 454.021851, valid precision: 0.690039, valid loss: 405171.437500
epoch: 997, train precision: 0.998580, train loss: 315.469757, valid precision: 0.693359, valid loss: 425789.187500
epoch: 998, train precision: 0.999223, train loss: 215.423523, valid precision: 0.696680, valid loss: 410372.312500
epoch: 999, train precision: 0.999423, train loss: 85.008881, valid precision: 0.690625, valid loss: 390194.500000
epoch: 1000, train precision: 0.998580, train loss: 346.296356, valid precision: 0.693164, valid loss: 406636.187500
epoch: 1001, train precision: 0.999711, train loss: 52.533859, valid precision: 0.700977, valid loss: 416566.687500
epoch: 1002, train precision: 0.999490, train loss: 137.710648, valid precision: 0.698633, valid loss: 417740.062500
epoch: 1003, train precision: 0.998402, train loss: 385.329987, valid precision: 0.686719, valid loss: 421017.093750
epoch: 1004, train precision: 0.999356, train loss: 106.418549, valid precision: 0.704883, valid loss: 396032.687500
epoch: 1005, train precision: 0.997314, train loss: 542.751587, valid precision: 0.682813, valid loss: 405350.812500
epoch: 1006, train precision: 0.999023, train loss: 349.956726, valid precision: 0.691797, valid loss: 396261.406250
epoch: 1007, train precision: 0.999290, train loss: 234.514343, valid precision: 0.692187, valid loss: 418186.593750
epoch: 1008, train precision: 0.998491, train loss: 385.713165, valid precision: 0.691797, valid loss: 404887.468750
epoch: 1009, train precision: 0.999334, train loss: 159.382141, valid precision: 0.692773, valid loss: 407092.812500
epoch: 1010, train precision: 0.999134, train loss: 241.556946, valid precision: 0.696680, valid loss: 420106.656250
epoch: 1011, train precision: 0.998713, train loss: 297.453796, valid precision: 0.690430, valid loss: 411624.312500
epoch: 1012, train precision: 0.998668, train loss: 333.605438, valid precision: 0.696875, valid loss: 415000.906250
epoch: 1013, train precision: 0.999356, train loss: 132.590210, valid precision: 0.692383, valid loss: 413204.750000
epoch: 1014, train precision: 0.999134, train loss: 183.427551, valid precision: 0.690234, valid loss: 433662.437500
epoch: 1015, train precision: 0.998935, train loss: 217.297607, valid precision: 0.685938, valid loss: 442396.437500
epoch: 1016, train precision: 0.999356, train loss: 107.648956, valid precision: 0.692578, valid loss: 411360.937500
epoch: 1017, train precision: 0.999290, train loss: 94.182198, valid precision: 0.690430, valid loss: 412698.718750
epoch: 1018, train precision: 0.999445, train loss: 99.848213, valid precision: 0.693945, valid loss: 415229.218750
epoch: 1019, train precision: 0.998779, train loss: 356.972809, valid precision: 0.688086, valid loss: 411881.343750
epoch: 1020, train precision: 0.998713, train loss: 257.416931, valid precision: 0.694727, valid loss: 444135.750000
epoch: 1021, train precision: 0.998602, train loss: 426.944122, valid precision: 0.695117, valid loss: 450861.906250
epoch: 1022, train precision: 0.998979, train loss: 241.707520, valid precision: 0.689258, valid loss: 429242.500000
epoch: 1023, train precision: 0.998402, train loss: 448.267090, valid precision: 0.690625, valid loss: 450517.156250
epoch: 1024, train precision: 0.998757, train loss: 311.733765, valid precision: 0.695898, valid loss: 435727.187500
epoch: 1025, train precision: 0.998202, train loss: 345.662994, valid precision: 0.694141, valid loss: 454855.343750
epoch: 1026, train precision: 0.998713, train loss: 314.723511, valid precision: 0.688672, valid loss: 438803.000000
epoch: 1027, train precision: 0.999312, train loss: 93.750587, valid precision: 0.690625, valid loss: 446603.000000
epoch: 1028, train precision: 0.998957, train loss: 279.610626, valid precision: 0.701367, valid loss: 462501.593750
epoch: 1029, train precision: 0.999223, train loss: 117.234863, valid precision: 0.698242, valid loss: 451708.187500
epoch: 1030, train precision: 0.998469, train loss: 405.888062, valid precision: 0.698047, valid loss: 422091.406250
epoch: 1031, train precision: 0.998313, train loss: 522.229248, valid precision: 0.705078, valid loss: 444021.906250
epoch: 1032, train precision: 0.999600, train loss: 69.635597, valid precision: 0.703125, valid loss: 446449.687500
epoch: 1033, train precision: 0.999467, train loss: 146.203827, valid precision: 0.697852, valid loss: 452367.593750
epoch: 1034, train precision: 0.999268, train loss: 230.201569, valid precision: 0.700000, valid loss: 447239.187500
epoch: 1035, train precision: 0.999223, train loss: 222.032135, valid precision: 0.694922, valid loss: 468637.500000
epoch: 1036, train precision: 0.999467, train loss: 112.142731, valid precision: 0.698438, valid loss: 448539.906250
epoch: 1037, train precision: 0.999245, train loss: 207.812988, valid precision: 0.698633, valid loss: 452285.250000
epoch: 1038, train precision: 0.999512, train loss: 89.921204, valid precision: 0.696094, valid loss: 429601.812500
epoch: 1039, train precision: 0.999068, train loss: 217.680893, valid precision: 0.695117, valid loss: 430629.687500
epoch: 1040, train precision: 0.998979, train loss: 256.001068, valid precision: 0.694727, valid loss: 448150.437500
epoch: 1041, train precision: 0.999223, train loss: 166.367615, valid precision: 0.701953, valid loss: 460496.656250
epoch: 1042, train precision: 0.998540, train loss: 373.751343, valid precision: 0.696289, valid loss: 447507.187500
epoch: 1043, train precision: 0.999157, train loss: 187.126602, valid precision: 0.695508, valid loss: 465269.656250
epoch: 1044, train precision: 0.999756, train loss: 38.153522, valid precision: 0.700977, valid loss: 456223.750000
epoch: 1045, train precision: 0.997337, train loss: 882.399963, valid precision: 0.698438, valid loss: 472775.250000
epoch: 1046, train precision: 0.998779, train loss: 300.213379, valid precision: 0.697852, valid loss: 452315.906250
epoch: 1047, train precision: 0.999445, train loss: 132.167282, valid precision: 0.706250, valid loss: 444118.250000
epoch: 1048, train precision: 0.999112, train loss: 167.092575, valid precision: 0.698438, valid loss: 428059.906250
epoch: 1049, train precision: 0.998291, train loss: 402.976654, valid precision: 0.699805, valid loss: 468057.687500
epoch: 1050, train precision: 0.999534, train loss: 60.808571, valid precision: 0.708008, valid loss: 461553.593750
epoch: 1051, train precision: 0.998912, train loss: 293.488983, valid precision: 0.701172, valid loss: 472643.656250
epoch: 1052, train precision: 0.999001, train loss: 259.791412, valid precision: 0.694727, valid loss: 464708.000000
epoch: 1053, train precision: 0.998957, train loss: 237.603333, valid precision: 0.698828, valid loss: 464266.187500
epoch: 1054, train precision: 0.999157, train loss: 194.738037, valid precision: 0.696094, valid loss: 467898.593750
epoch: 1055, train precision: 0.998469, train loss: 347.260468, valid precision: 0.693359, valid loss: 486466.093750
epoch: 1056, train precision: 0.999046, train loss: 309.786743, valid precision: 0.694922, valid loss: 461629.500000
epoch: 1057, train precision: 0.999001, train loss: 221.026962, valid precision: 0.700586, valid loss: 468487.500000
epoch: 1058, train precision: 0.999356, train loss: 99.191963, valid precision: 0.704687, valid loss: 463612.000000
epoch: 1059, train precision: 0.999268, train loss: 230.307388, valid precision: 0.700195, valid loss: 483094.093750
epoch: 1060, train precision: 0.999090, train loss: 188.528564, valid precision: 0.700000, valid loss: 467854.500000
epoch: 1061, train precision: 0.998979, train loss: 237.409134, valid precision: 0.698633, valid loss: 461494.500000
epoch: 1062, train precision: 0.997847, train loss: 740.891846, valid precision: 0.696094, valid loss: 481855.000000
epoch: 1063, train precision: 0.999179, train loss: 174.852478, valid precision: 0.698438, valid loss: 467041.187500
epoch: 1064, train precision: 0.997203, train loss: 890.857605, valid precision: 0.691992, valid loss: 482649.406250
epoch: 1065, train precision: 0.999334, train loss: 151.654037, valid precision: 0.703125, valid loss: 475275.500000
epoch: 1066, train precision: 0.998713, train loss: 338.019836, valid precision: 0.698242, valid loss: 472066.843750
epoch: 1067, train precision: 0.999845, train loss: 33.629272, valid precision: 0.703711, valid loss: 471584.593750
epoch: 1068, train precision: 0.999600, train loss: 79.688263, valid precision: 0.706445, valid loss: 481337.687500
epoch: 1069, train precision: 0.999467, train loss: 152.221451, valid precision: 0.704687, valid loss: 485390.906250
epoch: 1070, train precision: 0.999334, train loss: 197.398972, valid precision: 0.701758, valid loss: 472514.687500
epoch: 1071, train precision: 0.997314, train loss: 996.145691, valid precision: 0.699023, valid loss: 504275.062500
epoch: 1072, train precision: 0.997359, train loss: 823.362366, valid precision: 0.690820, valid loss: 497054.093750
epoch: 1073, train precision: 0.998424, train loss: 388.683075, valid precision: 0.696289, valid loss: 482585.000000
epoch: 1074, train precision: 0.998824, train loss: 273.309387, valid precision: 0.697266, valid loss: 461926.000000
epoch: 1075, train precision: 0.999046, train loss: 193.810944, valid precision: 0.702148, valid loss: 452709.593750
epoch: 1076, train precision: 0.999689, train loss: 72.270187, valid precision: 0.696289, valid loss: 464965.812500
epoch: 1077, train precision: 0.999046, train loss: 242.950638, valid precision: 0.698047, valid loss: 483381.500000
epoch: 1078, train precision: 0.998402, train loss: 568.995911, valid precision: 0.700977, valid loss: 478928.156250
epoch: 1079, train precision: 0.999467, train loss: 136.025040, valid precision: 0.699609, valid loss: 475325.000000
epoch: 1080, train precision: 0.999206, train loss: 237.351669, valid precision: 0.693555, valid loss: 489290.812500
epoch: 1081, train precision: 0.999379, train loss: 144.130463, valid precision: 0.698242, valid loss: 478679.906250
epoch: 1082, train precision: 0.999445, train loss: 164.373978, valid precision: 0.705859, valid loss: 496365.656250
epoch: 1083, train precision: 0.999290, train loss: 135.137543, valid precision: 0.706641, valid loss: 489946.750000
epoch: 1084, train precision: 0.998424, train loss: 418.976562, valid precision: 0.703711, valid loss: 480941.000000
epoch: 1085, train precision: 0.999312, train loss: 264.005859, valid precision: 0.701953, valid loss: 493038.562500
epoch: 1086, train precision: 0.999268, train loss: 210.122009, valid precision: 0.699414, valid loss: 505999.000000
epoch: 1087, train precision: 0.999157, train loss: 187.092041, valid precision: 0.696289, valid loss: 495172.312500
epoch: 1088, train precision: 0.999667, train loss: 93.845062, valid precision: 0.698438, valid loss: 479823.187500
epoch: 1089, train precision: 0.999734, train loss: 79.157074, valid precision: 0.699609, valid loss: 472767.000000
epoch: 1090, train precision: 0.998757, train loss: 322.482056, valid precision: 0.693359, valid loss: 499204.406250
epoch: 1091, train precision: 0.997980, train loss: 649.256592, valid precision: 0.696289, valid loss: 504581.093750
epoch: 1092, train precision: 0.999556, train loss: 80.228119, valid precision: 0.698438, valid loss: 477836.812500
epoch: 1093, train precision: 0.998801, train loss: 383.711334, valid precision: 0.700977, valid loss: 514783.312500
epoch: 1094, train precision: 0.998335, train loss: 486.212280, valid precision: 0.700977, valid loss: 504434.093750
epoch: 1095, train precision: 0.999112, train loss: 251.773178, valid precision: 0.701172, valid loss: 504480.062500
epoch: 1096, train precision: 0.999068, train loss: 253.476791, valid precision: 0.698828, valid loss: 510700.093750
epoch: 1097, train precision: 0.996671, train loss: 1098.885376, valid precision: 0.694141, valid loss: 524456.125000
epoch: 1098, train precision: 0.998691, train loss: 322.559326, valid precision: 0.682813, valid loss: 520630.156250
epoch: 1099, train precision: 0.998846, train loss: 308.063293, valid precision: 0.697070, valid loss: 506786.250000
epoch: 1100, train precision: 0.998513, train loss: 466.016388, valid precision: 0.706250, valid loss: 534924.875000
epoch: 1101, train precision: 0.999179, train loss: 148.261978, valid precision: 0.700977, valid loss: 514616.593750
epoch: 1102, train precision: 0.999911, train loss: 3.667011, valid precision: 0.707227, valid loss: 508191.093750
epoch: 1103, train precision: 0.996693, train loss: 1258.090820, valid precision: 0.693945, valid loss: 536717.375000
epoch: 1104, train precision: 0.999423, train loss: 147.729309, valid precision: 0.700781, valid loss: 510548.687500
epoch: 1105, train precision: 0.998868, train loss: 421.840912, valid precision: 0.697656, valid loss: 520686.500000
epoch: 1106, train precision: 0.999179, train loss: 244.995605, valid precision: 0.699805, valid loss: 529953.312500
epoch: 1107, train precision: 0.999423, train loss: 162.701935, valid precision: 0.700391, valid loss: 520807.093750
epoch: 1108, train precision: 0.999534, train loss: 110.658783, valid precision: 0.696484, valid loss: 513408.843750
epoch: 1109, train precision: 0.999711, train loss: 126.890984, valid precision: 0.709180, valid loss: 523683.500000
epoch: 1110, train precision: 0.998691, train loss: 673.151123, valid precision: 0.698633, valid loss: 558072.625000
epoch: 1111, train precision: 0.997026, train loss: 1046.883301, valid precision: 0.696289, valid loss: 524263.406250
epoch: 1112, train precision: 0.998846, train loss: 417.988373, valid precision: 0.699414, valid loss: 542713.125000
epoch: 1113, train precision: 0.999356, train loss: 148.770248, valid precision: 0.699805, valid loss: 533277.750000
epoch: 1114, train precision: 0.999756, train loss: 58.122269, valid precision: 0.704102, valid loss: 526630.000000
epoch: 1115, train precision: 0.999445, train loss: 139.351669, valid precision: 0.698633, valid loss: 515089.187500
epoch: 1116, train precision: 0.999090, train loss: 180.905090, valid precision: 0.695312, valid loss: 529053.812500
epoch: 1117, train precision: 0.999490, train loss: 133.316711, valid precision: 0.705273, valid loss: 530396.625000
epoch: 1118, train precision: 0.995761, train loss: 1985.341675, valid precision: 0.692578, valid loss: 567523.687500
epoch: 1119, train precision: 0.998979, train loss: 281.933380, valid precision: 0.696484, valid loss: 550260.312500
epoch: 1120, train precision: 0.999379, train loss: 132.532562, valid precision: 0.698438, valid loss: 519673.687500
epoch: 1121, train precision: 0.998335, train loss: 650.744873, valid precision: 0.701953, valid loss: 536336.625000
epoch: 1122, train precision: 0.999467, train loss: 147.945206, valid precision: 0.704102, valid loss: 536676.812500
epoch: 1123, train precision: 0.998757, train loss: 371.924438, valid precision: 0.700781, valid loss: 556564.375000
epoch: 1124, train precision: 0.998757, train loss: 396.147949, valid precision: 0.695508, valid loss: 543721.500000
epoch: 1125, train precision: 0.999334, train loss: 157.112167, valid precision: 0.706055, valid loss: 561242.687500
epoch: 1126, train precision: 0.999023, train loss: 353.410065, valid precision: 0.701758, valid loss: 568006.000000
epoch: 1127, train precision: 0.998979, train loss: 342.229828, valid precision: 0.696289, valid loss: 557602.312500
epoch: 1128, train precision: 0.999245, train loss: 275.945587, valid precision: 0.701172, valid loss: 549233.312500
epoch: 1129, train precision: 0.999756, train loss: 51.386654, valid precision: 0.706055, valid loss: 558223.312500
epoch: 1130, train precision: 0.998047, train loss: 634.349609, valid precision: 0.696680, valid loss: 568327.625000
epoch: 1131, train precision: 0.997070, train loss: 1100.490112, valid precision: 0.694336, valid loss: 550076.312500
epoch: 1132, train precision: 0.999001, train loss: 268.140991, valid precision: 0.694922, valid loss: 538136.312500
epoch: 1133, train precision: 0.999778, train loss: 73.525040, valid precision: 0.709570, valid loss: 559732.625000
epoch: 1134, train precision: 0.999667, train loss: 75.370735, valid precision: 0.702539, valid loss: 551210.375000
epoch: 1135, train precision: 0.999046, train loss: 263.016449, valid precision: 0.702148, valid loss: 562607.500000
epoch: 1136, train precision: 0.998025, train loss: 795.050964, valid precision: 0.691016, valid loss: 584406.125000
epoch: 1137, train precision: 0.999290, train loss: 337.172943, valid precision: 0.708984, valid loss: 567983.625000
epoch: 1138, train precision: 0.999245, train loss: 166.055878, valid precision: 0.700781, valid loss: 575977.187500
epoch: 1139, train precision: 0.998668, train loss: 365.598236, valid precision: 0.692187, valid loss: 551159.687500
epoch: 1140, train precision: 0.999134, train loss: 303.363312, valid precision: 0.696289, valid loss: 583166.000000
epoch: 1141, train precision: 0.999157, train loss: 236.540100, valid precision: 0.693555, valid loss: 564138.625000
epoch: 1142, train precision: 0.999401, train loss: 201.355942, valid precision: 0.689844, valid loss: 591691.812500
epoch: 1143, train precision: 0.999112, train loss: 265.121277, valid precision: 0.692187, valid loss: 583569.125000
epoch: 1144, train precision: 0.999245, train loss: 315.490509, valid precision: 0.698242, valid loss: 583468.687500
epoch: 1145, train precision: 0.999445, train loss: 147.761642, valid precision: 0.691016, valid loss: 575708.500000
epoch: 1146, train precision: 0.999445, train loss: 118.676781, valid precision: 0.691992, valid loss: 562467.000000
epoch: 1147, train precision: 0.999800, train loss: 60.398304, valid precision: 0.691992, valid loss: 552458.312500
epoch: 1148, train precision: 0.999134, train loss: 346.627655, valid precision: 0.690820, valid loss: 583514.500000
epoch: 1149, train precision: 0.998180, train loss: 547.027405, valid precision: 0.689844, valid loss: 564491.812500
epoch: 1150, train precision: 0.999423, train loss: 118.240105, valid precision: 0.700195, valid loss: 569423.312500
epoch: 1151, train precision: 0.999290, train loss: 232.282654, valid precision: 0.700391, valid loss: 584411.125000
epoch: 1152, train precision: 0.999001, train loss: 349.817474, valid precision: 0.695508, valid loss: 604937.000000
epoch: 1153, train precision: 0.999023, train loss: 297.735840, valid precision: 0.701367, valid loss: 599552.375000
epoch: 1154, train precision: 0.999356, train loss: 167.735443, valid precision: 0.697656, valid loss: 600303.750000
epoch: 1155, train precision: 0.999667, train loss: 100.239014, valid precision: 0.701172, valid loss: 571763.500000
epoch: 1156, train precision: 0.999401, train loss: 147.138077, valid precision: 0.696289, valid loss: 589111.625000
epoch: 1157, train precision: 0.999467, train loss: 134.544144, valid precision: 0.705273, valid loss: 583715.812500
epoch: 1158, train precision: 0.999401, train loss: 220.828720, valid precision: 0.704102, valid loss: 587341.687500
epoch: 1159, train precision: 0.998979, train loss: 332.848206, valid precision: 0.697070, valid loss: 649285.500000
epoch: 1160, train precision: 0.999046, train loss: 255.280991, valid precision: 0.700391, valid loss: 643910.625000
epoch: 1161, train precision: 0.999445, train loss: 127.985359, valid precision: 0.700586, valid loss: 617978.687500
epoch: 1162, train precision: 0.999290, train loss: 338.275787, valid precision: 0.699219, valid loss: 605569.625000
epoch: 1163, train precision: 0.999623, train loss: 113.127960, valid precision: 0.695117, valid loss: 605370.250000
epoch: 1164, train precision: 0.999800, train loss: 27.707043, valid precision: 0.691797, valid loss: 606404.000000
epoch: 1165, train precision: 0.998224, train loss: 655.724976, valid precision: 0.693555, valid loss: 656203.875000
epoch: 1166, train precision: 0.999512, train loss: 136.997131, valid precision: 0.703320, valid loss: 612488.875000
epoch: 1167, train precision: 0.998779, train loss: 503.945526, valid precision: 0.696680, valid loss: 619124.500000
epoch: 1168, train precision: 0.998713, train loss: 355.744659, valid precision: 0.704102, valid loss: 627870.062500
epoch: 1169, train precision: 0.999245, train loss: 205.285110, valid precision: 0.706641, valid loss: 608932.625000
epoch: 1170, train precision: 0.998779, train loss: 392.118530, valid precision: 0.700586, valid loss: 629766.937500
epoch: 1171, train precision: 0.999179, train loss: 204.542130, valid precision: 0.695898, valid loss: 637696.250000
epoch: 1172, train precision: 0.999667, train loss: 62.773270, valid precision: 0.699023, valid loss: 622289.125000
epoch: 1173, train precision: 0.998801, train loss: 380.651978, valid precision: 0.693750, valid loss: 635201.250000
epoch: 1174, train precision: 0.999556, train loss: 137.968414, valid precision: 0.702344, valid loss: 613459.375000
epoch: 1175, train precision: 0.999534, train loss: 90.158882, valid precision: 0.704492, valid loss: 642270.500000
epoch: 1176, train precision: 0.999645, train loss: 118.660355, valid precision: 0.704102, valid loss: 630416.125000
epoch: 1177, train precision: 0.998801, train loss: 415.765350, valid precision: 0.698242, valid loss: 642510.937500
epoch: 1178, train precision: 0.999068, train loss: 410.379089, valid precision: 0.695312, valid loss: 638456.625000
epoch: 1179, train precision: 0.999334, train loss: 200.893494, valid precision: 0.697070, valid loss: 630615.437500
epoch: 1180, train precision: 0.999401, train loss: 209.343704, valid precision: 0.692969, valid loss: 623349.625000
epoch: 1181, train precision: 0.998735, train loss: 395.294464, valid precision: 0.694141, valid loss: 643770.875000
epoch: 1182, train precision: 0.998957, train loss: 416.708313, valid precision: 0.683398, valid loss: 640452.500000
epoch: 1183, train precision: 0.999334, train loss: 274.224548, valid precision: 0.698438, valid loss: 627705.625000
epoch: 1184, train precision: 0.999356, train loss: 271.187195, valid precision: 0.692383, valid loss: 632525.312500
epoch: 1185, train precision: 0.999068, train loss: 228.602524, valid precision: 0.696875, valid loss: 603836.000000
epoch: 1186, train precision: 0.999467, train loss: 142.623688, valid precision: 0.691992, valid loss: 631866.375000
epoch: 1187, train precision: 0.998868, train loss: 335.546265, valid precision: 0.693750, valid loss: 634201.750000
epoch: 1188, train precision: 0.999023, train loss: 326.279999, valid precision: 0.705859, valid loss: 663146.937500
epoch: 1189, train precision: 0.998979, train loss: 353.877106, valid precision: 0.692578, valid loss: 648591.875000
epoch: 1190, train precision: 0.999645, train loss: 85.466751, valid precision: 0.698828, valid loss: 636918.375000
epoch: 1191, train precision: 0.999711, train loss: 91.654175, valid precision: 0.692578, valid loss: 627742.625000
epoch: 1192, train precision: 0.998691, train loss: 447.034363, valid precision: 0.693555, valid loss: 614491.187500
epoch: 1193, train precision: 0.998829, train loss: 363.433289, valid precision: 0.689844, valid loss: 644785.000000
epoch: 1194, train precision: 0.999556, train loss: 180.391800, valid precision: 0.703125, valid loss: 645668.812500
epoch: 1195, train precision: 0.998935, train loss: 325.508209, valid precision: 0.699219, valid loss: 623646.312500
epoch: 1196, train precision: 0.999623, train loss: 80.608734, valid precision: 0.694531, valid loss: 620446.250000
epoch: 1197, train precision: 0.999423, train loss: 215.029251, valid precision: 0.694727, valid loss: 655613.500000
epoch: 1198, train precision: 0.999467, train loss: 120.298164, valid precision: 0.697461, valid loss: 642125.875000
epoch: 1199, train precision: 0.999245, train loss: 204.364746, valid precision: 0.705273, valid loss: 647249.625000
epoch: 1200, train precision: 0.998868, train loss: 348.091461, valid precision: 0.695312, valid loss: 650263.625000
epoch: 1201, train precision: 0.998713, train loss: 635.519409, valid precision: 0.697852, valid loss: 656667.312500
epoch: 1202, train precision: 0.999268, train loss: 261.258820, valid precision: 0.692383, valid loss: 673941.375000
epoch: 1203, train precision: 0.998624, train loss: 416.680756, valid precision: 0.693164, valid loss: 644517.812500
epoch: 1204, train precision: 0.999023, train loss: 361.258820, valid precision: 0.694336, valid loss: 639459.000000
epoch: 1205, train precision: 0.998979, train loss: 339.674438, valid precision: 0.689453, valid loss: 661098.937500
epoch: 1206, train precision: 0.997647, train loss: 1122.567993, valid precision: 0.692187, valid loss: 687194.812500
epoch: 1207, train precision: 0.999534, train loss: 160.484528, valid precision: 0.695703, valid loss: 665179.625000
epoch: 1208, train precision: 0.999223, train loss: 216.731308, valid precision: 0.698047, valid loss: 702242.250000
epoch: 1209, train precision: 0.999090, train loss: 368.446411, valid precision: 0.700781, valid loss: 676812.000000
epoch: 1210, train precision: 0.999423, train loss: 179.740143, valid precision: 0.698242, valid loss: 684713.437500
epoch: 1211, train precision: 0.998535, train loss: 662.776123, valid precision: 0.691797, valid loss: 701128.187500
epoch: 1212, train precision: 0.998957, train loss: 475.008270, valid precision: 0.700000, valid loss: 670104.625000
epoch: 1213, train precision: 0.999112, train loss: 240.771255, valid precision: 0.698047, valid loss: 640878.187500
epoch: 1214, train precision: 0.999600, train loss: 110.919182, valid precision: 0.703516, valid loss: 673790.687500
epoch: 1215, train precision: 0.999534, train loss: 224.055603, valid precision: 0.700195, valid loss: 635298.875000
epoch: 1216, train precision: 0.998291, train loss: 628.055420, valid precision: 0.685547, valid loss: 693492.500000
epoch: 1217, train precision: 0.999090, train loss: 359.654022, valid precision: 0.689062, valid loss: 655569.375000
epoch: 1218, train precision: 0.999645, train loss: 147.099014, valid precision: 0.696680, valid loss: 675276.812500
epoch: 1219, train precision: 0.999800, train loss: 90.446754, valid precision: 0.693945, valid loss: 659151.250000
epoch: 1220, train precision: 0.999734, train loss: 52.889572, valid precision: 0.690430, valid loss: 682084.125000
epoch: 1221, train precision: 0.999512, train loss: 146.869156, valid precision: 0.684180, valid loss: 677758.125000
epoch: 1222, train precision: 0.999356, train loss: 214.744736, valid precision: 0.698438, valid loss: 702321.312500
epoch: 1223, train precision: 0.998912, train loss: 445.963379, valid precision: 0.691797, valid loss: 688012.750000
epoch: 1224, train precision: 0.999068, train loss: 381.581543, valid precision: 0.690039, valid loss: 704794.687500
epoch: 1225, train precision: 0.999467, train loss: 268.397339, valid precision: 0.688867, valid loss: 717533.187500
epoch: 1226, train precision: 0.999290, train loss: 230.919373, valid precision: 0.693359, valid loss: 694696.125000
epoch: 1227, train precision: 0.999778, train loss: 41.430248, valid precision: 0.696094, valid loss: 698313.625000
epoch: 1228, train precision: 0.999845, train loss: 25.287598, valid precision: 0.696680, valid loss: 704276.125000
epoch: 1229, train precision: 0.998602, train loss: 506.241730, valid precision: 0.697656, valid loss: 727319.375000
epoch: 1230, train precision: 0.998335, train loss: 805.663513, valid precision: 0.698242, valid loss: 728672.625000
epoch: 1231, train precision: 0.999401, train loss: 135.533051, valid precision: 0.698828, valid loss: 723923.500000
epoch: 1232, train precision: 0.999112, train loss: 368.467560, valid precision: 0.699609, valid loss: 715822.125000
epoch: 1233, train precision: 0.998624, train loss: 565.763184, valid precision: 0.696875, valid loss: 738851.500000
epoch: 1234, train precision: 0.998868, train loss: 390.099640, valid precision: 0.700977, valid loss: 727040.375000
epoch: 1235, train precision: 0.999578, train loss: 243.650635, valid precision: 0.699219, valid loss: 737450.812500
epoch: 1236, train precision: 0.998602, train loss: 586.223206, valid precision: 0.699805, valid loss: 694932.687500
epoch: 1237, train precision: 0.999201, train loss: 288.976959, valid precision: 0.693359, valid loss: 719095.812500
epoch: 1238, train precision: 0.999778, train loss: 51.516911, valid precision: 0.700977, valid loss: 712928.875000
epoch: 1239, train precision: 0.999157, train loss: 317.278870, valid precision: 0.696094, valid loss: 705097.937500
epoch: 1240, train precision: 0.998824, train loss: 417.760468, valid precision: 0.694727, valid loss: 723187.000000
epoch: 1241, train precision: 0.999290, train loss: 291.478912, valid precision: 0.701172, valid loss: 755515.125000
epoch: 1242, train precision: 0.999689, train loss: 194.932281, valid precision: 0.703125, valid loss: 726786.875000
epoch: 1243, train precision: 0.999490, train loss: 156.453171, valid precision: 0.705469, valid loss: 730104.687500
epoch: 1244, train precision: 0.998557, train loss: 691.363342, valid precision: 0.700781, valid loss: 777367.000000
epoch: 1245, train precision: 0.999356, train loss: 257.743439, valid precision: 0.701367, valid loss: 718625.187500
epoch: 1246, train precision: 0.999073, train loss: 366.303040, valid precision: 0.700391, valid loss: 729698.250000
epoch: 1247, train precision: 0.999734, train loss: 61.769680, valid precision: 0.702930, valid loss: 721014.562500
epoch: 1248, train precision: 0.999223, train loss: 366.169312, valid precision: 0.702539, valid loss: 704716.812500
epoch: 1249, train precision: 0.999490, train loss: 145.077393, valid precision: 0.709180, valid loss: 722514.625000
epoch: 1250, train precision: 0.999623, train loss: 111.308952, valid precision: 0.697461, valid loss: 702099.312500
epoch: 1251, train precision: 0.998935, train loss: 406.221558, valid precision: 0.696875, valid loss: 736977.187500
epoch: 1252, train precision: 0.999001, train loss: 404.362579, valid precision: 0.697070, valid loss: 741530.187500
epoch: 1253, train precision: 0.998691, train loss: 714.775757, valid precision: 0.696289, valid loss: 731710.125000
epoch: 1254, train precision: 0.999379, train loss: 204.215347, valid precision: 0.688477, valid loss: 715175.375000
epoch: 1255, train precision: 0.998713, train loss: 533.420532, valid precision: 0.686523, valid loss: 714743.125000
epoch: 1256, train precision: 0.999001, train loss: 319.045135, valid precision: 0.696680, valid loss: 696592.312500
epoch: 1257, train precision: 0.999068, train loss: 355.781860, valid precision: 0.692773, valid loss: 722068.875000
epoch: 1258, train precision: 0.999645, train loss: 74.119072, valid precision: 0.703320, valid loss: 692763.875000
epoch: 1259, train precision: 0.999578, train loss: 112.197090, valid precision: 0.698047, valid loss: 704367.125000
epoch: 1260, train precision: 0.998247, train loss: 745.003845, valid precision: 0.687109, valid loss: 732721.375000
epoch: 1261, train precision: 0.999445, train loss: 237.840775, valid precision: 0.701563, valid loss: 724220.062500
epoch: 1262, train precision: 0.998602, train loss: 679.165833, valid precision: 0.689453, valid loss: 740173.500000
epoch: 1263, train precision: 0.998602, train loss: 634.131409, valid precision: 0.702344, valid loss: 737591.375000
epoch: 1264, train precision: 0.999578, train loss: 104.963837, valid precision: 0.698242, valid loss: 750639.812500
epoch: 1265, train precision: 0.998979, train loss: 419.285828, valid precision: 0.693555, valid loss: 732668.000000
epoch: 1266, train precision: 0.999467, train loss: 186.992371, valid precision: 0.694141, valid loss: 757449.187500
epoch: 1267, train precision: 0.999201, train loss: 355.523956, valid precision: 0.693359, valid loss: 777982.375000
epoch: 1268, train precision: 0.998779, train loss: 638.878845, valid precision: 0.700000, valid loss: 775130.687500
epoch: 1269, train precision: 0.999223, train loss: 332.666687, valid precision: 0.697852, valid loss: 762202.562500
epoch: 1270, train precision: 0.999112, train loss: 410.311249, valid precision: 0.691992, valid loss: 715600.875000
epoch: 1271, train precision: 0.998402, train loss: 651.374023, valid precision: 0.697461, valid loss: 767027.062500
epoch: 1272, train precision: 0.999379, train loss: 315.811890, valid precision: 0.697070, valid loss: 729565.312500
epoch: 1273, train precision: 0.999623, train loss: 118.826462, valid precision: 0.697656, valid loss: 748559.562500
epoch: 1274, train precision: 0.999556, train loss: 173.311676, valid precision: 0.702734, valid loss: 737282.625000
epoch: 1275, train precision: 0.999800, train loss: 53.159611, valid precision: 0.704297, valid loss: 732193.312500
epoch: 1276, train precision: 0.999578, train loss: 172.567932, valid precision: 0.703320, valid loss: 733347.312500
epoch: 1277, train precision: 0.999356, train loss: 210.968994, valid precision: 0.705273, valid loss: 747989.312500
epoch: 1278, train precision: 0.999223, train loss: 319.353302, valid precision: 0.698242, valid loss: 783573.687500
epoch: 1279, train precision: 0.999068, train loss: 385.973511, valid precision: 0.688477, valid loss: 786283.187500
epoch: 1280, train precision: 0.998957, train loss: 386.236847, valid precision: 0.702734, valid loss: 785228.312500
epoch: 1281, train precision: 0.999534, train loss: 99.054268, valid precision: 0.693555, valid loss: 766817.687500
epoch: 1282, train precision: 0.999179, train loss: 359.719177, valid precision: 0.692969, valid loss: 799998.500000
epoch: 1283, train precision: 0.998757, train loss: 435.453308, valid precision: 0.695508, valid loss: 813661.000000
epoch: 1284, train precision: 0.998957, train loss: 538.916748, valid precision: 0.691602, valid loss: 799196.187500
epoch: 1285, train precision: 0.999046, train loss: 474.325165, valid precision: 0.697461, valid loss: 814535.625000
epoch: 1286, train precision: 0.998113, train loss: 902.966187, valid precision: 0.693750, valid loss: 847029.625000
epoch: 1287, train precision: 0.999667, train loss: 132.001968, valid precision: 0.702930, valid loss: 811415.187500
epoch: 1288, train precision: 0.999578, train loss: 137.477478, valid precision: 0.694531, valid loss: 831798.812500
epoch: 1289, train precision: 0.999245, train loss: 240.417480, valid precision: 0.705469, valid loss: 790258.812500
epoch: 1290, train precision: 0.999667, train loss: 136.213806, valid precision: 0.699414, valid loss: 810477.125000
epoch: 1291, train precision: 0.998358, train loss: 786.464844, valid precision: 0.688672, valid loss: 835183.750000
epoch: 1292, train precision: 0.999312, train loss: 324.405884, valid precision: 0.703711, valid loss: 786040.562500
epoch: 1293, train precision: 0.999445, train loss: 208.968842, valid precision: 0.697656, valid loss: 822901.125000
epoch: 1294, train precision: 0.999245, train loss: 324.893097, valid precision: 0.690625, valid loss: 785673.125000
epoch: 1295, train precision: 0.999157, train loss: 358.226562, valid precision: 0.701563, valid loss: 856055.875000
epoch: 1296, train precision: 0.999534, train loss: 160.154037, valid precision: 0.702148, valid loss: 817193.437500
epoch: 1297, train precision: 0.999734, train loss: 95.668922, valid precision: 0.704492, valid loss: 810008.000000
epoch: 1298, train precision: 0.999423, train loss: 444.560242, valid precision: 0.698438, valid loss: 827408.125000
epoch: 1299, train precision: 0.999334, train loss: 304.723541, valid precision: 0.696289, valid loss: 821388.312500
epoch: 1300, train precision: 0.999645, train loss: 196.499863, valid precision: 0.701367, valid loss: 841593.312500
epoch: 1301, train precision: 0.999512, train loss: 250.538910, valid precision: 0.699609, valid loss: 825010.125000
epoch: 1302, train precision: 0.999245, train loss: 315.746552, valid precision: 0.695703, valid loss: 847594.812500
epoch: 1303, train precision: 0.998691, train loss: 754.056091, valid precision: 0.693164, valid loss: 874054.687500
epoch: 1304, train precision: 0.999600, train loss: 169.599258, valid precision: 0.694922, valid loss: 853159.000000
epoch: 1305, train precision: 0.999623, train loss: 208.205704, valid precision: 0.698633, valid loss: 830196.750000
epoch: 1306, train precision: 0.999423, train loss: 259.740540, valid precision: 0.697461, valid loss: 835547.625000
epoch: 1307, train precision: 0.999334, train loss: 269.116821, valid precision: 0.693555, valid loss: 851652.375000
epoch: 1308, train precision: 0.999157, train loss: 348.208038, valid precision: 0.698047, valid loss: 870697.125000
epoch: 1309, train precision: 0.999445, train loss: 203.145172, valid precision: 0.693945, valid loss: 818307.187500
epoch: 1310, train precision: 0.999512, train loss: 220.352844, valid precision: 0.699219, valid loss: 841413.687500
epoch: 1311, train precision: 0.999534, train loss: 274.237335, valid precision: 0.694336, valid loss: 817216.812500
epoch: 1312, train precision: 0.999201, train loss: 256.707245, valid precision: 0.696875, valid loss: 824124.312500
epoch: 1313, train precision: 0.999512, train loss: 263.014587, valid precision: 0.690234, valid loss: 835279.125000
epoch: 1314, train precision: 0.999356, train loss: 457.792694, valid precision: 0.692773, valid loss: 878673.187500
epoch: 1315, train precision: 0.999401, train loss: 148.903214, valid precision: 0.693359, valid loss: 883203.812500
epoch: 1316, train precision: 0.999445, train loss: 193.809036, valid precision: 0.690430, valid loss: 873560.000000
epoch: 1317, train precision: 0.999822, train loss: 98.398239, valid precision: 0.695312, valid loss: 865215.625000
epoch: 1318, train precision: 0.999734, train loss: 83.980194, valid precision: 0.700977, valid loss: 882827.000000
epoch: 1319, train precision: 0.999112, train loss: 397.401978, valid precision: 0.701758, valid loss: 875089.687500
epoch: 1320, train precision: 0.997181, train loss: 1329.373535, valid precision: 0.685742, valid loss: 901472.687500
epoch: 1321, train precision: 0.999711, train loss: 77.814857, valid precision: 0.701563, valid loss: 862743.187500
epoch: 1322, train precision: 0.998513, train loss: 677.454346, valid precision: 0.682031, valid loss: 870348.000000
epoch: 1323, train precision: 0.999423, train loss: 232.055603, valid precision: 0.691211, valid loss: 875542.000000
epoch: 1324, train precision: 0.998846, train loss: 348.583374, valid precision: 0.694727, valid loss: 857841.000000
epoch: 1325, train precision: 0.999157, train loss: 328.846344, valid precision: 0.694336, valid loss: 870589.375000
epoch: 1326, train precision: 0.998779, train loss: 738.234009, valid precision: 0.697852, valid loss: 876052.125000
epoch: 1327, train precision: 0.999467, train loss: 188.633392, valid precision: 0.702344, valid loss: 839217.187500
epoch: 1328, train precision: 0.999023, train loss: 480.698730, valid precision: 0.701367, valid loss: 888834.687500
epoch: 1329, train precision: 0.999512, train loss: 192.915665, valid precision: 0.699609, valid loss: 845386.625000
epoch: 1330, train precision: 0.998446, train loss: 713.887268, valid precision: 0.694531, valid loss: 900265.500000
epoch: 1331, train precision: 0.999290, train loss: 305.114746, valid precision: 0.702930, valid loss: 843873.125000
epoch: 1332, train precision: 0.999822, train loss: 51.148769, valid precision: 0.700781, valid loss: 835236.750000
epoch: 1333, train precision: 0.999889, train loss: 42.503674, valid precision: 0.703320, valid loss: 818612.625000
epoch: 1334, train precision: 0.999600, train loss: 179.278412, valid precision: 0.700781, valid loss: 847905.375000
epoch: 1335, train precision: 0.998846, train loss: 567.273865, valid precision: 0.694531, valid loss: 837747.500000
epoch: 1336, train precision: 0.999534, train loss: 269.468933, valid precision: 0.699023, valid loss: 905137.000000
epoch: 1337, train precision: 0.999001, train loss: 362.042877, valid precision: 0.694141, valid loss: 833773.125000
epoch: 1338, train precision: 0.999201, train loss: 500.357635, valid precision: 0.697070, valid loss: 884814.812500
epoch: 1339, train precision: 0.999290, train loss: 349.846710, valid precision: 0.699023, valid loss: 861210.312500
epoch: 1340, train precision: 0.998007, train loss: 1163.778687, valid precision: 0.695117, valid loss: 893829.812500
epoch: 1341, train precision: 0.998917, train loss: 395.781708, valid precision: 0.694141, valid loss: 889917.812500
epoch: 1342, train precision: 0.999600, train loss: 139.485245, valid precision: 0.712109, valid loss: 851364.187500
epoch: 1343, train precision: 0.999356, train loss: 326.228973, valid precision: 0.705859, valid loss: 831413.062500
epoch: 1344, train precision: 0.998580, train loss: 792.420166, valid precision: 0.698828, valid loss: 880362.000000
epoch: 1345, train precision: 0.998691, train loss: 473.888458, valid precision: 0.696094, valid loss: 873413.375000
epoch: 1346, train precision: 0.999534, train loss: 216.329361, valid precision: 0.696875, valid loss: 866393.187500
epoch: 1347, train precision: 0.999157, train loss: 353.597504, valid precision: 0.700195, valid loss: 836352.625000
epoch: 1348, train precision: 0.999445, train loss: 375.967194, valid precision: 0.700391, valid loss: 851086.625000
epoch: 1349, train precision: 0.999822, train loss: 56.338791, valid precision: 0.701758, valid loss: 870544.812500
epoch: 1350, train precision: 0.998491, train loss: 859.193359, valid precision: 0.707812, valid loss: 913671.875000
epoch: 1351, train precision: 0.999112, train loss: 334.114044, valid precision: 0.701172, valid loss: 868520.000000
epoch: 1352, train precision: 0.999201, train loss: 454.815125, valid precision: 0.702930, valid loss: 929610.000000
epoch: 1353, train precision: 0.999401, train loss: 377.859894, valid precision: 0.702148, valid loss: 914356.125000
epoch: 1354, train precision: 0.999667, train loss: 170.528534, valid precision: 0.698633, valid loss: 904961.812500
epoch: 1355, train precision: 0.999645, train loss: 157.802261, valid precision: 0.697070, valid loss: 899629.000000
epoch: 1356, train precision: 0.999534, train loss: 281.274414, valid precision: 0.705469, valid loss: 884391.125000
epoch: 1357, train precision: 0.999689, train loss: 85.772072, valid precision: 0.693164, valid loss: 867542.812500
epoch: 1358, train precision: 0.999667, train loss: 186.638870, valid precision: 0.691016, valid loss: 883295.000000
epoch: 1359, train precision: 0.999245, train loss: 286.894714, valid precision: 0.697461, valid loss: 893107.125000
epoch: 1360, train precision: 0.999689, train loss: 101.379486, valid precision: 0.697461, valid loss: 908745.625000
epoch: 1361, train precision: 0.999645, train loss: 163.098862, valid precision: 0.701758, valid loss: 893840.375000
epoch: 1362, train precision: 0.999534, train loss: 206.560303, valid precision: 0.701172, valid loss: 921391.812500
epoch: 1363, train precision: 0.999090, train loss: 475.118683, valid precision: 0.692969, valid loss: 880036.500000
epoch: 1364, train precision: 0.999312, train loss: 301.696594, valid precision: 0.705078, valid loss: 876097.125000
epoch: 1365, train precision: 0.999356, train loss: 277.167938, valid precision: 0.696484, valid loss: 918247.875000
epoch: 1366, train precision: 0.999623, train loss: 163.665863, valid precision: 0.707812, valid loss: 912204.312500
epoch: 1367, train precision: 0.999245, train loss: 456.186707, valid precision: 0.701953, valid loss: 953660.625000
epoch: 1368, train precision: 0.998801, train loss: 648.812927, valid precision: 0.702148, valid loss: 933469.000000
epoch: 1369, train precision: 0.999312, train loss: 268.105347, valid precision: 0.707812, valid loss: 949854.312500
epoch: 1370, train precision: 0.999356, train loss: 245.143738, valid precision: 0.711914, valid loss: 935579.312500
epoch: 1371, train precision: 0.999245, train loss: 454.202515, valid precision: 0.698828, valid loss: 966242.375000
epoch: 1372, train precision: 0.999578, train loss: 111.818825, valid precision: 0.697852, valid loss: 887628.187500
epoch: 1373, train precision: 0.999379, train loss: 295.365112, valid precision: 0.700000, valid loss: 941316.375000
epoch: 1374, train precision: 0.999556, train loss: 250.331543, valid precision: 0.711914, valid loss: 943464.125000
epoch: 1375, train precision: 0.999201, train loss: 399.586823, valid precision: 0.702930, valid loss: 971667.875000
epoch: 1376, train precision: 0.999734, train loss: 195.660599, valid precision: 0.704297, valid loss: 961718.375000
epoch: 1377, train precision: 0.999734, train loss: 95.339325, valid precision: 0.698242, valid loss: 954922.812500
epoch: 1378, train precision: 0.999467, train loss: 308.305542, valid precision: 0.699219, valid loss: 962487.375000
epoch: 1379, train precision: 0.999734, train loss: 105.003021, valid precision: 0.700391, valid loss: 951108.500000
epoch: 1380, train precision: 0.998890, train loss: 420.568542, valid precision: 0.702344, valid loss: 937064.000000
epoch: 1381, train precision: 0.999379, train loss: 199.142181, valid precision: 0.702930, valid loss: 956980.687500
epoch: 1382, train precision: 0.999667, train loss: 132.802582, valid precision: 0.708203, valid loss: 947996.375000
epoch: 1383, train precision: 0.999800, train loss: 73.653275, valid precision: 0.706641, valid loss: 970494.375000
epoch: 1384, train precision: 0.998513, train loss: 978.437500, valid precision: 0.692969, valid loss: 996890.312500
epoch: 1385, train precision: 0.998935, train loss: 625.144653, valid precision: 0.694336, valid loss: 949446.812500
epoch: 1386, train precision: 0.999578, train loss: 135.302719, valid precision: 0.701758, valid loss: 975052.000000
epoch: 1387, train precision: 0.999534, train loss: 289.997498, valid precision: 0.704102, valid loss: 1032949.500000
epoch: 1388, train precision: 0.999090, train loss: 352.250366, valid precision: 0.695312, valid loss: 996525.187500
epoch: 1389, train precision: 0.999556, train loss: 296.988983, valid precision: 0.702539, valid loss: 957237.812500
epoch: 1390, train precision: 0.999756, train loss: 109.190819, valid precision: 0.699414, valid loss: 973865.625000
epoch: 1391, train precision: 0.999623, train loss: 172.567444, valid precision: 0.698633, valid loss: 1014948.375000
epoch: 1392, train precision: 0.998469, train loss: 940.354675, valid precision: 0.696289, valid loss: 999741.687500
epoch: 1393, train precision: 0.999711, train loss: 55.761143, valid precision: 0.701563, valid loss: 1004909.375000
epoch: 1394, train precision: 0.999401, train loss: 237.655014, valid precision: 0.698828, valid loss: 989569.000000
epoch: 1395, train precision: 0.999512, train loss: 193.168640, valid precision: 0.704102, valid loss: 1011467.187500
epoch: 1396, train precision: 0.999556, train loss: 351.920898, valid precision: 0.702734, valid loss: 990496.375000
epoch: 1397, train precision: 0.999223, train loss: 425.147339, valid precision: 0.703516, valid loss: 978482.000000
epoch: 1398, train precision: 0.998402, train loss: 759.705444, valid precision: 0.696094, valid loss: 993811.687500
epoch: 1399, train precision: 0.999689, train loss: 149.856949, valid precision: 0.701172, valid loss: 931707.812500
epoch: 1400, train precision: 0.999534, train loss: 236.347961, valid precision: 0.698828, valid loss: 984738.187500
epoch: 1401, train precision: 0.998957, train loss: 663.949951, valid precision: 0.692969, valid loss: 971132.375000
epoch: 1402, train precision: 0.999162, train loss: 509.854858, valid precision: 0.702539, valid loss: 970794.000000
epoch: 1403, train precision: 0.999822, train loss: 57.588245, valid precision: 0.704102, valid loss: 1002155.625000
epoch: 1404, train precision: 0.999778, train loss: 67.207611, valid precision: 0.707227, valid loss: 996523.500000
epoch: 1405, train precision: 0.999756, train loss: 128.597153, valid precision: 0.700977, valid loss: 1013395.187500
epoch: 1406, train precision: 0.999356, train loss: 313.140411, valid precision: 0.697852, valid loss: 1001088.375000
epoch: 1407, train precision: 0.998757, train loss: 748.108398, valid precision: 0.701758, valid loss: 1034893.500000
epoch: 1408, train precision: 0.999201, train loss: 403.569031, valid precision: 0.695508, valid loss: 1025834.312500
epoch: 1409, train precision: 0.998158, train loss: 1176.449829, valid precision: 0.691406, valid loss: 1022155.375000
epoch: 1410, train precision: 0.998979, train loss: 554.531006, valid precision: 0.703516, valid loss: 1003183.375000
epoch: 1411, train precision: 0.999556, train loss: 232.484619, valid precision: 0.704687, valid loss: 997239.375000
epoch: 1412, train precision: 0.999157, train loss: 365.361298, valid precision: 0.698633, valid loss: 997664.625000
epoch: 1413, train precision: 0.999556, train loss: 243.930176, valid precision: 0.700000, valid loss: 985639.375000
epoch: 1414, train precision: 0.999578, train loss: 199.561035, valid precision: 0.701367, valid loss: 988293.500000
epoch: 1415, train precision: 0.999556, train loss: 211.197128, valid precision: 0.702148, valid loss: 982256.000000
epoch: 1416, train precision: 0.998335, train loss: 838.103699, valid precision: 0.703516, valid loss: 1034966.000000
epoch: 1417, train precision: 0.999534, train loss: 173.477066, valid precision: 0.703711, valid loss: 976621.500000
epoch: 1418, train precision: 0.998935, train loss: 814.988708, valid precision: 0.696875, valid loss: 981898.625000
epoch: 1419, train precision: 0.999689, train loss: 177.964783, valid precision: 0.706641, valid loss: 974786.125000
epoch: 1420, train precision: 0.999756, train loss: 99.605370, valid precision: 0.700000, valid loss: 1013338.000000
epoch: 1421, train precision: 0.999334, train loss: 427.413757, valid precision: 0.700195, valid loss: 981862.625000
epoch: 1422, train precision: 0.999268, train loss: 351.310028, valid precision: 0.691992, valid loss: 1031598.187500
epoch: 1423, train precision: 0.999423, train loss: 187.739548, valid precision: 0.700781, valid loss: 1024894.625000
epoch: 1424, train precision: 0.999512, train loss: 178.896332, valid precision: 0.697852, valid loss: 989003.625000
epoch: 1425, train precision: 0.999778, train loss: 103.451973, valid precision: 0.693164, valid loss: 992468.000000
epoch: 1426, train precision: 0.999046, train loss: 562.374268, valid precision: 0.692969, valid loss: 1058925.375000
epoch: 1427, train precision: 0.999689, train loss: 133.437271, valid precision: 0.707227, valid loss: 996131.375000
epoch: 1428, train precision: 0.999667, train loss: 110.340897, valid precision: 0.701367, valid loss: 1025126.625000
epoch: 1429, train precision: 0.999667, train loss: 124.378761, valid precision: 0.707031, valid loss: 1048549.375000
epoch: 1430, train precision: 0.998469, train loss: 919.533203, valid precision: 0.694727, valid loss: 1081681.875000
epoch: 1431, train precision: 0.999667, train loss: 230.636185, valid precision: 0.701953, valid loss: 1051616.750000
epoch: 1432, train precision: 0.999845, train loss: 56.207699, valid precision: 0.696680, valid loss: 1054412.625000
epoch: 1433, train precision: 0.999734, train loss: 117.186981, valid precision: 0.707812, valid loss: 1077457.750000
epoch: 1434, train precision: 0.999490, train loss: 154.811539, valid precision: 0.704687, valid loss: 1097544.750000
epoch: 1435, train precision: 0.999467, train loss: 355.276001, valid precision: 0.706641, valid loss: 1091569.625000
epoch: 1436, train precision: 0.999423, train loss: 295.181244, valid precision: 0.704297, valid loss: 1054732.250000
epoch: 1437, train precision: 0.998224, train loss: 1185.677002, valid precision: 0.698633, valid loss: 1056577.500000
epoch: 1438, train precision: 0.999356, train loss: 298.495850, valid precision: 0.704102, valid loss: 1026722.375000
epoch: 1439, train precision: 0.998824, train loss: 756.510132, valid precision: 0.699414, valid loss: 1050437.250000
epoch: 1440, train precision: 0.999445, train loss: 235.463669, valid precision: 0.692773, valid loss: 1077964.250000
epoch: 1441, train precision: 0.999046, train loss: 434.173126, valid precision: 0.700586, valid loss: 1089000.875000
epoch: 1442, train precision: 0.999179, train loss: 387.055206, valid precision: 0.701953, valid loss: 1071111.250000
epoch: 1443, train precision: 0.999889, train loss: 101.467682, valid precision: 0.707227, valid loss: 1074572.750000
epoch: 1444, train precision: 0.999134, train loss: 568.075745, valid precision: 0.700195, valid loss: 1063287.500000
epoch: 1445, train precision: 0.999423, train loss: 264.189667, valid precision: 0.707617, valid loss: 1037620.812500
epoch: 1446, train precision: 0.998247, train loss: 1186.037720, valid precision: 0.685547, valid loss: 1083307.500000
epoch: 1447, train precision: 0.999512, train loss: 192.527298, valid precision: 0.698633, valid loss: 1061255.125000
epoch: 1448, train precision: 0.998291, train loss: 1176.782959, valid precision: 0.694727, valid loss: 1052074.625000
epoch: 1449, train precision: 0.999445, train loss: 317.311768, valid precision: 0.699023, valid loss: 1063831.250000
epoch: 1450, train precision: 0.999312, train loss: 367.846100, valid precision: 0.704102, valid loss: 1090081.500000
epoch: 1451, train precision: 0.998469, train loss: 938.811584, valid precision: 0.691797, valid loss: 1090602.125000
epoch: 1452, train precision: 0.999046, train loss: 525.040100, valid precision: 0.705664, valid loss: 1064946.750000
epoch: 1453, train precision: 0.999467, train loss: 374.149811, valid precision: 0.703711, valid loss: 1062631.500000
epoch: 1454, train precision: 0.999645, train loss: 270.297974, valid precision: 0.709766, valid loss: 1055223.250000
epoch: 1455, train precision: 0.999290, train loss: 484.457916, valid precision: 0.707227, valid loss: 1118224.000000
epoch: 1456, train precision: 0.999556, train loss: 224.325012, valid precision: 0.708789, valid loss: 1069029.375000
epoch: 1457, train precision: 0.999512, train loss: 295.891998, valid precision: 0.709180, valid loss: 1094857.250000
epoch: 1458, train precision: 0.999423, train loss: 381.361023, valid precision: 0.701172, valid loss: 1068703.625000
epoch: 1459, train precision: 0.999689, train loss: 127.907524, valid precision: 0.709570, valid loss: 1059022.625000
epoch: 1460, train precision: 0.999534, train loss: 235.516159, valid precision: 0.708008, valid loss: 1081576.250000
epoch: 1461, train precision: 0.999512, train loss: 222.579727, valid precision: 0.710547, valid loss: 1116088.250000
epoch: 1462, train precision: 0.999268, train loss: 483.458191, valid precision: 0.704492, valid loss: 1078783.250000
epoch: 1463, train precision: 0.999645, train loss: 91.105103, valid precision: 0.701563, valid loss: 1084929.250000
epoch: 1464, train precision: 0.999068, train loss: 590.795532, valid precision: 0.702344, valid loss: 1070723.750000
epoch: 1465, train precision: 0.999445, train loss: 365.554993, valid precision: 0.699023, valid loss: 1091190.625000
epoch: 1466, train precision: 0.999112, train loss: 472.741699, valid precision: 0.701367, valid loss: 1066844.875000
epoch: 1467, train precision: 0.999157, train loss: 727.721436, valid precision: 0.694727, valid loss: 1116156.750000
epoch: 1468, train precision: 0.999845, train loss: 198.721039, valid precision: 0.696289, valid loss: 1103976.250000
epoch: 1469, train precision: 0.999312, train loss: 544.766846, valid precision: 0.692187, valid loss: 1111100.250000
epoch: 1470, train precision: 0.999356, train loss: 363.301758, valid precision: 0.695898, valid loss: 1088143.750000
epoch: 1471, train precision: 0.999423, train loss: 456.564423, valid precision: 0.697852, valid loss: 1090095.375000
epoch: 1472, train precision: 0.999667, train loss: 166.005615, valid precision: 0.702930, valid loss: 1070845.000000
epoch: 1473, train precision: 0.999867, train loss: 51.404774, valid precision: 0.707422, valid loss: 1075741.250000
epoch: 1474, train precision: 0.999956, train loss: 21.211149, valid precision: 0.703906, valid loss: 1099639.250000
epoch: 1475, train precision: 0.998846, train loss: 569.318481, valid precision: 0.694531, valid loss: 1080762.250000
epoch: 1476, train precision: 0.998713, train loss: 1149.475098, valid precision: 0.696680, valid loss: 1189117.125000
epoch: 1477, train precision: 0.999401, train loss: 414.562225, valid precision: 0.700195, valid loss: 1179614.875000
epoch: 1478, train precision: 0.998979, train loss: 620.504761, valid precision: 0.695898, valid loss: 1165502.750000
epoch: 1479, train precision: 0.999556, train loss: 267.829315, valid precision: 0.701367, valid loss: 1157758.750000
epoch: 1480, train precision: 0.998979, train loss: 588.639404, valid precision: 0.703320, valid loss: 1116221.000000
epoch: 1481, train precision: 0.999134, train loss: 314.262207, valid precision: 0.696680, valid loss: 1139775.375000
epoch: 1482, train precision: 0.998935, train loss: 885.974243, valid precision: 0.691797, valid loss: 1190369.000000
epoch: 1483, train precision: 0.999423, train loss: 331.970428, valid precision: 0.697461, valid loss: 1154991.000000
epoch: 1484, train precision: 0.999556, train loss: 434.060272, valid precision: 0.698633, valid loss: 1185239.500000
epoch: 1485, train precision: 0.999867, train loss: 103.567650, valid precision: 0.696094, valid loss: 1160663.375000
epoch: 1486, train precision: 0.998469, train loss: 1021.290100, valid precision: 0.694531, valid loss: 1190846.875000
epoch: 1487, train precision: 0.997070, train loss: 2933.984131, valid precision: 0.701563, valid loss: 1226674.250000
epoch: 1488, train precision: 0.999534, train loss: 211.553665, valid precision: 0.692969, valid loss: 1133077.500000
epoch: 1489, train precision: 0.999312, train loss: 307.508911, valid precision: 0.700781, valid loss: 1132802.750000
epoch: 1490, train precision: 0.999689, train loss: 183.728745, valid precision: 0.703711, valid loss: 1189000.250000
epoch: 1491, train precision: 0.999134, train loss: 508.639923, valid precision: 0.701758, valid loss: 1230822.000000
epoch: 1492, train precision: 0.999711, train loss: 109.726189, valid precision: 0.700977, valid loss: 1208757.125000
epoch: 1493, train precision: 0.998691, train loss: 896.008362, valid precision: 0.704102, valid loss: 1232399.625000
epoch: 1494, train precision: 0.999112, train loss: 554.223206, valid precision: 0.695312, valid loss: 1197841.375000
epoch: 1495, train precision: 0.999490, train loss: 211.832428, valid precision: 0.704492, valid loss: 1197463.125000
epoch: 1496, train precision: 0.999556, train loss: 287.751801, valid precision: 0.699805, valid loss: 1239239.250000
epoch: 1497, train precision: 0.999312, train loss: 387.526978, valid precision: 0.697656, valid loss: 1243588.750000
epoch: 1498, train precision: 0.999245, train loss: 616.854065, valid precision: 0.707617, valid loss: 1249076.250000
epoch: 1499, train precision: 0.999268, train loss: 403.211304, valid precision: 0.695703, valid loss: 1243641.750000
epoch: 1500, train precision: 0.999667, train loss: 209.619232, valid precision: 0.706055, valid loss: 1168837.375000
epoch: 1501, train precision: 0.999867, train loss: 32.403118, valid precision: 0.702148, valid loss: 1175851.125000
epoch: 1502, train precision: 0.999600, train loss: 281.533478, valid precision: 0.698047, valid loss: 1219928.625000
epoch: 1503, train precision: 0.999534, train loss: 305.343719, valid precision: 0.690430, valid loss: 1145685.250000
epoch: 1504, train precision: 0.999445, train loss: 210.151505, valid precision: 0.697461, valid loss: 1155219.750000
epoch: 1505, train precision: 0.998446, train loss: 959.628174, valid precision: 0.701563, valid loss: 1226088.250000
epoch: 1506, train precision: 0.998291, train loss: 1346.016724, valid precision: 0.692578, valid loss: 1261231.750000
epoch: 1507, train precision: 0.998890, train loss: 779.908203, valid precision: 0.701172, valid loss: 1255427.750000
epoch: 1508, train precision: 0.999534, train loss: 213.029480, valid precision: 0.704883, valid loss: 1272883.000000
epoch: 1509, train precision: 0.999756, train loss: 70.427979, valid precision: 0.709961, valid loss: 1201619.750000
epoch: 1510, train precision: 0.999845, train loss: 93.051414, valid precision: 0.708984, valid loss: 1239530.875000
epoch: 1511, train precision: 0.999467, train loss: 384.969818, valid precision: 0.701367, valid loss: 1238535.750000
epoch: 1512, train precision: 0.998935, train loss: 833.089111, valid precision: 0.706055, valid loss: 1275022.250000
epoch: 1513, train precision: 0.999667, train loss: 176.554489, valid precision: 0.709766, valid loss: 1252462.750000
epoch: 1514, train precision: 0.999578, train loss: 288.073639, valid precision: 0.707422, valid loss: 1241939.250000
epoch: 1515, train precision: 0.999645, train loss: 193.081680, valid precision: 0.707031, valid loss: 1252712.000000
epoch: 1516, train precision: 0.997470, train loss: 2507.055664, valid precision: 0.680273, valid loss: 1172028.750000
epoch: 1517, train precision: 0.999911, train loss: 85.906853, valid precision: 0.701953, valid loss: 1204695.250000
epoch: 1518, train precision: 0.999534, train loss: 310.746368, valid precision: 0.700586, valid loss: 1213447.500000
epoch: 1519, train precision: 0.999667, train loss: 246.009949, valid precision: 0.704297, valid loss: 1215861.750000
epoch: 1520, train precision: 0.999534, train loss: 270.230286, valid precision: 0.701367, valid loss: 1302951.625000
epoch: 1521, train precision: 0.999667, train loss: 260.932251, valid precision: 0.708984, valid loss: 1259097.625000
epoch: 1522, train precision: 0.999667, train loss: 131.421341, valid precision: 0.697656, valid loss: 1236924.250000
epoch: 1523, train precision: 0.999445, train loss: 334.893829, valid precision: 0.700977, valid loss: 1248971.750000
epoch: 1524, train precision: 0.999134, train loss: 591.573853, valid precision: 0.702539, valid loss: 1279842.250000
epoch: 1525, train precision: 0.999423, train loss: 361.421234, valid precision: 0.698633, valid loss: 1298795.750000
epoch: 1526, train precision: 0.999578, train loss: 233.968887, valid precision: 0.701758, valid loss: 1282930.375000
epoch: 1527, train precision: 0.999711, train loss: 150.864502, valid precision: 0.706641, valid loss: 1315021.375000
epoch: 1528, train precision: 0.999578, train loss: 268.525116, valid precision: 0.690820, valid loss: 1290758.250000
epoch: 1529, train precision: 0.999023, train loss: 571.215027, valid precision: 0.688672, valid loss: 1353731.250000
epoch: 1530, train precision: 0.998957, train loss: 723.006409, valid precision: 0.694922, valid loss: 1261406.000000
epoch: 1531, train precision: 0.999556, train loss: 225.462753, valid precision: 0.697070, valid loss: 1273413.750000
epoch: 1532, train precision: 0.999778, train loss: 86.141861, valid precision: 0.700977, valid loss: 1219389.625000
epoch: 1533, train precision: 0.999578, train loss: 354.010223, valid precision: 0.708594, valid loss: 1235919.250000
epoch: 1534, train precision: 0.999023, train loss: 682.016052, valid precision: 0.697461, valid loss: 1239027.000000
epoch: 1535, train precision: 0.999379, train loss: 338.299591, valid precision: 0.702344, valid loss: 1249216.750000
epoch: 1536, train precision: 0.999245, train loss: 553.049255, valid precision: 0.702734, valid loss: 1294713.625000
epoch: 1537, train precision: 0.999112, train loss: 704.915222, valid precision: 0.696875, valid loss: 1322982.375000
epoch: 1538, train precision: 0.999245, train loss: 433.126740, valid precision: 0.698438, valid loss: 1320128.750000
epoch: 1539, train precision: 0.999090, train loss: 514.025330, valid precision: 0.697266, valid loss: 1296225.750000
epoch: 1540, train precision: 0.999467, train loss: 403.111023, valid precision: 0.700977, valid loss: 1247077.375000
epoch: 1541, train precision: 0.999711, train loss: 189.542038, valid precision: 0.706250, valid loss: 1285221.375000
epoch: 1542, train precision: 0.999312, train loss: 445.456268, valid precision: 0.699023, valid loss: 1259039.000000
epoch: 1543, train precision: 0.999490, train loss: 266.688751, valid precision: 0.706445, valid loss: 1260515.625000
epoch: 1544, train precision: 0.999512, train loss: 276.275116, valid precision: 0.696094, valid loss: 1259300.125000
epoch: 1545, train precision: 0.998757, train loss: 969.835999, valid precision: 0.694531, valid loss: 1277239.500000
epoch: 1546, train precision: 0.999490, train loss: 323.520020, valid precision: 0.695898, valid loss: 1313234.750000
epoch: 1547, train precision: 0.999401, train loss: 480.402344, valid precision: 0.699805, valid loss: 1264544.375000
epoch: 1548, train precision: 0.999578, train loss: 225.076126, valid precision: 0.705859, valid loss: 1302927.625000
epoch: 1549, train precision: 0.999867, train loss: 49.271011, valid precision: 0.709570, valid loss: 1286842.625000
epoch: 1550, train precision: 0.998535, train loss: 1400.544189, valid precision: 0.708984, valid loss: 1377940.375000
epoch: 1551, train precision: 0.999023, train loss: 885.054260, valid precision: 0.706445, valid loss: 1368485.625000
epoch: 1552, train precision: 0.999068, train loss: 599.705994, valid precision: 0.702148, valid loss: 1391297.750000
epoch: 1553, train precision: 0.999512, train loss: 336.157104, valid precision: 0.718164, valid loss: 1344976.875000
epoch: 1554, train precision: 0.999711, train loss: 85.036613, valid precision: 0.699805, valid loss: 1287958.875000
epoch: 1555, train precision: 0.999490, train loss: 273.848633, valid precision: 0.700781, valid loss: 1273773.875000
epoch: 1556, train precision: 0.999512, train loss: 288.361084, valid precision: 0.704492, valid loss: 1287523.500000
epoch: 1557, train precision: 0.999401, train loss: 331.177063, valid precision: 0.708789, valid loss: 1327089.250000
epoch: 1558, train precision: 0.999134, train loss: 485.241516, valid precision: 0.697461, valid loss: 1279177.375000
epoch: 1559, train precision: 0.999534, train loss: 437.043488, valid precision: 0.710547, valid loss: 1292028.875000
epoch: 1560, train precision: 0.999734, train loss: 235.565521, valid precision: 0.712109, valid loss: 1310549.750000
epoch: 1561, train precision: 0.999379, train loss: 529.806824, valid precision: 0.708594, valid loss: 1288201.000000
epoch: 1562, train precision: 0.999512, train loss: 228.658737, valid precision: 0.702734, valid loss: 1303335.500000
epoch: 1563, train precision: 0.999401, train loss: 385.373932, valid precision: 0.695312, valid loss: 1300889.625000
epoch: 1564, train precision: 0.999134, train loss: 551.294800, valid precision: 0.705469, valid loss: 1298686.500000
epoch: 1565, train precision: 0.999312, train loss: 458.211700, valid precision: 0.709180, valid loss: 1323189.750000
epoch: 1566, train precision: 0.998890, train loss: 643.019043, valid precision: 0.707617, valid loss: 1357108.375000
epoch: 1567, train precision: 0.999600, train loss: 316.258514, valid precision: 0.709180, valid loss: 1286851.375000
epoch: 1568, train precision: 0.999667, train loss: 173.226822, valid precision: 0.702344, valid loss: 1323800.375000
epoch: 1569, train precision: 0.999201, train loss: 704.063232, valid precision: 0.697852, valid loss: 1335393.250000
epoch: 1570, train precision: 0.999623, train loss: 226.482681, valid precision: 0.709570, valid loss: 1378449.750000
epoch: 1571, train precision: 0.999157, train loss: 600.180420, valid precision: 0.703516, valid loss: 1310222.250000
epoch: 1572, train precision: 0.998247, train loss: 1183.823486, valid precision: 0.705078, valid loss: 1375068.375000
epoch: 1573, train precision: 0.999445, train loss: 311.005554, valid precision: 0.701172, valid loss: 1334683.625000
epoch: 1574, train precision: 0.999689, train loss: 178.234085, valid precision: 0.706445, valid loss: 1346622.000000
epoch: 1575, train precision: 0.999090, train loss: 642.909973, valid precision: 0.702539, valid loss: 1360616.750000
epoch: 1576, train precision: 0.998935, train loss: 1000.140808, valid precision: 0.699414, valid loss: 1343877.250000
epoch: 1577, train precision: 0.999401, train loss: 371.124298, valid precision: 0.702539, valid loss: 1360098.375000
epoch: 1578, train precision: 0.998557, train loss: 1132.691895, valid precision: 0.704687, valid loss: 1391605.625000
epoch: 1579, train precision: 0.999179, train loss: 663.645935, valid precision: 0.700000, valid loss: 1363688.000000
epoch: 1580, train precision: 0.999578, train loss: 228.765442, valid precision: 0.698438, valid loss: 1397098.625000
epoch: 1581, train precision: 0.998535, train loss: 1268.397949, valid precision: 0.695117, valid loss: 1412460.750000
epoch: 1582, train precision: 0.998868, train loss: 761.922424, valid precision: 0.701172, valid loss: 1413427.000000
epoch: 1583, train precision: 0.998091, train loss: 1957.127441, valid precision: 0.688281, valid loss: 1472627.375000
epoch: 1584, train precision: 0.999157, train loss: 605.900818, valid precision: 0.698047, valid loss: 1358393.375000
epoch: 1585, train precision: 0.999334, train loss: 384.052032, valid precision: 0.698047, valid loss: 1351721.875000
epoch: 1586, train precision: 0.998446, train loss: 1128.812500, valid precision: 0.688867, valid loss: 1370859.750000
epoch: 1587, train precision: 0.999090, train loss: 553.923401, valid precision: 0.709180, valid loss: 1331655.125000
epoch: 1588, train precision: 0.999623, train loss: 215.053375, valid precision: 0.695508, valid loss: 1345701.625000
epoch: 1589, train precision: 0.999423, train loss: 379.127472, valid precision: 0.700781, valid loss: 1352878.125000
epoch: 1590, train precision: 0.999600, train loss: 186.442688, valid precision: 0.703125, valid loss: 1411669.375000
epoch: 1591, train precision: 0.999556, train loss: 238.935562, valid precision: 0.708594, valid loss: 1421198.750000
epoch: 1592, train precision: 0.999467, train loss: 437.707642, valid precision: 0.704687, valid loss: 1413977.375000
epoch: 1593, train precision: 0.999600, train loss: 300.784790, valid precision: 0.702148, valid loss: 1388199.625000
epoch: 1594, train precision: 0.999578, train loss: 304.416870, valid precision: 0.697656, valid loss: 1395486.875000
epoch: 1595, train precision: 0.999379, train loss: 459.630890, valid precision: 0.701953, valid loss: 1438546.375000
epoch: 1596, train precision: 0.999734, train loss: 160.123764, valid precision: 0.708789, valid loss: 1391828.750000
epoch: 1597, train precision: 0.999112, train loss: 756.184631, valid precision: 0.699805, valid loss: 1406922.625000
epoch: 1598, train precision: 0.998735, train loss: 942.926575, valid precision: 0.690234, valid loss: 1383623.625000
epoch: 1599, train precision: 0.999711, train loss: 94.705170, valid precision: 0.697266, valid loss: 1351731.250000
epoch: 1600, train precision: 0.999778, train loss: 80.006638, valid precision: 0.696289, valid loss: 1369870.250000
epoch: 1601, train precision: 0.999711, train loss: 146.213745, valid precision: 0.707812, valid loss: 1442668.625000
epoch: 1602, train precision: 0.998491, train loss: 1274.901855, valid precision: 0.700586, valid loss: 1436945.625000
epoch: 1603, train precision: 0.999490, train loss: 375.749481, valid precision: 0.701758, valid loss: 1412068.125000
epoch: 1604, train precision: 0.999578, train loss: 310.230774, valid precision: 0.705859, valid loss: 1382151.000000
epoch: 1605, train precision: 0.999245, train loss: 400.748444, valid precision: 0.706250, valid loss: 1416114.625000
epoch: 1606, train precision: 0.999867, train loss: 63.914650, valid precision: 0.710156, valid loss: 1427383.750000
epoch: 1607, train precision: 0.999245, train loss: 498.474701, valid precision: 0.694141, valid loss: 1460452.750000
epoch: 1608, train precision: 0.999445, train loss: 577.846130, valid precision: 0.702344, valid loss: 1431446.250000
epoch: 1609, train precision: 0.999578, train loss: 348.410522, valid precision: 0.702734, valid loss: 1417263.750000
epoch: 1610, train precision: 0.999490, train loss: 318.886505, valid precision: 0.704297, valid loss: 1448845.750000
epoch: 1611, train precision: 0.999379, train loss: 494.984161, valid precision: 0.702148, valid loss: 1440911.750000
epoch: 1612, train precision: 0.999467, train loss: 366.286255, valid precision: 0.702930, valid loss: 1457546.750000
epoch: 1613, train precision: 0.999689, train loss: 268.631897, valid precision: 0.699219, valid loss: 1491861.750000
epoch: 1614, train precision: 0.999379, train loss: 633.689209, valid precision: 0.696289, valid loss: 1449983.625000
epoch: 1615, train precision: 0.999268, train loss: 588.633606, valid precision: 0.699219, valid loss: 1417071.375000
epoch: 1616, train precision: 0.999268, train loss: 578.715881, valid precision: 0.703320, valid loss: 1416427.625000
epoch: 1617, train precision: 0.999600, train loss: 232.043762, valid precision: 0.694141, valid loss: 1471470.250000
epoch: 1618, train precision: 0.999201, train loss: 894.756897, valid precision: 0.704102, valid loss: 1471975.250000
epoch: 1619, train precision: 0.999268, train loss: 962.184937, valid precision: 0.707227, valid loss: 1508315.125000
epoch: 1620, train precision: 0.999179, train loss: 833.448486, valid precision: 0.708398, valid loss: 1539640.125000
epoch: 1621, train precision: 0.999845, train loss: 86.377144, valid precision: 0.709570, valid loss: 1562825.375000
epoch: 1622, train precision: 0.999312, train loss: 565.259583, valid precision: 0.708789, valid loss: 1575771.250000
epoch: 1623, train precision: 0.999623, train loss: 522.825745, valid precision: 0.706250, valid loss: 1555963.375000
epoch: 1624, train precision: 0.999889, train loss: 21.589369, valid precision: 0.708984, valid loss: 1553237.375000
epoch: 1625, train precision: 0.999512, train loss: 275.366608, valid precision: 0.705273, valid loss: 1503246.625000
epoch: 1626, train precision: 0.999312, train loss: 537.227295, valid precision: 0.708789, valid loss: 1536605.125000
epoch: 1627, train precision: 0.999556, train loss: 330.976410, valid precision: 0.704687, valid loss: 1496863.625000
epoch: 1628, train precision: 0.999268, train loss: 725.672852, valid precision: 0.706641, valid loss: 1552041.625000
epoch: 1629, train precision: 0.999356, train loss: 694.842102, valid precision: 0.699023, valid loss: 1528095.375000
epoch: 1630, train precision: 0.998735, train loss: 1073.520630, valid precision: 0.703906, valid loss: 1536563.750000
epoch: 1631, train precision: 0.999711, train loss: 150.995102, valid precision: 0.703125, valid loss: 1518871.750000
epoch: 1632, train precision: 0.999689, train loss: 109.442703, valid precision: 0.698828, valid loss: 1499447.125000
epoch: 1633, train precision: 0.999689, train loss: 319.147583, valid precision: 0.704687, valid loss: 1548743.250000
epoch: 1634, train precision: 0.999245, train loss: 612.536316, valid precision: 0.702930, valid loss: 1557106.000000
epoch: 1635, train precision: 0.999423, train loss: 489.863739, valid precision: 0.700391, valid loss: 1555969.250000
epoch: 1636, train precision: 0.999023, train loss: 1047.582397, valid precision: 0.705273, valid loss: 1514759.375000
epoch: 1637, train precision: 0.998912, train loss: 1139.081543, valid precision: 0.706055, valid loss: 1567840.750000
epoch: 1638, train precision: 0.999467, train loss: 309.415009, valid precision: 0.706445, valid loss: 1517426.625000
epoch: 1639, train precision: 0.999778, train loss: 201.170456, valid precision: 0.707031, valid loss: 1534202.250000
epoch: 1640, train precision: 0.999645, train loss: 209.793365, valid precision: 0.707031, valid loss: 1589363.000000
epoch: 1641, train precision: 0.999800, train loss: 124.897835, valid precision: 0.702930, valid loss: 1540360.500000
epoch: 1642, train precision: 0.999157, train loss: 807.337891, valid precision: 0.695312, valid loss: 1573047.625000
epoch: 1643, train precision: 0.999667, train loss: 352.635345, valid precision: 0.701758, valid loss: 1581782.750000
epoch: 1644, train precision: 0.999068, train loss: 833.913696, valid precision: 0.694531, valid loss: 1586655.375000
epoch: 1645, train precision: 0.999134, train loss: 524.227966, valid precision: 0.697070, valid loss: 1559719.250000
epoch: 1646, train precision: 0.999689, train loss: 128.308945, valid precision: 0.703125, valid loss: 1537209.250000
epoch: 1647, train precision: 0.998424, train loss: 1143.496216, valid precision: 0.699805, valid loss: 1593496.500000
epoch: 1648, train precision: 0.999490, train loss: 370.792847, valid precision: 0.707227, valid loss: 1604984.750000
epoch: 1649, train precision: 0.999090, train loss: 1152.317627, valid precision: 0.700195, valid loss: 1562477.375000
epoch: 1650, train precision: 0.999623, train loss: 289.367950, valid precision: 0.696680, valid loss: 1584552.750000
epoch: 1651, train precision: 0.999600, train loss: 270.969879, valid precision: 0.709180, valid loss: 1560932.625000
epoch: 1652, train precision: 0.999512, train loss: 276.932678, valid precision: 0.706055, valid loss: 1535750.250000
epoch: 1653, train precision: 0.999711, train loss: 160.471298, valid precision: 0.710352, valid loss: 1579355.625000
epoch: 1654, train precision: 0.999512, train loss: 543.920288, valid precision: 0.703320, valid loss: 1614654.250000
epoch: 1655, train precision: 0.999667, train loss: 228.145950, valid precision: 0.698828, valid loss: 1546987.750000
epoch: 1656, train precision: 0.999467, train loss: 432.756927, valid precision: 0.703711, valid loss: 1582275.250000
epoch: 1657, train precision: 0.999401, train loss: 320.429016, valid precision: 0.702539, valid loss: 1561813.000000
epoch: 1658, train precision: 0.999911, train loss: 47.248947, valid precision: 0.709570, valid loss: 1537279.000000
epoch: 1659, train precision: 0.999623, train loss: 279.922394, valid precision: 0.704687, valid loss: 1546900.750000
epoch: 1660, train precision: 0.999623, train loss: 205.139740, valid precision: 0.705273, valid loss: 1553953.250000
epoch: 1661, train precision: 0.999423, train loss: 469.763763, valid precision: 0.697266, valid loss: 1644556.250000
epoch: 1662, train precision: 0.999556, train loss: 271.871124, valid precision: 0.694727, valid loss: 1602247.250000
epoch: 1663, train precision: 0.999578, train loss: 218.024185, valid precision: 0.717969, valid loss: 1636990.250000
epoch: 1664, train precision: 0.999645, train loss: 254.398972, valid precision: 0.714844, valid loss: 1605769.750000
epoch: 1665, train precision: 0.999667, train loss: 209.503998, valid precision: 0.711914, valid loss: 1625053.750000
epoch: 1666, train precision: 0.999356, train loss: 541.189880, valid precision: 0.703711, valid loss: 1640757.375000
epoch: 1667, train precision: 0.998602, train loss: 1354.790894, valid precision: 0.701953, valid loss: 1655547.500000
epoch: 1668, train precision: 0.999578, train loss: 385.370117, valid precision: 0.706250, valid loss: 1634324.750000
epoch: 1669, train precision: 0.999512, train loss: 352.553497, valid precision: 0.704297, valid loss: 1605879.250000
epoch: 1670, train precision: 0.999645, train loss: 419.855164, valid precision: 0.709570, valid loss: 1645633.250000
epoch: 1671, train precision: 0.999445, train loss: 332.484344, valid precision: 0.714844, valid loss: 1611750.375000
epoch: 1672, train precision: 0.999490, train loss: 410.749023, valid precision: 0.699023, valid loss: 1646312.250000
epoch: 1673, train precision: 0.999734, train loss: 112.803978, valid precision: 0.700391, valid loss: 1567169.000000
epoch: 1674, train precision: 0.999845, train loss: 87.381638, valid precision: 0.700586, valid loss: 1617899.250000
epoch: 1675, train precision: 0.999711, train loss: 180.806274, valid precision: 0.700195, valid loss: 1641208.000000
epoch: 1676, train precision: 0.999068, train loss: 899.369690, valid precision: 0.702344, valid loss: 1668289.875000
epoch: 1677, train precision: 0.999711, train loss: 238.265610, valid precision: 0.701172, valid loss: 1649179.250000
epoch: 1678, train precision: 0.999223, train loss: 824.337952, valid precision: 0.703320, valid loss: 1624987.000000
epoch: 1679, train precision: 0.999667, train loss: 238.180817, valid precision: 0.700977, valid loss: 1650335.000000
epoch: 1680, train precision: 0.999600, train loss: 237.667130, valid precision: 0.696875, valid loss: 1608743.000000
epoch: 1681, train precision: 0.999223, train loss: 760.535889, valid precision: 0.708789, valid loss: 1614532.625000
epoch: 1682, train precision: 0.999600, train loss: 266.548553, valid precision: 0.702930, valid loss: 1666745.250000
epoch: 1683, train precision: 0.999667, train loss: 458.953613, valid precision: 0.701953, valid loss: 1704160.750000
epoch: 1684, train precision: 0.999689, train loss: 288.003784, valid precision: 0.706836, valid loss: 1716345.000000
epoch: 1685, train precision: 0.999290, train loss: 890.534119, valid precision: 0.701758, valid loss: 1729267.375000
epoch: 1686, train precision: 0.999534, train loss: 601.206299, valid precision: 0.703125, valid loss: 1711675.625000
epoch: 1687, train precision: 0.999445, train loss: 357.548309, valid precision: 0.705859, valid loss: 1710662.000000
epoch: 1688, train precision: 0.999556, train loss: 340.729126, valid precision: 0.710547, valid loss: 1732766.750000
epoch: 1689, train precision: 0.999778, train loss: 97.868607, valid precision: 0.707422, valid loss: 1637255.250000
epoch: 1690, train precision: 0.999245, train loss: 518.528992, valid precision: 0.707812, valid loss: 1643231.250000
epoch: 1691, train precision: 0.999534, train loss: 224.656631, valid precision: 0.705273, valid loss: 1657380.375000
epoch: 1692, train precision: 0.999911, train loss: 93.216461, valid precision: 0.709766, valid loss: 1634580.750000
epoch: 1693, train precision: 0.999867, train loss: 88.716499, valid precision: 0.714844, valid loss: 1650719.500000
epoch: 1694, train precision: 0.998691, train loss: 1430.675293, valid precision: 0.704297, valid loss: 1735814.375000
epoch: 1695, train precision: 0.998491, train loss: 1300.551758, valid precision: 0.710156, valid loss: 1713644.750000
epoch: 1696, train precision: 0.999245, train loss: 714.954651, valid precision: 0.704492, valid loss: 1666295.750000
epoch: 1697, train precision: 0.999734, train loss: 152.218246, valid precision: 0.714844, valid loss: 1716525.750000
epoch: 1698, train precision: 0.999600, train loss: 197.645859, valid precision: 0.713477, valid loss: 1701513.625000
epoch: 1699, train precision: 0.999689, train loss: 243.001450, valid precision: 0.705859, valid loss: 1719117.625000
epoch: 1700, train precision: 0.999711, train loss: 207.523132, valid precision: 0.711133, valid loss: 1678494.625000
epoch: 1701, train precision: 0.999800, train loss: 162.658142, valid precision: 0.713672, valid loss: 1640684.625000
epoch: 1702, train precision: 0.999334, train loss: 613.372131, valid precision: 0.712500, valid loss: 1662021.875000
epoch: 1703, train precision: 0.995855, train loss: 5413.467773, valid precision: 0.697656, valid loss: 1746077.250000
epoch: 1704, train precision: 0.999645, train loss: 337.478058, valid precision: 0.713086, valid loss: 1708540.625000
epoch: 1705, train precision: 0.999623, train loss: 377.382416, valid precision: 0.710352, valid loss: 1765804.375000
epoch: 1706, train precision: 0.999534, train loss: 362.707001, valid precision: 0.708984, valid loss: 1706787.750000
epoch: 1707, train precision: 0.999734, train loss: 194.827209, valid precision: 0.718555, valid loss: 1709910.000000
epoch: 1708, train precision: 0.999556, train loss: 397.160767, valid precision: 0.709961, valid loss: 1726334.375000
epoch: 1709, train precision: 0.999822, train loss: 84.266365, valid precision: 0.714844, valid loss: 1759984.250000
epoch: 1710, train precision: 0.999822, train loss: 85.692192, valid precision: 0.710352, valid loss: 1741937.375000
epoch: 1711, train precision: 0.999800, train loss: 195.519058, valid precision: 0.712500, valid loss: 1732942.250000
epoch: 1712, train precision: 0.999334, train loss: 681.555054, valid precision: 0.701953, valid loss: 1751302.000000
epoch: 1713, train precision: 0.999112, train loss: 779.471497, valid precision: 0.704687, valid loss: 1770278.000000
epoch: 1714, train precision: 0.999822, train loss: 46.836681, valid precision: 0.709570, valid loss: 1700301.000000
epoch: 1715, train precision: 0.999467, train loss: 436.834778, valid precision: 0.709570, valid loss: 1773074.250000
epoch: 1716, train precision: 0.999423, train loss: 498.317078, valid precision: 0.715039, valid loss: 1828739.625000
epoch: 1717, train precision: 0.999467, train loss: 449.445221, valid precision: 0.709570, valid loss: 1785162.000000
epoch: 1718, train precision: 0.999756, train loss: 220.424408, valid precision: 0.707617, valid loss: 1762273.375000
epoch: 1719, train precision: 0.999822, train loss: 143.546860, valid precision: 0.712305, valid loss: 1780975.000000
epoch: 1720, train precision: 0.999490, train loss: 315.058502, valid precision: 0.703906, valid loss: 1727015.750000
epoch: 1721, train precision: 0.999933, train loss: 19.236549, valid precision: 0.711719, valid loss: 1707709.250000
epoch: 1722, train precision: 0.999623, train loss: 179.555527, valid precision: 0.707031, valid loss: 1733907.250000
epoch: 1723, train precision: 0.999578, train loss: 467.381744, valid precision: 0.714258, valid loss: 1825222.750000
epoch: 1724, train precision: 0.999800, train loss: 88.258530, valid precision: 0.705664, valid loss: 1729437.250000
epoch: 1725, train precision: 0.999512, train loss: 422.083527, valid precision: 0.712695, valid loss: 1763082.375000
epoch: 1726, train precision: 0.999490, train loss: 788.198608, valid precision: 0.709375, valid loss: 1778920.375000
epoch: 1727, train precision: 0.999401, train loss: 338.740051, valid precision: 0.706055, valid loss: 1780997.250000
epoch: 1728, train precision: 0.999734, train loss: 109.253494, valid precision: 0.717383, valid loss: 1812260.000000
epoch: 1729, train precision: 0.999268, train loss: 633.720947, valid precision: 0.710742, valid loss: 1757703.625000
epoch: 1730, train precision: 0.998779, train loss: 1290.752075, valid precision: 0.696680, valid loss: 1908612.625000
epoch: 1731, train precision: 0.999711, train loss: 267.052856, valid precision: 0.713281, valid loss: 1787054.000000
epoch: 1732, train precision: 0.998979, train loss: 916.088074, valid precision: 0.706445, valid loss: 1815473.625000
epoch: 1733, train precision: 0.999867, train loss: 30.590370, valid precision: 0.720117, valid loss: 1749357.250000
epoch: 1734, train precision: 0.999334, train loss: 641.761902, valid precision: 0.716211, valid loss: 1837163.625000
epoch: 1735, train precision: 0.999401, train loss: 628.580627, valid precision: 0.716211, valid loss: 1842997.625000
epoch: 1736, train precision: 0.999578, train loss: 397.486694, valid precision: 0.714063, valid loss: 1825240.625000
epoch: 1737, train precision: 0.999578, train loss: 333.861450, valid precision: 0.712500, valid loss: 1739304.000000
epoch: 1738, train precision: 0.999756, train loss: 230.799225, valid precision: 0.717773, valid loss: 1724742.250000
epoch: 1739, train precision: 0.999423, train loss: 436.383698, valid precision: 0.715820, valid loss: 1770825.625000
epoch: 1740, train precision: 0.999623, train loss: 275.028778, valid precision: 0.709766, valid loss: 1768982.375000
epoch: 1741, train precision: 0.999423, train loss: 414.283661, valid precision: 0.712500, valid loss: 1746087.375000
epoch: 1742, train precision: 0.999623, train loss: 370.446808, valid precision: 0.718945, valid loss: 1749969.000000
epoch: 1743, train precision: 0.999623, train loss: 272.286041, valid precision: 0.707227, valid loss: 1776868.000000
epoch: 1744, train precision: 0.999645, train loss: 222.158936, valid precision: 0.707812, valid loss: 1761945.375000
epoch: 1745, train precision: 0.999867, train loss: 107.050667, valid precision: 0.706250, valid loss: 1756374.250000
epoch: 1746, train precision: 0.999800, train loss: 126.012810, valid precision: 0.706250, valid loss: 1808785.375000
epoch: 1747, train precision: 0.999667, train loss: 290.056549, valid precision: 0.708398, valid loss: 1824273.625000
epoch: 1748, train precision: 0.999578, train loss: 500.809113, valid precision: 0.703711, valid loss: 1851832.375000
epoch: 1749, train precision: 0.998424, train loss: 1842.028198, valid precision: 0.705664, valid loss: 1931975.250000
epoch: 1750, train precision: 0.999711, train loss: 340.068970, valid precision: 0.707227, valid loss: 1857315.625000
epoch: 1751, train precision: 0.999490, train loss: 482.638947, valid precision: 0.702148, valid loss: 1845560.250000
epoch: 1752, train precision: 0.999467, train loss: 514.671936, valid precision: 0.701563, valid loss: 1787152.000000
epoch: 1753, train precision: 0.999711, train loss: 237.728165, valid precision: 0.707422, valid loss: 1801636.750000
epoch: 1754, train precision: 0.999756, train loss: 127.337761, valid precision: 0.713477, valid loss: 1844654.750000
epoch: 1755, train precision: 0.999911, train loss: 34.154240, valid precision: 0.715820, valid loss: 1873841.250000
epoch: 1756, train precision: 0.999911, train loss: 91.893456, valid precision: 0.717578, valid loss: 1890262.625000
epoch: 1757, train precision: 0.999578, train loss: 429.994659, valid precision: 0.706250, valid loss: 1886794.625000
epoch: 1758, train precision: 0.998868, train loss: 1636.687134, valid precision: 0.701563, valid loss: 1868896.375000
epoch: 1759, train precision: 0.999490, train loss: 493.552826, valid precision: 0.703125, valid loss: 1808201.000000
epoch: 1760, train precision: 0.998912, train loss: 1184.885986, valid precision: 0.707227, valid loss: 1837580.750000
epoch: 1761, train precision: 0.999867, train loss: 79.225464, valid precision: 0.702734, valid loss: 1734021.375000
epoch: 1762, train precision: 0.999046, train loss: 1015.177551, valid precision: 0.705078, valid loss: 1856048.750000
epoch: 1763, train precision: 0.999822, train loss: 189.012955, valid precision: 0.713281, valid loss: 1868429.250000
epoch: 1764, train precision: 0.999867, train loss: 59.075783, valid precision: 0.711719, valid loss: 1808448.750000
epoch: 1765, train precision: 0.999689, train loss: 179.383850, valid precision: 0.712500, valid loss: 1837677.375000
epoch: 1766, train precision: 0.999756, train loss: 349.400665, valid precision: 0.704687, valid loss: 1879222.375000
epoch: 1767, train precision: 0.999134, train loss: 900.936951, valid precision: 0.701758, valid loss: 1876101.250000
epoch: 1768, train precision: 0.999445, train loss: 407.807617, valid precision: 0.701172, valid loss: 1883556.000000
epoch: 1769, train precision: 0.999445, train loss: 583.001221, valid precision: 0.704297, valid loss: 1952149.000000
epoch: 1770, train precision: 0.999845, train loss: 69.244942, valid precision: 0.704102, valid loss: 1941641.250000
epoch: 1771, train precision: 0.999512, train loss: 461.523224, valid precision: 0.701953, valid loss: 1864490.000000
epoch: 1772, train precision: 0.999356, train loss: 698.337097, valid precision: 0.702344, valid loss: 1976761.625000
epoch: 1773, train precision: 0.999490, train loss: 617.811523, valid precision: 0.703320, valid loss: 1879356.625000
epoch: 1774, train precision: 0.999711, train loss: 181.407242, valid precision: 0.708203, valid loss: 1818757.625000
epoch: 1775, train precision: 0.999379, train loss: 627.512085, valid precision: 0.700391, valid loss: 1892001.625000
epoch: 1776, train precision: 0.999423, train loss: 498.796509, valid precision: 0.706055, valid loss: 1949604.750000
epoch: 1777, train precision: 0.999778, train loss: 148.913086, valid precision: 0.702930, valid loss: 1933318.625000
epoch: 1778, train precision: 0.999867, train loss: 182.332809, valid precision: 0.695312, valid loss: 1892299.000000
epoch: 1779, train precision: 0.999778, train loss: 98.471390, valid precision: 0.704102, valid loss: 1844465.375000
epoch: 1780, train precision: 0.999534, train loss: 360.018250, valid precision: 0.698828, valid loss: 1919809.625000
epoch: 1781, train precision: 0.999689, train loss: 329.501587, valid precision: 0.707812, valid loss: 1981505.375000
epoch: 1782, train precision: 0.999467, train loss: 515.035095, valid precision: 0.705078, valid loss: 1883055.375000
epoch: 1783, train precision: 0.999672, train loss: 257.469818, valid precision: 0.708008, valid loss: 1830033.750000
epoch: 1784, train precision: 0.999512, train loss: 369.197357, valid precision: 0.704297, valid loss: 1832025.000000
epoch: 1785, train precision: 0.999290, train loss: 833.406677, valid precision: 0.706055, valid loss: 1868607.625000
epoch: 1786, train precision: 0.999734, train loss: 243.250351, valid precision: 0.702930, valid loss: 1814881.625000
epoch: 1787, train precision: 0.999756, train loss: 155.279800, valid precision: 0.706055, valid loss: 1820160.000000
epoch: 1788, train precision: 0.999933, train loss: 29.629944, valid precision: 0.705273, valid loss: 1887575.750000
epoch: 1789, train precision: 0.998979, train loss: 1329.087769, valid precision: 0.699609, valid loss: 1985005.250000
epoch: 1790, train precision: 0.999023, train loss: 992.058777, valid precision: 0.707617, valid loss: 2024994.000000
epoch: 1791, train precision: 0.999756, train loss: 140.411972, valid precision: 0.707617, valid loss: 1956847.625000
epoch: 1792, train precision: 0.999711, train loss: 233.389160, valid precision: 0.702539, valid loss: 1975555.250000
epoch: 1793, train precision: 0.999334, train loss: 656.318298, valid precision: 0.702148, valid loss: 1965965.625000
epoch: 1794, train precision: 0.999689, train loss: 376.782806, valid precision: 0.699414, valid loss: 1987720.750000
epoch: 1795, train precision: 0.999534, train loss: 433.416595, valid precision: 0.707031, valid loss: 1958010.750000
epoch: 1796, train precision: 0.999334, train loss: 660.315735, valid precision: 0.691211, valid loss: 2055990.750000
epoch: 1797, train precision: 0.999734, train loss: 202.974915, valid precision: 0.703516, valid loss: 2028111.375000
epoch: 1798, train precision: 0.998735, train loss: 1281.986206, valid precision: 0.704297, valid loss: 1931174.375000
epoch: 1799, train precision: 0.999578, train loss: 327.610565, valid precision: 0.697461, valid loss: 1940014.375000
epoch: 1800, train precision: 0.999445, train loss: 388.114075, valid precision: 0.699219, valid loss: 1953532.375000
epoch: 1801, train precision: 0.999578, train loss: 252.849701, valid precision: 0.709570, valid loss: 1928955.625000
epoch: 1802, train precision: 0.999556, train loss: 420.435760, valid precision: 0.707031, valid loss: 2034501.625000
epoch: 1803, train precision: 0.999756, train loss: 275.636597, valid precision: 0.703711, valid loss: 1967147.000000
epoch: 1804, train precision: 0.999645, train loss: 401.567993, valid precision: 0.708594, valid loss: 2016851.375000
epoch: 1805, train precision: 0.999645, train loss: 360.260468, valid precision: 0.703320, valid loss: 1960187.250000
epoch: 1806, train precision: 0.999667, train loss: 488.799042, valid precision: 0.705664, valid loss: 1953999.250000
epoch: 1807, train precision: 0.999756, train loss: 101.490509, valid precision: 0.701367, valid loss: 1972310.375000
epoch: 1808, train precision: 0.999667, train loss: 354.937805, valid precision: 0.703906, valid loss: 1957435.750000
epoch: 1809, train precision: 0.999734, train loss: 211.838226, valid precision: 0.709961, valid loss: 1953484.625000
epoch: 1810, train precision: 0.999778, train loss: 309.580109, valid precision: 0.715234, valid loss: 1950916.625000
epoch: 1811, train precision: 0.998979, train loss: 1312.693481, valid precision: 0.704687, valid loss: 1944984.000000
epoch: 1812, train precision: 0.998624, train loss: 1759.447144, valid precision: 0.698633, valid loss: 2143068.500000
epoch: 1813, train precision: 0.999467, train loss: 482.232422, valid precision: 0.707227, valid loss: 2010928.625000
epoch: 1814, train precision: 0.999822, train loss: 134.188782, valid precision: 0.712695, valid loss: 2026014.000000
epoch: 1815, train precision: 0.999534, train loss: 498.905304, valid precision: 0.707422, valid loss: 2022879.375000
epoch: 1816, train precision: 0.999734, train loss: 247.746765, valid precision: 0.709180, valid loss: 1999263.000000
epoch: 1817, train precision: 0.999600, train loss: 338.017487, valid precision: 0.709570, valid loss: 1999385.625000
epoch: 1818, train precision: 0.998624, train loss: 1729.258545, valid precision: 0.702539, valid loss: 2012521.625000
epoch: 1819, train precision: 0.999734, train loss: 296.221619, valid precision: 0.709570, valid loss: 2006146.000000
epoch: 1820, train precision: 0.999023, train loss: 1080.564087, valid precision: 0.706641, valid loss: 2031872.000000
epoch: 1821, train precision: 0.998868, train loss: 1314.279663, valid precision: 0.704297, valid loss: 2078107.250000
epoch: 1822, train precision: 0.999645, train loss: 422.663177, valid precision: 0.705664, valid loss: 2002257.000000
epoch: 1823, train precision: 0.999245, train loss: 859.573486, valid precision: 0.709180, valid loss: 2030491.000000
epoch: 1824, train precision: 0.999490, train loss: 440.571014, valid precision: 0.708594, valid loss: 2009414.000000
epoch: 1825, train precision: 0.999734, train loss: 237.639206, valid precision: 0.706836, valid loss: 2007680.375000
epoch: 1826, train precision: 0.999134, train loss: 868.523376, valid precision: 0.705469, valid loss: 2080941.250000
epoch: 1827, train precision: 0.998735, train loss: 1600.163574, valid precision: 0.709570, valid loss: 2077025.000000
epoch: 1828, train precision: 0.999689, train loss: 170.717545, valid precision: 0.705078, valid loss: 2031302.750000
epoch: 1829, train precision: 0.999734, train loss: 460.423462, valid precision: 0.706836, valid loss: 2074708.375000
epoch: 1830, train precision: 0.999756, train loss: 227.772720, valid precision: 0.709766, valid loss: 1977668.375000
epoch: 1831, train precision: 0.998580, train loss: 1465.934448, valid precision: 0.706641, valid loss: 2061211.000000
epoch: 1832, train precision: 0.999268, train loss: 977.543152, valid precision: 0.707227, valid loss: 1997143.250000
epoch: 1833, train precision: 0.999734, train loss: 356.243530, valid precision: 0.715625, valid loss: 1904335.250000
epoch: 1834, train precision: 0.999667, train loss: 323.557892, valid precision: 0.709766, valid loss: 1943708.750000
epoch: 1835, train precision: 0.999734, train loss: 312.166870, valid precision: 0.706836, valid loss: 1993717.750000
epoch: 1836, train precision: 0.999600, train loss: 319.185303, valid precision: 0.706055, valid loss: 2074430.375000
epoch: 1837, train precision: 0.998890, train loss: 1079.827759, valid precision: 0.702930, valid loss: 1979723.625000
epoch: 1838, train precision: 0.999667, train loss: 184.926788, valid precision: 0.706641, valid loss: 2025406.375000
epoch: 1839, train precision: 0.999334, train loss: 777.707825, valid precision: 0.708789, valid loss: 2082271.250000
epoch: 1840, train precision: 0.999556, train loss: 696.149902, valid precision: 0.703711, valid loss: 2064525.250000
epoch: 1841, train precision: 0.999667, train loss: 293.440735, valid precision: 0.710742, valid loss: 1998268.000000
epoch: 1842, train precision: 0.999711, train loss: 301.136200, valid precision: 0.709961, valid loss: 1986817.250000
epoch: 1843, train precision: 0.999645, train loss: 297.036469, valid precision: 0.712891, valid loss: 2020398.375000
epoch: 1844, train precision: 0.999423, train loss: 587.443359, valid precision: 0.704883, valid loss: 1965452.000000
epoch: 1845, train precision: 0.999512, train loss: 472.621094, valid precision: 0.715430, valid loss: 1956000.625000
epoch: 1846, train precision: 0.999800, train loss: 232.225357, valid precision: 0.712891, valid loss: 1956488.000000
epoch: 1847, train precision: 0.999711, train loss: 349.154755, valid precision: 0.717969, valid loss: 2029364.000000
epoch: 1848, train precision: 0.999112, train loss: 1044.810913, valid precision: 0.701953, valid loss: 2103458.250000
epoch: 1849, train precision: 0.999401, train loss: 847.678467, valid precision: 0.708594, valid loss: 2081400.750000
epoch: 1850, train precision: 0.999822, train loss: 157.109360, valid precision: 0.711328, valid loss: 2055824.250000
epoch: 1851, train precision: 0.999534, train loss: 420.419464, valid precision: 0.712695, valid loss: 1974066.250000
epoch: 1852, train precision: 0.998890, train loss: 1562.299683, valid precision: 0.713672, valid loss: 2078029.625000
epoch: 1853, train precision: 0.999600, train loss: 348.653992, valid precision: 0.708984, valid loss: 2040805.750000
epoch: 1854, train precision: 0.999800, train loss: 157.095459, valid precision: 0.712695, valid loss: 2055607.625000
epoch: 1855, train precision: 0.999401, train loss: 648.116211, valid precision: 0.712500, valid loss: 1994010.000000
epoch: 1856, train precision: 0.999179, train loss: 1121.602051, valid precision: 0.703906, valid loss: 2109725.500000
epoch: 1857, train precision: 0.999645, train loss: 477.901398, valid precision: 0.707617, valid loss: 2063086.375000
epoch: 1858, train precision: 0.999623, train loss: 443.599609, valid precision: 0.702734, valid loss: 2017488.375000
epoch: 1859, train precision: 0.999645, train loss: 172.099838, valid precision: 0.705078, valid loss: 2020193.625000
epoch: 1860, train precision: 0.999889, train loss: 46.519871, valid precision: 0.707812, valid loss: 2045492.750000
epoch: 1861, train precision: 0.999867, train loss: 122.780983, valid precision: 0.708203, valid loss: 2039166.375000
epoch: 1862, train precision: 0.999667, train loss: 383.705566, valid precision: 0.704297, valid loss: 2001712.000000
epoch: 1863, train precision: 0.999334, train loss: 744.014099, valid precision: 0.711133, valid loss: 2067755.750000
epoch: 1864, train precision: 0.999734, train loss: 292.965973, valid precision: 0.711328, valid loss: 2026896.000000
epoch: 1865, train precision: 0.999534, train loss: 479.568359, valid precision: 0.707812, valid loss: 2038358.000000
epoch: 1866, train precision: 0.999623, train loss: 507.281433, valid precision: 0.702930, valid loss: 2055502.000000
epoch: 1867, train precision: 0.999157, train loss: 934.741272, valid precision: 0.703320, valid loss: 2098664.750000
epoch: 1868, train precision: 0.999179, train loss: 1082.019775, valid precision: 0.706836, valid loss: 2157365.000000
epoch: 1869, train precision: 0.999223, train loss: 962.037109, valid precision: 0.705664, valid loss: 2213227.250000
epoch: 1870, train precision: 0.999201, train loss: 929.523621, valid precision: 0.702539, valid loss: 2256317.500000
epoch: 1871, train precision: 0.999711, train loss: 250.809036, valid precision: 0.712695, valid loss: 2232373.750000
epoch: 1872, train precision: 0.999578, train loss: 480.917664, valid precision: 0.709961, valid loss: 2141836.750000
epoch: 1873, train precision: 0.999867, train loss: 40.383392, valid precision: 0.711523, valid loss: 2156335.750000
epoch: 1874, train precision: 0.998979, train loss: 1058.101196, valid precision: 0.698828, valid loss: 2224098.000000
epoch: 1875, train precision: 0.999822, train loss: 252.874527, valid precision: 0.716797, valid loss: 2186611.250000
epoch: 1876, train precision: 0.999734, train loss: 260.863037, valid precision: 0.708789, valid loss: 2160715.500000
epoch: 1877, train precision: 0.999312, train loss: 580.685791, valid precision: 0.707812, valid loss: 2154182.000000
epoch: 1878, train precision: 0.999689, train loss: 245.604309, valid precision: 0.718555, valid loss: 2191854.500000
epoch: 1879, train precision: 0.999667, train loss: 344.206085, valid precision: 0.705469, valid loss: 2123826.500000
epoch: 1880, train precision: 0.999512, train loss: 727.933533, valid precision: 0.708984, valid loss: 2182610.500000
epoch: 1881, train precision: 0.999734, train loss: 388.136108, valid precision: 0.712695, valid loss: 2157782.000000
epoch: 1882, train precision: 0.998890, train loss: 1545.200684, valid precision: 0.705078, valid loss: 2108003.500000
epoch: 1883, train precision: 0.999645, train loss: 307.860718, valid precision: 0.706445, valid loss: 2228626.500000
epoch: 1884, train precision: 0.999689, train loss: 320.849335, valid precision: 0.707617, valid loss: 2206818.500000
epoch: 1885, train precision: 0.999778, train loss: 88.531693, valid precision: 0.712305, valid loss: 2165544.750000
epoch: 1886, train precision: 0.999933, train loss: 37.647404, valid precision: 0.708398, valid loss: 2173516.500000
epoch: 1887, train precision: 0.999956, train loss: 27.613214, valid precision: 0.706641, valid loss: 2241533.250000
epoch: 1888, train precision: 0.999401, train loss: 594.369141, valid precision: 0.712305, valid loss: 2323909.500000
epoch: 1889, train precision: 0.999822, train loss: 251.139160, valid precision: 0.700586, valid loss: 2217665.250000
epoch: 1890, train precision: 0.999867, train loss: 74.191010, valid precision: 0.705469, valid loss: 2241497.250000
epoch: 1891, train precision: 0.999245, train loss: 913.394897, valid precision: 0.700391, valid loss: 2324193.500000
epoch: 1892, train precision: 0.998491, train loss: 1633.848389, valid precision: 0.697461, valid loss: 2335841.250000
epoch: 1893, train precision: 0.999734, train loss: 151.992081, valid precision: 0.703711, valid loss: 2288211.750000
epoch: 1894, train precision: 0.999734, train loss: 230.683487, valid precision: 0.702930, valid loss: 2333014.750000
epoch: 1895, train precision: 0.999556, train loss: 640.684937, valid precision: 0.704687, valid loss: 2372746.500000
epoch: 1896, train precision: 0.999756, train loss: 297.833038, valid precision: 0.706445, valid loss: 2304012.500000
epoch: 1897, train precision: 0.999245, train loss: 807.788879, valid precision: 0.703125, valid loss: 2343694.750000
epoch: 1898, train precision: 0.999778, train loss: 211.255310, valid precision: 0.705664, valid loss: 2253090.500000
epoch: 1899, train precision: 0.999623, train loss: 367.387817, valid precision: 0.713086, valid loss: 2252042.750000
epoch: 1900, train precision: 0.999556, train loss: 556.522644, valid precision: 0.703125, valid loss: 2268328.000000
epoch: 1901, train precision: 0.998824, train loss: 1470.840820, valid precision: 0.705078, valid loss: 2280549.500000
epoch: 1902, train precision: 0.999711, train loss: 443.739349, valid precision: 0.704297, valid loss: 2178806.500000
epoch: 1903, train precision: 0.999534, train loss: 643.473999, valid precision: 0.707031, valid loss: 2172107.250000
epoch: 1904, train precision: 0.999201, train loss: 735.265564, valid precision: 0.703906, valid loss: 2244384.000000
epoch: 1905, train precision: 0.999512, train loss: 586.738220, valid precision: 0.713672, valid loss: 2250062.000000
epoch: 1906, train precision: 0.999556, train loss: 375.334076, valid precision: 0.704492, valid loss: 2258345.000000
epoch: 1907, train precision: 0.999645, train loss: 289.571411, valid precision: 0.702930, valid loss: 2256693.500000
epoch: 1908, train precision: 0.999445, train loss: 604.310486, valid precision: 0.706445, valid loss: 2305845.250000
epoch: 1909, train precision: 0.999356, train loss: 984.504883, valid precision: 0.709570, valid loss: 2321430.500000
epoch: 1910, train precision: 0.999689, train loss: 572.774475, valid precision: 0.700586, valid loss: 2308817.750000
epoch: 1911, train precision: 0.999068, train loss: 1177.753784, valid precision: 0.706250, valid loss: 2361622.500000
epoch: 1912, train precision: 0.999822, train loss: 107.094063, valid precision: 0.712109, valid loss: 2278906.250000
epoch: 1913, train precision: 0.999512, train loss: 858.963257, valid precision: 0.702344, valid loss: 2395404.000000
epoch: 1914, train precision: 0.999822, train loss: 69.407249, valid precision: 0.707617, valid loss: 2348359.500000
epoch: 1915, train precision: 0.999667, train loss: 306.641022, valid precision: 0.705859, valid loss: 2326540.500000
epoch: 1916, train precision: 0.999800, train loss: 283.609375, valid precision: 0.709180, valid loss: 2258208.250000
epoch: 1917, train precision: 0.999379, train loss: 700.790222, valid precision: 0.700195, valid loss: 2250126.000000
epoch: 1918, train precision: 0.999711, train loss: 341.940613, valid precision: 0.705859, valid loss: 2332599.000000
epoch: 1919, train precision: 0.999911, train loss: 105.049774, valid precision: 0.706250, valid loss: 2261535.500000
epoch: 1920, train precision: 0.999734, train loss: 407.237915, valid precision: 0.701563, valid loss: 2284942.750000
epoch: 1921, train precision: 0.999800, train loss: 107.439140, valid precision: 0.702344, valid loss: 2337550.000000
epoch: 1922, train precision: 0.999379, train loss: 772.757996, valid precision: 0.699805, valid loss: 2301499.000000
epoch: 1923, train precision: 0.999778, train loss: 292.355652, valid precision: 0.709961, valid loss: 2315516.500000
epoch: 1924, train precision: 0.999734, train loss: 286.350311, valid precision: 0.707812, valid loss: 2333433.500000
epoch: 1925, train precision: 0.999845, train loss: 205.456696, valid precision: 0.708203, valid loss: 2215214.500000
epoch: 1926, train precision: 0.999445, train loss: 580.284424, valid precision: 0.710547, valid loss: 2268890.000000
epoch: 1927, train precision: 0.999512, train loss: 521.146729, valid precision: 0.708398, valid loss: 2303552.000000
epoch: 1928, train precision: 0.999800, train loss: 201.600632, valid precision: 0.711133, valid loss: 2190589.250000
epoch: 1929, train precision: 0.999667, train loss: 503.238403, valid precision: 0.707227, valid loss: 2234571.500000
epoch: 1930, train precision: 0.999467, train loss: 433.468567, valid precision: 0.703320, valid loss: 2286216.500000
epoch: 1931, train precision: 0.999800, train loss: 256.647797, valid precision: 0.705664, valid loss: 2261266.750000
epoch: 1932, train precision: 0.999933, train loss: 26.845802, valid precision: 0.711914, valid loss: 2272074.500000
epoch: 1933, train precision: 0.999689, train loss: 299.583984, valid precision: 0.713867, valid loss: 2235774.750000
epoch: 1934, train precision: 0.999600, train loss: 395.967163, valid precision: 0.705078, valid loss: 2267205.250000
epoch: 1935, train precision: 0.999623, train loss: 377.821259, valid precision: 0.702734, valid loss: 2295876.000000
epoch: 1936, train precision: 0.999778, train loss: 137.475357, valid precision: 0.704492, valid loss: 2328140.750000
epoch: 1937, train precision: 0.999467, train loss: 622.423584, valid precision: 0.697266, valid loss: 2401311.500000
epoch: 1938, train precision: 0.999578, train loss: 516.482971, valid precision: 0.705469, valid loss: 2310528.000000
epoch: 1939, train precision: 0.999379, train loss: 672.577148, valid precision: 0.712305, valid loss: 2328734.000000
epoch: 1940, train precision: 0.999334, train loss: 650.544434, valid precision: 0.702344, valid loss: 2416944.500000
epoch: 1941, train precision: 0.999600, train loss: 715.074097, valid precision: 0.704297, valid loss: 2376160.500000
epoch: 1942, train precision: 0.999623, train loss: 547.689880, valid precision: 0.708203, valid loss: 2366352.750000
epoch: 1943, train precision: 0.999889, train loss: 63.454269, valid precision: 0.710547, valid loss: 2342467.750000
epoch: 1944, train precision: 0.999778, train loss: 158.887924, valid precision: 0.707617, valid loss: 2391388.250000
epoch: 1945, train precision: 0.999556, train loss: 344.153748, valid precision: 0.704297, valid loss: 2289670.500000
epoch: 1946, train precision: 0.999001, train loss: 1186.333374, valid precision: 0.706250, valid loss: 2392184.500000
epoch: 1947, train precision: 0.999467, train loss: 1310.396240, valid precision: 0.705273, valid loss: 2431339.500000
epoch: 1948, train precision: 0.999645, train loss: 369.650208, valid precision: 0.709375, valid loss: 2430670.500000
epoch: 1949, train precision: 0.999734, train loss: 309.670319, valid precision: 0.709375, valid loss: 2449497.500000
epoch: 1950, train precision: 0.998291, train loss: 3270.964111, valid precision: 0.704883, valid loss: 2597075.750000
epoch: 1951, train precision: 0.998557, train loss: 2315.207275, valid precision: 0.699805, valid loss: 2534198.750000
epoch: 1952, train precision: 0.999689, train loss: 221.489212, valid precision: 0.711133, valid loss: 2486644.750000
epoch: 1953, train precision: 0.999822, train loss: 78.963776, valid precision: 0.708789, valid loss: 2486789.250000
epoch: 1954, train precision: 0.999956, train loss: 10.797519, valid precision: 0.709766, valid loss: 2466786.000000
epoch: 1955, train precision: 0.999623, train loss: 500.751953, valid precision: 0.698438, valid loss: 2487463.250000
epoch: 1956, train precision: 0.999023, train loss: 1580.548462, valid precision: 0.705078, valid loss: 2533851.000000
epoch: 1957, train precision: 0.999623, train loss: 652.018250, valid precision: 0.701367, valid loss: 2520160.250000
epoch: 1958, train precision: 0.999734, train loss: 196.303482, valid precision: 0.708984, valid loss: 2454660.500000
epoch: 1959, train precision: 0.999800, train loss: 93.860886, valid precision: 0.709180, valid loss: 2435039.250000
epoch: 1960, train precision: 0.999623, train loss: 511.826172, valid precision: 0.711328, valid loss: 2547335.500000
epoch: 1961, train precision: 0.999445, train loss: 1114.901611, valid precision: 0.708398, valid loss: 2561164.500000
epoch: 1962, train precision: 0.998513, train loss: 2409.792969, valid precision: 0.694531, valid loss: 2490796.000000
epoch: 1963, train precision: 0.999445, train loss: 544.957581, valid precision: 0.709570, valid loss: 2408638.750000
epoch: 1964, train precision: 0.999667, train loss: 394.513550, valid precision: 0.707812, valid loss: 2530537.500000
epoch: 1965, train precision: 0.999556, train loss: 307.483765, valid precision: 0.714258, valid loss: 2462927.500000
epoch: 1966, train precision: 0.999778, train loss: 212.346436, valid precision: 0.706055, valid loss: 2479912.750000
epoch: 1967, train precision: 0.999445, train loss: 843.218384, valid precision: 0.708203, valid loss: 2493836.000000
epoch: 1968, train precision: 0.999756, train loss: 217.372330, valid precision: 0.711328, valid loss: 2417346.500000
epoch: 1969, train precision: 0.999112, train loss: 1130.843628, valid precision: 0.708984, valid loss: 2471598.250000
epoch: 1970, train precision: 0.998624, train loss: 2300.371826, valid precision: 0.699414, valid loss: 2585126.750000
epoch: 1971, train precision: 0.999778, train loss: 139.832748, valid precision: 0.708984, valid loss: 2494960.750000
epoch: 1972, train precision: 0.999978, train loss: 17.897505, valid precision: 0.709375, valid loss: 2404970.000000
epoch: 1973, train precision: 0.999867, train loss: 118.414948, valid precision: 0.712109, valid loss: 2414002.000000
epoch: 1974, train precision: 0.999711, train loss: 344.602997, valid precision: 0.703320, valid loss: 2460545.250000
epoch: 1975, train precision: 0.999423, train loss: 1475.708130, valid precision: 0.699023, valid loss: 2497250.000000
epoch: 1976, train precision: 0.999756, train loss: 289.901550, valid precision: 0.712305, valid loss: 2476226.000000
epoch: 1977, train precision: 0.999223, train loss: 1256.486328, valid precision: 0.716797, valid loss: 2467434.250000
epoch: 1978, train precision: 0.999356, train loss: 770.862488, valid precision: 0.708008, valid loss: 2528354.750000
epoch: 1979, train precision: 0.999445, train loss: 482.062134, valid precision: 0.708203, valid loss: 2518297.500000
epoch: 1980, train precision: 0.999312, train loss: 1106.200684, valid precision: 0.708594, valid loss: 2575305.500000
epoch: 1981, train precision: 0.999734, train loss: 309.525452, valid precision: 0.713086, valid loss: 2543509.000000
epoch: 1982, train precision: 0.999756, train loss: 234.552872, valid precision: 0.714453, valid loss: 2527516.000000
epoch: 1983, train precision: 0.999157, train loss: 920.761108, valid precision: 0.708203, valid loss: 2481315.500000
epoch: 1984, train precision: 0.999112, train loss: 1538.918335, valid precision: 0.704492, valid loss: 2571653.750000
epoch: 1985, train precision: 0.999689, train loss: 363.061371, valid precision: 0.703906, valid loss: 2527227.500000
epoch: 1986, train precision: 0.999356, train loss: 1190.458496, valid precision: 0.702930, valid loss: 2529136.000000
epoch: 1987, train precision: 0.999046, train loss: 1397.681274, valid precision: 0.703125, valid loss: 2524667.500000
epoch: 1988, train precision: 0.999711, train loss: 312.406281, valid precision: 0.713867, valid loss: 2428854.500000
epoch: 1989, train precision: 0.999512, train loss: 606.393738, valid precision: 0.708398, valid loss: 2558810.000000
epoch: 1990, train precision: 0.999734, train loss: 279.608368, valid precision: 0.706641, valid loss: 2516111.250000
epoch: 1991, train precision: 0.999512, train loss: 454.180389, valid precision: 0.706250, valid loss: 2509303.250000
epoch: 1992, train precision: 0.999556, train loss: 526.810486, valid precision: 0.710156, valid loss: 2610196.500000
epoch: 1993, train precision: 0.999534, train loss: 491.145782, valid precision: 0.706445, valid loss: 2554646.500000
epoch: 1994, train precision: 0.999756, train loss: 177.025467, valid precision: 0.711914, valid loss: 2530335.500000
epoch: 1995, train precision: 0.999578, train loss: 562.261536, valid precision: 0.712695, valid loss: 2616713.250000
epoch: 1996, train precision: 0.999179, train loss: 1014.751892, valid precision: 0.700781, valid loss: 2651969.500000
epoch: 1997, train precision: 0.999623, train loss: 524.256409, valid precision: 0.709570, valid loss: 2529226.000000
epoch: 1998, train precision: 0.999711, train loss: 415.009491, valid precision: 0.710547, valid loss: 2502645.500000
epoch: 1999, train precision: 0.999889, train loss: 87.905373, valid precision: 0.714258, valid loss: 2496696.500000
epoch: 2000, train precision: 0.999756, train loss: 195.312317, valid precision: 0.706055, valid loss: 2449360.750000
epoch: 2001, train precision: 0.999645, train loss: 367.047638, valid precision: 0.711719, valid loss: 2502063.250000
epoch: 2002, train precision: 0.999179, train loss: 1074.324829, valid precision: 0.710352, valid loss: 2659267.500000
epoch: 2003, train precision: 0.999600, train loss: 621.691895, valid precision: 0.710352, valid loss: 2660496.500000
epoch: 2004, train precision: 0.999578, train loss: 528.224487, valid precision: 0.703320, valid loss: 2546670.000000
epoch: 2005, train precision: 0.999334, train loss: 888.963928, valid precision: 0.708008, valid loss: 2542429.750000
epoch: 2006, train precision: 0.999445, train loss: 794.783997, valid precision: 0.704297, valid loss: 2619123.750000
epoch: 2007, train precision: 0.998979, train loss: 1408.140259, valid precision: 0.695703, valid loss: 2555833.500000
epoch: 2008, train precision: 0.999734, train loss: 347.414185, valid precision: 0.709375, valid loss: 2563668.000000
epoch: 2009, train precision: 0.999312, train loss: 684.413147, valid precision: 0.687891, valid loss: 2510407.500000
epoch: 2010, train precision: 0.999268, train loss: 690.909058, valid precision: 0.706250, valid loss: 2488937.250000
epoch: 2011, train precision: 0.999734, train loss: 191.840271, valid precision: 0.701953, valid loss: 2553826.000000
epoch: 2012, train precision: 0.999556, train loss: 485.976105, valid precision: 0.698828, valid loss: 2602372.000000
epoch: 2013, train precision: 0.999534, train loss: 438.781921, valid precision: 0.702148, valid loss: 2570542.500000
epoch: 2014, train precision: 0.999090, train loss: 1491.134277, valid precision: 0.705664, valid loss: 2594528.250000
epoch: 2015, train precision: 0.999046, train loss: 1772.459717, valid precision: 0.707422, valid loss: 2602864.000000
epoch: 2016, train precision: 0.999756, train loss: 145.765396, valid precision: 0.709180, valid loss: 2541915.500000
epoch: 2017, train precision: 0.999756, train loss: 242.741394, valid precision: 0.712891, valid loss: 2574635.000000
epoch: 2018, train precision: 0.999778, train loss: 179.253510, valid precision: 0.708008, valid loss: 2583899.500000
epoch: 2019, train precision: 0.999711, train loss: 335.190796, valid precision: 0.708398, valid loss: 2594916.500000
epoch: 2020, train precision: 0.999756, train loss: 329.357971, valid precision: 0.700000, valid loss: 2620558.500000
epoch: 2021, train precision: 0.999689, train loss: 300.964569, valid precision: 0.706250, valid loss: 2628294.000000
epoch: 2022, train precision: 0.999379, train loss: 815.337463, valid precision: 0.705859, valid loss: 2580993.500000
epoch: 2023, train precision: 0.999689, train loss: 278.605408, valid precision: 0.698047, valid loss: 2606872.000000
epoch: 2024, train precision: 0.999756, train loss: 318.785614, valid precision: 0.707031, valid loss: 2552263.250000
epoch: 2025, train precision: 0.999933, train loss: 86.162010, valid precision: 0.708984, valid loss: 2622387.500000
epoch: 2026, train precision: 0.998535, train loss: 2393.663086, valid precision: 0.709375, valid loss: 2668690.000000
epoch: 2027, train precision: 0.999467, train loss: 594.237488, valid precision: 0.702344, valid loss: 2730867.750000
epoch: 2028, train precision: 0.999467, train loss: 630.942017, valid precision: 0.699219, valid loss: 2660133.500000
epoch: 2029, train precision: 0.999112, train loss: 1368.612793, valid precision: 0.705078, valid loss: 2605204.500000
epoch: 2030, train precision: 0.999068, train loss: 1183.898926, valid precision: 0.711133, valid loss: 2596654.750000
epoch: 2031, train precision: 0.999223, train loss: 920.977783, valid precision: 0.703320, valid loss: 2653704.500000
epoch: 2032, train precision: 0.999711, train loss: 308.318085, valid precision: 0.706250, valid loss: 2556375.750000
epoch: 2033, train precision: 0.999756, train loss: 300.864807, valid precision: 0.706836, valid loss: 2588511.000000
epoch: 2034, train precision: 0.999911, train loss: 83.138718, valid precision: 0.713086, valid loss: 2661056.000000
epoch: 2035, train precision: 0.999467, train loss: 819.982056, valid precision: 0.709961, valid loss: 2779420.750000
epoch: 2036, train precision: 0.999689, train loss: 313.053162, valid precision: 0.707031, valid loss: 2664905.250000
epoch: 2037, train precision: 0.999623, train loss: 772.803528, valid precision: 0.703711, valid loss: 2698989.250000
epoch: 2038, train precision: 0.999423, train loss: 1142.572388, valid precision: 0.698633, valid loss: 2767876.500000
epoch: 2039, train precision: 0.999845, train loss: 131.031342, valid precision: 0.697266, valid loss: 2662759.750000
epoch: 2040, train precision: 0.999623, train loss: 459.906342, valid precision: 0.709961, valid loss: 2614787.500000
epoch: 2041, train precision: 0.999845, train loss: 118.289032, valid precision: 0.712891, valid loss: 2614283.500000
epoch: 2042, train precision: 0.999445, train loss: 799.304932, valid precision: 0.701172, valid loss: 2647641.750000
epoch: 2043, train precision: 0.999734, train loss: 403.115540, valid precision: 0.712500, valid loss: 2744033.500000
epoch: 2044, train precision: 0.999645, train loss: 556.332458, valid precision: 0.700781, valid loss: 2607489.250000
epoch: 2045, train precision: 0.999512, train loss: 477.854492, valid precision: 0.708789, valid loss: 2623780.500000
epoch: 2046, train precision: 0.999911, train loss: 239.369049, valid precision: 0.705273, valid loss: 2642590.750000
epoch: 2047, train precision: 0.999512, train loss: 911.301392, valid precision: 0.706445, valid loss: 2679476.000000
epoch: 2048, train precision: 0.999268, train loss: 836.900146, valid precision: 0.705273, valid loss: 2665655.000000
epoch: 2049, train precision: 0.998735, train loss: 1843.744263, valid precision: 0.702148, valid loss: 2696891.250000
epoch: 2050, train precision: 0.999711, train loss: 189.143997, valid precision: 0.709180, valid loss: 2626550.250000
epoch: 2051, train precision: 0.999112, train loss: 1189.960938, valid precision: 0.711133, valid loss: 2634115.250000
epoch: 2052, train precision: 0.999756, train loss: 276.026367, valid precision: 0.713672, valid loss: 2719084.750000
epoch: 2053, train precision: 0.999600, train loss: 606.899841, valid precision: 0.707227, valid loss: 2657148.500000
epoch: 2054, train precision: 0.998358, train loss: 3198.534180, valid precision: 0.706250, valid loss: 2873890.750000
epoch: 2055, train precision: 0.999711, train loss: 434.664429, valid precision: 0.710938, valid loss: 2779220.750000
epoch: 2056, train precision: 0.999822, train loss: 327.357910, valid precision: 0.701953, valid loss: 2779148.750000
epoch: 2057, train precision: 0.999734, train loss: 263.952271, valid precision: 0.709180, valid loss: 2793976.750000
epoch: 2058, train precision: 0.999467, train loss: 554.390015, valid precision: 0.707617, valid loss: 2724886.750000
epoch: 2059, train precision: 0.999534, train loss: 659.433289, valid precision: 0.710742, valid loss: 2704770.500000
epoch: 2060, train precision: 0.999778, train loss: 347.691467, valid precision: 0.706055, valid loss: 2828048.500000
epoch: 2061, train precision: 0.999933, train loss: 192.453613, valid precision: 0.705859, valid loss: 2847488.000000
epoch: 2062, train precision: 0.999623, train loss: 468.686035, valid precision: 0.712109, valid loss: 2865979.500000
epoch: 2063, train precision: 0.999756, train loss: 156.387466, valid precision: 0.699609, valid loss: 2755162.000000
epoch: 2064, train precision: 0.999867, train loss: 98.384277, valid precision: 0.703320, valid loss: 2755374.750000
epoch: 2065, train precision: 0.999711, train loss: 333.510773, valid precision: 0.704687, valid loss: 2761693.500000
epoch: 2066, train precision: 0.999600, train loss: 367.041779, valid precision: 0.695898, valid loss: 2710024.000000
epoch: 2067, train precision: 0.999689, train loss: 458.881165, valid precision: 0.706055, valid loss: 2699001.000000
epoch: 2068, train precision: 0.999756, train loss: 327.713501, valid precision: 0.704492, valid loss: 2679064.000000
epoch: 2069, train precision: 0.999800, train loss: 341.837372, valid precision: 0.704297, valid loss: 2700900.750000
epoch: 2070, train precision: 0.999756, train loss: 224.953964, valid precision: 0.697461, valid loss: 2693247.500000
epoch: 2071, train precision: 0.999756, train loss: 502.542694, valid precision: 0.703516, valid loss: 2722307.500000
epoch: 2072, train precision: 0.998935, train loss: 2311.611084, valid precision: 0.688867, valid loss: 2876104.500000
epoch: 2073, train precision: 0.999334, train loss: 1127.362061, valid precision: 0.702930, valid loss: 2803197.500000
epoch: 2074, train precision: 0.999778, train loss: 268.185791, valid precision: 0.707422, valid loss: 2708519.500000
epoch: 2075, train precision: 0.999800, train loss: 90.764862, valid precision: 0.709961, valid loss: 2680724.250000
epoch: 2076, train precision: 0.999822, train loss: 173.917862, valid precision: 0.703125, valid loss: 2726209.000000
epoch: 2077, train precision: 0.999711, train loss: 433.347565, valid precision: 0.703711, valid loss: 2746787.500000
epoch: 2078, train precision: 0.999711, train loss: 333.427673, valid precision: 0.704102, valid loss: 2756489.000000
epoch: 2079, train precision: 0.998446, train loss: 3226.454590, valid precision: 0.699219, valid loss: 3049830.000000
epoch: 2080, train precision: 0.999290, train loss: 1640.044434, valid precision: 0.701758, valid loss: 3020606.500000
epoch: 2081, train precision: 0.999822, train loss: 214.759964, valid precision: 0.706641, valid loss: 3037404.250000
epoch: 2082, train precision: 0.999800, train loss: 367.577637, valid precision: 0.711133, valid loss: 2927771.500000
epoch: 2083, train precision: 0.999778, train loss: 264.761536, valid precision: 0.706250, valid loss: 2875611.500000
epoch: 2084, train precision: 0.999600, train loss: 377.506134, valid precision: 0.706055, valid loss: 2954600.000000
epoch: 2085, train precision: 0.999734, train loss: 436.676727, valid precision: 0.708789, valid loss: 2972290.750000
epoch: 2086, train precision: 0.999800, train loss: 280.134430, valid precision: 0.711133, valid loss: 2894020.750000
epoch: 2087, train precision: 0.998957, train loss: 1497.755371, valid precision: 0.707812, valid loss: 2953461.500000
epoch: 2088, train precision: 0.999845, train loss: 209.945267, valid precision: 0.711719, valid loss: 2937434.750000
epoch: 2089, train precision: 0.999778, train loss: 185.604309, valid precision: 0.711719, valid loss: 2866849.250000
epoch: 2090, train precision: 0.999756, train loss: 247.273285, valid precision: 0.711719, valid loss: 2920737.250000
epoch: 2091, train precision: 0.997714, train loss: 3913.925781, valid precision: 0.698633, valid loss: 2993245.500000
epoch: 2092, train precision: 0.998646, train loss: 2894.435791, valid precision: 0.703711, valid loss: 3027605.750000
epoch: 2093, train precision: 0.999623, train loss: 532.431213, valid precision: 0.712109, valid loss: 3046559.750000
epoch: 2094, train precision: 0.999822, train loss: 219.246140, valid precision: 0.711719, valid loss: 3088157.500000
epoch: 2095, train precision: 0.999867, train loss: 49.085892, valid precision: 0.710547, valid loss: 3044708.000000
epoch: 2096, train precision: 0.999822, train loss: 209.881927, valid precision: 0.713477, valid loss: 3104971.500000
epoch: 2097, train precision: 0.999756, train loss: 425.504211, valid precision: 0.709180, valid loss: 3061798.000000
epoch: 2098, train precision: 0.999312, train loss: 1164.234497, valid precision: 0.705273, valid loss: 2945181.500000
epoch: 2099, train precision: 0.999845, train loss: 236.209579, valid precision: 0.704883, valid loss: 2937772.500000
epoch: 2100, train precision: 0.999822, train loss: 280.151489, valid precision: 0.706641, valid loss: 2972778.500000
epoch: 2101, train precision: 0.999667, train loss: 432.213104, valid precision: 0.705469, valid loss: 3051628.750000
epoch: 2102, train precision: 0.999867, train loss: 196.384506, valid precision: 0.703906, valid loss: 2926007.500000
epoch: 2103, train precision: 0.999933, train loss: 58.672909, valid precision: 0.709375, valid loss: 2963953.250000
epoch: 2104, train precision: 0.999245, train loss: 1770.501465, valid precision: 0.697852, valid loss: 3093900.250000
epoch: 2105, train precision: 0.999623, train loss: 519.234619, valid precision: 0.694922, valid loss: 2971974.000000
epoch: 2106, train precision: 0.999512, train loss: 948.721252, valid precision: 0.699609, valid loss: 3089841.250000
epoch: 2107, train precision: 0.999179, train loss: 1222.340332, valid precision: 0.700391, valid loss: 3001061.500000
epoch: 2108, train precision: 0.999534, train loss: 749.226624, valid precision: 0.696289, valid loss: 2992133.000000
epoch: 2109, train precision: 0.999756, train loss: 429.311920, valid precision: 0.702734, valid loss: 3032078.500000
epoch: 2110, train precision: 0.999889, train loss: 162.772644, valid precision: 0.704883, valid loss: 3065338.750000
epoch: 2111, train precision: 0.999911, train loss: 161.743637, valid precision: 0.703125, valid loss: 3046583.750000
epoch: 2112, train precision: 0.999956, train loss: 64.064232, valid precision: 0.703320, valid loss: 3028221.250000
epoch: 2113, train precision: 0.999800, train loss: 287.796844, valid precision: 0.700195, valid loss: 2980019.500000
epoch: 2114, train precision: 0.998735, train loss: 2019.745728, valid precision: 0.691016, valid loss: 3109576.750000
epoch: 2115, train precision: 0.999023, train loss: 1572.948853, valid precision: 0.698242, valid loss: 3064551.500000
epoch: 2116, train precision: 0.999600, train loss: 716.732666, valid precision: 0.704687, valid loss: 3052076.500000
epoch: 2117, train precision: 0.999845, train loss: 95.698441, valid precision: 0.709961, valid loss: 2909776.500000
epoch: 2118, train precision: 0.999689, train loss: 331.170166, valid precision: 0.708203, valid loss: 2919463.500000
epoch: 2119, train precision: 0.999645, train loss: 555.219727, valid precision: 0.703906, valid loss: 3055924.500000
epoch: 2120, train precision: 0.999889, train loss: 128.615494, valid precision: 0.710352, valid loss: 3002381.750000
epoch: 2121, train precision: 0.998580, train loss: 2715.702881, valid precision: 0.700391, valid loss: 3092184.750000
epoch: 2122, train precision: 0.999290, train loss: 1506.122925, valid precision: 0.699805, valid loss: 3204441.000000
epoch: 2123, train precision: 0.999623, train loss: 714.766418, valid precision: 0.707617, valid loss: 3095516.500000
epoch: 2124, train precision: 0.998890, train loss: 1635.690552, valid precision: 0.702930, valid loss: 3096269.750000
epoch: 2125, train precision: 0.999645, train loss: 521.704163, valid precision: 0.709375, valid loss: 3103954.500000
epoch: 2126, train precision: 0.999778, train loss: 131.969833, valid precision: 0.709375, valid loss: 3099198.500000
epoch: 2127, train precision: 0.999600, train loss: 577.940430, valid precision: 0.713086, valid loss: 3032408.500000
epoch: 2128, train precision: 0.999290, train loss: 1369.453369, valid precision: 0.704492, valid loss: 3132432.250000
epoch: 2129, train precision: 0.999778, train loss: 235.552597, valid precision: 0.711719, valid loss: 3131874.250000
epoch: 2130, train precision: 0.999645, train loss: 416.456024, valid precision: 0.704492, valid loss: 3098991.500000
epoch: 2131, train precision: 0.999978, train loss: 16.536476, valid precision: 0.712500, valid loss: 3026492.000000
epoch: 2132, train precision: 0.999911, train loss: 38.110863, valid precision: 0.710352, valid loss: 3064859.750000
epoch: 2133, train precision: 0.999623, train loss: 273.264496, valid precision: 0.711523, valid loss: 3008394.000000
epoch: 2134, train precision: 0.999800, train loss: 236.839218, valid precision: 0.706250, valid loss: 3026498.000000
epoch: 2135, train precision: 0.999645, train loss: 929.517395, valid precision: 0.705469, valid loss: 3050029.500000
epoch: 2136, train precision: 0.999600, train loss: 623.165039, valid precision: 0.706641, valid loss: 3164379.500000
epoch: 2137, train precision: 0.999778, train loss: 184.579834, valid precision: 0.711719, valid loss: 2982648.250000
epoch: 2138, train precision: 0.999445, train loss: 751.320679, valid precision: 0.709180, valid loss: 3022971.750000
epoch: 2139, train precision: 0.999800, train loss: 301.580292, valid precision: 0.712500, valid loss: 3026034.250000
epoch: 2140, train precision: 0.999490, train loss: 909.299011, valid precision: 0.712891, valid loss: 3102209.250000
epoch: 2141, train precision: 0.999600, train loss: 561.605652, valid precision: 0.706641, valid loss: 3046763.000000
epoch: 2142, train precision: 0.999867, train loss: 56.275536, valid precision: 0.712305, valid loss: 3162876.000000
epoch: 2143, train precision: 0.999845, train loss: 101.927567, valid precision: 0.711914, valid loss: 3056677.500000
epoch: 2144, train precision: 0.999845, train loss: 218.857849, valid precision: 0.705664, valid loss: 3174703.250000
epoch: 2145, train precision: 0.998491, train loss: 2403.489258, valid precision: 0.705664, valid loss: 3147475.500000
epoch: 2146, train precision: 0.999667, train loss: 619.843689, valid precision: 0.710156, valid loss: 3184069.500000
epoch: 2147, train precision: 0.999023, train loss: 1248.578491, valid precision: 0.700000, valid loss: 3222572.500000
epoch: 2148, train precision: 0.999734, train loss: 327.937225, valid precision: 0.707812, valid loss: 3153936.500000
epoch: 2149, train precision: 0.999534, train loss: 691.332397, valid precision: 0.701953, valid loss: 3193618.250000
epoch: 2150, train precision: 0.999623, train loss: 649.627075, valid precision: 0.710938, valid loss: 3169711.750000
epoch: 2151, train precision: 0.999778, train loss: 202.379211, valid precision: 0.711328, valid loss: 3174464.250000
epoch: 2152, train precision: 0.999800, train loss: 235.640472, valid precision: 0.711133, valid loss: 3089545.250000
epoch: 2153, train precision: 0.999201, train loss: 1197.423706, valid precision: 0.712695, valid loss: 3105035.250000
epoch: 2154, train precision: 0.999179, train loss: 2344.832764, valid precision: 0.706641, valid loss: 3176781.500000
epoch: 2155, train precision: 0.999867, train loss: 96.652901, valid precision: 0.712500, valid loss: 3143815.500000
epoch: 2156, train precision: 0.999756, train loss: 298.491211, valid precision: 0.707227, valid loss: 3082671.250000
epoch: 2157, train precision: 0.999046, train loss: 1890.533081, valid precision: 0.710938, valid loss: 3196737.500000
epoch: 2158, train precision: 0.999689, train loss: 668.434570, valid precision: 0.712891, valid loss: 3307906.000000
epoch: 2159, train precision: 0.999600, train loss: 689.784424, valid precision: 0.714258, valid loss: 3260637.500000
epoch: 2160, train precision: 0.999623, train loss: 452.049622, valid precision: 0.706055, valid loss: 3130297.250000
epoch: 2161, train precision: 0.999667, train loss: 688.585754, valid precision: 0.712109, valid loss: 3087048.750000
epoch: 2162, train precision: 0.999490, train loss: 794.674561, valid precision: 0.700977, valid loss: 3222652.000000
epoch: 2163, train precision: 0.999778, train loss: 311.829559, valid precision: 0.707031, valid loss: 3041665.250000
epoch: 2164, train precision: 0.999756, train loss: 227.811340, valid precision: 0.704102, valid loss: 3061187.250000
epoch: 2165, train precision: 0.999556, train loss: 748.064819, valid precision: 0.704102, valid loss: 3146600.000000
epoch: 2166, train precision: 0.999623, train loss: 671.104736, valid precision: 0.711133, valid loss: 3166821.250000
epoch: 2167, train precision: 0.999756, train loss: 490.922760, valid precision: 0.700781, valid loss: 3184937.500000
epoch: 2168, train precision: 0.999734, train loss: 362.162628, valid precision: 0.704492, valid loss: 3254192.750000
epoch: 2169, train precision: 0.999667, train loss: 510.872070, valid precision: 0.706836, valid loss: 3234983.500000
epoch: 2170, train precision: 0.999756, train loss: 359.733398, valid precision: 0.715625, valid loss: 3307116.500000
epoch: 2171, train precision: 0.999756, train loss: 334.659149, valid precision: 0.708203, valid loss: 3264871.250000
epoch: 2172, train precision: 0.999623, train loss: 451.795319, valid precision: 0.709180, valid loss: 3211729.250000
epoch: 2173, train precision: 0.999711, train loss: 523.101990, valid precision: 0.713281, valid loss: 3247332.250000
epoch: 2174, train precision: 0.999711, train loss: 355.457336, valid precision: 0.707422, valid loss: 3373940.750000
epoch: 2175, train precision: 0.999867, train loss: 122.789597, valid precision: 0.715039, valid loss: 3346120.500000
epoch: 2176, train precision: 0.999046, train loss: 1749.225464, valid precision: 0.704687, valid loss: 3329935.000000
epoch: 2177, train precision: 0.999467, train loss: 642.677979, valid precision: 0.709766, valid loss: 3174338.500000
epoch: 2178, train precision: 0.999672, train loss: 759.164429, valid precision: 0.712695, valid loss: 3183256.500000
epoch: 2179, train precision: 0.999689, train loss: 475.155731, valid precision: 0.708594, valid loss: 3178536.250000
epoch: 2180, train precision: 0.999645, train loss: 382.594543, valid precision: 0.704883, valid loss: 3259909.000000
epoch: 2181, train precision: 0.999800, train loss: 247.255554, valid precision: 0.705469, valid loss: 3101881.750000
epoch: 2182, train precision: 0.999401, train loss: 1023.333374, valid precision: 0.703516, valid loss: 3318542.500000
epoch: 2183, train precision: 0.999889, train loss: 85.333076, valid precision: 0.712500, valid loss: 3227423.250000
epoch: 2184, train precision: 0.999179, train loss: 1423.664185, valid precision: 0.699805, valid loss: 3193723.250000
epoch: 2185, train precision: 0.998624, train loss: 2728.949463, valid precision: 0.700781, valid loss: 3278430.500000
epoch: 2186, train precision: 0.999800, train loss: 749.481262, valid precision: 0.709570, valid loss: 3295025.250000
epoch: 2187, train precision: 0.999090, train loss: 1880.799316, valid precision: 0.703906, valid loss: 3270400.500000
epoch: 2188, train precision: 0.999379, train loss: 908.005127, valid precision: 0.708008, valid loss: 3202500.750000
epoch: 2189, train precision: 0.999889, train loss: 113.376732, valid precision: 0.711719, valid loss: 3229597.500000
epoch: 2190, train precision: 0.999734, train loss: 459.037567, valid precision: 0.713086, valid loss: 3261137.750000
epoch: 2191, train precision: 0.999689, train loss: 621.515198, valid precision: 0.719141, valid loss: 3298757.250000
epoch: 2192, train precision: 0.999889, train loss: 196.033188, valid precision: 0.706836, valid loss: 3336344.000000
epoch: 2193, train precision: 0.999711, train loss: 322.227509, valid precision: 0.708594, valid loss: 3308784.000000
epoch: 2194, train precision: 0.999667, train loss: 499.584503, valid precision: 0.708008, valid loss: 3246693.500000
epoch: 2195, train precision: 0.999312, train loss: 1269.719482, valid precision: 0.708203, valid loss: 3352234.500000
epoch: 2196, train precision: 0.999467, train loss: 873.013306, valid precision: 0.710742, valid loss: 3448337.500000
epoch: 2197, train precision: 0.998873, train loss: 2202.508545, valid precision: 0.715625, valid loss: 3392130.750000
epoch: 2198, train precision: 0.999778, train loss: 405.428589, valid precision: 0.709766, valid loss: 3298052.750000
epoch: 2199, train precision: 0.999734, train loss: 289.679230, valid precision: 0.710352, valid loss: 3455273.500000
epoch: 2200, train precision: 0.999467, train loss: 888.565857, valid precision: 0.712695, valid loss: 3468895.250000
epoch: 2201, train precision: 0.999711, train loss: 521.422119, valid precision: 0.715625, valid loss: 3421810.000000
epoch: 2202, train precision: 0.999578, train loss: 444.927734, valid precision: 0.714063, valid loss: 3431698.000000
epoch: 2203, train precision: 0.999312, train loss: 896.700623, valid precision: 0.709570, valid loss: 3391574.750000
epoch: 2204, train precision: 0.999800, train loss: 205.491653, valid precision: 0.716406, valid loss: 3360174.500000
epoch: 2205, train precision: 0.999889, train loss: 135.499207, valid precision: 0.716016, valid loss: 3364561.250000
epoch: 2206, train precision: 0.999534, train loss: 600.008789, valid precision: 0.714453, valid loss: 3428142.500000
epoch: 2207, train precision: 0.999134, train loss: 1054.061768, valid precision: 0.709375, valid loss: 3295455.250000
epoch: 2208, train precision: 0.999068, train loss: 1713.857422, valid precision: 0.706055, valid loss: 3463390.500000
epoch: 2209, train precision: 0.999201, train loss: 1778.005737, valid precision: 0.706445, valid loss: 3460004.500000
epoch: 2210, train precision: 0.999534, train loss: 653.803162, valid precision: 0.713477, valid loss: 3354738.500000
epoch: 2211, train precision: 0.999467, train loss: 765.219666, valid precision: 0.702734, valid loss: 3349320.250000
epoch: 2212, train precision: 0.999512, train loss: 923.856995, valid precision: 0.712305, valid loss: 3280125.250000
epoch: 2213, train precision: 0.999689, train loss: 589.779053, valid precision: 0.713477, valid loss: 3275124.500000
epoch: 2214, train precision: 0.999356, train loss: 1368.741455, valid precision: 0.702734, valid loss: 3343580.500000
epoch: 2215, train precision: 0.999578, train loss: 730.341614, valid precision: 0.705078, valid loss: 3202014.000000
epoch: 2216, train precision: 0.999334, train loss: 1504.385620, valid precision: 0.701758, valid loss: 3250594.250000
epoch: 2217, train precision: 0.999822, train loss: 197.316452, valid precision: 0.709180, valid loss: 3193173.500000
epoch: 2218, train precision: 0.999933, train loss: 42.351376, valid precision: 0.707812, valid loss: 3165783.500000
epoch: 2219, train precision: 0.999845, train loss: 88.439064, valid precision: 0.707227, valid loss: 3194528.750000
epoch: 2220, train precision: 0.999822, train loss: 155.848831, valid precision: 0.706250, valid loss: 3184439.500000
epoch: 2221, train precision: 0.999184, train loss: 1280.733643, valid precision: 0.705664, valid loss: 3214319.750000
epoch: 2222, train precision: 0.999623, train loss: 859.488464, valid precision: 0.710742, valid loss: 3244521.000000
epoch: 2223, train precision: 0.999800, train loss: 265.262817, valid precision: 0.707227, valid loss: 3173194.500000
epoch: 2224, train precision: 0.999889, train loss: 144.565933, valid precision: 0.709766, valid loss: 3194967.250000
epoch: 2225, train precision: 0.999889, train loss: 86.579369, valid precision: 0.706641, valid loss: 3255094.500000
epoch: 2226, train precision: 0.999822, train loss: 178.289841, valid precision: 0.704492, valid loss: 3317125.500000
epoch: 2227, train precision: 0.998846, train loss: 2550.224854, valid precision: 0.703320, valid loss: 3333155.500000
epoch: 2228, train precision: 0.999600, train loss: 700.953796, valid precision: 0.705078, valid loss: 3410909.500000
epoch: 2229, train precision: 0.999600, train loss: 475.540802, valid precision: 0.705469, valid loss: 3446940.000000
epoch: 2230, train precision: 0.999800, train loss: 182.724945, valid precision: 0.713477, valid loss: 3455638.000000
epoch: 2231, train precision: 0.999822, train loss: 304.624298, valid precision: 0.712500, valid loss: 3467153.500000
epoch: 2232, train precision: 0.999845, train loss: 185.904160, valid precision: 0.711523, valid loss: 3349438.500000
epoch: 2233, train precision: 0.999689, train loss: 508.534698, valid precision: 0.700000, valid loss: 3387264.750000
epoch: 2234, train precision: 0.999623, train loss: 1180.195435, valid precision: 0.709570, valid loss: 3379920.500000
epoch: 2235, train precision: 0.999179, train loss: 1849.897705, valid precision: 0.705664, valid loss: 3361369.500000
epoch: 2236, train precision: 0.999911, train loss: 302.287476, valid precision: 0.707422, valid loss: 3301483.000000
epoch: 2237, train precision: 0.999956, train loss: 40.522961, valid precision: 0.710156, valid loss: 3308857.500000
epoch: 2238, train precision: 0.999778, train loss: 573.239441, valid precision: 0.711328, valid loss: 3529682.500000
epoch: 2239, train precision: 0.999179, train loss: 1715.753052, valid precision: 0.709375, valid loss: 3416889.500000
epoch: 2240, train precision: 0.999600, train loss: 954.603271, valid precision: 0.704687, valid loss: 3449647.250000
epoch: 2241, train precision: 0.999667, train loss: 600.970703, valid precision: 0.703320, valid loss: 3430369.500000
epoch: 2242, train precision: 0.999956, train loss: 20.843529, valid precision: 0.708203, valid loss: 3511526.500000
epoch: 2243, train precision: 0.999933, train loss: 49.222755, valid precision: 0.707422, valid loss: 3501016.000000
epoch: 2244, train precision: 0.999667, train loss: 432.715332, valid precision: 0.706641, valid loss: 3490711.500000
epoch: 2245, train precision: 0.999423, train loss: 1148.654663, valid precision: 0.704102, valid loss: 3492955.250000
epoch: 2246, train precision: 0.999512, train loss: 936.599609, valid precision: 0.704297, valid loss: 3436906.500000
epoch: 2247, train precision: 0.999734, train loss: 512.009583, valid precision: 0.711523, valid loss: 3416856.000000
epoch: 2248, train precision: 0.999734, train loss: 416.797852, valid precision: 0.708594, valid loss: 3428272.500000
epoch: 2249, train precision: 0.999778, train loss: 368.293610, valid precision: 0.710742, valid loss: 3367313.500000
epoch: 2250, train precision: 0.999867, train loss: 101.808273, valid precision: 0.708203, valid loss: 3375272.750000
epoch: 2251, train precision: 0.999778, train loss: 242.031143, valid precision: 0.707812, valid loss: 3379266.500000
epoch: 2252, train precision: 0.999667, train loss: 501.511810, valid precision: 0.704687, valid loss: 3361512.500000
epoch: 2253, train precision: 0.999845, train loss: 246.899261, valid precision: 0.707617, valid loss: 3304357.500000
epoch: 2254, train precision: 0.999245, train loss: 1456.993408, valid precision: 0.707227, valid loss: 3343800.750000
epoch: 2255, train precision: 0.999534, train loss: 744.337524, valid precision: 0.703320, valid loss: 3395989.500000
epoch: 2256, train precision: 0.999423, train loss: 1502.737183, valid precision: 0.701758, valid loss: 3496924.000000
epoch: 2257, train precision: 0.999667, train loss: 359.732635, valid precision: 0.709766, valid loss: 3437638.750000
epoch: 2258, train precision: 0.999711, train loss: 422.362396, valid precision: 0.706641, valid loss: 3509228.000000
epoch: 2259, train precision: 0.999889, train loss: 110.401375, valid precision: 0.706445, valid loss: 3506143.250000
epoch: 2260, train precision: 0.999600, train loss: 600.500549, valid precision: 0.707422, valid loss: 3463986.500000
epoch: 2261, train precision: 0.999534, train loss: 956.108826, valid precision: 0.698438, valid loss: 3565000.500000
epoch: 2262, train precision: 0.999734, train loss: 329.501434, valid precision: 0.704687, valid loss: 3490723.250000
epoch: 2263, train precision: 0.999667, train loss: 413.774933, valid precision: 0.709961, valid loss: 3317301.250000
epoch: 2264, train precision: 0.999822, train loss: 281.543091, valid precision: 0.709570, valid loss: 3438271.250000
epoch: 2265, train precision: 0.999534, train loss: 588.138062, valid precision: 0.703516, valid loss: 3409280.500000
epoch: 2266, train precision: 0.999556, train loss: 527.366028, valid precision: 0.705469, valid loss: 3509755.250000
epoch: 2267, train precision: 0.999623, train loss: 410.872864, valid precision: 0.709961, valid loss: 3675137.500000
epoch: 2268, train precision: 0.999490, train loss: 1009.166931, valid precision: 0.706641, valid loss: 3483298.500000
epoch: 2269, train precision: 0.999867, train loss: 273.677368, valid precision: 0.704883, valid loss: 3481196.000000
epoch: 2270, train precision: 0.999711, train loss: 257.871613, valid precision: 0.708789, valid loss: 3459876.750000
epoch: 2271, train precision: 0.999534, train loss: 1370.136963, valid precision: 0.707617, valid loss: 3643798.000000
epoch: 2272, train precision: 0.999645, train loss: 512.338989, valid precision: 0.704492, valid loss: 3443892.000000
epoch: 2273, train precision: 0.999245, train loss: 1752.067139, valid precision: 0.698242, valid loss: 3650701.500000
epoch: 2274, train precision: 0.999822, train loss: 361.790131, valid precision: 0.708789, valid loss: 3583706.000000
epoch: 2275, train precision: 0.999245, train loss: 1106.788818, valid precision: 0.705664, valid loss: 3637587.500000
epoch: 2276, train precision: 0.999845, train loss: 211.048431, valid precision: 0.709766, valid loss: 3638896.500000
epoch: 2277, train precision: 0.999290, train loss: 1020.373779, valid precision: 0.702344, valid loss: 3663333.250000
epoch: 2278, train precision: 0.999711, train loss: 486.759644, valid precision: 0.703320, valid loss: 3570938.500000
epoch: 2279, train precision: 0.999112, train loss: 1550.238281, valid precision: 0.707227, valid loss: 3431902.500000
epoch: 2280, train precision: 0.999734, train loss: 229.438324, valid precision: 0.703125, valid loss: 3438121.500000
epoch: 2281, train precision: 0.999401, train loss: 758.085938, valid precision: 0.703711, valid loss: 3485488.000000
epoch: 2282, train precision: 0.999911, train loss: 67.129181, valid precision: 0.706836, valid loss: 3469022.750000
epoch: 2283, train precision: 0.999978, train loss: 9.079545, valid precision: 0.708984, valid loss: 3446461.250000
epoch: 2284, train precision: 0.999445, train loss: 1108.797729, valid precision: 0.706641, valid loss: 3551650.000000
epoch: 2285, train precision: 0.999556, train loss: 1015.039429, valid precision: 0.708594, valid loss: 3560591.250000
epoch: 2286, train precision: 0.999356, train loss: 1186.337769, valid precision: 0.706641, valid loss: 3545271.250000
epoch: 2287, train precision: 0.999578, train loss: 721.004944, valid precision: 0.702148, valid loss: 3560172.000000
epoch: 2288, train precision: 0.999778, train loss: 435.464050, valid precision: 0.707812, valid loss: 3604759.250000
epoch: 2289, train precision: 0.999889, train loss: 106.236626, valid precision: 0.705469, valid loss: 3694496.750000
epoch: 2290, train precision: 0.999845, train loss: 197.680923, valid precision: 0.712695, valid loss: 3762490.500000
epoch: 2291, train precision: 0.999689, train loss: 379.598450, valid precision: 0.710938, valid loss: 3659726.500000
epoch: 2292, train precision: 0.999312, train loss: 760.867004, valid precision: 0.711719, valid loss: 3672447.250000
epoch: 2293, train precision: 0.999578, train loss: 940.937866, valid precision: 0.707227, valid loss: 3712103.250000
epoch: 2294, train precision: 0.999756, train loss: 215.230759, valid precision: 0.704687, valid loss: 3741675.250000
epoch: 2295, train precision: 0.999822, train loss: 115.230736, valid precision: 0.704687, valid loss: 3660201.500000
epoch: 2296, train precision: 0.999800, train loss: 188.225052, valid precision: 0.702930, valid loss: 3528633.250000
epoch: 2297, train precision: 0.999845, train loss: 187.348770, valid precision: 0.704102, valid loss: 3556303.250000
epoch: 2298, train precision: 0.999490, train loss: 817.115417, valid precision: 0.708789, valid loss: 3508564.000000
epoch: 2299, train precision: 0.999845, train loss: 322.083984, valid precision: 0.714258, valid loss: 3502272.000000
epoch: 2300, train precision: 0.999623, train loss: 527.291077, valid precision: 0.705469, valid loss: 3515961.500000
epoch: 2301, train precision: 0.999889, train loss: 247.559174, valid precision: 0.712695, valid loss: 3633752.500000
epoch: 2302, train precision: 0.999667, train loss: 496.629883, valid precision: 0.700586, valid loss: 3658934.500000
epoch: 2303, train precision: 0.999534, train loss: 1010.006836, valid precision: 0.713672, valid loss: 3759197.500000
epoch: 2304, train precision: 0.998224, train loss: 3654.161133, valid precision: 0.701172, valid loss: 3840626.500000
epoch: 2305, train precision: 0.999667, train loss: 570.279785, valid precision: 0.704297, valid loss: 3703707.250000
epoch: 2306, train precision: 0.999911, train loss: 211.475082, valid precision: 0.706055, valid loss: 3745137.500000
epoch: 2307, train precision: 0.999534, train loss: 777.880859, valid precision: 0.706445, valid loss: 3755112.750000
epoch: 2308, train precision: 0.999578, train loss: 552.433533, valid precision: 0.703711, valid loss: 3844010.500000
epoch: 2309, train precision: 0.999379, train loss: 1038.733643, valid precision: 0.709766, valid loss: 3879844.000000
epoch: 2310, train precision: 0.999623, train loss: 773.168518, valid precision: 0.707227, valid loss: 3935761.500000
epoch: 2311, train precision: 0.999889, train loss: 153.106018, valid precision: 0.709180, valid loss: 3822710.500000
epoch: 2312, train precision: 0.999822, train loss: 625.281860, valid precision: 0.700586, valid loss: 3901841.500000
epoch: 2313, train precision: 0.999889, train loss: 193.977798, valid precision: 0.707617, valid loss: 3876256.750000
epoch: 2314, train precision: 0.999645, train loss: 442.488007, valid precision: 0.707617, valid loss: 3835408.500000
epoch: 2315, train precision: 0.999800, train loss: 398.830261, valid precision: 0.700781, valid loss: 3759244.750000
epoch: 2316, train precision: 0.999600, train loss: 656.022400, valid precision: 0.703906, valid loss: 3797612.500000
epoch: 2317, train precision: 0.999911, train loss: 189.978027, valid precision: 0.698828, valid loss: 3738716.750000
epoch: 2318, train precision: 0.999956, train loss: 65.343483, valid precision: 0.703516, valid loss: 3760655.250000
epoch: 2319, train precision: 0.999756, train loss: 293.845825, valid precision: 0.700977, valid loss: 3802838.500000
epoch: 2320, train precision: 0.998624, train loss: 3524.064697, valid precision: 0.698242, valid loss: 3979712.500000
epoch: 2321, train precision: 0.999268, train loss: 1453.080200, valid precision: 0.704883, valid loss: 3889347.500000
epoch: 2322, train precision: 0.999822, train loss: 184.844818, valid precision: 0.704687, valid loss: 3840705.250000
epoch: 2323, train precision: 0.999645, train loss: 412.219055, valid precision: 0.709766, valid loss: 3780837.500000
epoch: 2324, train precision: 0.999845, train loss: 136.601562, valid precision: 0.710742, valid loss: 3892331.500000
epoch: 2325, train precision: 0.999800, train loss: 269.066223, valid precision: 0.711133, valid loss: 4028790.500000
epoch: 2326, train precision: 0.999711, train loss: 388.713501, valid precision: 0.707422, valid loss: 3889270.500000
epoch: 2327, train precision: 0.999778, train loss: 301.378143, valid precision: 0.700781, valid loss: 3969156.750000
epoch: 2328, train precision: 0.999845, train loss: 317.549072, valid precision: 0.706445, valid loss: 3911447.500000
epoch: 2329, train precision: 0.999134, train loss: 1840.899658, valid precision: 0.701172, valid loss: 4060343.250000
epoch: 2330, train precision: 0.999623, train loss: 831.702393, valid precision: 0.712109, valid loss: 3906704.500000
epoch: 2331, train precision: 0.999756, train loss: 580.813416, valid precision: 0.716211, valid loss: 3689060.750000
epoch: 2332, train precision: 0.999711, train loss: 762.987549, valid precision: 0.706641, valid loss: 3804126.500000
epoch: 2333, train precision: 0.999556, train loss: 1008.490601, valid precision: 0.709375, valid loss: 3740743.250000
epoch: 2334, train precision: 0.999778, train loss: 393.554962, valid precision: 0.710742, valid loss: 3803797.500000
epoch: 2335, train precision: 0.999889, train loss: 91.549103, valid precision: 0.712500, valid loss: 3771717.250000
epoch: 2336, train precision: 0.999911, train loss: 81.113716, valid precision: 0.710742, valid loss: 3763466.500000
epoch: 2337, train precision: 0.999711, train loss: 486.087524, valid precision: 0.702344, valid loss: 3880871.500000
epoch: 2338, train precision: 0.999445, train loss: 798.834534, valid precision: 0.698438, valid loss: 3892445.250000
epoch: 2339, train precision: 0.999600, train loss: 468.001556, valid precision: 0.706836, valid loss: 3940383.250000
epoch: 2340, train precision: 0.999711, train loss: 692.075806, valid precision: 0.702539, valid loss: 3932236.000000
epoch: 2341, train precision: 0.999645, train loss: 801.540955, valid precision: 0.709180, valid loss: 3809551.250000
epoch: 2342, train precision: 0.999600, train loss: 807.639099, valid precision: 0.701172, valid loss: 3912512.750000
epoch: 2343, train precision: 0.999756, train loss: 661.748108, valid precision: 0.708008, valid loss: 3911155.500000
epoch: 2344, train precision: 0.999689, train loss: 767.668152, valid precision: 0.704102, valid loss: 3904295.500000
epoch: 2345, train precision: 0.999778, train loss: 330.532501, valid precision: 0.706445, valid loss: 3900076.750000
epoch: 2346, train precision: 0.999689, train loss: 304.253296, valid precision: 0.705664, valid loss: 3869470.500000
epoch: 2347, train precision: 0.999867, train loss: 76.519363, valid precision: 0.705859, valid loss: 3956195.250000
epoch: 2348, train precision: 0.999467, train loss: 1017.598633, valid precision: 0.703906, valid loss: 3972176.750000
epoch: 2349, train precision: 0.999356, train loss: 1405.922607, valid precision: 0.706445, valid loss: 3965528.000000
epoch: 2350, train precision: 0.999645, train loss: 652.058838, valid precision: 0.705078, valid loss: 3881969.250000
epoch: 2351, train precision: 0.999867, train loss: 265.466278, valid precision: 0.711133, valid loss: 3821920.750000
epoch: 2352, train precision: 0.999667, train loss: 539.723389, valid precision: 0.698047, valid loss: 3847226.000000
epoch: 2353, train precision: 0.999734, train loss: 396.217010, valid precision: 0.709961, valid loss: 3775395.250000
epoch: 2354, train precision: 0.999667, train loss: 903.860291, valid precision: 0.707812, valid loss: 3807811.250000
epoch: 2355, train precision: 0.999179, train loss: 1373.200928, valid precision: 0.698242, valid loss: 3936623.500000
epoch: 2356, train precision: 0.999756, train loss: 191.492447, valid precision: 0.704883, valid loss: 3838976.000000
epoch: 2357, train precision: 0.999756, train loss: 322.575378, valid precision: 0.708398, valid loss: 4019457.500000
epoch: 2358, train precision: 0.999112, train loss: 1516.599243, valid precision: 0.708398, valid loss: 4049477.250000
epoch: 2359, train precision: 0.999845, train loss: 412.617798, valid precision: 0.708008, valid loss: 4011593.250000
epoch: 2360, train precision: 0.999822, train loss: 278.179321, valid precision: 0.709570, valid loss: 4023256.000000
epoch: 2361, train precision: 0.999534, train loss: 817.823425, valid precision: 0.703320, valid loss: 4007525.250000
epoch: 2362, train precision: 0.999356, train loss: 731.562134, valid precision: 0.706250, valid loss: 3876450.000000
epoch: 2363, train precision: 0.999734, train loss: 404.673309, valid precision: 0.705273, valid loss: 4039109.500000
epoch: 2364, train precision: 0.999423, train loss: 1213.544434, valid precision: 0.705664, valid loss: 3978470.750000
epoch: 2365, train precision: 0.999867, train loss: 197.717468, valid precision: 0.706445, valid loss: 3912861.500000
epoch: 2366, train precision: 0.999756, train loss: 373.054962, valid precision: 0.703516, valid loss: 3990481.500000
epoch: 2367, train precision: 0.999778, train loss: 374.598114, valid precision: 0.703906, valid loss: 3857942.000000
epoch: 2368, train precision: 0.999956, train loss: 64.189545, valid precision: 0.708398, valid loss: 4041167.250000
epoch: 2369, train precision: 0.999933, train loss: 38.675182, valid precision: 0.708398, valid loss: 4020945.500000
epoch: 2370, train precision: 0.999245, train loss: 1087.581665, valid precision: 0.708789, valid loss: 3707537.500000
epoch: 2371, train precision: 0.999756, train loss: 604.852478, valid precision: 0.708398, valid loss: 3981398.500000
epoch: 2372, train precision: 0.999778, train loss: 488.749878, valid precision: 0.710352, valid loss: 3996612.000000
epoch: 2373, train precision: 0.999667, train loss: 563.800903, valid precision: 0.704687, valid loss: 3983264.750000
epoch: 2374, train precision: 0.999645, train loss: 877.807617, valid precision: 0.708984, valid loss: 4052831.250000
epoch: 2375, train precision: 0.999756, train loss: 775.029358, valid precision: 0.704687, valid loss: 4077421.500000
epoch: 2376, train precision: 0.999756, train loss: 384.252411, valid precision: 0.703125, valid loss: 4135009.500000
epoch: 2377, train precision: 0.999867, train loss: 237.424179, valid precision: 0.705273, valid loss: 4108591.500000
epoch: 2378, train precision: 0.999734, train loss: 305.355499, valid precision: 0.709570, valid loss: 4096792.750000
epoch: 2379, train precision: 0.999556, train loss: 840.551514, valid precision: 0.698828, valid loss: 4091978.000000
epoch: 2380, train precision: 0.999689, train loss: 539.794006, valid precision: 0.712891, valid loss: 4120938.750000
epoch: 2381, train precision: 0.999556, train loss: 479.814911, valid precision: 0.709961, valid loss: 4088776.500000
epoch: 2382, train precision: 0.999911, train loss: 78.313362, valid precision: 0.711328, valid loss: 4014067.500000
epoch: 2383, train precision: 0.999157, train loss: 2294.241943, valid precision: 0.701563, valid loss: 3989248.000000
epoch: 2384, train precision: 0.999800, train loss: 235.104584, valid precision: 0.701172, valid loss: 4055216.000000
epoch: 2385, train precision: 0.999556, train loss: 762.721497, valid precision: 0.705078, valid loss: 4136964.750000
epoch: 2386, train precision: 0.999645, train loss: 434.827545, valid precision: 0.699023, valid loss: 4010130.500000
epoch: 2387, train precision: 0.999490, train loss: 1174.644897, valid precision: 0.702734, valid loss: 4151736.000000
epoch: 2388, train precision: 0.999445, train loss: 911.394714, valid precision: 0.702148, valid loss: 4137444.000000
epoch: 2389, train precision: 0.999645, train loss: 822.235352, valid precision: 0.713086, valid loss: 4097139.250000
epoch: 2390, train precision: 0.999845, train loss: 271.025696, valid precision: 0.725000, valid loss: 4169914.500000
epoch: 2391, train precision: 0.999312, train loss: 1066.829224, valid precision: 0.709375, valid loss: 4113787.250000
epoch: 2392, train precision: 0.999623, train loss: 566.528503, valid precision: 0.711328, valid loss: 4297505.000000
epoch: 2393, train precision: 0.999157, train loss: 2116.112549, valid precision: 0.712305, valid loss: 4278156.000000
epoch: 2394, train precision: 0.999756, train loss: 422.386810, valid precision: 0.711719, valid loss: 4265321.000000
epoch: 2395, train precision: 0.999978, train loss: 14.835982, valid precision: 0.706250, valid loss: 4288367.000000
epoch: 2396, train precision: 0.998912, train loss: 2250.046875, valid precision: 0.703906, valid loss: 4382104.000000
epoch: 2397, train precision: 0.999312, train loss: 1158.291504, valid precision: 0.709570, valid loss: 4277826.500000
epoch: 2398, train precision: 0.999822, train loss: 413.140900, valid precision: 0.712695, valid loss: 4180816.750000
epoch: 2399, train precision: 0.999600, train loss: 850.284424, valid precision: 0.712891, valid loss: 4167294.500000
epoch: 2400, train precision: 0.999423, train loss: 1044.551025, valid precision: 0.709961, valid loss: 4089682.750000
epoch: 2401, train precision: 0.999689, train loss: 481.025787, valid precision: 0.701758, valid loss: 4064091.250000
epoch: 2402, train precision: 0.999667, train loss: 399.537567, valid precision: 0.706055, valid loss: 4184329.500000
epoch: 2403, train precision: 0.999822, train loss: 222.990570, valid precision: 0.707031, valid loss: 4176364.750000
epoch: 2404, train precision: 0.999645, train loss: 916.142029, valid precision: 0.702734, valid loss: 4154189.500000
epoch: 2405, train precision: 0.999822, train loss: 327.608582, valid precision: 0.713281, valid loss: 4143196.500000
epoch: 2406, train precision: 0.999889, train loss: 122.638191, valid precision: 0.708789, valid loss: 4273073.500000
epoch: 2407, train precision: 0.999911, train loss: 205.134369, valid precision: 0.713477, valid loss: 4264339.000000
epoch: 2408, train precision: 0.999578, train loss: 689.401001, valid precision: 0.713672, valid loss: 4094903.250000
epoch: 2409, train precision: 0.999667, train loss: 545.624451, valid precision: 0.705273, valid loss: 4170513.500000
epoch: 2410, train precision: 0.999822, train loss: 372.837708, valid precision: 0.710352, valid loss: 4116654.500000
epoch: 2411, train precision: 0.999889, train loss: 219.086365, valid precision: 0.708594, valid loss: 4065468.750000
epoch: 2412, train precision: 0.999933, train loss: 29.256458, valid precision: 0.712695, valid loss: 4079209.500000
epoch: 2413, train precision: 0.999756, train loss: 310.745514, valid precision: 0.708594, valid loss: 4165294.500000
epoch: 2414, train precision: 0.999623, train loss: 411.747772, valid precision: 0.707617, valid loss: 4232685.500000
epoch: 2415, train precision: 0.999534, train loss: 764.886169, valid precision: 0.714844, valid loss: 4272367.000000
epoch: 2416, train precision: 0.999512, train loss: 979.052673, valid precision: 0.711133, valid loss: 4253232.500000
epoch: 2417, train precision: 0.999734, train loss: 574.077026, valid precision: 0.705469, valid loss: 4151074.500000
epoch: 2418, train precision: 0.999822, train loss: 293.768036, valid precision: 0.710547, valid loss: 4203196.500000
epoch: 2419, train precision: 0.999933, train loss: 219.025986, valid precision: 0.711719, valid loss: 4207899.000000
epoch: 2420, train precision: 0.999800, train loss: 357.012512, valid precision: 0.715820, valid loss: 4251474.500000
epoch: 2421, train precision: 0.999490, train loss: 950.228943, valid precision: 0.704102, valid loss: 4353193.000000
epoch: 2422, train precision: 0.999334, train loss: 1535.665161, valid precision: 0.698633, valid loss: 4279175.500000
epoch: 2423, train precision: 0.999778, train loss: 375.496368, valid precision: 0.709375, valid loss: 4237886.500000
epoch: 2424, train precision: 0.999534, train loss: 1350.326172, valid precision: 0.695898, valid loss: 4173691.250000
epoch: 2425, train precision: 0.999667, train loss: 509.703644, valid precision: 0.707227, valid loss: 4121504.000000
epoch: 2426, train precision: 0.998801, train loss: 3178.899902, valid precision: 0.701367, valid loss: 4322087.000000
epoch: 2427, train precision: 0.999978, train loss: 35.605423, valid precision: 0.711328, valid loss: 4235971.000000
epoch: 2428, train precision: 0.999867, train loss: 322.440643, valid precision: 0.712500, valid loss: 4240818.000000
epoch: 2429, train precision: 0.999268, train loss: 2663.847168, valid precision: 0.701172, valid loss: 4440156.000000
epoch: 2430, train precision: 0.999423, train loss: 1327.533569, valid precision: 0.710547, valid loss: 4425241.000000
epoch: 2431, train precision: 0.999667, train loss: 589.042908, valid precision: 0.701953, valid loss: 4160804.500000
epoch: 2432, train precision: 0.999711, train loss: 435.636322, valid precision: 0.701953, valid loss: 4115064.000000
epoch: 2433, train precision: 0.999822, train loss: 158.006332, valid precision: 0.709766, valid loss: 4329779.000000
epoch: 2434, train precision: 0.999889, train loss: 254.553406, valid precision: 0.704102, valid loss: 4390689.500000
epoch: 2435, train precision: 0.999623, train loss: 579.023254, valid precision: 0.692773, valid loss: 4410487.000000
epoch: 2436, train precision: 0.999667, train loss: 788.355103, valid precision: 0.711523, valid loss: 4389443.000000
epoch: 2437, train precision: 0.999734, train loss: 760.384033, valid precision: 0.705469, valid loss: 4563756.000000
epoch: 2438, train precision: 0.999578, train loss: 420.051971, valid precision: 0.702539, valid loss: 4482609.500000
epoch: 2439, train precision: 0.999845, train loss: 189.160416, valid precision: 0.706445, valid loss: 4395401.500000
epoch: 2440, train precision: 0.999889, train loss: 404.218048, valid precision: 0.708594, valid loss: 4386760.000000
epoch: 2441, train precision: 0.999800, train loss: 479.892273, valid precision: 0.714258, valid loss: 4318882.500000
epoch: 2442, train precision: 0.999867, train loss: 79.098877, valid precision: 0.705469, valid loss: 4468297.000000
epoch: 2443, train precision: 0.999467, train loss: 1269.257935, valid precision: 0.708789, valid loss: 4468988.500000
epoch: 2444, train precision: 0.999379, train loss: 778.972656, valid precision: 0.705273, valid loss: 4237172.000000
epoch: 2445, train precision: 0.998757, train loss: 2478.107910, valid precision: 0.702148, valid loss: 4534009.500000
epoch: 2446, train precision: 0.999711, train loss: 372.308594, valid precision: 0.702930, valid loss: 4272062.500000
epoch: 2447, train precision: 0.999800, train loss: 287.334015, valid precision: 0.712500, valid loss: 4387992.500000
epoch: 2448, train precision: 0.999889, train loss: 143.088425, valid precision: 0.712695, valid loss: 4369101.500000
epoch: 2449, train precision: 0.999933, train loss: 63.810482, valid precision: 0.708789, valid loss: 4304053.000000
epoch: 2450, train precision: 0.999822, train loss: 458.823273, valid precision: 0.703516, valid loss: 4322217.500000
epoch: 2451, train precision: 0.999889, train loss: 159.102249, valid precision: 0.701172, valid loss: 4371930.000000
epoch: 2452, train precision: 0.999889, train loss: 192.573593, valid precision: 0.706836, valid loss: 4425501.000000
epoch: 2453, train precision: 0.999556, train loss: 1194.888550, valid precision: 0.708398, valid loss: 4387705.000000
epoch: 2454, train precision: 0.999645, train loss: 1097.570190, valid precision: 0.703516, valid loss: 4294453.000000
epoch: 2455, train precision: 0.999201, train loss: 1663.570801, valid precision: 0.695312, valid loss: 4338398.500000
epoch: 2456, train precision: 0.999578, train loss: 971.127869, valid precision: 0.701953, valid loss: 4404364.500000
epoch: 2457, train precision: 0.999734, train loss: 351.836395, valid precision: 0.700977, valid loss: 4319364.000000
epoch: 2458, train precision: 0.999845, train loss: 379.450714, valid precision: 0.708594, valid loss: 4374042.000000
epoch: 2459, train precision: 0.999689, train loss: 820.738892, valid precision: 0.712109, valid loss: 4484321.000000
epoch: 2460, train precision: 0.999911, train loss: 189.517471, valid precision: 0.708203, valid loss: 4438241.500000
epoch: 2461, train precision: 0.999689, train loss: 581.753174, valid precision: 0.710352, valid loss: 4511149.000000
epoch: 2462, train precision: 0.999734, train loss: 511.178436, valid precision: 0.709766, valid loss: 4401903.000000
epoch: 2463, train precision: 0.999556, train loss: 799.698669, valid precision: 0.698828, valid loss: 4436545.000000
epoch: 2464, train precision: 0.999467, train loss: 1639.540161, valid precision: 0.707617, valid loss: 4392194.500000
epoch: 2465, train precision: 0.999867, train loss: 329.294556, valid precision: 0.705078, valid loss: 4363116.000000
epoch: 2466, train precision: 0.998691, train loss: 2858.958496, valid precision: 0.696680, valid loss: 4576205.500000
epoch: 2467, train precision: 0.999312, train loss: 1287.200073, valid precision: 0.699023, valid loss: 4463509.000000
epoch: 2468, train precision: 0.999467, train loss: 1100.784058, valid precision: 0.704492, valid loss: 4356801.500000
epoch: 2469, train precision: 0.999645, train loss: 666.730042, valid precision: 0.708984, valid loss: 4525671.500000
epoch: 2470, train precision: 0.999822, train loss: 448.860321, valid precision: 0.708984, valid loss: 4544912.000000
epoch: 2471, train precision: 0.999179, train loss: 1753.894165, valid precision: 0.712695, valid loss: 4436624.000000
epoch: 2472, train precision: 0.999600, train loss: 752.815857, valid precision: 0.708008, valid loss: 4420527.000000
epoch: 2473, train precision: 0.999556, train loss: 698.295654, valid precision: 0.699414, valid loss: 4307387.500000
epoch: 2474, train precision: 0.999933, train loss: 76.593475, valid precision: 0.706445, valid loss: 4305450.500000
epoch: 2475, train precision: 0.999578, train loss: 957.674194, valid precision: 0.707617, valid loss: 4256625.500000
epoch: 2476, train precision: 0.999179, train loss: 2655.944580, valid precision: 0.706836, valid loss: 4450018.500000
epoch: 2477, train precision: 0.999734, train loss: 862.484009, valid precision: 0.697266, valid loss: 4434224.000000
epoch: 2478, train precision: 0.999911, train loss: 258.494598, valid precision: 0.707031, valid loss: 4340559.000000
epoch: 2479, train precision: 0.999734, train loss: 676.346558, valid precision: 0.710938, valid loss: 4427055.000000
epoch: 2480, train precision: 0.999645, train loss: 845.567749, valid precision: 0.713477, valid loss: 4647097.000000
epoch: 2481, train precision: 0.999734, train loss: 643.157227, valid precision: 0.699805, valid loss: 4632445.000000
epoch: 2482, train precision: 0.999467, train loss: 1465.236206, valid precision: 0.708984, valid loss: 4608783.000000
epoch: 2483, train precision: 0.999756, train loss: 461.732513, valid precision: 0.707617, valid loss: 4498592.500000
epoch: 2484, train precision: 0.999689, train loss: 728.268738, valid precision: 0.706836, valid loss: 4460452.000000
epoch: 2485, train precision: 0.999667, train loss: 801.411865, valid precision: 0.708203, valid loss: 4413517.000000
epoch: 2486, train precision: 0.999756, train loss: 438.288300, valid precision: 0.706641, valid loss: 4365352.000000
epoch: 2487, train precision: 0.999756, train loss: 575.578552, valid precision: 0.711719, valid loss: 4339671.500000
epoch: 2488, train precision: 0.999556, train loss: 1291.296143, valid precision: 0.710352, valid loss: 4497177.000000
epoch: 2489, train precision: 0.999956, train loss: 49.599789, valid precision: 0.703125, valid loss: 4284535.000000
epoch: 2490, train precision: 0.999911, train loss: 65.428352, valid precision: 0.706250, valid loss: 4335002.500000
epoch: 2491, train precision: 0.999889, train loss: 316.334259, valid precision: 0.707617, valid loss: 4334507.000000
epoch: 2492, train precision: 0.999689, train loss: 651.132996, valid precision: 0.705859, valid loss: 4458996.500000
epoch: 2493, train precision: 0.999490, train loss: 784.840454, valid precision: 0.709180, valid loss: 4617145.000000
epoch: 2494, train precision: 0.999467, train loss: 1523.867920, valid precision: 0.715039, valid loss: 4540074.500000
epoch: 2495, train precision: 0.999822, train loss: 267.783325, valid precision: 0.712109, valid loss: 4423170.500000
epoch: 2496, train precision: 0.999867, train loss: 305.483704, valid precision: 0.709570, valid loss: 4510891.000000
epoch: 2497, train precision: 0.999134, train loss: 2738.760010, valid precision: 0.711523, valid loss: 4365849.500000
epoch: 2498, train precision: 0.999623, train loss: 519.359253, valid precision: 0.703711, valid loss: 4538153.000000
epoch: 2499, train precision: 0.999756, train loss: 367.690674, valid precision: 0.709180, valid loss: 4502126.500000
epoch: 2500, train precision: 0.999490, train loss: 2091.468262, valid precision: 0.705664, valid loss: 4568542.500000
epoch: 2501, train precision: 0.999068, train loss: 1915.180420, valid precision: 0.703516, valid loss: 4499927.000000
epoch: 2502, train precision: 0.999534, train loss: 842.172913, valid precision: 0.709180, valid loss: 4381271.000000
epoch: 2503, train precision: 0.999756, train loss: 307.520905, valid precision: 0.711523, valid loss: 4247654.000000
epoch: 2504, train precision: 0.999867, train loss: 178.113037, valid precision: 0.707031, valid loss: 4347455.000000
epoch: 2505, train precision: 0.999867, train loss: 249.210495, valid precision: 0.705078, valid loss: 4477121.500000
epoch: 2506, train precision: 0.999467, train loss: 957.549377, valid precision: 0.693750, valid loss: 4540391.000000
epoch: 2507, train precision: 0.999534, train loss: 1087.379272, valid precision: 0.712305, valid loss: 4583540.500000
epoch: 2508, train precision: 0.999578, train loss: 1485.614014, valid precision: 0.707031, valid loss: 4620017.500000
epoch: 2509, train precision: 0.999534, train loss: 984.943909, valid precision: 0.710938, valid loss: 4598509.500000
epoch: 2510, train precision: 0.999933, train loss: 53.736118, valid precision: 0.716211, valid loss: 4555830.500000
epoch: 2511, train precision: 0.999933, train loss: 52.378551, valid precision: 0.716016, valid loss: 4463456.000000
epoch: 2512, train precision: 0.999756, train loss: 430.151733, valid precision: 0.717969, valid loss: 4643428.000000
epoch: 2513, train precision: 0.999600, train loss: 661.227478, valid precision: 0.720312, valid loss: 4622731.000000
epoch: 2514, train precision: 0.999667, train loss: 1272.136353, valid precision: 0.717383, valid loss: 4636138.500000
epoch: 2515, train precision: 0.999467, train loss: 1935.433960, valid precision: 0.710547, valid loss: 4547915.000000
epoch: 2516, train precision: 0.999800, train loss: 301.108704, valid precision: 0.708203, valid loss: 4535874.500000
epoch: 2517, train precision: 0.999645, train loss: 577.773804, valid precision: 0.716406, valid loss: 4424000.000000
epoch: 2518, train precision: 0.999711, train loss: 719.981812, valid precision: 0.716797, valid loss: 4425006.500000
epoch: 2519, train precision: 0.999867, train loss: 382.180298, valid precision: 0.717578, valid loss: 4376643.000000
epoch: 2520, train precision: 0.999756, train loss: 481.517456, valid precision: 0.714258, valid loss: 4453039.000000
epoch: 2521, train precision: 0.999623, train loss: 494.731964, valid precision: 0.719336, valid loss: 4395928.000000
epoch: 2522, train precision: 0.999867, train loss: 164.743713, valid precision: 0.709570, valid loss: 4368403.000000
epoch: 2523, train precision: 0.999845, train loss: 176.827469, valid precision: 0.709375, valid loss: 4451317.000000
epoch: 2524, train precision: 0.999956, train loss: 44.088955, valid precision: 0.712695, valid loss: 4439033.000000
epoch: 2525, train precision: 0.999933, train loss: 204.831848, valid precision: 0.714844, valid loss: 4380661.000000
epoch: 2526, train precision: 0.999379, train loss: 1395.936768, valid precision: 0.703125, valid loss: 4351609.500000
epoch: 2527, train precision: 0.999689, train loss: 579.198364, valid precision: 0.709180, valid loss: 4503972.500000
epoch: 2528, train precision: 0.999645, train loss: 831.876404, valid precision: 0.712500, valid loss: 4530688.500000
epoch: 2529, train precision: 0.999600, train loss: 759.700134, valid precision: 0.715820, valid loss: 4383324.500000
epoch: 2530, train precision: 0.999845, train loss: 216.407730, valid precision: 0.714453, valid loss: 4307935.000000
epoch: 2531, train precision: 0.999845, train loss: 310.208527, valid precision: 0.716992, valid loss: 4255567.000000
epoch: 2532, train precision: 0.999623, train loss: 404.073761, valid precision: 0.708594, valid loss: 4379305.000000
epoch: 2533, train precision: 0.999423, train loss: 1105.106323, valid precision: 0.710742, valid loss: 4408333.500000
epoch: 2534, train precision: 0.999534, train loss: 1311.435425, valid precision: 0.715234, valid loss: 4332341.000000
epoch: 2535, train precision: 0.999667, train loss: 517.333740, valid precision: 0.709570, valid loss: 4399969.500000
epoch: 2536, train precision: 0.999822, train loss: 360.002960, valid precision: 0.711328, valid loss: 4499539.500000
epoch: 2537, train precision: 0.999667, train loss: 893.635498, valid precision: 0.709766, valid loss: 4452331.000000
epoch: 2538, train precision: 0.999800, train loss: 339.698517, valid precision: 0.705469, valid loss: 4322230.000000
epoch: 2539, train precision: 0.999578, train loss: 1176.413940, valid precision: 0.703906, valid loss: 4464609.000000
epoch: 2540, train precision: 0.999689, train loss: 769.534180, valid precision: 0.710352, valid loss: 4406631.000000
epoch: 2541, train precision: 0.999512, train loss: 1363.049194, valid precision: 0.709570, valid loss: 4430627.000000
epoch: 2542, train precision: 0.999090, train loss: 2897.206787, valid precision: 0.709180, valid loss: 4546175.000000
epoch: 2543, train precision: 0.999512, train loss: 873.524048, valid precision: 0.712891, valid loss: 4556461.000000
epoch: 2544, train precision: 0.999423, train loss: 1313.619385, valid precision: 0.711133, valid loss: 4684937.000000
epoch: 2545, train precision: 0.999933, train loss: 114.525879, valid precision: 0.711719, valid loss: 4639035.000000
epoch: 2546, train precision: 0.999534, train loss: 1108.120117, valid precision: 0.708594, valid loss: 4718735.000000
epoch: 2547, train precision: 0.999867, train loss: 110.579803, valid precision: 0.709375, valid loss: 4745040.500000
epoch: 2548, train precision: 0.999800, train loss: 914.817139, valid precision: 0.716016, valid loss: 4581755.000000
epoch: 2549, train precision: 0.999290, train loss: 1283.581177, valid precision: 0.708789, valid loss: 4592510.500000
epoch: 2550, train precision: 0.999822, train loss: 272.751495, valid precision: 0.709180, valid loss: 4688353.500000
epoch: 2551, train precision: 0.999800, train loss: 207.687271, valid precision: 0.714258, valid loss: 4618940.000000
epoch: 2552, train precision: 0.999956, train loss: 6.085671, valid precision: 0.716211, valid loss: 4630481.000000
epoch: 2553, train precision: 0.999933, train loss: 27.740612, valid precision: 0.709375, valid loss: 4713010.500000
epoch: 2554, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2555, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2556, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2557, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2558, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2559, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2560, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2561, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2562, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2563, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2564, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2565, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2566, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2567, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2568, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2569, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2570, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2571, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2572, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2573, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2574, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2575, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2576, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2577, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2578, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2579, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2580, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2581, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2582, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2583, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2584, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2585, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2586, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2587, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2588, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2589, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2590, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2591, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2592, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2593, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2594, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2595, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2596, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2597, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2598, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2599, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2600, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2601, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2602, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2603, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2604, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2605, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2606, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2607, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2608, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2609, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2610, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2611, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2612, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2613, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2614, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2615, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2616, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2617, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2618, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2619, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2620, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2621, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2622, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2623, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2624, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2625, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2626, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2627, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2628, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2629, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2630, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2631, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2632, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2633, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2634, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2635, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2636, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2637, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2638, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2639, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2640, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2641, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2642, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2643, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2644, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2645, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2646, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2647, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2648, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2649, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2650, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2651, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2652, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2653, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2654, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2655, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2656, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2657, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2658, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2659, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2660, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2661, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2662, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2663, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2664, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2665, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 2666, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2667, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2668, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2669, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2670, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2671, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2672, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2673, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2674, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2675, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2676, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2677, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2678, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2679, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2680, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2681, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2682, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2683, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2684, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2685, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2686, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2687, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2688, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2689, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2690, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2691, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2692, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2693, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2694, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2695, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2696, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2697, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2698, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2699, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 2700, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2701, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2702, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2703, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2704, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2705, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2706, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2707, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2708, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2709, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2710, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2711, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2712, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2713, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2714, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2715, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2716, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2717, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2718, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2719, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2720, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2721, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2722, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2723, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2724, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2725, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2726, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2727, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2728, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2729, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2730, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2731, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2732, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2733, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2734, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2735, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2736, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2737, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2738, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2739, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2740, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2741, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2742, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2743, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2744, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2745, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2746, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2747, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2748, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2749, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2750, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2751, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2752, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2753, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2754, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2755, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2756, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2757, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2758, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2759, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2760, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2761, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2762, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2763, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2764, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2765, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2766, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2767, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2768, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2769, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2770, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2771, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2772, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2773, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2774, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2775, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2776, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2777, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2778, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2779, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2780, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2781, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2782, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2783, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2784, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2785, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2786, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2787, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2788, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2789, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2790, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2791, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2792, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2793, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2794, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2795, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2796, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2797, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2798, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2799, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2800, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2801, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2802, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2803, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2804, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 2805, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2806, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2807, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2808, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2809, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2810, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2811, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2812, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2813, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2814, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2815, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2816, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2817, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2818, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2819, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2820, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2821, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2822, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2823, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2824, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2825, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2826, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2827, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2828, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2829, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2830, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2831, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2832, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2833, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2834, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2835, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2836, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2837, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2838, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2839, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2840, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2841, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2842, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2843, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2844, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2845, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2846, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2847, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2848, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2849, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2850, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2851, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2852, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2853, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2854, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2855, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2856, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2857, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2858, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2859, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2860, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2861, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2862, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2863, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2864, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2865, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2866, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2867, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2868, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2869, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2870, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2871, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2872, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2873, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2874, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2875, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2876, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2877, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2878, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2879, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2880, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2881, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2882, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2883, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2884, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2885, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2886, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2887, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2888, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2889, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2890, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2891, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2892, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2893, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2894, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2895, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2896, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2897, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2898, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2899, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2900, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2901, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2902, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2903, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2904, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2905, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2906, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2907, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2908, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2909, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2910, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2911, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2912, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2913, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2914, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2915, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2916, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2917, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2918, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2919, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2920, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2921, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2922, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2923, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2924, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2925, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2926, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2927, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2928, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2929, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2930, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2931, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2932, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2933, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2934, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2935, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2936, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2937, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2938, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2939, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2940, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2941, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2942, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2943, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2944, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2945, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2946, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2947, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2948, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2949, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2950, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2951, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2952, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2953, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2954, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2955, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2956, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2957, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2958, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2959, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2960, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2961, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2962, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2963, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2964, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2965, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2966, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2967, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2968, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2969, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2970, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2971, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2972, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2973, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2974, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2975, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2976, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2977, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2978, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2979, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2980, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2981, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2982, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2983, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2984, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2985, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2986, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2987, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2988, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2989, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2990, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2991, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2992, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2993, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2994, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2995, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2996, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2997, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2998, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 2999, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3000, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3001, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3002, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3003, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3004, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3005, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3006, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3007, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3008, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3009, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3010, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3011, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3012, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3013, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3014, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3015, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3016, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3017, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3018, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3019, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3020, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3021, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3022, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3023, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3024, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3025, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3026, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3027, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3028, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3029, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3030, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3031, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3032, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3033, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3034, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3035, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3036, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3037, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3038, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3039, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3040, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3041, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3042, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3043, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3044, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3045, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3046, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3047, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3048, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3049, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3050, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3051, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3052, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3053, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3054, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3055, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3056, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3057, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3058, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3059, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3060, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3061, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3062, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3063, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3064, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3065, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3066, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3067, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3068, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3069, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3070, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3071, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3072, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3073, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3074, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3075, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3076, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3077, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3078, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3079, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3080, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3081, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3082, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3083, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3084, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3085, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3086, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3087, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3088, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3089, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3090, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3091, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3092, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3093, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3094, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3095, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3096, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3097, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3098, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3099, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3100, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3101, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3102, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3103, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3104, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3105, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3106, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3107, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3108, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3109, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3110, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3111, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3112, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3113, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3114, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3115, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3116, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 3117, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3118, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3119, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3120, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3121, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3122, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3123, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3124, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3125, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3126, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3127, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3128, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3129, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3130, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3131, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3132, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3133, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3134, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3135, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3136, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3137, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3138, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3139, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3140, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3141, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3142, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3143, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3144, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3145, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3146, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3147, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3148, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3149, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3150, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3151, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3152, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3153, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3154, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3155, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3156, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3157, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3158, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3159, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3160, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3161, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3162, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3163, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3164, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3165, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3166, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3167, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3168, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3169, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3170, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3171, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3172, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3173, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3174, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3175, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3176, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3177, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3178, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3179, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3180, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3181, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3182, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3183, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3184, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3185, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3186, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3187, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3188, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3189, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3190, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3191, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3192, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3193, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3194, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3195, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3196, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3197, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3198, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3199, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3200, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3201, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3202, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3203, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3204, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3205, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3206, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3207, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3208, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3209, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3210, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3211, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3212, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3213, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3214, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3215, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3216, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3217, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3218, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3219, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3220, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3221, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3222, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3223, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3224, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3225, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3226, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3227, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3228, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3229, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3230, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3231, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3232, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3233, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3234, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3235, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3236, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3237, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3238, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3239, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3240, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3241, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3242, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3243, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3244, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3245, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3246, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3247, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3248, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3249, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3250, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3251, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3252, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3253, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3254, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3255, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3256, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3257, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3258, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3259, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3260, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3261, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3262, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3263, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3264, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3265, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3266, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3267, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3268, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3269, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3270, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3271, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3272, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3273, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3274, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3275, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3276, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3277, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3278, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3279, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3280, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3281, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3282, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3283, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3284, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3285, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3286, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3287, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3288, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3289, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3290, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3291, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3292, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3293, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3294, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3295, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3296, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3297, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3298, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3299, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3300, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3301, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3302, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3303, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3304, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3305, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3306, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3307, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3308, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3309, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3310, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3311, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3312, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3313, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3314, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3315, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3316, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3317, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3318, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3319, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3320, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3321, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3322, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3323, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3324, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3325, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3326, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3327, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3328, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3329, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3330, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3331, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3332, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3333, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3334, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3335, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3336, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3337, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3338, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3339, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3340, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3341, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3342, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3343, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3344, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3345, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3346, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3347, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3348, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3349, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3350, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3351, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3352, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3353, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3354, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3355, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3356, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3357, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3358, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3359, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3360, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3361, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3362, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3363, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3364, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3365, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3366, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3367, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3368, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3369, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3370, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3371, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3372, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3373, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3374, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3375, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3376, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3377, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3378, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3379, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3380, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3381, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3382, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3383, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3384, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3385, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3386, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3387, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3388, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3389, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3390, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3391, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3392, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3393, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3394, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3395, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3396, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3397, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3398, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3399, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3400, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3401, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3402, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3403, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3404, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3405, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3406, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3407, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3408, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3409, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3410, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3411, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3412, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3413, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3414, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3415, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3416, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 3417, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3418, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3419, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3420, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3421, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3422, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3423, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3424, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3425, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3426, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3427, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3428, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3429, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3430, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3431, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3432, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3433, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3434, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3435, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3436, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3437, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3438, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3439, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3440, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3441, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3442, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3443, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3444, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3445, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3446, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3447, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3448, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3449, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3450, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3451, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3452, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3453, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3454, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3455, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3456, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3457, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3458, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3459, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3460, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3461, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3462, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3463, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3464, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3465, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3466, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3467, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3468, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3469, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3470, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3471, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3472, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3473, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3474, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3475, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3476, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3477, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3478, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3479, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3480, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3481, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3482, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3483, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3484, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3485, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3486, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3487, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3488, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3489, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3490, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3491, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3492, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3493, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3494, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3495, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3496, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3497, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3498, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3499, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3500, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3501, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3502, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3503, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3504, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3505, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3506, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3507, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3508, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3509, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3510, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3511, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3512, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3513, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3514, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3515, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3516, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3517, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3518, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3519, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3520, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3521, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3522, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3523, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3524, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3525, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3526, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3527, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3528, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3529, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3530, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3531, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3532, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3533, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3534, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3535, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3536, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3537, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3538, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3539, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3540, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3541, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3542, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3543, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3544, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3545, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3546, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3547, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3548, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3549, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3550, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3551, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3552, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3553, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3554, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3555, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3556, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3557, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3558, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3559, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3560, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3561, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3562, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3563, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3564, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3565, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3566, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3567, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3568, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3569, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3570, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3571, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3572, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3573, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3574, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3575, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3576, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3577, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3578, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3579, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3580, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3581, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3582, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3583, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3584, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3585, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3586, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3587, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3588, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3589, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3590, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3591, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3592, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3593, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3594, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3595, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3596, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3597, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3598, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3599, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3600, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3601, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3602, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3603, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3604, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3605, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3606, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3607, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3608, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3609, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3610, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3611, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3612, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3613, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3614, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3615, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3616, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3617, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3618, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3619, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3620, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3621, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3622, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3623, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3624, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3625, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3626, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3627, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3628, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3629, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3630, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3631, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3632, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3633, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3634, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3635, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3636, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3637, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3638, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3639, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3640, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3641, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3642, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3643, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3644, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3645, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3646, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3647, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3648, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3649, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3650, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3651, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3652, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3653, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3654, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3655, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3656, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3657, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3658, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3659, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3660, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3661, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 3662, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3663, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3664, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3665, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3666, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3667, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3668, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3669, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3670, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3671, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3672, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3673, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3674, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3675, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3676, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3677, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3678, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3679, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3680, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3681, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3682, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3683, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3684, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3685, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3686, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3687, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3688, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3689, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3690, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3691, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3692, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3693, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3694, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3695, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3696, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3697, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3698, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3699, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3700, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3701, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3702, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3703, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3704, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3705, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3706, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3707, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3708, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3709, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3710, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3711, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3712, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3713, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3714, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3715, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3716, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3717, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3718, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3719, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3720, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3721, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3722, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3723, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3724, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3725, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3726, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3727, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3728, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3729, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3730, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3731, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3732, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3733, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3734, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3735, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3736, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3737, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3738, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3739, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3740, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3741, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3742, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3743, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3744, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3745, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3746, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3747, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3748, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3749, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3750, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3751, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3752, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3753, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3754, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3755, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3756, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3757, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3758, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3759, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3760, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3761, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3762, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3763, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3764, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3765, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3766, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3767, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3768, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3769, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3770, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3771, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3772, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3773, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3774, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3775, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3776, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3777, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3778, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3779, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3780, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3781, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3782, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3783, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3784, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3785, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3786, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3787, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3788, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3789, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3790, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3791, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3792, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3793, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3794, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3795, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3796, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3797, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3798, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3799, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3800, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3801, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3802, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3803, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3804, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3805, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3806, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3807, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3808, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3809, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3810, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3811, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3812, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3813, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3814, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3815, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3816, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3817, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3818, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3819, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3820, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3821, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3822, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3823, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3824, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3825, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3826, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3827, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 3828, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3829, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3830, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3831, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3832, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3833, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3834, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3835, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3836, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3837, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3838, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3839, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3840, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3841, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3842, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3843, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3844, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3845, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3846, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3847, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3848, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3849, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3850, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3851, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3852, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3853, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3854, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3855, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3856, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3857, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3858, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3859, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3860, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3861, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3862, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3863, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3864, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3865, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3866, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3867, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3868, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3869, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3870, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3871, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3872, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3873, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3874, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3875, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3876, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3877, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3878, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3879, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3880, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3881, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3882, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3883, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3884, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3885, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3886, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3887, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3888, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3889, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3890, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3891, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3892, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3893, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3894, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3895, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3896, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3897, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3898, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3899, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3900, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3901, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3902, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3903, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3904, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 3905, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3906, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3907, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3908, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3909, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3910, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3911, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3912, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3913, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3914, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3915, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3916, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3917, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3918, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3919, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3920, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3921, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3922, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3923, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3924, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3925, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3926, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3927, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3928, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3929, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3930, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3931, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3932, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3933, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3934, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3935, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3936, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3937, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3938, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3939, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3940, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3941, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3942, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3943, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3944, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3945, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3946, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3947, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3948, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3949, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3950, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3951, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3952, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3953, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3954, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3955, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3956, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3957, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3958, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3959, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3960, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3961, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3962, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3963, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3964, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3965, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3966, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3967, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3968, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3969, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3970, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3971, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3972, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3973, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3974, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3975, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3976, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3977, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3978, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3979, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3980, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 3981, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3982, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3983, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3984, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3985, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3986, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3987, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3988, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3989, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3990, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3991, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3992, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3993, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3994, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3995, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3996, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3997, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3998, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 3999, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4000, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4001, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4002, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4003, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4004, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4005, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4006, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4007, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4008, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4009, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4010, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4011, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4012, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4013, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4014, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4015, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4016, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4017, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4018, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4019, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 4020, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4021, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4022, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4023, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4024, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4025, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4026, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4027, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4028, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4029, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4030, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4031, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4032, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4033, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4034, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4035, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4036, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4037, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4038, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4039, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4040, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4041, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4042, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4043, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4044, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4045, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4046, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4047, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4048, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4049, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4050, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4051, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4052, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4053, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4054, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4055, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4056, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4057, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4058, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4059, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4060, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4061, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4062, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4063, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4064, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4065, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4066, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4067, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4068, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4069, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4070, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4071, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4072, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4073, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4074, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4075, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4076, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4077, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4078, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4079, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4080, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4081, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4082, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4083, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4084, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4085, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4086, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4087, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4088, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4089, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4090, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4091, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4092, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4093, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4094, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4095, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4096, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4097, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4098, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4099, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4100, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4101, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4102, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4103, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4104, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4105, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4106, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4107, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4108, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4109, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4110, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4111, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 4112, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4113, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4114, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4115, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4116, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4117, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4118, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4119, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4120, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4121, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4122, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4123, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4124, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4125, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4126, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4127, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4128, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4129, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4130, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4131, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4132, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4133, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4134, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4135, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4136, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4137, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4138, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4139, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4140, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4141, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4142, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4143, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4144, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4145, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4146, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4147, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4148, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4149, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4150, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4151, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4152, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4153, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4154, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4155, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4156, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4157, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4158, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4159, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4160, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4161, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4162, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4163, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4164, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4165, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4166, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4167, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4168, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4169, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4170, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4171, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4172, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4173, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4174, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4175, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4176, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4177, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4178, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4179, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4180, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4181, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4182, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4183, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4184, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4185, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4186, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4187, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4188, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4189, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4190, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4191, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4192, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4193, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4194, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4195, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4196, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4197, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4198, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4199, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4200, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4201, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4202, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4203, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4204, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4205, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4206, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4207, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4208, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4209, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4210, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4211, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4212, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4213, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4214, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4215, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4216, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4217, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4218, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4219, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4220, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4221, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4222, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4223, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4224, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4225, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4226, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4227, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4228, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4229, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4230, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4231, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4232, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4233, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4234, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4235, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4236, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4237, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4238, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4239, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4240, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4241, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4242, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4243, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4244, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4245, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4246, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4247, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4248, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4249, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4250, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4251, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4252, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4253, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4254, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4255, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4256, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4257, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4258, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4259, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4260, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4261, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4262, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4263, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4264, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4265, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4266, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4267, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4268, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4269, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4270, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4271, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4272, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4273, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4274, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4275, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4276, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4277, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4278, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4279, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4280, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4281, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4282, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4283, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4284, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4285, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4286, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4287, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4288, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4289, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4290, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4291, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4292, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4293, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4294, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4295, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4296, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4297, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4298, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4299, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4300, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4301, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4302, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4303, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4304, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4305, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4306, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4307, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4308, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4309, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4310, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4311, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4312, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4313, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4314, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4315, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4316, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4317, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4318, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4319, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4320, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4321, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4322, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4323, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4324, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4325, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4326, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4327, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4328, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4329, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4330, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4331, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4332, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4333, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4334, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4335, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4336, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4337, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4338, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4339, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4340, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4341, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4342, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4343, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4344, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4345, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4346, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4347, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4348, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4349, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4350, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4351, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4352, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4353, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4354, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4355, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4356, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4357, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4358, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 4359, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4360, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4361, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4362, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4363, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4364, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4365, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4366, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4367, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4368, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4369, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4370, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4371, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4372, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4373, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4374, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4375, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4376, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4377, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4378, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4379, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4380, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4381, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4382, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4383, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4384, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4385, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4386, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4387, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4388, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4389, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4390, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4391, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4392, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4393, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4394, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4395, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4396, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4397, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4398, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4399, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4400, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4401, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4402, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4403, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4404, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4405, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4406, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4407, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4408, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4409, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4410, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4411, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4412, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4413, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4414, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 4415, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4416, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4417, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4418, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4419, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4420, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4421, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4422, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4423, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4424, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4425, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4426, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4427, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4428, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4429, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4430, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4431, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4432, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4433, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4434, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4435, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4436, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4437, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4438, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4439, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4440, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4441, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4442, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4443, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4444, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4445, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4446, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4447, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4448, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4449, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4450, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4451, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4452, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4453, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4454, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4455, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4456, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4457, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4458, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4459, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4460, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4461, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4462, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4463, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4464, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4465, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4466, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4467, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4468, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4469, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4470, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4471, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4472, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4473, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4474, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4475, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4476, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4477, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4478, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4479, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4480, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4481, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4482, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4483, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4484, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4485, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4486, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4487, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4488, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4489, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4490, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4491, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4492, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4493, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4494, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4495, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4496, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4497, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4498, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4499, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4500, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4501, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4502, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4503, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4504, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4505, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4506, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4507, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4508, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4509, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4510, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4511, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4512, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4513, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4514, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4515, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4516, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4517, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4518, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4519, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4520, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4521, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4522, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4523, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4524, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4525, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4526, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4527, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4528, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4529, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4530, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4531, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4532, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4533, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4534, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4535, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4536, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4537, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4538, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4539, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4540, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4541, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4542, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4543, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4544, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4545, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4546, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4547, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4548, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4549, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4550, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4551, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4552, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4553, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4554, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4555, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4556, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4557, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4558, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4559, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4560, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4561, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4562, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4563, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4564, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4565, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4566, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4567, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4568, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4569, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4570, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4571, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4572, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4573, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4574, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4575, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4576, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4577, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4578, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4579, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4580, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4581, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4582, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4583, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4584, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4585, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4586, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4587, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4588, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4589, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4590, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4591, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4592, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4593, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4594, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4595, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4596, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4597, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4598, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4599, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4600, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4601, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4602, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4603, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4604, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4605, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4606, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4607, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4608, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4609, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4610, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4611, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4612, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4613, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4614, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4615, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4616, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4617, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4618, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4619, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4620, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4621, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4622, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4623, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4624, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4625, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4626, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4627, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4628, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4629, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4630, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4631, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4632, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4633, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4634, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4635, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4636, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4637, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4638, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4639, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4640, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4641, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4642, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4643, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4644, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4645, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4646, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4647, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4648, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4649, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4650, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4651, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4652, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4653, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4654, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4655, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4656, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4657, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4658, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4659, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4660, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4661, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4662, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4663, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4664, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4665, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4666, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4667, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4668, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4669, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4670, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4671, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4672, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4673, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4674, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4675, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4676, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4677, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4678, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4679, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4680, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4681, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4682, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4683, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4684, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4685, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4686, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4687, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4688, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4689, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4690, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4691, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4692, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4693, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4694, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4695, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4696, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4697, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4698, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4699, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4700, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4701, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4702, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4703, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4704, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4705, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4706, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4707, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4708, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4709, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4710, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4711, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4712, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 4713, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4714, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4715, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4716, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4717, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4718, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4719, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4720, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 4721, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4722, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4723, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4724, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4725, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4726, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4727, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4728, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4729, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4730, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4731, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4732, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4733, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4734, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4735, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4736, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4737, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4738, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4739, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4740, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4741, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4742, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4743, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4744, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4745, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4746, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4747, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4748, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4749, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4750, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4751, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4752, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4753, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4754, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4755, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 4756, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4757, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4758, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4759, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4760, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4761, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4762, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4763, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4764, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4765, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4766, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4767, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4768, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4769, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4770, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4771, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4772, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4773, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4774, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4775, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4776, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4777, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4778, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4779, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4780, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4781, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4782, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4783, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4784, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4785, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 4786, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4787, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4788, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4789, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4790, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4791, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4792, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4793, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4794, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4795, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4796, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4797, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4798, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4799, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4800, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4801, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4802, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4803, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4804, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4805, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4806, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4807, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4808, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4809, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4810, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4811, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4812, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4813, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4814, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4815, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4816, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4817, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4818, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4819, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4820, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4821, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4822, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4823, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4824, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4825, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4826, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4827, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4828, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4829, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4830, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4831, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4832, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4833, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4834, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4835, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664051.000000
epoch: 4836, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4837, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4838, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4839, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4840, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4841, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4842, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4843, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4844, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4845, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4846, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4847, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4848, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4849, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4850, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4851, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4852, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4853, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4854, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4855, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4856, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4857, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4858, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4859, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4860, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4861, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4862, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4863, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4864, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4865, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4866, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4867, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4868, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4869, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4870, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4871, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4872, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4873, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4874, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4875, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4876, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4877, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4878, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4879, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4880, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4881, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4882, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4883, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4884, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4885, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4886, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4887, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4888, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4889, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4890, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4891, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4892, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4893, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4894, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4895, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4896, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4897, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4898, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4899, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4900, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4901, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4902, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4903, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4904, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4905, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4906, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4907, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4908, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4909, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4910, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4911, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4912, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4913, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4914, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4915, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4916, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4917, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4918, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4919, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4920, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4921, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4922, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4923, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4924, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4925, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4926, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4927, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4928, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4929, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4930, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4931, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4932, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4933, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4934, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4935, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4936, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4937, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4938, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4939, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4940, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4941, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4942, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4943, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4944, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4945, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4946, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4947, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4948, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4949, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4950, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4951, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4952, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4953, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4954, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4955, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4956, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4957, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4958, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4959, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4960, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4961, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4962, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4963, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4964, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4965, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4966, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4967, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4968, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4969, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4970, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4971, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4972, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4973, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4974, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4975, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4976, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4977, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4978, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4979, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4980, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4981, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4982, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4983, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4984, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4985, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4986, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4987, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4988, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4989, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4990, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4991, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4992, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4993, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4994, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4995, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4996, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4997, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4998, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 4999, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
epoch: 5000, train precision: 1.000000, train loss: 0.000000, valid precision: 0.716016, valid loss: 4664050.500000
