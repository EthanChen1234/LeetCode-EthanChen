nohup: ignoring input
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:83:00.0
Total memory: 11.90GiB
Free memory: 3.19GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:83:00.0)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 7700 get requests, put_count=7684 evicted_count=1000 eviction_rate=0.130141 and unsatisfied allocation rate=0.144935
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
epoch{0}, iter[352], train loss: 234.774007, valid precision: 0.427200, valid loss: 196.702932
epoch{1}, iter[704], train loss: 177.895856, valid precision: 0.594400, valid loss: 145.979702
epoch{2}, iter[1056], train loss: 148.579761, valid precision: 0.629000, valid loss: 133.889424
epoch{3}, iter[1408], train loss: 135.273146, valid precision: 0.675600, valid loss: 117.830287
epoch{4}, iter[1760], train loss: 124.617280, valid precision: 0.703400, valid loss: 110.150502
epoch{5}, iter[2112], train loss: 115.789254, valid precision: 0.717600, valid loss: 102.566273
epoch{6}, iter[2464], train loss: 109.344368, valid precision: 0.734600, valid loss: 98.037790
epoch{7}, iter[2816], train loss: 103.217100, valid precision: 0.750200, valid loss: 91.752898
epoch{8}, iter[3168], train loss: 99.446391, valid precision: 0.758400, valid loss: 89.620559
epoch{9}, iter[3520], train loss: 95.121900, valid precision: 0.762800, valid loss: 86.657192
epoch{10}, iter[3872], train loss: 92.077454, valid precision: 0.776000, valid loss: 83.004031
epoch{11}, iter[4224], train loss: 89.734040, valid precision: 0.783000, valid loss: 81.707664
epoch{12}, iter[4576], train loss: 87.674187, valid precision: 0.776000, valid loss: 82.850846
epoch{13}, iter[4928], train loss: 84.222750, valid precision: 0.787000, valid loss: 79.710789
epoch{14}, iter[5280], train loss: 82.207894, valid precision: 0.791200, valid loss: 79.366473
epoch{15}, iter[5632], train loss: 81.237899, valid precision: 0.790800, valid loss: 78.087385
epoch{16}, iter[5984], train loss: 79.323368, valid precision: 0.797200, valid loss: 76.826698
epoch{17}, iter[6336], train loss: 77.415130, valid precision: 0.794800, valid loss: 76.057360
epoch{18}, iter[6688], train loss: 76.461632, valid precision: 0.801400, valid loss: 75.736076
epoch{19}, iter[7040], train loss: 74.818089, valid precision: 0.816600, valid loss: 72.188032
epoch{20}, iter[7392], train loss: 73.935976, valid precision: 0.810000, valid loss: 72.968880
epoch{21}, iter[7744], train loss: 72.974470, valid precision: 0.804600, valid loss: 73.627071
epoch{22}, iter[8096], train loss: 72.093757, valid precision: 0.817600, valid loss: 70.361015
epoch{23}, iter[8448], train loss: 70.900610, valid precision: 0.820600, valid loss: 70.263509
epoch{24}, iter[8800], train loss: 70.168983, valid precision: 0.818800, valid loss: 70.313642
epoch{25}, iter[9152], train loss: 69.192745, valid precision: 0.815600, valid loss: 71.426976
epoch{26}, iter[9504], train loss: 68.661579, valid precision: 0.826800, valid loss: 68.167804
epoch{27}, iter[9856], train loss: 67.479252, valid precision: 0.827200, valid loss: 68.874877
epoch{28}, iter[10208], train loss: 66.643094, valid precision: 0.823800, valid loss: 70.824984
epoch{29}, iter[10560], train loss: 66.833845, valid precision: 0.826000, valid loss: 69.346034
epoch{30}, iter[10912], train loss: 65.772988, valid precision: 0.824400, valid loss: 70.041090
epoch{31}, iter[11264], train loss: 64.759957, valid precision: 0.823600, valid loss: 67.915798
epoch{32}, iter[11616], train loss: 64.658228, valid precision: 0.832200, valid loss: 68.763632
epoch{33}, iter[11968], train loss: 63.601733, valid precision: 0.830600, valid loss: 67.899334
epoch{34}, iter[12320], train loss: 62.509418, valid precision: 0.830000, valid loss: 67.965634
epoch{35}, iter[12672], train loss: 62.397664, valid precision: 0.832000, valid loss: 68.645323
epoch{36}, iter[13024], train loss: 61.835221, valid precision: 0.834200, valid loss: 66.603766
epoch{37}, iter[13376], train loss: 61.314928, valid precision: 0.834600, valid loss: 66.626409
epoch{38}, iter[13728], train loss: 61.031229, valid precision: 0.834200, valid loss: 67.861613
epoch{39}, iter[14080], train loss: 60.693143, valid precision: 0.839600, valid loss: 68.578895
epoch{40}, iter[14432], train loss: 60.457250, valid precision: 0.836600, valid loss: 66.081902
epoch{41}, iter[14784], train loss: 59.777979, valid precision: 0.836400, valid loss: 66.871255
epoch{42}, iter[15136], train loss: 59.082967, valid precision: 0.838800, valid loss: 68.044240
epoch{43}, iter[15488], train loss: 59.462248, valid precision: 0.841400, valid loss: 65.926581
epoch{44}, iter[15840], train loss: 58.621235, valid precision: 0.835600, valid loss: 67.856098
epoch{45}, iter[16192], train loss: 58.598717, valid precision: 0.835800, valid loss: 67.531274
epoch{46}, iter[16544], train loss: 57.722428, valid precision: 0.828600, valid loss: 71.307422
epoch{47}, iter[16896], train loss: 58.074083, valid precision: 0.838800, valid loss: 66.764086
epoch{48}, iter[17248], train loss: 56.966751, valid precision: 0.839400, valid loss: 65.920910
epoch{49}, iter[17600], train loss: 57.137715, valid precision: 0.841000, valid loss: 66.728236
epoch{50}, iter[17952], train loss: 57.256995, valid precision: 0.842200, valid loss: 67.155208
epoch{51}, iter[18304], train loss: 56.942366, valid precision: 0.849600, valid loss: 65.772517
epoch{52}, iter[18656], train loss: 56.535682, valid precision: 0.842200, valid loss: 65.362742
epoch{53}, iter[19008], train loss: 56.325174, valid precision: 0.842400, valid loss: 67.509824
epoch{54}, iter[19360], train loss: 55.732402, valid precision: 0.837800, valid loss: 68.042691
epoch{55}, iter[19712], train loss: 55.401183, valid precision: 0.846200, valid loss: 67.350826
epoch{56}, iter[20064], train loss: 55.790959, valid precision: 0.840000, valid loss: 67.090228
epoch{57}, iter[20416], train loss: 55.729360, valid precision: 0.845400, valid loss: 66.511802
epoch{58}, iter[20768], train loss: 54.867439, valid precision: 0.849600, valid loss: 65.343400
epoch{59}, iter[21120], train loss: 54.996218, valid precision: 0.846800, valid loss: 64.817626
epoch{60}, iter[21472], train loss: 53.988785, valid precision: 0.844200, valid loss: 65.553061
epoch{61}, iter[21824], train loss: 54.158440, valid precision: 0.848800, valid loss: 66.056842
epoch{62}, iter[22176], train loss: 54.720510, valid precision: 0.853600, valid loss: 64.861599
epoch{63}, iter[22528], train loss: 53.698697, valid precision: 0.848400, valid loss: 65.676303
epoch{64}, iter[22880], train loss: 53.588309, valid precision: 0.842800, valid loss: 67.966015
epoch{65}, iter[23232], train loss: 54.188836, valid precision: 0.846800, valid loss: 67.041049
epoch{66}, iter[23584], train loss: 53.011226, valid precision: 0.844600, valid loss: 68.352434
epoch{67}, iter[23936], train loss: 53.375651, valid precision: 0.847200, valid loss: 66.740610
epoch{68}, iter[24288], train loss: 53.470441, valid precision: 0.849000, valid loss: 67.926243
epoch{69}, iter[24640], train loss: 53.544883, valid precision: 0.851800, valid loss: 64.396421
epoch{70}, iter[24992], train loss: 53.390203, valid precision: 0.850800, valid loss: 65.206817
epoch{71}, iter[25344], train loss: 52.604366, valid precision: 0.851600, valid loss: 65.585989
epoch{72}, iter[25696], train loss: 52.313582, valid precision: 0.846600, valid loss: 67.408496
epoch{73}, iter[26048], train loss: 52.198610, valid precision: 0.847200, valid loss: 67.510376
epoch{74}, iter[26400], train loss: 51.812270, valid precision: 0.844200, valid loss: 68.505635
epoch{75}, iter[26752], train loss: 52.108593, valid precision: 0.848400, valid loss: 66.429301
epoch{76}, iter[27104], train loss: 51.637511, valid precision: 0.849400, valid loss: 68.065155
epoch{77}, iter[27456], train loss: 51.283369, valid precision: 0.850800, valid loss: 67.180961
epoch{78}, iter[27808], train loss: 51.089440, valid precision: 0.850600, valid loss: 67.100580
epoch{79}, iter[28160], train loss: 51.782450, valid precision: 0.847200, valid loss: 67.168097
epoch{80}, iter[28512], train loss: 51.268008, valid precision: 0.851400, valid loss: 67.706144
epoch{81}, iter[28864], train loss: 51.282928, valid precision: 0.849400, valid loss: 68.051174
epoch{82}, iter[29216], train loss: 50.626426, valid precision: 0.843400, valid loss: 70.803936
epoch{83}, iter[29568], train loss: 50.999735, valid precision: 0.853800, valid loss: 67.594852
epoch{84}, iter[29920], train loss: 49.994455, valid precision: 0.850200, valid loss: 67.016596
epoch{85}, iter[30272], train loss: 50.050415, valid precision: 0.853200, valid loss: 66.856094
epoch{86}, iter[30624], train loss: 50.826893, valid precision: 0.855600, valid loss: 67.310526
epoch{87}, iter[30976], train loss: 50.097895, valid precision: 0.854200, valid loss: 67.893655
epoch{88}, iter[31328], train loss: 50.203726, valid precision: 0.858600, valid loss: 66.808732
epoch{89}, iter[31680], train loss: 49.813452, valid precision: 0.854000, valid loss: 66.436354
epoch{90}, iter[32032], train loss: 49.633578, valid precision: 0.853600, valid loss: 68.612147
epoch{91}, iter[32384], train loss: 50.066414, valid precision: 0.852800, valid loss: 68.585425
epoch{92}, iter[32736], train loss: 49.823201, valid precision: 0.855000, valid loss: 67.707151
epoch{93}, iter[33088], train loss: 50.095531, valid precision: 0.855000, valid loss: 65.305779
epoch{94}, iter[33440], train loss: 48.646748, valid precision: 0.855800, valid loss: 66.869497
epoch{95}, iter[33792], train loss: 50.037430, valid precision: 0.848600, valid loss: 68.749552
epoch{96}, iter[34144], train loss: 49.664285, valid precision: 0.858200, valid loss: 65.855462
epoch{97}, iter[34496], train loss: 48.754083, valid precision: 0.854800, valid loss: 67.324470
epoch{98}, iter[34848], train loss: 49.040533, valid precision: 0.855600, valid loss: 65.901764
epoch{99}, iter[35200], train loss: 49.293837, valid precision: 0.863400, valid loss: 66.593769
epoch{100}, iter[35552], train loss: 49.322773, valid precision: 0.852200, valid loss: 67.682871
epoch{101}, iter[35904], train loss: 49.102656, valid precision: 0.856800, valid loss: 66.259833
epoch{102}, iter[36256], train loss: 49.049484, valid precision: 0.858400, valid loss: 67.473727
epoch{103}, iter[36608], train loss: 49.032188, valid precision: 0.860400, valid loss: 64.183329
epoch{104}, iter[36960], train loss: 48.209413, valid precision: 0.859000, valid loss: 67.737412
epoch{105}, iter[37312], train loss: 48.599552, valid precision: 0.862200, valid loss: 65.264268
epoch{106}, iter[37664], train loss: 48.486443, valid precision: 0.858400, valid loss: 65.996873
epoch{107}, iter[38016], train loss: 48.671596, valid precision: 0.858200, valid loss: 67.617010
epoch{108}, iter[38368], train loss: 48.580678, valid precision: 0.858000, valid loss: 67.628673
epoch{109}, iter[38720], train loss: 47.862720, valid precision: 0.859200, valid loss: 66.819278
epoch{110}, iter[39072], train loss: 48.323683, valid precision: 0.852800, valid loss: 66.882955
epoch{111}, iter[39424], train loss: 47.303410, valid precision: 0.853400, valid loss: 67.843660
epoch{112}, iter[39776], train loss: 47.788640, valid precision: 0.859000, valid loss: 66.676905
epoch{113}, iter[40128], train loss: 47.892470, valid precision: 0.862000, valid loss: 66.151248
epoch{114}, iter[40480], train loss: 48.603898, valid precision: 0.856400, valid loss: 67.121515
epoch{115}, iter[40832], train loss: 47.357578, valid precision: 0.852600, valid loss: 68.129313
epoch{116}, iter[41184], train loss: 47.900925, valid precision: 0.862400, valid loss: 65.877429
epoch{117}, iter[41536], train loss: 47.119285, valid precision: 0.852600, valid loss: 68.071033
epoch{118}, iter[41888], train loss: 47.771988, valid precision: 0.862800, valid loss: 66.206601
epoch{119}, iter[42240], train loss: 47.964372, valid precision: 0.854400, valid loss: 67.498719
epoch{120}, iter[42592], train loss: 47.577812, valid precision: 0.854800, valid loss: 68.054572
epoch{121}, iter[42944], train loss: 47.450468, valid precision: 0.860200, valid loss: 68.224109
epoch{122}, iter[43296], train loss: 47.534238, valid precision: 0.858200, valid loss: 67.494634
epoch{123}, iter[43648], train loss: 47.353387, valid precision: 0.857400, valid loss: 68.840123
epoch{124}, iter[44000], train loss: 46.865434, valid precision: 0.854600, valid loss: 69.579679
epoch{125}, iter[44352], train loss: 45.986225, valid precision: 0.859200, valid loss: 67.848160
epoch{126}, iter[44704], train loss: 47.662028, valid precision: 0.860200, valid loss: 66.035357
epoch{127}, iter[45056], train loss: 46.990710, valid precision: 0.860000, valid loss: 66.590658
epoch{128}, iter[45408], train loss: 46.980715, valid precision: 0.863200, valid loss: 66.511152
epoch{129}, iter[45760], train loss: 46.903567, valid precision: 0.860600, valid loss: 67.047666
epoch{130}, iter[46112], train loss: 47.230551, valid precision: 0.857200, valid loss: 68.624876
epoch{131}, iter[46464], train loss: 46.469034, valid precision: 0.861400, valid loss: 67.985332
epoch{132}, iter[46816], train loss: 46.804046, valid precision: 0.859800, valid loss: 67.447834
epoch{133}, iter[47168], train loss: 46.527299, valid precision: 0.858400, valid loss: 67.721249
epoch{134}, iter[47520], train loss: 46.040578, valid precision: 0.859200, valid loss: 68.220906
epoch{135}, iter[47872], train loss: 46.763183, valid precision: 0.858200, valid loss: 69.343880
epoch{136}, iter[48224], train loss: 46.905768, valid precision: 0.857800, valid loss: 68.278590
epoch{137}, iter[48576], train loss: 46.504349, valid precision: 0.856800, valid loss: 68.041858
epoch{138}, iter[48928], train loss: 45.875232, valid precision: 0.854400, valid loss: 69.188455
epoch{139}, iter[49280], train loss: 46.626997, valid precision: 0.861200, valid loss: 66.780738
epoch{140}, iter[49632], train loss: 46.550866, valid precision: 0.858000, valid loss: 69.619343
epoch{141}, iter[49984], train loss: 46.504044, valid precision: 0.866600, valid loss: 67.712681
epoch{142}, iter[50336], train loss: 41.313449, valid precision: 0.866000, valid loss: 66.052593
epoch{143}, iter[50688], train loss: 40.136452, valid precision: 0.871800, valid loss: 65.494923
epoch{144}, iter[51040], train loss: 39.217072, valid precision: 0.867200, valid loss: 67.239924
epoch{145}, iter[51392], train loss: 39.256270, valid precision: 0.870600, valid loss: 66.044423
epoch{146}, iter[51744], train loss: 38.547223, valid precision: 0.863800, valid loss: 66.917367
epoch{147}, iter[52096], train loss: 38.152794, valid precision: 0.863400, valid loss: 68.591463
epoch{148}, iter[52448], train loss: 38.272208, valid precision: 0.864800, valid loss: 66.794066
epoch{149}, iter[52800], train loss: 37.833959, valid precision: 0.867000, valid loss: 68.822509
epoch{150}, iter[53152], train loss: 37.818735, valid precision: 0.869400, valid loss: 67.241315
epoch{151}, iter[53504], train loss: 37.775822, valid precision: 0.867200, valid loss: 68.513188
epoch{152}, iter[53856], train loss: 37.070710, valid precision: 0.864800, valid loss: 67.421819
epoch{153}, iter[54208], train loss: 37.192659, valid precision: 0.865000, valid loss: 67.388122
epoch{154}, iter[54560], train loss: 37.051254, valid precision: 0.869200, valid loss: 67.037009
epoch{155}, iter[54912], train loss: 36.377952, valid precision: 0.869200, valid loss: 67.189184
epoch{156}, iter[55264], train loss: 35.668182, valid precision: 0.862400, valid loss: 67.782370
epoch{157}, iter[55616], train loss: 36.607066, valid precision: 0.861400, valid loss: 68.633043
epoch{158}, iter[55968], train loss: 35.864709, valid precision: 0.866600, valid loss: 68.090630
epoch{159}, iter[56320], train loss: 36.810300, valid precision: 0.867400, valid loss: 67.665535
epoch{160}, iter[56672], train loss: 36.406487, valid precision: 0.868400, valid loss: 65.331705
epoch{161}, iter[57024], train loss: 36.203775, valid precision: 0.863400, valid loss: 68.007057
epoch{162}, iter[57376], train loss: 35.880632, valid precision: 0.866600, valid loss: 68.391385
epoch{163}, iter[57728], train loss: 35.534953, valid precision: 0.858000, valid loss: 71.918001
epoch{164}, iter[58080], train loss: 35.821970, valid precision: 0.865400, valid loss: 68.674524
epoch{165}, iter[58432], train loss: 35.462980, valid precision: 0.864200, valid loss: 68.774425
epoch{166}, iter[58784], train loss: 35.133331, valid precision: 0.863600, valid loss: 68.077845
epoch{167}, iter[59136], train loss: 35.068233, valid precision: 0.860800, valid loss: 67.869586
epoch{168}, iter[59488], train loss: 35.397083, valid precision: 0.868600, valid loss: 66.448169
epoch{169}, iter[59840], train loss: 35.005926, valid precision: 0.864400, valid loss: 68.460120
epoch{170}, iter[60192], train loss: 35.570167, valid precision: 0.868600, valid loss: 68.433514
epoch{171}, iter[60544], train loss: 34.548852, valid precision: 0.862000, valid loss: 69.732445
epoch{172}, iter[60896], train loss: 34.420417, valid precision: 0.865200, valid loss: 70.247045
epoch{173}, iter[61248], train loss: 35.348074, valid precision: 0.866200, valid loss: 68.031535
epoch{174}, iter[61600], train loss: 35.001058, valid precision: 0.860400, valid loss: 71.362670
epoch{175}, iter[61952], train loss: 34.078453, valid precision: 0.862600, valid loss: 71.881320
epoch{176}, iter[62304], train loss: 35.021274, valid precision: 0.865000, valid loss: 68.942173
epoch{177}, iter[62656], train loss: 34.470696, valid precision: 0.864000, valid loss: 68.325706
epoch{178}, iter[63008], train loss: 34.295266, valid precision: 0.866200, valid loss: 69.209191
epoch{179}, iter[63360], train loss: 34.511270, valid precision: 0.867600, valid loss: 68.619782
epoch{180}, iter[63712], train loss: 34.906640, valid precision: 0.867400, valid loss: 68.483089
epoch{181}, iter[64064], train loss: 34.192219, valid precision: 0.864200, valid loss: 69.068611
epoch{182}, iter[64416], train loss: 34.398326, valid precision: 0.871200, valid loss: 66.568116
epoch{183}, iter[64768], train loss: 34.310129, valid precision: 0.867600, valid loss: 68.132403
epoch{184}, iter[65120], train loss: 33.629428, valid precision: 0.869600, valid loss: 68.995248
epoch{185}, iter[65472], train loss: 34.215158, valid precision: 0.871400, valid loss: 65.667766
epoch{186}, iter[65824], train loss: 33.587288, valid precision: 0.867200, valid loss: 67.766165
epoch{187}, iter[66176], train loss: 33.414485, valid precision: 0.867000, valid loss: 69.327469
epoch{188}, iter[66528], train loss: 33.979025, valid precision: 0.864600, valid loss: 70.141115
epoch{189}, iter[66880], train loss: 33.362971, valid precision: 0.868800, valid loss: 67.754793
epoch{190}, iter[67232], train loss: 33.865412, valid precision: 0.869200, valid loss: 67.768731
epoch{191}, iter[67584], train loss: 33.809569, valid precision: 0.869200, valid loss: 68.962434
epoch{192}, iter[67936], train loss: 33.355988, valid precision: 0.865600, valid loss: 68.710287
epoch{193}, iter[68288], train loss: 33.607055, valid precision: 0.862600, valid loss: 68.781967
epoch{194}, iter[68640], train loss: 33.090828, valid precision: 0.866400, valid loss: 68.771027
epoch{195}, iter[68992], train loss: 33.359634, valid precision: 0.865200, valid loss: 69.610212
epoch{196}, iter[69344], train loss: 33.501332, valid precision: 0.865000, valid loss: 68.510701
epoch{197}, iter[69696], train loss: 33.382191, valid precision: 0.863200, valid loss: 69.187897
epoch{198}, iter[70048], train loss: 33.215508, valid precision: 0.869600, valid loss: 68.600338
epoch{199}, iter[70400], train loss: 33.339184, valid precision: 0.867600, valid loss: 70.470562
epoch{200}, iter[70752], train loss: 32.974589, valid precision: 0.865400, valid loss: 69.791115
epoch{201}, iter[71104], train loss: 33.179491, valid precision: 0.864400, valid loss: 70.774352
epoch{202}, iter[71456], train loss: 32.719903, valid precision: 0.867200, valid loss: 69.335071
epoch{203}, iter[71808], train loss: 32.602006, valid precision: 0.868600, valid loss: 69.330363
epoch{204}, iter[72160], train loss: 32.975924, valid precision: 0.865600, valid loss: 68.418477
epoch{205}, iter[72512], train loss: 32.833197, valid precision: 0.866400, valid loss: 69.729404
epoch{206}, iter[72864], train loss: 32.569648, valid precision: 0.864800, valid loss: 69.889944
epoch{207}, iter[73216], train loss: 32.795597, valid precision: 0.870200, valid loss: 68.225516
epoch{208}, iter[73568], train loss: 32.426969, valid precision: 0.865600, valid loss: 68.059921
epoch{209}, iter[73920], train loss: 32.461546, valid precision: 0.872200, valid loss: 67.286959
epoch{210}, iter[74272], train loss: 32.139177, valid precision: 0.866800, valid loss: 68.137193
epoch{211}, iter[74624], train loss: 32.154239, valid precision: 0.865600, valid loss: 70.433243
epoch{212}, iter[74976], train loss: 33.018801, valid precision: 0.870400, valid loss: 67.304453
epoch{213}, iter[75328], train loss: 32.197059, valid precision: 0.872200, valid loss: 69.384070
epoch{214}, iter[75680], train loss: 32.370213, valid precision: 0.872600, valid loss: 68.331259
epoch{215}, iter[76032], train loss: 32.308176, valid precision: 0.871600, valid loss: 67.191701
epoch{216}, iter[76384], train loss: 32.603521, valid precision: 0.861600, valid loss: 71.745566
epoch{217}, iter[76736], train loss: 32.143569, valid precision: 0.869600, valid loss: 68.932138
epoch{218}, iter[77088], train loss: 32.830389, valid precision: 0.869200, valid loss: 68.490109
epoch{219}, iter[77440], train loss: 32.317332, valid precision: 0.867800, valid loss: 68.331125
epoch{220}, iter[77792], train loss: 32.150796, valid precision: 0.868400, valid loss: 67.364166
epoch{221}, iter[78144], train loss: 32.366583, valid precision: 0.865800, valid loss: 67.333205
epoch{222}, iter[78496], train loss: 31.982176, valid precision: 0.867200, valid loss: 68.839459
epoch{223}, iter[78848], train loss: 32.150313, valid precision: 0.867000, valid loss: 68.169927
epoch{224}, iter[79200], train loss: 32.105488, valid precision: 0.867800, valid loss: 70.041893
epoch{225}, iter[79552], train loss: 31.418534, valid precision: 0.875600, valid loss: 68.042280
epoch{226}, iter[79904], train loss: 32.308401, valid precision: 0.866800, valid loss: 68.518166
epoch{227}, iter[80256], train loss: 32.019656, valid precision: 0.864600, valid loss: 69.303921
epoch{228}, iter[80608], train loss: 31.716629, valid precision: 0.869600, valid loss: 70.424766
epoch{229}, iter[80960], train loss: 32.013522, valid precision: 0.866600, valid loss: 71.202436
epoch{230}, iter[81312], train loss: 31.957913, valid precision: 0.873800, valid loss: 68.418640
epoch{231}, iter[81664], train loss: 31.732076, valid precision: 0.864800, valid loss: 69.987621
epoch{232}, iter[82016], train loss: 31.851785, valid precision: 0.863000, valid loss: 70.442852
epoch{233}, iter[82368], train loss: 31.677225, valid precision: 0.863800, valid loss: 70.453245
epoch{234}, iter[82720], train loss: 31.720005, valid precision: 0.858600, valid loss: 71.833850
epoch{235}, iter[83072], train loss: 31.634661, valid precision: 0.862000, valid loss: 71.161715
epoch{236}, iter[83424], train loss: 31.781615, valid precision: 0.870400, valid loss: 69.585612
epoch{237}, iter[83776], train loss: 31.213239, valid precision: 0.871800, valid loss: 69.374139
epoch{238}, iter[84128], train loss: 31.175209, valid precision: 0.868000, valid loss: 68.651012
epoch{239}, iter[84480], train loss: 31.203334, valid precision: 0.869000, valid loss: 69.218974
epoch{240}, iter[84832], train loss: 31.229250, valid precision: 0.860400, valid loss: 71.818864
epoch{241}, iter[85184], train loss: 32.201291, valid precision: 0.867800, valid loss: 69.834982
epoch{242}, iter[85536], train loss: 31.920848, valid precision: 0.866800, valid loss: 68.580119
epoch{243}, iter[85888], train loss: 31.363217, valid precision: 0.863800, valid loss: 71.675374
epoch{244}, iter[86240], train loss: 31.462217, valid precision: 0.868200, valid loss: 69.145413
epoch{245}, iter[86592], train loss: 31.220377, valid precision: 0.865000, valid loss: 70.756674
epoch{246}, iter[86944], train loss: 30.818898, valid precision: 0.859800, valid loss: 73.075134
epoch{247}, iter[87296], train loss: 31.196546, valid precision: 0.868600, valid loss: 71.461765
epoch{248}, iter[87648], train loss: 30.884962, valid precision: 0.864200, valid loss: 71.041174
epoch{249}, iter[88000], train loss: 31.278910, valid precision: 0.867800, valid loss: 69.854092
epoch{250}, iter[88352], train loss: 31.054896, valid precision: 0.864600, valid loss: 70.125811
epoch{251}, iter[88704], train loss: 31.882232, valid precision: 0.864600, valid loss: 68.188725
epoch{252}, iter[89056], train loss: 31.080950, valid precision: 0.859600, valid loss: 71.461127
epoch{253}, iter[89408], train loss: 30.613346, valid precision: 0.859000, valid loss: 72.057602
epoch{254}, iter[89760], train loss: 30.493352, valid precision: 0.864200, valid loss: 72.504603
epoch{255}, iter[90112], train loss: 32.016260, valid precision: 0.869000, valid loss: 69.610456
epoch{256}, iter[90464], train loss: 31.496284, valid precision: 0.865400, valid loss: 69.213249
epoch{257}, iter[90816], train loss: 31.391696, valid precision: 0.864600, valid loss: 69.554834
epoch{258}, iter[91168], train loss: 30.992488, valid precision: 0.862800, valid loss: 71.151473
epoch{259}, iter[91520], train loss: 30.726514, valid precision: 0.863800, valid loss: 70.523064
epoch{260}, iter[91872], train loss: 30.862779, valid precision: 0.866400, valid loss: 71.429270
epoch{261}, iter[92224], train loss: 31.294639, valid precision: 0.870000, valid loss: 67.907679
epoch{262}, iter[92576], train loss: 31.270272, valid precision: 0.871800, valid loss: 68.268493
epoch{263}, iter[92928], train loss: 31.201729, valid precision: 0.863400, valid loss: 69.109962
epoch{264}, iter[93280], train loss: 30.878609, valid precision: 0.869000, valid loss: 69.397440
epoch{265}, iter[93632], train loss: 30.529350, valid precision: 0.862600, valid loss: 72.350572
epoch{266}, iter[93984], train loss: 31.019048, valid precision: 0.862400, valid loss: 70.737757
epoch{267}, iter[94336], train loss: 31.310212, valid precision: 0.870800, valid loss: 68.938232
epoch{268}, iter[94688], train loss: 30.691950, valid precision: 0.872400, valid loss: 71.153998
epoch{269}, iter[95040], train loss: 30.696020, valid precision: 0.865600, valid loss: 70.787312
epoch{270}, iter[95392], train loss: 30.778757, valid precision: 0.861400, valid loss: 70.369961
epoch{271}, iter[95744], train loss: 30.699912, valid precision: 0.864400, valid loss: 69.720080
epoch{272}, iter[96096], train loss: 30.249969, valid precision: 0.862800, valid loss: 71.655115
epoch{273}, iter[96448], train loss: 30.522010, valid precision: 0.865400, valid loss: 70.205052
epoch{274}, iter[96800], train loss: 31.067001, valid precision: 0.863800, valid loss: 72.124636
epoch{275}, iter[97152], train loss: 30.809164, valid precision: 0.862400, valid loss: 69.856721
epoch{276}, iter[97504], train loss: 30.370780, valid precision: 0.863800, valid loss: 69.943212
epoch{277}, iter[97856], train loss: 30.425671, valid precision: 0.864000, valid loss: 71.514103
epoch{278}, iter[98208], train loss: 30.812849, valid precision: 0.867800, valid loss: 72.375262
epoch{279}, iter[98560], train loss: 30.666417, valid precision: 0.863600, valid loss: 71.512292
epoch{280}, iter[98912], train loss: 30.345805, valid precision: 0.867200, valid loss: 70.031984
epoch{281}, iter[99264], train loss: 30.317613, valid precision: 0.863800, valid loss: 68.981183
epoch{282}, iter[99616], train loss: 30.130636, valid precision: 0.865200, valid loss: 70.175710
epoch{283}, iter[99968], train loss: 30.360220, valid precision: 0.858400, valid loss: 72.570020
epoch{284}, iter[100320], train loss: 28.293956, valid precision: 0.868600, valid loss: 70.725552
epoch{285}, iter[100672], train loss: 26.387549, valid precision: 0.868400, valid loss: 72.425132
epoch{286}, iter[101024], train loss: 26.307376, valid precision: 0.873000, valid loss: 72.022151
epoch{287}, iter[101376], train loss: 25.687732, valid precision: 0.872200, valid loss: 72.998283
epoch{288}, iter[101728], train loss: 26.194215, valid precision: 0.869000, valid loss: 73.798510
epoch{289}, iter[102080], train loss: 25.633394, valid precision: 0.871000, valid loss: 73.952683
epoch{290}, iter[102432], train loss: 25.851759, valid precision: 0.870000, valid loss: 73.979315
epoch{291}, iter[102784], train loss: 25.576741, valid precision: 0.867400, valid loss: 73.597246
epoch{292}, iter[103136], train loss: 25.621836, valid precision: 0.866400, valid loss: 74.509492
epoch{293}, iter[103488], train loss: 25.634595, valid precision: 0.867400, valid loss: 73.731850
epoch{294}, iter[103840], train loss: 24.659117, valid precision: 0.869800, valid loss: 74.296465
epoch{295}, iter[104192], train loss: 25.685384, valid precision: 0.868400, valid loss: 71.569299
epoch{296}, iter[104544], train loss: 25.209705, valid precision: 0.867600, valid loss: 73.876914
epoch{297}, iter[104896], train loss: 25.090836, valid precision: 0.869400, valid loss: 73.577752
epoch{298}, iter[105248], train loss: 25.137853, valid precision: 0.871200, valid loss: 73.917524
epoch{299}, iter[105600], train loss: 24.840761, valid precision: 0.869600, valid loss: 75.804679
epoch{300}, iter[105952], train loss: 24.472918, valid precision: 0.866200, valid loss: 74.120953
epoch{301}, iter[106304], train loss: 24.681076, valid precision: 0.867600, valid loss: 74.647293
epoch{302}, iter[106656], train loss: 24.765018, valid precision: 0.867000, valid loss: 74.869803
epoch{303}, iter[107008], train loss: 24.253123, valid precision: 0.870200, valid loss: 74.869595
epoch{304}, iter[107360], train loss: 24.561947, valid precision: 0.871200, valid loss: 74.438996
epoch{305}, iter[107712], train loss: 23.981513, valid precision: 0.868800, valid loss: 73.967059
epoch{306}, iter[108064], train loss: 24.365094, valid precision: 0.867800, valid loss: 74.315677
epoch{307}, iter[108416], train loss: 24.264562, valid precision: 0.863400, valid loss: 76.924871
epoch{308}, iter[108768], train loss: 23.934552, valid precision: 0.869400, valid loss: 75.700400
epoch{309}, iter[109120], train loss: 24.156361, valid precision: 0.866200, valid loss: 75.004869
epoch{310}, iter[109472], train loss: 24.257090, valid precision: 0.861600, valid loss: 76.122548
epoch{311}, iter[109824], train loss: 24.065779, valid precision: 0.865000, valid loss: 76.195914
epoch{312}, iter[110176], train loss: 23.935696, valid precision: 0.870000, valid loss: 77.302535
epoch{313}, iter[110528], train loss: 24.405651, valid precision: 0.865600, valid loss: 74.626796
epoch{314}, iter[110880], train loss: 23.681795, valid precision: 0.868800, valid loss: 75.815108
epoch{315}, iter[111232], train loss: 23.970023, valid precision: 0.867200, valid loss: 76.488141
epoch{316}, iter[111584], train loss: 24.408198, valid precision: 0.867400, valid loss: 74.916864
epoch{317}, iter[111936], train loss: 23.873676, valid precision: 0.869200, valid loss: 75.500671
epoch{318}, iter[112288], train loss: 23.815273, valid precision: 0.867800, valid loss: 74.823006
epoch{319}, iter[112640], train loss: 23.740430, valid precision: 0.864800, valid loss: 76.699585
epoch{320}, iter[112992], train loss: 23.613770, valid precision: 0.869000, valid loss: 75.612785
epoch{321}, iter[113344], train loss: 23.546977, valid precision: 0.867000, valid loss: 75.120505
epoch{322}, iter[113696], train loss: 23.286801, valid precision: 0.868000, valid loss: 74.227472
epoch{323}, iter[114048], train loss: 23.608973, valid precision: 0.869000, valid loss: 74.634769
epoch{324}, iter[114400], train loss: 23.966354, valid precision: 0.869200, valid loss: 75.847597
epoch{325}, iter[114752], train loss: 23.455429, valid precision: 0.865000, valid loss: 76.688052
epoch{326}, iter[115104], train loss: 23.370505, valid precision: 0.868200, valid loss: 76.110918
epoch{327}, iter[115456], train loss: 23.269185, valid precision: 0.866800, valid loss: 77.245990
epoch{328}, iter[115808], train loss: 23.999366, valid precision: 0.866200, valid loss: 77.011249
epoch{329}, iter[116160], train loss: 23.530785, valid precision: 0.867600, valid loss: 77.244688
epoch{330}, iter[116512], train loss: 23.192246, valid precision: 0.867000, valid loss: 77.564814
epoch{331}, iter[116864], train loss: 24.015883, valid precision: 0.866200, valid loss: 76.766324
epoch{332}, iter[117216], train loss: 23.587387, valid precision: 0.866600, valid loss: 75.874303
epoch{333}, iter[117568], train loss: 23.310823, valid precision: 0.865800, valid loss: 77.468015
epoch{334}, iter[117920], train loss: 23.261882, valid precision: 0.868600, valid loss: 75.579901
epoch{335}, iter[118272], train loss: 23.300271, valid precision: 0.863400, valid loss: 75.896414
epoch{336}, iter[118624], train loss: 23.142810, valid precision: 0.864200, valid loss: 78.740851
epoch{337}, iter[118976], train loss: 23.209019, valid precision: 0.867600, valid loss: 75.896258
epoch{338}, iter[119328], train loss: 23.320148, valid precision: 0.869200, valid loss: 76.081043
epoch{339}, iter[119680], train loss: 23.433392, valid precision: 0.865800, valid loss: 77.133885
epoch{340}, iter[120032], train loss: 23.003637, valid precision: 0.862600, valid loss: 76.598257
epoch{341}, iter[120384], train loss: 22.918379, valid precision: 0.864800, valid loss: 77.749693
epoch{342}, iter[120736], train loss: 23.145856, valid precision: 0.865600, valid loss: 77.136199
epoch{343}, iter[121088], train loss: 23.094566, valid precision: 0.865200, valid loss: 76.755331
epoch{344}, iter[121440], train loss: 23.249311, valid precision: 0.862200, valid loss: 77.429928
epoch{345}, iter[121792], train loss: 22.961012, valid precision: 0.867800, valid loss: 76.335432
epoch{346}, iter[122144], train loss: 23.199022, valid precision: 0.866800, valid loss: 75.420141
epoch{347}, iter[122496], train loss: 23.193965, valid precision: 0.865200, valid loss: 76.308540
epoch{348}, iter[122848], train loss: 22.401663, valid precision: 0.864600, valid loss: 77.014481
epoch{349}, iter[123200], train loss: 22.940279, valid precision: 0.869200, valid loss: 77.129146
epoch{350}, iter[123552], train loss: 23.029757, valid precision: 0.866800, valid loss: 77.685782
epoch{351}, iter[123904], train loss: 22.833297, valid precision: 0.867200, valid loss: 77.574379
epoch{352}, iter[124256], train loss: 23.022566, valid precision: 0.865800, valid loss: 77.498483
epoch{353}, iter[124608], train loss: 22.682711, valid precision: 0.871000, valid loss: 76.663339
epoch{354}, iter[124960], train loss: 22.699754, valid precision: 0.868800, valid loss: 76.459445
epoch{355}, iter[125312], train loss: 22.741383, valid precision: 0.869800, valid loss: 76.168581
epoch{356}, iter[125664], train loss: 22.644239, valid precision: 0.865800, valid loss: 76.963608
epoch{357}, iter[126016], train loss: 22.305765, valid precision: 0.867600, valid loss: 77.693754
epoch{358}, iter[126368], train loss: 22.794626, valid precision: 0.868200, valid loss: 77.948008
epoch{359}, iter[126720], train loss: 22.453092, valid precision: 0.867800, valid loss: 76.451506
epoch{360}, iter[127072], train loss: 22.523486, valid precision: 0.867400, valid loss: 76.684589
epoch{361}, iter[127424], train loss: 22.614051, valid precision: 0.865200, valid loss: 77.147381
epoch{362}, iter[127776], train loss: 22.900416, valid precision: 0.866200, valid loss: 77.150980
epoch{363}, iter[128128], train loss: 22.695362, valid precision: 0.868400, valid loss: 76.657012
epoch{364}, iter[128480], train loss: 22.725455, valid precision: 0.867800, valid loss: 77.088102
epoch{365}, iter[128832], train loss: 22.489903, valid precision: 0.870200, valid loss: 77.454443
epoch{366}, iter[129184], train loss: 22.811254, valid precision: 0.868600, valid loss: 78.092283
epoch{367}, iter[129536], train loss: 22.591635, valid precision: 0.861800, valid loss: 78.222102
epoch{368}, iter[129888], train loss: 22.052366, valid precision: 0.865000, valid loss: 77.008341
epoch{369}, iter[130240], train loss: 22.180039, valid precision: 0.865800, valid loss: 77.411280
epoch{370}, iter[130592], train loss: 22.347967, valid precision: 0.868600, valid loss: 75.513852
epoch{371}, iter[130944], train loss: 22.645995, valid precision: 0.865000, valid loss: 76.275845
epoch{372}, iter[131296], train loss: 22.264740, valid precision: 0.864800, valid loss: 78.444364
epoch{373}, iter[131648], train loss: 22.180906, valid precision: 0.866000, valid loss: 79.405897
epoch{374}, iter[132000], train loss: 22.112486, valid precision: 0.871400, valid loss: 77.198724
epoch{375}, iter[132352], train loss: 22.562012, valid precision: 0.870200, valid loss: 76.146166
epoch{376}, iter[132704], train loss: 21.889402, valid precision: 0.869400, valid loss: 76.060891
epoch{377}, iter[133056], train loss: 21.998615, valid precision: 0.867400, valid loss: 78.475315
epoch{378}, iter[133408], train loss: 22.373314, valid precision: 0.865400, valid loss: 77.714897
epoch{379}, iter[133760], train loss: 21.891055, valid precision: 0.867000, valid loss: 79.077049
epoch{380}, iter[134112], train loss: 22.001432, valid precision: 0.866600, valid loss: 75.920831
epoch{381}, iter[134464], train loss: 22.758016, valid precision: 0.867600, valid loss: 75.916034
epoch{382}, iter[134816], train loss: 21.800114, valid precision: 0.864600, valid loss: 77.869948
epoch{383}, iter[135168], train loss: 22.269922, valid precision: 0.866200, valid loss: 77.855200
epoch{384}, iter[135520], train loss: 22.503518, valid precision: 0.863400, valid loss: 77.650471
epoch{385}, iter[135872], train loss: 22.255636, valid precision: 0.870000, valid loss: 77.971332
epoch{386}, iter[136224], train loss: 22.455971, valid precision: 0.867200, valid loss: 76.950932
epoch{387}, iter[136576], train loss: 21.632932, valid precision: 0.871000, valid loss: 77.513938
epoch{388}, iter[136928], train loss: 22.156937, valid precision: 0.869400, valid loss: 78.920078
epoch{389}, iter[137280], train loss: 21.888950, valid precision: 0.869600, valid loss: 78.536196
epoch{390}, iter[137632], train loss: 21.875064, valid precision: 0.865000, valid loss: 78.039869
epoch{391}, iter[137984], train loss: 22.018194, valid precision: 0.864400, valid loss: 77.306906
epoch{392}, iter[138336], train loss: 22.030862, valid precision: 0.872200, valid loss: 76.280127
epoch{393}, iter[138688], train loss: 22.008610, valid precision: 0.863000, valid loss: 77.056074
epoch{394}, iter[139040], train loss: 22.042408, valid precision: 0.870600, valid loss: 76.149491
epoch{395}, iter[139392], train loss: 21.960360, valid precision: 0.866800, valid loss: 78.916326
epoch{396}, iter[139744], train loss: 21.235984, valid precision: 0.864800, valid loss: 79.879396
epoch{397}, iter[140096], train loss: 21.840862, valid precision: 0.867400, valid loss: 77.624990
epoch{398}, iter[140448], train loss: 21.664439, valid precision: 0.863800, valid loss: 79.119797
epoch{399}, iter[140800], train loss: 22.036067, valid precision: 0.871400, valid loss: 77.128454
epoch{400}, iter[141152], train loss: 21.786741, valid precision: 0.866000, valid loss: 80.242642
epoch{401}, iter[141504], train loss: 21.912052, valid precision: 0.867400, valid loss: 75.619521
epoch{402}, iter[141856], train loss: 21.915065, valid precision: 0.866400, valid loss: 77.030536
epoch{403}, iter[142208], train loss: 21.777399, valid precision: 0.867200, valid loss: 78.641144
epoch{404}, iter[142560], train loss: 21.882543, valid precision: 0.866400, valid loss: 77.526371
epoch{405}, iter[142912], train loss: 21.716445, valid precision: 0.861600, valid loss: 78.332809
epoch{406}, iter[143264], train loss: 21.703548, valid precision: 0.865200, valid loss: 77.601125
epoch{407}, iter[143616], train loss: 21.504882, valid precision: 0.865400, valid loss: 77.993797
epoch{408}, iter[143968], train loss: 21.444441, valid precision: 0.861200, valid loss: 79.790142
epoch{409}, iter[144320], train loss: 21.383648, valid precision: 0.864800, valid loss: 79.360938
epoch{410}, iter[144672], train loss: 21.760909, valid precision: 0.864600, valid loss: 78.936560
epoch{411}, iter[145024], train loss: 21.386866, valid precision: 0.865200, valid loss: 78.502612
epoch{412}, iter[145376], train loss: 21.647802, valid precision: 0.868600, valid loss: 77.680583
epoch{413}, iter[145728], train loss: 21.897836, valid precision: 0.864800, valid loss: 78.974356
epoch{414}, iter[146080], train loss: 21.584957, valid precision: 0.866800, valid loss: 80.526232
epoch{415}, iter[146432], train loss: 21.493384, valid precision: 0.866600, valid loss: 79.205908
epoch{416}, iter[146784], train loss: 21.662334, valid precision: 0.866800, valid loss: 79.228358
epoch{417}, iter[147136], train loss: 21.305409, valid precision: 0.864800, valid loss: 77.856835
epoch{418}, iter[147488], train loss: 20.952362, valid precision: 0.865600, valid loss: 79.785234
epoch{419}, iter[147840], train loss: 21.745644, valid precision: 0.867600, valid loss: 80.725427
epoch{420}, iter[148192], train loss: 21.496452, valid precision: 0.870000, valid loss: 78.846788
epoch{421}, iter[148544], train loss: 21.191366, valid precision: 0.863800, valid loss: 82.183145
epoch{422}, iter[148896], train loss: 21.139860, valid precision: 0.865600, valid loss: 78.849639
epoch{423}, iter[149248], train loss: 21.231029, valid precision: 0.867800, valid loss: 78.244498
epoch{424}, iter[149600], train loss: 21.094397, valid precision: 0.869200, valid loss: 77.505050
epoch{425}, iter[149952], train loss: 21.206194, valid precision: 0.871400, valid loss: 78.283023
epoch{426}, iter[150304], train loss: 19.697522, valid precision: 0.873200, valid loss: 78.325790
epoch{427}, iter[150656], train loss: 19.506121, valid precision: 0.873200, valid loss: 78.314721
epoch{428}, iter[151008], train loss: 18.988793, valid precision: 0.871400, valid loss: 78.070545
epoch{429}, iter[151360], train loss: 19.094384, valid precision: 0.872600, valid loss: 79.595483
epoch{430}, iter[151712], train loss: 18.380709, valid precision: 0.873200, valid loss: 80.789307
epoch{431}, iter[152064], train loss: 18.305611, valid precision: 0.870000, valid loss: 79.940441
epoch{432}, iter[152416], train loss: 18.418226, valid precision: 0.873600, valid loss: 79.848074
epoch{433}, iter[152768], train loss: 17.956001, valid precision: 0.871200, valid loss: 81.043876
epoch{434}, iter[153120], train loss: 18.474848, valid precision: 0.869200, valid loss: 81.427588
epoch{435}, iter[153472], train loss: 18.347028, valid precision: 0.869000, valid loss: 81.912161
epoch{436}, iter[153824], train loss: 18.239910, valid precision: 0.869000, valid loss: 81.112849
epoch{437}, iter[154176], train loss: 18.252663, valid precision: 0.870600, valid loss: 80.879797
epoch{438}, iter[154528], train loss: 18.093150, valid precision: 0.869000, valid loss: 81.017551
epoch{439}, iter[154880], train loss: 18.120062, valid precision: 0.867200, valid loss: 81.829295
epoch{440}, iter[155232], train loss: 18.602282, valid precision: 0.872600, valid loss: 81.004307
epoch{441}, iter[155584], train loss: 17.983429, valid precision: 0.869800, valid loss: 80.841012
epoch{442}, iter[155936], train loss: 17.899208, valid precision: 0.871600, valid loss: 82.698023
epoch{443}, iter[156288], train loss: 17.928009, valid precision: 0.872200, valid loss: 82.798520
epoch{444}, iter[156640], train loss: 17.984057, valid precision: 0.869200, valid loss: 81.770943
epoch{445}, iter[156992], train loss: 17.924155, valid precision: 0.869400, valid loss: 83.045744
epoch{446}, iter[157344], train loss: 17.737770, valid precision: 0.870400, valid loss: 83.229927
epoch{447}, iter[157696], train loss: 17.844079, valid precision: 0.870600, valid loss: 82.310838
epoch{448}, iter[158048], train loss: 17.715638, valid precision: 0.870400, valid loss: 82.281524
epoch{449}, iter[158400], train loss: 17.453105, valid precision: 0.869800, valid loss: 84.041899
epoch{450}, iter[158752], train loss: 17.349582, valid precision: 0.873000, valid loss: 83.763731
epoch{451}, iter[159104], train loss: 17.400525, valid precision: 0.871400, valid loss: 82.368109
epoch{452}, iter[159456], train loss: 17.259639, valid precision: 0.871200, valid loss: 83.903083
epoch{453}, iter[159808], train loss: 17.589122, valid precision: 0.868400, valid loss: 82.756605
epoch{454}, iter[160160], train loss: 17.783166, valid precision: 0.867800, valid loss: 82.869632
epoch{455}, iter[160512], train loss: 17.690042, valid precision: 0.869800, valid loss: 82.208685
epoch{456}, iter[160864], train loss: 16.973445, valid precision: 0.871600, valid loss: 84.186029
epoch{457}, iter[161216], train loss: 17.288521, valid precision: 0.869800, valid loss: 84.748508
epoch{458}, iter[161568], train loss: 17.171309, valid precision: 0.872000, valid loss: 83.330422
epoch{459}, iter[161920], train loss: 17.281565, valid precision: 0.869800, valid loss: 84.679524
epoch{460}, iter[162272], train loss: 17.046884, valid precision: 0.872200, valid loss: 83.110547
epoch{461}, iter[162624], train loss: 17.058752, valid precision: 0.867600, valid loss: 84.410859
epoch{462}, iter[162976], train loss: 17.019115, valid precision: 0.873800, valid loss: 83.195817
epoch{463}, iter[163328], train loss: 17.203428, valid precision: 0.871400, valid loss: 82.529271
epoch{464}, iter[163680], train loss: 17.098996, valid precision: 0.871000, valid loss: 81.513580
epoch{465}, iter[164032], train loss: 17.004344, valid precision: 0.871400, valid loss: 81.922368
epoch{466}, iter[164384], train loss: 17.354190, valid precision: 0.875800, valid loss: 80.942020
epoch{467}, iter[164736], train loss: 16.924589, valid precision: 0.870200, valid loss: 82.488878
epoch{468}, iter[165088], train loss: 16.884404, valid precision: 0.868400, valid loss: 84.314449
epoch{469}, iter[165440], train loss: 17.070824, valid precision: 0.868000, valid loss: 83.181216
epoch{470}, iter[165792], train loss: 17.322982, valid precision: 0.870200, valid loss: 83.921828
epoch{471}, iter[166144], train loss: 16.841492, valid precision: 0.869200, valid loss: 84.516360
epoch{472}, iter[166496], train loss: 17.013188, valid precision: 0.871200, valid loss: 83.790612
epoch{473}, iter[166848], train loss: 16.834116, valid precision: 0.869800, valid loss: 84.660625
epoch{474}, iter[167200], train loss: 16.930118, valid precision: 0.869200, valid loss: 83.095837
epoch{475}, iter[167552], train loss: 17.043227, valid precision: 0.869600, valid loss: 82.977209
epoch{476}, iter[167904], train loss: 16.620682, valid precision: 0.871200, valid loss: 82.374878
epoch{477}, iter[168256], train loss: 16.967813, valid precision: 0.869200, valid loss: 83.046727
epoch{478}, iter[168608], train loss: 17.187110, valid precision: 0.871200, valid loss: 82.222975
epoch{479}, iter[168960], train loss: 16.844531, valid precision: 0.869200, valid loss: 83.127359
epoch{480}, iter[169312], train loss: 16.646949, valid precision: 0.870000, valid loss: 83.200078
epoch{481}, iter[169664], train loss: 16.289269, valid precision: 0.868000, valid loss: 84.410268
epoch{482}, iter[170016], train loss: 16.851168, valid precision: 0.869400, valid loss: 82.680503
epoch{483}, iter[170368], train loss: 16.943749, valid precision: 0.868400, valid loss: 83.101790
epoch{484}, iter[170720], train loss: 16.857338, valid precision: 0.870200, valid loss: 83.016626
epoch{485}, iter[171072], train loss: 17.008204, valid precision: 0.870000, valid loss: 84.156969
epoch{486}, iter[171424], train loss: 16.595119, valid precision: 0.869600, valid loss: 83.740043
epoch{487}, iter[171776], train loss: 16.978435, valid precision: 0.873600, valid loss: 84.993640
epoch{488}, iter[172128], train loss: 16.905165, valid precision: 0.868400, valid loss: 85.487277
epoch{489}, iter[172480], train loss: 17.045342, valid precision: 0.871000, valid loss: 85.805062
epoch{490}, iter[172832], train loss: 16.653753, valid precision: 0.871600, valid loss: 84.397965
epoch{491}, iter[173184], train loss: 16.529181, valid precision: 0.870400, valid loss: 85.132786
epoch{492}, iter[173536], train loss: 16.439809, valid precision: 0.870200, valid loss: 85.970726
epoch{493}, iter[173888], train loss: 16.599517, valid precision: 0.871600, valid loss: 85.801546
epoch{494}, iter[174240], train loss: 16.278248, valid precision: 0.868200, valid loss: 85.979585
epoch{495}, iter[174592], train loss: 16.445122, valid precision: 0.867400, valid loss: 86.340296
epoch{496}, iter[174944], train loss: 16.359212, valid precision: 0.869200, valid loss: 85.899352
epoch{497}, iter[175296], train loss: 16.635734, valid precision: 0.867600, valid loss: 85.370043
epoch{498}, iter[175648], train loss: 16.416545, valid precision: 0.866800, valid loss: 85.186160
epoch{499}, iter[176000], train loss: 16.605142, valid precision: 0.869600, valid loss: 86.082877
epoch{500}, iter[176352], train loss: 16.753200, valid precision: 0.869600, valid loss: 85.514797
