nohup: ignoring input
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:02:00.0
Total memory: 11.90GiB
Free memory: 8.37GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0)
epoch: 0, train precision: 0.445556, train loss: 194.034753, valid precision: 0.470800, valid loss: 186.611253
epoch: 1, train precision: 0.528978, train loss: 168.405577, valid precision: 0.547800, valid loss: 164.464934
epoch: 2, train precision: 0.607933, train loss: 141.037703, valid precision: 0.611400, valid loss: 141.439057
epoch: 3, train precision: 0.666200, train loss: 124.141513, valid precision: 0.664200, valid loss: 126.210799
epoch: 4, train precision: 0.694911, train loss: 112.312185, valid precision: 0.682200, valid loss: 117.919445
epoch: 5, train precision: 0.724556, train loss: 102.428801, valid precision: 0.701000, valid loss: 112.196159
epoch: 6, train precision: 0.741800, train loss: 95.657643, valid precision: 0.704600, valid loss: 109.530655
epoch: 7, train precision: 0.746156, train loss: 93.452526, valid precision: 0.708400, valid loss: 107.870836
epoch: 8, train precision: 0.774133, train loss: 84.694052, valid precision: 0.726600, valid loss: 102.872180
epoch: 9, train precision: 0.758867, train loss: 87.372176, valid precision: 0.715400, valid loss: 107.522963
epoch: 10, train precision: 0.790778, train loss: 79.148267, valid precision: 0.730000, valid loss: 102.136355
epoch: 11, train precision: 0.797400, train loss: 75.346244, valid precision: 0.727200, valid loss: 102.420568
epoch: 12, train precision: 0.790044, train loss: 77.594207, valid precision: 0.711400, valid loss: 107.502870
epoch: 13, train precision: 0.806889, train loss: 72.460977, valid precision: 0.726600, valid loss: 104.583167
epoch: 14, train precision: 0.796667, train loss: 76.822866, valid precision: 0.719000, valid loss: 108.819947
epoch: 15, train precision: 0.820133, train loss: 66.663319, valid precision: 0.737200, valid loss: 100.252114
epoch: 16, train precision: 0.831467, train loss: 61.389488, valid precision: 0.743000, valid loss: 102.095160
epoch: 17, train precision: 0.844800, train loss: 58.117611, valid precision: 0.747800, valid loss: 101.131493
epoch: 18, train precision: 0.852600, train loss: 55.749684, valid precision: 0.746000, valid loss: 100.653207
epoch: 19, train precision: 0.852222, train loss: 55.397083, valid precision: 0.755600, valid loss: 99.120329
epoch: 20, train precision: 0.830911, train loss: 62.219535, valid precision: 0.728600, valid loss: 111.862274
epoch: 21, train precision: 0.856244, train loss: 54.177313, valid precision: 0.741000, valid loss: 102.794939
epoch: 22, train precision: 0.849511, train loss: 55.233170, valid precision: 0.740800, valid loss: 102.064762
epoch: 23, train precision: 0.862800, train loss: 51.759550, valid precision: 0.736400, valid loss: 107.547434
epoch: 24, train precision: 0.838556, train loss: 61.390467, valid precision: 0.723800, valid loss: 115.268274
epoch: 25, train precision: 0.873378, train loss: 48.530777, valid precision: 0.744800, valid loss: 102.924557
epoch: 26, train precision: 0.863022, train loss: 51.272404, valid precision: 0.739400, valid loss: 107.330955
epoch: 27, train precision: 0.860089, train loss: 52.592173, valid precision: 0.739200, valid loss: 110.601375
epoch: 28, train precision: 0.844822, train loss: 57.415059, valid precision: 0.725600, valid loss: 113.513909
epoch: 29, train precision: 0.880044, train loss: 45.004353, valid precision: 0.740400, valid loss: 111.517051
epoch: 30, train precision: 0.872889, train loss: 48.606649, valid precision: 0.741800, valid loss: 111.597228
epoch: 31, train precision: 0.889689, train loss: 41.171742, valid precision: 0.755000, valid loss: 103.416139
epoch: 32, train precision: 0.890133, train loss: 41.359004, valid precision: 0.756800, valid loss: 106.239560
epoch: 33, train precision: 0.886067, train loss: 42.391131, valid precision: 0.749400, valid loss: 109.655503
epoch: 34, train precision: 0.868622, train loss: 49.682228, valid precision: 0.734600, valid loss: 114.686938
epoch: 35, train precision: 0.896222, train loss: 39.767012, valid precision: 0.763800, valid loss: 105.209706
epoch: 36, train precision: 0.893756, train loss: 40.734516, valid precision: 0.750200, valid loss: 106.242703
epoch: 37, train precision: 0.867956, train loss: 50.034954, valid precision: 0.737800, valid loss: 114.560415
epoch: 38, train precision: 0.877667, train loss: 45.476575, valid precision: 0.739800, valid loss: 113.587286
epoch: 39, train precision: 0.874933, train loss: 47.273521, valid precision: 0.733000, valid loss: 118.160759
epoch: 40, train precision: 0.886222, train loss: 41.896938, valid precision: 0.747600, valid loss: 112.023779
epoch: 41, train precision: 0.898378, train loss: 37.557323, valid precision: 0.751200, valid loss: 112.689211
epoch: 42, train precision: 0.875844, train loss: 46.947315, valid precision: 0.729600, valid loss: 126.732035
epoch: 43, train precision: 0.905067, train loss: 35.748106, valid precision: 0.749400, valid loss: 119.223145
epoch: 44, train precision: 0.902689, train loss: 37.038390, valid precision: 0.753400, valid loss: 112.430458
epoch: 45, train precision: 0.894689, train loss: 39.616074, valid precision: 0.743600, valid loss: 118.483079
epoch: 46, train precision: 0.880133, train loss: 44.856249, valid precision: 0.735200, valid loss: 124.077645
epoch: 47, train precision: 0.898644, train loss: 38.102465, valid precision: 0.754000, valid loss: 112.398375
epoch: 48, train precision: 0.894889, train loss: 39.520506, valid precision: 0.752800, valid loss: 114.845479
epoch: 49, train precision: 0.911022, train loss: 33.229967, valid precision: 0.764400, valid loss: 111.812528
epoch: 50, train precision: 0.909711, train loss: 33.610288, valid precision: 0.755800, valid loss: 117.010507
epoch: 51, train precision: 0.903156, train loss: 36.269109, valid precision: 0.750000, valid loss: 116.470825
epoch: 52, train precision: 0.897000, train loss: 38.594201, valid precision: 0.741000, valid loss: 125.646489
epoch: 53, train precision: 0.901044, train loss: 37.081461, valid precision: 0.748600, valid loss: 116.803627
epoch: 54, train precision: 0.904422, train loss: 36.111497, valid precision: 0.756800, valid loss: 119.054789
epoch: 55, train precision: 0.911622, train loss: 33.363506, valid precision: 0.764200, valid loss: 113.780298
epoch: 56, train precision: 0.912556, train loss: 33.530401, valid precision: 0.754800, valid loss: 118.289972
epoch: 57, train precision: 0.908822, train loss: 34.097666, valid precision: 0.755400, valid loss: 122.141527
epoch: 58, train precision: 0.888711, train loss: 41.579216, valid precision: 0.740000, valid loss: 123.200033
epoch: 59, train precision: 0.907822, train loss: 34.323442, valid precision: 0.760000, valid loss: 121.567151
epoch: 60, train precision: 0.901444, train loss: 37.027374, valid precision: 0.753200, valid loss: 127.258037
epoch: 61, train precision: 0.919378, train loss: 30.729153, valid precision: 0.759800, valid loss: 118.837928
epoch: 62, train precision: 0.906200, train loss: 35.517690, valid precision: 0.751400, valid loss: 126.943486
epoch: 63, train precision: 0.907444, train loss: 35.570175, valid precision: 0.747600, valid loss: 124.915420
epoch: 64, train precision: 0.924911, train loss: 28.483419, valid precision: 0.761600, valid loss: 121.042576
epoch: 65, train precision: 0.916111, train loss: 31.248843, valid precision: 0.756000, valid loss: 126.018217
epoch: 66, train precision: 0.906911, train loss: 35.135496, valid precision: 0.746200, valid loss: 126.916656
epoch: 67, train precision: 0.912756, train loss: 32.822375, valid precision: 0.756400, valid loss: 129.745529
epoch: 68, train precision: 0.913556, train loss: 32.430305, valid precision: 0.755400, valid loss: 122.670480
epoch: 69, train precision: 0.921333, train loss: 29.658453, valid precision: 0.758000, valid loss: 125.375581
epoch: 70, train precision: 0.915400, train loss: 32.260803, valid precision: 0.756600, valid loss: 131.190446
epoch: 71, train precision: 0.909667, train loss: 34.241203, valid precision: 0.757600, valid loss: 124.476180
epoch: 72, train precision: 0.915400, train loss: 31.844669, valid precision: 0.754000, valid loss: 126.338975
epoch: 73, train precision: 0.920644, train loss: 29.818835, valid precision: 0.760600, valid loss: 127.674805
epoch: 74, train precision: 0.905844, train loss: 35.919923, valid precision: 0.745000, valid loss: 135.663362
epoch: 75, train precision: 0.908067, train loss: 34.843420, valid precision: 0.760600, valid loss: 124.130321
epoch: 76, train precision: 0.888400, train loss: 41.692050, valid precision: 0.747000, valid loss: 132.852898
epoch: 77, train precision: 0.914311, train loss: 32.978024, valid precision: 0.746800, valid loss: 133.151276
epoch: 78, train precision: 0.920533, train loss: 30.555235, valid precision: 0.756200, valid loss: 127.114931
epoch: 79, train precision: 0.918844, train loss: 31.203543, valid precision: 0.756200, valid loss: 133.008278
epoch: 80, train precision: 0.916556, train loss: 31.614263, valid precision: 0.758200, valid loss: 124.982341
epoch: 81, train precision: 0.926933, train loss: 27.857821, valid precision: 0.760200, valid loss: 124.754028
epoch: 82, train precision: 0.916289, train loss: 31.462582, valid precision: 0.755600, valid loss: 130.214918
epoch: 83, train precision: 0.924200, train loss: 28.501854, valid precision: 0.757400, valid loss: 131.022009
epoch: 84, train precision: 0.917467, train loss: 31.017760, valid precision: 0.760400, valid loss: 131.368759
epoch: 85, train precision: 0.927378, train loss: 27.806370, valid precision: 0.764000, valid loss: 130.256296
epoch: 86, train precision: 0.920267, train loss: 30.222177, valid precision: 0.753400, valid loss: 131.403616
epoch: 87, train precision: 0.914311, train loss: 32.464759, valid precision: 0.750800, valid loss: 133.461356
epoch: 88, train precision: 0.910867, train loss: 33.337135, valid precision: 0.753800, valid loss: 134.735405
epoch: 89, train precision: 0.915311, train loss: 32.234888, valid precision: 0.751400, valid loss: 134.646680
epoch: 90, train precision: 0.926400, train loss: 27.377423, valid precision: 0.762400, valid loss: 130.102065
epoch: 91, train precision: 0.935733, train loss: 24.247385, valid precision: 0.760600, valid loss: 136.812946
epoch: 92, train precision: 0.903756, train loss: 35.943335, valid precision: 0.749400, valid loss: 134.829772
epoch: 93, train precision: 0.922867, train loss: 29.810426, valid precision: 0.761200, valid loss: 140.377820
epoch: 94, train precision: 0.924400, train loss: 28.880334, valid precision: 0.761800, valid loss: 136.382971
epoch: 95, train precision: 0.913889, train loss: 32.815408, valid precision: 0.748800, valid loss: 142.765704
epoch: 96, train precision: 0.915022, train loss: 32.679774, valid precision: 0.752600, valid loss: 143.195861
epoch: 97, train precision: 0.934489, train loss: 24.969085, valid precision: 0.761400, valid loss: 130.975418
epoch: 98, train precision: 0.920422, train loss: 30.265906, valid precision: 0.751000, valid loss: 135.648622
epoch: 99, train precision: 0.920244, train loss: 30.562292, valid precision: 0.750400, valid loss: 137.808751
epoch: 100, train precision: 0.932067, train loss: 26.220740, valid precision: 0.758000, valid loss: 144.490672
epoch: 101, train precision: 0.930844, train loss: 26.238748, valid precision: 0.760200, valid loss: 137.996053
epoch: 102, train precision: 0.927600, train loss: 27.786776, valid precision: 0.761800, valid loss: 138.220554
epoch: 103, train precision: 0.929044, train loss: 27.131709, valid precision: 0.761000, valid loss: 132.575434
epoch: 104, train precision: 0.889644, train loss: 43.136154, valid precision: 0.736800, valid loss: 146.469969
epoch: 105, train precision: 0.916400, train loss: 32.152475, valid precision: 0.758200, valid loss: 144.141616
epoch: 106, train precision: 0.907178, train loss: 35.874057, valid precision: 0.738800, valid loss: 146.356086
epoch: 107, train precision: 0.932267, train loss: 25.924640, valid precision: 0.755600, valid loss: 140.997035
epoch: 108, train precision: 0.927422, train loss: 28.410057, valid precision: 0.751800, valid loss: 147.796982
epoch: 109, train precision: 0.932489, train loss: 25.882163, valid precision: 0.758200, valid loss: 138.463650
epoch: 110, train precision: 0.896356, train loss: 40.725420, valid precision: 0.740600, valid loss: 151.594242
epoch: 111, train precision: 0.913711, train loss: 32.804350, valid precision: 0.754200, valid loss: 146.839550
epoch: 112, train precision: 0.909356, train loss: 36.699989, valid precision: 0.748800, valid loss: 156.111700
epoch: 113, train precision: 0.932889, train loss: 25.814748, valid precision: 0.763200, valid loss: 136.377118
epoch: 114, train precision: 0.934489, train loss: 25.107872, valid precision: 0.761000, valid loss: 139.740054
epoch: 115, train precision: 0.910267, train loss: 34.572931, valid precision: 0.750800, valid loss: 149.828236
epoch: 116, train precision: 0.933311, train loss: 25.669733, valid precision: 0.754000, valid loss: 152.515779
epoch: 117, train precision: 0.914533, train loss: 33.559346, valid precision: 0.741000, valid loss: 156.985753
epoch: 118, train precision: 0.930867, train loss: 26.564500, valid precision: 0.751400, valid loss: 155.903152
epoch: 119, train precision: 0.919222, train loss: 31.744848, valid precision: 0.745000, valid loss: 158.778787
epoch: 120, train precision: 0.915267, train loss: 33.088691, valid precision: 0.738000, valid loss: 149.266577
epoch: 121, train precision: 0.931444, train loss: 26.055671, valid precision: 0.756200, valid loss: 146.737682
epoch: 122, train precision: 0.942000, train loss: 22.416865, valid precision: 0.751800, valid loss: 150.169488
epoch: 123, train precision: 0.925311, train loss: 28.583756, valid precision: 0.752600, valid loss: 144.627844
epoch: 124, train precision: 0.930889, train loss: 26.335871, valid precision: 0.752800, valid loss: 141.729636
epoch: 125, train precision: 0.913044, train loss: 34.859719, valid precision: 0.745200, valid loss: 161.305637
epoch: 126, train precision: 0.901356, train loss: 39.001584, valid precision: 0.728200, valid loss: 172.258328
epoch: 127, train precision: 0.928667, train loss: 28.007991, valid precision: 0.753400, valid loss: 145.171014
epoch: 128, train precision: 0.925044, train loss: 29.304276, valid precision: 0.745800, valid loss: 155.310504
epoch: 129, train precision: 0.890178, train loss: 45.080822, valid precision: 0.728800, valid loss: 161.195454
epoch: 130, train precision: 0.927978, train loss: 27.732228, valid precision: 0.755400, valid loss: 145.543693
epoch: 131, train precision: 0.933889, train loss: 25.459451, valid precision: 0.751200, valid loss: 149.641764
epoch: 132, train precision: 0.924222, train loss: 30.105490, valid precision: 0.749800, valid loss: 149.796206
epoch: 133, train precision: 0.935333, train loss: 25.134158, valid precision: 0.762400, valid loss: 143.671983
epoch: 134, train precision: 0.942511, train loss: 22.710004, valid precision: 0.763600, valid loss: 155.016442
epoch: 135, train precision: 0.927267, train loss: 28.353188, valid precision: 0.766200, valid loss: 144.446367
epoch: 136, train precision: 0.938178, train loss: 24.910474, valid precision: 0.753200, valid loss: 151.208804
epoch: 137, train precision: 0.924667, train loss: 28.915915, valid precision: 0.745400, valid loss: 151.828109
epoch: 138, train precision: 0.945067, train loss: 21.196121, valid precision: 0.760800, valid loss: 149.658581
epoch: 139, train precision: 0.932622, train loss: 26.263730, valid precision: 0.763000, valid loss: 147.679194
epoch: 140, train precision: 0.944711, train loss: 20.802784, valid precision: 0.757400, valid loss: 153.035511
epoch: 141, train precision: 0.925133, train loss: 29.056970, valid precision: 0.756800, valid loss: 154.077508
epoch: 142, train precision: 0.917689, train loss: 32.021921, valid precision: 0.749000, valid loss: 150.204099
epoch: 143, train precision: 0.931800, train loss: 27.504199, valid precision: 0.758000, valid loss: 160.355904
epoch: 144, train precision: 0.927778, train loss: 27.936771, valid precision: 0.756400, valid loss: 148.047919
epoch: 145, train precision: 0.942533, train loss: 22.423981, valid precision: 0.759200, valid loss: 149.208078
epoch: 146, train precision: 0.925178, train loss: 29.864680, valid precision: 0.751200, valid loss: 158.449852
epoch: 147, train precision: 0.948667, train loss: 19.970617, valid precision: 0.764400, valid loss: 145.238367
epoch: 148, train precision: 0.943178, train loss: 22.339609, valid precision: 0.764800, valid loss: 157.411659
epoch: 149, train precision: 0.934333, train loss: 26.228730, valid precision: 0.750000, valid loss: 151.634072
epoch: 150, train precision: 0.927489, train loss: 28.135075, valid precision: 0.756800, valid loss: 153.378550
epoch: 151, train precision: 0.931289, train loss: 26.614382, valid precision: 0.755000, valid loss: 146.011971
epoch: 152, train precision: 0.938600, train loss: 23.962071, valid precision: 0.758800, valid loss: 148.253050
epoch: 153, train precision: 0.938911, train loss: 23.809403, valid precision: 0.759200, valid loss: 158.836559
epoch: 154, train precision: 0.936178, train loss: 25.735952, valid precision: 0.757800, valid loss: 159.362729
epoch: 155, train precision: 0.941867, train loss: 23.630506, valid precision: 0.761000, valid loss: 156.778238
epoch: 156, train precision: 0.923867, train loss: 30.539743, valid precision: 0.751400, valid loss: 157.377492
epoch: 157, train precision: 0.934956, train loss: 26.585865, valid precision: 0.752200, valid loss: 159.508463
epoch: 158, train precision: 0.945378, train loss: 20.660100, valid precision: 0.756600, valid loss: 148.504456
epoch: 159, train precision: 0.932111, train loss: 27.009306, valid precision: 0.756800, valid loss: 152.758717
epoch: 160, train precision: 0.940933, train loss: 23.262745, valid precision: 0.764000, valid loss: 153.659590
epoch: 161, train precision: 0.937333, train loss: 24.646204, valid precision: 0.763800, valid loss: 150.555028
epoch: 162, train precision: 0.921444, train loss: 31.141852, valid precision: 0.749600, valid loss: 164.839964
epoch: 163, train precision: 0.918711, train loss: 33.255764, valid precision: 0.741600, valid loss: 167.294967
epoch: 164, train precision: 0.934067, train loss: 26.150332, valid precision: 0.754200, valid loss: 158.847075
epoch: 165, train precision: 0.935644, train loss: 24.908087, valid precision: 0.755800, valid loss: 147.803358
epoch: 166, train precision: 0.938867, train loss: 24.509797, valid precision: 0.759000, valid loss: 161.552368
epoch: 167, train precision: 0.943200, train loss: 22.490974, valid precision: 0.757600, valid loss: 155.235701
epoch: 168, train precision: 0.948222, train loss: 20.914299, valid precision: 0.761400, valid loss: 160.925055
epoch: 169, train precision: 0.915489, train loss: 34.112318, valid precision: 0.748800, valid loss: 165.087760
epoch: 170, train precision: 0.923978, train loss: 30.571135, valid precision: 0.740000, valid loss: 162.892778
epoch: 171, train precision: 0.928333, train loss: 28.610207, valid precision: 0.752400, valid loss: 156.438690
epoch: 172, train precision: 0.944444, train loss: 22.102543, valid precision: 0.754800, valid loss: 173.426900
epoch: 173, train precision: 0.935689, train loss: 24.907973, valid precision: 0.758200, valid loss: 152.447736
epoch: 174, train precision: 0.930578, train loss: 28.442728, valid precision: 0.758400, valid loss: 161.907961
epoch: 175, train precision: 0.933644, train loss: 26.477463, valid precision: 0.752400, valid loss: 159.645859
epoch: 176, train precision: 0.940911, train loss: 24.537715, valid precision: 0.761400, valid loss: 167.714844
epoch: 177, train precision: 0.941867, train loss: 22.966476, valid precision: 0.747400, valid loss: 174.595646
epoch: 178, train precision: 0.932533, train loss: 26.762398, valid precision: 0.755400, valid loss: 163.798037
epoch: 179, train precision: 0.930844, train loss: 27.454580, valid precision: 0.752800, valid loss: 169.058753
epoch: 180, train precision: 0.932311, train loss: 28.044380, valid precision: 0.751200, valid loss: 168.863441
epoch: 181, train precision: 0.935600, train loss: 25.657034, valid precision: 0.755600, valid loss: 153.336477
epoch: 182, train precision: 0.937378, train loss: 24.913013, valid precision: 0.762400, valid loss: 158.323662
epoch: 183, train precision: 0.939911, train loss: 24.276281, valid precision: 0.755000, valid loss: 167.071585
epoch: 184, train precision: 0.930933, train loss: 27.845587, valid precision: 0.747800, valid loss: 168.676577
epoch: 185, train precision: 0.947289, train loss: 21.515034, valid precision: 0.754200, valid loss: 169.198218
epoch: 186, train precision: 0.942911, train loss: 22.768018, valid precision: 0.758800, valid loss: 158.650308
epoch: 187, train precision: 0.940733, train loss: 24.120600, valid precision: 0.751600, valid loss: 161.560563
epoch: 188, train precision: 0.934267, train loss: 26.549168, valid precision: 0.754200, valid loss: 162.596939
epoch: 189, train precision: 0.941067, train loss: 23.435850, valid precision: 0.758600, valid loss: 165.658173
epoch: 190, train precision: 0.942978, train loss: 22.752271, valid precision: 0.758000, valid loss: 172.971310
epoch: 191, train precision: 0.946644, train loss: 21.680109, valid precision: 0.765400, valid loss: 165.393754
epoch: 192, train precision: 0.932867, train loss: 27.954947, valid precision: 0.755800, valid loss: 162.774621
epoch: 193, train precision: 0.941867, train loss: 23.849308, valid precision: 0.758400, valid loss: 172.157812
epoch: 194, train precision: 0.942356, train loss: 23.952883, valid precision: 0.764600, valid loss: 165.323489
epoch: 195, train precision: 0.944667, train loss: 22.520552, valid precision: 0.752200, valid loss: 171.308866
epoch: 196, train precision: 0.941667, train loss: 24.410489, valid precision: 0.759800, valid loss: 177.820944
epoch: 197, train precision: 0.936289, train loss: 25.757984, valid precision: 0.753400, valid loss: 166.219841
epoch: 198, train precision: 0.941667, train loss: 22.846230, valid precision: 0.758800, valid loss: 166.074797
epoch: 199, train precision: 0.904378, train loss: 39.675887, valid precision: 0.735000, valid loss: 181.494112
epoch: 200, train precision: 0.949022, train loss: 20.232510, valid precision: 0.768000, valid loss: 161.278863
epoch: 201, train precision: 0.931289, train loss: 28.557727, valid precision: 0.758200, valid loss: 175.586137
epoch: 202, train precision: 0.933756, train loss: 27.617499, valid precision: 0.750600, valid loss: 169.329077
epoch: 203, train precision: 0.943956, train loss: 22.822235, valid precision: 0.761400, valid loss: 168.754730
epoch: 204, train precision: 0.944578, train loss: 22.163847, valid precision: 0.755600, valid loss: 159.228707
epoch: 205, train precision: 0.948689, train loss: 20.919137, valid precision: 0.761600, valid loss: 169.714224
epoch: 206, train precision: 0.947289, train loss: 21.435330, valid precision: 0.754800, valid loss: 171.105039
epoch: 207, train precision: 0.927667, train loss: 29.304071, valid precision: 0.744400, valid loss: 183.423023
epoch: 208, train precision: 0.947511, train loss: 20.694945, valid precision: 0.761600, valid loss: 157.980994
epoch: 209, train precision: 0.938911, train loss: 24.556223, valid precision: 0.747400, valid loss: 168.838016
epoch: 210, train precision: 0.943733, train loss: 23.189568, valid precision: 0.766400, valid loss: 170.604543
epoch: 211, train precision: 0.942444, train loss: 23.042709, valid precision: 0.760000, valid loss: 166.306358
epoch: 212, train precision: 0.932356, train loss: 27.312143, valid precision: 0.742200, valid loss: 175.478527
epoch: 213, train precision: 0.940222, train loss: 24.215916, valid precision: 0.741600, valid loss: 171.738866
epoch: 214, train precision: 0.918644, train loss: 33.551124, valid precision: 0.742000, valid loss: 180.291850
epoch: 215, train precision: 0.949111, train loss: 20.783077, valid precision: 0.761800, valid loss: 172.948729
epoch: 216, train precision: 0.927156, train loss: 30.324108, valid precision: 0.736600, valid loss: 182.461230
epoch: 217, train precision: 0.915400, train loss: 34.999962, valid precision: 0.730200, valid loss: 184.652434
epoch: 218, train precision: 0.943422, train loss: 22.825553, valid precision: 0.753800, valid loss: 156.944467
epoch: 219, train precision: 0.934444, train loss: 27.348564, valid precision: 0.745800, valid loss: 177.089899
epoch: 220, train precision: 0.939400, train loss: 24.494664, valid precision: 0.756400, valid loss: 176.046934
epoch: 221, train precision: 0.929844, train loss: 28.816933, valid precision: 0.750600, valid loss: 175.597565
epoch: 222, train precision: 0.938778, train loss: 24.751909, valid precision: 0.752600, valid loss: 173.720435
epoch: 223, train precision: 0.941467, train loss: 23.216536, valid precision: 0.749600, valid loss: 167.245968
epoch: 224, train precision: 0.941111, train loss: 23.959010, valid precision: 0.760400, valid loss: 167.698176
epoch: 225, train precision: 0.943689, train loss: 23.369680, valid precision: 0.756800, valid loss: 174.418574
epoch: 226, train precision: 0.926978, train loss: 30.022093, valid precision: 0.750400, valid loss: 165.136203
epoch: 227, train precision: 0.937422, train loss: 26.296994, valid precision: 0.755800, valid loss: 179.044791
epoch: 228, train precision: 0.947489, train loss: 21.115988, valid precision: 0.761800, valid loss: 172.916761
epoch: 229, train precision: 0.944711, train loss: 23.675863, valid precision: 0.760200, valid loss: 189.393469
epoch: 230, train precision: 0.943822, train loss: 23.199614, valid precision: 0.764400, valid loss: 169.963215
epoch: 231, train precision: 0.939156, train loss: 25.379194, valid precision: 0.757800, valid loss: 169.454505
epoch: 232, train precision: 0.938822, train loss: 24.564472, valid precision: 0.750800, valid loss: 179.817292
epoch: 233, train precision: 0.948356, train loss: 20.554738, valid precision: 0.759000, valid loss: 171.145542
epoch: 234, train precision: 0.935600, train loss: 27.048608, valid precision: 0.753800, valid loss: 160.389639
epoch: 235, train precision: 0.940467, train loss: 24.787021, valid precision: 0.755000, valid loss: 185.035521
epoch: 236, train precision: 0.935089, train loss: 26.743773, valid precision: 0.753400, valid loss: 178.634258
epoch: 237, train precision: 0.945156, train loss: 23.055587, valid precision: 0.760800, valid loss: 182.317364
epoch: 238, train precision: 0.929400, train loss: 30.202442, valid precision: 0.745600, valid loss: 183.412515
epoch: 239, train precision: 0.942800, train loss: 23.870467, valid precision: 0.754000, valid loss: 181.313937
epoch: 240, train precision: 0.927867, train loss: 30.396858, valid precision: 0.751400, valid loss: 175.494934
epoch: 241, train precision: 0.922578, train loss: 32.249488, valid precision: 0.735200, valid loss: 189.569299
epoch: 242, train precision: 0.923422, train loss: 33.475279, valid precision: 0.751000, valid loss: 175.895001
epoch: 243, train precision: 0.948133, train loss: 21.150581, valid precision: 0.766800, valid loss: 173.737204
epoch: 244, train precision: 0.936244, train loss: 27.460275, valid precision: 0.755000, valid loss: 180.616466
epoch: 245, train precision: 0.950289, train loss: 20.810945, valid precision: 0.766000, valid loss: 184.289554
epoch: 246, train precision: 0.945489, train loss: 22.234250, valid precision: 0.757200, valid loss: 191.125994
epoch: 247, train precision: 0.946978, train loss: 22.330684, valid precision: 0.757000, valid loss: 184.495891
epoch: 248, train precision: 0.928578, train loss: 30.436517, valid precision: 0.746200, valid loss: 186.188877
epoch: 249, train precision: 0.941867, train loss: 24.506361, valid precision: 0.752200, valid loss: 182.426770
epoch: 250, train precision: 0.919622, train loss: 34.655663, valid precision: 0.742800, valid loss: 194.956923
epoch: 251, train precision: 0.946533, train loss: 21.817557, valid precision: 0.754400, valid loss: 173.923849
epoch: 252, train precision: 0.947222, train loss: 22.140832, valid precision: 0.759200, valid loss: 173.995308
epoch: 253, train precision: 0.930889, train loss: 29.320577, valid precision: 0.753200, valid loss: 184.439337
epoch: 254, train precision: 0.924311, train loss: 33.342614, valid precision: 0.739000, valid loss: 187.063514
epoch: 255, train precision: 0.949356, train loss: 20.719630, valid precision: 0.752400, valid loss: 177.728831
epoch: 256, train precision: 0.929244, train loss: 29.759172, valid precision: 0.738000, valid loss: 184.028244
epoch: 257, train precision: 0.919289, train loss: 36.400809, valid precision: 0.746200, valid loss: 184.440659
epoch: 258, train precision: 0.949178, train loss: 20.837388, valid precision: 0.764800, valid loss: 176.877183
epoch: 259, train precision: 0.930378, train loss: 31.608465, valid precision: 0.751800, valid loss: 190.838528
epoch: 260, train precision: 0.935356, train loss: 27.244950, valid precision: 0.757000, valid loss: 178.141053
epoch: 261, train precision: 0.946356, train loss: 22.396280, valid precision: 0.762400, valid loss: 181.091642
epoch: 262, train precision: 0.948911, train loss: 22.384942, valid precision: 0.762200, valid loss: 200.925259
epoch: 263, train precision: 0.953489, train loss: 19.496889, valid precision: 0.757400, valid loss: 185.833248
epoch: 264, train precision: 0.943800, train loss: 23.777874, valid precision: 0.749800, valid loss: 177.880061
epoch: 265, train precision: 0.943378, train loss: 24.135979, valid precision: 0.757000, valid loss: 191.498603
epoch: 266, train precision: 0.940467, train loss: 25.717494, valid precision: 0.746800, valid loss: 192.423278
epoch: 267, train precision: 0.943889, train loss: 24.857673, valid precision: 0.758400, valid loss: 194.268863
epoch: 268, train precision: 0.932089, train loss: 28.433414, valid precision: 0.758000, valid loss: 168.893961
epoch: 269, train precision: 0.934978, train loss: 26.980649, valid precision: 0.753000, valid loss: 182.540648
epoch: 270, train precision: 0.944422, train loss: 23.263911, valid precision: 0.760800, valid loss: 173.712652
epoch: 271, train precision: 0.922911, train loss: 32.882825, valid precision: 0.742200, valid loss: 188.011338
epoch: 272, train precision: 0.937911, train loss: 26.503049, valid precision: 0.748000, valid loss: 183.024055
epoch: 273, train precision: 0.943844, train loss: 23.311379, valid precision: 0.754000, valid loss: 188.003817
epoch: 274, train precision: 0.945489, train loss: 23.330590, valid precision: 0.747800, valid loss: 190.673630
epoch: 275, train precision: 0.916133, train loss: 36.830031, valid precision: 0.741200, valid loss: 188.075231
epoch: 276, train precision: 0.941867, train loss: 24.764914, valid precision: 0.751200, valid loss: 181.573667
epoch: 277, train precision: 0.937867, train loss: 27.177363, valid precision: 0.750000, valid loss: 197.910065
epoch: 278, train precision: 0.950556, train loss: 21.112482, valid precision: 0.758000, valid loss: 191.949670
epoch: 279, train precision: 0.952511, train loss: 20.262648, valid precision: 0.771400, valid loss: 186.313360
epoch: 280, train precision: 0.940133, train loss: 24.244975, valid precision: 0.752800, valid loss: 181.754391
epoch: 281, train precision: 0.939511, train loss: 25.570072, valid precision: 0.756600, valid loss: 186.056546
epoch: 282, train precision: 0.945289, train loss: 23.144716, valid precision: 0.755600, valid loss: 190.872657
epoch: 283, train precision: 0.941489, train loss: 25.049787, valid precision: 0.748800, valid loss: 184.831509
epoch: 284, train precision: 0.940422, train loss: 24.668687, valid precision: 0.756400, valid loss: 179.588414
epoch: 285, train precision: 0.930133, train loss: 30.726674, valid precision: 0.741800, valid loss: 203.580097
epoch: 286, train precision: 0.930244, train loss: 31.487168, valid precision: 0.748400, valid loss: 197.988536
epoch: 287, train precision: 0.943311, train loss: 24.287205, valid precision: 0.762400, valid loss: 182.872697
epoch: 288, train precision: 0.932911, train loss: 28.446590, valid precision: 0.756800, valid loss: 189.886112
epoch: 289, train precision: 0.933400, train loss: 28.884482, valid precision: 0.740600, valid loss: 203.551671
epoch: 290, train precision: 0.916111, train loss: 38.388728, valid precision: 0.748000, valid loss: 204.887198
epoch: 291, train precision: 0.945289, train loss: 23.434101, valid precision: 0.754800, valid loss: 204.042614
epoch: 292, train precision: 0.944111, train loss: 23.591908, valid precision: 0.754800, valid loss: 179.546764
epoch: 293, train precision: 0.933289, train loss: 29.408654, valid precision: 0.746400, valid loss: 206.864446
epoch: 294, train precision: 0.946244, train loss: 22.337942, valid precision: 0.747400, valid loss: 186.551930
epoch: 295, train precision: 0.913000, train loss: 39.546517, valid precision: 0.738400, valid loss: 190.552127
epoch: 296, train precision: 0.943311, train loss: 25.209621, valid precision: 0.751400, valid loss: 202.312329
epoch: 297, train precision: 0.942844, train loss: 25.183638, valid precision: 0.747800, valid loss: 201.575839
epoch: 298, train precision: 0.935089, train loss: 27.814941, valid precision: 0.753800, valid loss: 193.300508
epoch: 299, train precision: 0.928133, train loss: 31.380626, valid precision: 0.735200, valid loss: 203.365268
epoch: 300, train precision: 0.952467, train loss: 20.068424, valid precision: 0.763600, valid loss: 180.030105
epoch: 301, train precision: 0.946422, train loss: 22.120841, valid precision: 0.759400, valid loss: 183.969502
epoch: 302, train precision: 0.947933, train loss: 22.439074, valid precision: 0.764400, valid loss: 188.860994
epoch: 303, train precision: 0.929000, train loss: 29.737820, valid precision: 0.757800, valid loss: 182.560107
epoch: 304, train precision: 0.951822, train loss: 20.118240, valid precision: 0.757000, valid loss: 190.576005
epoch: 305, train precision: 0.923578, train loss: 33.031317, valid precision: 0.730600, valid loss: 201.461367
epoch: 306, train precision: 0.946244, train loss: 24.479396, valid precision: 0.760000, valid loss: 206.544355
epoch: 307, train precision: 0.942356, train loss: 25.237630, valid precision: 0.745800, valid loss: 199.093398
epoch: 308, train precision: 0.943667, train loss: 24.099916, valid precision: 0.751600, valid loss: 201.729509
epoch: 309, train precision: 0.945600, train loss: 23.271372, valid precision: 0.760400, valid loss: 192.263616
epoch: 310, train precision: 0.924200, train loss: 33.578359, valid precision: 0.739600, valid loss: 202.300519
epoch: 311, train precision: 0.951156, train loss: 21.342851, valid precision: 0.753200, valid loss: 199.182122
epoch: 312, train precision: 0.946644, train loss: 22.874057, valid precision: 0.762200, valid loss: 181.333201
epoch: 313, train precision: 0.946756, train loss: 22.615119, valid precision: 0.755200, valid loss: 185.958003
epoch: 314, train precision: 0.948911, train loss: 22.419448, valid precision: 0.754000, valid loss: 200.301172
epoch: 315, train precision: 0.931778, train loss: 29.853832, valid precision: 0.741000, valid loss: 189.668662
epoch: 316, train precision: 0.921822, train loss: 34.097082, valid precision: 0.733200, valid loss: 200.084661
epoch: 317, train precision: 0.940356, train loss: 27.652664, valid precision: 0.759800, valid loss: 200.709380
epoch: 318, train precision: 0.951267, train loss: 20.613139, valid precision: 0.765200, valid loss: 184.571327
epoch: 319, train precision: 0.949533, train loss: 22.181777, valid precision: 0.752600, valid loss: 209.422492
epoch: 320, train precision: 0.938778, train loss: 26.426155, valid precision: 0.757000, valid loss: 188.002661
epoch: 321, train precision: 0.927933, train loss: 29.971519, valid precision: 0.735600, valid loss: 186.254597
epoch: 322, train precision: 0.946044, train loss: 23.216854, valid precision: 0.761200, valid loss: 187.555482
epoch: 323, train precision: 0.946867, train loss: 22.410595, valid precision: 0.759800, valid loss: 199.367222
epoch: 324, train precision: 0.945333, train loss: 23.377327, valid precision: 0.751800, valid loss: 193.320218
epoch: 325, train precision: 0.945378, train loss: 22.937985, valid precision: 0.761200, valid loss: 189.407008
epoch: 326, train precision: 0.934022, train loss: 28.925340, valid precision: 0.745600, valid loss: 197.901958
epoch: 327, train precision: 0.938333, train loss: 27.299053, valid precision: 0.752600, valid loss: 204.507494
epoch: 328, train precision: 0.938422, train loss: 25.753265, valid precision: 0.751600, valid loss: 191.408638
epoch: 329, train precision: 0.951489, train loss: 20.610055, valid precision: 0.770800, valid loss: 205.697911
epoch: 330, train precision: 0.940156, train loss: 27.342223, valid precision: 0.758200, valid loss: 202.950342
epoch: 331, train precision: 0.955933, train loss: 19.211078, valid precision: 0.761800, valid loss: 199.902977
epoch: 332, train precision: 0.933067, train loss: 29.426339, valid precision: 0.743600, valid loss: 206.679484
epoch: 333, train precision: 0.956933, train loss: 17.912790, valid precision: 0.758600, valid loss: 189.943342
epoch: 334, train precision: 0.909422, train loss: 41.410156, valid precision: 0.732600, valid loss: 212.776600
epoch: 335, train precision: 0.936689, train loss: 27.895616, valid precision: 0.752400, valid loss: 213.553360
epoch: 336, train precision: 0.905622, train loss: 43.507096, valid precision: 0.723400, valid loss: 210.372732
epoch: 337, train precision: 0.924844, train loss: 33.287510, valid precision: 0.743800, valid loss: 203.756883
epoch: 338, train precision: 0.935489, train loss: 28.898283, valid precision: 0.746400, valid loss: 199.892111
epoch: 339, train precision: 0.930333, train loss: 30.321516, valid precision: 0.746600, valid loss: 189.198846
epoch: 340, train precision: 0.948156, train loss: 22.787234, valid precision: 0.761000, valid loss: 215.723908
epoch: 341, train precision: 0.935133, train loss: 30.101649, valid precision: 0.751400, valid loss: 217.652248
epoch: 342, train precision: 0.947378, train loss: 21.967661, valid precision: 0.758000, valid loss: 196.802555
epoch: 343, train precision: 0.942022, train loss: 27.213132, valid precision: 0.750800, valid loss: 222.227999
epoch: 344, train precision: 0.918467, train loss: 37.731079, valid precision: 0.740600, valid loss: 216.172296
epoch: 345, train precision: 0.938467, train loss: 28.270794, valid precision: 0.749200, valid loss: 225.605219
epoch: 346, train precision: 0.932644, train loss: 29.423699, valid precision: 0.743000, valid loss: 206.976605
epoch: 347, train precision: 0.913778, train loss: 41.743660, valid precision: 0.735000, valid loss: 211.530815
epoch: 348, train precision: 0.942978, train loss: 26.371587, valid precision: 0.749200, valid loss: 223.539424
epoch: 349, train precision: 0.928156, train loss: 33.707331, valid precision: 0.747400, valid loss: 215.101378
epoch: 350, train precision: 0.953289, train loss: 21.367327, valid precision: 0.766000, valid loss: 210.284218
epoch: 351, train precision: 0.936933, train loss: 29.406267, valid precision: 0.758000, valid loss: 208.621305
epoch: 352, train precision: 0.944778, train loss: 26.973119, valid precision: 0.758200, valid loss: 237.731189
epoch: 353, train precision: 0.952289, train loss: 21.839683, valid precision: 0.759600, valid loss: 223.460395
epoch: 354, train precision: 0.949311, train loss: 21.807268, valid precision: 0.763800, valid loss: 203.161689
epoch: 355, train precision: 0.928667, train loss: 31.352931, valid precision: 0.735400, valid loss: 202.165350
epoch: 356, train precision: 0.943489, train loss: 25.524037, valid precision: 0.758200, valid loss: 208.320218
epoch: 357, train precision: 0.950089, train loss: 22.113217, valid precision: 0.757000, valid loss: 206.651447
epoch: 358, train precision: 0.934667, train loss: 28.497678, valid precision: 0.752000, valid loss: 190.193429
epoch: 359, train precision: 0.911511, train loss: 41.568667, valid precision: 0.736000, valid loss: 201.525137
epoch: 360, train precision: 0.930733, train loss: 29.747643, valid precision: 0.745000, valid loss: 190.220199
epoch: 361, train precision: 0.956978, train loss: 18.968924, valid precision: 0.767600, valid loss: 202.549254
epoch: 362, train precision: 0.952756, train loss: 20.776304, valid precision: 0.774600, valid loss: 199.253123
epoch: 363, train precision: 0.918244, train loss: 39.759134, valid precision: 0.743600, valid loss: 217.566555
epoch: 364, train precision: 0.941133, train loss: 24.814414, valid precision: 0.756800, valid loss: 187.880746
epoch: 365, train precision: 0.934067, train loss: 30.023761, valid precision: 0.746600, valid loss: 204.571436
epoch: 366, train precision: 0.952867, train loss: 21.334268, valid precision: 0.759400, valid loss: 199.264352
epoch: 367, train precision: 0.931600, train loss: 31.454714, valid precision: 0.750000, valid loss: 204.847098
epoch: 368, train precision: 0.941044, train loss: 26.450813, valid precision: 0.752600, valid loss: 201.061473
epoch: 369, train precision: 0.959111, train loss: 17.248737, valid precision: 0.759200, valid loss: 193.019945
epoch: 370, train precision: 0.934444, train loss: 30.075568, valid precision: 0.744600, valid loss: 204.971767
epoch: 371, train precision: 0.925044, train loss: 34.292505, valid precision: 0.747000, valid loss: 209.339456
epoch: 372, train precision: 0.944622, train loss: 26.440972, valid precision: 0.750400, valid loss: 211.468777
epoch: 373, train precision: 0.939600, train loss: 26.670115, valid precision: 0.755200, valid loss: 188.230259
epoch: 374, train precision: 0.939511, train loss: 28.516073, valid precision: 0.752600, valid loss: 218.777764
epoch: 375, train precision: 0.940822, train loss: 25.885753, valid precision: 0.753000, valid loss: 194.408159
epoch: 376, train precision: 0.933889, train loss: 29.230256, valid precision: 0.749200, valid loss: 202.908026
epoch: 377, train precision: 0.952622, train loss: 20.908135, valid precision: 0.765000, valid loss: 197.111901
epoch: 378, train precision: 0.950511, train loss: 21.829519, valid precision: 0.755400, valid loss: 200.506244
epoch: 379, train precision: 0.941356, train loss: 26.158756, valid precision: 0.756000, valid loss: 181.511178
epoch: 380, train precision: 0.920644, train loss: 40.122014, valid precision: 0.751000, valid loss: 222.795437
epoch: 381, train precision: 0.933778, train loss: 30.844735, valid precision: 0.753800, valid loss: 215.339018
epoch: 382, train precision: 0.949244, train loss: 22.322630, valid precision: 0.761200, valid loss: 207.079134
epoch: 383, train precision: 0.945000, train loss: 26.088074, valid precision: 0.765000, valid loss: 213.605913
epoch: 384, train precision: 0.945000, train loss: 24.191240, valid precision: 0.753200, valid loss: 204.773805
epoch: 385, train precision: 0.936978, train loss: 27.452169, valid precision: 0.752400, valid loss: 192.382409
epoch: 386, train precision: 0.904800, train loss: 46.025515, valid precision: 0.723200, valid loss: 235.008084
epoch: 387, train precision: 0.932933, train loss: 29.392476, valid precision: 0.751800, valid loss: 194.600338
epoch: 388, train precision: 0.939933, train loss: 26.989727, valid precision: 0.743000, valid loss: 191.319293
epoch: 389, train precision: 0.938400, train loss: 29.274377, valid precision: 0.750400, valid loss: 229.236919
epoch: 390, train precision: 0.942178, train loss: 25.866601, valid precision: 0.754600, valid loss: 211.199750
epoch: 391, train precision: 0.941222, train loss: 26.332138, valid precision: 0.758800, valid loss: 192.293208
epoch: 392, train precision: 0.934000, train loss: 30.929523, valid precision: 0.741600, valid loss: 223.143422
epoch: 393, train precision: 0.939267, train loss: 27.630588, valid precision: 0.753200, valid loss: 218.486315
epoch: 394, train precision: 0.924089, train loss: 36.094390, valid precision: 0.743200, valid loss: 214.572369
epoch: 395, train precision: 0.945244, train loss: 24.913415, valid precision: 0.756400, valid loss: 209.411601
epoch: 396, train precision: 0.957667, train loss: 18.378155, valid precision: 0.759400, valid loss: 211.191875
epoch: 397, train precision: 0.937578, train loss: 30.514302, valid precision: 0.748800, valid loss: 231.225441
epoch: 398, train precision: 0.938444, train loss: 27.028458, valid precision: 0.742000, valid loss: 200.581423
epoch: 399, train precision: 0.927356, train loss: 31.502164, valid precision: 0.743000, valid loss: 186.485545
epoch: 400, train precision: 0.950911, train loss: 23.152957, valid precision: 0.766600, valid loss: 222.543409
epoch: 401, train precision: 0.940267, train loss: 27.378104, valid precision: 0.748800, valid loss: 219.028354
epoch: 402, train precision: 0.956089, train loss: 19.830482, valid precision: 0.769800, valid loss: 207.394430
epoch: 403, train precision: 0.928956, train loss: 33.638202, valid precision: 0.745000, valid loss: 221.441347
epoch: 404, train precision: 0.949489, train loss: 23.685634, valid precision: 0.764000, valid loss: 231.785898
epoch: 405, train precision: 0.944956, train loss: 25.512269, valid precision: 0.754800, valid loss: 216.708074
epoch: 406, train precision: 0.938444, train loss: 30.383096, valid precision: 0.747000, valid loss: 240.311421
epoch: 407, train precision: 0.938178, train loss: 28.481645, valid precision: 0.755800, valid loss: 196.822708
epoch: 408, train precision: 0.940689, train loss: 26.993331, valid precision: 0.750200, valid loss: 200.208649
epoch: 409, train precision: 0.919978, train loss: 37.517525, valid precision: 0.745000, valid loss: 209.250161
epoch: 410, train precision: 0.938200, train loss: 26.915908, valid precision: 0.746800, valid loss: 206.419679
epoch: 411, train precision: 0.946956, train loss: 24.609744, valid precision: 0.753200, valid loss: 223.070836
epoch: 412, train precision: 0.934578, train loss: 29.667107, valid precision: 0.739200, valid loss: 208.993317
epoch: 413, train precision: 0.940644, train loss: 25.770710, valid precision: 0.748800, valid loss: 205.422417
epoch: 414, train precision: 0.932489, train loss: 31.176258, valid precision: 0.746200, valid loss: 209.689815
epoch: 415, train precision: 0.935467, train loss: 28.519461, valid precision: 0.746800, valid loss: 199.803651
epoch: 416, train precision: 0.942378, train loss: 25.896556, valid precision: 0.754800, valid loss: 207.852348
epoch: 417, train precision: 0.918133, train loss: 35.672156, valid precision: 0.729200, valid loss: 210.351707
epoch: 418, train precision: 0.950467, train loss: 21.708017, valid precision: 0.755000, valid loss: 197.328918
epoch: 419, train precision: 0.925000, train loss: 34.000662, valid precision: 0.728600, valid loss: 215.172071
epoch: 420, train precision: 0.936022, train loss: 29.798375, valid precision: 0.753000, valid loss: 212.866825
epoch: 421, train precision: 0.941089, train loss: 27.885446, valid precision: 0.758800, valid loss: 211.568628
epoch: 422, train precision: 0.932644, train loss: 32.658426, valid precision: 0.745000, valid loss: 245.158939
epoch: 423, train precision: 0.923600, train loss: 35.423285, valid precision: 0.734800, valid loss: 236.121906
epoch: 424, train precision: 0.943711, train loss: 25.117535, valid precision: 0.753600, valid loss: 211.449548
epoch: 425, train precision: 0.919356, train loss: 38.374820, valid precision: 0.739200, valid loss: 235.511668
epoch: 426, train precision: 0.943311, train loss: 24.976220, valid precision: 0.755200, valid loss: 211.261660
epoch: 427, train precision: 0.937000, train loss: 29.405064, valid precision: 0.756000, valid loss: 213.914113
epoch: 428, train precision: 0.939756, train loss: 26.587631, valid precision: 0.761200, valid loss: 201.119936
epoch: 429, train precision: 0.931222, train loss: 33.637613, valid precision: 0.744600, valid loss: 238.724166
epoch: 430, train precision: 0.929800, train loss: 32.585473, valid precision: 0.753400, valid loss: 204.527116
epoch: 431, train precision: 0.954556, train loss: 20.337737, valid precision: 0.758200, valid loss: 215.644701
epoch: 432, train precision: 0.939733, train loss: 27.413181, valid precision: 0.752400, valid loss: 229.006689
epoch: 433, train precision: 0.925111, train loss: 37.201369, valid precision: 0.751400, valid loss: 234.162961
epoch: 434, train precision: 0.918267, train loss: 39.556482, valid precision: 0.737800, valid loss: 227.735651
epoch: 435, train precision: 0.949244, train loss: 22.973253, valid precision: 0.757400, valid loss: 224.153857
epoch: 436, train precision: 0.944733, train loss: 26.036047, valid precision: 0.750800, valid loss: 217.317425
epoch: 437, train precision: 0.945444, train loss: 24.476094, valid precision: 0.755400, valid loss: 217.591676
epoch: 438, train precision: 0.957489, train loss: 20.238705, valid precision: 0.765200, valid loss: 237.704638
epoch: 439, train precision: 0.954111, train loss: 20.818703, valid precision: 0.769000, valid loss: 231.034888
epoch: 440, train precision: 0.948689, train loss: 23.030375, valid precision: 0.761200, valid loss: 225.677782
epoch: 441, train precision: 0.941867, train loss: 27.800179, valid precision: 0.753600, valid loss: 256.359640
epoch: 442, train precision: 0.933444, train loss: 29.208956, valid precision: 0.753200, valid loss: 197.051300
epoch: 443, train precision: 0.941400, train loss: 27.406650, valid precision: 0.744400, valid loss: 230.188538
epoch: 444, train precision: 0.929556, train loss: 32.521526, valid precision: 0.750400, valid loss: 216.217808
epoch: 445, train precision: 0.932578, train loss: 33.887115, valid precision: 0.751200, valid loss: 236.543754
epoch: 446, train precision: 0.927644, train loss: 33.761155, valid precision: 0.755200, valid loss: 210.656790
epoch: 447, train precision: 0.944600, train loss: 25.862114, valid precision: 0.752000, valid loss: 211.972109
epoch: 448, train precision: 0.937444, train loss: 28.192838, valid precision: 0.754000, valid loss: 203.518952
epoch: 449, train precision: 0.929778, train loss: 32.538644, valid precision: 0.753400, valid loss: 204.471374
epoch: 450, train precision: 0.954600, train loss: 20.944031, valid precision: 0.757200, valid loss: 226.363855
epoch: 451, train precision: 0.935867, train loss: 31.840778, valid precision: 0.756000, valid loss: 233.215576
epoch: 452, train precision: 0.922578, train loss: 36.043644, valid precision: 0.745800, valid loss: 212.266217
epoch: 453, train precision: 0.917911, train loss: 42.773713, valid precision: 0.741800, valid loss: 241.640328
epoch: 454, train precision: 0.952822, train loss: 21.478007, valid precision: 0.765200, valid loss: 194.511642
epoch: 455, train precision: 0.933444, train loss: 30.954265, valid precision: 0.752600, valid loss: 205.475838
epoch: 456, train precision: 0.948444, train loss: 23.589483, valid precision: 0.756800, valid loss: 216.481894
epoch: 457, train precision: 0.936089, train loss: 30.546286, valid precision: 0.743200, valid loss: 221.811295
epoch: 458, train precision: 0.926000, train loss: 33.746045, valid precision: 0.746200, valid loss: 206.707992
epoch: 459, train precision: 0.930933, train loss: 34.754689, valid precision: 0.753000, valid loss: 242.742105
epoch: 460, train precision: 0.920667, train loss: 35.073306, valid precision: 0.742200, valid loss: 197.984138
epoch: 461, train precision: 0.949222, train loss: 23.754433, valid precision: 0.762000, valid loss: 227.915657
epoch: 462, train precision: 0.935400, train loss: 29.144406, valid precision: 0.758600, valid loss: 204.448759
epoch: 463, train precision: 0.932444, train loss: 29.861398, valid precision: 0.753000, valid loss: 211.283392
epoch: 464, train precision: 0.935378, train loss: 28.809125, valid precision: 0.750200, valid loss: 210.110973
epoch: 465, train precision: 0.949689, train loss: 23.685791, valid precision: 0.763000, valid loss: 223.820711
epoch: 466, train precision: 0.948400, train loss: 23.342076, valid precision: 0.748200, valid loss: 214.595799
epoch: 467, train precision: 0.953022, train loss: 20.832486, valid precision: 0.753000, valid loss: 206.587182
epoch: 468, train precision: 0.904222, train loss: 46.015001, valid precision: 0.733200, valid loss: 210.037943
epoch: 469, train precision: 0.930067, train loss: 32.800056, valid precision: 0.752800, valid loss: 200.408478
epoch: 470, train precision: 0.931311, train loss: 33.485983, valid precision: 0.749600, valid loss: 216.062481
epoch: 471, train precision: 0.941844, train loss: 26.405769, valid precision: 0.752400, valid loss: 193.350098
epoch: 472, train precision: 0.941356, train loss: 26.881057, valid precision: 0.751000, valid loss: 225.803862
epoch: 473, train precision: 0.949000, train loss: 23.371841, valid precision: 0.756600, valid loss: 218.541696
epoch: 474, train precision: 0.914133, train loss: 39.440595, valid precision: 0.735200, valid loss: 210.476430
epoch: 475, train precision: 0.956689, train loss: 20.607295, valid precision: 0.758400, valid loss: 232.855500
epoch: 476, train precision: 0.933489, train loss: 33.726040, valid precision: 0.742200, valid loss: 236.336971
epoch: 477, train precision: 0.950067, train loss: 24.763207, valid precision: 0.756400, valid loss: 244.358793
epoch: 478, train precision: 0.945067, train loss: 26.462391, valid precision: 0.746600, valid loss: 224.338996
epoch: 479, train precision: 0.944600, train loss: 25.803345, valid precision: 0.755200, valid loss: 235.949604
epoch: 480, train precision: 0.920289, train loss: 40.160970, valid precision: 0.743600, valid loss: 239.850158
epoch: 481, train precision: 0.931533, train loss: 32.723025, valid precision: 0.750000, valid loss: 208.177855
epoch: 482, train precision: 0.945556, train loss: 25.751839, valid precision: 0.755600, valid loss: 223.198734
epoch: 483, train precision: 0.950022, train loss: 25.650361, valid precision: 0.751400, valid loss: 268.247205
epoch: 484, train precision: 0.922156, train loss: 35.507079, valid precision: 0.743600, valid loss: 214.260251
epoch: 485, train precision: 0.950644, train loss: 22.770001, valid precision: 0.753400, valid loss: 233.769659
epoch: 486, train precision: 0.945800, train loss: 26.927442, valid precision: 0.760200, valid loss: 215.169144
epoch: 487, train precision: 0.935756, train loss: 28.824269, valid precision: 0.753600, valid loss: 213.651643
epoch: 488, train precision: 0.939222, train loss: 28.130009, valid precision: 0.754800, valid loss: 228.440066
epoch: 489, train precision: 0.930067, train loss: 33.593249, valid precision: 0.749400, valid loss: 223.521464
epoch: 490, train precision: 0.945244, train loss: 25.427140, valid precision: 0.754000, valid loss: 211.932263
epoch: 491, train precision: 0.939289, train loss: 29.302667, valid precision: 0.752600, valid loss: 228.142770
epoch: 492, train precision: 0.947178, train loss: 23.783207, valid precision: 0.752400, valid loss: 225.891707
epoch: 493, train precision: 0.944422, train loss: 25.608049, valid precision: 0.761800, valid loss: 203.410756
epoch: 494, train precision: 0.936311, train loss: 28.997078, valid precision: 0.756400, valid loss: 195.974288
epoch: 495, train precision: 0.921311, train loss: 38.316758, valid precision: 0.745200, valid loss: 222.848582
epoch: 496, train precision: 0.949133, train loss: 22.982229, valid precision: 0.758600, valid loss: 210.591940
epoch: 497, train precision: 0.940467, train loss: 26.870996, valid precision: 0.753200, valid loss: 202.067184
epoch: 498, train precision: 0.917778, train loss: 39.519996, valid precision: 0.741600, valid loss: 221.819573
epoch: 499, train precision: 0.949822, train loss: 24.858573, valid precision: 0.765600, valid loss: 228.696760
epoch: 500, train precision: 0.925133, train loss: 35.647833, valid precision: 0.742000, valid loss: 219.969338
epoch: 501, train precision: 0.942711, train loss: 26.652888, valid precision: 0.750000, valid loss: 228.370494
epoch: 502, train precision: 0.950689, train loss: 22.930884, valid precision: 0.756800, valid loss: 238.828680
epoch: 503, train precision: 0.938333, train loss: 31.058322, valid precision: 0.749800, valid loss: 238.485486
epoch: 504, train precision: 0.945511, train loss: 25.678878, valid precision: 0.751600, valid loss: 228.884016
epoch: 505, train precision: 0.945867, train loss: 25.672976, valid precision: 0.757200, valid loss: 229.064594
epoch: 506, train precision: 0.933400, train loss: 31.123341, valid precision: 0.745400, valid loss: 208.932098
epoch: 507, train precision: 0.937667, train loss: 29.205404, valid precision: 0.758200, valid loss: 210.273931
epoch: 508, train precision: 0.937533, train loss: 30.862796, valid precision: 0.753200, valid loss: 247.099738
epoch: 509, train precision: 0.942444, train loss: 27.367035, valid precision: 0.748800, valid loss: 229.933435
epoch: 510, train precision: 0.952667, train loss: 21.933909, valid precision: 0.763400, valid loss: 237.424314
epoch: 511, train precision: 0.930156, train loss: 32.948714, valid precision: 0.747200, valid loss: 230.653387
epoch: 512, train precision: 0.950978, train loss: 26.806735, valid precision: 0.759600, valid loss: 286.583444
epoch: 513, train precision: 0.950200, train loss: 23.441796, valid precision: 0.756800, valid loss: 235.307719
epoch: 514, train precision: 0.940889, train loss: 28.335369, valid precision: 0.756000, valid loss: 225.155014
epoch: 515, train precision: 0.942044, train loss: 29.701552, valid precision: 0.757400, valid loss: 242.018412
epoch: 516, train precision: 0.953867, train loss: 20.803544, valid precision: 0.760600, valid loss: 213.570167
epoch: 517, train precision: 0.943867, train loss: 25.519822, valid precision: 0.760600, valid loss: 220.118979
epoch: 518, train precision: 0.917133, train loss: 40.014013, valid precision: 0.747000, valid loss: 219.735489
epoch: 519, train precision: 0.952578, train loss: 21.949867, valid precision: 0.761600, valid loss: 232.274297
epoch: 520, train precision: 0.940067, train loss: 29.106808, valid precision: 0.750600, valid loss: 238.501822
epoch: 521, train precision: 0.946911, train loss: 25.765213, valid precision: 0.762200, valid loss: 230.745508
epoch: 522, train precision: 0.951022, train loss: 24.009830, valid precision: 0.760000, valid loss: 238.754655
epoch: 523, train precision: 0.952533, train loss: 24.065870, valid precision: 0.755400, valid loss: 272.329636
epoch: 524, train precision: 0.933956, train loss: 30.740042, valid precision: 0.755800, valid loss: 217.732167
epoch: 525, train precision: 0.936222, train loss: 29.492282, valid precision: 0.761600, valid loss: 220.295132
epoch: 526, train precision: 0.940844, train loss: 29.855973, valid precision: 0.749800, valid loss: 249.954905
epoch: 527, train precision: 0.901622, train loss: 46.338382, valid precision: 0.730400, valid loss: 205.121446
epoch: 528, train precision: 0.937156, train loss: 30.061049, valid precision: 0.750400, valid loss: 228.437841
epoch: 529, train precision: 0.917800, train loss: 37.149455, valid precision: 0.743400, valid loss: 207.362620
epoch: 530, train precision: 0.944644, train loss: 25.806350, valid precision: 0.761400, valid loss: 212.020384
epoch: 531, train precision: 0.920711, train loss: 37.887895, valid precision: 0.745200, valid loss: 204.757973
epoch: 532, train precision: 0.944467, train loss: 30.085235, valid precision: 0.760600, valid loss: 258.482519
epoch: 533, train precision: 0.956356, train loss: 20.139249, valid precision: 0.769400, valid loss: 221.401953
epoch: 534, train precision: 0.925933, train loss: 38.220962, valid precision: 0.744800, valid loss: 239.114276
epoch: 535, train precision: 0.950111, train loss: 25.193878, valid precision: 0.758800, valid loss: 250.703864
epoch: 536, train precision: 0.944911, train loss: 25.889389, valid precision: 0.764000, valid loss: 200.194764
epoch: 537, train precision: 0.912022, train loss: 42.266183, valid precision: 0.742800, valid loss: 218.194510
epoch: 538, train precision: 0.925644, train loss: 33.265903, valid precision: 0.747800, valid loss: 205.208415
epoch: 539, train precision: 0.922444, train loss: 38.056989, valid precision: 0.742800, valid loss: 247.343795
epoch: 540, train precision: 0.928289, train loss: 33.498592, valid precision: 0.745400, valid loss: 215.480826
epoch: 541, train precision: 0.931733, train loss: 34.402945, valid precision: 0.745000, valid loss: 248.064397
epoch: 542, train precision: 0.936956, train loss: 29.510976, valid precision: 0.755800, valid loss: 222.767700
epoch: 543, train precision: 0.951800, train loss: 22.398521, valid precision: 0.763400, valid loss: 229.126860
epoch: 544, train precision: 0.941644, train loss: 26.709381, valid precision: 0.759000, valid loss: 220.510513
epoch: 545, train precision: 0.938222, train loss: 29.610436, valid precision: 0.756200, valid loss: 211.778731
epoch: 546, train precision: 0.932933, train loss: 31.905938, valid precision: 0.753600, valid loss: 211.128996
epoch: 547, train precision: 0.939822, train loss: 29.302088, valid precision: 0.754600, valid loss: 233.172175
epoch: 548, train precision: 0.923689, train loss: 38.565651, valid precision: 0.745200, valid loss: 229.968256
epoch: 549, train precision: 0.936667, train loss: 28.836985, valid precision: 0.752800, valid loss: 216.713197
epoch: 550, train precision: 0.918333, train loss: 40.823495, valid precision: 0.742800, valid loss: 227.855667
epoch: 551, train precision: 0.935711, train loss: 32.008418, valid precision: 0.743000, valid loss: 256.411302
epoch: 552, train precision: 0.939667, train loss: 29.732506, valid precision: 0.744200, valid loss: 249.514048
epoch: 553, train precision: 0.940667, train loss: 28.966960, valid precision: 0.746200, valid loss: 255.196189
epoch: 554, train precision: 0.948156, train loss: 25.130839, valid precision: 0.760200, valid loss: 255.397947
epoch: 555, train precision: 0.943444, train loss: 26.033896, valid precision: 0.765200, valid loss: 211.446431
epoch: 556, train precision: 0.913467, train loss: 43.607168, valid precision: 0.742400, valid loss: 245.088026
epoch: 557, train precision: 0.922200, train loss: 41.224629, valid precision: 0.741200, valid loss: 261.418565
epoch: 558, train precision: 0.941822, train loss: 26.437841, valid precision: 0.749200, valid loss: 218.549938
epoch: 559, train precision: 0.939556, train loss: 29.485266, valid precision: 0.751000, valid loss: 243.301795
epoch: 560, train precision: 0.935356, train loss: 30.263432, valid precision: 0.745800, valid loss: 231.178377
epoch: 561, train precision: 0.915778, train loss: 45.087243, valid precision: 0.743800, valid loss: 262.538649
epoch: 562, train precision: 0.929244, train loss: 36.231516, valid precision: 0.746600, valid loss: 238.290740
epoch: 563, train precision: 0.916133, train loss: 40.005564, valid precision: 0.748600, valid loss: 205.640846
epoch: 564, train precision: 0.912489, train loss: 44.741303, valid precision: 0.752600, valid loss: 229.060949
epoch: 565, train precision: 0.949800, train loss: 24.529609, valid precision: 0.765800, valid loss: 236.863598
epoch: 566, train precision: 0.918756, train loss: 40.385455, valid precision: 0.744800, valid loss: 233.744888
epoch: 567, train precision: 0.934911, train loss: 31.057464, valid precision: 0.750800, valid loss: 220.971730
epoch: 568, train precision: 0.952422, train loss: 23.051800, valid precision: 0.766800, valid loss: 234.335498
epoch: 569, train precision: 0.953711, train loss: 22.252993, valid precision: 0.771600, valid loss: 247.092636
epoch: 570, train precision: 0.938911, train loss: 27.383610, valid precision: 0.750200, valid loss: 209.859204
epoch: 571, train precision: 0.935000, train loss: 30.260830, valid precision: 0.754200, valid loss: 224.604752
epoch: 572, train precision: 0.922711, train loss: 37.808117, valid precision: 0.747400, valid loss: 223.124571
epoch: 573, train precision: 0.947911, train loss: 25.545991, valid precision: 0.757000, valid loss: 260.877873
epoch: 574, train precision: 0.937156, train loss: 31.766685, valid precision: 0.751200, valid loss: 244.426007
epoch: 575, train precision: 0.892244, train loss: 58.505019, valid precision: 0.736000, valid loss: 243.782784
epoch: 576, train precision: 0.926467, train loss: 34.716204, valid precision: 0.753400, valid loss: 196.945918
epoch: 577, train precision: 0.942156, train loss: 27.567541, valid precision: 0.755000, valid loss: 228.553228
epoch: 578, train precision: 0.939733, train loss: 29.348098, valid precision: 0.760000, valid loss: 218.694584
epoch: 579, train precision: 0.942889, train loss: 29.218099, valid precision: 0.761400, valid loss: 235.807013
epoch: 580, train precision: 0.929044, train loss: 36.036467, valid precision: 0.753800, valid loss: 229.574363
epoch: 581, train precision: 0.904422, train loss: 49.898925, valid precision: 0.732800, valid loss: 251.908011
epoch: 582, train precision: 0.936644, train loss: 29.359794, valid precision: 0.758000, valid loss: 214.765536
epoch: 583, train precision: 0.941200, train loss: 27.402700, valid precision: 0.750200, valid loss: 218.003043
epoch: 584, train precision: 0.944711, train loss: 26.582791, valid precision: 0.765200, valid loss: 235.583329
epoch: 585, train precision: 0.939400, train loss: 31.366330, valid precision: 0.772000, valid loss: 232.165799
epoch: 586, train precision: 0.936600, train loss: 35.553427, valid precision: 0.760400, valid loss: 253.108451
epoch: 587, train precision: 0.880444, train loss: 62.502926, valid precision: 0.721600, valid loss: 237.677473
epoch: 588, train precision: 0.950378, train loss: 24.647187, valid precision: 0.764000, valid loss: 236.805838
epoch: 589, train precision: 0.944978, train loss: 26.504942, valid precision: 0.760800, valid loss: 239.435144
epoch: 590, train precision: 0.915644, train loss: 40.401857, valid precision: 0.738800, valid loss: 232.353282
epoch: 591, train precision: 0.918711, train loss: 43.544874, valid precision: 0.752600, valid loss: 254.496490
epoch: 592, train precision: 0.911289, train loss: 49.290705, valid precision: 0.741000, valid loss: 269.422574
epoch: 593, train precision: 0.930333, train loss: 36.382696, valid precision: 0.750800, valid loss: 265.616056
epoch: 594, train precision: 0.933644, train loss: 37.105068, valid precision: 0.755600, valid loss: 264.223253
epoch: 595, train precision: 0.933778, train loss: 31.240557, valid precision: 0.752200, valid loss: 215.696136
epoch: 596, train precision: 0.958133, train loss: 20.978512, valid precision: 0.758800, valid loss: 255.223527
epoch: 597, train precision: 0.948844, train loss: 25.976746, valid precision: 0.758800, valid loss: 266.518938
epoch: 598, train precision: 0.938978, train loss: 34.813142, valid precision: 0.762400, valid loss: 274.720065
epoch: 599, train precision: 0.930667, train loss: 36.849004, valid precision: 0.749400, valid loss: 255.578391
epoch: 600, train precision: 0.921711, train loss: 43.851825, valid precision: 0.742800, valid loss: 274.840474
epoch: 601, train precision: 0.924911, train loss: 38.888398, valid precision: 0.748000, valid loss: 258.322258
epoch: 602, train precision: 0.940156, train loss: 29.456211, valid precision: 0.753600, valid loss: 237.098323
epoch: 603, train precision: 0.935533, train loss: 35.527736, valid precision: 0.751400, valid loss: 271.648929
epoch: 604, train precision: 0.945933, train loss: 25.867643, valid precision: 0.757600, valid loss: 223.630715
epoch: 605, train precision: 0.931778, train loss: 32.534434, valid precision: 0.751400, valid loss: 209.473428
epoch: 606, train precision: 0.951000, train loss: 24.325896, valid precision: 0.763600, valid loss: 253.597994
epoch: 607, train precision: 0.948578, train loss: 26.731969, valid precision: 0.759600, valid loss: 272.218002
epoch: 608, train precision: 0.933689, train loss: 32.110723, valid precision: 0.744400, valid loss: 240.558400
epoch: 609, train precision: 0.920333, train loss: 39.559882, valid precision: 0.751200, valid loss: 226.977612
epoch: 610, train precision: 0.919289, train loss: 37.230043, valid precision: 0.743200, valid loss: 202.282822
epoch: 611, train precision: 0.926822, train loss: 35.244327, valid precision: 0.741400, valid loss: 218.928972
epoch: 612, train precision: 0.932978, train loss: 31.337970, valid precision: 0.750200, valid loss: 209.328271
epoch: 613, train precision: 0.940044, train loss: 27.974696, valid precision: 0.752400, valid loss: 221.172243
epoch: 614, train precision: 0.922689, train loss: 37.696607, valid precision: 0.736200, valid loss: 234.765707
epoch: 615, train precision: 0.907889, train loss: 46.477709, valid precision: 0.729600, valid loss: 227.942528
epoch: 616, train precision: 0.935200, train loss: 30.503604, valid precision: 0.755000, valid loss: 211.482001
epoch: 617, train precision: 0.944756, train loss: 28.203382, valid precision: 0.764000, valid loss: 262.385197
epoch: 618, train precision: 0.930622, train loss: 39.521965, valid precision: 0.750200, valid loss: 268.572270
epoch: 619, train precision: 0.939867, train loss: 28.845522, valid precision: 0.747400, valid loss: 237.960851
epoch: 620, train precision: 0.917956, train loss: 39.035813, valid precision: 0.746200, valid loss: 197.849356
epoch: 621, train precision: 0.906156, train loss: 45.097488, valid precision: 0.744000, valid loss: 215.791011
epoch: 622, train precision: 0.929422, train loss: 34.638658, valid precision: 0.741000, valid loss: 236.246954
epoch: 623, train precision: 0.943311, train loss: 30.346219, valid precision: 0.753400, valid loss: 271.670254
epoch: 624, train precision: 0.938578, train loss: 31.395755, valid precision: 0.757600, valid loss: 239.204159
epoch: 625, train precision: 0.938867, train loss: 31.724625, valid precision: 0.758000, valid loss: 255.340329
epoch: 626, train precision: 0.932178, train loss: 34.585918, valid precision: 0.743200, valid loss: 247.806138
epoch: 627, train precision: 0.934422, train loss: 33.611421, valid precision: 0.752200, valid loss: 227.429741
epoch: 628, train precision: 0.903089, train loss: 49.496432, valid precision: 0.738800, valid loss: 230.087025
epoch: 629, train precision: 0.924089, train loss: 40.320290, valid precision: 0.743800, valid loss: 243.804003
epoch: 630, train precision: 0.926533, train loss: 36.510445, valid precision: 0.739800, valid loss: 248.366715
epoch: 631, train precision: 0.918111, train loss: 38.634750, valid precision: 0.742800, valid loss: 206.814018
epoch: 632, train precision: 0.921467, train loss: 35.798217, valid precision: 0.747600, valid loss: 195.595981
epoch: 633, train precision: 0.920956, train loss: 37.784673, valid precision: 0.747600, valid loss: 222.342713
epoch: 634, train precision: 0.904156, train loss: 54.718623, valid precision: 0.735000, valid loss: 261.999219
epoch: 635, train precision: 0.932711, train loss: 35.459689, valid precision: 0.753600, valid loss: 258.589932
epoch: 636, train precision: 0.938133, train loss: 30.396120, valid precision: 0.754400, valid loss: 239.349577
epoch: 637, train precision: 0.910822, train loss: 44.715349, valid precision: 0.726000, valid loss: 228.357608
epoch: 638, train precision: 0.913178, train loss: 44.880107, valid precision: 0.741000, valid loss: 232.885729
epoch: 639, train precision: 0.939044, train loss: 27.955797, valid precision: 0.759800, valid loss: 224.871069
epoch: 640, train precision: 0.944667, train loss: 27.621878, valid precision: 0.764000, valid loss: 246.285961
epoch: 641, train precision: 0.915533, train loss: 42.257125, valid precision: 0.742800, valid loss: 263.043190
epoch: 642, train precision: 0.950733, train loss: 24.741737, valid precision: 0.756400, valid loss: 256.884983
epoch: 643, train precision: 0.928911, train loss: 33.255890, valid precision: 0.747200, valid loss: 218.400664
epoch: 644, train precision: 0.924600, train loss: 37.736968, valid precision: 0.748800, valid loss: 236.162696
epoch: 645, train precision: 0.931467, train loss: 35.625433, valid precision: 0.754400, valid loss: 258.464444
epoch: 646, train precision: 0.921711, train loss: 36.103495, valid precision: 0.760200, valid loss: 196.959509
epoch: 647, train precision: 0.930222, train loss: 40.562909, valid precision: 0.753600, valid loss: 310.905694
epoch: 648, train precision: 0.919333, train loss: 39.279651, valid precision: 0.745600, valid loss: 218.549950
epoch: 649, train precision: 0.917889, train loss: 43.904747, valid precision: 0.748400, valid loss: 246.939883
epoch: 650, train precision: 0.954067, train loss: 22.894462, valid precision: 0.763000, valid loss: 258.414686
epoch: 651, train precision: 0.914778, train loss: 40.187368, valid precision: 0.742000, valid loss: 215.559412
epoch: 652, train precision: 0.877556, train loss: 64.512492, valid precision: 0.724200, valid loss: 234.464619
epoch: 653, train precision: 0.929622, train loss: 35.412071, valid precision: 0.754600, valid loss: 235.195951
epoch: 654, train precision: 0.940867, train loss: 29.698157, valid precision: 0.755200, valid loss: 256.336442
epoch: 655, train precision: 0.929133, train loss: 33.149354, valid precision: 0.742600, valid loss: 253.834842
epoch: 656, train precision: 0.935733, train loss: 32.501950, valid precision: 0.753200, valid loss: 262.822329
epoch: 657, train precision: 0.944089, train loss: 26.248416, valid precision: 0.763800, valid loss: 230.302027
epoch: 658, train precision: 0.945533, train loss: 27.529011, valid precision: 0.764000, valid loss: 268.812109
epoch: 659, train precision: 0.928644, train loss: 36.308092, valid precision: 0.755800, valid loss: 252.995527
epoch: 660, train precision: 0.940867, train loss: 30.539565, valid precision: 0.756200, valid loss: 274.409473
epoch: 661, train precision: 0.946222, train loss: 28.519096, valid precision: 0.762200, valid loss: 277.339188
epoch: 662, train precision: 0.928178, train loss: 34.409510, valid precision: 0.752000, valid loss: 224.289862
epoch: 663, train precision: 0.925578, train loss: 35.052513, valid precision: 0.751000, valid loss: 215.127916
epoch: 664, train precision: 0.907578, train loss: 50.754184, valid precision: 0.745000, valid loss: 263.622640
epoch: 665, train precision: 0.932422, train loss: 33.010227, valid precision: 0.753400, valid loss: 225.611332
epoch: 666, train precision: 0.918644, train loss: 42.657998, valid precision: 0.735600, valid loss: 264.955159
epoch: 667, train precision: 0.929044, train loss: 36.390772, valid precision: 0.747800, valid loss: 259.071804
epoch: 668, train precision: 0.941933, train loss: 27.755873, valid precision: 0.754800, valid loss: 225.752795
epoch: 669, train precision: 0.916933, train loss: 45.298241, valid precision: 0.730800, valid loss: 282.116130
epoch: 670, train precision: 0.937867, train loss: 30.164362, valid precision: 0.753200, valid loss: 235.929959
epoch: 671, train precision: 0.894022, train loss: 52.000027, valid precision: 0.723400, valid loss: 230.110660
epoch: 672, train precision: 0.933067, train loss: 31.738004, valid precision: 0.743400, valid loss: 240.844664
epoch: 673, train precision: 0.948422, train loss: 24.947242, valid precision: 0.754400, valid loss: 254.210090
epoch: 674, train precision: 0.914333, train loss: 44.451311, valid precision: 0.744400, valid loss: 255.467591
epoch: 675, train precision: 0.905822, train loss: 46.492170, valid precision: 0.743400, valid loss: 223.004255
epoch: 676, train precision: 0.943156, train loss: 29.897004, valid precision: 0.760200, valid loss: 272.209541
epoch: 677, train precision: 0.937756, train loss: 30.301099, valid precision: 0.756000, valid loss: 249.504918
epoch: 678, train precision: 0.934711, train loss: 35.533035, valid precision: 0.749400, valid loss: 290.265699
epoch: 679, train precision: 0.943489, train loss: 30.748771, valid precision: 0.761800, valid loss: 267.660213
epoch: 680, train precision: 0.929067, train loss: 34.369458, valid precision: 0.749600, valid loss: 235.467932
epoch: 681, train precision: 0.951489, train loss: 26.974455, valid precision: 0.766600, valid loss: 284.813879
epoch: 682, train precision: 0.920600, train loss: 44.675272, valid precision: 0.746600, valid loss: 269.865548
epoch: 683, train precision: 0.919867, train loss: 40.475724, valid precision: 0.750200, valid loss: 246.789134
epoch: 684, train precision: 0.946889, train loss: 27.037508, valid precision: 0.762600, valid loss: 268.206999
epoch: 685, train precision: 0.873778, train loss: 69.052640, valid precision: 0.724200, valid loss: 243.950897
epoch: 686, train precision: 0.924978, train loss: 34.951697, valid precision: 0.752600, valid loss: 227.594878
epoch: 687, train precision: 0.936733, train loss: 30.376477, valid precision: 0.756200, valid loss: 241.206434
epoch: 688, train precision: 0.935978, train loss: 34.218124, valid precision: 0.752000, valid loss: 273.886444
epoch: 689, train precision: 0.903867, train loss: 42.491376, valid precision: 0.737400, valid loss: 192.400945
epoch: 690, train precision: 0.934600, train loss: 32.753618, valid precision: 0.752400, valid loss: 257.069789
epoch: 691, train precision: 0.933711, train loss: 30.826607, valid precision: 0.758600, valid loss: 221.912056
epoch: 692, train precision: 0.902200, train loss: 51.178401, valid precision: 0.736600, valid loss: 252.547149
epoch: 693, train precision: 0.899911, train loss: 45.102943, valid precision: 0.733200, valid loss: 208.878263
epoch: 694, train precision: 0.922822, train loss: 39.844032, valid precision: 0.752200, valid loss: 241.613493
epoch: 695, train precision: 0.925378, train loss: 34.977996, valid precision: 0.759200, valid loss: 201.267304
epoch: 696, train precision: 0.904067, train loss: 60.351300, valid precision: 0.736200, valid loss: 305.682202
epoch: 697, train precision: 0.919422, train loss: 40.670429, valid precision: 0.742600, valid loss: 247.397831
epoch: 698, train precision: 0.918044, train loss: 39.183481, valid precision: 0.746800, valid loss: 223.411224
epoch: 699, train precision: 0.922622, train loss: 36.786146, valid precision: 0.750000, valid loss: 238.082717
epoch: 700, train precision: 0.939622, train loss: 30.232840, valid precision: 0.751800, valid loss: 242.821462
epoch: 701, train precision: 0.884533, train loss: 61.140314, valid precision: 0.724600, valid loss: 268.549712
epoch: 702, train precision: 0.933911, train loss: 32.319065, valid precision: 0.758600, valid loss: 236.210661
epoch: 703, train precision: 0.936267, train loss: 31.296072, valid precision: 0.758000, valid loss: 258.746940
epoch: 704, train precision: 0.911400, train loss: 44.974163, valid precision: 0.743400, valid loss: 251.740182
epoch: 705, train precision: 0.934467, train loss: 33.962644, valid precision: 0.757600, valid loss: 285.777479
epoch: 706, train precision: 0.939689, train loss: 30.403999, valid precision: 0.754000, valid loss: 284.172683
epoch: 707, train precision: 0.908356, train loss: 49.160490, valid precision: 0.733200, valid loss: 265.676387
epoch: 708, train precision: 0.935200, train loss: 36.320095, valid precision: 0.761600, valid loss: 283.659715
epoch: 709, train precision: 0.935333, train loss: 34.069717, valid precision: 0.757000, valid loss: 273.511271
epoch: 710, train precision: 0.927844, train loss: 36.518751, valid precision: 0.751200, valid loss: 256.361197
epoch: 711, train precision: 0.938889, train loss: 29.976027, valid precision: 0.760200, valid loss: 251.205274
epoch: 712, train precision: 0.929089, train loss: 34.488878, valid precision: 0.755600, valid loss: 256.748684
epoch: 713, train precision: 0.922756, train loss: 36.299456, valid precision: 0.747000, valid loss: 231.165443
epoch: 714, train precision: 0.935867, train loss: 31.491622, valid precision: 0.756000, valid loss: 241.741709
epoch: 715, train precision: 0.923844, train loss: 38.095262, valid precision: 0.750400, valid loss: 239.054218
epoch: 716, train precision: 0.924044, train loss: 38.383438, valid precision: 0.752800, valid loss: 242.394547
epoch: 717, train precision: 0.881867, train loss: 57.598519, valid precision: 0.726400, valid loss: 221.399916
epoch: 718, train precision: 0.924689, train loss: 35.858334, valid precision: 0.755600, valid loss: 241.324568
epoch: 719, train precision: 0.918622, train loss: 44.464370, valid precision: 0.753800, valid loss: 264.281522
epoch: 720, train precision: 0.908556, train loss: 44.285619, valid precision: 0.734200, valid loss: 239.846691
epoch: 721, train precision: 0.931756, train loss: 38.129891, valid precision: 0.757400, valid loss: 290.449139
epoch: 722, train precision: 0.930622, train loss: 39.397897, valid precision: 0.757200, valid loss: 285.735903
epoch: 723, train precision: 0.931689, train loss: 38.575064, valid precision: 0.756000, valid loss: 306.473004
epoch: 724, train precision: 0.868622, train loss: 69.504514, valid precision: 0.726200, valid loss: 239.329071
epoch: 725, train precision: 0.909556, train loss: 48.970857, valid precision: 0.737000, valid loss: 259.190035
epoch: 726, train precision: 0.936111, train loss: 33.098809, valid precision: 0.749800, valid loss: 281.920854
epoch: 727, train precision: 0.897556, train loss: 49.639946, valid precision: 0.748000, valid loss: 229.030474
epoch: 728, train precision: 0.922067, train loss: 37.797654, valid precision: 0.751000, valid loss: 230.838502
epoch: 729, train precision: 0.921778, train loss: 38.062997, valid precision: 0.745600, valid loss: 256.298261
epoch: 730, train precision: 0.897333, train loss: 47.967575, valid precision: 0.735400, valid loss: 223.358026
epoch: 731, train precision: 0.931956, train loss: 35.126939, valid precision: 0.741000, valid loss: 254.274747
epoch: 732, train precision: 0.910711, train loss: 42.850749, valid precision: 0.733600, valid loss: 226.862006
epoch: 733, train precision: 0.932978, train loss: 37.601570, valid precision: 0.759200, valid loss: 298.002700
epoch: 734, train precision: 0.931022, train loss: 36.913703, valid precision: 0.752000, valid loss: 296.933907
epoch: 735, train precision: 0.939000, train loss: 33.245281, valid precision: 0.759400, valid loss: 273.867053
epoch: 736, train precision: 0.916133, train loss: 43.109667, valid precision: 0.749200, valid loss: 255.350035
epoch: 737, train precision: 0.928778, train loss: 36.306704, valid precision: 0.753400, valid loss: 255.561396
epoch: 738, train precision: 0.940533, train loss: 29.032311, valid precision: 0.761000, valid loss: 262.900487
epoch: 739, train precision: 0.924044, train loss: 37.691770, valid precision: 0.754200, valid loss: 257.963429
epoch: 740, train precision: 0.934978, train loss: 33.056109, valid precision: 0.752000, valid loss: 256.578572
epoch: 741, train precision: 0.911067, train loss: 43.499495, valid precision: 0.741600, valid loss: 257.962544
epoch: 742, train precision: 0.917133, train loss: 39.651881, valid precision: 0.751000, valid loss: 227.746754
epoch: 743, train precision: 0.914333, train loss: 39.037205, valid precision: 0.742000, valid loss: 216.326192
epoch: 744, train precision: 0.881400, train loss: 54.537438, valid precision: 0.736800, valid loss: 212.537212
epoch: 745, train precision: 0.877089, train loss: 64.543671, valid precision: 0.727000, valid loss: 245.639072
epoch: 746, train precision: 0.918556, train loss: 42.638758, valid precision: 0.756400, valid loss: 266.936767
epoch: 747, train precision: 0.911044, train loss: 40.270774, valid precision: 0.741000, valid loss: 212.377861
epoch: 748, train precision: 0.897622, train loss: 50.369634, valid precision: 0.739800, valid loss: 233.532588
epoch: 749, train precision: 0.914733, train loss: 45.060115, valid precision: 0.758800, valid loss: 255.475346
epoch: 750, train precision: 0.928644, train loss: 35.473096, valid precision: 0.754400, valid loss: 249.164455
epoch: 751, train precision: 0.913889, train loss: 42.494498, valid precision: 0.755800, valid loss: 230.628281
epoch: 752, train precision: 0.919511, train loss: 40.189714, valid precision: 0.750600, valid loss: 234.514318
epoch: 753, train precision: 0.917889, train loss: 47.008963, valid precision: 0.745000, valid loss: 270.766653
epoch: 754, train precision: 0.915622, train loss: 44.275056, valid precision: 0.750000, valid loss: 257.260152
epoch: 755, train precision: 0.939111, train loss: 30.560785, valid precision: 0.763000, valid loss: 256.449452
epoch: 756, train precision: 0.920933, train loss: 39.131063, valid precision: 0.754800, valid loss: 219.871792
epoch: 757, train precision: 0.916578, train loss: 38.067147, valid precision: 0.753000, valid loss: 209.970955
epoch: 758, train precision: 0.927267, train loss: 38.626177, valid precision: 0.760400, valid loss: 236.162800
epoch: 759, train precision: 0.927689, train loss: 35.650732, valid precision: 0.753400, valid loss: 246.914007
epoch: 760, train precision: 0.908178, train loss: 44.215766, valid precision: 0.737200, valid loss: 238.294780
epoch: 761, train precision: 0.915289, train loss: 44.509382, valid precision: 0.748800, valid loss: 262.460921
epoch: 762, train precision: 0.939800, train loss: 30.524781, valid precision: 0.754800, valid loss: 265.879732
epoch: 763, train precision: 0.925067, train loss: 35.353207, valid precision: 0.748600, valid loss: 241.254273
epoch: 764, train precision: 0.927511, train loss: 36.005948, valid precision: 0.757200, valid loss: 243.069455
epoch: 765, train precision: 0.890156, train loss: 53.605514, valid precision: 0.741200, valid loss: 221.197781
epoch: 766, train precision: 0.923467, train loss: 40.893457, valid precision: 0.746600, valid loss: 275.555006
epoch: 767, train precision: 0.904733, train loss: 44.051401, valid precision: 0.751800, valid loss: 206.764047
epoch: 768, train precision: 0.907644, train loss: 42.905990, valid precision: 0.741200, valid loss: 212.924922
epoch: 769, train precision: 0.904400, train loss: 48.358181, valid precision: 0.752200, valid loss: 225.241200
epoch: 770, train precision: 0.928333, train loss: 34.033073, valid precision: 0.762600, valid loss: 222.465662
epoch: 771, train precision: 0.919689, train loss: 41.846308, valid precision: 0.761600, valid loss: 258.215196
epoch: 772, train precision: 0.907022, train loss: 43.100091, valid precision: 0.751800, valid loss: 207.351614
epoch: 773, train precision: 0.921600, train loss: 39.545580, valid precision: 0.747800, valid loss: 246.500919
epoch: 774, train precision: 0.927911, train loss: 34.540077, valid precision: 0.759400, valid loss: 261.383464
epoch: 775, train precision: 0.902089, train loss: 46.332873, valid precision: 0.752800, valid loss: 235.807207
epoch: 776, train precision: 0.919844, train loss: 39.097203, valid precision: 0.759200, valid loss: 245.777677
epoch: 777, train precision: 0.911444, train loss: 44.805531, valid precision: 0.745200, valid loss: 256.157215
epoch: 778, train precision: 0.931578, train loss: 36.418978, valid precision: 0.761000, valid loss: 272.713766
epoch: 779, train precision: 0.933844, train loss: 37.676292, valid precision: 0.764400, valid loss: 293.927702
epoch: 780, train precision: 0.894667, train loss: 50.383354, valid precision: 0.734200, valid loss: 227.884135
epoch: 781, train precision: 0.921489, train loss: 38.457151, valid precision: 0.756600, valid loss: 221.037764
epoch: 782, train precision: 0.917889, train loss: 41.647345, valid precision: 0.751800, valid loss: 250.963721
epoch: 783, train precision: 0.925778, train loss: 38.033823, valid precision: 0.756400, valid loss: 241.521455
epoch: 784, train precision: 0.918822, train loss: 47.616068, valid precision: 0.759800, valid loss: 286.753429
epoch: 785, train precision: 0.913978, train loss: 43.490641, valid precision: 0.751600, valid loss: 257.331201
epoch: 786, train precision: 0.916111, train loss: 42.986427, valid precision: 0.755600, valid loss: 250.317262
epoch: 787, train precision: 0.915400, train loss: 39.292111, valid precision: 0.748000, valid loss: 200.482793
epoch: 788, train precision: 0.917667, train loss: 43.875533, valid precision: 0.750000, valid loss: 261.231957
epoch: 789, train precision: 0.923889, train loss: 37.586538, valid precision: 0.759800, valid loss: 240.860625
epoch: 790, train precision: 0.917267, train loss: 42.191648, valid precision: 0.764600, valid loss: 240.763256
epoch: 791, train precision: 0.922689, train loss: 39.470592, valid precision: 0.759400, valid loss: 256.630921
epoch: 792, train precision: 0.916467, train loss: 44.609887, valid precision: 0.754200, valid loss: 241.259618
epoch: 793, train precision: 0.925489, train loss: 37.059184, valid precision: 0.755200, valid loss: 242.429847
epoch: 794, train precision: 0.910956, train loss: 44.383492, valid precision: 0.753600, valid loss: 228.047222
epoch: 795, train precision: 0.878933, train loss: 62.518236, valid precision: 0.738800, valid loss: 234.874433
epoch: 796, train precision: 0.919756, train loss: 42.010014, valid precision: 0.751400, valid loss: 267.939359
epoch: 797, train precision: 0.936600, train loss: 31.924362, valid precision: 0.770200, valid loss: 255.108902
epoch: 798, train precision: 0.903844, train loss: 58.488591, valid precision: 0.745800, valid loss: 278.291951
epoch: 799, train precision: 0.903044, train loss: 47.523742, valid precision: 0.745400, valid loss: 228.522032
epoch: 800, train precision: 0.896644, train loss: 48.405409, valid precision: 0.753400, valid loss: 195.571678
epoch: 801, train precision: 0.926067, train loss: 38.366095, valid precision: 0.759600, valid loss: 262.979554
epoch: 802, train precision: 0.902067, train loss: 44.221480, valid precision: 0.751000, valid loss: 205.466022
epoch: 803, train precision: 0.923867, train loss: 41.219072, valid precision: 0.768600, valid loss: 260.022985
epoch: 804, train precision: 0.900889, train loss: 45.991414, valid precision: 0.739800, valid loss: 219.769806
epoch: 805, train precision: 0.903222, train loss: 43.674599, valid precision: 0.751600, valid loss: 217.925471
epoch: 806, train precision: 0.937711, train loss: 34.920613, valid precision: 0.763000, valid loss: 297.441951
epoch: 807, train precision: 0.910489, train loss: 47.035607, valid precision: 0.750400, valid loss: 276.078801
epoch: 808, train precision: 0.904089, train loss: 50.573498, valid precision: 0.742400, valid loss: 257.426360
epoch: 809, train precision: 0.916956, train loss: 39.742421, valid precision: 0.757000, valid loss: 224.820815
epoch: 810, train precision: 0.914444, train loss: 44.405668, valid precision: 0.758600, valid loss: 259.429857
epoch: 811, train precision: 0.906311, train loss: 46.446748, valid precision: 0.753600, valid loss: 230.048844
epoch: 812, train precision: 0.915889, train loss: 41.180651, valid precision: 0.754600, valid loss: 243.383384
epoch: 813, train precision: 0.886333, train loss: 48.982731, valid precision: 0.728400, valid loss: 193.773972
epoch: 814, train precision: 0.893600, train loss: 47.507460, valid precision: 0.744600, valid loss: 203.518279
epoch: 815, train precision: 0.916222, train loss: 42.742401, valid precision: 0.753200, valid loss: 269.128598
epoch: 816, train precision: 0.895844, train loss: 46.969571, valid precision: 0.750600, valid loss: 187.825270
epoch: 817, train precision: 0.911089, train loss: 43.288910, valid precision: 0.747800, valid loss: 241.756290
epoch: 818, train precision: 0.935000, train loss: 34.956505, valid precision: 0.760600, valid loss: 264.920610
epoch: 819, train precision: 0.914911, train loss: 37.124371, valid precision: 0.754600, valid loss: 220.110376
epoch: 820, train precision: 0.906756, train loss: 46.144009, valid precision: 0.750800, valid loss: 238.053091
epoch: 821, train precision: 0.897778, train loss: 55.404219, valid precision: 0.739600, valid loss: 248.576527
epoch: 822, train precision: 0.901044, train loss: 63.479085, valid precision: 0.743800, valid loss: 331.987445
epoch: 823, train precision: 0.912578, train loss: 45.420182, valid precision: 0.762000, valid loss: 262.240470
epoch: 824, train precision: 0.933044, train loss: 34.791489, valid precision: 0.760600, valid loss: 287.148101
epoch: 825, train precision: 0.848156, train loss: 75.450773, valid precision: 0.719800, valid loss: 225.541598
epoch: 826, train precision: 0.928489, train loss: 41.085761, valid precision: 0.760800, valid loss: 315.838807
epoch: 827, train precision: 0.911622, train loss: 40.511558, valid precision: 0.750400, valid loss: 211.292994
epoch: 828, train precision: 0.917422, train loss: 41.464400, valid precision: 0.753800, valid loss: 253.130943
epoch: 829, train precision: 0.907800, train loss: 43.576582, valid precision: 0.743000, valid loss: 233.647737
epoch: 830, train precision: 0.929467, train loss: 36.658428, valid precision: 0.768600, valid loss: 264.788034
epoch: 831, train precision: 0.880689, train loss: 55.004798, valid precision: 0.744600, valid loss: 205.744058
epoch: 832, train precision: 0.833578, train loss: 71.461130, valid precision: 0.722200, valid loss: 194.051295
epoch: 833, train precision: 0.916778, train loss: 41.857747, valid precision: 0.763200, valid loss: 234.192765
epoch: 834, train precision: 0.918089, train loss: 40.983233, valid precision: 0.753600, valid loss: 260.436951
epoch: 835, train precision: 0.897422, train loss: 49.290206, valid precision: 0.753600, valid loss: 219.926135
epoch: 836, train precision: 0.918756, train loss: 41.965864, valid precision: 0.752000, valid loss: 280.953729
epoch: 837, train precision: 0.875756, train loss: 57.580264, valid precision: 0.736200, valid loss: 205.257202
epoch: 838, train precision: 0.901200, train loss: 48.924101, valid precision: 0.754200, valid loss: 240.573643
epoch: 839, train precision: 0.904467, train loss: 42.508634, valid precision: 0.750800, valid loss: 200.359558
epoch: 840, train precision: 0.912267, train loss: 52.439445, valid precision: 0.754800, valid loss: 296.694915
epoch: 841, train precision: 0.907533, train loss: 48.751280, valid precision: 0.752000, valid loss: 262.639060
epoch: 842, train precision: 0.910622, train loss: 51.910442, valid precision: 0.760800, valid loss: 294.009261
epoch: 843, train precision: 0.922778, train loss: 40.836527, valid precision: 0.756000, valid loss: 275.604524
epoch: 844, train precision: 0.921511, train loss: 45.265916, valid precision: 0.759600, valid loss: 289.760350
epoch: 845, train precision: 0.891378, train loss: 50.487550, valid precision: 0.746000, valid loss: 219.018720
epoch: 846, train precision: 0.913378, train loss: 42.306246, valid precision: 0.756200, valid loss: 242.802026
epoch: 847, train precision: 0.870911, train loss: 77.111095, valid precision: 0.736200, valid loss: 275.198807
epoch: 848, train precision: 0.924556, train loss: 45.673843, valid precision: 0.758600, valid loss: 313.962505
epoch: 849, train precision: 0.916267, train loss: 44.477213, valid precision: 0.761400, valid loss: 273.270281
epoch: 850, train precision: 0.885889, train loss: 56.748675, valid precision: 0.746400, valid loss: 235.588934
epoch: 851, train precision: 0.898667, train loss: 49.225443, valid precision: 0.745000, valid loss: 244.625179
epoch: 852, train precision: 0.908067, train loss: 48.183164, valid precision: 0.754800, valid loss: 241.061997
epoch: 853, train precision: 0.914644, train loss: 41.555309, valid precision: 0.755600, valid loss: 232.465024
epoch: 854, train precision: 0.899822, train loss: 48.042546, valid precision: 0.743200, valid loss: 225.837497
epoch: 855, train precision: 0.868867, train loss: 58.958462, valid precision: 0.730600, valid loss: 206.018702
epoch: 856, train precision: 0.866244, train loss: 57.467534, valid precision: 0.745600, valid loss: 161.643104
epoch: 857, train precision: 0.902400, train loss: 46.500732, valid precision: 0.756200, valid loss: 226.721232
epoch: 858, train precision: 0.923911, train loss: 37.357535, valid precision: 0.764400, valid loss: 246.160427
epoch: 859, train precision: 0.849578, train loss: 66.907156, valid precision: 0.731600, valid loss: 166.256840
epoch: 860, train precision: 0.912889, train loss: 42.480404, valid precision: 0.767200, valid loss: 232.346315
epoch: 861, train precision: 0.850778, train loss: 80.029834, valid precision: 0.732200, valid loss: 220.059907
epoch: 862, train precision: 0.885311, train loss: 51.315771, valid precision: 0.751200, valid loss: 183.853668
epoch: 863, train precision: 0.930644, train loss: 40.389086, valid precision: 0.771600, valid loss: 300.925781
epoch: 864, train precision: 0.862378, train loss: 83.715530, valid precision: 0.727000, valid loss: 292.541283
epoch: 865, train precision: 0.839889, train loss: 74.018047, valid precision: 0.715200, valid loss: 223.673236
epoch: 866, train precision: 0.893689, train loss: 47.567924, valid precision: 0.750000, valid loss: 205.123448
epoch: 867, train precision: 0.912178, train loss: 43.318049, valid precision: 0.757400, valid loss: 241.097001
epoch: 868, train precision: 0.892556, train loss: 50.921249, valid precision: 0.755400, valid loss: 203.855516
epoch: 869, train precision: 0.923511, train loss: 39.010427, valid precision: 0.771800, valid loss: 267.377030
epoch: 870, train precision: 0.869556, train loss: 74.655650, valid precision: 0.742600, valid loss: 249.566778
epoch: 871, train precision: 0.915133, train loss: 45.042576, valid precision: 0.765600, valid loss: 241.867063
epoch: 872, train precision: 0.887422, train loss: 54.023614, valid precision: 0.745400, valid loss: 238.036099
epoch: 873, train precision: 0.862756, train loss: 63.564773, valid precision: 0.739400, valid loss: 206.565067
epoch: 874, train precision: 0.909778, train loss: 45.403280, valid precision: 0.751600, valid loss: 269.324673
epoch: 875, train precision: 0.915044, train loss: 47.047769, valid precision: 0.755000, valid loss: 276.698545
epoch: 876, train precision: 0.882133, train loss: 60.044593, valid precision: 0.745000, valid loss: 237.860603
epoch: 877, train precision: 0.907267, train loss: 45.121177, valid precision: 0.749800, valid loss: 238.119530
epoch: 878, train precision: 0.897022, train loss: 54.828522, valid precision: 0.760400, valid loss: 249.694235
epoch: 879, train precision: 0.841578, train loss: 71.826678, valid precision: 0.730400, valid loss: 195.263270
epoch: 880, train precision: 0.894889, train loss: 52.023172, valid precision: 0.741600, valid loss: 247.392519
epoch: 881, train precision: 0.888222, train loss: 57.423319, valid precision: 0.751400, valid loss: 246.734783
epoch: 882, train precision: 0.899867, train loss: 44.525480, valid precision: 0.750800, valid loss: 220.440347
epoch: 883, train precision: 0.896733, train loss: 52.821378, valid precision: 0.748600, valid loss: 265.502355
epoch: 884, train precision: 0.905200, train loss: 48.543203, valid precision: 0.747000, valid loss: 284.038660
epoch: 885, train precision: 0.881400, train loss: 56.013237, valid precision: 0.750800, valid loss: 217.717041
epoch: 886, train precision: 0.904022, train loss: 52.180505, valid precision: 0.762800, valid loss: 249.627885
epoch: 887, train precision: 0.888156, train loss: 68.355612, valid precision: 0.752000, valid loss: 277.411362
epoch: 888, train precision: 0.907822, train loss: 42.415600, valid precision: 0.761200, valid loss: 221.086029
epoch: 889, train precision: 0.895422, train loss: 54.195382, valid precision: 0.754600, valid loss: 279.738737
epoch: 890, train precision: 0.897578, train loss: 47.970535, valid precision: 0.753600, valid loss: 211.077841
epoch: 891, train precision: 0.907889, train loss: 47.184970, valid precision: 0.754800, valid loss: 264.985174
epoch: 892, train precision: 0.853289, train loss: 67.641153, valid precision: 0.732600, valid loss: 205.059367
epoch: 893, train precision: 0.886222, train loss: 58.933441, valid precision: 0.750200, valid loss: 234.116397
epoch: 894, train precision: 0.863022, train loss: 64.618632, valid precision: 0.737600, valid loss: 194.365508
epoch: 895, train precision: 0.914822, train loss: 45.467337, valid precision: 0.761000, valid loss: 276.430312
epoch: 896, train precision: 0.914356, train loss: 45.380130, valid precision: 0.754200, valid loss: 270.927534
epoch: 897, train precision: 0.903156, train loss: 47.942856, valid precision: 0.759000, valid loss: 234.094526
epoch: 898, train precision: 0.895578, train loss: 49.726204, valid precision: 0.749200, valid loss: 230.055209
epoch: 899, train precision: 0.902578, train loss: 50.098094, valid precision: 0.745400, valid loss: 279.024865
epoch: 900, train precision: 0.884289, train loss: 53.484179, valid precision: 0.744200, valid loss: 213.654985
epoch: 901, train precision: 0.864800, train loss: 62.581273, valid precision: 0.734000, valid loss: 215.516556
epoch: 902, train precision: 0.868467, train loss: 56.913262, valid precision: 0.748600, valid loss: 178.618753
epoch: 903, train precision: 0.886733, train loss: 50.910415, valid precision: 0.754400, valid loss: 200.091517
epoch: 904, train precision: 0.889067, train loss: 51.790139, valid precision: 0.748200, valid loss: 212.441985
epoch: 905, train precision: 0.895644, train loss: 54.863947, valid precision: 0.747600, valid loss: 256.990900
epoch: 906, train precision: 0.856200, train loss: 61.036735, valid precision: 0.744200, valid loss: 176.106365
epoch: 907, train precision: 0.856533, train loss: 66.034633, valid precision: 0.731800, valid loss: 217.596017
epoch: 908, train precision: 0.888489, train loss: 52.911873, valid precision: 0.750400, valid loss: 226.070619
epoch: 909, train precision: 0.900378, train loss: 47.471837, valid precision: 0.751000, valid loss: 224.048559
epoch: 910, train precision: 0.889578, train loss: 51.949308, valid precision: 0.757400, valid loss: 213.747383
epoch: 911, train precision: 0.888356, train loss: 50.135337, valid precision: 0.754200, valid loss: 200.329365
epoch: 912, train precision: 0.894733, train loss: 51.617316, valid precision: 0.743600, valid loss: 246.196573
epoch: 913, train precision: 0.894044, train loss: 57.773544, valid precision: 0.760600, valid loss: 252.476698
epoch: 914, train precision: 0.880444, train loss: 62.659506, valid precision: 0.747400, valid loss: 221.678688
epoch: 915, train precision: 0.895400, train loss: 49.287220, valid precision: 0.752000, valid loss: 218.885877
epoch: 916, train precision: 0.889244, train loss: 67.656964, valid precision: 0.752200, valid loss: 310.293639
epoch: 917, train precision: 0.886756, train loss: 54.260858, valid precision: 0.742400, valid loss: 234.858644
epoch: 918, train precision: 0.782156, train loss: 93.201195, valid precision: 0.709600, valid loss: 171.597141
epoch: 919, train precision: 0.826156, train loss: 78.233400, valid precision: 0.722600, valid loss: 190.566179
epoch: 920, train precision: 0.900133, train loss: 57.080874, valid precision: 0.759000, valid loss: 294.659577
epoch: 921, train precision: 0.877644, train loss: 54.708733, valid precision: 0.745000, valid loss: 194.706888
epoch: 922, train precision: 0.888178, train loss: 54.049264, valid precision: 0.750800, valid loss: 196.837179
epoch: 923, train precision: 0.880533, train loss: 64.692440, valid precision: 0.754800, valid loss: 255.310156
epoch: 924, train precision: 0.834178, train loss: 69.399311, valid precision: 0.733600, valid loss: 152.046986
epoch: 925, train precision: 0.900644, train loss: 64.539746, valid precision: 0.757800, valid loss: 314.662678
epoch: 926, train precision: 0.904889, train loss: 59.002363, valid precision: 0.758800, valid loss: 297.690392
epoch: 927, train precision: 0.855711, train loss: 63.753392, valid precision: 0.736600, valid loss: 182.983820
epoch: 928, train precision: 0.870844, train loss: 63.818531, valid precision: 0.732800, valid loss: 221.063683
epoch: 929, train precision: 0.869089, train loss: 59.317489, valid precision: 0.738400, valid loss: 213.902543
epoch: 930, train precision: 0.796044, train loss: 85.010572, valid precision: 0.708000, valid loss: 158.841683
epoch: 931, train precision: 0.867422, train loss: 59.269377, valid precision: 0.739600, valid loss: 196.979458
epoch: 932, train precision: 0.882889, train loss: 60.199510, valid precision: 0.746600, valid loss: 231.089430
epoch: 933, train precision: 0.880956, train loss: 63.605993, valid precision: 0.735000, valid loss: 239.907842
epoch: 934, train precision: 0.863644, train loss: 63.469638, valid precision: 0.742200, valid loss: 183.228018
epoch: 935, train precision: 0.864044, train loss: 60.401491, valid precision: 0.737600, valid loss: 193.015346
epoch: 936, train precision: 0.876911, train loss: 57.849168, valid precision: 0.747000, valid loss: 203.257767
epoch: 937, train precision: 0.891889, train loss: 54.213122, valid precision: 0.745600, valid loss: 226.212932
epoch: 938, train precision: 0.892822, train loss: 49.766420, valid precision: 0.755600, valid loss: 198.285676
epoch: 939, train precision: 0.897622, train loss: 55.638625, valid precision: 0.743200, valid loss: 268.699765
epoch: 940, train precision: 0.885467, train loss: 50.056189, valid precision: 0.758800, valid loss: 190.902856
epoch: 941, train precision: 0.902889, train loss: 56.526339, valid precision: 0.759800, valid loss: 274.847860
epoch: 942, train precision: 0.865689, train loss: 61.689716, valid precision: 0.748800, valid loss: 189.676949
epoch: 943, train precision: 0.860178, train loss: 71.092573, valid precision: 0.747200, valid loss: 198.942391
epoch: 944, train precision: 0.914022, train loss: 47.765644, valid precision: 0.770600, valid loss: 254.280106
epoch: 945, train precision: 0.874200, train loss: 60.190189, valid precision: 0.746600, valid loss: 202.643909
epoch: 946, train precision: 0.912578, train loss: 50.892600, valid precision: 0.763000, valid loss: 261.060291
epoch: 947, train precision: 0.870244, train loss: 64.353209, valid precision: 0.744200, valid loss: 210.128783
epoch: 948, train precision: 0.897311, train loss: 51.335689, valid precision: 0.760000, valid loss: 216.929978
epoch: 949, train precision: 0.861378, train loss: 60.943058, valid precision: 0.738000, valid loss: 181.685230
epoch: 950, train precision: 0.882178, train loss: 55.818333, valid precision: 0.760600, valid loss: 210.241968
epoch: 951, train precision: 0.884156, train loss: 56.736189, valid precision: 0.749800, valid loss: 202.314870
epoch: 952, train precision: 0.882378, train loss: 51.008101, valid precision: 0.749400, valid loss: 192.490902
epoch: 953, train precision: 0.856667, train loss: 66.984591, valid precision: 0.730600, valid loss: 194.711691
epoch: 954, train precision: 0.845022, train loss: 76.399106, valid precision: 0.739400, valid loss: 212.631451
epoch: 955, train precision: 0.876667, train loss: 54.020428, valid precision: 0.757400, valid loss: 172.810502
epoch: 956, train precision: 0.869800, train loss: 62.211186, valid precision: 0.742200, valid loss: 209.008426
epoch: 957, train precision: 0.859578, train loss: 63.589863, valid precision: 0.751000, valid loss: 165.989956
epoch: 958, train precision: 0.892267, train loss: 50.082550, valid precision: 0.762600, valid loss: 210.963454
epoch: 959, train precision: 0.888711, train loss: 50.439871, valid precision: 0.760000, valid loss: 199.886194
epoch: 960, train precision: 0.891200, train loss: 55.126697, valid precision: 0.765400, valid loss: 230.952950
epoch: 961, train precision: 0.876978, train loss: 61.086241, valid precision: 0.747800, valid loss: 233.204518
epoch: 962, train precision: 0.838756, train loss: 74.925801, valid precision: 0.737200, valid loss: 180.444493
epoch: 963, train precision: 0.793267, train loss: 83.991955, valid precision: 0.730400, valid loss: 136.108914
epoch: 964, train precision: 0.729600, train loss: 117.001457, valid precision: 0.680600, valid loss: 167.077444
epoch: 965, train precision: 0.860444, train loss: 59.497035, valid precision: 0.740200, valid loss: 167.047073
epoch: 966, train precision: 0.866222, train loss: 65.908014, valid precision: 0.748600, valid loss: 215.368167
epoch: 967, train precision: 0.854622, train loss: 67.870138, valid precision: 0.743000, valid loss: 183.494294
epoch: 968, train precision: 0.896422, train loss: 52.046072, valid precision: 0.760600, valid loss: 235.013792
epoch: 969, train precision: 0.865044, train loss: 67.408221, valid precision: 0.741600, valid loss: 246.017237
epoch: 970, train precision: 0.848022, train loss: 70.036112, valid precision: 0.741200, valid loss: 186.768161
epoch: 971, train precision: 0.891600, train loss: 53.126894, valid precision: 0.761400, valid loss: 225.082463
epoch: 972, train precision: 0.868044, train loss: 58.184155, valid precision: 0.754000, valid loss: 173.316873
epoch: 973, train precision: 0.841378, train loss: 68.188365, valid precision: 0.739000, valid loss: 168.784397
epoch: 974, train precision: 0.851622, train loss: 71.130301, valid precision: 0.735400, valid loss: 208.196799
epoch: 975, train precision: 0.864400, train loss: 65.672908, valid precision: 0.748600, valid loss: 216.323301
epoch: 976, train precision: 0.882333, train loss: 56.675645, valid precision: 0.755400, valid loss: 234.321313
epoch: 977, train precision: 0.862511, train loss: 64.560166, valid precision: 0.742800, valid loss: 207.071975
epoch: 978, train precision: 0.811822, train loss: 85.778472, valid precision: 0.710000, valid loss: 195.666271
epoch: 979, train precision: 0.833933, train loss: 71.677379, valid precision: 0.736400, valid loss: 189.133904
epoch: 980, train precision: 0.833756, train loss: 73.583432, valid precision: 0.737600, valid loss: 179.730036
epoch: 981, train precision: 0.846667, train loss: 67.534430, valid precision: 0.734200, valid loss: 172.020552
epoch: 982, train precision: 0.865822, train loss: 61.733264, valid precision: 0.747000, valid loss: 195.632982
epoch: 983, train precision: 0.811622, train loss: 78.659948, valid precision: 0.723000, valid loss: 151.613045
epoch: 984, train precision: 0.824711, train loss: 73.518368, valid precision: 0.737600, valid loss: 163.527533
epoch: 985, train precision: 0.840022, train loss: 68.838771, valid precision: 0.735400, valid loss: 170.645582
epoch: 986, train precision: 0.835800, train loss: 68.676962, valid precision: 0.742800, valid loss: 152.255771
epoch: 987, train precision: 0.861022, train loss: 66.246002, valid precision: 0.739800, valid loss: 220.003798
epoch: 988, train precision: 0.862778, train loss: 60.023085, valid precision: 0.754200, valid loss: 177.194433
epoch: 989, train precision: 0.851756, train loss: 72.587384, valid precision: 0.747000, valid loss: 204.122772
epoch: 990, train precision: 0.879844, train loss: 61.321951, valid precision: 0.759200, valid loss: 248.210567
epoch: 991, train precision: 0.857067, train loss: 62.823066, valid precision: 0.746200, valid loss: 195.478840
epoch: 992, train precision: 0.886844, train loss: 57.254702, valid precision: 0.750400, valid loss: 240.952168
epoch: 993, train precision: 0.865556, train loss: 60.821720, valid precision: 0.752200, valid loss: 185.238705
epoch: 994, train precision: 0.838578, train loss: 86.959244, valid precision: 0.724800, valid loss: 236.941858
epoch: 995, train precision: 0.859844, train loss: 63.310730, valid precision: 0.746600, valid loss: 183.681667
epoch: 996, train precision: 0.821600, train loss: 72.578839, valid precision: 0.736200, valid loss: 140.648608
epoch: 997, train precision: 0.868556, train loss: 62.185943, valid precision: 0.747800, valid loss: 214.513988
epoch: 998, train precision: 0.799978, train loss: 98.344109, valid precision: 0.724200, valid loss: 177.836197
epoch: 999, train precision: 0.848844, train loss: 65.509693, valid precision: 0.742600, valid loss: 181.521536
epoch: 1000, train precision: 0.821289, train loss: 80.157553, valid precision: 0.736800, valid loss: 169.636505
epoch: 1001, train precision: 0.877467, train loss: 57.427953, valid precision: 0.756400, valid loss: 210.992363
epoch: 1002, train precision: 0.869956, train loss: 69.725917, valid precision: 0.748400, valid loss: 253.442172
epoch: 1003, train precision: 0.715089, train loss: 126.712904, valid precision: 0.677000, valid loss: 160.663921
epoch: 1004, train precision: 0.858533, train loss: 62.680950, valid precision: 0.749400, valid loss: 178.471520
epoch: 1005, train precision: 0.844222, train loss: 66.533105, valid precision: 0.742600, valid loss: 167.922341
epoch: 1006, train precision: 0.852689, train loss: 61.198272, valid precision: 0.749000, valid loss: 152.679273
epoch: 1007, train precision: 0.838311, train loss: 70.186143, valid precision: 0.739400, valid loss: 171.647881
epoch: 1008, train precision: 0.793911, train loss: 104.839572, valid precision: 0.718600, valid loss: 198.179091
epoch: 1009, train precision: 0.858356, train loss: 71.888808, valid precision: 0.746000, valid loss: 225.684568
epoch: 1010, train precision: 0.844956, train loss: 67.394036, valid precision: 0.745000, valid loss: 174.765938
epoch: 1011, train precision: 0.861356, train loss: 65.679212, valid precision: 0.741200, valid loss: 199.942537
epoch: 1012, train precision: 0.805044, train loss: 88.747592, valid precision: 0.727200, valid loss: 160.490232
epoch: 1013, train precision: 0.864489, train loss: 60.817403, valid precision: 0.758000, valid loss: 172.480931
epoch: 1014, train precision: 0.798711, train loss: 87.815112, valid precision: 0.718800, valid loss: 169.247016
epoch: 1015, train precision: 0.816356, train loss: 78.416974, valid precision: 0.738400, valid loss: 161.957683
epoch: 1016, train precision: 0.861978, train loss: 68.538726, valid precision: 0.750000, valid loss: 207.984089
epoch: 1017, train precision: 0.865578, train loss: 65.477571, valid precision: 0.748000, valid loss: 209.675169
epoch: 1018, train precision: 0.862556, train loss: 66.276707, valid precision: 0.753200, valid loss: 184.602578
epoch: 1019, train precision: 0.862689, train loss: 73.086317, valid precision: 0.743800, valid loss: 247.226564
epoch: 1020, train precision: 0.610267, train loss: 159.575461, valid precision: 0.602600, valid loss: 164.732088
epoch: 1021, train precision: 0.845378, train loss: 67.340371, valid precision: 0.746600, valid loss: 170.692619
epoch: 1022, train precision: 0.821022, train loss: 75.123474, valid precision: 0.739600, valid loss: 183.689227
epoch: 1023, train precision: 0.854000, train loss: 62.819143, valid precision: 0.756800, valid loss: 166.930914
epoch: 1024, train precision: 0.844467, train loss: 68.078897, valid precision: 0.757800, valid loss: 155.806036
epoch: 1025, train precision: 0.842556, train loss: 77.019153, valid precision: 0.747000, valid loss: 208.149307
epoch: 1026, train precision: 0.834178, train loss: 68.726764, valid precision: 0.746400, valid loss: 145.476499
epoch: 1027, train precision: 0.782156, train loss: 89.582952, valid precision: 0.713800, valid loss: 159.015534
epoch: 1028, train precision: 0.854222, train loss: 64.033089, valid precision: 0.761200, valid loss: 171.937400
epoch: 1029, train precision: 0.857044, train loss: 62.538854, valid precision: 0.753600, valid loss: 176.832917
epoch: 1030, train precision: 0.824156, train loss: 75.617615, valid precision: 0.735400, valid loss: 171.848630
epoch: 1031, train precision: 0.810756, train loss: 80.103012, valid precision: 0.737800, valid loss: 154.921986
epoch: 1032, train precision: 0.838333, train loss: 69.842924, valid precision: 0.748600, valid loss: 155.804523
epoch: 1033, train precision: 0.871333, train loss: 64.731153, valid precision: 0.748000, valid loss: 240.728920
epoch: 1034, train precision: 0.795333, train loss: 87.310761, valid precision: 0.722200, valid loss: 157.864551
epoch: 1035, train precision: 0.854022, train loss: 68.528120, valid precision: 0.760400, valid loss: 171.681484
epoch: 1036, train precision: 0.837911, train loss: 71.333069, valid precision: 0.748400, valid loss: 143.258188
epoch: 1037, train precision: 0.773422, train loss: 96.482617, valid precision: 0.715000, valid loss: 153.570051
epoch: 1038, train precision: 0.827911, train loss: 88.134237, valid precision: 0.745800, valid loss: 200.543497
epoch: 1039, train precision: 0.861289, train loss: 64.027331, valid precision: 0.761200, valid loss: 181.054063
epoch: 1040, train precision: 0.797156, train loss: 81.517932, valid precision: 0.736400, valid loss: 127.149647
epoch: 1041, train precision: 0.825622, train loss: 74.191352, valid precision: 0.742000, valid loss: 158.736520
epoch: 1042, train precision: 0.779978, train loss: 90.761494, valid precision: 0.708600, valid loss: 148.831025
epoch: 1043, train precision: 0.800622, train loss: 83.534806, valid precision: 0.723600, valid loss: 160.567857
epoch: 1044, train precision: 0.833222, train loss: 75.548906, valid precision: 0.751400, valid loss: 161.055290
epoch: 1045, train precision: 0.828044, train loss: 77.780462, valid precision: 0.744400, valid loss: 174.475774
epoch: 1046, train precision: 0.870022, train loss: 63.500861, valid precision: 0.766400, valid loss: 206.795339
epoch: 1047, train precision: 0.867444, train loss: 63.695430, valid precision: 0.751000, valid loss: 228.004908
epoch: 1048, train precision: 0.792467, train loss: 97.549794, valid precision: 0.722200, valid loss: 183.846788
epoch: 1049, train precision: 0.852222, train loss: 75.211199, valid precision: 0.744200, valid loss: 232.189156
epoch: 1050, train precision: 0.802622, train loss: 83.349179, valid precision: 0.724000, valid loss: 155.553708
epoch: 1051, train precision: 0.820378, train loss: 75.350599, valid precision: 0.748200, valid loss: 155.544853
epoch: 1052, train precision: 0.842933, train loss: 68.353459, valid precision: 0.749200, valid loss: 202.711992
epoch: 1053, train precision: 0.783622, train loss: 88.072364, valid precision: 0.721000, valid loss: 164.513435
epoch: 1054, train precision: 0.826400, train loss: 70.319603, valid precision: 0.751200, valid loss: 154.613911
epoch: 1055, train precision: 0.695267, train loss: 125.774009, valid precision: 0.676600, valid loss: 145.193585
epoch: 1056, train precision: 0.831733, train loss: 89.799984, valid precision: 0.745800, valid loss: 198.502716
epoch: 1057, train precision: 0.804911, train loss: 79.189740, valid precision: 0.747400, valid loss: 133.608914
epoch: 1058, train precision: 0.845911, train loss: 70.741917, valid precision: 0.756800, valid loss: 186.450872
epoch: 1059, train precision: 0.852222, train loss: 64.434978, valid precision: 0.757000, valid loss: 173.194238
epoch: 1060, train precision: 0.786000, train loss: 86.274330, valid precision: 0.736600, valid loss: 125.788929
epoch: 1061, train precision: 0.763289, train loss: 98.936405, valid precision: 0.715400, valid loss: 127.446314
epoch: 1062, train precision: 0.795711, train loss: 82.707947, valid precision: 0.732200, valid loss: 130.506488
epoch: 1063, train precision: 0.827422, train loss: 80.198125, valid precision: 0.740600, valid loss: 168.270758
epoch: 1064, train precision: 0.809844, train loss: 81.766240, valid precision: 0.743200, valid loss: 162.486392
epoch: 1065, train precision: 0.813911, train loss: 76.574396, valid precision: 0.743800, valid loss: 141.476358
epoch: 1066, train precision: 0.780467, train loss: 90.580421, valid precision: 0.724400, valid loss: 129.740678
epoch: 1067, train precision: 0.836600, train loss: 78.550528, valid precision: 0.747800, valid loss: 181.056617
epoch: 1068, train precision: 0.816089, train loss: 75.337489, valid precision: 0.741600, valid loss: 135.072148
epoch: 1069, train precision: 0.827867, train loss: 71.709588, valid precision: 0.752000, valid loss: 147.625138
epoch: 1070, train precision: 0.808156, train loss: 84.700445, valid precision: 0.733800, valid loss: 148.096052
epoch: 1071, train precision: 0.799067, train loss: 85.495065, valid precision: 0.731400, valid loss: 159.191939
epoch: 1072, train precision: 0.817644, train loss: 77.991927, valid precision: 0.739400, valid loss: 150.264170
epoch: 1073, train precision: 0.753356, train loss: 101.517001, valid precision: 0.715400, valid loss: 135.468941
epoch: 1074, train precision: 0.723467, train loss: 110.518040, valid precision: 0.678200, valid loss: 149.426343
epoch: 1075, train precision: 0.813311, train loss: 79.372899, valid precision: 0.740000, valid loss: 147.661336
epoch: 1076, train precision: 0.808889, train loss: 80.779537, valid precision: 0.731000, valid loss: 154.946834
epoch: 1077, train precision: 0.799867, train loss: 82.858736, valid precision: 0.741400, valid loss: 123.320925
epoch: 1078, train precision: 0.815778, train loss: 73.112505, valid precision: 0.736200, valid loss: 129.171519
epoch: 1079, train precision: 0.805111, train loss: 83.118015, valid precision: 0.732000, valid loss: 152.326840
epoch: 1080, train precision: 0.815467, train loss: 75.225167, valid precision: 0.741000, valid loss: 142.376575
epoch: 1081, train precision: 0.792956, train loss: 90.541392, valid precision: 0.723800, valid loss: 178.974700
epoch: 1082, train precision: 0.794467, train loss: 82.739749, valid precision: 0.735400, valid loss: 140.814387
epoch: 1083, train precision: 0.835044, train loss: 77.233717, valid precision: 0.744800, valid loss: 169.037052
epoch: 1084, train precision: 0.818400, train loss: 76.043766, valid precision: 0.746000, valid loss: 128.505560
epoch: 1085, train precision: 0.769800, train loss: 90.824932, valid precision: 0.719000, valid loss: 125.826267
epoch: 1086, train precision: 0.835244, train loss: 74.745623, valid precision: 0.748600, valid loss: 154.799973
epoch: 1087, train precision: 0.825178, train loss: 70.659913, valid precision: 0.751000, valid loss: 116.994591
epoch: 1088, train precision: 0.816489, train loss: 82.419723, valid precision: 0.745200, valid loss: 153.407221
epoch: 1089, train precision: 0.804178, train loss: 79.191152, valid precision: 0.738200, valid loss: 131.385608
epoch: 1090, train precision: 0.807889, train loss: 76.694801, valid precision: 0.743600, valid loss: 139.862419
epoch: 1091, train precision: 0.837244, train loss: 80.472734, valid precision: 0.747600, valid loss: 198.714540
epoch: 1092, train precision: 0.819267, train loss: 73.447703, valid precision: 0.752600, valid loss: 140.714829
epoch: 1093, train precision: 0.736067, train loss: 105.247755, valid precision: 0.711600, valid loss: 119.976316
epoch: 1094, train precision: 0.793600, train loss: 82.276465, valid precision: 0.741800, valid loss: 116.252481
epoch: 1095, train precision: 0.837911, train loss: 67.437271, valid precision: 0.758000, valid loss: 124.462358
epoch: 1096, train precision: 0.791844, train loss: 89.563438, valid precision: 0.741600, valid loss: 145.384778
epoch: 1097, train precision: 0.784978, train loss: 86.465095, valid precision: 0.728600, valid loss: 122.268498
epoch: 1098, train precision: 0.807756, train loss: 82.610711, valid precision: 0.742800, valid loss: 145.058527
epoch: 1099, train precision: 0.781111, train loss: 95.046171, valid precision: 0.722400, valid loss: 148.889502
epoch: 1100, train precision: 0.795089, train loss: 83.666974, valid precision: 0.741200, valid loss: 121.597921
epoch: 1101, train precision: 0.815978, train loss: 75.894354, valid precision: 0.745600, valid loss: 143.774502
epoch: 1102, train precision: 0.824156, train loss: 69.850475, valid precision: 0.754600, valid loss: 120.098980
epoch: 1103, train precision: 0.834178, train loss: 67.934832, valid precision: 0.763400, valid loss: 140.956677
epoch: 1104, train precision: 0.815000, train loss: 76.515382, valid precision: 0.751800, valid loss: 127.944125
epoch: 1105, train precision: 0.821778, train loss: 77.683458, valid precision: 0.749400, valid loss: 150.236021
epoch: 1106, train precision: 0.815911, train loss: 79.445040, valid precision: 0.743200, valid loss: 147.233577
epoch: 1107, train precision: 0.800200, train loss: 80.874385, valid precision: 0.725200, valid loss: 172.421429
epoch: 1108, train precision: 0.815356, train loss: 76.110978, valid precision: 0.736200, valid loss: 206.400056
epoch: 1109, train precision: 0.830978, train loss: 69.869289, valid precision: 0.758800, valid loss: 128.104695
epoch: 1110, train precision: 0.711889, train loss: 107.232148, valid precision: 0.683200, valid loss: 138.780485
epoch: 1111, train precision: 0.791000, train loss: 81.731428, valid precision: 0.735200, valid loss: 119.556002
epoch: 1112, train precision: 0.803778, train loss: 81.241407, valid precision: 0.742000, valid loss: 132.244728
epoch: 1113, train precision: 0.787867, train loss: 90.528500, valid precision: 0.735400, valid loss: 135.386679
epoch: 1114, train precision: 0.778111, train loss: 104.678903, valid precision: 0.723800, valid loss: 156.313867
epoch: 1115, train precision: 0.810178, train loss: 76.173361, valid precision: 0.755800, valid loss: 119.765185
epoch: 1116, train precision: 0.792289, train loss: 82.867110, valid precision: 0.737400, valid loss: 110.252139
epoch: 1117, train precision: 0.827222, train loss: 68.527311, valid precision: 0.756200, valid loss: 130.700275
epoch: 1118, train precision: 0.813444, train loss: 74.266527, valid precision: 0.747200, valid loss: 123.007780
epoch: 1119, train precision: 0.822822, train loss: 71.514873, valid precision: 0.754000, valid loss: 124.940720
epoch: 1120, train precision: 0.820600, train loss: 70.319448, valid precision: 0.753000, valid loss: 107.215861
epoch: 1121, train precision: 0.799333, train loss: 83.129610, valid precision: 0.737000, valid loss: 122.331403
epoch: 1122, train precision: 0.798444, train loss: 79.928839, valid precision: 0.738600, valid loss: 123.199065
epoch: 1123, train precision: 0.815733, train loss: 73.380997, valid precision: 0.748200, valid loss: 121.763805
epoch: 1124, train precision: 0.827667, train loss: 72.059131, valid precision: 0.757800, valid loss: 127.544701
epoch: 1125, train precision: 0.842311, train loss: 70.792302, valid precision: 0.768600, valid loss: 179.094063
epoch: 1126, train precision: 0.797444, train loss: 82.766470, valid precision: 0.744000, valid loss: 134.741500
epoch: 1127, train precision: 0.814800, train loss: 76.045456, valid precision: 0.757600, valid loss: 118.739488
epoch: 1128, train precision: 0.760956, train loss: 94.018209, valid precision: 0.715600, valid loss: 119.901886
epoch: 1129, train precision: 0.811689, train loss: 77.960804, valid precision: 0.750200, valid loss: 115.413050
epoch: 1130, train precision: 0.827556, train loss: 72.107915, valid precision: 0.754800, valid loss: 132.575132
epoch: 1131, train precision: 0.808933, train loss: 75.753291, valid precision: 0.744000, valid loss: 113.562565
epoch: 1132, train precision: 0.755978, train loss: 97.111023, valid precision: 0.708600, valid loss: 120.991212
epoch: 1133, train precision: 0.780178, train loss: 89.556047, valid precision: 0.732000, valid loss: 126.370225
epoch: 1134, train precision: 0.804778, train loss: 80.446147, valid precision: 0.748800, valid loss: 129.324506
epoch: 1135, train precision: 0.827578, train loss: 69.729016, valid precision: 0.763400, valid loss: 111.105911
epoch: 1136, train precision: 0.791733, train loss: 81.799287, valid precision: 0.742200, valid loss: 110.552385
epoch: 1137, train precision: 0.827400, train loss: 69.454049, valid precision: 0.765000, valid loss: 115.509218
epoch: 1138, train precision: 0.816289, train loss: 74.369884, valid precision: 0.755000, valid loss: 118.244789
epoch: 1139, train precision: 0.690756, train loss: 123.783705, valid precision: 0.667400, valid loss: 137.791577
epoch: 1140, train precision: 0.818289, train loss: 71.779482, valid precision: 0.752400, valid loss: 114.982560
epoch: 1141, train precision: 0.822689, train loss: 73.802802, valid precision: 0.756400, valid loss: 122.592014
epoch: 1142, train precision: 0.778822, train loss: 89.936130, valid precision: 0.731000, valid loss: 117.246450
epoch: 1143, train precision: 0.841289, train loss: 63.382436, valid precision: 0.766400, valid loss: 109.218372
epoch: 1144, train precision: 0.815178, train loss: 81.442155, valid precision: 0.751400, valid loss: 139.752011
epoch: 1145, train precision: 0.816422, train loss: 94.846608, valid precision: 0.743800, valid loss: 167.636573
epoch: 1146, train precision: 0.791356, train loss: 85.667871, valid precision: 0.734000, valid loss: 127.632789
epoch: 1147, train precision: 0.821778, train loss: 73.281104, valid precision: 0.757600, valid loss: 119.619493
epoch: 1148, train precision: 0.800644, train loss: 78.367914, valid precision: 0.747000, valid loss: 112.571897
epoch: 1149, train precision: 0.837333, train loss: 65.355024, valid precision: 0.761400, valid loss: 110.946702
epoch: 1150, train precision: 0.802133, train loss: 77.110628, valid precision: 0.750800, valid loss: 132.114540
epoch: 1151, train precision: 0.797622, train loss: 81.123963, valid precision: 0.736400, valid loss: 115.172611
epoch: 1152, train precision: 0.830667, train loss: 67.396496, valid precision: 0.769400, valid loss: 181.024229
epoch: 1153, train precision: 0.813133, train loss: 76.949747, valid precision: 0.742400, valid loss: 119.396974
epoch: 1154, train precision: 0.825600, train loss: 68.722467, valid precision: 0.761400, valid loss: 172.908718
epoch: 1155, train precision: 0.821733, train loss: 78.442543, valid precision: 0.757800, valid loss: 171.273604
epoch: 1156, train precision: 0.811378, train loss: 75.723185, valid precision: 0.742800, valid loss: 182.398005
epoch: 1157, train precision: 0.837044, train loss: 66.136784, valid precision: 0.768600, valid loss: 143.176233
epoch: 1158, train precision: 0.839133, train loss: 77.483041, valid precision: 0.760000, valid loss: 182.030936
epoch: 1159, train precision: 0.840756, train loss: 64.509188, valid precision: 0.765000, valid loss: 141.078706
epoch: 1160, train precision: 0.823200, train loss: 70.692564, valid precision: 0.751400, valid loss: 134.296924
epoch: 1161, train precision: 0.827400, train loss: 70.456941, valid precision: 0.755600, valid loss: 132.121180
epoch: 1162, train precision: 0.720756, train loss: 107.548765, valid precision: 0.696600, valid loss: 124.555540
epoch: 1163, train precision: 0.773778, train loss: 90.286515, valid precision: 0.736200, valid loss: 132.081931
epoch: 1164, train precision: 0.832889, train loss: 65.948296, valid precision: 0.759200, valid loss: 133.285457
epoch: 1165, train precision: 0.813644, train loss: 72.601882, valid precision: 0.751200, valid loss: 110.781722
epoch: 1166, train precision: 0.830556, train loss: 67.787171, valid precision: 0.762800, valid loss: 114.084708
epoch: 1167, train precision: 0.780667, train loss: 87.659037, valid precision: 0.743400, valid loss: 115.189828
epoch: 1168, train precision: 0.823489, train loss: 69.871541, valid precision: 0.748200, valid loss: 120.684517
epoch: 1169, train precision: 0.795689, train loss: 80.734219, valid precision: 0.739600, valid loss: 137.096172
epoch: 1170, train precision: 0.800911, train loss: 79.154285, valid precision: 0.729400, valid loss: 140.628808
epoch: 1171, train precision: 0.812044, train loss: 75.156146, valid precision: 0.758800, valid loss: 126.295555
epoch: 1172, train precision: 0.831844, train loss: 66.263133, valid precision: 0.757400, valid loss: 166.527667
epoch: 1173, train precision: 0.811756, train loss: 74.024000, valid precision: 0.748800, valid loss: 176.989369
epoch: 1174, train precision: 0.786200, train loss: 86.825491, valid precision: 0.737000, valid loss: 117.089691
epoch: 1175, train precision: 0.783200, train loss: 84.473950, valid precision: 0.732400, valid loss: 112.530816
epoch: 1176, train precision: 0.842444, train loss: 61.859948, valid precision: 0.775200, valid loss: 109.595508
epoch: 1177, train precision: 0.798667, train loss: 79.321500, valid precision: 0.736800, valid loss: 120.409470
epoch: 1178, train precision: 0.837822, train loss: 68.150048, valid precision: 0.769800, valid loss: 113.938006
epoch: 1179, train precision: 0.833778, train loss: 65.705887, valid precision: 0.758000, valid loss: 107.903767
epoch: 1180, train precision: 0.820556, train loss: 70.652985, valid precision: 0.764400, valid loss: 105.285945
epoch: 1181, train precision: 0.800089, train loss: 82.238896, valid precision: 0.741800, valid loss: 118.044400
epoch: 1182, train precision: 0.834333, train loss: 65.575699, valid precision: 0.765600, valid loss: 107.446057
epoch: 1183, train precision: 0.846956, train loss: 63.030336, valid precision: 0.765800, valid loss: 117.827849
epoch: 1184, train precision: 0.834356, train loss: 65.011146, valid precision: 0.766000, valid loss: 107.263003
epoch: 1185, train precision: 0.782511, train loss: 85.536043, valid precision: 0.737800, valid loss: 111.298394
epoch: 1186, train precision: 0.742289, train loss: 100.672212, valid precision: 0.700600, valid loss: 129.062740
epoch: 1187, train precision: 0.842778, train loss: 62.655547, valid precision: 0.764000, valid loss: 153.337166
epoch: 1188, train precision: 0.848778, train loss: 60.989753, valid precision: 0.775600, valid loss: 113.056138
epoch: 1189, train precision: 0.789289, train loss: 84.333973, valid precision: 0.726600, valid loss: 119.894983
epoch: 1190, train precision: 0.840022, train loss: 63.477156, valid precision: 0.769600, valid loss: 104.497405
epoch: 1191, train precision: 0.842822, train loss: 62.395117, valid precision: 0.759400, valid loss: 105.196613
epoch: 1192, train precision: 0.847489, train loss: 61.620776, valid precision: 0.765200, valid loss: 116.606735
epoch: 1193, train precision: 0.818156, train loss: 78.642025, valid precision: 0.745800, valid loss: 112.439744
epoch: 1194, train precision: 0.853578, train loss: 59.032505, valid precision: 0.772800, valid loss: 104.136265
epoch: 1195, train precision: 0.843933, train loss: 62.086016, valid precision: 0.760000, valid loss: 147.162445
epoch: 1196, train precision: 0.840778, train loss: 65.075974, valid precision: 0.757000, valid loss: 111.857837
epoch: 1197, train precision: 0.841800, train loss: 65.371107, valid precision: 0.759000, valid loss: 126.111323
epoch: 1198, train precision: 0.796333, train loss: 81.384856, valid precision: 0.742800, valid loss: 112.578176
epoch: 1199, train precision: 0.842489, train loss: 62.453493, valid precision: 0.765200, valid loss: 107.033340
epoch: 1200, train precision: 0.849444, train loss: 60.026136, valid precision: 0.769200, valid loss: 111.374146
epoch: 1201, train precision: 0.847111, train loss: 59.813121, valid precision: 0.760200, valid loss: 105.652387
epoch: 1202, train precision: 0.840689, train loss: 63.796366, valid precision: 0.764400, valid loss: 123.712880
epoch: 1203, train precision: 0.813044, train loss: 73.079828, valid precision: 0.751000, valid loss: 123.002304
epoch: 1204, train precision: 0.779844, train loss: 86.109435, valid precision: 0.719800, valid loss: 117.539996
epoch: 1205, train precision: 0.852111, train loss: 59.047444, valid precision: 0.775000, valid loss: 101.227275
epoch: 1206, train precision: 0.829978, train loss: 76.759786, valid precision: 0.752200, valid loss: 124.596486
epoch: 1207, train precision: 0.857067, train loss: 55.905112, valid precision: 0.767200, valid loss: 108.832489
epoch: 1208, train precision: 0.850733, train loss: 58.938862, valid precision: 0.771800, valid loss: 102.570683
epoch: 1209, train precision: 0.842711, train loss: 61.340719, valid precision: 0.760400, valid loss: 107.613939
epoch: 1210, train precision: 0.831622, train loss: 67.346456, valid precision: 0.762800, valid loss: 108.539548
epoch: 1211, train precision: 0.855778, train loss: 57.007038, valid precision: 0.771000, valid loss: 102.888459
epoch: 1212, train precision: 0.849356, train loss: 60.336494, valid precision: 0.774000, valid loss: 104.171572
epoch: 1213, train precision: 0.842956, train loss: 61.899439, valid precision: 0.764000, valid loss: 108.294350
epoch: 1214, train precision: 0.837489, train loss: 64.394386, valid precision: 0.756800, valid loss: 114.626337
epoch: 1215, train precision: 0.826067, train loss: 67.668274, valid precision: 0.751800, valid loss: 111.589585
epoch: 1216, train precision: 0.828067, train loss: 69.047200, valid precision: 0.754600, valid loss: 113.685707
epoch: 1217, train precision: 0.795667, train loss: 83.048994, valid precision: 0.731800, valid loss: 119.943420
epoch: 1218, train precision: 0.755067, train loss: 94.787914, valid precision: 0.716400, valid loss: 118.023891
epoch: 1219, train precision: 0.822556, train loss: 73.261409, valid precision: 0.760400, valid loss: 113.582862
epoch: 1220, train precision: 0.838933, train loss: 65.555622, valid precision: 0.758400, valid loss: 104.368587
epoch: 1221, train precision: 0.857667, train loss: 56.732415, valid precision: 0.774400, valid loss: 101.097656
epoch: 1222, train precision: 0.815378, train loss: 72.834359, valid precision: 0.746000, valid loss: 109.347815
epoch: 1223, train precision: 0.856044, train loss: 57.834353, valid precision: 0.764200, valid loss: 108.668342
epoch: 1224, train precision: 0.841756, train loss: 62.755143, valid precision: 0.761000, valid loss: 111.297077
epoch: 1225, train precision: 0.751533, train loss: 97.478655, valid precision: 0.702000, valid loss: 126.786334
epoch: 1226, train precision: 0.818400, train loss: 72.324260, valid precision: 0.746200, valid loss: 114.534110
epoch: 1227, train precision: 0.784222, train loss: 83.760539, valid precision: 0.727400, valid loss: 116.234259
epoch: 1228, train precision: 0.847444, train loss: 64.789056, valid precision: 0.760800, valid loss: 121.494901
epoch: 1229, train precision: 0.825111, train loss: 67.319646, valid precision: 0.754600, valid loss: 109.648920
epoch: 1230, train precision: 0.849733, train loss: 59.415656, valid precision: 0.765200, valid loss: 103.700949
epoch: 1231, train precision: 0.830867, train loss: 68.284059, valid precision: 0.750800, valid loss: 127.587589
epoch: 1232, train precision: 0.840044, train loss: 63.431658, valid precision: 0.750000, valid loss: 114.215383
epoch: 1233, train precision: 0.811467, train loss: 74.678186, valid precision: 0.740600, valid loss: 109.592871
epoch: 1234, train precision: 0.859178, train loss: 56.985987, valid precision: 0.771600, valid loss: 112.525415
epoch: 1235, train precision: 0.736956, train loss: 109.842186, valid precision: 0.702000, valid loss: 137.189910
epoch: 1236, train precision: 0.861467, train loss: 54.600115, valid precision: 0.768200, valid loss: 110.558807
epoch: 1237, train precision: 0.855711, train loss: 56.571608, valid precision: 0.765000, valid loss: 115.488957
epoch: 1238, train precision: 0.850356, train loss: 59.816947, valid precision: 0.759400, valid loss: 108.629891
epoch: 1239, train precision: 0.844978, train loss: 61.490362, valid precision: 0.770200, valid loss: 106.663209
epoch: 1240, train precision: 0.862133, train loss: 54.566065, valid precision: 0.768000, valid loss: 104.593456
epoch: 1241, train precision: 0.825422, train loss: 68.796114, valid precision: 0.755200, valid loss: 110.561931
epoch: 1242, train precision: 0.850133, train loss: 58.524783, valid precision: 0.758600, valid loss: 113.340459
epoch: 1243, train precision: 0.826156, train loss: 70.597732, valid precision: 0.747200, valid loss: 126.889178
epoch: 1244, train precision: 0.860022, train loss: 55.041626, valid precision: 0.765000, valid loss: 115.466125
epoch: 1245, train precision: 0.853267, train loss: 62.717401, valid precision: 0.761600, valid loss: 130.273846
epoch: 1246, train precision: 0.863089, train loss: 53.649840, valid precision: 0.767400, valid loss: 109.778084
epoch: 1247, train precision: 0.805222, train loss: 76.391699, valid precision: 0.739000, valid loss: 111.162295
epoch: 1248, train precision: 0.858933, train loss: 57.089212, valid precision: 0.763600, valid loss: 120.667356
epoch: 1249, train precision: 0.866933, train loss: 53.942763, valid precision: 0.773800, valid loss: 100.825948
epoch: 1250, train precision: 0.840733, train loss: 70.497422, valid precision: 0.757400, valid loss: 104.615564
epoch: 1251, train precision: 0.747267, train loss: 100.171212, valid precision: 0.705000, valid loss: 125.062527
epoch: 1252, train precision: 0.780600, train loss: 89.346125, valid precision: 0.740400, valid loss: 114.021057
epoch: 1253, train precision: 0.845933, train loss: 59.694382, valid precision: 0.762400, valid loss: 106.723466
epoch: 1254, train precision: 0.841356, train loss: 61.932743, valid precision: 0.750400, valid loss: 120.329669
epoch: 1255, train precision: 0.873511, train loss: 49.721958, valid precision: 0.776400, valid loss: 106.425269
epoch: 1256, train precision: 0.871222, train loss: 50.619569, valid precision: 0.772200, valid loss: 106.695718
epoch: 1257, train precision: 0.874178, train loss: 50.038414, valid precision: 0.773800, valid loss: 107.301564
epoch: 1258, train precision: 0.846800, train loss: 59.582699, valid precision: 0.768000, valid loss: 110.279253
epoch: 1259, train precision: 0.856644, train loss: 58.928962, valid precision: 0.767000, valid loss: 112.654006
epoch: 1260, train precision: 0.863089, train loss: 54.120931, valid precision: 0.762000, valid loss: 103.478776
epoch: 1261, train precision: 0.867000, train loss: 52.449861, valid precision: 0.765400, valid loss: 101.247972
epoch: 1262, train precision: 0.847978, train loss: 64.911879, valid precision: 0.765000, valid loss: 109.669765
epoch: 1263, train precision: 0.858844, train loss: 56.499679, valid precision: 0.766600, valid loss: 108.154328
epoch: 1264, train precision: 0.862289, train loss: 54.298229, valid precision: 0.767200, valid loss: 106.379233
epoch: 1265, train precision: 0.857044, train loss: 56.017849, valid precision: 0.762800, valid loss: 105.524094
epoch: 1266, train precision: 0.861622, train loss: 54.822661, valid precision: 0.766800, valid loss: 113.190944
epoch: 1267, train precision: 0.496022, train loss: 209.281262, valid precision: 0.497400, valid loss: 208.888621
epoch: 1268, train precision: 0.763289, train loss: 93.563368, valid precision: 0.725400, valid loss: 112.666896
epoch: 1269, train precision: 0.841889, train loss: 62.546583, valid precision: 0.766200, valid loss: 105.121622
epoch: 1270, train precision: 0.845178, train loss: 62.629819, valid precision: 0.763200, valid loss: 107.269501
epoch: 1271, train precision: 0.826956, train loss: 67.807525, valid precision: 0.752400, valid loss: 113.114295
epoch: 1272, train precision: 0.838422, train loss: 65.495895, valid precision: 0.764800, valid loss: 108.923684
epoch: 1273, train precision: 0.834667, train loss: 64.484538, valid precision: 0.749200, valid loss: 117.453433
epoch: 1274, train precision: 0.849356, train loss: 58.980714, valid precision: 0.751000, valid loss: 130.157171
epoch: 1275, train precision: 0.876600, train loss: 48.759810, valid precision: 0.769000, valid loss: 115.548925
epoch: 1276, train precision: 0.869778, train loss: 52.898741, valid precision: 0.771200, valid loss: 110.336437
epoch: 1277, train precision: 0.854689, train loss: 56.775515, valid precision: 0.761200, valid loss: 110.049990
epoch: 1278, train precision: 0.858178, train loss: 56.786455, valid precision: 0.762600, valid loss: 104.212120
epoch: 1279, train precision: 0.833911, train loss: 67.830724, valid precision: 0.747400, valid loss: 114.043549
epoch: 1280, train precision: 0.867222, train loss: 52.933719, valid precision: 0.771800, valid loss: 103.339315
epoch: 1281, train precision: 0.869267, train loss: 51.922655, valid precision: 0.775000, valid loss: 100.958808
epoch: 1282, train precision: 0.869556, train loss: 51.287327, valid precision: 0.768000, valid loss: 101.586925
epoch: 1283, train precision: 0.859222, train loss: 55.605286, valid precision: 0.766800, valid loss: 106.116180
epoch: 1284, train precision: 0.859733, train loss: 56.078776, valid precision: 0.767400, valid loss: 109.305149
epoch: 1285, train precision: 0.846089, train loss: 61.489663, valid precision: 0.762800, valid loss: 107.493000
epoch: 1286, train precision: 0.875822, train loss: 50.307340, valid precision: 0.776800, valid loss: 104.772425
epoch: 1287, train precision: 0.802511, train loss: 78.068323, valid precision: 0.747200, valid loss: 117.212955
epoch: 1288, train precision: 0.732556, train loss: 106.298428, valid precision: 0.677400, valid loss: 177.547581
epoch: 1289, train precision: 0.205244, train loss: 252.140465, valid precision: 0.208000, valid loss: 249.685725
epoch: 1290, train precision: 0.315622, train loss: 225.743601, valid precision: 0.332000, valid loss: 221.345263
epoch: 1291, train precision: 0.442867, train loss: 193.634724, valid precision: 0.471200, valid loss: 189.392879
epoch: 1292, train precision: 0.605022, train loss: 136.186427, valid precision: 0.580600, valid loss: 149.062133
epoch: 1293, train precision: 0.738956, train loss: 97.239360, valid precision: 0.680600, valid loss: 124.493446
epoch: 1294, train precision: 0.780244, train loss: 83.512319, valid precision: 0.721800, valid loss: 115.388310
epoch: 1295, train precision: 0.806200, train loss: 74.725655, valid precision: 0.727800, valid loss: 111.000190
epoch: 1296, train precision: 0.819422, train loss: 66.742095, valid precision: 0.745200, valid loss: 105.024177
epoch: 1297, train precision: 0.819800, train loss: 67.840578, valid precision: 0.746200, valid loss: 110.043012
epoch: 1298, train precision: 0.727444, train loss: 104.871240, valid precision: 0.688800, valid loss: 128.885589
epoch: 1299, train precision: 0.806089, train loss: 73.384561, valid precision: 0.734400, valid loss: 116.283679
epoch: 1300, train precision: 0.827533, train loss: 66.907414, valid precision: 0.739600, valid loss: 106.272781
epoch: 1301, train precision: 0.818689, train loss: 69.860676, valid precision: 0.742600, valid loss: 113.664178
epoch: 1302, train precision: 0.828444, train loss: 66.604927, valid precision: 0.747000, valid loss: 114.768487
epoch: 1303, train precision: 0.824178, train loss: 69.211946, valid precision: 0.744000, valid loss: 114.153635
epoch: 1304, train precision: 0.810644, train loss: 73.459989, valid precision: 0.739000, valid loss: 117.619076
epoch: 1305, train precision: 0.665111, train loss: 166.616651, valid precision: 0.651400, valid loss: 181.779672
epoch: 1306, train precision: 0.837533, train loss: 64.287023, valid precision: 0.759600, valid loss: 107.812432
epoch: 1307, train precision: 0.842822, train loss: 61.216121, valid precision: 0.759600, valid loss: 105.075275
epoch: 1308, train precision: 0.846889, train loss: 59.260649, valid precision: 0.759800, valid loss: 102.051447
epoch: 1309, train precision: 0.852044, train loss: 58.095971, valid precision: 0.768400, valid loss: 102.117175
epoch: 1310, train precision: 0.808111, train loss: 73.932382, valid precision: 0.745600, valid loss: 105.688187
epoch: 1311, train precision: 0.843956, train loss: 61.240524, valid precision: 0.751400, valid loss: 107.047871
epoch: 1312, train precision: 0.859556, train loss: 55.754664, valid precision: 0.766400, valid loss: 104.583971
epoch: 1313, train precision: 0.827867, train loss: 69.034324, valid precision: 0.748600, valid loss: 115.660374
epoch: 1314, train precision: 0.857778, train loss: 55.508128, valid precision: 0.765400, valid loss: 104.406958
epoch: 1315, train precision: 0.855644, train loss: 56.536250, valid precision: 0.760000, valid loss: 109.144992
epoch: 1316, train precision: 0.834689, train loss: 64.364487, valid precision: 0.747600, valid loss: 105.972954
epoch: 1317, train precision: 0.855444, train loss: 56.363184, valid precision: 0.761600, valid loss: 108.761522
epoch: 1318, train precision: 0.844422, train loss: 60.523269, valid precision: 0.762400, valid loss: 109.830305
epoch: 1319, train precision: 0.874333, train loss: 50.986740, valid precision: 0.773600, valid loss: 108.246108
epoch: 1320, train precision: 0.594533, train loss: 162.930963, valid precision: 0.568600, valid loss: 177.165384
epoch: 1321, train precision: 0.670467, train loss: 133.801298, valid precision: 0.659600, valid loss: 142.172952
epoch: 1322, train precision: 0.747111, train loss: 96.107443, valid precision: 0.696200, valid loss: 120.364636
epoch: 1323, train precision: 0.823622, train loss: 68.815179, valid precision: 0.736400, valid loss: 115.421631
epoch: 1324, train precision: 0.782689, train loss: 84.973997, valid precision: 0.723200, valid loss: 118.688969
epoch: 1325, train precision: 0.836067, train loss: 64.522061, valid precision: 0.760600, valid loss: 106.659383
epoch: 1326, train precision: 0.861733, train loss: 53.917555, valid precision: 0.768400, valid loss: 105.716781
epoch: 1327, train precision: 0.869200, train loss: 52.662677, valid precision: 0.775200, valid loss: 104.807452
epoch: 1328, train precision: 0.801556, train loss: 78.530286, valid precision: 0.742400, valid loss: 116.501996
epoch: 1329, train precision: 0.859622, train loss: 56.703018, valid precision: 0.763400, valid loss: 109.942701
epoch: 1330, train precision: 0.870244, train loss: 53.537778, valid precision: 0.771000, valid loss: 109.706154
epoch: 1331, train precision: 0.870511, train loss: 51.777930, valid precision: 0.755400, valid loss: 127.956926
epoch: 1332, train precision: 0.868156, train loss: 53.086311, valid precision: 0.765600, valid loss: 111.570902
epoch: 1333, train precision: 0.710733, train loss: 119.747021, valid precision: 0.668800, valid loss: 144.436693
epoch: 1334, train precision: 0.862622, train loss: 55.194811, valid precision: 0.759000, valid loss: 117.446213
epoch: 1335, train precision: 0.850622, train loss: 60.061725, valid precision: 0.758400, valid loss: 110.562018
epoch: 1336, train precision: 0.868111, train loss: 51.683124, valid precision: 0.764800, valid loss: 107.926492
epoch: 1337, train precision: 0.854289, train loss: 56.078352, valid precision: 0.766400, valid loss: 105.042660
epoch: 1338, train precision: 0.858156, train loss: 57.500253, valid precision: 0.762200, valid loss: 113.323577
epoch: 1339, train precision: 0.820067, train loss: 71.062572, valid precision: 0.748000, valid loss: 114.106675
epoch: 1340, train precision: 0.876822, train loss: 49.055350, valid precision: 0.768400, valid loss: 104.506124
epoch: 1341, train precision: 0.858933, train loss: 55.591654, valid precision: 0.768600, valid loss: 106.791319
epoch: 1342, train precision: 0.880667, train loss: 48.464412, valid precision: 0.770400, valid loss: 103.978100
epoch: 1343, train precision: 0.424556, train loss: 213.770444, valid precision: 0.417800, valid loss: 221.181270
epoch: 1344, train precision: 0.862556, train loss: 54.371357, valid precision: 0.765200, valid loss: 108.721282
epoch: 1345, train precision: 0.882689, train loss: 47.302364, valid precision: 0.775600, valid loss: 109.377469
epoch: 1346, train precision: 0.862467, train loss: 53.929186, valid precision: 0.759800, valid loss: 120.369340
epoch: 1347, train precision: 0.869000, train loss: 52.064658, valid precision: 0.762600, valid loss: 108.332739
epoch: 1348, train precision: 0.864333, train loss: 55.243663, valid precision: 0.762200, valid loss: 114.405177
epoch: 1349, train precision: 0.860422, train loss: 55.458435, valid precision: 0.758400, valid loss: 104.883330
epoch: 1350, train precision: 0.869311, train loss: 51.352351, valid precision: 0.771000, valid loss: 102.866244
epoch: 1351, train precision: 0.858844, train loss: 55.462014, valid precision: 0.761200, valid loss: 113.922589
epoch: 1352, train precision: 0.877400, train loss: 48.856766, valid precision: 0.775000, valid loss: 108.862002
epoch: 1353, train precision: 0.838111, train loss: 63.102428, valid precision: 0.743400, valid loss: 117.364938
epoch: 1354, train precision: 0.881133, train loss: 47.501097, valid precision: 0.770400, valid loss: 101.889820
epoch: 1355, train precision: 0.854067, train loss: 58.741128, valid precision: 0.764000, valid loss: 103.484498
epoch: 1356, train precision: 0.822022, train loss: 70.049838, valid precision: 0.743200, valid loss: 114.809120
epoch: 1357, train precision: 0.871022, train loss: 50.473126, valid precision: 0.767000, valid loss: 105.152185
epoch: 1358, train precision: 0.886400, train loss: 45.913876, valid precision: 0.778000, valid loss: 106.496588
epoch: 1359, train precision: 0.888622, train loss: 47.195737, valid precision: 0.773200, valid loss: 104.394869
epoch: 1360, train precision: 0.864422, train loss: 53.475369, valid precision: 0.765400, valid loss: 106.576273
epoch: 1361, train precision: 0.869756, train loss: 50.571434, valid precision: 0.774400, valid loss: 103.125211
epoch: 1362, train precision: 0.875222, train loss: 49.123846, valid precision: 0.761200, valid loss: 108.269758
epoch: 1363, train precision: 0.874089, train loss: 49.935834, valid precision: 0.769200, valid loss: 107.057446
epoch: 1364, train precision: 0.852667, train loss: 57.236243, valid precision: 0.760000, valid loss: 109.864796
epoch: 1365, train precision: 0.859578, train loss: 56.000056, valid precision: 0.750000, valid loss: 120.655150
epoch: 1366, train precision: 0.847756, train loss: 69.007859, valid precision: 0.755800, valid loss: 117.088436
epoch: 1367, train precision: 0.876644, train loss: 49.282339, valid precision: 0.765600, valid loss: 113.402857
epoch: 1368, train precision: 0.712222, train loss: 118.449170, valid precision: 0.669000, valid loss: 153.733201
epoch: 1369, train precision: 0.641778, train loss: 141.509736, valid precision: 0.619200, valid loss: 156.226694
epoch: 1370, train precision: 0.884511, train loss: 45.958437, valid precision: 0.769000, valid loss: 108.684297
epoch: 1371, train precision: 0.880711, train loss: 47.206181, valid precision: 0.769400, valid loss: 109.222933
epoch: 1372, train precision: 0.875267, train loss: 49.937034, valid precision: 0.762400, valid loss: 112.176302
epoch: 1373, train precision: 0.877156, train loss: 50.962118, valid precision: 0.763600, valid loss: 116.913624
epoch: 1374, train precision: 0.848000, train loss: 60.619914, valid precision: 0.749600, valid loss: 120.960803
epoch: 1375, train precision: 0.864133, train loss: 54.413174, valid precision: 0.763800, valid loss: 111.917158
epoch: 1376, train precision: 0.877400, train loss: 48.334419, valid precision: 0.766400, valid loss: 111.098441
epoch: 1377, train precision: 0.876200, train loss: 49.676097, valid precision: 0.772400, valid loss: 105.664067
epoch: 1378, train precision: 0.866667, train loss: 52.474109, valid precision: 0.764000, valid loss: 112.199239
epoch: 1379, train precision: 0.841178, train loss: 67.022731, valid precision: 0.749000, valid loss: 136.836577
epoch: 1380, train precision: 0.871667, train loss: 50.722299, valid precision: 0.764800, valid loss: 110.251097
epoch: 1381, train precision: 0.862378, train loss: 55.099278, valid precision: 0.758800, valid loss: 108.478507
epoch: 1382, train precision: 0.888089, train loss: 45.251469, valid precision: 0.771600, valid loss: 108.706625
epoch: 1383, train precision: 0.862644, train loss: 56.456921, valid precision: 0.760000, valid loss: 113.547032
epoch: 1384, train precision: 0.886467, train loss: 44.706979, valid precision: 0.776000, valid loss: 104.053097
epoch: 1385, train precision: 0.875089, train loss: 49.568182, valid precision: 0.764200, valid loss: 105.752611
epoch: 1386, train precision: 0.844511, train loss: 60.766001, valid precision: 0.751200, valid loss: 107.792568
epoch: 1387, train precision: 0.860933, train loss: 55.976277, valid precision: 0.767200, valid loss: 110.475585
epoch: 1388, train precision: 0.873844, train loss: 50.458261, valid precision: 0.774000, valid loss: 105.293828
epoch: 1389, train precision: 0.889000, train loss: 44.006275, valid precision: 0.773400, valid loss: 108.942442
epoch: 1390, train precision: 0.885911, train loss: 44.724742, valid precision: 0.767800, valid loss: 110.074184
epoch: 1391, train precision: 0.904644, train loss: 39.048311, valid precision: 0.781800, valid loss: 110.836704
epoch: 1392, train precision: 0.811356, train loss: 71.204448, valid precision: 0.724200, valid loss: 123.056397
epoch: 1393, train precision: 0.839600, train loss: 62.669707, valid precision: 0.744800, valid loss: 125.286361
epoch: 1394, train precision: 0.866644, train loss: 52.311438, valid precision: 0.762200, valid loss: 112.749993
epoch: 1395, train precision: 0.865889, train loss: 55.976300, valid precision: 0.765200, valid loss: 129.532018
epoch: 1396, train precision: 0.872711, train loss: 50.147116, valid precision: 0.758200, valid loss: 110.685377
epoch: 1397, train precision: 0.827356, train loss: 68.808281, valid precision: 0.738400, valid loss: 113.431760
epoch: 1398, train precision: 0.898178, train loss: 41.819026, valid precision: 0.770600, valid loss: 140.942355
epoch: 1399, train precision: 0.818756, train loss: 74.373809, valid precision: 0.740000, valid loss: 132.385320
epoch: 1400, train precision: 0.850444, train loss: 58.089780, valid precision: 0.750800, valid loss: 108.305222
epoch: 1401, train precision: 0.852489, train loss: 58.257496, valid precision: 0.762200, valid loss: 109.545631
epoch: 1402, train precision: 0.886156, train loss: 44.670602, valid precision: 0.769800, valid loss: 107.739102
epoch: 1403, train precision: 0.885911, train loss: 44.658668, valid precision: 0.768600, valid loss: 112.725510
epoch: 1404, train precision: 0.863444, train loss: 53.662871, valid precision: 0.765400, valid loss: 107.650307
epoch: 1405, train precision: 0.876467, train loss: 49.085210, valid precision: 0.766000, valid loss: 113.829177
epoch: 1406, train precision: 0.834933, train loss: 67.197715, valid precision: 0.750200, valid loss: 111.669679
epoch: 1407, train precision: 0.889156, train loss: 44.205660, valid precision: 0.766000, valid loss: 111.634302
epoch: 1408, train precision: 0.862667, train loss: 53.171833, valid precision: 0.766800, valid loss: 110.654138
epoch: 1409, train precision: 0.885444, train loss: 46.117450, valid precision: 0.769200, valid loss: 110.868887
epoch: 1410, train precision: 0.866444, train loss: 52.470302, valid precision: 0.760400, valid loss: 110.762452
epoch: 1411, train precision: 0.882889, train loss: 47.643294, valid precision: 0.764000, valid loss: 120.511125
epoch: 1412, train precision: 0.876533, train loss: 48.313743, valid precision: 0.763200, valid loss: 112.997927
epoch: 1413, train precision: 0.896956, train loss: 42.044389, valid precision: 0.773200, valid loss: 104.279312
epoch: 1414, train precision: 0.879467, train loss: 48.178433, valid precision: 0.761800, valid loss: 114.164876
epoch: 1415, train precision: 0.849444, train loss: 59.645609, valid precision: 0.753800, valid loss: 113.382287
epoch: 1416, train precision: 0.889778, train loss: 44.934974, valid precision: 0.771200, valid loss: 111.358691
epoch: 1417, train precision: 0.860178, train loss: 54.480150, valid precision: 0.757200, valid loss: 114.379398
epoch: 1418, train precision: 0.805578, train loss: 78.204600, valid precision: 0.713400, valid loss: 135.326436
epoch: 1419, train precision: 0.892578, train loss: 42.597103, valid precision: 0.778400, valid loss: 114.360920
epoch: 1420, train precision: 0.850000, train loss: 59.063364, valid precision: 0.743800, valid loss: 112.987639
epoch: 1421, train precision: 0.895756, train loss: 41.967623, valid precision: 0.773600, valid loss: 112.628916
epoch: 1422, train precision: 0.897667, train loss: 41.300752, valid precision: 0.771400, valid loss: 113.750533
epoch: 1423, train precision: 0.879067, train loss: 49.366077, valid precision: 0.767800, valid loss: 112.273397
epoch: 1424, train precision: 0.897644, train loss: 41.646085, valid precision: 0.771800, valid loss: 112.890103
epoch: 1425, train precision: 0.889267, train loss: 49.667951, valid precision: 0.767600, valid loss: 134.594683
epoch: 1426, train precision: 0.888089, train loss: 45.225593, valid precision: 0.770400, valid loss: 108.819101
epoch: 1427, train precision: 0.865000, train loss: 53.798319, valid precision: 0.765600, valid loss: 113.080602
epoch: 1428, train precision: 0.898311, train loss: 40.132196, valid precision: 0.768000, valid loss: 111.067231
epoch: 1429, train precision: 0.895044, train loss: 41.729385, valid precision: 0.776600, valid loss: 110.404486
epoch: 1430, train precision: 0.902622, train loss: 38.484378, valid precision: 0.771000, valid loss: 115.903647
epoch: 1431, train precision: 0.889333, train loss: 43.583530, valid precision: 0.767600, valid loss: 115.316663
epoch: 1432, train precision: 0.898800, train loss: 40.924507, valid precision: 0.764600, valid loss: 123.959799
epoch: 1433, train precision: 0.855156, train loss: 57.679180, valid precision: 0.747800, valid loss: 134.998534
epoch: 1434, train precision: 0.900800, train loss: 40.489807, valid precision: 0.772000, valid loss: 120.399718
epoch: 1435, train precision: 0.840267, train loss: 64.122145, valid precision: 0.742800, valid loss: 121.857843
epoch: 1436, train precision: 0.896000, train loss: 42.497380, valid precision: 0.761200, valid loss: 122.080394
epoch: 1437, train precision: 0.813911, train loss: 72.595978, valid precision: 0.738400, valid loss: 119.907710
epoch: 1438, train precision: 0.880356, train loss: 48.805329, valid precision: 0.757800, valid loss: 132.596716
epoch: 1439, train precision: 0.830644, train loss: 67.751858, valid precision: 0.745600, valid loss: 115.494514
epoch: 1440, train precision: 0.892667, train loss: 43.951784, valid precision: 0.770600, valid loss: 113.122776
epoch: 1441, train precision: 0.893422, train loss: 42.224888, valid precision: 0.770800, valid loss: 111.119548
epoch: 1442, train precision: 0.901267, train loss: 39.591638, valid precision: 0.769200, valid loss: 112.624461
epoch: 1443, train precision: 0.841778, train loss: 63.069984, valid precision: 0.749400, valid loss: 112.378496
epoch: 1444, train precision: 0.879867, train loss: 46.827383, valid precision: 0.773200, valid loss: 104.133109
epoch: 1445, train precision: 0.810556, train loss: 74.727998, valid precision: 0.730600, valid loss: 115.919506
epoch: 1446, train precision: 0.834822, train loss: 64.566136, valid precision: 0.739600, valid loss: 128.149750
epoch: 1447, train precision: 0.872556, train loss: 51.067405, valid precision: 0.763000, valid loss: 113.679127
epoch: 1448, train precision: 0.899200, train loss: 44.368783, valid precision: 0.778200, valid loss: 114.273750
epoch: 1449, train precision: 0.866733, train loss: 52.784890, valid precision: 0.756400, valid loss: 120.713000
epoch: 1450, train precision: 0.894289, train loss: 41.877159, valid precision: 0.769600, valid loss: 115.400904
epoch: 1451, train precision: 0.906111, train loss: 38.982510, valid precision: 0.776200, valid loss: 111.350556
epoch: 1452, train precision: 0.840400, train loss: 64.464808, valid precision: 0.745200, valid loss: 118.780958
epoch: 1453, train precision: 0.833000, train loss: 66.233986, valid precision: 0.730400, valid loss: 117.827487
epoch: 1454, train precision: 0.875600, train loss: 51.629009, valid precision: 0.757600, valid loss: 124.021116
epoch: 1455, train precision: 0.900111, train loss: 41.455654, valid precision: 0.767000, valid loss: 113.292293
epoch: 1456, train precision: 0.880889, train loss: 48.533718, valid precision: 0.763000, valid loss: 118.069885
epoch: 1457, train precision: 0.891156, train loss: 43.837356, valid precision: 0.774000, valid loss: 128.400235
epoch: 1458, train precision: 0.746333, train loss: 105.512219, valid precision: 0.693800, valid loss: 147.368107
epoch: 1459, train precision: 0.892244, train loss: 44.645475, valid precision: 0.772200, valid loss: 134.843061
epoch: 1460, train precision: 0.896444, train loss: 42.300148, valid precision: 0.761400, valid loss: 120.459772
epoch: 1461, train precision: 0.860711, train loss: 55.659367, valid precision: 0.759200, valid loss: 115.941990
epoch: 1462, train precision: 0.893311, train loss: 42.780824, valid precision: 0.763000, valid loss: 121.179057
epoch: 1463, train precision: 0.899378, train loss: 40.158824, valid precision: 0.775400, valid loss: 111.785139
epoch: 1464, train precision: 0.904089, train loss: 38.610181, valid precision: 0.767600, valid loss: 150.657941
epoch: 1465, train precision: 0.901733, train loss: 39.646948, valid precision: 0.776800, valid loss: 109.555443
epoch: 1466, train precision: 0.800244, train loss: 79.816185, valid precision: 0.727000, valid loss: 123.500091
epoch: 1467, train precision: 0.896556, train loss: 42.159379, valid precision: 0.777000, valid loss: 107.816519
epoch: 1468, train precision: 0.900333, train loss: 40.093992, valid precision: 0.769000, valid loss: 111.467135
epoch: 1469, train precision: 0.893222, train loss: 42.342915, valid precision: 0.766400, valid loss: 116.618955
epoch: 1470, train precision: 0.858644, train loss: 55.568952, valid precision: 0.756800, valid loss: 117.761683
epoch: 1471, train precision: 0.905756, train loss: 37.673449, valid precision: 0.782000, valid loss: 107.083918
epoch: 1472, train precision: 0.668133, train loss: 137.567472, valid precision: 0.640200, valid loss: 160.208686
epoch: 1473, train precision: 0.841267, train loss: 63.712344, valid precision: 0.741800, valid loss: 122.030363
epoch: 1474, train precision: 0.908400, train loss: 36.673780, valid precision: 0.772000, valid loss: 115.269990
epoch: 1475, train precision: 0.909244, train loss: 39.104191, valid precision: 0.771400, valid loss: 130.318666
epoch: 1476, train precision: 0.794244, train loss: 82.717434, valid precision: 0.725800, valid loss: 148.233766
epoch: 1477, train precision: 0.906244, train loss: 38.393504, valid precision: 0.776600, valid loss: 127.261453
epoch: 1478, train precision: 0.888067, train loss: 44.608093, valid precision: 0.769600, valid loss: 126.853065
epoch: 1479, train precision: 0.894556, train loss: 41.813540, valid precision: 0.772800, valid loss: 147.680189
epoch: 1480, train precision: 0.877911, train loss: 49.848036, valid precision: 0.758000, valid loss: 124.702595
epoch: 1481, train precision: 0.891267, train loss: 45.362432, valid precision: 0.764800, valid loss: 116.395367
epoch: 1482, train precision: 0.899178, train loss: 40.947960, valid precision: 0.769200, valid loss: 120.610071
epoch: 1483, train precision: 0.889400, train loss: 44.556176, valid precision: 0.766800, valid loss: 118.186229
epoch: 1484, train precision: 0.850156, train loss: 59.778930, valid precision: 0.763000, valid loss: 119.051004
epoch: 1485, train precision: 0.907000, train loss: 37.036800, valid precision: 0.773600, valid loss: 140.144771
epoch: 1486, train precision: 0.905644, train loss: 38.683915, valid precision: 0.771600, valid loss: 137.205790
epoch: 1487, train precision: 0.905778, train loss: 38.097633, valid precision: 0.771400, valid loss: 140.780910
epoch: 1488, train precision: 0.865689, train loss: 53.652375, valid precision: 0.761000, valid loss: 138.629879
epoch: 1489, train precision: 0.902889, train loss: 39.296736, valid precision: 0.771000, valid loss: 135.085047
epoch: 1490, train precision: 0.897667, train loss: 40.538087, valid precision: 0.774600, valid loss: 109.732961
epoch: 1491, train precision: 0.869533, train loss: 52.444398, valid precision: 0.756600, valid loss: 116.747012
epoch: 1492, train precision: 0.351000, train loss: 322.762814, valid precision: 0.364200, valid loss: 305.522805
epoch: 1493, train precision: 0.432333, train loss: 199.263182, valid precision: 0.438600, valid loss: 194.874807
epoch: 1494, train precision: 0.806133, train loss: 74.213011, valid precision: 0.715600, valid loss: 129.431498
epoch: 1495, train precision: 0.869178, train loss: 51.507278, valid precision: 0.748800, valid loss: 111.419085
epoch: 1496, train precision: 0.870333, train loss: 50.847348, valid precision: 0.759600, valid loss: 107.693868
epoch: 1497, train precision: 0.888467, train loss: 46.456769, valid precision: 0.764600, valid loss: 123.348255
epoch: 1498, train precision: 0.903400, train loss: 38.934828, valid precision: 0.768200, valid loss: 110.977419
epoch: 1499, train precision: 0.872133, train loss: 51.039250, valid precision: 0.766600, valid loss: 111.600952
epoch: 1500, train precision: 0.854200, train loss: 56.924143, valid precision: 0.750200, valid loss: 117.158269
epoch: 1501, train precision: 0.839044, train loss: 65.392132, valid precision: 0.755200, valid loss: 123.893710
epoch: 1502, train precision: 0.871356, train loss: 49.683445, valid precision: 0.762600, valid loss: 122.754422
epoch: 1503, train precision: 0.898822, train loss: 41.460996, valid precision: 0.775000, valid loss: 133.537907
epoch: 1504, train precision: 0.897978, train loss: 41.032337, valid precision: 0.775000, valid loss: 141.454914
epoch: 1505, train precision: 0.885289, train loss: 46.144680, valid precision: 0.766600, valid loss: 128.759328
epoch: 1506, train precision: 0.725156, train loss: 112.921649, valid precision: 0.675400, valid loss: 148.867176
epoch: 1507, train precision: 0.826867, train loss: 67.768309, valid precision: 0.733800, valid loss: 131.607756
epoch: 1508, train precision: 0.864933, train loss: 56.291291, valid precision: 0.752200, valid loss: 136.273189
epoch: 1509, train precision: 0.898511, train loss: 42.073290, valid precision: 0.773800, valid loss: 133.197158
epoch: 1510, train precision: 0.882889, train loss: 45.109383, valid precision: 0.766800, valid loss: 127.696478
epoch: 1511, train precision: 0.899889, train loss: 40.282118, valid precision: 0.771400, valid loss: 127.946699
epoch: 1512, train precision: 0.912422, train loss: 35.300861, valid precision: 0.768600, valid loss: 121.846420
epoch: 1513, train precision: 0.907000, train loss: 38.198450, valid precision: 0.776200, valid loss: 118.450452
epoch: 1514, train precision: 0.912133, train loss: 35.679090, valid precision: 0.773600, valid loss: 111.722406
epoch: 1515, train precision: 0.832044, train loss: 67.894200, valid precision: 0.741000, valid loss: 120.611694
epoch: 1516, train precision: 0.767178, train loss: 90.548944, valid precision: 0.701400, valid loss: 147.236242
epoch: 1517, train precision: 0.892156, train loss: 44.549172, valid precision: 0.776200, valid loss: 113.810589
epoch: 1518, train precision: 0.874622, train loss: 50.077419, valid precision: 0.766600, valid loss: 116.001603
epoch: 1519, train precision: 0.894800, train loss: 42.467345, valid precision: 0.768800, valid loss: 123.992269
epoch: 1520, train precision: 0.642978, train loss: 141.658247, valid precision: 0.617000, valid loss: 156.776389
epoch: 1521, train precision: 0.893133, train loss: 43.503265, valid precision: 0.764000, valid loss: 117.524540
epoch: 1522, train precision: 0.896311, train loss: 42.302213, valid precision: 0.765200, valid loss: 116.832280
epoch: 1523, train precision: 0.896756, train loss: 42.078113, valid precision: 0.773600, valid loss: 115.629747
epoch: 1524, train precision: 0.902600, train loss: 40.136688, valid precision: 0.775800, valid loss: 116.990546
epoch: 1525, train precision: 0.871733, train loss: 49.836582, valid precision: 0.763600, valid loss: 112.351131
epoch: 1526, train precision: 0.901689, train loss: 40.689621, valid precision: 0.772200, valid loss: 123.245743
epoch: 1527, train precision: 0.899978, train loss: 39.928260, valid precision: 0.770800, valid loss: 114.163767
epoch: 1528, train precision: 0.900111, train loss: 40.537839, valid precision: 0.769600, valid loss: 116.277213
epoch: 1529, train precision: 0.864956, train loss: 54.552711, valid precision: 0.750600, valid loss: 116.334496
epoch: 1530, train precision: 0.904022, train loss: 39.403091, valid precision: 0.769800, valid loss: 117.912559
epoch: 1531, train precision: 0.826044, train loss: 70.792387, valid precision: 0.739800, valid loss: 119.865473
epoch: 1532, train precision: 0.900044, train loss: 41.934181, valid precision: 0.773000, valid loss: 112.553277
epoch: 1533, train precision: 0.891978, train loss: 43.400127, valid precision: 0.763600, valid loss: 122.176614
epoch: 1534, train precision: 0.915133, train loss: 35.004581, valid precision: 0.775200, valid loss: 114.054884
epoch: 1535, train precision: 0.900756, train loss: 39.805112, valid precision: 0.768400, valid loss: 119.316764
epoch: 1536, train precision: 0.767889, train loss: 92.427145, valid precision: 0.701200, valid loss: 146.657677
epoch: 1537, train precision: 0.824067, train loss: 71.578937, valid precision: 0.749400, valid loss: 125.339802
epoch: 1538, train precision: 0.897489, train loss: 42.327000, valid precision: 0.770000, valid loss: 113.591924
epoch: 1539, train precision: 0.594467, train loss: 170.920279, valid precision: 0.591400, valid loss: 194.239383
epoch: 1540, train precision: 0.899600, train loss: 40.323113, valid precision: 0.766400, valid loss: 113.960526
epoch: 1541, train precision: 0.913378, train loss: 35.411098, valid precision: 0.777400, valid loss: 116.106023
epoch: 1542, train precision: 0.911556, train loss: 35.681379, valid precision: 0.773800, valid loss: 134.841336
epoch: 1543, train precision: 0.905622, train loss: 37.794405, valid precision: 0.767400, valid loss: 141.701821
epoch: 1544, train precision: 0.898133, train loss: 43.130658, valid precision: 0.766000, valid loss: 138.433651
epoch: 1545, train precision: 0.907422, train loss: 37.261756, valid precision: 0.773200, valid loss: 113.046151
epoch: 1546, train precision: 0.436444, train loss: 205.586893, valid precision: 0.438000, valid loss: 206.923070
epoch: 1547, train precision: 0.900422, train loss: 40.530507, valid precision: 0.772200, valid loss: 119.786514
epoch: 1548, train precision: 0.500489, train loss: 213.208342, valid precision: 0.510800, valid loss: 209.361021
epoch: 1549, train precision: 0.898067, train loss: 41.061791, valid precision: 0.769800, valid loss: 157.087837
epoch: 1550, train precision: 0.896000, train loss: 41.591238, valid precision: 0.769400, valid loss: 111.758277
epoch: 1551, train precision: 0.896022, train loss: 43.008933, valid precision: 0.764600, valid loss: 138.162356
epoch: 1552, train precision: 0.902733, train loss: 38.959147, valid precision: 0.782000, valid loss: 113.347407
epoch: 1553, train precision: 0.909044, train loss: 36.653638, valid precision: 0.775600, valid loss: 110.861423
epoch: 1554, train precision: 0.676489, train loss: 135.650155, valid precision: 0.647800, valid loss: 157.435368
epoch: 1555, train precision: 0.905200, train loss: 39.284289, valid precision: 0.776600, valid loss: 113.798905
epoch: 1556, train precision: 0.876822, train loss: 49.216665, valid precision: 0.760400, valid loss: 117.148961
epoch: 1557, train precision: 0.907533, train loss: 37.756120, valid precision: 0.776200, valid loss: 117.760385
epoch: 1558, train precision: 0.844578, train loss: 65.114574, valid precision: 0.746400, valid loss: 127.587479
epoch: 1559, train precision: 0.871667, train loss: 51.772855, valid precision: 0.763800, valid loss: 115.171412
epoch: 1560, train precision: 0.889222, train loss: 45.129961, valid precision: 0.762800, valid loss: 119.417209
epoch: 1561, train precision: 0.901800, train loss: 39.767473, valid precision: 0.766800, valid loss: 121.348849
epoch: 1562, train precision: 0.904867, train loss: 39.198241, valid precision: 0.774400, valid loss: 124.574951
epoch: 1563, train precision: 0.900489, train loss: 39.609998, valid precision: 0.772000, valid loss: 117.728692
epoch: 1564, train precision: 0.883978, train loss: 46.039126, valid precision: 0.757400, valid loss: 116.549127
epoch: 1565, train precision: 0.885067, train loss: 46.203995, valid precision: 0.765800, valid loss: 123.916679
epoch: 1566, train precision: 0.898644, train loss: 40.788204, valid precision: 0.766800, valid loss: 124.205403
epoch: 1567, train precision: 0.907733, train loss: 37.884828, valid precision: 0.766800, valid loss: 124.024982
epoch: 1568, train precision: 0.912933, train loss: 34.416769, valid precision: 0.768400, valid loss: 121.714099
epoch: 1569, train precision: 0.908933, train loss: 36.809249, valid precision: 0.774400, valid loss: 136.956191
epoch: 1570, train precision: 0.686867, train loss: 141.853099, valid precision: 0.653200, valid loss: 172.702541
epoch: 1571, train precision: 0.903378, train loss: 38.287857, valid precision: 0.763400, valid loss: 121.857868
epoch: 1572, train precision: 0.902333, train loss: 39.454525, valid precision: 0.771000, valid loss: 128.481737
epoch: 1573, train precision: 0.846778, train loss: 63.315988, valid precision: 0.740000, valid loss: 129.060498
epoch: 1574, train precision: 0.894911, train loss: 42.693249, valid precision: 0.766800, valid loss: 155.680017
epoch: 1575, train precision: 0.904489, train loss: 39.405197, valid precision: 0.770600, valid loss: 122.508320
epoch: 1576, train precision: 0.903733, train loss: 39.553440, valid precision: 0.759600, valid loss: 129.947221
epoch: 1577, train precision: 0.897444, train loss: 41.025757, valid precision: 0.757000, valid loss: 120.793917
epoch: 1578, train precision: 0.882844, train loss: 46.721719, valid precision: 0.768800, valid loss: 122.574414
epoch: 1579, train precision: 0.912644, train loss: 37.285868, valid precision: 0.773000, valid loss: 116.358235
epoch: 1580, train precision: 0.883978, train loss: 46.748839, valid precision: 0.758800, valid loss: 117.924589
epoch: 1581, train precision: 0.911422, train loss: 36.020938, valid precision: 0.775000, valid loss: 112.044995
epoch: 1582, train precision: 0.814600, train loss: 74.662066, valid precision: 0.727000, valid loss: 121.416833
epoch: 1583, train precision: 0.898511, train loss: 40.811093, valid precision: 0.769600, valid loss: 117.034962
epoch: 1584, train precision: 0.911933, train loss: 35.813721, valid precision: 0.767200, valid loss: 120.881753
epoch: 1585, train precision: 0.890422, train loss: 42.783219, valid precision: 0.765600, valid loss: 114.639617
epoch: 1586, train precision: 0.915222, train loss: 34.608411, valid precision: 0.771400, valid loss: 120.403597
epoch: 1587, train precision: 0.885933, train loss: 50.362044, valid precision: 0.763600, valid loss: 120.806016
epoch: 1588, train precision: 0.895689, train loss: 42.115521, valid precision: 0.771800, valid loss: 119.076943
epoch: 1589, train precision: 0.903956, train loss: 38.711877, valid precision: 0.767400, valid loss: 121.773924
epoch: 1590, train precision: 0.893711, train loss: 42.409562, valid precision: 0.758600, valid loss: 126.669819
epoch: 1591, train precision: 0.924133, train loss: 31.021098, valid precision: 0.775800, valid loss: 117.147238
epoch: 1592, train precision: 0.898511, train loss: 42.973555, valid precision: 0.756200, valid loss: 126.640290
epoch: 1593, train precision: 0.919000, train loss: 33.209803, valid precision: 0.785200, valid loss: 117.777007
epoch: 1594, train precision: 0.871756, train loss: 51.403188, valid precision: 0.752200, valid loss: 129.115218
epoch: 1595, train precision: 0.895800, train loss: 42.380017, valid precision: 0.772200, valid loss: 125.806938
epoch: 1596, train precision: 0.865089, train loss: 54.260268, valid precision: 0.753400, valid loss: 124.473617
epoch: 1597, train precision: 0.922689, train loss: 32.631943, valid precision: 0.772800, valid loss: 119.792142
epoch: 1598, train precision: 0.888444, train loss: 45.712766, valid precision: 0.768400, valid loss: 116.126290
epoch: 1599, train precision: 0.914667, train loss: 36.279110, valid precision: 0.776400, valid loss: 118.487822
epoch: 1600, train precision: 0.922178, train loss: 31.818439, valid precision: 0.776600, valid loss: 110.726255
epoch: 1601, train precision: 0.324089, train loss: 230.973222, valid precision: 0.331800, valid loss: 228.521255
epoch: 1602, train precision: 0.551933, train loss: 164.009665, valid precision: 0.560000, valid loss: 168.688323
epoch: 1603, train precision: 0.832356, train loss: 66.171225, valid precision: 0.738800, valid loss: 119.438034
epoch: 1604, train precision: 0.909689, train loss: 37.069716, valid precision: 0.768400, valid loss: 158.634162
epoch: 1605, train precision: 0.921489, train loss: 33.676261, valid precision: 0.780400, valid loss: 124.592892
epoch: 1606, train precision: 0.895733, train loss: 41.594774, valid precision: 0.773000, valid loss: 115.550601
epoch: 1607, train precision: 0.909444, train loss: 36.805878, valid precision: 0.766000, valid loss: 121.478003
epoch: 1608, train precision: 0.837867, train loss: 64.238158, valid precision: 0.727200, valid loss: 131.304403
epoch: 1609, train precision: 0.906467, train loss: 37.663349, valid precision: 0.765200, valid loss: 120.665396
epoch: 1610, train precision: 0.822600, train loss: 71.065512, valid precision: 0.739800, valid loss: 125.186005
epoch: 1611, train precision: 0.910400, train loss: 36.076173, valid precision: 0.776200, valid loss: 114.998627
epoch: 1612, train precision: 0.862400, train loss: 58.344634, valid precision: 0.756600, valid loss: 126.264076
epoch: 1613, train precision: 0.827400, train loss: 70.054166, valid precision: 0.743400, valid loss: 131.550314
epoch: 1614, train precision: 0.910600, train loss: 36.996472, valid precision: 0.779800, valid loss: 123.366016
epoch: 1615, train precision: 0.925156, train loss: 30.527508, valid precision: 0.780800, valid loss: 139.354613
epoch: 1616, train precision: 0.906622, train loss: 36.903775, valid precision: 0.769400, valid loss: 115.840117
epoch: 1617, train precision: 0.912600, train loss: 35.330849, valid precision: 0.773200, valid loss: 121.602942
epoch: 1618, train precision: 0.468933, train loss: 203.110343, valid precision: 0.477600, valid loss: 199.697070
epoch: 1619, train precision: 0.903022, train loss: 40.333897, valid precision: 0.769200, valid loss: 119.894638
epoch: 1620, train precision: 0.926333, train loss: 30.976988, valid precision: 0.778200, valid loss: 117.015812
epoch: 1621, train precision: 0.896844, train loss: 41.196425, valid precision: 0.774400, valid loss: 111.089956
epoch: 1622, train precision: 0.869667, train loss: 52.945201, valid precision: 0.762800, valid loss: 117.129589
epoch: 1623, train precision: 0.902533, train loss: 38.489866, valid precision: 0.770200, valid loss: 115.730362
epoch: 1624, train precision: 0.910378, train loss: 37.964144, valid precision: 0.767600, valid loss: 120.439615
epoch: 1625, train precision: 0.903756, train loss: 38.786175, valid precision: 0.767000, valid loss: 122.304918
epoch: 1626, train precision: 0.913178, train loss: 37.001890, valid precision: 0.778200, valid loss: 121.694370
epoch: 1627, train precision: 0.888111, train loss: 45.488318, valid precision: 0.752800, valid loss: 132.851991
epoch: 1628, train precision: 0.923422, train loss: 32.639252, valid precision: 0.770400, valid loss: 124.228516
epoch: 1629, train precision: 0.901844, train loss: 39.107700, valid precision: 0.752400, valid loss: 130.169342
epoch: 1630, train precision: 0.912933, train loss: 35.953932, valid precision: 0.767800, valid loss: 131.877239
epoch: 1631, train precision: 0.890311, train loss: 43.846118, valid precision: 0.771800, valid loss: 113.438288
epoch: 1632, train precision: 0.925844, train loss: 30.992988, valid precision: 0.778400, valid loss: 112.588537
epoch: 1633, train precision: 0.785356, train loss: 86.903422, valid precision: 0.721600, valid loss: 127.390986
epoch: 1634, train precision: 0.891356, train loss: 43.350338, valid precision: 0.773800, valid loss: 111.864555
epoch: 1635, train precision: 0.918422, train loss: 33.115478, valid precision: 0.780600, valid loss: 112.380123
epoch: 1636, train precision: 0.879733, train loss: 49.808901, valid precision: 0.752200, valid loss: 130.154479
epoch: 1637, train precision: 0.906422, train loss: 38.577498, valid precision: 0.767400, valid loss: 118.371574
epoch: 1638, train precision: 0.920422, train loss: 32.406736, valid precision: 0.777400, valid loss: 117.355057
epoch: 1639, train precision: 0.882822, train loss: 46.814988, valid precision: 0.768800, valid loss: 111.145638
epoch: 1640, train precision: 0.916622, train loss: 34.293258, valid precision: 0.772800, valid loss: 118.139658
epoch: 1641, train precision: 0.885244, train loss: 46.553944, valid precision: 0.759400, valid loss: 119.386001
epoch: 1642, train precision: 0.866911, train loss: 55.111750, valid precision: 0.745000, valid loss: 130.460120
epoch: 1643, train precision: 0.921489, train loss: 32.236860, valid precision: 0.777800, valid loss: 113.572326
epoch: 1644, train precision: 0.715067, train loss: 189.783219, valid precision: 0.663600, valid loss: 275.958939
epoch: 1645, train precision: 0.893511, train loss: 42.672657, valid precision: 0.761600, valid loss: 123.332551
epoch: 1646, train precision: 0.623444, train loss: 154.930739, valid precision: 0.612800, valid loss: 170.648396
epoch: 1647, train precision: 0.916800, train loss: 34.979759, valid precision: 0.780200, valid loss: 108.734845
epoch: 1648, train precision: 0.915956, train loss: 33.869592, valid precision: 0.775600, valid loss: 118.273962
epoch: 1649, train precision: 0.912689, train loss: 35.966497, valid precision: 0.773800, valid loss: 123.856861
epoch: 1650, train precision: 0.918600, train loss: 33.342611, valid precision: 0.770200, valid loss: 149.266410
epoch: 1651, train precision: 0.917978, train loss: 33.072466, valid precision: 0.772200, valid loss: 147.892891
epoch: 1652, train precision: 0.878867, train loss: 49.443246, valid precision: 0.753800, valid loss: 126.444401
epoch: 1653, train precision: 0.853978, train loss: 60.308113, valid precision: 0.737600, valid loss: 136.513246
epoch: 1654, train precision: 0.917911, train loss: 33.958539, valid precision: 0.769600, valid loss: 120.940352
epoch: 1655, train precision: 0.881400, train loss: 48.530937, valid precision: 0.749400, valid loss: 127.867229
epoch: 1656, train precision: 0.468356, train loss: 222.451050, valid precision: 0.459200, valid loss: 224.768618
epoch: 1657, train precision: 0.813289, train loss: 65.712223, valid precision: 0.709600, valid loss: 124.305282
epoch: 1658, train precision: 0.914533, train loss: 35.359966, valid precision: 0.773000, valid loss: 110.958960
epoch: 1659, train precision: 0.917733, train loss: 33.926169, valid precision: 0.769800, valid loss: 124.828809
epoch: 1660, train precision: 0.917578, train loss: 33.458425, valid precision: 0.776600, valid loss: 118.611029
epoch: 1661, train precision: 0.923022, train loss: 32.666762, valid precision: 0.776000, valid loss: 121.063289
epoch: 1662, train precision: 0.913467, train loss: 35.585717, valid precision: 0.773000, valid loss: 124.542352
epoch: 1663, train precision: 0.564800, train loss: 191.340603, valid precision: 0.567000, valid loss: 197.679056
epoch: 1664, train precision: 0.291422, train loss: 239.436732, valid precision: 0.299400, valid loss: 235.196342
epoch: 1665, train precision: 0.634133, train loss: 137.562291, valid precision: 0.603400, valid loss: 149.879316
epoch: 1666, train precision: 0.756311, train loss: 93.636809, valid precision: 0.686600, valid loss: 124.453680
epoch: 1667, train precision: 0.799622, train loss: 76.732212, valid precision: 0.727400, valid loss: 116.572186
epoch: 1668, train precision: 0.824067, train loss: 68.772487, valid precision: 0.743600, valid loss: 115.808071
epoch: 1669, train precision: 0.876000, train loss: 50.850474, valid precision: 0.767400, valid loss: 122.796969
epoch: 1670, train precision: 0.887267, train loss: 45.815841, valid precision: 0.770000, valid loss: 133.229997
epoch: 1671, train precision: 0.890244, train loss: 44.701646, valid precision: 0.756000, valid loss: 121.968302
epoch: 1672, train precision: 0.905844, train loss: 38.444157, valid precision: 0.772000, valid loss: 130.451574
epoch: 1673, train precision: 0.901178, train loss: 39.711773, valid precision: 0.766000, valid loss: 115.091435
epoch: 1674, train precision: 0.890067, train loss: 44.777251, valid precision: 0.766400, valid loss: 118.957133
epoch: 1675, train precision: 0.905756, train loss: 38.555047, valid precision: 0.767800, valid loss: 119.672281
epoch: 1676, train precision: 0.909867, train loss: 37.004106, valid precision: 0.764400, valid loss: 122.165749
epoch: 1677, train precision: 0.894022, train loss: 44.407913, valid precision: 0.755000, valid loss: 135.999678
epoch: 1678, train precision: 0.898467, train loss: 41.365833, valid precision: 0.758000, valid loss: 129.344710
epoch: 1679, train precision: 0.904756, train loss: 39.382939, valid precision: 0.770600, valid loss: 124.603620
epoch: 1680, train precision: 0.892867, train loss: 44.444408, valid precision: 0.761800, valid loss: 127.029547
epoch: 1681, train precision: 0.893067, train loss: 43.986442, valid precision: 0.767400, valid loss: 121.144627
epoch: 1682, train precision: 0.896444, train loss: 42.960771, valid precision: 0.770200, valid loss: 124.601199
epoch: 1683, train precision: 0.899244, train loss: 41.664307, valid precision: 0.773800, valid loss: 120.162350
epoch: 1684, train precision: 0.536956, train loss: 235.112704, valid precision: 0.523400, valid loss: 244.388621
epoch: 1685, train precision: 0.914067, train loss: 36.293624, valid precision: 0.781400, valid loss: 116.335821
epoch: 1686, train precision: 0.891600, train loss: 45.608777, valid precision: 0.769600, valid loss: 127.306215
epoch: 1687, train precision: 0.879244, train loss: 49.634719, valid precision: 0.757000, valid loss: 126.268577
epoch: 1688, train precision: 0.903733, train loss: 39.802848, valid precision: 0.774400, valid loss: 119.264662
epoch: 1689, train precision: 0.909311, train loss: 36.386642, valid precision: 0.775000, valid loss: 120.337594
epoch: 1690, train precision: 0.929200, train loss: 29.505997, valid precision: 0.780200, valid loss: 118.550956
epoch: 1691, train precision: 0.927978, train loss: 30.155949, valid precision: 0.781200, valid loss: 122.915562
epoch: 1692, train precision: 0.889511, train loss: 45.693223, valid precision: 0.764000, valid loss: 123.161097
epoch: 1693, train precision: 0.900600, train loss: 41.986250, valid precision: 0.769000, valid loss: 127.730954
epoch: 1694, train precision: 0.849378, train loss: 62.756892, valid precision: 0.741000, valid loss: 213.978390
epoch: 1695, train precision: 0.891244, train loss: 45.323547, valid precision: 0.763600, valid loss: 120.374960
epoch: 1696, train precision: 0.915133, train loss: 39.721717, valid precision: 0.773600, valid loss: 149.536128
epoch: 1697, train precision: 0.829267, train loss: 68.687992, valid precision: 0.743600, valid loss: 115.613568
epoch: 1698, train precision: 0.915422, train loss: 34.710070, valid precision: 0.770800, valid loss: 117.433080
epoch: 1699, train precision: 0.923578, train loss: 31.012919, valid precision: 0.771800, valid loss: 121.887093
epoch: 1700, train precision: 0.885044, train loss: 48.915083, valid precision: 0.751600, valid loss: 148.275630
epoch: 1701, train precision: 0.925533, train loss: 33.108562, valid precision: 0.778600, valid loss: 132.434068
epoch: 1702, train precision: 0.913756, train loss: 36.798494, valid precision: 0.777800, valid loss: 146.391231
epoch: 1703, train precision: 0.926956, train loss: 30.608388, valid precision: 0.774400, valid loss: 191.574154
epoch: 1704, train precision: 0.918956, train loss: 34.031960, valid precision: 0.769000, valid loss: 232.102082
epoch: 1705, train precision: 0.886089, train loss: 48.494502, valid precision: 0.753800, valid loss: 195.185993
epoch: 1706, train precision: 0.894978, train loss: 43.406749, valid precision: 0.761600, valid loss: 132.866687
epoch: 1707, train precision: 0.892756, train loss: 44.734029, valid precision: 0.763400, valid loss: 169.931010
epoch: 1708, train precision: 0.821822, train loss: 75.446972, valid precision: 0.730600, valid loss: 135.361345
epoch: 1709, train precision: 0.894333, train loss: 43.584393, valid precision: 0.769800, valid loss: 126.794593
epoch: 1710, train precision: 0.915956, train loss: 34.538068, valid precision: 0.771400, valid loss: 153.922396
epoch: 1711, train precision: 0.904422, train loss: 39.216951, valid precision: 0.772000, valid loss: 121.147190
epoch: 1712, train precision: 0.926467, train loss: 30.810418, valid precision: 0.781000, valid loss: 138.664166
epoch: 1713, train precision: 0.885200, train loss: 46.935340, valid precision: 0.750000, valid loss: 121.570743
epoch: 1714, train precision: 0.912978, train loss: 36.105910, valid precision: 0.764600, valid loss: 133.111487
epoch: 1715, train precision: 0.933689, train loss: 28.428072, valid precision: 0.776800, valid loss: 154.594416
epoch: 1716, train precision: 0.931267, train loss: 28.736994, valid precision: 0.779200, valid loss: 179.909043
epoch: 1717, train precision: 0.890622, train loss: 44.798136, valid precision: 0.763200, valid loss: 124.444855
epoch: 1718, train precision: 0.902422, train loss: 40.454455, valid precision: 0.767400, valid loss: 123.660241
epoch: 1719, train precision: 0.922356, train loss: 31.796802, valid precision: 0.778600, valid loss: 125.080815
epoch: 1720, train precision: 0.865356, train loss: 55.461889, valid precision: 0.757200, valid loss: 125.438753
epoch: 1721, train precision: 0.729578, train loss: 113.947563, valid precision: 0.683000, valid loss: 154.922049
epoch: 1722, train precision: 0.645822, train loss: 158.913413, valid precision: 0.624400, valid loss: 184.277352
epoch: 1723, train precision: 0.930022, train loss: 28.772313, valid precision: 0.781000, valid loss: 127.873848
epoch: 1724, train precision: 0.902622, train loss: 41.202992, valid precision: 0.773200, valid loss: 134.219531
epoch: 1725, train precision: 0.925867, train loss: 30.734381, valid precision: 0.773200, valid loss: 135.382442
epoch: 1726, train precision: 0.899822, train loss: 41.205308, valid precision: 0.758000, valid loss: 146.724816
epoch: 1727, train precision: 0.921889, train loss: 32.432823, valid precision: 0.772200, valid loss: 120.186397
epoch: 1728, train precision: 0.918556, train loss: 35.287811, valid precision: 0.775800, valid loss: 157.396127
epoch: 1729, train precision: 0.916978, train loss: 33.763775, valid precision: 0.770600, valid loss: 123.294412
epoch: 1730, train precision: 0.904022, train loss: 39.197930, valid precision: 0.761600, valid loss: 150.052194
epoch: 1731, train precision: 0.910156, train loss: 38.092985, valid precision: 0.767400, valid loss: 219.353950
epoch: 1732, train precision: 0.896644, train loss: 40.744511, valid precision: 0.762400, valid loss: 168.029832
epoch: 1733, train precision: 0.918667, train loss: 37.015191, valid precision: 0.774200, valid loss: 195.965788
epoch: 1734, train precision: 0.889933, train loss: 44.648805, valid precision: 0.773000, valid loss: 164.625828
epoch: 1735, train precision: 0.889267, train loss: 47.694445, valid precision: 0.754800, valid loss: 189.598715
epoch: 1736, train precision: 0.912733, train loss: 36.365967, valid precision: 0.768800, valid loss: 169.077181
epoch: 1737, train precision: 0.921622, train loss: 33.281691, valid precision: 0.774600, valid loss: 141.391514
epoch: 1738, train precision: 0.924089, train loss: 30.939426, valid precision: 0.771000, valid loss: 144.184734
epoch: 1739, train precision: 0.900044, train loss: 42.186963, valid precision: 0.766200, valid loss: 130.151696
epoch: 1740, train precision: 0.864156, train loss: 55.809317, valid precision: 0.748200, valid loss: 129.628404
epoch: 1741, train precision: 0.910178, train loss: 36.581358, valid precision: 0.767200, valid loss: 177.690626
epoch: 1742, train precision: 0.660756, train loss: 127.260779, valid precision: 0.645600, valid loss: 139.940308
epoch: 1743, train precision: 0.886378, train loss: 47.533262, valid precision: 0.768400, valid loss: 122.305706
epoch: 1744, train precision: 0.902422, train loss: 39.544974, valid precision: 0.774200, valid loss: 117.219516
epoch: 1745, train precision: 0.891889, train loss: 43.090568, valid precision: 0.764200, valid loss: 121.099874
epoch: 1746, train precision: 0.231956, train loss: 292.460419, valid precision: 0.244800, valid loss: 287.148491
epoch: 1747, train precision: 0.621178, train loss: 143.721176, valid precision: 0.610600, valid loss: 151.596964
epoch: 1748, train precision: 0.891600, train loss: 46.982289, valid precision: 0.770000, valid loss: 122.457628
epoch: 1749, train precision: 0.910756, train loss: 36.496843, valid precision: 0.775000, valid loss: 125.645619
epoch: 1750, train precision: 0.907400, train loss: 38.591677, valid precision: 0.768400, valid loss: 122.638864
epoch: 1751, train precision: 0.920489, train loss: 33.031841, valid precision: 0.775800, valid loss: 142.565330
epoch: 1752, train precision: 0.929644, train loss: 29.328951, valid precision: 0.778000, valid loss: 163.964759
epoch: 1753, train precision: 0.924778, train loss: 31.317075, valid precision: 0.777800, valid loss: 149.020218
epoch: 1754, train precision: 0.877000, train loss: 51.278094, valid precision: 0.752200, valid loss: 124.998991
epoch: 1755, train precision: 0.798756, train loss: 84.808525, valid precision: 0.711000, valid loss: 135.734449
epoch: 1756, train precision: 0.902444, train loss: 41.521280, valid precision: 0.760200, valid loss: 173.032669
epoch: 1757, train precision: 0.641022, train loss: 152.334225, valid precision: 0.615200, valid loss: 175.914262
epoch: 1758, train precision: 0.713911, train loss: 134.838567, valid precision: 0.652800, valid loss: 180.581376
epoch: 1759, train precision: 0.832667, train loss: 67.997065, valid precision: 0.735400, valid loss: 125.936309
epoch: 1760, train precision: 0.917044, train loss: 34.134839, valid precision: 0.771400, valid loss: 122.976254
epoch: 1761, train precision: 0.927422, train loss: 31.124687, valid precision: 0.773600, valid loss: 140.740010
epoch: 1762, train precision: 0.895178, train loss: 43.196640, valid precision: 0.763600, valid loss: 129.169964
epoch: 1763, train precision: 0.322911, train loss: 286.422504, valid precision: 0.331800, valid loss: 281.562164
epoch: 1764, train precision: 0.915956, train loss: 36.285650, valid precision: 0.777200, valid loss: 119.053212
epoch: 1765, train precision: 0.913133, train loss: 35.515464, valid precision: 0.778600, valid loss: 127.416360
epoch: 1766, train precision: 0.870000, train loss: 51.902492, valid precision: 0.757200, valid loss: 122.677113
epoch: 1767, train precision: 0.909978, train loss: 37.661857, valid precision: 0.771000, valid loss: 127.852983
epoch: 1768, train precision: 0.742422, train loss: 107.446936, valid precision: 0.689600, valid loss: 146.546746
epoch: 1769, train precision: 0.926244, train loss: 31.345599, valid precision: 0.781800, valid loss: 121.199816
epoch: 1770, train precision: 0.882222, train loss: 49.190383, valid precision: 0.753000, valid loss: 131.570032
epoch: 1771, train precision: 0.829111, train loss: 69.425010, valid precision: 0.732800, valid loss: 132.574890
epoch: 1772, train precision: 0.918667, train loss: 33.959514, valid precision: 0.774200, valid loss: 131.272135
epoch: 1773, train precision: 0.916400, train loss: 32.761938, valid precision: 0.769800, valid loss: 124.346464
epoch: 1774, train precision: 0.902556, train loss: 39.746934, valid precision: 0.763800, valid loss: 132.277131
epoch: 1775, train precision: 0.906044, train loss: 38.013470, valid precision: 0.765400, valid loss: 130.096873
epoch: 1776, train precision: 0.876822, train loss: 48.862735, valid precision: 0.750600, valid loss: 125.274578
epoch: 1777, train precision: 0.924400, train loss: 31.143822, valid precision: 0.770600, valid loss: 127.691762
epoch: 1778, train precision: 0.923311, train loss: 31.425132, valid precision: 0.770800, valid loss: 131.443888
epoch: 1779, train precision: 0.910289, train loss: 38.749601, valid precision: 0.769000, valid loss: 134.530121
epoch: 1780, train precision: 0.912889, train loss: 36.739819, valid precision: 0.771000, valid loss: 130.820373
epoch: 1781, train precision: 0.918200, train loss: 34.038081, valid precision: 0.767200, valid loss: 141.093918
epoch: 1782, train precision: 0.907467, train loss: 38.586182, valid precision: 0.757800, valid loss: 137.820990
epoch: 1783, train precision: 0.909333, train loss: 37.044649, valid precision: 0.767200, valid loss: 129.870157
epoch: 1784, train precision: 0.764156, train loss: 93.250358, valid precision: 0.681800, valid loss: 141.592854
epoch: 1785, train precision: 0.906422, train loss: 39.674860, valid precision: 0.761400, valid loss: 144.093211
epoch: 1786, train precision: 0.175533, train loss: 287.071097, valid precision: 0.174800, valid loss: 283.488802
epoch: 1787, train precision: 0.361044, train loss: 216.821002, valid precision: 0.376000, valid loss: 216.701260
epoch: 1788, train precision: 0.542844, train loss: 168.388503, valid precision: 0.535800, valid loss: 173.494188
epoch: 1789, train precision: 0.860267, train loss: 54.782057, valid precision: 0.733400, valid loss: 120.136518
epoch: 1790, train precision: 0.884667, train loss: 46.342962, valid precision: 0.750400, valid loss: 122.757806
epoch: 1791, train precision: 0.819156, train loss: 75.106295, valid precision: 0.724200, valid loss: 139.896985
epoch: 1792, train precision: 0.694533, train loss: 115.816900, valid precision: 0.631000, valid loss: 154.056021
epoch: 1793, train precision: 0.908267, train loss: 38.057670, valid precision: 0.761200, valid loss: 121.033124
epoch: 1794, train precision: 0.898111, train loss: 42.166500, valid precision: 0.748600, valid loss: 126.822262
epoch: 1795, train precision: 0.491889, train loss: 211.905517, valid precision: 0.489200, valid loss: 224.547011
epoch: 1796, train precision: 0.903333, train loss: 39.099375, valid precision: 0.763000, valid loss: 121.075692
epoch: 1797, train precision: 0.909556, train loss: 36.777440, valid precision: 0.770200, valid loss: 125.263656
epoch: 1798, train precision: 0.841711, train loss: 65.847215, valid precision: 0.742200, valid loss: 135.349413
epoch: 1799, train precision: 0.895378, train loss: 48.123892, valid precision: 0.762800, valid loss: 143.433546
epoch: 1800, train precision: 0.851378, train loss: 63.633291, valid precision: 0.737400, valid loss: 146.858591
epoch: 1801, train precision: 0.919156, train loss: 34.346445, valid precision: 0.775400, valid loss: 127.945343
epoch: 1802, train precision: 0.916578, train loss: 34.293011, valid precision: 0.771000, valid loss: 165.145923
epoch: 1803, train precision: 0.922333, train loss: 32.540621, valid precision: 0.773400, valid loss: 131.795367
epoch: 1804, train precision: 0.926467, train loss: 31.322521, valid precision: 0.783400, valid loss: 130.425414
epoch: 1805, train precision: 0.893933, train loss: 43.234696, valid precision: 0.749000, valid loss: 140.473043
epoch: 1806, train precision: 0.716022, train loss: 150.311711, valid precision: 0.654000, valid loss: 216.979718
epoch: 1807, train precision: 0.922667, train loss: 32.260943, valid precision: 0.775200, valid loss: 125.052507
epoch: 1808, train precision: 0.902378, train loss: 40.151486, valid precision: 0.763600, valid loss: 122.140173
epoch: 1809, train precision: 0.912089, train loss: 36.025809, valid precision: 0.763600, valid loss: 124.617050
epoch: 1810, train precision: 0.922311, train loss: 32.083103, valid precision: 0.769800, valid loss: 138.245825
epoch: 1811, train precision: 0.935756, train loss: 27.347545, valid precision: 0.781000, valid loss: 121.734680
epoch: 1812, train precision: 0.834756, train loss: 72.410589, valid precision: 0.729000, valid loss: 144.315126
epoch: 1813, train precision: 0.920600, train loss: 34.316110, valid precision: 0.764400, valid loss: 146.935790
epoch: 1814, train precision: 0.910444, train loss: 40.274729, valid precision: 0.758800, valid loss: 172.145631
epoch: 1815, train precision: 0.924778, train loss: 31.813033, valid precision: 0.769400, valid loss: 130.007897
epoch: 1816, train precision: 0.788000, train loss: 88.239722, valid precision: 0.705600, valid loss: 138.881111
epoch: 1817, train precision: 0.870778, train loss: 53.001614, valid precision: 0.751200, valid loss: 129.570573
epoch: 1818, train precision: 0.899822, train loss: 40.870694, valid precision: 0.766000, valid loss: 125.598903
epoch: 1819, train precision: 0.926756, train loss: 30.207177, valid precision: 0.776400, valid loss: 170.223691
epoch: 1820, train precision: 0.918822, train loss: 33.196325, valid precision: 0.769000, valid loss: 136.747364
epoch: 1821, train precision: 0.788711, train loss: 93.346084, valid precision: 0.701400, valid loss: 156.263913
epoch: 1822, train precision: 0.769978, train loss: 106.137889, valid precision: 0.705400, valid loss: 161.650904
epoch: 1823, train precision: 0.912756, train loss: 35.802884, valid precision: 0.763000, valid loss: 126.055541
epoch: 1824, train precision: 0.909867, train loss: 37.188862, valid precision: 0.771000, valid loss: 133.079994
epoch: 1825, train precision: 0.902644, train loss: 39.812227, valid precision: 0.771000, valid loss: 123.470216
epoch: 1826, train precision: 0.900000, train loss: 42.107292, valid precision: 0.755400, valid loss: 144.184282
epoch: 1827, train precision: 0.939022, train loss: 25.479370, valid precision: 0.788200, valid loss: 121.139021
epoch: 1828, train precision: 0.918222, train loss: 34.741125, valid precision: 0.772600, valid loss: 137.100731
epoch: 1829, train precision: 0.925422, train loss: 30.632992, valid precision: 0.771600, valid loss: 135.304676
epoch: 1830, train precision: 0.675244, train loss: 130.122272, valid precision: 0.658800, valid loss: 144.091146
epoch: 1831, train precision: 0.919689, train loss: 33.217919, valid precision: 0.772600, valid loss: 123.919410
epoch: 1832, train precision: 0.897978, train loss: 40.159324, valid precision: 0.767000, valid loss: 124.337113
epoch: 1833, train precision: 0.937289, train loss: 26.955278, valid precision: 0.781000, valid loss: 124.643497
epoch: 1834, train precision: 0.876089, train loss: 50.746979, valid precision: 0.754400, valid loss: 126.595790
epoch: 1835, train precision: 0.929467, train loss: 30.150359, valid precision: 0.770400, valid loss: 131.523795
epoch: 1836, train precision: 0.918089, train loss: 34.565080, valid precision: 0.767800, valid loss: 144.153249
epoch: 1837, train precision: 0.913467, train loss: 36.974706, valid precision: 0.765000, valid loss: 131.397840
epoch: 1838, train precision: 0.931156, train loss: 30.568685, valid precision: 0.774800, valid loss: 140.012233
epoch: 1839, train precision: 0.389444, train loss: 333.448482, valid precision: 0.386600, valid loss: 336.182945
epoch: 1840, train precision: 0.921022, train loss: 33.848303, valid precision: 0.780400, valid loss: 188.768266
epoch: 1841, train precision: 0.918867, train loss: 34.329507, valid precision: 0.778800, valid loss: 130.339419
epoch: 1842, train precision: 0.902556, train loss: 40.527020, valid precision: 0.772000, valid loss: 125.963256
epoch: 1843, train precision: 0.922644, train loss: 33.732023, valid precision: 0.782800, valid loss: 129.394882
epoch: 1844, train precision: 0.917089, train loss: 34.271899, valid precision: 0.773600, valid loss: 133.590793
epoch: 1845, train precision: 0.907489, train loss: 39.480097, valid precision: 0.772600, valid loss: 123.784641
epoch: 1846, train precision: 0.931311, train loss: 30.537641, valid precision: 0.778600, valid loss: 126.995448
epoch: 1847, train precision: 0.928578, train loss: 29.981379, valid precision: 0.781600, valid loss: 127.250479
epoch: 1848, train precision: 0.930644, train loss: 29.260268, valid precision: 0.776200, valid loss: 144.967699
epoch: 1849, train precision: 0.921022, train loss: 33.193325, valid precision: 0.776000, valid loss: 148.923278
epoch: 1850, train precision: 0.893400, train loss: 45.181684, valid precision: 0.756800, valid loss: 154.843205
epoch: 1851, train precision: 0.890844, train loss: 45.429945, valid precision: 0.755800, valid loss: 126.336894
epoch: 1852, train precision: 0.931244, train loss: 28.673103, valid precision: 0.782800, valid loss: 130.128179
epoch: 1853, train precision: 0.930889, train loss: 29.163691, valid precision: 0.769000, valid loss: 138.100001
epoch: 1854, train precision: 0.931444, train loss: 28.564813, valid precision: 0.772000, valid loss: 151.892352
epoch: 1855, train precision: 0.928667, train loss: 30.133157, valid precision: 0.776000, valid loss: 150.204380
epoch: 1856, train precision: 0.922400, train loss: 33.303718, valid precision: 0.772000, valid loss: 154.339218
epoch: 1857, train precision: 0.912444, train loss: 36.380887, valid precision: 0.772800, valid loss: 129.621298
epoch: 1858, train precision: 0.895511, train loss: 43.646004, valid precision: 0.762400, valid loss: 132.755962
epoch: 1859, train precision: 0.927644, train loss: 29.766664, valid precision: 0.778800, valid loss: 127.361953
epoch: 1860, train precision: 0.928089, train loss: 29.365510, valid precision: 0.773600, valid loss: 124.277118
epoch: 1861, train precision: 0.927822, train loss: 30.129612, valid precision: 0.766600, valid loss: 135.513182
epoch: 1862, train precision: 0.930400, train loss: 29.723203, valid precision: 0.777600, valid loss: 133.198450
epoch: 1863, train precision: 0.893756, train loss: 43.725449, valid precision: 0.753800, valid loss: 133.699554
epoch: 1864, train precision: 0.916378, train loss: 35.566826, valid precision: 0.774600, valid loss: 134.083868
epoch: 1865, train precision: 0.927756, train loss: 30.797176, valid precision: 0.778800, valid loss: 131.777280
epoch: 1866, train precision: 0.934089, train loss: 29.612814, valid precision: 0.776000, valid loss: 128.281772
epoch: 1867, train precision: 0.878267, train loss: 50.746501, valid precision: 0.759600, valid loss: 133.436318
epoch: 1868, train precision: 0.932111, train loss: 28.454950, valid precision: 0.779400, valid loss: 127.130547
epoch: 1869, train precision: 0.929311, train loss: 31.111789, valid precision: 0.776000, valid loss: 139.838434
epoch: 1870, train precision: 0.909800, train loss: 38.225827, valid precision: 0.771200, valid loss: 132.462532
epoch: 1871, train precision: 0.930289, train loss: 30.306861, valid precision: 0.779200, valid loss: 135.949873
epoch: 1872, train precision: 0.858933, train loss: 60.216975, valid precision: 0.760200, valid loss: 134.185806
epoch: 1873, train precision: 0.928400, train loss: 30.422621, valid precision: 0.778200, valid loss: 127.192979
epoch: 1874, train precision: 0.930222, train loss: 28.770505, valid precision: 0.777400, valid loss: 131.209816
epoch: 1875, train precision: 0.918044, train loss: 35.657668, valid precision: 0.762800, valid loss: 132.156656
epoch: 1876, train precision: 0.863556, train loss: 60.000894, valid precision: 0.745600, valid loss: 146.672851
epoch: 1877, train precision: 0.931489, train loss: 32.290018, valid precision: 0.774000, valid loss: 138.715876
epoch: 1878, train precision: 0.899844, train loss: 44.351775, valid precision: 0.762400, valid loss: 144.799886
epoch: 1879, train precision: 0.860956, train loss: 58.853531, valid precision: 0.749800, valid loss: 126.496647
epoch: 1880, train precision: 0.880267, train loss: 50.540033, valid precision: 0.751000, valid loss: 133.877722
epoch: 1881, train precision: 0.809133, train loss: 80.087502, valid precision: 0.732000, valid loss: 129.658330
epoch: 1882, train precision: 0.919622, train loss: 34.202830, valid precision: 0.774200, valid loss: 152.560804
epoch: 1883, train precision: 0.917956, train loss: 34.464299, valid precision: 0.771000, valid loss: 131.574595
epoch: 1884, train precision: 0.907311, train loss: 40.849082, valid precision: 0.769400, valid loss: 139.021466
epoch: 1885, train precision: 0.919000, train loss: 34.726538, valid precision: 0.772000, valid loss: 140.239936
epoch: 1886, train precision: 0.932622, train loss: 28.346210, valid precision: 0.784200, valid loss: 125.515427
epoch: 1887, train precision: 0.867778, train loss: 55.094913, valid precision: 0.753200, valid loss: 130.626854
epoch: 1888, train precision: 0.932578, train loss: 28.953161, valid precision: 0.785600, valid loss: 131.423676
epoch: 1889, train precision: 0.684333, train loss: 139.193335, valid precision: 0.642000, valid loss: 175.914017
epoch: 1890, train precision: 0.934600, train loss: 27.232546, valid precision: 0.784200, valid loss: 173.341738
epoch: 1891, train precision: 0.902467, train loss: 41.126782, valid precision: 0.770000, valid loss: 130.777505
epoch: 1892, train precision: 0.204267, train loss: 314.331138, valid precision: 0.216600, valid loss: 308.588786
epoch: 1893, train precision: 0.789111, train loss: 85.037441, valid precision: 0.700800, valid loss: 138.967089
epoch: 1894, train precision: 0.862289, train loss: 55.268591, valid precision: 0.747200, valid loss: 123.014183
epoch: 1895, train precision: 0.903933, train loss: 39.719851, valid precision: 0.768200, valid loss: 121.586705
epoch: 1896, train precision: 0.893311, train loss: 43.972573, valid precision: 0.751000, valid loss: 200.360091
epoch: 1897, train precision: 0.921511, train loss: 34.635649, valid precision: 0.777000, valid loss: 194.606313
epoch: 1898, train precision: 0.920978, train loss: 34.076253, valid precision: 0.772200, valid loss: 334.909557
epoch: 1899, train precision: 0.923711, train loss: 32.130117, valid precision: 0.767600, valid loss: 136.452585
epoch: 1900, train precision: 0.914733, train loss: 37.217642, valid precision: 0.770600, valid loss: 133.269079
epoch: 1901, train precision: 0.916467, train loss: 34.687609, valid precision: 0.776600, valid loss: 126.451484
epoch: 1902, train precision: 0.927378, train loss: 31.057992, valid precision: 0.770000, valid loss: 197.192363
epoch: 1903, train precision: 0.930600, train loss: 30.536838, valid precision: 0.769800, valid loss: 232.262846
epoch: 1904, train precision: 0.909733, train loss: 38.551526, valid precision: 0.782600, valid loss: 130.378376
epoch: 1905, train precision: 0.936556, train loss: 26.772045, valid precision: 0.784400, valid loss: 120.009101
epoch: 1906, train precision: 0.928311, train loss: 31.237339, valid precision: 0.777800, valid loss: 127.988324
epoch: 1907, train precision: 0.936044, train loss: 26.872505, valid precision: 0.779600, valid loss: 133.197213
epoch: 1908, train precision: 0.919222, train loss: 34.455008, valid precision: 0.787200, valid loss: 130.039041
epoch: 1909, train precision: 0.938111, train loss: 26.555830, valid precision: 0.788800, valid loss: 132.956522
epoch: 1910, train precision: 0.907444, train loss: 39.619169, valid precision: 0.769400, valid loss: 135.846843
epoch: 1911, train precision: 0.935400, train loss: 27.752291, valid precision: 0.787600, valid loss: 147.181460
epoch: 1912, train precision: 0.896311, train loss: 42.467869, valid precision: 0.758800, valid loss: 126.242260
epoch: 1913, train precision: 0.517800, train loss: 204.048230, valid precision: 0.512600, valid loss: 210.120622
epoch: 1914, train precision: 0.915044, train loss: 35.682383, valid precision: 0.774800, valid loss: 166.643588
epoch: 1915, train precision: 0.932600, train loss: 28.908493, valid precision: 0.779000, valid loss: 146.881231
epoch: 1916, train precision: 0.933511, train loss: 28.481694, valid precision: 0.774400, valid loss: 155.594053
epoch: 1917, train precision: 0.855622, train loss: 63.421683, valid precision: 0.730400, valid loss: 146.111156
epoch: 1918, train precision: 0.807222, train loss: 85.026302, valid precision: 0.719400, valid loss: 144.450652
epoch: 1919, train precision: 0.929244, train loss: 29.562566, valid precision: 0.779400, valid loss: 131.305257
epoch: 1920, train precision: 0.922867, train loss: 34.701070, valid precision: 0.773800, valid loss: 151.148538
epoch: 1921, train precision: 0.882089, train loss: 50.472658, valid precision: 0.747600, valid loss: 143.830390
epoch: 1922, train precision: 0.911644, train loss: 37.038115, valid precision: 0.769400, valid loss: 134.928573
epoch: 1923, train precision: 0.917778, train loss: 35.710242, valid precision: 0.764800, valid loss: 141.068433
epoch: 1924, train precision: 0.930733, train loss: 30.057506, valid precision: 0.779800, valid loss: 150.732878
epoch: 1925, train precision: 0.768644, train loss: 100.748864, valid precision: 0.712800, valid loss: 140.407944
epoch: 1926, train precision: 0.897222, train loss: 44.339280, valid precision: 0.767000, valid loss: 135.439183
epoch: 1927, train precision: 0.932778, train loss: 28.536191, valid precision: 0.778600, valid loss: 136.883264
epoch: 1928, train precision: 0.916644, train loss: 35.748154, valid precision: 0.771200, valid loss: 142.428602
epoch: 1929, train precision: 0.723467, train loss: 115.067647, valid precision: 0.659800, valid loss: 162.413924
epoch: 1930, train precision: 0.918311, train loss: 34.838961, valid precision: 0.769600, valid loss: 129.261184
epoch: 1931, train precision: 0.816711, train loss: 76.035570, valid precision: 0.727000, valid loss: 138.585693
epoch: 1932, train precision: 0.915711, train loss: 37.535531, valid precision: 0.768000, valid loss: 133.158680
epoch: 1933, train precision: 0.921289, train loss: 32.105893, valid precision: 0.781400, valid loss: 125.936080
epoch: 1934, train precision: 0.917933, train loss: 35.376227, valid precision: 0.770600, valid loss: 130.365310
epoch: 1935, train precision: 0.897422, train loss: 43.096179, valid precision: 0.767000, valid loss: 128.342405
epoch: 1936, train precision: 0.821867, train loss: 78.084933, valid precision: 0.727200, valid loss: 143.943656
epoch: 1937, train precision: 0.928933, train loss: 29.618485, valid precision: 0.782800, valid loss: 130.009969
epoch: 1938, train precision: 0.934067, train loss: 27.327633, valid precision: 0.776800, valid loss: 129.194096
epoch: 1939, train precision: 0.926200, train loss: 30.328095, valid precision: 0.780800, valid loss: 124.935738
epoch: 1940, train precision: 0.928867, train loss: 31.133123, valid precision: 0.772200, valid loss: 144.723560
epoch: 1941, train precision: 0.920244, train loss: 34.559730, valid precision: 0.779400, valid loss: 135.113457
epoch: 1942, train precision: 0.924600, train loss: 31.785512, valid precision: 0.777600, valid loss: 139.137657
epoch: 1943, train precision: 0.929178, train loss: 30.683657, valid precision: 0.776400, valid loss: 146.053228
epoch: 1944, train precision: 0.934956, train loss: 27.234543, valid precision: 0.785200, valid loss: 124.840756
epoch: 1945, train precision: 0.822489, train loss: 77.892972, valid precision: 0.720600, valid loss: 149.300615
epoch: 1946, train precision: 0.921289, train loss: 33.895435, valid precision: 0.765600, valid loss: 137.935800
epoch: 1947, train precision: 0.930911, train loss: 30.772073, valid precision: 0.780800, valid loss: 139.099138
epoch: 1948, train precision: 0.871978, train loss: 54.296809, valid precision: 0.752600, valid loss: 148.772662
epoch: 1949, train precision: 0.884978, train loss: 47.515900, valid precision: 0.770600, valid loss: 122.586103
epoch: 1950, train precision: 0.911444, train loss: 37.271975, valid precision: 0.768400, valid loss: 137.214892
epoch: 1951, train precision: 0.921644, train loss: 34.071831, valid precision: 0.766400, valid loss: 146.812902
epoch: 1952, train precision: 0.932067, train loss: 28.670389, valid precision: 0.781600, valid loss: 156.629651
epoch: 1953, train precision: 0.933778, train loss: 28.525759, valid precision: 0.777600, valid loss: 153.416664
epoch: 1954, train precision: 0.812689, train loss: 81.254207, valid precision: 0.719400, valid loss: 180.528058
epoch: 1955, train precision: 0.914022, train loss: 36.725713, valid precision: 0.769800, valid loss: 147.502519
epoch: 1956, train precision: 0.929489, train loss: 29.534708, valid precision: 0.777800, valid loss: 124.479452
epoch: 1957, train precision: 0.925489, train loss: 34.369408, valid precision: 0.766200, valid loss: 159.264219
epoch: 1958, train precision: 0.931556, train loss: 30.777189, valid precision: 0.778200, valid loss: 139.895983
epoch: 1959, train precision: 0.932044, train loss: 30.833589, valid precision: 0.769600, valid loss: 133.070342
epoch: 1960, train precision: 0.906933, train loss: 40.429678, valid precision: 0.771000, valid loss: 130.122182
epoch: 1961, train precision: 0.912689, train loss: 36.726506, valid precision: 0.774000, valid loss: 133.143565
epoch: 1962, train precision: 0.928267, train loss: 31.525963, valid precision: 0.779200, valid loss: 139.095027
epoch: 1963, train precision: 0.926911, train loss: 31.485777, valid precision: 0.780000, valid loss: 127.723796
epoch: 1964, train precision: 0.444578, train loss: 218.874847, valid precision: 0.452200, valid loss: 217.094784
epoch: 1965, train precision: 0.917889, train loss: 35.013361, valid precision: 0.765800, valid loss: 127.830660
epoch: 1966, train precision: 0.934844, train loss: 27.455986, valid precision: 0.777600, valid loss: 129.242947
epoch: 1967, train precision: 0.590822, train loss: 196.898140, valid precision: 0.562400, valid loss: 223.584824
epoch: 1968, train precision: 0.933533, train loss: 28.257153, valid precision: 0.787000, valid loss: 120.372068
epoch: 1969, train precision: 0.928133, train loss: 29.832491, valid precision: 0.777000, valid loss: 135.388272
epoch: 1970, train precision: 0.916822, train loss: 35.558958, valid precision: 0.768000, valid loss: 138.738260
epoch: 1971, train precision: 0.780422, train loss: 88.401588, valid precision: 0.703000, valid loss: 137.813336
epoch: 1972, train precision: 0.940022, train loss: 29.344550, valid precision: 0.784800, valid loss: 138.977513
epoch: 1973, train precision: 0.921000, train loss: 34.490050, valid precision: 0.761400, valid loss: 145.757280
epoch: 1974, train precision: 0.926267, train loss: 32.442435, valid precision: 0.777200, valid loss: 146.659646
epoch: 1975, train precision: 0.918333, train loss: 33.681750, valid precision: 0.768000, valid loss: 134.743463
epoch: 1976, train precision: 0.930644, train loss: 29.383986, valid precision: 0.782000, valid loss: 133.639448
epoch: 1977, train precision: 0.937844, train loss: 27.073181, valid precision: 0.785200, valid loss: 154.684655
epoch: 1978, train precision: 0.921578, train loss: 34.097762, valid precision: 0.777200, valid loss: 129.790603
epoch: 1979, train precision: 0.935133, train loss: 27.031436, valid precision: 0.774600, valid loss: 132.416445
epoch: 1980, train precision: 0.622000, train loss: 197.083484, valid precision: 0.591600, valid loss: 223.607694
epoch: 1981, train precision: 0.929378, train loss: 30.404776, valid precision: 0.777400, valid loss: 127.074061
epoch: 1982, train precision: 0.896489, train loss: 44.925140, valid precision: 0.766400, valid loss: 140.585683
epoch: 1983, train precision: 0.925778, train loss: 30.348598, valid precision: 0.769600, valid loss: 127.553764
epoch: 1984, train precision: 0.925467, train loss: 32.035858, valid precision: 0.767000, valid loss: 145.554530
epoch: 1985, train precision: 0.924711, train loss: 32.735179, valid precision: 0.774400, valid loss: 145.137789
epoch: 1986, train precision: 0.932356, train loss: 28.770242, valid precision: 0.774800, valid loss: 125.715381
epoch: 1987, train precision: 0.927378, train loss: 31.157037, valid precision: 0.773000, valid loss: 139.689639
epoch: 1988, train precision: 0.896756, train loss: 45.333868, valid precision: 0.758600, valid loss: 154.498572
epoch: 1989, train precision: 0.933044, train loss: 28.040258, valid precision: 0.777800, valid loss: 129.544381
epoch: 1990, train precision: 0.945778, train loss: 23.635847, valid precision: 0.790600, valid loss: 132.599689
epoch: 1991, train precision: 0.903378, train loss: 42.737654, valid precision: 0.766200, valid loss: 139.445790
epoch: 1992, train precision: 0.943022, train loss: 25.066497, valid precision: 0.785600, valid loss: 145.098145
epoch: 1993, train precision: 0.917867, train loss: 38.446149, valid precision: 0.775000, valid loss: 145.880514
epoch: 1994, train precision: 0.925289, train loss: 32.191025, valid precision: 0.777400, valid loss: 147.543938
epoch: 1995, train precision: 0.923578, train loss: 33.121153, valid precision: 0.776200, valid loss: 136.925849
epoch: 1996, train precision: 0.940089, train loss: 26.715695, valid precision: 0.780800, valid loss: 141.243087
epoch: 1997, train precision: 0.934289, train loss: 27.941439, valid precision: 0.785000, valid loss: 138.519471
epoch: 1998, train precision: 0.933733, train loss: 29.632224, valid precision: 0.779200, valid loss: 138.838690
epoch: 1999, train precision: 0.924044, train loss: 33.092922, valid precision: 0.772000, valid loss: 148.960436
epoch: 2000, train precision: 0.712667, train loss: 121.982087, valid precision: 0.677400, valid loss: 141.877094
epoch: 2001, train precision: 0.712733, train loss: 128.195366, valid precision: 0.665200, valid loss: 169.328750
epoch: 2002, train precision: 0.936778, train loss: 26.780734, valid precision: 0.781400, valid loss: 129.801588
epoch: 2003, train precision: 0.930911, train loss: 29.651011, valid precision: 0.773600, valid loss: 140.328324
epoch: 2004, train precision: 0.929667, train loss: 29.533235, valid precision: 0.780600, valid loss: 130.638170
epoch: 2005, train precision: 0.890356, train loss: 45.664226, valid precision: 0.755200, valid loss: 137.707280
epoch: 2006, train precision: 0.924089, train loss: 33.030319, valid precision: 0.776200, valid loss: 137.077193
epoch: 2007, train precision: 0.923533, train loss: 32.470308, valid precision: 0.779000, valid loss: 131.768811
epoch: 2008, train precision: 0.850244, train loss: 63.592450, valid precision: 0.752800, valid loss: 133.494839
epoch: 2009, train precision: 0.930089, train loss: 29.701137, valid precision: 0.777600, valid loss: 136.871878
epoch: 2010, train precision: 0.926467, train loss: 32.070744, valid precision: 0.775800, valid loss: 138.771780
epoch: 2011, train precision: 0.942756, train loss: 25.074402, valid precision: 0.782000, valid loss: 133.713300
epoch: 2012, train precision: 0.932289, train loss: 28.967346, valid precision: 0.778200, valid loss: 127.931841
epoch: 2013, train precision: 0.927733, train loss: 32.148538, valid precision: 0.774200, valid loss: 135.403119
epoch: 2014, train precision: 0.766622, train loss: 120.306370, valid precision: 0.691800, valid loss: 189.563881
epoch: 2015, train precision: 0.906911, train loss: 39.442254, valid precision: 0.767400, valid loss: 142.059804
epoch: 2016, train precision: 0.407356, train loss: 216.147391, valid precision: 0.407200, valid loss: 217.902165
epoch: 2017, train precision: 0.858622, train loss: 54.585716, valid precision: 0.735400, valid loss: 137.443288
epoch: 2018, train precision: 0.399089, train loss: 232.536971, valid precision: 0.414400, valid loss: 228.363285
epoch: 2019, train precision: 0.875333, train loss: 50.557021, valid precision: 0.753200, valid loss: 139.144133
epoch: 2020, train precision: 0.888511, train loss: 44.587461, valid precision: 0.750800, valid loss: 139.450323
epoch: 2021, train precision: 0.901578, train loss: 38.773086, valid precision: 0.763200, valid loss: 131.058145
epoch: 2022, train precision: 0.765400, train loss: 92.718529, valid precision: 0.697000, valid loss: 132.059351
epoch: 2023, train precision: 0.902644, train loss: 39.898500, valid precision: 0.773000, valid loss: 122.692934
epoch: 2024, train precision: 0.907956, train loss: 37.193789, valid precision: 0.770200, valid loss: 127.132533
epoch: 2025, train precision: 0.787867, train loss: 87.063352, valid precision: 0.704600, valid loss: 140.196540
epoch: 2026, train precision: 0.861956, train loss: 56.924016, valid precision: 0.741000, valid loss: 131.485487
epoch: 2027, train precision: 0.922089, train loss: 32.567507, valid precision: 0.774200, valid loss: 128.072966
epoch: 2028, train precision: 0.922222, train loss: 31.876028, valid precision: 0.772200, valid loss: 137.126924
epoch: 2029, train precision: 0.340311, train loss: 251.718518, valid precision: 0.353400, valid loss: 249.922434
epoch: 2030, train precision: 0.900600, train loss: 42.570735, valid precision: 0.763800, valid loss: 133.891757
epoch: 2031, train precision: 0.842289, train loss: 66.959426, valid precision: 0.731600, valid loss: 144.773224
epoch: 2032, train precision: 0.918867, train loss: 34.623521, valid precision: 0.777800, valid loss: 129.458334
epoch: 2033, train precision: 0.922400, train loss: 34.191472, valid precision: 0.769000, valid loss: 126.574653
epoch: 2034, train precision: 0.915022, train loss: 36.362813, valid precision: 0.766400, valid loss: 130.451638
epoch: 2035, train precision: 0.914756, train loss: 35.147903, valid precision: 0.763000, valid loss: 141.151679
epoch: 2036, train precision: 0.922844, train loss: 32.926699, valid precision: 0.769400, valid loss: 144.784150
epoch: 2037, train precision: 0.897378, train loss: 41.703781, valid precision: 0.762200, valid loss: 123.313929
epoch: 2038, train precision: 0.919267, train loss: 34.514096, valid precision: 0.773200, valid loss: 137.787947
epoch: 2039, train precision: 0.517267, train loss: 211.981236, valid precision: 0.520600, valid loss: 206.074965
epoch: 2040, train precision: 0.869956, train loss: 56.049936, valid precision: 0.767400, valid loss: 117.686220
epoch: 2041, train precision: 0.907667, train loss: 37.438226, valid precision: 0.772600, valid loss: 118.650384
epoch: 2042, train precision: 0.895711, train loss: 43.037577, valid precision: 0.762200, valid loss: 136.988407
epoch: 2043, train precision: 0.914422, train loss: 36.205386, valid precision: 0.765600, valid loss: 132.243780
epoch: 2044, train precision: 0.922511, train loss: 36.145312, valid precision: 0.777400, valid loss: 126.090699
epoch: 2045, train precision: 0.909311, train loss: 37.845239, valid precision: 0.769200, valid loss: 139.991491
epoch: 2046, train precision: 0.910756, train loss: 36.344031, valid precision: 0.765600, valid loss: 134.744815
epoch: 2047, train precision: 0.893089, train loss: 43.331261, valid precision: 0.759400, valid loss: 119.331712
epoch: 2048, train precision: 0.925444, train loss: 30.529304, valid precision: 0.770600, valid loss: 130.189069
epoch: 2049, train precision: 0.922178, train loss: 33.318993, valid precision: 0.771400, valid loss: 136.667400
epoch: 2050, train precision: 0.923489, train loss: 31.740375, valid precision: 0.766400, valid loss: 135.498696
epoch: 2051, train precision: 0.823756, train loss: 76.559779, valid precision: 0.713800, valid loss: 158.511847
epoch: 2052, train precision: 0.925933, train loss: 33.036456, valid precision: 0.768200, valid loss: 136.343242
epoch: 2053, train precision: 0.913978, train loss: 36.578184, valid precision: 0.761000, valid loss: 135.746279
epoch: 2054, train precision: 0.922711, train loss: 36.669156, valid precision: 0.771000, valid loss: 151.552621
epoch: 2055, train precision: 0.924556, train loss: 31.769943, valid precision: 0.766200, valid loss: 138.683587
epoch: 2056, train precision: 0.813467, train loss: 89.154053, valid precision: 0.719800, valid loss: 164.357377
epoch: 2057, train precision: 0.929178, train loss: 30.500563, valid precision: 0.773200, valid loss: 141.925028
epoch: 2058, train precision: 0.734022, train loss: 131.727146, valid precision: 0.665000, valid loss: 204.998379
epoch: 2059, train precision: 0.929533, train loss: 29.929940, valid precision: 0.773000, valid loss: 133.032600
epoch: 2060, train precision: 0.918556, train loss: 34.271350, valid precision: 0.766600, valid loss: 134.902593
epoch: 2061, train precision: 0.927378, train loss: 30.184754, valid precision: 0.767000, valid loss: 139.256122
epoch: 2062, train precision: 0.466689, train loss: 202.423948, valid precision: 0.470600, valid loss: 219.731177
epoch: 2063, train precision: 0.911578, train loss: 37.647923, valid precision: 0.767600, valid loss: 138.705978
epoch: 2064, train precision: 0.290222, train loss: 254.240722, valid precision: 0.287800, valid loss: 256.674018
epoch: 2065, train precision: 0.866511, train loss: 55.353150, valid precision: 0.749600, valid loss: 131.954141
epoch: 2066, train precision: 0.918711, train loss: 34.511906, valid precision: 0.773400, valid loss: 121.144911
epoch: 2067, train precision: 0.925000, train loss: 31.331806, valid precision: 0.773400, valid loss: 125.889810
epoch: 2068, train precision: 0.914378, train loss: 35.312233, valid precision: 0.772800, valid loss: 128.677909
epoch: 2069, train precision: 0.933289, train loss: 28.109208, valid precision: 0.773200, valid loss: 135.405546
epoch: 2070, train precision: 0.934333, train loss: 28.244361, valid precision: 0.779400, valid loss: 126.724683
epoch: 2071, train precision: 0.936933, train loss: 27.543032, valid precision: 0.777800, valid loss: 130.837301
epoch: 2072, train precision: 0.917889, train loss: 34.276002, valid precision: 0.774800, valid loss: 127.438187
epoch: 2073, train precision: 0.923600, train loss: 32.488523, valid precision: 0.770400, valid loss: 130.678934
epoch: 2074, train precision: 0.912378, train loss: 35.920346, valid precision: 0.764000, valid loss: 140.783445
epoch: 2075, train precision: 0.929489, train loss: 30.409642, valid precision: 0.772800, valid loss: 139.024060
epoch: 2076, train precision: 0.920711, train loss: 35.565685, valid precision: 0.768000, valid loss: 167.247767
epoch: 2077, train precision: 0.880511, train loss: 49.369069, valid precision: 0.749800, valid loss: 139.583904
epoch: 2078, train precision: 0.932422, train loss: 30.040003, valid precision: 0.770400, valid loss: 136.482490
epoch: 2079, train precision: 0.928022, train loss: 30.414322, valid precision: 0.774200, valid loss: 135.002426
epoch: 2080, train precision: 0.927400, train loss: 30.544172, valid precision: 0.772200, valid loss: 131.513729
epoch: 2081, train precision: 0.878022, train loss: 53.041740, valid precision: 0.751000, valid loss: 151.799213
epoch: 2082, train precision: 0.933044, train loss: 28.763962, valid precision: 0.777600, valid loss: 128.769534
epoch: 2083, train precision: 0.929556, train loss: 29.759205, valid precision: 0.778000, valid loss: 142.775837
epoch: 2084, train precision: 0.208911, train loss: 342.689033, valid precision: 0.217800, valid loss: 337.146672
epoch: 2085, train precision: 0.639089, train loss: 136.467213, valid precision: 0.611400, valid loss: 152.768277
epoch: 2086, train precision: 0.910378, train loss: 37.882103, valid precision: 0.773400, valid loss: 135.871621
epoch: 2087, train precision: 0.925689, train loss: 33.376770, valid precision: 0.769600, valid loss: 161.802834
epoch: 2088, train precision: 0.668644, train loss: 134.198706, valid precision: 0.628200, valid loss: 168.086045
epoch: 2089, train precision: 0.918978, train loss: 34.292076, valid precision: 0.774000, valid loss: 126.304922
epoch: 2090, train precision: 0.927889, train loss: 30.245514, valid precision: 0.778000, valid loss: 133.744983
epoch: 2091, train precision: 0.919978, train loss: 38.879864, valid precision: 0.756600, valid loss: 138.916805
epoch: 2092, train precision: 0.928422, train loss: 30.082073, valid precision: 0.769200, valid loss: 136.119190
epoch: 2093, train precision: 0.399667, train loss: 240.055430, valid precision: 0.407600, valid loss: 236.032243
epoch: 2094, train precision: 0.887222, train loss: 46.984098, valid precision: 0.769200, valid loss: 130.029996
epoch: 2095, train precision: 0.931933, train loss: 28.472224, valid precision: 0.778800, valid loss: 122.663306
epoch: 2096, train precision: 0.906267, train loss: 39.374310, valid precision: 0.771000, valid loss: 128.337512
epoch: 2097, train precision: 0.922156, train loss: 33.048268, valid precision: 0.771600, valid loss: 143.093607
epoch: 2098, train precision: 0.916578, train loss: 34.647959, valid precision: 0.763400, valid loss: 143.859213
epoch: 2099, train precision: 0.917511, train loss: 35.566856, valid precision: 0.762200, valid loss: 148.522860
epoch: 2100, train precision: 0.920133, train loss: 33.939654, valid precision: 0.769600, valid loss: 134.607846
epoch: 2101, train precision: 0.916111, train loss: 34.853881, valid precision: 0.764000, valid loss: 141.415969
epoch: 2102, train precision: 0.889467, train loss: 49.051859, valid precision: 0.753200, valid loss: 155.127342
epoch: 2103, train precision: 0.924289, train loss: 32.535928, valid precision: 0.762800, valid loss: 138.417291
epoch: 2104, train precision: 0.909444, train loss: 36.893549, valid precision: 0.769800, valid loss: 127.980296
epoch: 2105, train precision: 0.929756, train loss: 29.512531, valid precision: 0.773800, valid loss: 144.821606
epoch: 2106, train precision: 0.927600, train loss: 30.758588, valid precision: 0.773400, valid loss: 137.982784
epoch: 2107, train precision: 0.925267, train loss: 31.380634, valid precision: 0.765400, valid loss: 141.141696
epoch: 2108, train precision: 0.936511, train loss: 27.968175, valid precision: 0.775400, valid loss: 168.438577
epoch: 2109, train precision: 0.916333, train loss: 34.847691, valid precision: 0.765200, valid loss: 165.415326
epoch: 2110, train precision: 0.907378, train loss: 38.998397, valid precision: 0.770200, valid loss: 136.880242
epoch: 2111, train precision: 0.914422, train loss: 39.759489, valid precision: 0.771400, valid loss: 139.281073
epoch: 2112, train precision: 0.928489, train loss: 30.802571, valid precision: 0.775200, valid loss: 136.091338
epoch: 2113, train precision: 0.898911, train loss: 41.529862, valid precision: 0.760400, valid loss: 133.638830
epoch: 2114, train precision: 0.852200, train loss: 65.039051, valid precision: 0.734800, valid loss: 173.390031
epoch: 2115, train precision: 0.931311, train loss: 30.082745, valid precision: 0.768800, valid loss: 299.067149
epoch: 2116, train precision: 0.926711, train loss: 31.142664, valid precision: 0.768600, valid loss: 229.632971
epoch: 2117, train precision: 0.909133, train loss: 38.536814, valid precision: 0.754600, valid loss: 147.928476
epoch: 2118, train precision: 0.927911, train loss: 30.278519, valid precision: 0.770200, valid loss: 314.818274
epoch: 2119, train precision: 0.788511, train loss: 87.225845, valid precision: 0.717800, valid loss: 149.504057
epoch: 2120, train precision: 0.904111, train loss: 39.229826, valid precision: 0.771000, valid loss: 374.082578
epoch: 2121, train precision: 0.421133, train loss: 207.857314, valid precision: 0.413000, valid loss: 212.387211
epoch: 2122, train precision: 0.884600, train loss: 47.196978, valid precision: 0.757000, valid loss: 128.017400
epoch: 2123, train precision: 0.916800, train loss: 34.325945, valid precision: 0.774200, valid loss: 127.257238
epoch: 2124, train precision: 0.936756, train loss: 29.021134, valid precision: 0.779600, valid loss: 156.195810
epoch: 2125, train precision: 0.919733, train loss: 33.671601, valid precision: 0.760200, valid loss: 142.154365
epoch: 2126, train precision: 0.923356, train loss: 32.133987, valid precision: 0.766800, valid loss: 137.692718
epoch: 2127, train precision: 0.936200, train loss: 30.863330, valid precision: 0.773400, valid loss: 143.795533
epoch: 2128, train precision: 0.933000, train loss: 27.893427, valid precision: 0.774200, valid loss: 140.376723
epoch: 2129, train precision: 0.903844, train loss: 38.310307, valid precision: 0.755400, valid loss: 138.929056
epoch: 2130, train precision: 0.920422, train loss: 34.724733, valid precision: 0.759600, valid loss: 156.011361
epoch: 2131, train precision: 0.924778, train loss: 33.681701, valid precision: 0.765400, valid loss: 152.755260
epoch: 2132, train precision: 0.933511, train loss: 28.533648, valid precision: 0.775400, valid loss: 148.056230
epoch: 2133, train precision: 0.934000, train loss: 28.830470, valid precision: 0.774600, valid loss: 144.938341
epoch: 2134, train precision: 0.935000, train loss: 27.852571, valid precision: 0.771200, valid loss: 145.014550
epoch: 2135, train precision: 0.928667, train loss: 30.194405, valid precision: 0.779600, valid loss: 139.692713
epoch: 2136, train precision: 0.933244, train loss: 28.557825, valid precision: 0.778600, valid loss: 131.119132
epoch: 2137, train precision: 0.931533, train loss: 29.284386, valid precision: 0.781000, valid loss: 127.739350
epoch: 2138, train precision: 0.885311, train loss: 47.964254, valid precision: 0.742200, valid loss: 143.690198
epoch: 2139, train precision: 0.937889, train loss: 26.481342, valid precision: 0.777600, valid loss: 138.389907
epoch: 2140, train precision: 0.904489, train loss: 40.075209, valid precision: 0.758400, valid loss: 145.252139
epoch: 2141, train precision: 0.891911, train loss: 45.305778, valid precision: 0.762400, valid loss: 146.947869
epoch: 2142, train precision: 0.923622, train loss: 31.842118, valid precision: 0.779600, valid loss: 133.517060
epoch: 2143, train precision: 0.926467, train loss: 30.537877, valid precision: 0.775800, valid loss: 132.404790
epoch: 2144, train precision: 0.922200, train loss: 33.890071, valid precision: 0.762400, valid loss: 156.261245
epoch: 2145, train precision: 0.937956, train loss: 25.821293, valid precision: 0.782800, valid loss: 126.741759
epoch: 2146, train precision: 0.920378, train loss: 32.942938, valid precision: 0.771600, valid loss: 140.182348
epoch: 2147, train precision: 0.724200, train loss: 118.081117, valid precision: 0.668600, valid loss: 161.515096
epoch: 2148, train precision: 0.330667, train loss: 323.661971, valid precision: 0.329000, valid loss: 329.024420
epoch: 2149, train precision: 0.915978, train loss: 34.706604, valid precision: 0.772000, valid loss: 131.771231
epoch: 2150, train precision: 0.939622, train loss: 25.222072, valid precision: 0.777200, valid loss: 133.476535
epoch: 2151, train precision: 0.934022, train loss: 29.708265, valid precision: 0.772200, valid loss: 130.840220
epoch: 2152, train precision: 0.928044, train loss: 30.507381, valid precision: 0.765000, valid loss: 142.129291
epoch: 2153, train precision: 0.785822, train loss: 93.069657, valid precision: 0.696400, valid loss: 156.136395
epoch: 2154, train precision: 0.923533, train loss: 32.560797, valid precision: 0.764000, valid loss: 136.132678
epoch: 2155, train precision: 0.933400, train loss: 27.752559, valid precision: 0.772800, valid loss: 147.988190
epoch: 2156, train precision: 0.919022, train loss: 33.647331, valid precision: 0.767600, valid loss: 147.448764
epoch: 2157, train precision: 0.925244, train loss: 30.697362, valid precision: 0.770000, valid loss: 161.489264
epoch: 2158, train precision: 0.921733, train loss: 33.660880, valid precision: 0.763400, valid loss: 270.697952
epoch: 2159, train precision: 0.935933, train loss: 28.720011, valid precision: 0.775200, valid loss: 253.764463
epoch: 2160, train precision: 0.934756, train loss: 27.278660, valid precision: 0.778800, valid loss: 184.188534
epoch: 2161, train precision: 0.864111, train loss: 59.591057, valid precision: 0.740200, valid loss: 144.175272
epoch: 2162, train precision: 0.918511, train loss: 33.873302, valid precision: 0.769600, valid loss: 137.601190
epoch: 2163, train precision: 0.929622, train loss: 29.433498, valid precision: 0.777200, valid loss: 177.199275
epoch: 2164, train precision: 0.928667, train loss: 29.814452, valid precision: 0.776000, valid loss: 147.183646
epoch: 2165, train precision: 0.906778, train loss: 40.495888, valid precision: 0.759400, valid loss: 162.123568
epoch: 2166, train precision: 0.747889, train loss: 104.558035, valid precision: 0.686600, valid loss: 148.602590
epoch: 2167, train precision: 0.927267, train loss: 31.611075, valid precision: 0.774600, valid loss: 176.799678
epoch: 2168, train precision: 0.930644, train loss: 28.011266, valid precision: 0.777600, valid loss: 132.987523
epoch: 2169, train precision: 0.913956, train loss: 37.366993, valid precision: 0.763000, valid loss: 155.578482
epoch: 2170, train precision: 0.934800, train loss: 28.133824, valid precision: 0.772600, valid loss: 213.015495
epoch: 2171, train precision: 0.302911, train loss: 304.547445, valid precision: 0.317000, valid loss: 290.909654
epoch: 2172, train precision: 0.862711, train loss: 56.971333, valid precision: 0.748200, valid loss: 129.607691
epoch: 2173, train precision: 0.918378, train loss: 34.326032, valid precision: 0.769600, valid loss: 137.258714
epoch: 2174, train precision: 0.935822, train loss: 27.093334, valid precision: 0.781800, valid loss: 125.927148
epoch: 2175, train precision: 0.843444, train loss: 65.451989, valid precision: 0.739600, valid loss: 134.787764
epoch: 2176, train precision: 0.927089, train loss: 30.116026, valid precision: 0.775000, valid loss: 124.392019
epoch: 2177, train precision: 0.913578, train loss: 35.977055, valid precision: 0.758000, valid loss: 140.287265
epoch: 2178, train precision: 0.929756, train loss: 29.428389, valid precision: 0.776000, valid loss: 144.109417
epoch: 2179, train precision: 0.914311, train loss: 35.861333, valid precision: 0.769200, valid loss: 139.065817
epoch: 2180, train precision: 0.929822, train loss: 28.338997, valid precision: 0.775600, valid loss: 139.258849
epoch: 2181, train precision: 0.921178, train loss: 102.032004, valid precision: 0.769800, valid loss: 138.470697
epoch: 2182, train precision: 0.930489, train loss: 29.274744, valid precision: 0.772600, valid loss: 153.731273
epoch: 2183, train precision: 0.925867, train loss: 31.675613, valid precision: 0.769600, valid loss: 145.726802
epoch: 2184, train precision: 0.475089, train loss: 288.779440, valid precision: 0.474200, valid loss: 297.830520
epoch: 2185, train precision: 0.908756, train loss: 42.914099, valid precision: 0.770000, valid loss: 131.182557
epoch: 2186, train precision: 0.933444, train loss: 28.916256, valid precision: 0.774400, valid loss: 193.284651
epoch: 2187, train precision: 0.933356, train loss: 30.379382, valid precision: 0.776600, valid loss: 133.215537
epoch: 2188, train precision: 0.923733, train loss: 32.850185, valid precision: 0.771200, valid loss: 136.419536
epoch: 2189, train precision: 0.941556, train loss: 24.308948, valid precision: 0.784200, valid loss: 137.612072
epoch: 2190, train precision: 0.940222, train loss: 45.951683, valid precision: 0.773800, valid loss: 174.975339
epoch: 2191, train precision: 0.479311, train loss: 197.697847, valid precision: 0.480200, valid loss: 202.516118
epoch: 2192, train precision: 0.886489, train loss: 47.283501, valid precision: 0.757400, valid loss: 126.207114
epoch: 2193, train precision: 0.922244, train loss: 31.782631, valid precision: 0.771000, valid loss: 132.895318
epoch: 2194, train precision: 0.726511, train loss: 117.436526, valid precision: 0.669400, valid loss: 156.126338
epoch: 2195, train precision: 0.699356, train loss: 122.389534, valid precision: 0.638400, valid loss: 166.649996
epoch: 2196, train precision: 0.913556, train loss: 36.923288, valid precision: 0.771400, valid loss: 137.488272
epoch: 2197, train precision: 0.786689, train loss: 92.943324, valid precision: 0.717000, valid loss: 143.837772
epoch: 2198, train precision: 0.914622, train loss: 35.741256, valid precision: 0.760400, valid loss: 136.291807
epoch: 2199, train precision: 0.941044, train loss: 26.265647, valid precision: 0.780000, valid loss: 141.216221
epoch: 2200, train precision: 0.912244, train loss: 38.464016, valid precision: 0.771200, valid loss: 133.338372
epoch: 2201, train precision: 0.934422, train loss: 28.789657, valid precision: 0.771400, valid loss: 138.691088
epoch: 2202, train precision: 0.916111, train loss: 35.487778, valid precision: 0.766800, valid loss: 137.037409
epoch: 2203, train precision: 0.929933, train loss: 29.970050, valid precision: 0.774200, valid loss: 140.765461
epoch: 2204, train precision: 0.888178, train loss: 47.694491, valid precision: 0.756000, valid loss: 142.805440
epoch: 2205, train precision: 0.919889, train loss: 34.484959, valid precision: 0.768800, valid loss: 146.129153
epoch: 2206, train precision: 0.842156, train loss: 70.048170, valid precision: 0.738200, valid loss: 148.223590
epoch: 2207, train precision: 0.209133, train loss: 271.670888, valid precision: 0.213600, valid loss: 283.737141
epoch: 2208, train precision: 0.589311, train loss: 157.565914, valid precision: 0.583000, valid loss: 167.221155
epoch: 2209, train precision: 0.811156, train loss: 81.284452, valid precision: 0.723200, valid loss: 141.705201
epoch: 2210, train precision: 0.927556, train loss: 31.949694, valid precision: 0.762800, valid loss: 133.538956
epoch: 2211, train precision: 0.939867, train loss: 25.794036, valid precision: 0.775800, valid loss: 131.696856
epoch: 2212, train precision: 0.863333, train loss: 56.027858, valid precision: 0.747600, valid loss: 130.147703
epoch: 2213, train precision: 0.928800, train loss: 30.372045, valid precision: 0.761400, valid loss: 143.532273
epoch: 2214, train precision: 0.919289, train loss: 34.586902, valid precision: 0.764800, valid loss: 146.499533
epoch: 2215, train precision: 0.939133, train loss: 25.787830, valid precision: 0.775200, valid loss: 135.136144
epoch: 2216, train precision: 0.944089, train loss: 26.058626, valid precision: 0.772400, valid loss: 158.480841
epoch: 2217, train precision: 0.932889, train loss: 31.171228, valid precision: 0.762600, valid loss: 145.506121
epoch: 2218, train precision: 0.389467, train loss: 223.577013, valid precision: 0.392600, valid loss: 217.021321
epoch: 2219, train precision: 0.845956, train loss: 57.266851, valid precision: 0.709600, valid loss: 141.739190
epoch: 2220, train precision: 0.924600, train loss: 32.592834, valid precision: 0.759800, valid loss: 146.860679
epoch: 2221, train precision: 0.304867, train loss: 262.061314, valid precision: 0.313800, valid loss: 260.962214
epoch: 2222, train precision: 0.859222, train loss: 58.077275, valid precision: 0.752000, valid loss: 126.099591
epoch: 2223, train precision: 0.919978, train loss: 34.481432, valid precision: 0.766800, valid loss: 140.743984
epoch: 2224, train precision: 0.930222, train loss: 30.891113, valid precision: 0.776600, valid loss: 130.767454
epoch: 2225, train precision: 0.941911, train loss: 25.428432, valid precision: 0.780400, valid loss: 134.375117
epoch: 2226, train precision: 0.921533, train loss: 32.282949, valid precision: 0.771000, valid loss: 137.268382
epoch: 2227, train precision: 0.937044, train loss: 26.641246, valid precision: 0.781400, valid loss: 137.634146
epoch: 2228, train precision: 0.923111, train loss: 32.677549, valid precision: 0.762400, valid loss: 146.725388
epoch: 2229, train precision: 0.924267, train loss: 31.903809, valid precision: 0.776800, valid loss: 128.329200
epoch: 2230, train precision: 0.936578, train loss: 28.611399, valid precision: 0.771800, valid loss: 153.544086
epoch: 2231, train precision: 0.913333, train loss: 36.461673, valid precision: 0.765800, valid loss: 137.879116
epoch: 2232, train precision: 0.934333, train loss: 31.930165, valid precision: 0.771800, valid loss: 138.922828
epoch: 2233, train precision: 0.940133, train loss: 25.679864, valid precision: 0.767800, valid loss: 153.926907
epoch: 2234, train precision: 0.606356, train loss: 155.739170, valid precision: 0.577400, valid loss: 180.791642
epoch: 2235, train precision: 0.939244, train loss: 25.957894, valid precision: 0.769400, valid loss: 147.540757
epoch: 2236, train precision: 0.935489, train loss: 27.655292, valid precision: 0.772800, valid loss: 145.113200
epoch: 2237, train precision: 0.206111, train loss: 268.189013, valid precision: 0.204800, valid loss: 268.197198
epoch: 2238, train precision: 0.200711, train loss: 253.290263, valid precision: 0.210600, valid loss: 251.989208
epoch: 2239, train precision: 0.331889, train loss: 224.502055, valid precision: 0.342200, valid loss: 220.606490
epoch: 2240, train precision: 0.834467, train loss: 88.964271, valid precision: 0.727400, valid loss: 156.048848
epoch: 2241, train precision: 0.825844, train loss: 72.594812, valid precision: 0.724400, valid loss: 158.386947
epoch: 2242, train precision: 0.898467, train loss: 46.427485, valid precision: 0.765200, valid loss: 146.608979
epoch: 2243, train precision: 0.864267, train loss: 57.766716, valid precision: 0.749000, valid loss: 131.733060
epoch: 2244, train precision: 0.907822, train loss: 42.007676, valid precision: 0.769800, valid loss: 144.870812
epoch: 2245, train precision: 0.362800, train loss: 222.144079, valid precision: 0.370800, valid loss: 217.656700
epoch: 2246, train precision: 0.895622, train loss: 47.709424, valid precision: 0.762000, valid loss: 126.669271
epoch: 2247, train precision: 0.900600, train loss: 50.146026, valid precision: 0.755200, valid loss: 150.001315
epoch: 2248, train precision: 0.921689, train loss: 34.693741, valid precision: 0.780400, valid loss: 123.825609
epoch: 2249, train precision: 0.930822, train loss: 30.555615, valid precision: 0.772800, valid loss: 124.411302
epoch: 2250, train precision: 0.914333, train loss: 36.126394, valid precision: 0.774400, valid loss: 135.067848
epoch: 2251, train precision: 0.938222, train loss: 27.530419, valid precision: 0.781400, valid loss: 131.666351
epoch: 2252, train precision: 0.926467, train loss: 31.805602, valid precision: 0.765000, valid loss: 149.231124
epoch: 2253, train precision: 0.926978, train loss: 31.725521, valid precision: 0.777800, valid loss: 141.487263
epoch: 2254, train precision: 0.928444, train loss: 30.923427, valid precision: 0.772000, valid loss: 141.979280
epoch: 2255, train precision: 0.941911, train loss: 26.184936, valid precision: 0.776400, valid loss: 139.574333
epoch: 2256, train precision: 0.937778, train loss: 26.411710, valid precision: 0.780800, valid loss: 137.590535
epoch: 2257, train precision: 0.940622, train loss: 25.225041, valid precision: 0.779600, valid loss: 150.879635
epoch: 2258, train precision: 0.783400, train loss: 82.436125, valid precision: 0.680000, valid loss: 157.431316
epoch: 2259, train precision: 0.931133, train loss: 30.812069, valid precision: 0.762800, valid loss: 152.194124
epoch: 2260, train precision: 0.917111, train loss: 36.566275, valid precision: 0.763800, valid loss: 152.929359
epoch: 2261, train precision: 0.932378, train loss: 29.382418, valid precision: 0.771000, valid loss: 144.237356
epoch: 2262, train precision: 0.924578, train loss: 31.673050, valid precision: 0.777400, valid loss: 146.811027
epoch: 2263, train precision: 0.933778, train loss: 28.237423, valid precision: 0.778800, valid loss: 136.489747
epoch: 2264, train precision: 0.912622, train loss: 36.109248, valid precision: 0.766600, valid loss: 135.516967
epoch: 2265, train precision: 0.932911, train loss: 28.091735, valid precision: 0.769800, valid loss: 151.906671
epoch: 2266, train precision: 0.926378, train loss: 31.678985, valid precision: 0.775800, valid loss: 139.950950
epoch: 2267, train precision: 0.938733, train loss: 26.516689, valid precision: 0.776000, valid loss: 139.424032
epoch: 2268, train precision: 0.928356, train loss: 31.342505, valid precision: 0.767400, valid loss: 155.289676
epoch: 2269, train precision: 0.442533, train loss: 220.971685, valid precision: 0.438400, valid loss: 224.590774
epoch: 2270, train precision: 0.926289, train loss: 30.705981, valid precision: 0.772400, valid loss: 141.251904
epoch: 2271, train precision: 0.909578, train loss: 38.141371, valid precision: 0.752000, valid loss: 144.790571
epoch: 2272, train precision: 0.907444, train loss: 39.247932, valid precision: 0.756800, valid loss: 139.205656
epoch: 2273, train precision: 0.918067, train loss: 35.002129, valid precision: 0.771800, valid loss: 137.302560
epoch: 2274, train precision: 0.914400, train loss: 35.610803, valid precision: 0.767000, valid loss: 136.324910
epoch: 2275, train precision: 0.929689, train loss: 30.171989, valid precision: 0.772600, valid loss: 147.173948
epoch: 2276, train precision: 0.932889, train loss: 28.853746, valid precision: 0.774400, valid loss: 136.010756
epoch: 2277, train precision: 0.631200, train loss: 166.697217, valid precision: 0.602000, valid loss: 196.630677
epoch: 2278, train precision: 0.889422, train loss: 47.482124, valid precision: 0.747800, valid loss: 141.671297
epoch: 2279, train precision: 0.926533, train loss: 32.235620, valid precision: 0.763600, valid loss: 152.978250
epoch: 2280, train precision: 0.881800, train loss: 49.267242, valid precision: 0.754600, valid loss: 152.446331
epoch: 2281, train precision: 0.862933, train loss: 60.101509, valid precision: 0.731800, valid loss: 152.961987
epoch: 2282, train precision: 0.928244, train loss: 30.688031, valid precision: 0.776200, valid loss: 133.860777
epoch: 2283, train precision: 0.924578, train loss: 30.843585, valid precision: 0.769000, valid loss: 143.189728
epoch: 2284, train precision: 0.587511, train loss: 185.936380, valid precision: 0.580000, valid loss: 194.018926
epoch: 2285, train precision: 0.928800, train loss: 30.394986, valid precision: 0.776600, valid loss: 138.467250
epoch: 2286, train precision: 0.897289, train loss: 42.842499, valid precision: 0.756800, valid loss: 132.352098
epoch: 2287, train precision: 0.905333, train loss: 39.737279, valid precision: 0.761800, valid loss: 137.789478
epoch: 2288, train precision: 0.943956, train loss: 24.308644, valid precision: 0.776800, valid loss: 139.229622
epoch: 2289, train precision: 0.941222, train loss: 24.402945, valid precision: 0.778400, valid loss: 135.728233
epoch: 2290, train precision: 0.931222, train loss: 30.258968, valid precision: 0.762000, valid loss: 141.617792
epoch: 2291, train precision: 0.922467, train loss: 33.868368, valid precision: 0.770000, valid loss: 142.146301
epoch: 2292, train precision: 0.933311, train loss: 30.788328, valid precision: 0.769600, valid loss: 156.441442
epoch: 2293, train precision: 0.848511, train loss: 63.920445, valid precision: 0.740200, valid loss: 133.029532
epoch: 2294, train precision: 0.931889, train loss: 30.179448, valid precision: 0.770600, valid loss: 138.806590
epoch: 2295, train precision: 0.942911, train loss: 24.394503, valid precision: 0.776800, valid loss: 141.016840
epoch: 2296, train precision: 0.887600, train loss: 48.168665, valid precision: 0.750200, valid loss: 142.009627
epoch: 2297, train precision: 0.938711, train loss: 27.323625, valid precision: 0.775600, valid loss: 143.702176
epoch: 2298, train precision: 0.935889, train loss: 28.957729, valid precision: 0.768600, valid loss: 154.679112
epoch: 2299, train precision: 0.943222, train loss: 24.596094, valid precision: 0.771200, valid loss: 166.940857
epoch: 2300, train precision: 0.939978, train loss: 25.702049, valid precision: 0.775000, valid loss: 176.354940
epoch: 2301, train precision: 0.936711, train loss: 27.313088, valid precision: 0.778800, valid loss: 192.683486
epoch: 2302, train precision: 0.941378, train loss: 25.134692, valid precision: 0.777600, valid loss: 191.317873
epoch: 2303, train precision: 0.934378, train loss: 28.018833, valid precision: 0.771200, valid loss: 144.364422
epoch: 2304, train precision: 0.900400, train loss: 42.780420, valid precision: 0.765600, valid loss: 146.974950
epoch: 2305, train precision: 0.926889, train loss: 29.467148, valid precision: 0.765200, valid loss: 132.605736
epoch: 2306, train precision: 0.713933, train loss: 130.317845, valid precision: 0.666800, valid loss: 181.430461
epoch: 2307, train precision: 0.642822, train loss: 156.560945, valid precision: 0.612400, valid loss: 183.385251
epoch: 2308, train precision: 0.926644, train loss: 31.195538, valid precision: 0.766600, valid loss: 131.433705
epoch: 2309, train precision: 0.883222, train loss: 50.419195, valid precision: 0.750400, valid loss: 141.292997
epoch: 2310, train precision: 0.926356, train loss: 31.163187, valid precision: 0.765400, valid loss: 147.722686
epoch: 2311, train precision: 0.942489, train loss: 24.529654, valid precision: 0.775600, valid loss: 152.574764
epoch: 2312, train precision: 0.916778, train loss: 36.602394, valid precision: 0.756000, valid loss: 177.995321
epoch: 2313, train precision: 0.913600, train loss: 40.498292, valid precision: 0.757000, valid loss: 175.645867
epoch: 2314, train precision: 0.935333, train loss: 27.564940, valid precision: 0.768600, valid loss: 149.626309
epoch: 2315, train precision: 0.925578, train loss: 33.046908, valid precision: 0.773200, valid loss: 153.894242
epoch: 2316, train precision: 0.930356, train loss: 30.676147, valid precision: 0.761800, valid loss: 155.081166
epoch: 2317, train precision: 0.936156, train loss: 27.903362, valid precision: 0.774600, valid loss: 275.217741
epoch: 2318, train precision: 0.930844, train loss: 29.805192, valid precision: 0.768800, valid loss: 301.066953
epoch: 2319, train precision: 0.885311, train loss: 49.067430, valid precision: 0.748000, valid loss: 139.607467
epoch: 2320, train precision: 0.940444, train loss: 24.565659, valid precision: 0.777400, valid loss: 142.942580
epoch: 2321, train precision: 0.919556, train loss: 33.693897, valid precision: 0.768200, valid loss: 128.034919
epoch: 2322, train precision: 0.910533, train loss: 36.991958, valid precision: 0.763000, valid loss: 143.387854
epoch: 2323, train precision: 0.937867, train loss: 26.989788, valid precision: 0.777400, valid loss: 144.123134
epoch: 2324, train precision: 0.938244, train loss: 26.771834, valid precision: 0.779600, valid loss: 149.857887
epoch: 2325, train precision: 0.931689, train loss: 29.606981, valid precision: 0.769400, valid loss: 160.271678
epoch: 2326, train precision: 0.951778, train loss: 20.891627, valid precision: 0.780800, valid loss: 214.462415
epoch: 2327, train precision: 0.905400, train loss: 43.703580, valid precision: 0.754400, valid loss: 175.722096
epoch: 2328, train precision: 0.267622, train loss: 271.053020, valid precision: 0.271400, valid loss: 271.378873
epoch: 2329, train precision: 0.882156, train loss: 49.902393, valid precision: 0.751200, valid loss: 131.583291
epoch: 2330, train precision: 0.940267, train loss: 26.568181, valid precision: 0.772800, valid loss: 146.431056
epoch: 2331, train precision: 0.939778, train loss: 26.178709, valid precision: 0.779200, valid loss: 140.135471
epoch: 2332, train precision: 0.940556, train loss: 25.650965, valid precision: 0.770000, valid loss: 140.776333
epoch: 2333, train precision: 0.939844, train loss: 26.757325, valid precision: 0.776000, valid loss: 144.720454
epoch: 2334, train precision: 0.909467, train loss: 40.499348, valid precision: 0.751800, valid loss: 161.107029
epoch: 2335, train precision: 0.940444, train loss: 25.452522, valid precision: 0.778200, valid loss: 142.814785
epoch: 2336, train precision: 0.896778, train loss: 42.406959, valid precision: 0.744400, valid loss: 163.407500
epoch: 2337, train precision: 0.776111, train loss: 97.445919, valid precision: 0.677000, valid loss: 171.817214
epoch: 2338, train precision: 0.941844, train loss: 27.227070, valid precision: 0.777200, valid loss: 145.052710
epoch: 2339, train precision: 0.938133, train loss: 26.259619, valid precision: 0.770000, valid loss: 149.176501
epoch: 2340, train precision: 0.920111, train loss: 33.157857, valid precision: 0.758800, valid loss: 167.267361
epoch: 2341, train precision: 0.846689, train loss: 69.053700, valid precision: 0.740200, valid loss: 245.044926
epoch: 2342, train precision: 0.942911, train loss: 24.631160, valid precision: 0.779200, valid loss: 154.589225
epoch: 2343, train precision: 0.941600, train loss: 25.285236, valid precision: 0.782400, valid loss: 140.941394
epoch: 2344, train precision: 0.689222, train loss: 143.754612, valid precision: 0.636000, valid loss: 187.528520
epoch: 2345, train precision: 0.926111, train loss: 31.207392, valid precision: 0.772800, valid loss: 151.436898
epoch: 2346, train precision: 0.942800, train loss: 25.222605, valid precision: 0.780000, valid loss: 144.765096
epoch: 2347, train precision: 0.941778, train loss: 24.921143, valid precision: 0.778000, valid loss: 144.004142
epoch: 2348, train precision: 0.918200, train loss: 34.682008, valid precision: 0.766600, valid loss: 151.250922
epoch: 2349, train precision: 0.939333, train loss: 27.997659, valid precision: 0.771800, valid loss: 146.707869
epoch: 2350, train precision: 0.894378, train loss: 46.422470, valid precision: 0.755400, valid loss: 145.718055
epoch: 2351, train precision: 0.884533, train loss: 47.036446, valid precision: 0.752800, valid loss: 135.531411
epoch: 2352, train precision: 0.935378, train loss: 28.057043, valid precision: 0.776200, valid loss: 146.526594
epoch: 2353, train precision: 0.932467, train loss: 28.471695, valid precision: 0.779000, valid loss: 137.543882
epoch: 2354, train precision: 0.944956, train loss: 24.034986, valid precision: 0.783200, valid loss: 156.015242
epoch: 2355, train precision: 0.919489, train loss: 36.147857, valid precision: 0.762000, valid loss: 161.363929
epoch: 2356, train precision: 0.939289, train loss: 26.329032, valid precision: 0.779000, valid loss: 154.384659
epoch: 2357, train precision: 0.903111, train loss: 42.502414, valid precision: 0.748800, valid loss: 159.484043
epoch: 2358, train precision: 0.931244, train loss: 30.097638, valid precision: 0.768800, valid loss: 153.648856
epoch: 2359, train precision: 0.945178, train loss: 23.900630, valid precision: 0.779600, valid loss: 156.612660
epoch: 2360, train precision: 0.928444, train loss: 31.883802, valid precision: 0.765800, valid loss: 185.386421
epoch: 2361, train precision: 0.931733, train loss: 29.742150, valid precision: 0.776600, valid loss: 153.801219
epoch: 2362, train precision: 0.921333, train loss: 33.099339, valid precision: 0.765200, valid loss: 149.499454
epoch: 2363, train precision: 0.894244, train loss: 44.531769, valid precision: 0.754200, valid loss: 145.409197
epoch: 2364, train precision: 0.932222, train loss: 30.234274, valid precision: 0.769000, valid loss: 172.677661
epoch: 2365, train precision: 0.919711, train loss: 34.135125, valid precision: 0.764600, valid loss: 153.150429
epoch: 2366, train precision: 0.903800, train loss: 40.747409, valid precision: 0.748600, valid loss: 264.275053
epoch: 2367, train precision: 0.321778, train loss: 290.712112, valid precision: 0.321000, valid loss: 293.831732
epoch: 2368, train precision: 0.922133, train loss: 35.740352, valid precision: 0.773200, valid loss: 238.410274
epoch: 2369, train precision: 0.847511, train loss: 66.394173, valid precision: 0.729600, valid loss: 183.161146
epoch: 2370, train precision: 0.936667, train loss: 27.135454, valid precision: 0.773000, valid loss: 143.192434
epoch: 2371, train precision: 0.937556, train loss: 27.487011, valid precision: 0.768800, valid loss: 167.248255
epoch: 2372, train precision: 0.941800, train loss: 25.339754, valid precision: 0.774000, valid loss: 156.112638
epoch: 2373, train precision: 0.822378, train loss: 80.022544, valid precision: 0.719600, valid loss: 163.480638
epoch: 2374, train precision: 0.941178, train loss: 25.558786, valid precision: 0.770200, valid loss: 144.841537
epoch: 2375, train precision: 0.932978, train loss: 28.841417, valid precision: 0.762600, valid loss: 167.311009
epoch: 2376, train precision: 0.936444, train loss: 29.339137, valid precision: 0.767000, valid loss: 191.915041
epoch: 2377, train precision: 0.935756, train loss: 27.655508, valid precision: 0.774600, valid loss: 137.627928
epoch: 2378, train precision: 0.935756, train loss: 29.194438, valid precision: 0.766400, valid loss: 166.414652
epoch: 2379, train precision: 0.923533, train loss: 33.459129, valid precision: 0.773600, valid loss: 149.792310
epoch: 2380, train precision: 0.937822, train loss: 26.618256, valid precision: 0.770400, valid loss: 157.733141
epoch: 2381, train precision: 0.940200, train loss: 25.943085, valid precision: 0.777600, valid loss: 141.253452
epoch: 2382, train precision: 0.937867, train loss: 28.643482, valid precision: 0.768000, valid loss: 156.977811
epoch: 2383, train precision: 0.938467, train loss: 26.832008, valid precision: 0.771800, valid loss: 158.760085
epoch: 2384, train precision: 0.933133, train loss: 28.820352, valid precision: 0.771000, valid loss: 160.897849
epoch: 2385, train precision: 0.919378, train loss: 34.403924, valid precision: 0.761400, valid loss: 149.366590
epoch: 2386, train precision: 0.929400, train loss: 30.039802, valid precision: 0.769400, valid loss: 160.114531
epoch: 2387, train precision: 0.933956, train loss: 29.972593, valid precision: 0.771800, valid loss: 153.441539
epoch: 2388, train precision: 0.247156, train loss: 243.884441, valid precision: 0.251800, valid loss: 245.817894
epoch: 2389, train precision: 0.732400, train loss: 104.136371, valid precision: 0.662000, valid loss: 162.609143
epoch: 2390, train precision: 0.921133, train loss: 34.764350, valid precision: 0.772400, valid loss: 190.221348
epoch: 2391, train precision: 0.943267, train loss: 27.270424, valid precision: 0.779400, valid loss: 178.780083
epoch: 2392, train precision: 0.930356, train loss: 31.054260, valid precision: 0.770600, valid loss: 157.197276
epoch: 2393, train precision: 0.828644, train loss: 74.001822, valid precision: 0.724000, valid loss: 143.549457
epoch: 2394, train precision: 0.913800, train loss: 36.871443, valid precision: 0.766800, valid loss: 136.102404
epoch: 2395, train precision: 0.926867, train loss: 32.882731, valid precision: 0.775000, valid loss: 149.419228
epoch: 2396, train precision: 0.889133, train loss: 46.563209, valid precision: 0.751200, valid loss: 148.843949
epoch: 2397, train precision: 0.936044, train loss: 28.727148, valid precision: 0.770600, valid loss: 150.772179
epoch: 2398, train precision: 0.862467, train loss: 58.769876, valid precision: 0.728200, valid loss: 151.055819
epoch: 2399, train precision: 0.459089, train loss: 225.686902, valid precision: 0.459400, valid loss: 229.966495
epoch: 2400, train precision: 0.941289, train loss: 26.850349, valid precision: 0.784400, valid loss: 176.956906
epoch: 2401, train precision: 0.929022, train loss: 31.063632, valid precision: 0.765400, valid loss: 175.234202
epoch: 2402, train precision: 0.186222, train loss: 326.535984, valid precision: 0.187600, valid loss: 324.395191
epoch: 2403, train precision: 0.777311, train loss: 91.066092, valid precision: 0.691800, valid loss: 145.338702
epoch: 2404, train precision: 0.923444, train loss: 33.640225, valid precision: 0.771000, valid loss: 155.771197
epoch: 2405, train precision: 0.674644, train loss: 142.267284, valid precision: 0.652000, valid loss: 173.991367
epoch: 2406, train precision: 0.915933, train loss: 34.722620, valid precision: 0.759200, valid loss: 212.715343
epoch: 2407, train precision: 0.937844, train loss: 27.166010, valid precision: 0.773200, valid loss: 161.726117
epoch: 2408, train precision: 0.877289, train loss: 52.226902, valid precision: 0.756600, valid loss: 324.653728
epoch: 2409, train precision: 0.926933, train loss: 31.130626, valid precision: 0.767000, valid loss: 147.669005
epoch: 2410, train precision: 0.928356, train loss: 31.293813, valid precision: 0.765800, valid loss: 229.417208
epoch: 2411, train precision: 0.922022, train loss: 33.419557, valid precision: 0.758000, valid loss: 158.832234
epoch: 2412, train precision: 0.936444, train loss: 27.176558, valid precision: 0.772600, valid loss: 150.944240
epoch: 2413, train precision: 0.632133, train loss: 190.592688, valid precision: 0.601200, valid loss: 227.754864
epoch: 2414, train precision: 0.929067, train loss: 30.586403, valid precision: 0.764800, valid loss: 206.360695
epoch: 2415, train precision: 0.934956, train loss: 30.184567, valid precision: 0.767800, valid loss: 193.192757
epoch: 2416, train precision: 0.915933, train loss: 36.020967, valid precision: 0.766600, valid loss: 166.267874
epoch: 2417, train precision: 0.897844, train loss: 42.874873, valid precision: 0.757200, valid loss: 142.122021
epoch: 2418, train precision: 0.925111, train loss: 32.135770, valid precision: 0.768600, valid loss: 166.780410
epoch: 2419, train precision: 0.938156, train loss: 26.783081, valid precision: 0.774400, valid loss: 157.397099
epoch: 2420, train precision: 0.931378, train loss: 30.142151, valid precision: 0.775800, valid loss: 160.417891
epoch: 2421, train precision: 0.939067, train loss: 26.145566, valid precision: 0.778600, valid loss: 165.747923
epoch: 2422, train precision: 0.937844, train loss: 26.782655, valid precision: 0.770600, valid loss: 159.743649
epoch: 2423, train precision: 0.923533, train loss: 33.591318, valid precision: 0.765200, valid loss: 161.143916
epoch: 2424, train precision: 0.924778, train loss: 34.578591, valid precision: 0.759600, valid loss: 174.778539
epoch: 2425, train precision: 0.928600, train loss: 31.038474, valid precision: 0.772000, valid loss: 153.241369
epoch: 2426, train precision: 0.840956, train loss: 69.862997, valid precision: 0.726600, valid loss: 429.589479
epoch: 2427, train precision: 0.936822, train loss: 27.636484, valid precision: 0.773000, valid loss: 161.327495
epoch: 2428, train precision: 0.941267, train loss: 25.624760, valid precision: 0.774400, valid loss: 306.492429
epoch: 2429, train precision: 0.937000, train loss: 27.529750, valid precision: 0.777600, valid loss: 152.490747
epoch: 2430, train precision: 0.904911, train loss: 41.960677, valid precision: 0.751600, valid loss: 155.704034
epoch: 2431, train precision: 0.938133, train loss: 27.226812, valid precision: 0.769000, valid loss: 147.291217
epoch: 2432, train precision: 0.829267, train loss: 76.576530, valid precision: 0.720400, valid loss: 162.279096
epoch: 2433, train precision: 0.932800, train loss: 28.898319, valid precision: 0.773800, valid loss: 168.672982
epoch: 2434, train precision: 0.927244, train loss: 31.702041, valid precision: 0.766600, valid loss: 163.131698
epoch: 2435, train precision: 0.933444, train loss: 31.208839, valid precision: 0.766800, valid loss: 200.225630
epoch: 2436, train precision: 0.939800, train loss: 25.271446, valid precision: 0.780600, valid loss: 151.542574
epoch: 2437, train precision: 0.920644, train loss: 33.508918, valid precision: 0.760000, valid loss: 146.884144
epoch: 2438, train precision: 0.902533, train loss: 39.412629, valid precision: 0.752200, valid loss: 144.803845
epoch: 2439, train precision: 0.948444, train loss: 22.671441, valid precision: 0.785000, valid loss: 154.173961
epoch: 2440, train precision: 0.937644, train loss: 26.819040, valid precision: 0.765200, valid loss: 230.450368
epoch: 2441, train precision: 0.942778, train loss: 24.952825, valid precision: 0.777200, valid loss: 155.097372
epoch: 2442, train precision: 0.906800, train loss: 40.649434, valid precision: 0.756400, valid loss: 161.079152
epoch: 2443, train precision: 0.931800, train loss: 27.849681, valid precision: 0.764800, valid loss: 241.012132
epoch: 2444, train precision: 0.422222, train loss: 188.776116, valid precision: 0.422200, valid loss: 191.178753
epoch: 2445, train precision: 0.798244, train loss: 92.621436, valid precision: 0.714800, valid loss: 162.572958
epoch: 2446, train precision: 0.939689, train loss: 25.341102, valid precision: 0.779000, valid loss: 140.120442
epoch: 2447, train precision: 0.939222, train loss: 25.455231, valid precision: 0.773400, valid loss: 162.496305
epoch: 2448, train precision: 0.892378, train loss: 43.968594, valid precision: 0.757600, valid loss: 132.942645
epoch: 2449, train precision: 0.943133, train loss: 24.950212, valid precision: 0.779200, valid loss: 153.112314
epoch: 2450, train precision: 0.934089, train loss: 28.673651, valid precision: 0.772600, valid loss: 180.453968
epoch: 2451, train precision: 0.919467, train loss: 35.353271, valid precision: 0.765000, valid loss: 159.615696
epoch: 2452, train precision: 0.876578, train loss: 55.446126, valid precision: 0.735800, valid loss: 176.464158
epoch: 2453, train precision: 0.928733, train loss: 30.269555, valid precision: 0.774600, valid loss: 146.652963
epoch: 2454, train precision: 0.936444, train loss: 30.336740, valid precision: 0.767400, valid loss: 260.607557
epoch: 2455, train precision: 0.454044, train loss: 227.290563, valid precision: 0.464000, valid loss: 238.983702
epoch: 2456, train precision: 0.933111, train loss: 29.006298, valid precision: 0.768000, valid loss: 171.161962
epoch: 2457, train precision: 0.935111, train loss: 28.909458, valid precision: 0.775600, valid loss: 205.440118
epoch: 2458, train precision: 0.937844, train loss: 26.619693, valid precision: 0.777800, valid loss: 148.064573
epoch: 2459, train precision: 0.910689, train loss: 39.778088, valid precision: 0.755000, valid loss: 160.240161
epoch: 2460, train precision: 0.941067, train loss: 26.000602, valid precision: 0.772600, valid loss: 157.754034
epoch: 2461, train precision: 0.926978, train loss: 32.843686, valid precision: 0.766000, valid loss: 177.798955
epoch: 2462, train precision: 0.927422, train loss: 30.549899, valid precision: 0.760400, valid loss: 184.469568
epoch: 2463, train precision: 0.291867, train loss: 252.301017, valid precision: 0.302200, valid loss: 254.203613
epoch: 2464, train precision: 0.680867, train loss: 123.545613, valid precision: 0.627000, valid loss: 158.088138
epoch: 2465, train precision: 0.938378, train loss: 26.991770, valid precision: 0.771600, valid loss: 136.026283
epoch: 2466, train precision: 0.931556, train loss: 29.518478, valid precision: 0.768000, valid loss: 137.758958
epoch: 2467, train precision: 0.936600, train loss: 28.204452, valid precision: 0.767600, valid loss: 157.337294
epoch: 2468, train precision: 0.919111, train loss: 35.097531, valid precision: 0.772200, valid loss: 151.173642
epoch: 2469, train precision: 0.939867, train loss: 27.755858, valid precision: 0.772800, valid loss: 163.850227
epoch: 2470, train precision: 0.930356, train loss: 30.053772, valid precision: 0.774000, valid loss: 146.699090
epoch: 2471, train precision: 0.942711, train loss: 25.283068, valid precision: 0.773600, valid loss: 160.126167
epoch: 2472, train precision: 0.926133, train loss: 33.911814, valid precision: 0.763000, valid loss: 180.341327
epoch: 2473, train precision: 0.930622, train loss: 28.557659, valid precision: 0.775000, valid loss: 160.541499
epoch: 2474, train precision: 0.939000, train loss: 26.793268, valid precision: 0.774600, valid loss: 218.204143
epoch: 2475, train precision: 0.938689, train loss: 27.854766, valid precision: 0.774600, valid loss: 152.506417
epoch: 2476, train precision: 0.753200, train loss: 112.641867, valid precision: 0.671600, valid loss: 164.353302
epoch: 2477, train precision: 0.905489, train loss: 41.954054, valid precision: 0.751400, valid loss: 160.086039
epoch: 2478, train precision: 0.939756, train loss: 27.019488, valid precision: 0.775800, valid loss: 161.052493
epoch: 2479, train precision: 0.517178, train loss: 228.352828, valid precision: 0.510200, valid loss: 244.250078
epoch: 2480, train precision: 0.921044, train loss: 34.517591, valid precision: 0.766000, valid loss: 146.586838
epoch: 2481, train precision: 0.921911, train loss: 33.086924, valid precision: 0.759800, valid loss: 149.618443
epoch: 2482, train precision: 0.942978, train loss: 29.624338, valid precision: 0.772600, valid loss: 160.882739
epoch: 2483, train precision: 0.914133, train loss: 36.098570, valid precision: 0.757600, valid loss: 153.611651
epoch: 2484, train precision: 0.951067, train loss: 22.003669, valid precision: 0.775800, valid loss: 160.749752
epoch: 2485, train precision: 0.439133, train loss: 196.455299, valid precision: 0.445200, valid loss: 230.663262
epoch: 2486, train precision: 0.735267, train loss: 106.000005, valid precision: 0.682600, valid loss: 141.592591
epoch: 2487, train precision: 0.901111, train loss: 41.482517, valid precision: 0.767800, valid loss: 128.414273
epoch: 2488, train precision: 0.945667, train loss: 24.412808, valid precision: 0.776600, valid loss: 145.717469
epoch: 2489, train precision: 0.940644, train loss: 28.344782, valid precision: 0.763400, valid loss: 168.675755
epoch: 2490, train precision: 0.951667, train loss: 21.804154, valid precision: 0.782800, valid loss: 141.227569
epoch: 2491, train precision: 0.848067, train loss: 63.535491, valid precision: 0.724800, valid loss: 145.778410
epoch: 2492, train precision: 0.925022, train loss: 33.142785, valid precision: 0.768200, valid loss: 180.038600
epoch: 2493, train precision: 0.948956, train loss: 23.064212, valid precision: 0.780400, valid loss: 205.758073
epoch: 2494, train precision: 0.426956, train loss: 255.212878, valid precision: 0.424200, valid loss: 263.368797
epoch: 2495, train precision: 0.909089, train loss: 38.162468, valid precision: 0.761600, valid loss: 242.240943
epoch: 2496, train precision: 0.939289, train loss: 28.953059, valid precision: 0.765800, valid loss: 254.205270
epoch: 2497, train precision: 0.944711, train loss: 23.145062, valid precision: 0.774600, valid loss: 146.972866
epoch: 2498, train precision: 0.947489, train loss: 22.194345, valid precision: 0.775400, valid loss: 156.305545
epoch: 2499, train precision: 0.941289, train loss: 26.792836, valid precision: 0.767400, valid loss: 170.954975
epoch: 2500, train precision: 0.929956, train loss: 30.137424, valid precision: 0.770600, valid loss: 145.688248
epoch: 2501, train precision: 0.950200, train loss: 23.570236, valid precision: 0.780000, valid loss: 164.750073
epoch: 2502, train precision: 0.887889, train loss: 51.150957, valid precision: 0.742600, valid loss: 161.993034
epoch: 2503, train precision: 0.926644, train loss: 34.195787, valid precision: 0.764200, valid loss: 182.585113
epoch: 2504, train precision: 0.934800, train loss: 28.120443, valid precision: 0.763600, valid loss: 150.821752
epoch: 2505, train precision: 0.939222, train loss: 27.271134, valid precision: 0.777600, valid loss: 167.061278
epoch: 2506, train precision: 0.798422, train loss: 86.150156, valid precision: 0.708600, valid loss: 144.476924
epoch: 2507, train precision: 0.938822, train loss: 25.508141, valid precision: 0.781600, valid loss: 142.018667
epoch: 2508, train precision: 0.942667, train loss: 23.670824, valid precision: 0.777000, valid loss: 157.345715
epoch: 2509, train precision: 0.690200, train loss: 148.870905, valid precision: 0.628800, valid loss: 204.914213
epoch: 2510, train precision: 0.942978, train loss: 24.758214, valid precision: 0.768200, valid loss: 151.481896
epoch: 2511, train precision: 0.945444, train loss: 22.821305, valid precision: 0.774600, valid loss: 144.431469
epoch: 2512, train precision: 0.929378, train loss: 30.786295, valid precision: 0.763000, valid loss: 168.651587
epoch: 2513, train precision: 0.944644, train loss: 27.537700, valid precision: 0.773600, valid loss: 165.580501
epoch: 2514, train precision: 0.925933, train loss: 31.666922, valid precision: 0.765800, valid loss: 151.042487
epoch: 2515, train precision: 0.887889, train loss: 47.582523, valid precision: 0.761600, valid loss: 153.939850
epoch: 2516, train precision: 0.399422, train loss: 268.955120, valid precision: 0.403600, valid loss: 271.315151
epoch: 2517, train precision: 0.910867, train loss: 39.460582, valid precision: 0.752800, valid loss: 151.017597
epoch: 2518, train precision: 0.942333, train loss: 27.012966, valid precision: 0.776800, valid loss: 158.620585
epoch: 2519, train precision: 0.938644, train loss: 27.591420, valid precision: 0.765600, valid loss: 160.863171
epoch: 2520, train precision: 0.780511, train loss: 102.463682, valid precision: 0.702200, valid loss: 181.947153
epoch: 2521, train precision: 0.945867, train loss: 23.238302, valid precision: 0.774400, valid loss: 141.056184
epoch: 2522, train precision: 0.944711, train loss: 25.330216, valid precision: 0.770400, valid loss: 158.064268
epoch: 2523, train precision: 0.942644, train loss: 25.248153, valid precision: 0.771400, valid loss: 163.660092
epoch: 2524, train precision: 0.939467, train loss: 26.292340, valid precision: 0.769800, valid loss: 153.618502
epoch: 2525, train precision: 0.931244, train loss: 29.272843, valid precision: 0.766200, valid loss: 146.783933
epoch: 2526, train precision: 0.924933, train loss: 35.480676, valid precision: 0.757200, valid loss: 199.304835
epoch: 2527, train precision: 0.911156, train loss: 37.306674, valid precision: 0.762000, valid loss: 148.258617
epoch: 2528, train precision: 0.945867, train loss: 23.755572, valid precision: 0.776000, valid loss: 155.886597
epoch: 2529, train precision: 0.601756, train loss: 186.012481, valid precision: 0.571400, valid loss: 359.885050
epoch: 2530, train precision: 0.941978, train loss: 27.267217, valid precision: 0.775600, valid loss: 167.203020
epoch: 2531, train precision: 0.935867, train loss: 28.486712, valid precision: 0.762600, valid loss: 164.741787
epoch: 2532, train precision: 0.942267, train loss: 24.955673, valid precision: 0.775000, valid loss: 153.247271
epoch: 2533, train precision: 0.937378, train loss: 27.801080, valid precision: 0.771200, valid loss: 160.301563
epoch: 2534, train precision: 0.922222, train loss: 36.588595, valid precision: 0.758600, valid loss: 167.721284
epoch: 2535, train precision: 0.932422, train loss: 29.827991, valid precision: 0.766200, valid loss: 163.740368
epoch: 2536, train precision: 0.929356, train loss: 30.236171, valid precision: 0.772000, valid loss: 153.676888
epoch: 2537, train precision: 0.937044, train loss: 28.468321, valid precision: 0.765000, valid loss: 180.463451
epoch: 2538, train precision: 0.919578, train loss: 36.544046, valid precision: 0.755800, valid loss: 171.999684
epoch: 2539, train precision: 0.938911, train loss: 27.062055, valid precision: 0.767400, valid loss: 230.719715
epoch: 2540, train precision: 0.337911, train loss: 249.320668, valid precision: 0.340400, valid loss: 255.289142
epoch: 2541, train precision: 0.934622, train loss: 28.012288, valid precision: 0.772400, valid loss: 144.532262
epoch: 2542, train precision: 0.935000, train loss: 27.637902, valid precision: 0.770000, valid loss: 183.302892
epoch: 2543, train precision: 0.927356, train loss: 30.707040, valid precision: 0.767000, valid loss: 156.919173
epoch: 2544, train precision: 0.927578, train loss: 33.069646, valid precision: 0.761600, valid loss: 170.770662
epoch: 2545, train precision: 0.950533, train loss: 22.618349, valid precision: 0.770600, valid loss: 166.535662
epoch: 2546, train precision: 0.940956, train loss: 24.662649, valid precision: 0.771400, valid loss: 156.976611
epoch: 2547, train precision: 0.945933, train loss: 24.860994, valid precision: 0.776400, valid loss: 156.138457
epoch: 2548, train precision: 0.940133, train loss: 25.631578, valid precision: 0.772400, valid loss: 162.289181
epoch: 2549, train precision: 0.948733, train loss: 22.722174, valid precision: 0.775800, valid loss: 175.451972
epoch: 2550, train precision: 0.928200, train loss: 31.161449, valid precision: 0.771800, valid loss: 158.089285
epoch: 2551, train precision: 0.949956, train loss: 22.423630, valid precision: 0.773600, valid loss: 184.884940
epoch: 2552, train precision: 0.917756, train loss: 40.593291, valid precision: 0.762600, valid loss: 157.612993
epoch: 2553, train precision: 0.487933, train loss: 228.005285, valid precision: 0.477200, valid loss: 239.316046
epoch: 2554, train precision: 0.916022, train loss: 37.395953, valid precision: 0.761200, valid loss: 173.540405
epoch: 2555, train precision: 0.936578, train loss: 27.744477, valid precision: 0.769000, valid loss: 154.591644
epoch: 2556, train precision: 0.950622, train loss: 21.863025, valid precision: 0.775600, valid loss: 172.702590
epoch: 2557, train precision: 0.922622, train loss: 36.656638, valid precision: 0.759200, valid loss: 164.953519
epoch: 2558, train precision: 0.866689, train loss: 55.164359, valid precision: 0.736600, valid loss: 157.978254
epoch: 2559, train precision: 0.948044, train loss: 23.245894, valid precision: 0.778200, valid loss: 153.760273
epoch: 2560, train precision: 0.930022, train loss: 38.462336, valid precision: 0.770800, valid loss: 157.739938
epoch: 2561, train precision: 0.936044, train loss: 40.778471, valid precision: 0.772200, valid loss: 152.314793
epoch: 2562, train precision: 0.178111, train loss: 340.850384, valid precision: 0.181400, valid loss: 354.974952
epoch: 2563, train precision: 0.199089, train loss: 262.611164, valid precision: 0.202400, valid loss: 276.016641
epoch: 2564, train precision: 0.214378, train loss: 250.260336, valid precision: 0.225000, valid loss: 253.974445
epoch: 2565, train precision: 0.273911, train loss: 232.527533, valid precision: 0.282200, valid loss: 251.335395
epoch: 2566, train precision: 0.525289, train loss: 181.485411, valid precision: 0.518200, valid loss: 238.110224
epoch: 2567, train precision: 0.880289, train loss: 59.177599, valid precision: 0.738800, valid loss: 211.933693
epoch: 2568, train precision: 0.843489, train loss: 70.396877, valid precision: 0.745000, valid loss: 171.128706
epoch: 2569, train precision: 0.905156, train loss: 43.370257, valid precision: 0.760800, valid loss: 167.794362
epoch: 2570, train precision: 0.902578, train loss: 46.077728, valid precision: 0.762600, valid loss: 152.075591
epoch: 2571, train precision: 0.892600, train loss: 47.047707, valid precision: 0.759000, valid loss: 147.143468
epoch: 2572, train precision: 0.942978, train loss: 26.613314, valid precision: 0.780200, valid loss: 143.056386
epoch: 2573, train precision: 0.932178, train loss: 31.177290, valid precision: 0.774000, valid loss: 150.413180
epoch: 2574, train precision: 0.921489, train loss: 35.593943, valid precision: 0.770000, valid loss: 146.606052
epoch: 2575, train precision: 0.941556, train loss: 26.279783, valid precision: 0.781400, valid loss: 147.569857
epoch: 2576, train precision: 0.711711, train loss: 143.786028, valid precision: 0.650800, valid loss: 202.843006
epoch: 2577, train precision: 0.937689, train loss: 28.007404, valid precision: 0.768600, valid loss: 152.948683
epoch: 2578, train precision: 0.698956, train loss: 139.959582, valid precision: 0.666800, valid loss: 177.145002
epoch: 2579, train precision: 0.924244, train loss: 38.879715, valid precision: 0.765600, valid loss: 174.539658
epoch: 2580, train precision: 0.925556, train loss: 32.988842, valid precision: 0.773400, valid loss: 151.153030
epoch: 2581, train precision: 0.935000, train loss: 29.152907, valid precision: 0.777800, valid loss: 149.174967
epoch: 2582, train precision: 0.908578, train loss: 39.736987, valid precision: 0.772200, valid loss: 153.763809
epoch: 2583, train precision: 0.938089, train loss: 27.390288, valid precision: 0.778400, valid loss: 149.423767
epoch: 2584, train precision: 0.922178, train loss: 38.303088, valid precision: 0.759400, valid loss: 161.426607
epoch: 2585, train precision: 0.937044, train loss: 27.407146, valid precision: 0.775200, valid loss: 154.291989
epoch: 2586, train precision: 0.935667, train loss: 28.362065, valid precision: 0.773200, valid loss: 162.974566
epoch: 2587, train precision: 0.258178, train loss: 265.494518, valid precision: 0.261400, valid loss: 263.828216
epoch: 2588, train precision: 0.637667, train loss: 138.198716, valid precision: 0.601800, valid loss: 168.620861
epoch: 2589, train precision: 0.933422, train loss: 29.189099, valid precision: 0.766600, valid loss: 133.218846
epoch: 2590, train precision: 0.927111, train loss: 33.620369, valid precision: 0.756800, valid loss: 166.690025
epoch: 2591, train precision: 0.947067, train loss: 24.384325, valid precision: 0.776400, valid loss: 161.147498
epoch: 2592, train precision: 0.914111, train loss: 37.444978, valid precision: 0.770800, valid loss: 150.995398
epoch: 2593, train precision: 0.900200, train loss: 41.448429, valid precision: 0.751800, valid loss: 146.023145
epoch: 2594, train precision: 0.773067, train loss: 96.734071, valid precision: 0.701000, valid loss: 143.069767
epoch: 2595, train precision: 0.889244, train loss: 47.114883, valid precision: 0.754400, valid loss: 183.582818
epoch: 2596, train precision: 0.249911, train loss: 440.824328, valid precision: 0.264000, valid loss: 380.924372
epoch: 2597, train precision: 0.183044, train loss: 267.995834, valid precision: 0.185600, valid loss: 266.668480
epoch: 2598, train precision: 0.259378, train loss: 246.119566, valid precision: 0.258200, valid loss: 242.145293
epoch: 2599, train precision: 0.269289, train loss: 240.618405, valid precision: 0.286000, valid loss: 234.771544
epoch: 2600, train precision: 0.402911, train loss: 203.309197, valid precision: 0.402800, valid loss: 203.799777
epoch: 2601, train precision: 0.502067, train loss: 172.415202, valid precision: 0.496000, valid loss: 173.541182
epoch: 2602, train precision: 0.382022, train loss: 207.401559, valid precision: 0.390000, valid loss: 204.381529
epoch: 2603, train precision: 0.556400, train loss: 156.827328, valid precision: 0.558200, valid loss: 158.884333
epoch: 2604, train precision: 0.342711, train loss: 249.849527, valid precision: 0.350600, valid loss: 246.705798
epoch: 2605, train precision: 0.803400, train loss: 81.867549, valid precision: 0.716400, valid loss: 139.082713
epoch: 2606, train precision: 0.885111, train loss: 51.337436, valid precision: 0.750200, valid loss: 130.939874
epoch: 2607, train precision: 0.903978, train loss: 41.327853, valid precision: 0.760600, valid loss: 135.358059
epoch: 2608, train precision: 0.918267, train loss: 36.617290, valid precision: 0.765400, valid loss: 136.056915
epoch: 2609, train precision: 0.928533, train loss: 34.321306, valid precision: 0.771400, valid loss: 139.749727
epoch: 2610, train precision: 0.371489, train loss: 252.224806, valid precision: 0.384000, valid loss: 247.913973
epoch: 2611, train precision: 0.920067, train loss: 36.495457, valid precision: 0.767400, valid loss: 142.586308
epoch: 2612, train precision: 0.920089, train loss: 37.397787, valid precision: 0.762200, valid loss: 161.362071
epoch: 2613, train precision: 0.916667, train loss: 35.335079, valid precision: 0.774000, valid loss: 149.431019
epoch: 2614, train precision: 0.928022, train loss: 32.230686, valid precision: 0.760400, valid loss: 156.541002
epoch: 2615, train precision: 0.935489, train loss: 42.209650, valid precision: 0.775200, valid loss: 160.093424
epoch: 2616, train precision: 0.912644, train loss: 39.994215, valid precision: 0.757600, valid loss: 178.884459
epoch: 2617, train precision: 0.927311, train loss: 34.418788, valid precision: 0.752400, valid loss: 177.703788
epoch: 2618, train precision: 0.695044, train loss: 128.887269, valid precision: 0.648800, valid loss: 164.587507
epoch: 2619, train precision: 0.934889, train loss: 28.166798, valid precision: 0.779200, valid loss: 150.349048
epoch: 2620, train precision: 0.943356, train loss: 25.343031, valid precision: 0.771000, valid loss: 149.097482
epoch: 2621, train precision: 0.939000, train loss: 27.257783, valid precision: 0.770000, valid loss: 157.626150
epoch: 2622, train precision: 0.861267, train loss: 59.893853, valid precision: 0.739600, valid loss: 147.589067
epoch: 2623, train precision: 0.933178, train loss: 31.641293, valid precision: 0.765000, valid loss: 167.434373
epoch: 2624, train precision: 0.930978, train loss: 31.993334, valid precision: 0.764600, valid loss: 175.661066
epoch: 2625, train precision: 0.937244, train loss: 28.533959, valid precision: 0.778600, valid loss: 151.167427
epoch: 2626, train precision: 0.936578, train loss: 28.621214, valid precision: 0.768800, valid loss: 147.616447
epoch: 2627, train precision: 0.930022, train loss: 30.575570, valid precision: 0.769800, valid loss: 161.340230
epoch: 2628, train precision: 0.946267, train loss: 23.765705, valid precision: 0.778200, valid loss: 160.799393
epoch: 2629, train precision: 0.928289, train loss: 31.179050, valid precision: 0.773600, valid loss: 151.496708
epoch: 2630, train precision: 0.930533, train loss: 30.711676, valid precision: 0.764200, valid loss: 165.988067
epoch: 2631, train precision: 0.923689, train loss: 34.203832, valid precision: 0.772400, valid loss: 150.685321
epoch: 2632, train precision: 0.939178, train loss: 27.971610, valid precision: 0.777000, valid loss: 183.757405
epoch: 2633, train precision: 0.150467, train loss: 345.602650, valid precision: 0.153600, valid loss: 338.445384
epoch: 2634, train precision: 0.259667, train loss: 245.182240, valid precision: 0.268800, valid loss: 244.298261
epoch: 2635, train precision: 0.418178, train loss: 198.817355, valid precision: 0.420400, valid loss: 208.491883
epoch: 2636, train precision: 0.888867, train loss: 48.136690, valid precision: 0.744600, valid loss: 164.089897
epoch: 2637, train precision: 0.939000, train loss: 27.230868, valid precision: 0.777000, valid loss: 145.268016
epoch: 2638, train precision: 0.603267, train loss: 159.824433, valid precision: 0.583000, valid loss: 174.162222
epoch: 2639, train precision: 0.934667, train loss: 28.999738, valid precision: 0.773600, valid loss: 136.783929
epoch: 2640, train precision: 0.937111, train loss: 27.831888, valid precision: 0.769600, valid loss: 145.411934
epoch: 2641, train precision: 0.948289, train loss: 23.174474, valid precision: 0.776400, valid loss: 160.702959
epoch: 2642, train precision: 0.927467, train loss: 32.491562, valid precision: 0.769600, valid loss: 148.285599
epoch: 2643, train precision: 0.931756, train loss: 29.256902, valid precision: 0.766400, valid loss: 150.674782
epoch: 2644, train precision: 0.940844, train loss: 26.047363, valid precision: 0.776200, valid loss: 172.476028
epoch: 2645, train precision: 0.938067, train loss: 27.221834, valid precision: 0.769600, valid loss: 157.844112
epoch: 2646, train precision: 0.935422, train loss: 28.941560, valid precision: 0.775800, valid loss: 159.584031
epoch: 2647, train precision: 0.894022, train loss: 46.914745, valid precision: 0.759200, valid loss: 153.141393
epoch: 2648, train precision: 0.832933, train loss: 71.098329, valid precision: 0.719400, valid loss: 140.013764
epoch: 2649, train precision: 0.930867, train loss: 30.784396, valid precision: 0.772200, valid loss: 194.424870
epoch: 2650, train precision: 0.908844, train loss: 42.414809, valid precision: 0.767800, valid loss: 153.166409
epoch: 2651, train precision: 0.921267, train loss: 35.125255, valid precision: 0.757000, valid loss: 159.936143
epoch: 2652, train precision: 0.951644, train loss: 21.747735, valid precision: 0.775600, valid loss: 155.005830
epoch: 2653, train precision: 0.865044, train loss: 62.435586, valid precision: 0.755200, valid loss: 153.505557
epoch: 2654, train precision: 0.931444, train loss: 31.485461, valid precision: 0.766600, valid loss: 165.083021
epoch: 2655, train precision: 0.946444, train loss: 24.309321, valid precision: 0.774600, valid loss: 157.918787
epoch: 2656, train precision: 0.936844, train loss: 28.119227, valid precision: 0.774400, valid loss: 160.099552
epoch: 2657, train precision: 0.947000, train loss: 25.079481, valid precision: 0.781400, valid loss: 153.279275
epoch: 2658, train precision: 0.884267, train loss: 47.507764, valid precision: 0.750000, valid loss: 143.251308
epoch: 2659, train precision: 0.929533, train loss: 31.635840, valid precision: 0.776800, valid loss: 211.674759
epoch: 2660, train precision: 0.939622, train loss: 27.009152, valid precision: 0.781800, valid loss: 158.858745
epoch: 2661, train precision: 0.941067, train loss: 26.346684, valid precision: 0.779400, valid loss: 176.342004
epoch: 2662, train precision: 0.932044, train loss: 29.513662, valid precision: 0.770800, valid loss: 155.046208
epoch: 2663, train precision: 0.944844, train loss: 26.143516, valid precision: 0.781800, valid loss: 176.721640
epoch: 2664, train precision: 0.926622, train loss: 31.734827, valid precision: 0.766400, valid loss: 219.829511
epoch: 2665, train precision: 0.576533, train loss: 188.243641, valid precision: 0.534400, valid loss: 222.252283
epoch: 2666, train precision: 0.939333, train loss: 27.022847, valid precision: 0.778800, valid loss: 157.215699
epoch: 2667, train precision: 0.944378, train loss: 29.003705, valid precision: 0.769000, valid loss: 363.191835
epoch: 2668, train precision: 0.938689, train loss: 26.845336, valid precision: 0.771800, valid loss: 230.666630
epoch: 2669, train precision: 0.815667, train loss: 85.284025, valid precision: 0.703200, valid loss: 168.968218
epoch: 2670, train precision: 0.901222, train loss: 42.504101, valid precision: 0.753400, valid loss: 144.426456
epoch: 2671, train precision: 0.935422, train loss: 30.342012, valid precision: 0.775800, valid loss: 146.626739
epoch: 2672, train precision: 0.912378, train loss: 38.316479, valid precision: 0.760000, valid loss: 156.918739
epoch: 2673, train precision: 0.942444, train loss: 24.955045, valid precision: 0.775800, valid loss: 158.420325
epoch: 2674, train precision: 0.754800, train loss: 112.331111, valid precision: 0.678200, valid loss: 175.224265
epoch: 2675, train precision: 0.947067, train loss: 23.190682, valid precision: 0.776800, valid loss: 152.836341
epoch: 2676, train precision: 0.943556, train loss: 24.325326, valid precision: 0.775800, valid loss: 148.132969
epoch: 2677, train precision: 0.940622, train loss: 25.906135, valid precision: 0.770600, valid loss: 179.844519
epoch: 2678, train precision: 0.381222, train loss: 261.811664, valid precision: 0.386800, valid loss: 262.335442
epoch: 2679, train precision: 0.930089, train loss: 29.524202, valid precision: 0.768400, valid loss: 151.862765
epoch: 2680, train precision: 0.931622, train loss: 29.588863, valid precision: 0.774400, valid loss: 180.372705
epoch: 2681, train precision: 0.943178, train loss: 26.143655, valid precision: 0.777800, valid loss: 210.854767
epoch: 2682, train precision: 0.931511, train loss: 32.019553, valid precision: 0.768000, valid loss: 258.808702
epoch: 2683, train precision: 0.934667, train loss: 30.458173, valid precision: 0.771800, valid loss: 223.388264
epoch: 2684, train precision: 0.757711, train loss: 104.910621, valid precision: 0.679600, valid loss: 167.355965
epoch: 2685, train precision: 0.920467, train loss: 34.490733, valid precision: 0.765400, valid loss: 157.232098
epoch: 2686, train precision: 0.944911, train loss: 23.656156, valid precision: 0.778600, valid loss: 168.812439
epoch: 2687, train precision: 0.645667, train loss: 170.343645, valid precision: 0.602000, valid loss: 216.160569
epoch: 2688, train precision: 0.944089, train loss: 24.790999, valid precision: 0.775000, valid loss: 159.999791
epoch: 2689, train precision: 0.922311, train loss: 32.975029, valid precision: 0.761600, valid loss: 153.938091
epoch: 2690, train precision: 0.946867, train loss: 22.540299, valid precision: 0.772200, valid loss: 155.653753
epoch: 2691, train precision: 0.938400, train loss: 26.553179, valid precision: 0.764400, valid loss: 162.953055
epoch: 2692, train precision: 0.253178, train loss: 260.222328, valid precision: 0.266600, valid loss: 259.568933
epoch: 2693, train precision: 0.917556, train loss: 39.887220, valid precision: 0.761200, valid loss: 178.672576
epoch: 2694, train precision: 0.949600, train loss: 22.532185, valid precision: 0.770600, valid loss: 160.202649
epoch: 2695, train precision: 0.940822, train loss: 28.486164, valid precision: 0.776400, valid loss: 175.401651
epoch: 2696, train precision: 0.930644, train loss: 31.711792, valid precision: 0.764000, valid loss: 191.174120
epoch: 2697, train precision: 0.945933, train loss: 26.598140, valid precision: 0.777600, valid loss: 162.236557
epoch: 2698, train precision: 0.924978, train loss: 34.675072, valid precision: 0.766200, valid loss: 169.474632
epoch: 2699, train precision: 0.937911, train loss: 30.167090, valid precision: 0.776800, valid loss: 154.886195
epoch: 2700, train precision: 0.953356, train loss: 21.492334, valid precision: 0.776000, valid loss: 167.242260
epoch: 2701, train precision: 0.868600, train loss: 67.618147, valid precision: 0.743600, valid loss: 165.631711
epoch: 2702, train precision: 0.919933, train loss: 36.188708, valid precision: 0.760000, valid loss: 162.419875
epoch: 2703, train precision: 0.928756, train loss: 30.852296, valid precision: 0.768600, valid loss: 169.623320
epoch: 2704, train precision: 0.943022, train loss: 26.048437, valid precision: 0.776400, valid loss: 168.202802
epoch: 2705, train precision: 0.926089, train loss: 33.263834, valid precision: 0.758000, valid loss: 158.694699
epoch: 2706, train precision: 0.249400, train loss: 273.096225, valid precision: 0.258200, valid loss: 274.129808
epoch: 2707, train precision: 0.916756, train loss: 36.574941, valid precision: 0.772200, valid loss: 136.054403
epoch: 2708, train precision: 0.936600, train loss: 28.190531, valid precision: 0.773200, valid loss: 151.626416
epoch: 2709, train precision: 0.942756, train loss: 26.738755, valid precision: 0.771800, valid loss: 165.959421
epoch: 2710, train precision: 0.940622, train loss: 26.992357, valid precision: 0.771200, valid loss: 172.159629
epoch: 2711, train precision: 0.928911, train loss: 34.944876, valid precision: 0.765400, valid loss: 189.544263
epoch: 2712, train precision: 0.934267, train loss: 28.700391, valid precision: 0.773400, valid loss: 156.046205
epoch: 2713, train precision: 0.939533, train loss: 27.245529, valid precision: 0.770000, valid loss: 175.377884
epoch: 2714, train precision: 0.949244, train loss: 23.370849, valid precision: 0.780600, valid loss: 161.742988
epoch: 2715, train precision: 0.911333, train loss: 38.585005, valid precision: 0.761400, valid loss: 157.018433
epoch: 2716, train precision: 0.947267, train loss: 23.624497, valid precision: 0.778200, valid loss: 171.025153
epoch: 2717, train precision: 0.604356, train loss: 169.769001, valid precision: 0.574400, valid loss: 197.548557
epoch: 2718, train precision: 0.927311, train loss: 32.689960, valid precision: 0.759800, valid loss: 159.988537
epoch: 2719, train precision: 0.930044, train loss: 31.364471, valid precision: 0.759000, valid loss: 174.119508
epoch: 2720, train precision: 0.939644, train loss: 27.023069, valid precision: 0.766000, valid loss: 162.218241
epoch: 2721, train precision: 0.739178, train loss: 117.542195, valid precision: 0.668000, valid loss: 198.272596
epoch: 2722, train precision: 0.945244, train loss: 25.908652, valid precision: 0.777400, valid loss: 158.302681
epoch: 2723, train precision: 0.936956, train loss: 27.587709, valid precision: 0.772200, valid loss: 159.256776
epoch: 2724, train precision: 0.940467, train loss: 31.861273, valid precision: 0.777200, valid loss: 155.162484
epoch: 2725, train precision: 0.933022, train loss: 31.607500, valid precision: 0.771400, valid loss: 154.997926
epoch: 2726, train precision: 0.913133, train loss: 36.946064, valid precision: 0.760800, valid loss: 151.155933
epoch: 2727, train precision: 0.942200, train loss: 26.076542, valid precision: 0.770800, valid loss: 157.302984
epoch: 2728, train precision: 0.763178, train loss: 109.930161, valid precision: 0.682400, valid loss: 184.829386
epoch: 2729, train precision: 0.947578, train loss: 24.238114, valid precision: 0.783800, valid loss: 174.406201
epoch: 2730, train precision: 0.942667, train loss: 25.110037, valid precision: 0.774000, valid loss: 155.874071
epoch: 2731, train precision: 0.946378, train loss: 23.510246, valid precision: 0.782800, valid loss: 152.573694
epoch: 2732, train precision: 0.893111, train loss: 48.368576, valid precision: 0.755600, valid loss: 151.878957
epoch: 2733, train precision: 0.936178, train loss: 28.168605, valid precision: 0.772800, valid loss: 171.449862
epoch: 2734, train precision: 0.300133, train loss: 256.333548, valid precision: 0.295600, valid loss: 260.687859
epoch: 2735, train precision: 0.926867, train loss: 31.576277, valid precision: 0.775400, valid loss: 136.741613
epoch: 2736, train precision: 0.922067, train loss: 35.960556, valid precision: 0.761800, valid loss: 164.990955
epoch: 2737, train precision: 0.944978, train loss: 24.641448, valid precision: 0.773800, valid loss: 155.447194
epoch: 2738, train precision: 0.944711, train loss: 25.448713, valid precision: 0.775800, valid loss: 161.970522
epoch: 2739, train precision: 0.905711, train loss: 43.828037, valid precision: 0.760200, valid loss: 171.460356
epoch: 2740, train precision: 0.924311, train loss: 32.575652, valid precision: 0.768400, valid loss: 156.582643
epoch: 2741, train precision: 0.941644, train loss: 33.170231, valid precision: 0.771200, valid loss: 156.395812
epoch: 2742, train precision: 0.948956, train loss: 24.574759, valid precision: 0.783400, valid loss: 164.697869
epoch: 2743, train precision: 0.947533, train loss: 23.698951, valid precision: 0.775600, valid loss: 179.357458
epoch: 2744, train precision: 0.710600, train loss: 144.762568, valid precision: 0.665800, valid loss: 193.287738
epoch: 2745, train precision: 0.920200, train loss: 35.986769, valid precision: 0.767000, valid loss: 157.737865
epoch: 2746, train precision: 0.518822, train loss: 252.679700, valid precision: 0.506800, valid loss: 281.296008
epoch: 2747, train precision: 0.921444, train loss: 34.541901, valid precision: 0.769200, valid loss: 150.742963
epoch: 2748, train precision: 0.931422, train loss: 30.121774, valid precision: 0.772600, valid loss: 164.002904
epoch: 2749, train precision: 0.523822, train loss: 205.558360, valid precision: 0.526600, valid loss: 217.473287
epoch: 2750, train precision: 0.920400, train loss: 35.501508, valid precision: 0.756000, valid loss: 158.821127
epoch: 2751, train precision: 0.926578, train loss: 33.287571, valid precision: 0.773800, valid loss: 171.455587
epoch: 2752, train precision: 0.925556, train loss: 33.564290, valid precision: 0.766000, valid loss: 167.762307
epoch: 2753, train precision: 0.819556, train loss: 85.397813, valid precision: 0.725200, valid loss: 177.490058
epoch: 2754, train precision: 0.745867, train loss: 129.548034, valid precision: 0.674800, valid loss: 205.867637
epoch: 2755, train precision: 0.945578, train loss: 24.305110, valid precision: 0.780800, valid loss: 180.696822
epoch: 2756, train precision: 0.951444, train loss: 22.659568, valid precision: 0.781000, valid loss: 185.561557
epoch: 2757, train precision: 0.943467, train loss: 24.484840, valid precision: 0.780800, valid loss: 143.344378
epoch: 2758, train precision: 0.936067, train loss: 27.837482, valid precision: 0.780200, valid loss: 152.804856
epoch: 2759, train precision: 0.939533, train loss: 26.731005, valid precision: 0.776800, valid loss: 151.723417
epoch: 2760, train precision: 0.722733, train loss: 124.421775, valid precision: 0.669200, valid loss: 169.388577
epoch: 2761, train precision: 0.937889, train loss: 26.999704, valid precision: 0.785400, valid loss: 147.488970
epoch: 2762, train precision: 0.944911, train loss: 25.118952, valid precision: 0.781800, valid loss: 165.559924
epoch: 2763, train precision: 0.934089, train loss: 29.901818, valid precision: 0.775000, valid loss: 158.280449
epoch: 2764, train precision: 0.535667, train loss: 197.932084, valid precision: 0.527400, valid loss: 213.405065
epoch: 2765, train precision: 0.942489, train loss: 25.321033, valid precision: 0.775000, valid loss: 147.227346
epoch: 2766, train precision: 0.938489, train loss: 29.418992, valid precision: 0.772400, valid loss: 220.192682
epoch: 2767, train precision: 0.899822, train loss: 42.662244, valid precision: 0.753200, valid loss: 166.432858
epoch: 2768, train precision: 0.908467, train loss: 42.613005, valid precision: 0.755600, valid loss: 164.207893
epoch: 2769, train precision: 0.947444, train loss: 24.014272, valid precision: 0.772000, valid loss: 166.875824
epoch: 2770, train precision: 0.951422, train loss: 20.765054, valid precision: 0.777400, valid loss: 148.663827
epoch: 2771, train precision: 0.937667, train loss: 26.393010, valid precision: 0.763600, valid loss: 146.358504
epoch: 2772, train precision: 0.930844, train loss: 29.599799, valid precision: 0.768800, valid loss: 162.539728
epoch: 2773, train precision: 0.941222, train loss: 26.803672, valid precision: 0.774200, valid loss: 167.316373
epoch: 2774, train precision: 0.950600, train loss: 22.438160, valid precision: 0.770400, valid loss: 163.362079
epoch: 2775, train precision: 0.907111, train loss: 39.779457, valid precision: 0.760800, valid loss: 146.436894
epoch: 2776, train precision: 0.945356, train loss: 24.966002, valid precision: 0.779000, valid loss: 147.498476
epoch: 2777, train precision: 0.920644, train loss: 34.879744, valid precision: 0.767800, valid loss: 160.860156
epoch: 2778, train precision: 0.841689, train loss: 70.932231, valid precision: 0.734200, valid loss: 155.242587
epoch: 2779, train precision: 0.943022, train loss: 25.601660, valid precision: 0.781400, valid loss: 151.591148
epoch: 2780, train precision: 0.945911, train loss: 24.793590, valid precision: 0.777600, valid loss: 152.751649
epoch: 2781, train precision: 0.942578, train loss: 27.457186, valid precision: 0.777400, valid loss: 148.837367
epoch: 2782, train precision: 0.947267, train loss: 23.965382, valid precision: 0.772600, valid loss: 169.813034
epoch: 2783, train precision: 0.943400, train loss: 25.248402, valid precision: 0.767000, valid loss: 169.589773
epoch: 2784, train precision: 0.939156, train loss: 28.567607, valid precision: 0.759800, valid loss: 191.188098
epoch: 2785, train precision: 0.922822, train loss: 34.295240, valid precision: 0.762200, valid loss: 159.146928
epoch: 2786, train precision: 0.942022, train loss: 24.700996, valid precision: 0.779400, valid loss: 148.058635
epoch: 2787, train precision: 0.936333, train loss: 29.222547, valid precision: 0.769000, valid loss: 175.206404
epoch: 2788, train precision: 0.931511, train loss: 29.824955, valid precision: 0.767400, valid loss: 161.478759
epoch: 2789, train precision: 0.951000, train loss: 24.632111, valid precision: 0.771400, valid loss: 228.097004
epoch: 2790, train precision: 0.939111, train loss: 27.538838, valid precision: 0.766000, valid loss: 155.033725
epoch: 2791, train precision: 0.810333, train loss: 89.478203, valid precision: 0.720800, valid loss: 165.689307
epoch: 2792, train precision: 0.921622, train loss: 33.619433, valid precision: 0.771200, valid loss: 138.006620
epoch: 2793, train precision: 0.947911, train loss: 23.280873, valid precision: 0.776600, valid loss: 151.682992
epoch: 2794, train precision: 0.920489, train loss: 35.728516, valid precision: 0.762800, valid loss: 165.840015
epoch: 2795, train precision: 0.943333, train loss: 25.575456, valid precision: 0.765800, valid loss: 166.931141
epoch: 2796, train precision: 0.926778, train loss: 34.474201, valid precision: 0.768600, valid loss: 187.343102
epoch: 2797, train precision: 0.948156, train loss: 23.887367, valid precision: 0.773600, valid loss: 170.424759
epoch: 2798, train precision: 0.468467, train loss: 195.376183, valid precision: 0.466400, valid loss: 197.203895
epoch: 2799, train precision: 0.883711, train loss: 51.206047, valid precision: 0.748400, valid loss: 150.306807
epoch: 2800, train precision: 0.169267, train loss: 291.330570, valid precision: 0.177200, valid loss: 288.936003
epoch: 2801, train precision: 0.204511, train loss: 256.860119, valid precision: 0.217400, valid loss: 255.870985
epoch: 2802, train precision: 0.260667, train loss: 245.574596, valid precision: 0.275000, valid loss: 243.701045
epoch: 2803, train precision: 0.333578, train loss: 217.623140, valid precision: 0.342000, valid loss: 215.630812
epoch: 2804, train precision: 0.386444, train loss: 201.734792, valid precision: 0.400200, valid loss: 202.540910
epoch: 2805, train precision: 0.407378, train loss: 192.873622, valid precision: 0.419000, valid loss: 195.283009
epoch: 2806, train precision: 0.424178, train loss: 186.958890, valid precision: 0.436800, valid loss: 188.101184
epoch: 2807, train precision: 0.492289, train loss: 168.679456, valid precision: 0.503800, valid loss: 173.314685
epoch: 2808, train precision: 0.520756, train loss: 160.903544, valid precision: 0.526000, valid loss: 172.185522
epoch: 2809, train precision: 0.625267, train loss: 121.869608, valid precision: 0.595600, valid loss: 143.455706
epoch: 2810, train precision: 0.785467, train loss: 75.734565, valid precision: 0.706000, valid loss: 199.124446
epoch: 2811, train precision: 0.826489, train loss: 64.331652, valid precision: 0.723000, valid loss: 306.141206
epoch: 2812, train precision: 0.818356, train loss: 76.901706, valid precision: 0.722800, valid loss: 147.221445
epoch: 2813, train precision: 0.901244, train loss: 45.231304, valid precision: 0.765000, valid loss: 188.289095
epoch: 2814, train precision: 0.881400, train loss: 54.726222, valid precision: 0.754800, valid loss: 155.980613
epoch: 2815, train precision: 0.859378, train loss: 69.215340, valid precision: 0.742200, valid loss: 177.784257
epoch: 2816, train precision: 0.916156, train loss: 39.131947, valid precision: 0.771000, valid loss: 186.179815
epoch: 2817, train precision: 0.928222, train loss: 31.193152, valid precision: 0.769600, valid loss: 169.544839
epoch: 2818, train precision: 0.893156, train loss: 50.312445, valid precision: 0.757200, valid loss: 267.425076
epoch: 2819, train precision: 0.586089, train loss: 191.702727, valid precision: 0.556800, valid loss: 212.862866
epoch: 2820, train precision: 0.917467, train loss: 36.111068, valid precision: 0.765600, valid loss: 172.090637
epoch: 2821, train precision: 0.934778, train loss: 29.792678, valid precision: 0.782200, valid loss: 164.369744
epoch: 2822, train precision: 0.928667, train loss: 31.307297, valid precision: 0.775400, valid loss: 174.402585
epoch: 2823, train precision: 0.931867, train loss: 32.625486, valid precision: 0.767400, valid loss: 178.937859
epoch: 2824, train precision: 0.942044, train loss: 27.005919, valid precision: 0.774200, valid loss: 190.831198
epoch: 2825, train precision: 0.937622, train loss: 28.251997, valid precision: 0.774400, valid loss: 174.613096
epoch: 2826, train precision: 0.571200, train loss: 167.129876, valid precision: 0.568200, valid loss: 172.210193
epoch: 2827, train precision: 0.924511, train loss: 38.183257, valid precision: 0.776800, valid loss: 155.439269
epoch: 2828, train precision: 0.817200, train loss: 79.622106, valid precision: 0.716200, valid loss: 146.211576
epoch: 2829, train precision: 0.940933, train loss: 25.890261, valid precision: 0.783400, valid loss: 140.140507
epoch: 2830, train precision: 0.933067, train loss: 30.702106, valid precision: 0.777000, valid loss: 172.022573
epoch: 2831, train precision: 0.939911, train loss: 27.623386, valid precision: 0.781400, valid loss: 169.524071
epoch: 2832, train precision: 0.937378, train loss: 27.725504, valid precision: 0.770000, valid loss: 170.921584
epoch: 2833, train precision: 0.352867, train loss: 203.911792, valid precision: 0.347000, valid loss: 207.646619
epoch: 2834, train precision: 0.931067, train loss: 31.808210, valid precision: 0.778000, valid loss: 145.801707
epoch: 2835, train precision: 0.944911, train loss: 24.983709, valid precision: 0.779800, valid loss: 167.850953
epoch: 2836, train precision: 0.802756, train loss: 74.596031, valid precision: 0.707600, valid loss: 155.096533
epoch: 2837, train precision: 0.937689, train loss: 29.063628, valid precision: 0.779800, valid loss: 165.663096
epoch: 2838, train precision: 0.891756, train loss: 47.075041, valid precision: 0.751600, valid loss: 191.971193
epoch: 2839, train precision: 0.921689, train loss: 34.897106, valid precision: 0.765000, valid loss: 165.525665
epoch: 2840, train precision: 0.940311, train loss: 26.845990, valid precision: 0.771000, valid loss: 166.934003
epoch: 2841, train precision: 0.943022, train loss: 28.842104, valid precision: 0.777200, valid loss: 202.800529
epoch: 2842, train precision: 0.872156, train loss: 57.398949, valid precision: 0.740600, valid loss: 163.283630
epoch: 2843, train precision: 0.941356, train loss: 26.292114, valid precision: 0.779000, valid loss: 161.865447
epoch: 2844, train precision: 0.919578, train loss: 40.259613, valid precision: 0.768600, valid loss: 192.670795
epoch: 2845, train precision: 0.909556, train loss: 41.897692, valid precision: 0.761400, valid loss: 170.752531
epoch: 2846, train precision: 0.936000, train loss: 30.046482, valid precision: 0.774000, valid loss: 270.728688
epoch: 2847, train precision: 0.899200, train loss: 41.286181, valid precision: 0.753000, valid loss: 165.324350
epoch: 2848, train precision: 0.925978, train loss: 32.986000, valid precision: 0.770600, valid loss: 200.141581
epoch: 2849, train precision: 0.941911, train loss: 26.334567, valid precision: 0.778800, valid loss: 196.535614
epoch: 2850, train precision: 0.852978, train loss: 67.384222, valid precision: 0.737400, valid loss: 173.494311
epoch: 2851, train precision: 0.937311, train loss: 27.718587, valid precision: 0.776600, valid loss: 161.481250
epoch: 2852, train precision: 0.939178, train loss: 28.708147, valid precision: 0.776400, valid loss: 225.265852
epoch: 2853, train precision: 0.946844, train loss: 24.482992, valid precision: 0.782000, valid loss: 244.473985
epoch: 2854, train precision: 0.904022, train loss: 44.926359, valid precision: 0.757000, valid loss: 150.995000
epoch: 2855, train precision: 0.948511, train loss: 24.547704, valid precision: 0.780800, valid loss: 265.418307
epoch: 2856, train precision: 0.923333, train loss: 34.488325, valid precision: 0.770200, valid loss: 165.445242
epoch: 2857, train precision: 0.922489, train loss: 34.090102, valid precision: 0.773200, valid loss: 157.572794
epoch: 2858, train precision: 0.943267, train loss: 25.883985, valid precision: 0.782600, valid loss: 239.447719
epoch: 2859, train precision: 0.183422, train loss: 263.567927, valid precision: 0.187400, valid loss: 262.837811
epoch: 2860, train precision: 0.310867, train loss: 224.191128, valid precision: 0.328800, valid loss: 221.210249
epoch: 2861, train precision: 0.721356, train loss: 103.705925, valid precision: 0.658600, valid loss: 146.300830
epoch: 2862, train precision: 0.932289, train loss: 33.943297, valid precision: 0.778600, valid loss: 177.324380
epoch: 2863, train precision: 0.910089, train loss: 42.349779, valid precision: 0.765400, valid loss: 147.913713
epoch: 2864, train precision: 0.930178, train loss: 33.033332, valid precision: 0.777000, valid loss: 157.276396
epoch: 2865, train precision: 0.949556, train loss: 24.146014, valid precision: 0.784800, valid loss: 244.940164
epoch: 2866, train precision: 0.298533, train loss: 251.738702, valid precision: 0.297600, valid loss: 255.101829
epoch: 2867, train precision: 0.920400, train loss: 37.351569, valid precision: 0.763200, valid loss: 160.042617
epoch: 2868, train precision: 0.949489, train loss: 24.173252, valid precision: 0.781400, valid loss: 171.970662
epoch: 2869, train precision: 0.936778, train loss: 28.762023, valid precision: 0.764200, valid loss: 190.117118
epoch: 2870, train precision: 0.903578, train loss: 44.295558, valid precision: 0.752400, valid loss: 162.204588
epoch: 2871, train precision: 0.936356, train loss: 29.971961, valid precision: 0.772000, valid loss: 188.244474
epoch: 2872, train precision: 0.943911, train loss: 25.429908, valid precision: 0.775600, valid loss: 272.495362
epoch: 2873, train precision: 0.944800, train loss: 24.170094, valid precision: 0.778800, valid loss: 384.354959
epoch: 2874, train precision: 0.918533, train loss: 37.418125, valid precision: 0.761000, valid loss: 329.517015
epoch: 2875, train precision: 0.941622, train loss: 27.008099, valid precision: 0.768400, valid loss: 587.645068
epoch: 2876, train precision: 0.869311, train loss: 62.457969, valid precision: 0.744200, valid loss: 159.414365
epoch: 2877, train precision: 0.932311, train loss: 32.779233, valid precision: 0.770600, valid loss: 273.774967
epoch: 2878, train precision: 0.808800, train loss: 88.965433, valid precision: 0.711400, valid loss: 169.338040
epoch: 2879, train precision: 0.162422, train loss: 372.650366, valid precision: 0.171000, valid loss: 363.735036
epoch: 2880, train precision: 0.226533, train loss: 252.240731, valid precision: 0.238000, valid loss: 249.625411
epoch: 2881, train precision: 0.328600, train loss: 223.416518, valid precision: 0.336200, valid loss: 219.407098
epoch: 2882, train precision: 0.414311, train loss: 194.726751, valid precision: 0.421400, valid loss: 195.319368
epoch: 2883, train precision: 0.780244, train loss: 71.696089, valid precision: 0.665800, valid loss: 140.231276
epoch: 2884, train precision: 0.878333, train loss: 51.216113, valid precision: 0.735800, valid loss: 154.945717
epoch: 2885, train precision: 0.846200, train loss: 61.375665, valid precision: 0.719800, valid loss: 142.325475
epoch: 2886, train precision: 0.905956, train loss: 40.433499, valid precision: 0.757200, valid loss: 145.083038
epoch: 2887, train precision: 0.751556, train loss: 105.074093, valid precision: 0.693400, valid loss: 766.148720
epoch: 2888, train precision: 0.211178, train loss: 259.594165, valid precision: 0.226200, valid loss: 253.001275
epoch: 2889, train precision: 0.349467, train loss: 215.255640, valid precision: 0.359600, valid loss: 207.244589
epoch: 2890, train precision: 0.602844, train loss: 145.144282, valid precision: 0.591400, valid loss: 171.913798
epoch: 2891, train precision: 0.860533, train loss: 59.970086, valid precision: 0.737000, valid loss: 398.827554
epoch: 2892, train precision: 0.890156, train loss: 48.628929, valid precision: 0.750800, valid loss: 343.045397
epoch: 2893, train precision: 0.911911, train loss: 40.751872, valid precision: 0.759000, valid loss: 196.206245
epoch: 2894, train precision: 0.897000, train loss: 44.373534, valid precision: 0.745800, valid loss: 300.930443
epoch: 2895, train precision: 0.916800, train loss: 35.256934, valid precision: 0.762000, valid loss: 239.889860
epoch: 2896, train precision: 0.913289, train loss: 36.645435, valid precision: 0.759000, valid loss: 235.898717
epoch: 2897, train precision: 0.913178, train loss: 40.727801, valid precision: 0.759000, valid loss: 234.376570
epoch: 2898, train precision: 0.927289, train loss: 32.685129, valid precision: 0.770800, valid loss: 177.697397
epoch: 2899, train precision: 0.911111, train loss: 41.309654, valid precision: 0.758800, valid loss: 184.282219
epoch: 2900, train precision: 0.561111, train loss: 166.670770, valid precision: 0.541600, valid loss: 185.988751
epoch: 2901, train precision: 0.840111, train loss: 66.921012, valid precision: 0.723200, valid loss: 155.401982
epoch: 2902, train precision: 0.867089, train loss: 55.622764, valid precision: 0.727200, valid loss: 147.763604
epoch: 2903, train precision: 0.893956, train loss: 46.655805, valid precision: 0.754800, valid loss: 153.143499
epoch: 2904, train precision: 0.922733, train loss: 33.727859, valid precision: 0.760200, valid loss: 144.718497
epoch: 2905, train precision: 0.927111, train loss: 31.460669, valid precision: 0.758400, valid loss: 163.682730
epoch: 2906, train precision: 0.930200, train loss: 29.484925, valid precision: 0.759200, valid loss: 164.902254
epoch: 2907, train precision: 0.907067, train loss: 39.083813, valid precision: 0.747400, valid loss: 172.877646
epoch: 2908, train precision: 0.927244, train loss: 31.009598, valid precision: 0.765200, valid loss: 171.251891
epoch: 2909, train precision: 0.918267, train loss: 37.380306, valid precision: 0.751800, valid loss: 247.092596
epoch: 2910, train precision: 0.931467, train loss: 32.213927, valid precision: 0.762600, valid loss: 186.614874
epoch: 2911, train precision: 0.903356, train loss: 43.273371, valid precision: 0.757400, valid loss: 271.680872
epoch: 2912, train precision: 0.794578, train loss: 91.534704, valid precision: 0.706200, valid loss: 169.703863
epoch: 2913, train precision: 0.898533, train loss: 42.699030, valid precision: 0.746200, valid loss: 141.710380
epoch: 2914, train precision: 0.885444, train loss: 48.630523, valid precision: 0.752600, valid loss: 138.340359
epoch: 2915, train precision: 0.924822, train loss: 31.441299, valid precision: 0.761600, valid loss: 154.841664
epoch: 2916, train precision: 0.908933, train loss: 39.042780, valid precision: 0.760400, valid loss: 154.359298
epoch: 2917, train precision: 0.913156, train loss: 36.108047, valid precision: 0.751400, valid loss: 152.878416
epoch: 2918, train precision: 0.924578, train loss: 32.113471, valid precision: 0.756200, valid loss: 152.527332
epoch: 2919, train precision: 0.924089, train loss: 34.143581, valid precision: 0.756600, valid loss: 182.670859
epoch: 2920, train precision: 0.913222, train loss: 37.701583, valid precision: 0.755000, valid loss: 151.928983
epoch: 2921, train precision: 0.909178, train loss: 38.020008, valid precision: 0.753600, valid loss: 203.045570
epoch: 2922, train precision: 0.722578, train loss: 135.775649, valid precision: 0.656000, valid loss: 193.829671
epoch: 2923, train precision: 0.931467, train loss: 33.926172, valid precision: 0.768600, valid loss: 230.111661
epoch: 2924, train precision: 0.916467, train loss: 34.530113, valid precision: 0.771800, valid loss: 149.695676
epoch: 2925, train precision: 0.931356, train loss: 28.582273, valid precision: 0.767400, valid loss: 260.041301
epoch: 2926, train precision: 0.925333, train loss: 31.451739, valid precision: 0.761800, valid loss: 229.580996
epoch: 2927, train precision: 0.903089, train loss: 47.066957, valid precision: 0.745200, valid loss: 269.853952
epoch: 2928, train precision: 0.900089, train loss: 41.861713, valid precision: 0.746600, valid loss: 165.839783
epoch: 2929, train precision: 0.917311, train loss: 34.360488, valid precision: 0.756000, valid loss: 172.032934
epoch: 2930, train precision: 0.912022, train loss: 37.407259, valid precision: 0.753800, valid loss: 205.616125
epoch: 2931, train precision: 0.926556, train loss: 33.078812, valid precision: 0.752400, valid loss: 342.494407
epoch: 2932, train precision: 0.764178, train loss: 103.596881, valid precision: 0.696200, valid loss: 167.565450
epoch: 2933, train precision: 0.912556, train loss: 37.465452, valid precision: 0.753400, valid loss: 265.525184
epoch: 2934, train precision: 0.914667, train loss: 37.852884, valid precision: 0.755600, valid loss: 215.855449
epoch: 2935, train precision: 0.805467, train loss: 202.722931, valid precision: 0.716200, valid loss: 591.129675
epoch: 2936, train precision: 0.281800, train loss: 251.392987, valid precision: 0.287000, valid loss: 250.242959
epoch: 2937, train precision: 0.589956, train loss: 158.085622, valid precision: 0.570000, valid loss: 173.392290
epoch: 2938, train precision: 0.881733, train loss: 49.828442, valid precision: 0.748400, valid loss: 137.378429
epoch: 2939, train precision: 0.922778, train loss: 34.672217, valid precision: 0.763800, valid loss: 146.787346
epoch: 2940, train precision: 0.922067, train loss: 33.380967, valid precision: 0.758800, valid loss: 149.354183
epoch: 2941, train precision: 0.924978, train loss: 31.196719, valid precision: 0.761000, valid loss: 150.153377
epoch: 2942, train precision: 0.931467, train loss: 38.100311, valid precision: 0.762400, valid loss: 201.989245
epoch: 2943, train precision: 0.913489, train loss: 38.234578, valid precision: 0.749000, valid loss: 266.016166
epoch: 2944, train precision: 0.913600, train loss: 38.011928, valid precision: 0.764800, valid loss: 211.892835
epoch: 2945, train precision: 0.923622, train loss: 33.317343, valid precision: 0.770800, valid loss: 204.719702
epoch: 2946, train precision: 0.902244, train loss: 39.501466, valid precision: 0.751800, valid loss: 329.026438
epoch: 2947, train precision: 0.908933, train loss: 37.402599, valid precision: 0.756400, valid loss: 180.122076
epoch: 2948, train precision: 0.789533, train loss: 133.633437, valid precision: 0.685600, valid loss: 277.501099
epoch: 2949, train precision: 0.914067, train loss: 35.130087, valid precision: 0.750800, valid loss: 154.937694
epoch: 2950, train precision: 0.308667, train loss: 241.314060, valid precision: 0.306800, valid loss: 241.073770
epoch: 2951, train precision: 0.591444, train loss: 160.581085, valid precision: 0.560800, valid loss: 229.833075
epoch: 2952, train precision: 0.894333, train loss: 43.310114, valid precision: 0.752600, valid loss: 147.151353
epoch: 2953, train precision: 0.926822, train loss: 30.688716, valid precision: 0.755800, valid loss: 163.908358
epoch: 2954, train precision: 0.623956, train loss: 186.144210, valid precision: 0.578600, valid loss: 221.308953
epoch: 2955, train precision: 0.929178, train loss: 30.150662, valid precision: 0.757000, valid loss: 156.874291
epoch: 2956, train precision: 0.935644, train loss: 27.200311, valid precision: 0.762600, valid loss: 214.386509
epoch: 2957, train precision: 0.614022, train loss: 171.220171, valid precision: 0.577400, valid loss: 208.400756
epoch: 2958, train precision: 0.923622, train loss: 32.832037, valid precision: 0.761800, valid loss: 215.094781
epoch: 2959, train precision: 0.934044, train loss: 28.235631, valid precision: 0.765000, valid loss: 199.752745
epoch: 2960, train precision: 0.930800, train loss: 32.693097, valid precision: 0.755400, valid loss: 273.643649
epoch: 2961, train precision: 0.932822, train loss: 28.590191, valid precision: 0.764200, valid loss: 195.990231
epoch: 2962, train precision: 0.521733, train loss: 182.423540, valid precision: 0.521800, valid loss: 187.716404
epoch: 2963, train precision: 0.908822, train loss: 38.193457, valid precision: 0.755000, valid loss: 180.850873
epoch: 2964, train precision: 0.938533, train loss: 26.754350, valid precision: 0.767600, valid loss: 255.958294
epoch: 2965, train precision: 0.617356, train loss: 149.746912, valid precision: 0.593400, valid loss: 177.776996
epoch: 2966, train precision: 0.925356, train loss: 31.126633, valid precision: 0.766800, valid loss: 156.533653
epoch: 2967, train precision: 0.936378, train loss: 27.897151, valid precision: 0.760200, valid loss: 285.613288
epoch: 2968, train precision: 0.633200, train loss: 150.173182, valid precision: 0.617800, valid loss: 162.456629
epoch: 2969, train precision: 0.889044, train loss: 49.456300, valid precision: 0.744800, valid loss: 163.107387
epoch: 2970, train precision: 0.890911, train loss: 44.584143, valid precision: 0.737600, valid loss: 152.437341
epoch: 2971, train precision: 0.926467, train loss: 32.276174, valid precision: 0.761000, valid loss: 162.501826
epoch: 2972, train precision: 0.905644, train loss: 40.109560, valid precision: 0.751400, valid loss: 152.965110
epoch: 2973, train precision: 0.919800, train loss: 33.687432, valid precision: 0.760400, valid loss: 149.278905
epoch: 2974, train precision: 0.921844, train loss: 33.103139, valid precision: 0.757800, valid loss: 170.008296
epoch: 2975, train precision: 0.901311, train loss: 41.842836, valid precision: 0.750600, valid loss: 166.038178
epoch: 2976, train precision: 0.912400, train loss: 37.339990, valid precision: 0.752600, valid loss: 180.481334
epoch: 2977, train precision: 0.942644, train loss: 24.824408, valid precision: 0.764600, valid loss: 165.095719
epoch: 2978, train precision: 0.940622, train loss: 25.286798, valid precision: 0.769400, valid loss: 205.755313
epoch: 2979, train precision: 0.164044, train loss: 301.876664, valid precision: 0.179000, valid loss: 295.466851
epoch: 2980, train precision: 0.174533, train loss: 277.238523, valid precision: 0.175000, valid loss: 275.406197
epoch: 2981, train precision: 0.178800, train loss: 270.544547, valid precision: 0.193200, valid loss: 266.725251
epoch: 2982, train precision: 0.206289, train loss: 260.971483, valid precision: 0.218400, valid loss: 257.817556
epoch: 2983, train precision: 0.211422, train loss: 250.512801, valid precision: 0.218800, valid loss: 246.954043
epoch: 2984, train precision: 0.224667, train loss: 243.807845, valid precision: 0.237800, valid loss: 239.760229
epoch: 2985, train precision: 0.218911, train loss: 244.367957, valid precision: 0.221400, valid loss: 242.297937
epoch: 2986, train precision: 0.249333, train loss: 237.841243, valid precision: 0.261600, valid loss: 232.026505
epoch: 2987, train precision: 0.246556, train loss: 232.243262, valid precision: 0.267800, valid loss: 228.333834
epoch: 2988, train precision: 0.267667, train loss: 228.820689, valid precision: 0.283000, valid loss: 225.730073
epoch: 2989, train precision: 0.268533, train loss: 225.649554, valid precision: 0.281600, valid loss: 224.224152
epoch: 2990, train precision: 0.265644, train loss: 226.967929, valid precision: 0.280800, valid loss: 226.173224
epoch: 2991, train precision: 0.333933, train loss: 218.116100, valid precision: 0.349600, valid loss: 219.949849
epoch: 2992, train precision: 0.390622, train loss: 205.133017, valid precision: 0.403400, valid loss: 208.194312
epoch: 2993, train precision: 0.237200, train loss: 237.152251, valid precision: 0.252600, valid loss: 234.862617
epoch: 2994, train precision: 0.349400, train loss: 205.904776, valid precision: 0.372600, valid loss: 205.423023
epoch: 2995, train precision: 0.426933, train loss: 183.293845, valid precision: 0.439800, valid loss: 190.138932
epoch: 2996, train precision: 0.433356, train loss: 176.993318, valid precision: 0.435600, valid loss: 185.761690
epoch: 2997, train precision: 0.485356, train loss: 163.795608, valid precision: 0.475400, valid loss: 180.417481
epoch: 2998, train precision: 0.210467, train loss: 257.032548, valid precision: 0.225800, valid loss: 252.090882
epoch: 2999, train precision: 0.380089, train loss: 199.805838, valid precision: 0.391800, valid loss: 202.430989
epoch: 3000, train precision: 0.457778, train loss: 174.858545, valid precision: 0.452000, valid loss: 181.676026
epoch: 3001, train precision: 0.506622, train loss: 153.597010, valid precision: 0.480800, valid loss: 173.735720
epoch: 3002, train precision: 0.524778, train loss: 144.732313, valid precision: 0.492400, valid loss: 177.560392
epoch: 3003, train precision: 0.543489, train loss: 138.361930, valid precision: 0.506400, valid loss: 174.844894
epoch: 3004, train precision: 0.558289, train loss: 144.016818, valid precision: 0.531600, valid loss: 165.013270
epoch: 3005, train precision: 0.563778, train loss: 140.916167, valid precision: 0.529400, valid loss: 167.638808
epoch: 3006, train precision: 0.567822, train loss: 142.953760, valid precision: 0.538200, valid loss: 169.430961
epoch: 3007, train precision: 0.631756, train loss: 121.985157, valid precision: 0.572600, valid loss: 171.885822
epoch: 3008, train precision: 0.472933, train loss: 180.375125, valid precision: 0.482200, valid loss: 186.595258
epoch: 3009, train precision: 0.635644, train loss: 119.380268, valid precision: 0.594800, valid loss: 160.557800
epoch: 3010, train precision: 0.485844, train loss: 173.975392, valid precision: 0.472600, valid loss: 187.864519
epoch: 3011, train precision: 0.643067, train loss: 118.150712, valid precision: 0.581400, valid loss: 181.076258
epoch: 3012, train precision: 0.660578, train loss: 110.592688, valid precision: 0.593200, valid loss: 200.146274
epoch: 3013, train precision: 0.613511, train loss: 132.108717, valid precision: 0.581400, valid loss: 167.810418
epoch: 3014, train precision: 0.358267, train loss: 216.893662, valid precision: 0.377400, valid loss: 213.111153
epoch: 3015, train precision: 0.457600, train loss: 182.902289, valid precision: 0.454800, valid loss: 187.919797
epoch: 3016, train precision: 0.624933, train loss: 132.749154, valid precision: 0.597200, valid loss: 160.194350
epoch: 3017, train precision: 0.680867, train loss: 106.593612, valid precision: 0.624200, valid loss: 148.879975
epoch: 3018, train precision: 0.716489, train loss: 93.939587, valid precision: 0.641200, valid loss: 157.686235
epoch: 3019, train precision: 0.751444, train loss: 85.644612, valid precision: 0.667200, valid loss: 145.179560
epoch: 3020, train precision: 0.746133, train loss: 88.861106, valid precision: 0.670400, valid loss: 162.358551
epoch: 3021, train precision: 0.736756, train loss: 90.174581, valid precision: 0.668200, valid loss: 145.425476
epoch: 3022, train precision: 0.754600, train loss: 83.491223, valid precision: 0.676400, valid loss: 158.269396
epoch: 3023, train precision: 0.757356, train loss: 93.964379, valid precision: 0.674600, valid loss: 154.266323
epoch: 3024, train precision: 0.813489, train loss: 73.414031, valid precision: 0.710600, valid loss: 182.450360
epoch: 3025, train precision: 0.570822, train loss: 164.350303, valid precision: 0.547800, valid loss: 181.511992
epoch: 3026, train precision: 0.847600, train loss: 58.571250, valid precision: 0.727800, valid loss: 181.009083
epoch: 3027, train precision: 0.828956, train loss: 64.810542, valid precision: 0.714000, valid loss: 143.263851
epoch: 3028, train precision: 0.663289, train loss: 135.862708, valid precision: 0.632600, valid loss: 159.047164
epoch: 3029, train precision: 0.820600, train loss: 67.410893, valid precision: 0.714200, valid loss: 144.106569
epoch: 3030, train precision: 0.844267, train loss: 61.646882, valid precision: 0.724400, valid loss: 149.655335
epoch: 3031, train precision: 0.852444, train loss: 58.767417, valid precision: 0.728800, valid loss: 141.032740
epoch: 3032, train precision: 0.868133, train loss: 49.490208, valid precision: 0.739400, valid loss: 133.742992
epoch: 3033, train precision: 0.280733, train loss: 263.706289, valid precision: 0.291200, valid loss: 259.809653
epoch: 3034, train precision: 0.515067, train loss: 171.086497, valid precision: 0.515800, valid loss: 169.805231
epoch: 3035, train precision: 0.662489, train loss: 128.638120, valid precision: 0.641200, valid loss: 151.432889
epoch: 3036, train precision: 0.831578, train loss: 63.503571, valid precision: 0.726400, valid loss: 139.057942
epoch: 3037, train precision: 0.833533, train loss: 63.363239, valid precision: 0.719800, valid loss: 145.208547
epoch: 3038, train precision: 0.856267, train loss: 53.605873, valid precision: 0.730200, valid loss: 149.050635
epoch: 3039, train precision: 0.868867, train loss: 55.521721, valid precision: 0.730000, valid loss: 188.616515
epoch: 3040, train precision: 0.289689, train loss: 245.262676, valid precision: 0.296200, valid loss: 241.835278
epoch: 3041, train precision: 0.377089, train loss: 209.396080, valid precision: 0.383800, valid loss: 208.374615
epoch: 3042, train precision: 0.415667, train loss: 184.462588, valid precision: 0.425600, valid loss: 185.845290
epoch: 3043, train precision: 0.644222, train loss: 124.775802, valid precision: 0.594800, valid loss: 163.548619
epoch: 3044, train precision: 0.837756, train loss: 61.916586, valid precision: 0.716800, valid loss: 146.754784
epoch: 3045, train precision: 0.869000, train loss: 50.030827, valid precision: 0.743000, valid loss: 137.217748
epoch: 3046, train precision: 0.757089, train loss: 94.446386, valid precision: 0.668800, valid loss: 155.003467
epoch: 3047, train precision: 0.860000, train loss: 52.162627, valid precision: 0.728400, valid loss: 143.601892
epoch: 3048, train precision: 0.880978, train loss: 45.345682, valid precision: 0.743400, valid loss: 139.763050
epoch: 3049, train precision: 0.870200, train loss: 48.771000, valid precision: 0.738000, valid loss: 150.208492
epoch: 3050, train precision: 0.792600, train loss: 82.337639, valid precision: 0.690200, valid loss: 143.806994
epoch: 3051, train precision: 0.610200, train loss: 150.621364, valid precision: 0.598800, valid loss: 160.746547
epoch: 3052, train precision: 0.816933, train loss: 66.650383, valid precision: 0.706600, valid loss: 136.936434
epoch: 3053, train precision: 0.856889, train loss: 53.516414, valid precision: 0.736400, valid loss: 130.330427
epoch: 3054, train precision: 0.874022, train loss: 49.843048, valid precision: 0.735200, valid loss: 137.464153
epoch: 3055, train precision: 0.864844, train loss: 49.562342, valid precision: 0.730800, valid loss: 137.849549
epoch: 3056, train precision: 0.839533, train loss: 61.696547, valid precision: 0.724600, valid loss: 141.965502
epoch: 3057, train precision: 0.890467, train loss: 41.415587, valid precision: 0.747000, valid loss: 140.783001
epoch: 3058, train precision: 0.809467, train loss: 69.866165, valid precision: 0.701600, valid loss: 146.104996
epoch: 3059, train precision: 0.843044, train loss: 59.530493, valid precision: 0.736400, valid loss: 134.853143
epoch: 3060, train precision: 0.850511, train loss: 55.040007, valid precision: 0.729600, valid loss: 146.966091
epoch: 3061, train precision: 0.864444, train loss: 50.160356, valid precision: 0.735800, valid loss: 148.937622
epoch: 3062, train precision: 0.882911, train loss: 43.482296, valid precision: 0.744200, valid loss: 135.650889
epoch: 3063, train precision: 0.870000, train loss: 48.130703, valid precision: 0.737200, valid loss: 144.070145
epoch: 3064, train precision: 0.880511, train loss: 44.835309, valid precision: 0.744600, valid loss: 141.151161
epoch: 3065, train precision: 0.874622, train loss: 46.575332, valid precision: 0.740200, valid loss: 150.468324
epoch: 3066, train precision: 0.882911, train loss: 43.393316, valid precision: 0.751600, valid loss: 144.263266
epoch: 3067, train precision: 0.684644, train loss: 143.559283, valid precision: 0.630000, valid loss: 190.913927
epoch: 3068, train precision: 0.850711, train loss: 57.355663, valid precision: 0.722600, valid loss: 148.702762
epoch: 3069, train precision: 0.895067, train loss: 39.572770, valid precision: 0.747000, valid loss: 142.560673
epoch: 3070, train precision: 0.844800, train loss: 57.802255, valid precision: 0.719400, valid loss: 138.856302
epoch: 3071, train precision: 0.890467, train loss: 40.800419, valid precision: 0.747400, valid loss: 146.034742
epoch: 3072, train precision: 0.875311, train loss: 47.228974, valid precision: 0.730600, valid loss: 151.867818
epoch: 3073, train precision: 0.895200, train loss: 40.131120, valid precision: 0.746600, valid loss: 153.875333
epoch: 3074, train precision: 0.882400, train loss: 43.598595, valid precision: 0.743000, valid loss: 179.037501
epoch: 3075, train precision: 0.882244, train loss: 44.267795, valid precision: 0.749400, valid loss: 143.799260
epoch: 3076, train precision: 0.860000, train loss: 53.569758, valid precision: 0.724600, valid loss: 173.431164
epoch: 3077, train precision: 0.882733, train loss: 45.120705, valid precision: 0.737000, valid loss: 141.747731
epoch: 3078, train precision: 0.317089, train loss: 227.668079, valid precision: 0.325800, valid loss: 225.954147
epoch: 3079, train precision: 0.761111, train loss: 101.278526, valid precision: 0.694400, valid loss: 150.162722
epoch: 3080, train precision: 0.872489, train loss: 49.932141, valid precision: 0.733600, valid loss: 146.834678
epoch: 3081, train precision: 0.881978, train loss: 46.227523, valid precision: 0.737600, valid loss: 138.237182
epoch: 3082, train precision: 0.877111, train loss: 48.853443, valid precision: 0.738600, valid loss: 139.049164
epoch: 3083, train precision: 0.555200, train loss: 180.866752, valid precision: 0.544800, valid loss: 193.588277
epoch: 3084, train precision: 0.883889, train loss: 45.457004, valid precision: 0.741600, valid loss: 148.079836
epoch: 3085, train precision: 0.877778, train loss: 48.854162, valid precision: 0.740200, valid loss: 143.742556
epoch: 3086, train precision: 0.884356, train loss: 44.416490, valid precision: 0.742800, valid loss: 132.961374
epoch: 3087, train precision: 0.889422, train loss: 40.557386, valid precision: 0.747600, valid loss: 145.611999
epoch: 3088, train precision: 0.584756, train loss: 171.288377, valid precision: 0.574200, valid loss: 187.356662
epoch: 3089, train precision: 0.902356, train loss: 39.096422, valid precision: 0.753200, valid loss: 142.848590
epoch: 3090, train precision: 0.904000, train loss: 37.697153, valid precision: 0.753400, valid loss: 149.609865
epoch: 3091, train precision: 0.871000, train loss: 50.459219, valid precision: 0.726800, valid loss: 196.699400
epoch: 3092, train precision: 0.808311, train loss: 77.125855, valid precision: 0.707800, valid loss: 147.378455
epoch: 3093, train precision: 0.885933, train loss: 43.750616, valid precision: 0.750000, valid loss: 151.868974
epoch: 3094, train precision: 0.902933, train loss: 38.571357, valid precision: 0.756600, valid loss: 168.412461
epoch: 3095, train precision: 0.888467, train loss: 43.088311, valid precision: 0.740400, valid loss: 225.060249
epoch: 3096, train precision: 0.893511, train loss: 41.084507, valid precision: 0.745400, valid loss: 169.223483
epoch: 3097, train precision: 0.855067, train loss: 58.017672, valid precision: 0.736000, valid loss: 145.912058
epoch: 3098, train precision: 0.897956, train loss: 41.223067, valid precision: 0.755200, valid loss: 191.949187
epoch: 3099, train precision: 0.397022, train loss: 230.622085, valid precision: 0.395600, valid loss: 234.419519
epoch: 3100, train precision: 0.880311, train loss: 47.002344, valid precision: 0.740200, valid loss: 140.524126
epoch: 3101, train precision: 0.782178, train loss: 96.769743, valid precision: 0.688200, valid loss: 179.796366
epoch: 3102, train precision: 0.891044, train loss: 44.067017, valid precision: 0.754400, valid loss: 443.510647
epoch: 3103, train precision: 0.901378, train loss: 38.513083, valid precision: 0.749400, valid loss: 246.762630
epoch: 3104, train precision: 0.920978, train loss: 31.593233, valid precision: 0.763200, valid loss: 196.887169
epoch: 3105, train precision: 0.896556, train loss: 41.497895, valid precision: 0.735800, valid loss: 229.065623
epoch: 3106, train precision: 0.899244, train loss: 40.177831, valid precision: 0.746800, valid loss: 148.331518
epoch: 3107, train precision: 0.897844, train loss: 39.938531, valid precision: 0.754600, valid loss: 242.479370
epoch: 3108, train precision: 0.868489, train loss: 51.700565, valid precision: 0.735800, valid loss: 161.495256
epoch: 3109, train precision: 0.859378, train loss: 54.468634, valid precision: 0.721200, valid loss: 169.880510
epoch: 3110, train precision: 0.886311, train loss: 45.525285, valid precision: 0.742200, valid loss: 144.838013
epoch: 3111, train precision: 0.259667, train loss: 321.841429, valid precision: 0.265200, valid loss: 315.879488
epoch: 3112, train precision: 0.871556, train loss: 51.994831, valid precision: 0.741200, valid loss: 142.408018
epoch: 3113, train precision: 0.895822, train loss: 40.232133, valid precision: 0.745800, valid loss: 138.852313
epoch: 3114, train precision: 0.731156, train loss: 106.902350, valid precision: 0.679800, valid loss: 146.916218
epoch: 3115, train precision: 0.899311, train loss: 39.320159, valid precision: 0.749800, valid loss: 145.606517
epoch: 3116, train precision: 0.911600, train loss: 34.360532, valid precision: 0.761000, valid loss: 140.115599
epoch: 3117, train precision: 0.898133, train loss: 39.235122, valid precision: 0.745400, valid loss: 149.153633
epoch: 3118, train precision: 0.745244, train loss: 102.142038, valid precision: 0.678000, valid loss: 152.056123
epoch: 3119, train precision: 0.869000, train loss: 54.708006, valid precision: 0.747000, valid loss: 134.198105
epoch: 3120, train precision: 0.525356, train loss: 171.557311, valid precision: 0.522200, valid loss: 175.157248
epoch: 3121, train precision: 0.867889, train loss: 52.312287, valid precision: 0.742800, valid loss: 140.804059
epoch: 3122, train precision: 0.906667, train loss: 36.160557, valid precision: 0.752400, valid loss: 137.021966
epoch: 3123, train precision: 0.901178, train loss: 38.136355, valid precision: 0.746000, valid loss: 147.941583
epoch: 3124, train precision: 0.776089, train loss: 86.932370, valid precision: 0.696000, valid loss: 140.310629
epoch: 3125, train precision: 0.813489, train loss: 77.764519, valid precision: 0.721800, valid loss: 149.038750
epoch: 3126, train precision: 0.900044, train loss: 38.371065, valid precision: 0.747400, valid loss: 148.951140
epoch: 3127, train precision: 0.880711, train loss: 47.935008, valid precision: 0.743400, valid loss: 148.597983
epoch: 3128, train precision: 0.918756, train loss: 32.471589, valid precision: 0.758800, valid loss: 142.429744
epoch: 3129, train precision: 0.910400, train loss: 34.970927, valid precision: 0.754800, valid loss: 145.401452
epoch: 3130, train precision: 0.906022, train loss: 37.399247, valid precision: 0.751000, valid loss: 157.274355
epoch: 3131, train precision: 0.895356, train loss: 44.273153, valid precision: 0.742000, valid loss: 160.951610
epoch: 3132, train precision: 0.755467, train loss: 110.789966, valid precision: 0.679600, valid loss: 177.020095
epoch: 3133, train precision: 0.899978, train loss: 39.426212, valid precision: 0.751200, valid loss: 146.686464
epoch: 3134, train precision: 0.901289, train loss: 38.662346, valid precision: 0.753600, valid loss: 159.649875
epoch: 3135, train precision: 0.899489, train loss: 39.379241, valid precision: 0.742200, valid loss: 159.327336
epoch: 3136, train precision: 0.900822, train loss: 41.308745, valid precision: 0.741800, valid loss: 165.088697
epoch: 3137, train precision: 0.879022, train loss: 48.065888, valid precision: 0.732800, valid loss: 149.233577
epoch: 3138, train precision: 0.907644, train loss: 40.457482, valid precision: 0.753600, valid loss: 149.496437
epoch: 3139, train precision: 0.881689, train loss: 46.193026, valid precision: 0.741600, valid loss: 138.119387
epoch: 3140, train precision: 0.896600, train loss: 40.690009, valid precision: 0.747200, valid loss: 154.183497
epoch: 3141, train precision: 0.891756, train loss: 44.334376, valid precision: 0.736600, valid loss: 170.354774
epoch: 3142, train precision: 0.890800, train loss: 45.543136, valid precision: 0.729400, valid loss: 179.815613
epoch: 3143, train precision: 0.898178, train loss: 44.995465, valid precision: 0.742800, valid loss: 181.616810
epoch: 3144, train precision: 0.898844, train loss: 38.871281, valid precision: 0.754000, valid loss: 147.041107
epoch: 3145, train precision: 0.907044, train loss: 36.299235, valid precision: 0.751600, valid loss: 148.232796
epoch: 3146, train precision: 0.880378, train loss: 47.431436, valid precision: 0.732200, valid loss: 161.419926
epoch: 3147, train precision: 0.871156, train loss: 50.428751, valid precision: 0.718600, valid loss: 158.482230
epoch: 3148, train precision: 0.775756, train loss: 90.758487, valid precision: 0.676600, valid loss: 160.000622
epoch: 3149, train precision: 0.919356, train loss: 32.187865, valid precision: 0.754800, valid loss: 148.877438
epoch: 3150, train precision: 0.912311, train loss: 35.441220, valid precision: 0.749200, valid loss: 144.213622
epoch: 3151, train precision: 0.690800, train loss: 124.336027, valid precision: 0.661800, valid loss: 150.616132
epoch: 3152, train precision: 0.720022, train loss: 109.684976, valid precision: 0.672000, valid loss: 146.321817
epoch: 3153, train precision: 0.912844, train loss: 35.528756, valid precision: 0.751400, valid loss: 151.003368
epoch: 3154, train precision: 0.907689, train loss: 36.607605, valid precision: 0.749400, valid loss: 153.210270
epoch: 3155, train precision: 0.912089, train loss: 34.182318, valid precision: 0.746000, valid loss: 150.047084
epoch: 3156, train precision: 0.915644, train loss: 33.366592, valid precision: 0.757800, valid loss: 148.601965
epoch: 3157, train precision: 0.910156, train loss: 37.218449, valid precision: 0.755800, valid loss: 164.496216
epoch: 3158, train precision: 0.822089, train loss: 71.578875, valid precision: 0.714200, valid loss: 146.251578
epoch: 3159, train precision: 0.903556, train loss: 37.230096, valid precision: 0.749400, valid loss: 148.791661
epoch: 3160, train precision: 0.899133, train loss: 39.169434, valid precision: 0.749000, valid loss: 163.294528
epoch: 3161, train precision: 0.787378, train loss: 87.622690, valid precision: 0.697400, valid loss: 156.986338
epoch: 3162, train precision: 0.899800, train loss: 39.793612, valid precision: 0.748000, valid loss: 141.927356
epoch: 3163, train precision: 0.900600, train loss: 39.514004, valid precision: 0.742400, valid loss: 161.230543
epoch: 3164, train precision: 0.889867, train loss: 44.947499, valid precision: 0.732000, valid loss: 159.382350
epoch: 3165, train precision: 0.923689, train loss: 29.567320, valid precision: 0.760000, valid loss: 152.744943
epoch: 3166, train precision: 0.445489, train loss: 193.635719, valid precision: 0.443200, valid loss: 195.519447
epoch: 3167, train precision: 0.904689, train loss: 38.253247, valid precision: 0.749000, valid loss: 134.953550
epoch: 3168, train precision: 0.923089, train loss: 30.830605, valid precision: 0.758600, valid loss: 143.609352
epoch: 3169, train precision: 0.785489, train loss: 85.762523, valid precision: 0.686400, valid loss: 159.943714
epoch: 3170, train precision: 0.898867, train loss: 40.023612, valid precision: 0.735400, valid loss: 154.390333
epoch: 3171, train precision: 0.895378, train loss: 40.122470, valid precision: 0.747000, valid loss: 166.833804
epoch: 3172, train precision: 0.882200, train loss: 45.760188, valid precision: 0.726600, valid loss: 151.369009
epoch: 3173, train precision: 0.917089, train loss: 32.107404, valid precision: 0.751400, valid loss: 153.183853
epoch: 3174, train precision: 0.882956, train loss: 48.704159, valid precision: 0.739800, valid loss: 159.718619
epoch: 3175, train precision: 0.858778, train loss: 56.377630, valid precision: 0.732800, valid loss: 139.334400
epoch: 3176, train precision: 0.188511, train loss: 360.718940, valid precision: 0.193800, valid loss: 350.646821
epoch: 3177, train precision: 0.301756, train loss: 227.427876, valid precision: 0.319800, valid loss: 224.989574
epoch: 3178, train precision: 0.474244, train loss: 184.962069, valid precision: 0.495200, valid loss: 181.744933
epoch: 3179, train precision: 0.516756, train loss: 163.682149, valid precision: 0.516000, valid loss: 164.405471
epoch: 3180, train precision: 0.593844, train loss: 144.022384, valid precision: 0.589400, valid loss: 150.379857
epoch: 3181, train precision: 0.682444, train loss: 114.162172, valid precision: 0.651400, valid loss: 136.788778
epoch: 3182, train precision: 0.858978, train loss: 57.408504, valid precision: 0.746200, valid loss: 135.945414
epoch: 3183, train precision: 0.868333, train loss: 53.984680, valid precision: 0.740800, valid loss: 152.038887
epoch: 3184, train precision: 0.880267, train loss: 47.812814, valid precision: 0.743400, valid loss: 149.880236
epoch: 3185, train precision: 0.888333, train loss: 43.449152, valid precision: 0.743400, valid loss: 151.410624
epoch: 3186, train precision: 0.898511, train loss: 43.766020, valid precision: 0.752800, valid loss: 156.723559
epoch: 3187, train precision: 0.889689, train loss: 42.084825, valid precision: 0.747400, valid loss: 150.769017
epoch: 3188, train precision: 0.919889, train loss: 32.828462, valid precision: 0.764000, valid loss: 145.039864
epoch: 3189, train precision: 0.910756, train loss: 35.488015, valid precision: 0.751400, valid loss: 150.589687
epoch: 3190, train precision: 0.896000, train loss: 42.585573, valid precision: 0.737200, valid loss: 155.722302
epoch: 3191, train precision: 0.916533, train loss: 33.177253, valid precision: 0.761400, valid loss: 144.902872
epoch: 3192, train precision: 0.217000, train loss: 287.740111, valid precision: 0.221200, valid loss: 287.181826
epoch: 3193, train precision: 0.239133, train loss: 258.842962, valid precision: 0.249600, valid loss: 258.186794
epoch: 3194, train precision: 0.499467, train loss: 174.480237, valid precision: 0.497000, valid loss: 179.522976
epoch: 3195, train precision: 0.754444, train loss: 93.290606, valid precision: 0.663400, valid loss: 156.685934
epoch: 3196, train precision: 0.771022, train loss: 91.809637, valid precision: 0.668200, valid loss: 159.828989
epoch: 3197, train precision: 0.878844, train loss: 47.610787, valid precision: 0.727200, valid loss: 144.013215
epoch: 3198, train precision: 0.781111, train loss: 86.363336, valid precision: 0.676600, valid loss: 167.059817
epoch: 3199, train precision: 0.846444, train loss: 57.988052, valid precision: 0.709600, valid loss: 154.611840
epoch: 3200, train precision: 0.868356, train loss: 48.097646, valid precision: 0.717000, valid loss: 153.691118
epoch: 3201, train precision: 0.885511, train loss: 45.960461, valid precision: 0.731800, valid loss: 164.458253
epoch: 3202, train precision: 0.910667, train loss: 35.791680, valid precision: 0.751600, valid loss: 155.362755
epoch: 3203, train precision: 0.909911, train loss: 38.094758, valid precision: 0.751200, valid loss: 165.082869
epoch: 3204, train precision: 0.916689, train loss: 31.402172, valid precision: 0.754000, valid loss: 151.293243
epoch: 3205, train precision: 0.915467, train loss: 34.868741, valid precision: 0.753200, valid loss: 152.338009
epoch: 3206, train precision: 0.902200, train loss: 42.182131, valid precision: 0.746600, valid loss: 152.445333
epoch: 3207, train precision: 0.895667, train loss: 41.889780, valid precision: 0.740200, valid loss: 161.969962
epoch: 3208, train precision: 0.889289, train loss: 44.185071, valid precision: 0.754200, valid loss: 202.984224
epoch: 3209, train precision: 0.890844, train loss: 40.924303, valid precision: 0.749600, valid loss: 150.414683
epoch: 3210, train precision: 0.732311, train loss: 104.356449, valid precision: 0.657000, valid loss: 161.500891
epoch: 3211, train precision: 0.915778, train loss: 32.963097, valid precision: 0.758600, valid loss: 146.440360
epoch: 3212, train precision: 0.871911, train loss: 51.977982, valid precision: 0.733800, valid loss: 161.277680
epoch: 3213, train precision: 0.905244, train loss: 37.919521, valid precision: 0.758200, valid loss: 139.665337
epoch: 3214, train precision: 0.915444, train loss: 34.401803, valid precision: 0.752800, valid loss: 157.182131
epoch: 3215, train precision: 0.875733, train loss: 48.979952, valid precision: 0.743000, valid loss: 151.011777
epoch: 3216, train precision: 0.893622, train loss: 40.638271, valid precision: 0.736800, valid loss: 159.450489
epoch: 3217, train precision: 0.897289, train loss: 37.889299, valid precision: 0.738800, valid loss: 159.649878
epoch: 3218, train precision: 0.922289, train loss: 32.532160, valid precision: 0.754400, valid loss: 153.976200
epoch: 3219, train precision: 0.866311, train loss: 56.788887, valid precision: 0.722200, valid loss: 170.855726
epoch: 3220, train precision: 0.816044, train loss: 73.514061, valid precision: 0.716000, valid loss: 152.392879
epoch: 3221, train precision: 0.873556, train loss: 49.071472, valid precision: 0.734400, valid loss: 143.516304
epoch: 3222, train precision: 0.924333, train loss: 30.439228, valid precision: 0.766200, valid loss: 147.066365
epoch: 3223, train precision: 0.906444, train loss: 36.809786, valid precision: 0.752800, valid loss: 150.764107
epoch: 3224, train precision: 0.914956, train loss: 33.102167, valid precision: 0.757200, valid loss: 149.340127
epoch: 3225, train precision: 0.757800, train loss: 100.499591, valid precision: 0.672000, valid loss: 175.865678
epoch: 3226, train precision: 0.914156, train loss: 33.135178, valid precision: 0.756200, valid loss: 145.960325
epoch: 3227, train precision: 0.928089, train loss: 29.350998, valid precision: 0.750600, valid loss: 153.664361
epoch: 3228, train precision: 0.904244, train loss: 38.155817, valid precision: 0.751000, valid loss: 159.623100
epoch: 3229, train precision: 0.442711, train loss: 199.472104, valid precision: 0.445600, valid loss: 203.064840
epoch: 3230, train precision: 0.695022, train loss: 118.934635, valid precision: 0.655200, valid loss: 149.534944
epoch: 3231, train precision: 0.895511, train loss: 41.919648, valid precision: 0.755800, valid loss: 143.728785
epoch: 3232, train precision: 0.233444, train loss: 325.312888, valid precision: 0.234600, valid loss: 325.859182
epoch: 3233, train precision: 0.412178, train loss: 195.098301, valid precision: 0.429800, valid loss: 213.190501
epoch: 3234, train precision: 0.587267, train loss: 149.951075, valid precision: 0.586400, valid loss: 157.664275
epoch: 3235, train precision: 0.834178, train loss: 68.286201, valid precision: 0.734000, valid loss: 152.754945
epoch: 3236, train precision: 0.881156, train loss: 46.784020, valid precision: 0.746600, valid loss: 127.221660
epoch: 3237, train precision: 0.898778, train loss: 40.438510, valid precision: 0.749800, valid loss: 142.076441
epoch: 3238, train precision: 0.846067, train loss: 59.204249, valid precision: 0.729000, valid loss: 137.099401
epoch: 3239, train precision: 0.882400, train loss: 47.651845, valid precision: 0.747000, valid loss: 143.324447
epoch: 3240, train precision: 0.907867, train loss: 36.760799, valid precision: 0.751000, valid loss: 153.872767
epoch: 3241, train precision: 0.915933, train loss: 33.193589, valid precision: 0.752600, valid loss: 150.303099
epoch: 3242, train precision: 0.199489, train loss: 292.821640, valid precision: 0.210000, valid loss: 292.631189
epoch: 3243, train precision: 0.243156, train loss: 265.539759, valid precision: 0.249000, valid loss: 263.702008
epoch: 3244, train precision: 0.254044, train loss: 249.358383, valid precision: 0.252000, valid loss: 249.923911
epoch: 3245, train precision: 0.295156, train loss: 231.847951, valid precision: 0.288000, valid loss: 246.012266
epoch: 3246, train precision: 0.497911, train loss: 174.960017, valid precision: 0.483000, valid loss: 188.333554
epoch: 3247, train precision: 0.591378, train loss: 146.100806, valid precision: 0.565000, valid loss: 165.622176
epoch: 3248, train precision: 0.878622, train loss: 51.357818, valid precision: 0.740000, valid loss: 160.544514
epoch: 3249, train precision: 0.905022, train loss: 39.592654, valid precision: 0.750200, valid loss: 146.358088
epoch: 3250, train precision: 0.903644, train loss: 40.876737, valid precision: 0.748800, valid loss: 149.536961
epoch: 3251, train precision: 0.896978, train loss: 41.701103, valid precision: 0.745000, valid loss: 215.942597
epoch: 3252, train precision: 0.913333, train loss: 34.782877, valid precision: 0.751000, valid loss: 187.338158
epoch: 3253, train precision: 0.925889, train loss: 31.437639, valid precision: 0.759000, valid loss: 150.897681
epoch: 3254, train precision: 0.917822, train loss: 32.382386, valid precision: 0.744200, valid loss: 166.612156
epoch: 3255, train precision: 0.908356, train loss: 36.717526, valid precision: 0.741200, valid loss: 160.676754
epoch: 3256, train precision: 0.920822, train loss: 32.237793, valid precision: 0.753400, valid loss: 185.911760
epoch: 3257, train precision: 0.664378, train loss: 122.724837, valid precision: 0.642200, valid loss: 148.428067
epoch: 3258, train precision: 0.886400, train loss: 46.915500, valid precision: 0.733200, valid loss: 165.805742
epoch: 3259, train precision: 0.912422, train loss: 34.947708, valid precision: 0.746000, valid loss: 155.221671
epoch: 3260, train precision: 0.911578, train loss: 35.022680, valid precision: 0.750400, valid loss: 167.057521
epoch: 3261, train precision: 0.929867, train loss: 30.255864, valid precision: 0.766600, valid loss: 146.644935
epoch: 3262, train precision: 0.907378, train loss: 40.810559, valid precision: 0.749200, valid loss: 163.528149
epoch: 3263, train precision: 0.867800, train loss: 56.308561, valid precision: 0.712000, valid loss: 333.519455
epoch: 3264, train precision: 0.916311, train loss: 35.329307, valid precision: 0.746400, valid loss: 237.033398
epoch: 3265, train precision: 0.309733, train loss: 238.337752, valid precision: 0.319200, valid loss: 237.450275
epoch: 3266, train precision: 0.877200, train loss: 51.197917, valid precision: 0.750000, valid loss: 169.405086
epoch: 3267, train precision: 0.908956, train loss: 37.466522, valid precision: 0.755600, valid loss: 252.140017
epoch: 3268, train precision: 0.338689, train loss: 243.490365, valid precision: 0.358400, valid loss: 241.892155
epoch: 3269, train precision: 0.415644, train loss: 187.709074, valid precision: 0.417200, valid loss: 198.741873
epoch: 3270, train precision: 0.757400, train loss: 95.012943, valid precision: 0.671800, valid loss: 159.443517
epoch: 3271, train precision: 0.897089, train loss: 40.908451, valid precision: 0.742000, valid loss: 150.240791
epoch: 3272, train precision: 0.918511, train loss: 34.155701, valid precision: 0.761800, valid loss: 158.902550
epoch: 3273, train precision: 0.865289, train loss: 56.806830, valid precision: 0.730600, valid loss: 177.243668
epoch: 3274, train precision: 0.637044, train loss: 194.104758, valid precision: 0.584400, valid loss: 260.829133
epoch: 3275, train precision: 0.714067, train loss: 110.790212, valid precision: 0.652600, valid loss: 153.403289
epoch: 3276, train precision: 0.894022, train loss: 42.357662, valid precision: 0.747600, valid loss: 172.166575
epoch: 3277, train precision: 0.910000, train loss: 36.316395, valid precision: 0.750200, valid loss: 165.309456
epoch: 3278, train precision: 0.891800, train loss: 42.365703, valid precision: 0.743200, valid loss: 168.206657
epoch: 3279, train precision: 0.755844, train loss: 92.890695, valid precision: 0.670600, valid loss: 158.523618
epoch: 3280, train precision: 0.914622, train loss: 34.267575, valid precision: 0.750600, valid loss: 173.041800
epoch: 3281, train precision: 0.918533, train loss: 34.503955, valid precision: 0.757400, valid loss: 202.583209
epoch: 3282, train precision: 0.913022, train loss: 34.991181, valid precision: 0.751400, valid loss: 185.197592
epoch: 3283, train precision: 0.866200, train loss: 53.019540, valid precision: 0.737800, valid loss: 154.325655
epoch: 3284, train precision: 0.913733, train loss: 35.238327, valid precision: 0.746400, valid loss: 157.902402
epoch: 3285, train precision: 0.891800, train loss: 42.312401, valid precision: 0.734800, valid loss: 164.951362
epoch: 3286, train precision: 0.933267, train loss: 27.285336, valid precision: 0.765800, valid loss: 142.397226
epoch: 3287, train precision: 0.880889, train loss: 48.651326, valid precision: 0.751000, valid loss: 147.483366
epoch: 3288, train precision: 0.914378, train loss: 35.057915, valid precision: 0.761400, valid loss: 147.997800
epoch: 3289, train precision: 0.893444, train loss: 44.771522, valid precision: 0.739600, valid loss: 154.778253
epoch: 3290, train precision: 0.920333, train loss: 31.533505, valid precision: 0.752200, valid loss: 166.770913
epoch: 3291, train precision: 0.857644, train loss: 57.366272, valid precision: 0.733400, valid loss: 171.229636
epoch: 3292, train precision: 0.888844, train loss: 47.135555, valid precision: 0.733600, valid loss: 347.298736
epoch: 3293, train precision: 0.914556, train loss: 34.015076, valid precision: 0.753600, valid loss: 190.743358
epoch: 3294, train precision: 0.482267, train loss: 215.566994, valid precision: 0.476400, valid loss: 229.990305
epoch: 3295, train precision: 0.849289, train loss: 59.920305, valid precision: 0.715400, valid loss: 162.487041
epoch: 3296, train precision: 0.914156, train loss: 34.391214, valid precision: 0.749400, valid loss: 155.740831
epoch: 3297, train precision: 0.894778, train loss: 41.549933, valid precision: 0.747400, valid loss: 172.031160
epoch: 3298, train precision: 0.909267, train loss: 35.272446, valid precision: 0.749000, valid loss: 166.324136
epoch: 3299, train precision: 0.678933, train loss: 136.624152, valid precision: 0.634000, valid loss: 177.890954
epoch: 3300, train precision: 0.919667, train loss: 32.997893, valid precision: 0.755000, valid loss: 153.422423
epoch: 3301, train precision: 0.920689, train loss: 31.188484, valid precision: 0.755200, valid loss: 152.345343
epoch: 3302, train precision: 0.919022, train loss: 33.264014, valid precision: 0.755000, valid loss: 160.924747
epoch: 3303, train precision: 0.379733, train loss: 279.207442, valid precision: 0.386000, valid loss: 275.689014
epoch: 3304, train precision: 0.888444, train loss: 45.284529, valid precision: 0.737200, valid loss: 209.056782
epoch: 3305, train precision: 0.920133, train loss: 30.759826, valid precision: 0.750600, valid loss: 223.707063
epoch: 3306, train precision: 0.917578, train loss: 36.518185, valid precision: 0.747200, valid loss: 202.370480
epoch: 3307, train precision: 0.177733, train loss: 471.017012, valid precision: 0.190200, valid loss: 463.886213
epoch: 3308, train precision: 0.366756, train loss: 217.646389, valid precision: 0.374000, valid loss: 219.564239
epoch: 3309, train precision: 0.522044, train loss: 168.084271, valid precision: 0.497200, valid loss: 178.004729
epoch: 3310, train precision: 0.870311, train loss: 51.447797, valid precision: 0.735200, valid loss: 135.472450
epoch: 3311, train precision: 0.837111, train loss: 63.176617, valid precision: 0.718000, valid loss: 142.334929
epoch: 3312, train precision: 0.906978, train loss: 37.166492, valid precision: 0.746600, valid loss: 148.559826
epoch: 3313, train precision: 0.923156, train loss: 33.640421, valid precision: 0.747400, valid loss: 196.847933
epoch: 3314, train precision: 0.915911, train loss: 33.440412, valid precision: 0.744000, valid loss: 229.138902
epoch: 3315, train precision: 0.853822, train loss: 57.112996, valid precision: 0.721200, valid loss: 161.571685
epoch: 3316, train precision: 0.903556, train loss: 37.596620, valid precision: 0.739200, valid loss: 276.425040
epoch: 3317, train precision: 0.899222, train loss: 41.516323, valid precision: 0.739400, valid loss: 216.298151
epoch: 3318, train precision: 0.890133, train loss: 43.331228, valid precision: 0.742000, valid loss: 199.944372
epoch: 3319, train precision: 0.918600, train loss: 32.288397, valid precision: 0.759600, valid loss: 244.687309
epoch: 3320, train precision: 0.886178, train loss: 44.971356, valid precision: 0.735600, valid loss: 172.297558
epoch: 3321, train precision: 0.788800, train loss: 85.047478, valid precision: 0.710600, valid loss: 137.885994
epoch: 3322, train precision: 0.907889, train loss: 36.574736, valid precision: 0.751800, valid loss: 154.537868
epoch: 3323, train precision: 0.902600, train loss: 37.417211, valid precision: 0.754800, valid loss: 153.759289
epoch: 3324, train precision: 0.913156, train loss: 40.246949, valid precision: 0.745400, valid loss: 189.433699
epoch: 3325, train precision: 0.899822, train loss: 40.794813, valid precision: 0.744000, valid loss: 160.325834
epoch: 3326, train precision: 0.706089, train loss: 117.060832, valid precision: 0.656800, valid loss: 156.437303
epoch: 3327, train precision: 0.911933, train loss: 35.158416, valid precision: 0.753600, valid loss: 160.074872
epoch: 3328, train precision: 0.931244, train loss: 28.135692, valid precision: 0.757800, valid loss: 152.623595
epoch: 3329, train precision: 0.915978, train loss: 36.024179, valid precision: 0.756600, valid loss: 156.087894
epoch: 3330, train precision: 0.900356, train loss: 39.647615, valid precision: 0.744000, valid loss: 162.040446
epoch: 3331, train precision: 0.906800, train loss: 36.460079, valid precision: 0.747200, valid loss: 166.332725
epoch: 3332, train precision: 0.919333, train loss: 32.136011, valid precision: 0.756000, valid loss: 161.568969
epoch: 3333, train precision: 0.871200, train loss: 49.857981, valid precision: 0.738400, valid loss: 134.012098
epoch: 3334, train precision: 0.911089, train loss: 35.171908, valid precision: 0.751600, valid loss: 153.778554
epoch: 3335, train precision: 0.891867, train loss: 42.348034, valid precision: 0.740200, valid loss: 174.577322
epoch: 3336, train precision: 0.909422, train loss: 36.160358, valid precision: 0.743000, valid loss: 306.642358
epoch: 3337, train precision: 0.908222, train loss: 35.492233, valid precision: 0.750200, valid loss: 151.376240
epoch: 3338, train precision: 0.895644, train loss: 41.358418, valid precision: 0.734400, valid loss: 171.960047
epoch: 3339, train precision: 0.910400, train loss: 36.337608, valid precision: 0.745200, valid loss: 264.745276
epoch: 3340, train precision: 0.934111, train loss: 28.083072, valid precision: 0.759000, valid loss: 188.962674
epoch: 3341, train precision: 0.889511, train loss: 44.068092, valid precision: 0.738000, valid loss: 167.515590
epoch: 3342, train precision: 0.888600, train loss: 43.483731, valid precision: 0.738800, valid loss: 165.176520
epoch: 3343, train precision: 0.910756, train loss: 34.522551, valid precision: 0.745400, valid loss: 193.359760
epoch: 3344, train precision: 0.918178, train loss: 32.810399, valid precision: 0.751400, valid loss: 153.151737
epoch: 3345, train precision: 0.927556, train loss: 29.291002, valid precision: 0.751800, valid loss: 151.664424
epoch: 3346, train precision: 0.886244, train loss: 46.844127, valid precision: 0.752400, valid loss: 141.741391
epoch: 3347, train precision: 0.890178, train loss: 44.754664, valid precision: 0.743200, valid loss: 184.137566
epoch: 3348, train precision: 0.903933, train loss: 37.540446, valid precision: 0.742000, valid loss: 168.733615
epoch: 3349, train precision: 0.815178, train loss: 75.517540, valid precision: 0.716400, valid loss: 152.918210
epoch: 3350, train precision: 0.854133, train loss: 61.566602, valid precision: 0.720200, valid loss: 224.389865
epoch: 3351, train precision: 0.930333, train loss: 29.812769, valid precision: 0.753200, valid loss: 230.356964
epoch: 3352, train precision: 0.906422, train loss: 38.795149, valid precision: 0.737200, valid loss: 376.510568
epoch: 3353, train precision: 0.486333, train loss: 193.259194, valid precision: 0.498200, valid loss: 200.541187
epoch: 3354, train precision: 0.879111, train loss: 51.504005, valid precision: 0.735200, valid loss: 153.173639
epoch: 3355, train precision: 0.911533, train loss: 37.973987, valid precision: 0.742600, valid loss: 181.636114
epoch: 3356, train precision: 0.935511, train loss: 26.904986, valid precision: 0.759400, valid loss: 156.673256
epoch: 3357, train precision: 0.917089, train loss: 32.061664, valid precision: 0.753200, valid loss: 165.602260
epoch: 3358, train precision: 0.354622, train loss: 233.712916, valid precision: 0.356600, valid loss: 234.588357
epoch: 3359, train precision: 0.554822, train loss: 156.946493, valid precision: 0.552600, valid loss: 166.456593
epoch: 3360, train precision: 0.748800, train loss: 87.277171, valid precision: 0.684200, valid loss: 140.650377
epoch: 3361, train precision: 0.523533, train loss: 166.594019, valid precision: 0.521000, valid loss: 168.274800
epoch: 3362, train precision: 0.612044, train loss: 133.472492, valid precision: 0.592600, valid loss: 149.444497
epoch: 3363, train precision: 0.723733, train loss: 96.038139, valid precision: 0.665600, valid loss: 141.994222
epoch: 3364, train precision: 0.777933, train loss: 74.862661, valid precision: 0.687600, valid loss: 138.902546
epoch: 3365, train precision: 0.816267, train loss: 62.191428, valid precision: 0.700600, valid loss: 134.035439
epoch: 3366, train precision: 0.817067, train loss: 69.740804, valid precision: 0.692400, valid loss: 261.174876
epoch: 3367, train precision: 0.783889, train loss: 87.615140, valid precision: 0.674600, valid loss: 144.237006
epoch: 3368, train precision: 0.822156, train loss: 60.853017, valid precision: 0.704200, valid loss: 150.481633
epoch: 3369, train precision: 0.828067, train loss: 61.158717, valid precision: 0.705000, valid loss: 154.279978
epoch: 3370, train precision: 0.255578, train loss: 720.708784, valid precision: 0.258000, valid loss: 312.794226
epoch: 3371, train precision: 0.268022, train loss: 247.503045, valid precision: 0.289400, valid loss: 244.909715
epoch: 3372, train precision: 0.271978, train loss: 244.805801, valid precision: 0.284600, valid loss: 242.577955
epoch: 3373, train precision: 0.324311, train loss: 229.942944, valid precision: 0.339600, valid loss: 228.229615
epoch: 3374, train precision: 0.383289, train loss: 211.763958, valid precision: 0.393000, valid loss: 214.567805
epoch: 3375, train precision: 0.521911, train loss: 179.849757, valid precision: 0.522800, valid loss: 187.572560
epoch: 3376, train precision: 0.627622, train loss: 131.065747, valid precision: 0.607600, valid loss: 149.492303
epoch: 3377, train precision: 0.759578, train loss: 85.642835, valid precision: 0.681600, valid loss: 146.759224
epoch: 3378, train precision: 0.722511, train loss: 96.396264, valid precision: 0.653800, valid loss: 146.973467
epoch: 3379, train precision: 0.804578, train loss: 68.059654, valid precision: 0.699400, valid loss: 134.523579
epoch: 3380, train precision: 0.813378, train loss: 67.611221, valid precision: 0.714200, valid loss: 147.259437
epoch: 3381, train precision: 0.616689, train loss: 141.578295, valid precision: 0.594000, valid loss: 175.253680
epoch: 3382, train precision: 0.762311, train loss: 89.252625, valid precision: 0.684600, valid loss: 153.770081
epoch: 3383, train precision: 0.797822, train loss: 72.799825, valid precision: 0.695000, valid loss: 147.515459
epoch: 3384, train precision: 0.839556, train loss: 57.612389, valid precision: 0.730600, valid loss: 141.429518
epoch: 3385, train precision: 0.852356, train loss: 54.952449, valid precision: 0.724800, valid loss: 139.999326
epoch: 3386, train precision: 0.870289, train loss: 47.919707, valid precision: 0.735600, valid loss: 143.945955
epoch: 3387, train precision: 0.872111, train loss: 46.929913, valid precision: 0.736600, valid loss: 146.902292
epoch: 3388, train precision: 0.866911, train loss: 48.839595, valid precision: 0.726200, valid loss: 150.144636
epoch: 3389, train precision: 0.868000, train loss: 48.580493, valid precision: 0.725800, valid loss: 161.654097
epoch: 3390, train precision: 0.866511, train loss: 49.827731, valid precision: 0.723800, valid loss: 160.339004
epoch: 3391, train precision: 0.858178, train loss: 51.740430, valid precision: 0.723600, valid loss: 158.140718
epoch: 3392, train precision: 0.867844, train loss: 50.631141, valid precision: 0.734400, valid loss: 165.538981
epoch: 3393, train precision: 0.863111, train loss: 50.098638, valid precision: 0.719600, valid loss: 157.677174
epoch: 3394, train precision: 0.865133, train loss: 49.193059, valid precision: 0.723000, valid loss: 160.319318
epoch: 3395, train precision: 0.882444, train loss: 42.838550, valid precision: 0.735400, valid loss: 162.815809
epoch: 3396, train precision: 0.421111, train loss: 232.838150, valid precision: 0.437000, valid loss: 231.168159
epoch: 3397, train precision: 0.800156, train loss: 86.427646, valid precision: 0.698400, valid loss: 152.148142
epoch: 3398, train precision: 0.830689, train loss: 66.482824, valid precision: 0.732800, valid loss: 140.967645
epoch: 3399, train precision: 0.862067, train loss: 52.297924, valid precision: 0.726400, valid loss: 148.085514
epoch: 3400, train precision: 0.872022, train loss: 46.696728, valid precision: 0.723800, valid loss: 150.999465
epoch: 3401, train precision: 0.809378, train loss: 70.787354, valid precision: 0.709400, valid loss: 145.077878
epoch: 3402, train precision: 0.798378, train loss: 77.099647, valid precision: 0.708000, valid loss: 144.347905
epoch: 3403, train precision: 0.873111, train loss: 46.941766, valid precision: 0.740200, valid loss: 137.419300
epoch: 3404, train precision: 0.847956, train loss: 55.827749, valid precision: 0.722200, valid loss: 145.810977
epoch: 3405, train precision: 0.876378, train loss: 45.353047, valid precision: 0.722600, valid loss: 149.383724
epoch: 3406, train precision: 0.854933, train loss: 56.273087, valid precision: 0.713600, valid loss: 162.605989
epoch: 3407, train precision: 0.864778, train loss: 48.299741, valid precision: 0.725400, valid loss: 147.821637
epoch: 3408, train precision: 0.882044, train loss: 43.939835, valid precision: 0.737000, valid loss: 162.146029
epoch: 3409, train precision: 0.874800, train loss: 44.644230, valid precision: 0.732200, valid loss: 148.383659
epoch: 3410, train precision: 0.845000, train loss: 58.280819, valid precision: 0.712200, valid loss: 171.451207
epoch: 3411, train precision: 0.860911, train loss: 50.378582, valid precision: 0.719600, valid loss: 164.510948
epoch: 3412, train precision: 0.651689, train loss: 124.439289, valid precision: 0.606600, valid loss: 150.867019
epoch: 3413, train precision: 0.860600, train loss: 50.290135, valid precision: 0.726000, valid loss: 150.295096
epoch: 3414, train precision: 0.866556, train loss: 48.698916, valid precision: 0.731200, valid loss: 147.234896
epoch: 3415, train precision: 0.873778, train loss: 46.198668, valid precision: 0.729400, valid loss: 156.499964
epoch: 3416, train precision: 0.875378, train loss: 47.905824, valid precision: 0.726000, valid loss: 165.975804
epoch: 3417, train precision: 0.890622, train loss: 40.478454, valid precision: 0.736200, valid loss: 146.342080
epoch: 3418, train precision: 0.882756, train loss: 45.374030, valid precision: 0.729800, valid loss: 191.442773
epoch: 3419, train precision: 0.881378, train loss: 47.125577, valid precision: 0.729000, valid loss: 190.182749
epoch: 3420, train precision: 0.171444, train loss: 278.809498, valid precision: 0.167000, valid loss: 277.678394
epoch: 3421, train precision: 0.244111, train loss: 248.413987, valid precision: 0.230400, valid loss: 249.356311
epoch: 3422, train precision: 0.511289, train loss: 170.494454, valid precision: 0.502200, valid loss: 184.776566
epoch: 3423, train precision: 0.748711, train loss: 96.170839, valid precision: 0.681400, valid loss: 145.662455
epoch: 3424, train precision: 0.840178, train loss: 58.971231, valid precision: 0.712800, valid loss: 152.790196
epoch: 3425, train precision: 0.716489, train loss: 106.505051, valid precision: 0.666800, valid loss: 140.125623
epoch: 3426, train precision: 0.826400, train loss: 64.735168, valid precision: 0.718800, valid loss: 137.646769
epoch: 3427, train precision: 0.870867, train loss: 47.782554, valid precision: 0.742000, valid loss: 150.773038
epoch: 3428, train precision: 0.850578, train loss: 55.509431, valid precision: 0.715600, valid loss: 169.754438
epoch: 3429, train precision: 0.794022, train loss: 77.332345, valid precision: 0.708600, valid loss: 148.550024
epoch: 3430, train precision: 0.866444, train loss: 49.548247, valid precision: 0.726400, valid loss: 175.889603
epoch: 3431, train precision: 0.887867, train loss: 43.247082, valid precision: 0.738200, valid loss: 177.603291
epoch: 3432, train precision: 0.883156, train loss: 42.275873, valid precision: 0.728600, valid loss: 175.612563
epoch: 3433, train precision: 0.199044, train loss: 285.492818, valid precision: 0.204000, valid loss: 286.229693
epoch: 3434, train precision: 0.457044, train loss: 171.835875, valid precision: 0.452600, valid loss: 186.236786
epoch: 3435, train precision: 0.757511, train loss: 91.569522, valid precision: 0.666800, valid loss: 155.895752
epoch: 3436, train precision: 0.839356, train loss: 63.030788, valid precision: 0.712800, valid loss: 170.011396
epoch: 3437, train precision: 0.856111, train loss: 56.189470, valid precision: 0.726600, valid loss: 151.942521
epoch: 3438, train precision: 0.886622, train loss: 42.321952, valid precision: 0.743800, valid loss: 143.616549
epoch: 3439, train precision: 0.858867, train loss: 51.179633, valid precision: 0.723400, valid loss: 163.030357
epoch: 3440, train precision: 0.887000, train loss: 42.656440, valid precision: 0.734000, valid loss: 154.736267
epoch: 3441, train precision: 0.809644, train loss: 75.375637, valid precision: 0.711600, valid loss: 150.871616
epoch: 3442, train precision: 0.870467, train loss: 46.596389, valid precision: 0.731800, valid loss: 146.141391
epoch: 3443, train precision: 0.874067, train loss: 47.020402, valid precision: 0.728200, valid loss: 154.142226
epoch: 3444, train precision: 0.820378, train loss: 72.477724, valid precision: 0.700200, valid loss: 167.054692
epoch: 3445, train precision: 0.870867, train loss: 48.202243, valid precision: 0.725800, valid loss: 164.036135
epoch: 3446, train precision: 0.891578, train loss: 43.125845, valid precision: 0.742200, valid loss: 147.785473
epoch: 3447, train precision: 0.745956, train loss: 101.950891, valid precision: 0.688200, valid loss: 147.277661
epoch: 3448, train precision: 0.839178, train loss: 61.728735, valid precision: 0.716200, valid loss: 152.615304
epoch: 3449, train precision: 0.865578, train loss: 50.452119, valid precision: 0.725200, valid loss: 154.588698
epoch: 3450, train precision: 0.892533, train loss: 40.671641, valid precision: 0.739200, valid loss: 159.204867
epoch: 3451, train precision: 0.887911, train loss: 41.313410, valid precision: 0.739200, valid loss: 150.934665
epoch: 3452, train precision: 0.879156, train loss: 46.101139, valid precision: 0.729600, valid loss: 154.884318
epoch: 3453, train precision: 0.896800, train loss: 39.168413, valid precision: 0.743600, valid loss: 145.681606
epoch: 3454, train precision: 0.774489, train loss: 89.368656, valid precision: 0.695400, valid loss: 150.506197
epoch: 3455, train precision: 0.881711, train loss: 43.827486, valid precision: 0.741400, valid loss: 141.007997
epoch: 3456, train precision: 0.844889, train loss: 61.580436, valid precision: 0.720800, valid loss: 167.652411
epoch: 3457, train precision: 0.884311, train loss: 42.566076, valid precision: 0.733600, valid loss: 146.174518
epoch: 3458, train precision: 0.895022, train loss: 39.401532, valid precision: 0.747200, valid loss: 164.527125
epoch: 3459, train precision: 0.912711, train loss: 33.205062, valid precision: 0.755600, valid loss: 169.580588
epoch: 3460, train precision: 0.893867, train loss: 39.756021, valid precision: 0.737200, valid loss: 185.529505
epoch: 3461, train precision: 0.895756, train loss: 39.460059, valid precision: 0.735800, valid loss: 219.499761
epoch: 3462, train precision: 0.810511, train loss: 73.626931, valid precision: 0.715400, valid loss: 147.499400
epoch: 3463, train precision: 0.862022, train loss: 50.741363, valid precision: 0.738600, valid loss: 156.303260
epoch: 3464, train precision: 0.782400, train loss: 84.503359, valid precision: 0.690600, valid loss: 151.755600
epoch: 3465, train precision: 0.729733, train loss: 101.040604, valid precision: 0.653600, valid loss: 146.898112
epoch: 3466, train precision: 0.844733, train loss: 58.616053, valid precision: 0.721200, valid loss: 164.905946
epoch: 3467, train precision: 0.884200, train loss: 46.369226, valid precision: 0.734000, valid loss: 152.116801
epoch: 3468, train precision: 0.876489, train loss: 44.371115, valid precision: 0.727400, valid loss: 159.842926
epoch: 3469, train precision: 0.881400, train loss: 45.080743, valid precision: 0.742000, valid loss: 161.735427
epoch: 3470, train precision: 0.894111, train loss: 38.917304, valid precision: 0.738800, valid loss: 152.491443
epoch: 3471, train precision: 0.896689, train loss: 37.603795, valid precision: 0.740600, valid loss: 270.325334
epoch: 3472, train precision: 0.864711, train loss: 49.710109, valid precision: 0.721800, valid loss: 167.957691
epoch: 3473, train precision: 0.883489, train loss: 43.756923, valid precision: 0.734600, valid loss: 194.332903
epoch: 3474, train precision: 0.905044, train loss: 36.128712, valid precision: 0.739600, valid loss: 203.421178
epoch: 3475, train precision: 0.857111, train loss: 54.155721, valid precision: 0.720800, valid loss: 157.860706
epoch: 3476, train precision: 0.889778, train loss: 41.116055, valid precision: 0.741600, valid loss: 377.210684
epoch: 3477, train precision: 0.888689, train loss: 41.314158, valid precision: 0.742200, valid loss: 216.504097
epoch: 3478, train precision: 0.907022, train loss: 36.172336, valid precision: 0.748400, valid loss: 233.567833
epoch: 3479, train precision: 0.857600, train loss: 54.720983, valid precision: 0.730200, valid loss: 212.847431
epoch: 3480, train precision: 0.267400, train loss: 263.503345, valid precision: 0.268000, valid loss: 259.674030
epoch: 3481, train precision: 0.426111, train loss: 181.464099, valid precision: 0.424400, valid loss: 187.895809
epoch: 3482, train precision: 0.503067, train loss: 150.978054, valid precision: 0.480200, valid loss: 179.162227
epoch: 3483, train precision: 0.866400, train loss: 50.202681, valid precision: 0.726600, valid loss: 157.006653
epoch: 3484, train precision: 0.881222, train loss: 43.244438, valid precision: 0.730600, valid loss: 155.150989
epoch: 3485, train precision: 0.891889, train loss: 39.443856, valid precision: 0.739400, valid loss: 158.623884
epoch: 3486, train precision: 0.891556, train loss: 40.516775, valid precision: 0.740800, valid loss: 153.134853
epoch: 3487, train precision: 0.661311, train loss: 138.458558, valid precision: 0.629400, valid loss: 167.831880
epoch: 3488, train precision: 0.892511, train loss: 41.189947, valid precision: 0.746000, valid loss: 141.057994
epoch: 3489, train precision: 0.872356, train loss: 47.871166, valid precision: 0.735600, valid loss: 150.443869
epoch: 3490, train precision: 0.899200, train loss: 37.508947, valid precision: 0.737800, valid loss: 145.301912
epoch: 3491, train precision: 0.894267, train loss: 39.353381, valid precision: 0.737400, valid loss: 159.252400
epoch: 3492, train precision: 0.842244, train loss: 58.448614, valid precision: 0.725600, valid loss: 155.333132
epoch: 3493, train precision: 0.898667, train loss: 43.539128, valid precision: 0.740400, valid loss: 167.650827
epoch: 3494, train precision: 0.598000, train loss: 211.432262, valid precision: 0.569400, valid loss: 256.950857
epoch: 3495, train precision: 0.863444, train loss: 52.644255, valid precision: 0.731000, valid loss: 158.978938
epoch: 3496, train precision: 0.868022, train loss: 49.312563, valid precision: 0.731000, valid loss: 147.740812
epoch: 3497, train precision: 0.901667, train loss: 38.117772, valid precision: 0.740600, valid loss: 147.234885
epoch: 3498, train precision: 0.906267, train loss: 34.927822, valid precision: 0.743000, valid loss: 152.830105
epoch: 3499, train precision: 0.867889, train loss: 46.725226, valid precision: 0.723600, valid loss: 178.311400
epoch: 3500, train precision: 0.878800, train loss: 46.208022, valid precision: 0.736800, valid loss: 174.159975
epoch: 3501, train precision: 0.493689, train loss: 174.115502, valid precision: 0.484600, valid loss: 194.889119
epoch: 3502, train precision: 0.830511, train loss: 68.667704, valid precision: 0.731400, valid loss: 148.470736
epoch: 3503, train precision: 0.903133, train loss: 37.503848, valid precision: 0.748800, valid loss: 159.609031
epoch: 3504, train precision: 0.858600, train loss: 52.993064, valid precision: 0.723400, valid loss: 178.263100
epoch: 3505, train precision: 0.884067, train loss: 43.421940, valid precision: 0.730600, valid loss: 171.470712
epoch: 3506, train precision: 0.893889, train loss: 39.245093, valid precision: 0.747200, valid loss: 167.984427
epoch: 3507, train precision: 0.818800, train loss: 68.681902, valid precision: 0.714400, valid loss: 153.080056
epoch: 3508, train precision: 0.892044, train loss: 39.619476, valid precision: 0.743200, valid loss: 146.776407
epoch: 3509, train precision: 0.898689, train loss: 37.935019, valid precision: 0.742400, valid loss: 167.346691
epoch: 3510, train precision: 0.909578, train loss: 33.857534, valid precision: 0.751000, valid loss: 157.330429
epoch: 3511, train precision: 0.880200, train loss: 44.017458, valid precision: 0.733600, valid loss: 229.802332
epoch: 3512, train precision: 0.884778, train loss: 46.932274, valid precision: 0.731200, valid loss: 256.827425
epoch: 3513, train precision: 0.868289, train loss: 47.255974, valid precision: 0.725000, valid loss: 150.083151
epoch: 3514, train precision: 0.874867, train loss: 48.408866, valid precision: 0.735000, valid loss: 161.623627
epoch: 3515, train precision: 0.907422, train loss: 34.081121, valid precision: 0.745600, valid loss: 159.200620
epoch: 3516, train precision: 0.373400, train loss: 211.758958, valid precision: 0.389600, valid loss: 211.472966
epoch: 3517, train precision: 0.362311, train loss: 220.803929, valid precision: 0.365800, valid loss: 219.618084
epoch: 3518, train precision: 0.725156, train loss: 103.865507, valid precision: 0.660800, valid loss: 164.130449
epoch: 3519, train precision: 0.567533, train loss: 166.289344, valid precision: 0.552400, valid loss: 181.213587
epoch: 3520, train precision: 0.865800, train loss: 49.651206, valid precision: 0.725400, valid loss: 260.380346
epoch: 3521, train precision: 0.894022, train loss: 41.223170, valid precision: 0.745800, valid loss: 343.354104
epoch: 3522, train precision: 0.883044, train loss: 59.172361, valid precision: 0.736600, valid loss: 2087.886430
epoch: 3523, train precision: 0.880222, train loss: 45.721381, valid precision: 0.732800, valid loss: 156.014148
epoch: 3524, train precision: 0.864844, train loss: 47.820827, valid precision: 0.728200, valid loss: 151.766619
epoch: 3525, train precision: 0.892622, train loss: 41.840003, valid precision: 0.740800, valid loss: 156.179990
epoch: 3526, train precision: 0.843533, train loss: 56.823004, valid precision: 0.721600, valid loss: 148.551279
epoch: 3527, train precision: 0.893889, train loss: 40.223898, valid precision: 0.742200, valid loss: 149.306278
epoch: 3528, train precision: 0.906911, train loss: 35.212025, valid precision: 0.747400, valid loss: 144.103673
epoch: 3529, train precision: 0.875933, train loss: 50.323630, valid precision: 0.727400, valid loss: 170.039653
epoch: 3530, train precision: 0.866956, train loss: 49.367992, valid precision: 0.717600, valid loss: 166.328080
epoch: 3531, train precision: 0.913067, train loss: 34.594119, valid precision: 0.748000, valid loss: 166.583194
epoch: 3532, train precision: 0.758111, train loss: 95.963594, valid precision: 0.687600, valid loss: 153.491204
epoch: 3533, train precision: 0.899289, train loss: 39.351109, valid precision: 0.732200, valid loss: 181.802514
epoch: 3534, train precision: 0.880778, train loss: 44.501927, valid precision: 0.726200, valid loss: 214.783258
epoch: 3535, train precision: 0.911889, train loss: 34.136220, valid precision: 0.745000, valid loss: 370.052342
epoch: 3536, train precision: 0.899067, train loss: 38.146211, valid precision: 0.738400, valid loss: 350.488754
epoch: 3537, train precision: 0.827044, train loss: 68.683227, valid precision: 0.714000, valid loss: 157.479943
epoch: 3538, train precision: 0.897267, train loss: 38.731157, valid precision: 0.733400, valid loss: 162.577348
epoch: 3539, train precision: 0.900667, train loss: 128.085704, valid precision: 0.735600, valid loss: 177.892650
epoch: 3540, train precision: 0.839689, train loss: 62.449913, valid precision: 0.714600, valid loss: 179.115142
epoch: 3541, train precision: 0.904378, train loss: 36.059702, valid precision: 0.740200, valid loss: 181.873947
epoch: 3542, train precision: 0.886067, train loss: 42.399730, valid precision: 0.737200, valid loss: 147.141755
epoch: 3543, train precision: 0.889956, train loss: 40.178854, valid precision: 0.738200, valid loss: 165.580605
epoch: 3544, train precision: 0.912022, train loss: 33.888468, valid precision: 0.743800, valid loss: 197.424224
epoch: 3545, train precision: 0.455111, train loss: 210.610431, valid precision: 0.443200, valid loss: 216.666950
epoch: 3546, train precision: 0.891311, train loss: 41.440437, valid precision: 0.744400, valid loss: 153.414317
epoch: 3547, train precision: 0.889244, train loss: 43.043046, valid precision: 0.732600, valid loss: 152.790739
epoch: 3548, train precision: 0.870756, train loss: 49.141434, valid precision: 0.717800, valid loss: 181.933889
epoch: 3549, train precision: 0.547778, train loss: 196.938420, valid precision: 0.524400, valid loss: 236.923688
epoch: 3550, train precision: 0.678244, train loss: 136.326294, valid precision: 0.620800, valid loss: 188.574913
epoch: 3551, train precision: 0.897489, train loss: 38.802930, valid precision: 0.740400, valid loss: 148.341646
epoch: 3552, train precision: 0.911400, train loss: 33.680634, valid precision: 0.745800, valid loss: 155.691874
epoch: 3553, train precision: 0.884667, train loss: 42.854423, valid precision: 0.730800, valid loss: 158.000596
epoch: 3554, train precision: 0.868533, train loss: 46.849047, valid precision: 0.724800, valid loss: 181.303957
epoch: 3555, train precision: 0.896800, train loss: 39.717585, valid precision: 0.747200, valid loss: 182.293691
epoch: 3556, train precision: 0.813556, train loss: 73.076322, valid precision: 0.730200, valid loss: 134.288793
epoch: 3557, train precision: 0.359533, train loss: 221.676694, valid precision: 0.356200, valid loss: 222.720620
epoch: 3558, train precision: 0.659956, train loss: 124.108018, valid precision: 0.607400, valid loss: 162.824957
epoch: 3559, train precision: 0.874422, train loss: 48.288791, valid precision: 0.735400, valid loss: 142.877702
epoch: 3560, train precision: 0.875311, train loss: 47.200350, valid precision: 0.726200, valid loss: 162.903284
epoch: 3561, train precision: 0.867978, train loss: 52.085250, valid precision: 0.726000, valid loss: 181.733691
epoch: 3562, train precision: 0.808267, train loss: 78.454116, valid precision: 0.692400, valid loss: 167.211303
epoch: 3563, train precision: 0.874067, train loss: 47.180492, valid precision: 0.721400, valid loss: 155.160399
epoch: 3564, train precision: 0.894933, train loss: 39.078069, valid precision: 0.737200, valid loss: 168.631185
epoch: 3565, train precision: 0.913889, train loss: 32.805445, valid precision: 0.751800, valid loss: 159.296599
epoch: 3566, train precision: 0.403600, train loss: 211.726060, valid precision: 0.411000, valid loss: 213.482072
epoch: 3567, train precision: 0.506511, train loss: 177.680850, valid precision: 0.501600, valid loss: 186.970948
epoch: 3568, train precision: 0.827911, train loss: 69.771901, valid precision: 0.714800, valid loss: 159.146544
epoch: 3569, train precision: 0.834511, train loss: 61.163182, valid precision: 0.714200, valid loss: 142.888461
epoch: 3570, train precision: 0.850756, train loss: 56.853238, valid precision: 0.713200, valid loss: 166.882593
epoch: 3571, train precision: 0.858378, train loss: 55.077044, valid precision: 0.718400, valid loss: 156.005718
epoch: 3572, train precision: 0.153800, train loss: 398.453184, valid precision: 0.157200, valid loss: 399.096922
epoch: 3573, train precision: 0.285844, train loss: 238.548387, valid precision: 0.276600, valid loss: 237.549206
epoch: 3574, train precision: 0.371156, train loss: 203.128400, valid precision: 0.375800, valid loss: 205.044996
epoch: 3575, train precision: 0.461711, train loss: 171.841104, valid precision: 0.451800, valid loss: 180.632111
epoch: 3576, train precision: 0.588667, train loss: 159.602250, valid precision: 0.573800, valid loss: 178.245508
epoch: 3577, train precision: 0.797511, train loss: 74.661940, valid precision: 0.700800, valid loss: 139.233690
epoch: 3578, train precision: 0.859244, train loss: 53.976992, valid precision: 0.728000, valid loss: 142.760882
epoch: 3579, train precision: 0.871978, train loss: 49.489678, valid precision: 0.734800, valid loss: 137.650043
epoch: 3580, train precision: 0.893756, train loss: 40.311273, valid precision: 0.742400, valid loss: 144.556358
epoch: 3581, train precision: 0.815467, train loss: 70.744034, valid precision: 0.720000, valid loss: 136.100017
epoch: 3582, train precision: 0.858289, train loss: 52.648711, valid precision: 0.721600, valid loss: 146.634031
epoch: 3583, train precision: 0.752578, train loss: 99.316401, valid precision: 0.674800, valid loss: 162.967784
epoch: 3584, train precision: 0.900822, train loss: 38.769244, valid precision: 0.749800, valid loss: 153.901020
epoch: 3585, train precision: 0.879578, train loss: 44.993853, valid precision: 0.726000, valid loss: 167.571076
epoch: 3586, train precision: 0.876067, train loss: 46.081267, valid precision: 0.730600, valid loss: 171.092991
epoch: 3587, train precision: 0.852200, train loss: 55.024645, valid precision: 0.726000, valid loss: 151.099230
epoch: 3588, train precision: 0.842489, train loss: 56.986029, valid precision: 0.716800, valid loss: 171.284674
epoch: 3589, train precision: 0.817156, train loss: 71.292297, valid precision: 0.702000, valid loss: 158.300249
epoch: 3590, train precision: 0.889644, train loss: 40.879444, valid precision: 0.735600, valid loss: 160.849457
epoch: 3591, train precision: 0.871511, train loss: 47.239536, valid precision: 0.718800, valid loss: 166.263020
epoch: 3592, train precision: 0.896000, train loss: 38.355174, valid precision: 0.736600, valid loss: 172.162222
epoch: 3593, train precision: 0.898000, train loss: 41.107010, valid precision: 0.738200, valid loss: 165.553092
epoch: 3594, train precision: 0.702289, train loss: 115.298747, valid precision: 0.626400, valid loss: 176.233233
epoch: 3595, train precision: 0.398978, train loss: 216.858944, valid precision: 0.399200, valid loss: 218.758258
epoch: 3596, train precision: 0.590222, train loss: 141.727907, valid precision: 0.546000, valid loss: 174.071552
epoch: 3597, train precision: 0.190222, train loss: 280.067704, valid precision: 0.187800, valid loss: 276.138681
epoch: 3598, train precision: 0.311133, train loss: 224.546705, valid precision: 0.326200, valid loss: 223.758132
epoch: 3599, train precision: 0.359156, train loss: 214.707996, valid precision: 0.369400, valid loss: 215.547922
epoch: 3600, train precision: 0.388556, train loss: 207.543866, valid precision: 0.385400, valid loss: 210.903481
epoch: 3601, train precision: 0.443489, train loss: 187.930304, valid precision: 0.439600, valid loss: 194.092747
epoch: 3602, train precision: 0.498156, train loss: 171.409504, valid precision: 0.479800, valid loss: 185.569975
epoch: 3603, train precision: 0.587556, train loss: 145.687128, valid precision: 0.545200, valid loss: 175.632950
epoch: 3604, train precision: 0.634622, train loss: 137.566883, valid precision: 0.568400, valid loss: 175.877598
epoch: 3605, train precision: 0.518400, train loss: 163.465712, valid precision: 0.505000, valid loss: 178.670644
epoch: 3606, train precision: 0.606311, train loss: 135.225424, valid precision: 0.554200, valid loss: 167.901972
epoch: 3607, train precision: 0.671400, train loss: 115.991398, valid precision: 0.608800, valid loss: 163.905612
epoch: 3608, train precision: 0.643911, train loss: 131.153236, valid precision: 0.584000, valid loss: 204.130033
epoch: 3609, train precision: 0.725356, train loss: 97.931823, valid precision: 0.627200, valid loss: 181.010046
epoch: 3610, train precision: 0.701711, train loss: 107.105599, valid precision: 0.609600, valid loss: 208.774888
epoch: 3611, train precision: 0.250156, train loss: 265.122965, valid precision: 0.259400, valid loss: 260.851345
epoch: 3612, train precision: 0.363978, train loss: 219.407729, valid precision: 0.370200, valid loss: 218.799082
epoch: 3613, train precision: 0.420111, train loss: 204.055217, valid precision: 0.434800, valid loss: 195.291001
epoch: 3614, train precision: 0.365711, train loss: 207.822775, valid precision: 0.374600, valid loss: 207.718181
epoch: 3615, train precision: 0.463267, train loss: 180.139040, valid precision: 0.475800, valid loss: 182.198331
epoch: 3616, train precision: 0.521244, train loss: 160.982812, valid precision: 0.516000, valid loss: 365.338433
epoch: 3617, train precision: 0.611044, train loss: 133.205976, valid precision: 0.561000, valid loss: 358.319961
epoch: 3618, train precision: 0.659556, train loss: 121.630006, valid precision: 0.602600, valid loss: 158.611557
epoch: 3619, train precision: 0.721489, train loss: 104.283268, valid precision: 0.638000, valid loss: 228.141056
epoch: 3620, train precision: 0.750533, train loss: 91.410057, valid precision: 0.641800, valid loss: 210.441078
epoch: 3621, train precision: 0.754556, train loss: 91.302781, valid precision: 0.645200, valid loss: 278.583023
epoch: 3622, train precision: 0.477644, train loss: 177.929029, valid precision: 0.476000, valid loss: 182.736101
epoch: 3623, train precision: 0.671178, train loss: 123.760247, valid precision: 0.612400, valid loss: 166.467731
epoch: 3624, train precision: 0.759044, train loss: 89.257237, valid precision: 0.651200, valid loss: 164.321849
epoch: 3625, train precision: 0.749333, train loss: 96.162142, valid precision: 0.647400, valid loss: 173.019346
epoch: 3626, train precision: 0.498267, train loss: 177.479049, valid precision: 0.488800, valid loss: 189.349432
epoch: 3627, train precision: 0.728556, train loss: 102.642004, valid precision: 0.633400, valid loss: 173.989465
epoch: 3628, train precision: 0.758178, train loss: 91.496143, valid precision: 0.656000, valid loss: 171.339418
epoch: 3629, train precision: 0.746533, train loss: 94.477428, valid precision: 0.653800, valid loss: 162.463730
epoch: 3630, train precision: 0.765533, train loss: 86.342186, valid precision: 0.668400, valid loss: 163.321126
epoch: 3631, train precision: 0.790556, train loss: 78.413384, valid precision: 0.670200, valid loss: 160.707580
epoch: 3632, train precision: 0.806689, train loss: 73.384235, valid precision: 0.677600, valid loss: 164.850858
epoch: 3633, train precision: 0.747267, train loss: 94.298676, valid precision: 0.652400, valid loss: 182.185159
epoch: 3634, train precision: 0.300467, train loss: 286.143573, valid precision: 0.310800, valid loss: 288.763683
epoch: 3635, train precision: 0.761200, train loss: 89.607793, valid precision: 0.653000, valid loss: 167.751361
epoch: 3636, train precision: 0.416844, train loss: 195.913202, valid precision: 0.417000, valid loss: 201.655108
epoch: 3637, train precision: 0.609289, train loss: 141.942382, valid precision: 0.562200, valid loss: 175.469628
epoch: 3638, train precision: 0.696222, train loss: 116.633842, valid precision: 0.606200, valid loss: 176.730685
epoch: 3639, train precision: 0.767178, train loss: 87.271805, valid precision: 0.656200, valid loss: 174.713000
epoch: 3640, train precision: 0.794667, train loss: 76.303152, valid precision: 0.672200, valid loss: 157.386145
epoch: 3641, train precision: 0.784422, train loss: 91.443597, valid precision: 0.669200, valid loss: 173.491891
epoch: 3642, train precision: 0.344467, train loss: 229.452038, valid precision: 0.343000, valid loss: 226.811455
epoch: 3643, train precision: 0.492756, train loss: 184.437751, valid precision: 0.500200, valid loss: 187.905075
epoch: 3644, train precision: 0.612578, train loss: 141.774696, valid precision: 0.591800, valid loss: 162.420881
epoch: 3645, train precision: 0.297756, train loss: 262.873421, valid precision: 0.307400, valid loss: 260.244606
epoch: 3646, train precision: 0.585578, train loss: 146.521661, valid precision: 0.560400, valid loss: 180.081898
epoch: 3647, train precision: 0.620067, train loss: 127.636352, valid precision: 0.580600, valid loss: 163.614128
epoch: 3648, train precision: 0.762067, train loss: 89.495076, valid precision: 0.651800, valid loss: 163.471982
epoch: 3649, train precision: 0.773911, train loss: 83.383596, valid precision: 0.657600, valid loss: 170.544141
epoch: 3650, train precision: 0.785333, train loss: 78.494161, valid precision: 0.663400, valid loss: 168.927979
epoch: 3651, train precision: 0.774956, train loss: 81.951207, valid precision: 0.654800, valid loss: 202.325366
epoch: 3652, train precision: 0.628378, train loss: 129.838356, valid precision: 0.580000, valid loss: 163.501760
epoch: 3653, train precision: 0.797978, train loss: 77.806093, valid precision: 0.677400, valid loss: 158.810729
epoch: 3654, train precision: 0.782222, train loss: 80.557892, valid precision: 0.664400, valid loss: 163.595993
epoch: 3655, train precision: 0.796489, train loss: 76.059746, valid precision: 0.677400, valid loss: 161.244282
epoch: 3656, train precision: 0.769111, train loss: 86.962180, valid precision: 0.664400, valid loss: 154.373075
epoch: 3657, train precision: 0.727867, train loss: 104.119668, valid precision: 0.655000, valid loss: 171.238402
epoch: 3658, train precision: 0.776156, train loss: 82.918616, valid precision: 0.664200, valid loss: 164.044815
epoch: 3659, train precision: 0.805133, train loss: 74.490634, valid precision: 0.673400, valid loss: 164.570868
epoch: 3660, train precision: 0.318356, train loss: 237.969362, valid precision: 0.322600, valid loss: 239.337889
epoch: 3661, train precision: 0.741933, train loss: 96.789907, valid precision: 0.648600, valid loss: 168.559421
epoch: 3662, train precision: 0.759822, train loss: 91.254166, valid precision: 0.657000, valid loss: 163.268956
epoch: 3663, train precision: 0.793533, train loss: 76.889191, valid precision: 0.672200, valid loss: 180.403483
epoch: 3664, train precision: 0.760289, train loss: 87.790331, valid precision: 0.648600, valid loss: 217.682351
epoch: 3665, train precision: 0.500400, train loss: 184.680849, valid precision: 0.489400, valid loss: 201.050547
epoch: 3666, train precision: 0.716778, train loss: 101.189000, valid precision: 0.615200, valid loss: 172.454357
epoch: 3667, train precision: 0.542911, train loss: 167.511724, valid precision: 0.530200, valid loss: 180.432059
epoch: 3668, train precision: 0.401289, train loss: 222.182092, valid precision: 0.403800, valid loss: 232.983517
epoch: 3669, train precision: 0.772244, train loss: 83.035216, valid precision: 0.662600, valid loss: 163.699877
epoch: 3670, train precision: 0.770378, train loss: 81.543651, valid precision: 0.659000, valid loss: 170.757586
epoch: 3671, train precision: 0.767822, train loss: 82.764671, valid precision: 0.654200, valid loss: 168.371787
epoch: 3672, train precision: 0.818111, train loss: 68.824881, valid precision: 0.684000, valid loss: 168.071192
epoch: 3673, train precision: 0.613956, train loss: 143.571580, valid precision: 0.577600, valid loss: 179.353429
epoch: 3674, train precision: 0.768867, train loss: 92.854233, valid precision: 0.658000, valid loss: 202.346249
epoch: 3675, train precision: 0.803911, train loss: 73.840372, valid precision: 0.677200, valid loss: 185.515269
epoch: 3676, train precision: 0.578067, train loss: 238.101092, valid precision: 0.538200, valid loss: 320.984597
epoch: 3677, train precision: 0.691222, train loss: 115.201205, valid precision: 0.632000, valid loss: 173.311501
epoch: 3678, train precision: 0.776444, train loss: 81.742792, valid precision: 0.661400, valid loss: 154.947232
epoch: 3679, train precision: 0.761511, train loss: 84.380717, valid precision: 0.637400, valid loss: 177.858930
epoch: 3680, train precision: 0.803222, train loss: 71.828983, valid precision: 0.680600, valid loss: 188.967592
epoch: 3681, train precision: 0.620867, train loss: 141.279872, valid precision: 0.583000, valid loss: 173.343740
epoch: 3682, train precision: 0.783667, train loss: 80.255497, valid precision: 0.669800, valid loss: 163.926061
epoch: 3683, train precision: 0.794400, train loss: 74.441578, valid precision: 0.673000, valid loss: 169.380605
epoch: 3684, train precision: 0.804489, train loss: 74.248820, valid precision: 0.671600, valid loss: 180.149470
epoch: 3685, train precision: 0.678222, train loss: 122.432379, valid precision: 0.597000, valid loss: 194.094767
epoch: 3686, train precision: 0.805600, train loss: 72.710063, valid precision: 0.670600, valid loss: 171.907825
epoch: 3687, train precision: 0.797933, train loss: 80.121201, valid precision: 0.676800, valid loss: 175.248182
epoch: 3688, train precision: 0.820822, train loss: 67.298638, valid precision: 0.675600, valid loss: 160.725394
epoch: 3689, train precision: 0.809956, train loss: 69.090033, valid precision: 0.679600, valid loss: 177.126434
epoch: 3690, train precision: 0.822644, train loss: 65.932367, valid precision: 0.692400, valid loss: 171.135649
epoch: 3691, train precision: 0.262400, train loss: 296.767858, valid precision: 0.272600, valid loss: 293.465813
epoch: 3692, train precision: 0.737667, train loss: 98.042024, valid precision: 0.642200, valid loss: 167.056701
epoch: 3693, train precision: 0.815044, train loss: 68.079324, valid precision: 0.679000, valid loss: 167.477465
epoch: 3694, train precision: 0.796000, train loss: 73.394430, valid precision: 0.671400, valid loss: 175.456914
epoch: 3695, train precision: 0.812156, train loss: 68.947961, valid precision: 0.682200, valid loss: 181.974360
epoch: 3696, train precision: 0.756644, train loss: 90.402877, valid precision: 0.653200, valid loss: 181.719031
epoch: 3697, train precision: 0.819467, train loss: 68.397700, valid precision: 0.676200, valid loss: 174.666518
epoch: 3698, train precision: 0.526378, train loss: 169.581818, valid precision: 0.511000, valid loss: 180.340066
epoch: 3699, train precision: 0.792533, train loss: 78.895730, valid precision: 0.666800, valid loss: 165.060644
epoch: 3700, train precision: 0.801156, train loss: 75.436108, valid precision: 0.670600, valid loss: 165.207255
epoch: 3701, train precision: 0.820600, train loss: 64.624469, valid precision: 0.687000, valid loss: 173.741150
epoch: 3702, train precision: 0.201200, train loss: 277.043532, valid precision: 0.200400, valid loss: 274.981582
epoch: 3703, train precision: 0.515578, train loss: 182.321511, valid precision: 0.498200, valid loss: 207.802802
epoch: 3704, train precision: 0.599533, train loss: 144.403204, valid precision: 0.548800, valid loss: 186.733369
epoch: 3705, train precision: 0.682689, train loss: 109.436556, valid precision: 0.590600, valid loss: 284.263673
epoch: 3706, train precision: 0.761311, train loss: 86.507508, valid precision: 0.656800, valid loss: 238.849166
epoch: 3707, train precision: 0.489844, train loss: 228.095284, valid precision: 0.464400, valid loss: 582.532484
epoch: 3708, train precision: 0.781867, train loss: 79.518555, valid precision: 0.677400, valid loss: 417.804466
epoch: 3709, train precision: 0.806778, train loss: 71.075551, valid precision: 0.679200, valid loss: 1847.418015
epoch: 3710, train precision: 0.748822, train loss: 105.653272, valid precision: 0.646200, valid loss: 682.059675
epoch: 3711, train precision: 0.722822, train loss: 102.024182, valid precision: 0.652600, valid loss: 1239.084687
epoch: 3712, train precision: 0.787133, train loss: 88.004124, valid precision: 0.660400, valid loss: 3673.726312
epoch: 3713, train precision: 0.732844, train loss: 642.299273, valid precision: 0.636000, valid loss: 1072.510356
epoch: 3714, train precision: 0.187756, train loss: 311.891579, valid precision: 0.187200, valid loss: 311.196919
epoch: 3715, train precision: 0.385556, train loss: 224.801529, valid precision: 0.394800, valid loss: 225.082257
epoch: 3716, train precision: 0.469444, train loss: 179.780610, valid precision: 0.455000, valid loss: 190.969867
epoch: 3717, train precision: 0.707467, train loss: 107.937081, valid precision: 0.637000, valid loss: 162.977860
epoch: 3718, train precision: 0.763467, train loss: 85.060436, valid precision: 0.645000, valid loss: 178.070330
epoch: 3719, train precision: 0.802422, train loss: 73.412552, valid precision: 0.670400, valid loss: 172.784687
epoch: 3720, train precision: 0.757778, train loss: 87.900376, valid precision: 0.652200, valid loss: 166.826636
epoch: 3721, train precision: 0.821689, train loss: 65.172466, valid precision: 0.687000, valid loss: 155.986599
epoch: 3722, train precision: 0.811911, train loss: 69.866957, valid precision: 0.690200, valid loss: 163.045159
epoch: 3723, train precision: 0.819311, train loss: 66.830379, valid precision: 0.687000, valid loss: 160.658961
epoch: 3724, train precision: 0.824467, train loss: 64.249024, valid precision: 0.690400, valid loss: 160.239849
epoch: 3725, train precision: 0.664711, train loss: 120.480262, valid precision: 0.609400, valid loss: 157.010329
epoch: 3726, train precision: 0.404000, train loss: 211.645390, valid precision: 0.406600, valid loss: 212.925986
epoch: 3727, train precision: 0.744911, train loss: 95.909309, valid precision: 0.672000, valid loss: 148.068168
epoch: 3728, train precision: 0.630556, train loss: 133.700565, valid precision: 0.577400, valid loss: 176.027533
epoch: 3729, train precision: 0.765711, train loss: 86.972418, valid precision: 0.669200, valid loss: 148.617096
epoch: 3730, train precision: 0.834356, train loss: 62.776347, valid precision: 0.703400, valid loss: 144.752977
epoch: 3731, train precision: 0.833133, train loss: 69.689266, valid precision: 0.695000, valid loss: 153.043676
epoch: 3732, train precision: 0.625578, train loss: 139.566282, valid precision: 0.593600, valid loss: 164.975508
epoch: 3733, train precision: 0.788200, train loss: 78.375135, valid precision: 0.679800, valid loss: 150.766602
epoch: 3734, train precision: 0.786467, train loss: 77.295867, valid precision: 0.676600, valid loss: 163.065204
epoch: 3735, train precision: 0.836200, train loss: 62.566788, valid precision: 0.710800, valid loss: 146.911249
epoch: 3736, train precision: 0.834356, train loss: 61.600267, valid precision: 0.712000, valid loss: 159.343830
epoch: 3737, train precision: 0.860400, train loss: 52.460243, valid precision: 0.714400, valid loss: 148.471815
epoch: 3738, train precision: 0.857844, train loss: 53.253277, valid precision: 0.715800, valid loss: 161.578051
epoch: 3739, train precision: 0.863178, train loss: 51.906277, valid precision: 0.720000, valid loss: 157.441033
epoch: 3740, train precision: 0.836178, train loss: 62.675977, valid precision: 0.701400, valid loss: 186.635210
epoch: 3741, train precision: 0.756422, train loss: 92.501560, valid precision: 0.673800, valid loss: 165.605809
epoch: 3742, train precision: 0.417622, train loss: 200.812881, valid precision: 0.416800, valid loss: 202.063494
epoch: 3743, train precision: 0.647956, train loss: 134.770201, valid precision: 0.610000, valid loss: 164.585550
epoch: 3744, train precision: 0.832867, train loss: 63.062129, valid precision: 0.707800, valid loss: 166.845009
epoch: 3745, train precision: 0.852822, train loss: 54.657525, valid precision: 0.713400, valid loss: 155.155897
epoch: 3746, train precision: 0.672556, train loss: 129.398490, valid precision: 0.613600, valid loss: 184.241403
epoch: 3747, train precision: 0.849089, train loss: 56.518562, valid precision: 0.718400, valid loss: 160.149211
epoch: 3748, train precision: 0.767422, train loss: 88.822636, valid precision: 0.677400, valid loss: 170.408515
epoch: 3749, train precision: 0.854133, train loss: 55.283995, valid precision: 0.716800, valid loss: 270.245833
epoch: 3750, train precision: 0.831378, train loss: 65.304667, valid precision: 0.720600, valid loss: 140.811215
epoch: 3751, train precision: 0.797356, train loss: 78.062000, valid precision: 0.708600, valid loss: 152.991220
epoch: 3752, train precision: 0.824444, train loss: 67.500617, valid precision: 0.706600, valid loss: 167.053983
epoch: 3753, train precision: 0.863978, train loss: 51.770260, valid precision: 0.726800, valid loss: 149.601731
epoch: 3754, train precision: 0.850889, train loss: 55.814756, valid precision: 0.712800, valid loss: 165.479421
epoch: 3755, train precision: 0.865556, train loss: 52.524860, valid precision: 0.724800, valid loss: 158.842791
epoch: 3756, train precision: 0.577733, train loss: 167.828707, valid precision: 0.554000, valid loss: 188.395797
epoch: 3757, train precision: 0.788289, train loss: 80.373320, valid precision: 0.675600, valid loss: 204.276838
epoch: 3758, train precision: 0.819800, train loss: 69.676389, valid precision: 0.697600, valid loss: 167.059233
epoch: 3759, train precision: 0.861533, train loss: 51.578736, valid precision: 0.728600, valid loss: 143.449230
epoch: 3760, train precision: 0.868200, train loss: 61.547874, valid precision: 0.724000, valid loss: 185.214550
epoch: 3761, train precision: 0.882533, train loss: 44.335523, valid precision: 0.734000, valid loss: 154.240875
epoch: 3762, train precision: 0.876644, train loss: 45.962467, valid precision: 0.730400, valid loss: 159.529388
epoch: 3763, train precision: 0.567200, train loss: 154.537704, valid precision: 0.548600, valid loss: 176.211129
epoch: 3764, train precision: 0.707978, train loss: 114.174708, valid precision: 0.647200, valid loss: 172.385239
epoch: 3765, train precision: 0.823822, train loss: 68.175070, valid precision: 0.699000, valid loss: 159.820952
epoch: 3766, train precision: 0.870556, train loss: 47.714071, valid precision: 0.720800, valid loss: 268.154097
epoch: 3767, train precision: 0.858022, train loss: 52.511258, valid precision: 0.709000, valid loss: 260.391501
epoch: 3768, train precision: 0.818467, train loss: 90.951574, valid precision: 0.712600, valid loss: 335.672777
epoch: 3769, train precision: 0.832111, train loss: 61.825456, valid precision: 0.708800, valid loss: 212.229876
epoch: 3770, train precision: 0.814022, train loss: 68.989089, valid precision: 0.681400, valid loss: 446.430790
epoch: 3771, train precision: 0.836489, train loss: 62.663977, valid precision: 0.704600, valid loss: 316.103149
epoch: 3772, train precision: 0.803556, train loss: 76.790393, valid precision: 0.705600, valid loss: 167.078293
epoch: 3773, train precision: 0.811800, train loss: 71.624516, valid precision: 0.705400, valid loss: 687.411622
epoch: 3774, train precision: 0.856333, train loss: 53.219389, valid precision: 0.718800, valid loss: 422.671562
epoch: 3775, train precision: 0.696756, train loss: 129.201083, valid precision: 0.636200, valid loss: 195.553391
epoch: 3776, train precision: 0.488733, train loss: 174.809161, valid precision: 0.490200, valid loss: 179.207776
epoch: 3777, train precision: 0.481267, train loss: 200.983747, valid precision: 0.467000, valid loss: 213.823438
epoch: 3778, train precision: 0.840756, train loss: 58.129245, valid precision: 0.713400, valid loss: 146.703813
epoch: 3779, train precision: 0.847689, train loss: 56.283195, valid precision: 0.715000, valid loss: 195.465531
epoch: 3780, train precision: 0.876933, train loss: 47.467434, valid precision: 0.728600, valid loss: 186.094548
epoch: 3781, train precision: 0.827200, train loss: 65.179423, valid precision: 0.702600, valid loss: 150.607852
epoch: 3782, train precision: 0.882533, train loss: 44.707988, valid precision: 0.730600, valid loss: 220.632876
epoch: 3783, train precision: 0.225689, train loss: 303.409401, valid precision: 0.233200, valid loss: 834.757937
epoch: 3784, train precision: 0.435756, train loss: 208.637721, valid precision: 0.451000, valid loss: 228.463109
epoch: 3785, train precision: 0.575511, train loss: 162.272836, valid precision: 0.571400, valid loss: 175.903786
epoch: 3786, train precision: 0.785756, train loss: 88.545414, valid precision: 0.687400, valid loss: 462.163425
epoch: 3787, train precision: 0.799422, train loss: 77.448867, valid precision: 0.688000, valid loss: 231.887107
epoch: 3788, train precision: 0.779600, train loss: 85.314252, valid precision: 0.685600, valid loss: 156.149194
epoch: 3789, train precision: 0.853600, train loss: 54.538928, valid precision: 0.717800, valid loss: 145.920760
epoch: 3790, train precision: 0.861378, train loss: 51.008417, valid precision: 0.720000, valid loss: 140.894471
epoch: 3791, train precision: 0.870267, train loss: 50.408750, valid precision: 0.720200, valid loss: 155.513390
epoch: 3792, train precision: 0.586933, train loss: 144.158787, valid precision: 0.545400, valid loss: 214.410208
epoch: 3793, train precision: 0.843200, train loss: 57.115739, valid precision: 0.715600, valid loss: 186.416102
epoch: 3794, train precision: 0.287578, train loss: 256.972545, valid precision: 0.301400, valid loss: 250.587339
epoch: 3795, train precision: 0.679289, train loss: 122.410236, valid precision: 0.634600, valid loss: 152.685942
epoch: 3796, train precision: 0.841800, train loss: 58.609079, valid precision: 0.722800, valid loss: 140.848623
epoch: 3797, train precision: 0.817867, train loss: 69.048980, valid precision: 0.692600, valid loss: 163.966671
epoch: 3798, train precision: 0.868556, train loss: 52.039132, valid precision: 0.732400, valid loss: 144.388115
epoch: 3799, train precision: 0.851822, train loss: 53.740455, valid precision: 0.714000, valid loss: 159.604178
epoch: 3800, train precision: 0.881778, train loss: 45.071486, valid precision: 0.730400, valid loss: 164.651932
epoch: 3801, train precision: 0.248111, train loss: 252.118638, valid precision: 0.255400, valid loss: 251.142249
epoch: 3802, train precision: 0.486733, train loss: 174.753734, valid precision: 0.488600, valid loss: 180.838225
epoch: 3803, train precision: 0.792467, train loss: 78.828193, valid precision: 0.689000, valid loss: 142.840338
epoch: 3804, train precision: 0.818511, train loss: 67.111858, valid precision: 0.690800, valid loss: 150.101045
epoch: 3805, train precision: 0.862911, train loss: 51.179960, valid precision: 0.718400, valid loss: 150.371924
epoch: 3806, train precision: 0.855378, train loss: 55.992134, valid precision: 0.727200, valid loss: 145.941371
epoch: 3807, train precision: 0.859600, train loss: 51.297003, valid precision: 0.716600, valid loss: 173.380013
epoch: 3808, train precision: 0.854867, train loss: 55.847074, valid precision: 0.711400, valid loss: 179.257223
epoch: 3809, train precision: 0.856311, train loss: 53.772191, valid precision: 0.713000, valid loss: 183.128942
epoch: 3810, train precision: 0.890911, train loss: 43.539374, valid precision: 0.729200, valid loss: 155.334730
epoch: 3811, train precision: 0.880600, train loss: 45.738679, valid precision: 0.723000, valid loss: 151.611351
epoch: 3812, train precision: 0.864000, train loss: 50.946529, valid precision: 0.716000, valid loss: 178.334451
epoch: 3813, train precision: 0.723800, train loss: 106.429880, valid precision: 0.658200, valid loss: 155.014898
epoch: 3814, train precision: 0.863867, train loss: 51.767976, valid precision: 0.725600, valid loss: 144.190008
epoch: 3815, train precision: 0.853178, train loss: 53.432260, valid precision: 0.709000, valid loss: 149.939998
epoch: 3816, train precision: 0.378267, train loss: 222.610152, valid precision: 0.383400, valid loss: 224.789898
epoch: 3817, train precision: 0.790978, train loss: 79.339721, valid precision: 0.699400, valid loss: 148.663667
epoch: 3818, train precision: 0.818556, train loss: 69.783538, valid precision: 0.700600, valid loss: 152.007282
epoch: 3819, train precision: 0.843867, train loss: 57.567182, valid precision: 0.707200, valid loss: 165.003876
epoch: 3820, train precision: 0.865444, train loss: 51.491192, valid precision: 0.726800, valid loss: 208.872900
epoch: 3821, train precision: 0.877956, train loss: 45.527757, valid precision: 0.727000, valid loss: 155.192894
epoch: 3822, train precision: 0.498244, train loss: 187.759098, valid precision: 0.492200, valid loss: 207.056030
epoch: 3823, train precision: 0.825067, train loss: 78.840206, valid precision: 0.703800, valid loss: 157.346882
epoch: 3824, train precision: 0.804378, train loss: 73.243096, valid precision: 0.699000, valid loss: 151.608900
epoch: 3825, train precision: 0.874511, train loss: 49.519136, valid precision: 0.727800, valid loss: 149.773809
epoch: 3826, train precision: 0.876933, train loss: 45.897589, valid precision: 0.712400, valid loss: 148.440623
epoch: 3827, train precision: 0.877533, train loss: 75.143582, valid precision: 0.724200, valid loss: 159.559990
epoch: 3828, train precision: 0.417000, train loss: 204.019622, valid precision: 0.414000, valid loss: 209.931651
epoch: 3829, train precision: 0.597267, train loss: 139.005924, valid precision: 0.557800, valid loss: 179.861910
epoch: 3830, train precision: 0.868089, train loss: 50.588084, valid precision: 0.723600, valid loss: 193.858366
epoch: 3831, train precision: 0.871822, train loss: 49.785629, valid precision: 0.728600, valid loss: 161.533004
epoch: 3832, train precision: 0.867756, train loss: 50.639063, valid precision: 0.719400, valid loss: 151.145465
epoch: 3833, train precision: 0.850444, train loss: 59.159340, valid precision: 0.713400, valid loss: 179.083053
epoch: 3834, train precision: 0.855267, train loss: 52.857543, valid precision: 0.717400, valid loss: 143.719404
epoch: 3835, train precision: 0.866889, train loss: 50.546016, valid precision: 0.718600, valid loss: 161.925246
epoch: 3836, train precision: 0.533267, train loss: 168.282182, valid precision: 0.525800, valid loss: 193.070706
epoch: 3837, train precision: 0.877556, train loss: 46.087528, valid precision: 0.732000, valid loss: 149.958037
epoch: 3838, train precision: 0.417289, train loss: 221.329718, valid precision: 0.432000, valid loss: 224.267423
epoch: 3839, train precision: 0.751711, train loss: 98.849041, valid precision: 0.678600, valid loss: 154.860921
epoch: 3840, train precision: 0.859111, train loss: 53.558076, valid precision: 0.721200, valid loss: 143.803103
epoch: 3841, train precision: 0.879178, train loss: 46.048137, valid precision: 0.731000, valid loss: 153.159673
epoch: 3842, train precision: 0.887333, train loss: 43.871412, valid precision: 0.743200, valid loss: 149.001658
epoch: 3843, train precision: 0.882644, train loss: 43.685982, valid precision: 0.734800, valid loss: 145.433662
epoch: 3844, train precision: 0.719689, train loss: 111.285328, valid precision: 0.652600, valid loss: 160.820938
epoch: 3845, train precision: 0.856289, train loss: 54.315217, valid precision: 0.730000, valid loss: 139.625524
epoch: 3846, train precision: 0.895467, train loss: 41.244899, valid precision: 0.745400, valid loss: 142.845873
epoch: 3847, train precision: 0.876178, train loss: 46.540492, valid precision: 0.734200, valid loss: 140.522652
epoch: 3848, train precision: 0.897089, train loss: 39.622026, valid precision: 0.739200, valid loss: 151.523936
epoch: 3849, train precision: 0.891822, train loss: 41.408528, valid precision: 0.741000, valid loss: 145.077606
epoch: 3850, train precision: 0.910178, train loss: 35.250190, valid precision: 0.746800, valid loss: 143.254377
epoch: 3851, train precision: 0.296000, train loss: 221.550056, valid precision: 0.296400, valid loss: 224.562500
epoch: 3852, train precision: 0.696867, train loss: 103.841035, valid precision: 0.618000, valid loss: 164.280372
epoch: 3853, train precision: 0.756267, train loss: 84.225073, valid precision: 0.634800, valid loss: 369.799768
epoch: 3854, train precision: 0.836644, train loss: 64.868635, valid precision: 0.709000, valid loss: 166.427809
epoch: 3855, train precision: 0.891822, train loss: 42.788142, valid precision: 0.733200, valid loss: 155.466773
epoch: 3856, train precision: 0.883000, train loss: 44.200001, valid precision: 0.726600, valid loss: 155.043611
epoch: 3857, train precision: 0.788289, train loss: 79.953846, valid precision: 0.689200, valid loss: 144.120325
epoch: 3858, train precision: 0.879600, train loss: 45.357356, valid precision: 0.732800, valid loss: 157.703212
epoch: 3859, train precision: 0.880644, train loss: 47.337749, valid precision: 0.725600, valid loss: 174.164775
epoch: 3860, train precision: 0.484667, train loss: 176.822144, valid precision: 0.485800, valid loss: 191.684783
epoch: 3861, train precision: 0.858378, train loss: 55.221151, valid precision: 0.731000, valid loss: 148.640852
epoch: 3862, train precision: 0.898444, train loss: 38.372405, valid precision: 0.741000, valid loss: 185.303223
epoch: 3863, train precision: 0.885511, train loss: 44.314656, valid precision: 0.729400, valid loss: 175.240955
epoch: 3864, train precision: 0.166178, train loss: 322.458581, valid precision: 0.168600, valid loss: 318.948066
epoch: 3865, train precision: 0.251022, train loss: 256.647726, valid precision: 0.261800, valid loss: 259.974987
epoch: 3866, train precision: 0.292133, train loss: 232.886494, valid precision: 0.298200, valid loss: 282.751942
epoch: 3867, train precision: 0.846778, train loss: 60.018332, valid precision: 0.717400, valid loss: 243.753837
epoch: 3868, train precision: 0.867111, train loss: 50.800411, valid precision: 0.725200, valid loss: 152.641146
epoch: 3869, train precision: 0.896422, train loss: 39.130880, valid precision: 0.736000, valid loss: 232.768580
epoch: 3870, train precision: 0.903356, train loss: 37.409789, valid precision: 0.740600, valid loss: 274.544981
epoch: 3871, train precision: 0.561178, train loss: 207.713737, valid precision: 0.548200, valid loss: 225.517776
epoch: 3872, train precision: 0.631067, train loss: 141.462355, valid precision: 0.601400, valid loss: 159.311713
epoch: 3873, train precision: 0.872133, train loss: 50.056988, valid precision: 0.721400, valid loss: 325.796671
epoch: 3874, train precision: 0.865667, train loss: 51.464634, valid precision: 0.723000, valid loss: 170.207799
epoch: 3875, train precision: 0.538311, train loss: 176.191242, valid precision: 0.528000, valid loss: 206.126460
epoch: 3876, train precision: 0.882422, train loss: 44.424375, valid precision: 0.740000, valid loss: 144.681715
epoch: 3877, train precision: 0.904422, train loss: 36.464750, valid precision: 0.743200, valid loss: 151.250623
epoch: 3878, train precision: 0.889556, train loss: 42.240720, valid precision: 0.724400, valid loss: 157.217948
epoch: 3879, train precision: 0.895489, train loss: 40.176146, valid precision: 0.740000, valid loss: 167.990682
epoch: 3880, train precision: 0.890378, train loss: 42.038812, valid precision: 0.732400, valid loss: 162.657018
epoch: 3881, train precision: 0.876600, train loss: 47.994507, valid precision: 0.724600, valid loss: 174.457103
epoch: 3882, train precision: 0.839444, train loss: 61.685431, valid precision: 0.703000, valid loss: 178.261096
epoch: 3883, train precision: 0.860622, train loss: 52.794660, valid precision: 0.722000, valid loss: 142.994930
epoch: 3884, train precision: 0.881933, train loss: 45.709500, valid precision: 0.735400, valid loss: 141.880707
epoch: 3885, train precision: 0.877578, train loss: 46.305097, valid precision: 0.724000, valid loss: 158.279568
epoch: 3886, train precision: 0.902956, train loss: 37.124289, valid precision: 0.738400, valid loss: 146.688566
epoch: 3887, train precision: 0.915022, train loss: 33.668147, valid precision: 0.744200, valid loss: 158.832793
epoch: 3888, train precision: 0.296378, train loss: 471.963493, valid precision: 0.304600, valid loss: 475.531594
epoch: 3889, train precision: 0.496889, train loss: 181.665186, valid precision: 0.491200, valid loss: 189.353676
epoch: 3890, train precision: 0.674867, train loss: 115.503285, valid precision: 0.609200, valid loss: 158.338608
epoch: 3891, train precision: 0.751667, train loss: 88.874789, valid precision: 0.631800, valid loss: 171.132946
epoch: 3892, train precision: 0.870578, train loss: 50.326797, valid precision: 0.714200, valid loss: 171.031974
epoch: 3893, train precision: 0.904956, train loss: 37.118685, valid precision: 0.741000, valid loss: 155.924336
epoch: 3894, train precision: 0.901111, train loss: 39.153505, valid precision: 0.731200, valid loss: 153.579845
epoch: 3895, train precision: 0.491933, train loss: 186.349662, valid precision: 0.487400, valid loss: 193.539232
epoch: 3896, train precision: 0.840711, train loss: 62.400128, valid precision: 0.720200, valid loss: 166.549367
epoch: 3897, train precision: 0.885444, train loss: 44.867970, valid precision: 0.732600, valid loss: 163.234147
epoch: 3898, train precision: 0.909600, train loss: 38.164527, valid precision: 0.743800, valid loss: 160.082857
epoch: 3899, train precision: 0.431133, train loss: 192.570891, valid precision: 0.425000, valid loss: 200.436503
epoch: 3900, train precision: 0.886622, train loss: 50.265720, valid precision: 0.743200, valid loss: 150.756759
epoch: 3901, train precision: 0.790844, train loss: 81.868665, valid precision: 0.702200, valid loss: 135.985717
epoch: 3902, train precision: 0.866578, train loss: 52.083647, valid precision: 0.728000, valid loss: 152.022228
epoch: 3903, train precision: 0.886778, train loss: 43.136058, valid precision: 0.732400, valid loss: 148.417973
epoch: 3904, train precision: 0.865444, train loss: 49.693307, valid precision: 0.722200, valid loss: 169.472498
epoch: 3905, train precision: 0.895111, train loss: 40.856104, valid precision: 0.736200, valid loss: 155.473432
epoch: 3906, train precision: 0.882067, train loss: 45.786507, valid precision: 0.733800, valid loss: 263.155776
epoch: 3907, train precision: 0.399200, train loss: 221.746422, valid precision: 0.395000, valid loss: 253.750837
epoch: 3908, train precision: 0.837422, train loss: 63.668895, valid precision: 0.717600, valid loss: 162.787974
epoch: 3909, train precision: 0.419200, train loss: 220.968993, valid precision: 0.417000, valid loss: 224.690010
epoch: 3910, train precision: 0.688756, train loss: 117.096838, valid precision: 0.648400, valid loss: 147.511361
epoch: 3911, train precision: 0.800422, train loss: 73.139461, valid precision: 0.694200, valid loss: 147.222921
epoch: 3912, train precision: 0.846867, train loss: 56.074911, valid precision: 0.718000, valid loss: 220.253783
epoch: 3913, train precision: 0.874000, train loss: 48.724572, valid precision: 0.730000, valid loss: 232.130640
epoch: 3914, train precision: 0.866956, train loss: 52.285846, valid precision: 0.719000, valid loss: 166.944103
epoch: 3915, train precision: 0.860667, train loss: 50.649531, valid precision: 0.715200, valid loss: 217.140648
epoch: 3916, train precision: 0.907200, train loss: 37.841341, valid precision: 0.751800, valid loss: 301.701211
epoch: 3917, train precision: 0.451089, train loss: 191.343420, valid precision: 0.444400, valid loss: 205.635878
epoch: 3918, train precision: 0.865578, train loss: 52.967893, valid precision: 0.731200, valid loss: 247.885573
epoch: 3919, train precision: 0.856422, train loss: 53.620321, valid precision: 0.719000, valid loss: 160.130862
epoch: 3920, train precision: 0.889022, train loss: 41.320939, valid precision: 0.740200, valid loss: 146.734734
epoch: 3921, train precision: 0.867489, train loss: 49.705048, valid precision: 0.718800, valid loss: 160.644262
epoch: 3922, train precision: 0.897644, train loss: 44.477242, valid precision: 0.733200, valid loss: 162.679375
epoch: 3923, train precision: 0.773267, train loss: 89.186305, valid precision: 0.674200, valid loss: 186.595824
epoch: 3924, train precision: 0.887867, train loss: 43.692893, valid precision: 0.731200, valid loss: 198.029937
epoch: 3925, train precision: 0.899800, train loss: 38.571055, valid precision: 0.734800, valid loss: 199.107808
epoch: 3926, train precision: 0.498533, train loss: 162.785529, valid precision: 0.473800, valid loss: 189.502999
epoch: 3927, train precision: 0.861800, train loss: 52.538681, valid precision: 0.726400, valid loss: 153.101176
epoch: 3928, train precision: 0.886978, train loss: 43.028496, valid precision: 0.732400, valid loss: 256.201698
epoch: 3929, train precision: 0.882400, train loss: 45.868510, valid precision: 0.738600, valid loss: 169.929350
epoch: 3930, train precision: 0.708867, train loss: 136.370595, valid precision: 0.636600, valid loss: 332.641642
epoch: 3931, train precision: 0.868622, train loss: 49.364254, valid precision: 0.712800, valid loss: 254.887729
epoch: 3932, train precision: 0.893089, train loss: 41.214947, valid precision: 0.730600, valid loss: 246.538470
epoch: 3933, train precision: 0.908378, train loss: 37.015797, valid precision: 0.734600, valid loss: 224.519708
epoch: 3934, train precision: 0.867022, train loss: 62.095353, valid precision: 0.713800, valid loss: 331.877265
epoch: 3935, train precision: 0.234844, train loss: 380.981275, valid precision: 0.239400, valid loss: 376.788333
epoch: 3936, train precision: 0.727400, train loss: 108.080735, valid precision: 0.665200, valid loss: 179.878517
epoch: 3937, train precision: 0.855489, train loss: 56.058224, valid precision: 0.725600, valid loss: 167.312041
epoch: 3938, train precision: 0.873000, train loss: 48.958604, valid precision: 0.718200, valid loss: 209.783509
epoch: 3939, train precision: 0.891067, train loss: 41.915947, valid precision: 0.725400, valid loss: 350.175925
epoch: 3940, train precision: 0.804022, train loss: 79.070225, valid precision: 0.705800, valid loss: 153.174540
epoch: 3941, train precision: 0.897800, train loss: 40.373327, valid precision: 0.735800, valid loss: 235.741748
epoch: 3942, train precision: 0.874222, train loss: 47.320203, valid precision: 0.719000, valid loss: 298.848604
epoch: 3943, train precision: 0.696778, train loss: 118.169794, valid precision: 0.641600, valid loss: 160.147050
epoch: 3944, train precision: 0.304867, train loss: 235.276717, valid precision: 0.307800, valid loss: 232.843833
epoch: 3945, train precision: 0.463956, train loss: 180.477274, valid precision: 0.455000, valid loss: 189.752399
epoch: 3946, train precision: 0.799600, train loss: 77.011711, valid precision: 0.703000, valid loss: 225.101702
epoch: 3947, train precision: 0.882067, train loss: 45.524835, valid precision: 0.745200, valid loss: 345.057708
epoch: 3948, train precision: 0.908622, train loss: 35.670202, valid precision: 0.745600, valid loss: 593.027096
epoch: 3949, train precision: 0.547311, train loss: 170.372289, valid precision: 0.538200, valid loss: 182.047030
epoch: 3950, train precision: 0.657822, train loss: 128.051825, valid precision: 0.631600, valid loss: 349.582545
epoch: 3951, train precision: 0.867733, train loss: 51.045915, valid precision: 0.729600, valid loss: 404.360179
epoch: 3952, train precision: 0.883978, train loss: 44.672575, valid precision: 0.729800, valid loss: 301.484346
epoch: 3953, train precision: 0.899756, train loss: 38.624326, valid precision: 0.739400, valid loss: 483.015376
epoch: 3954, train precision: 0.894556, train loss: 40.204027, valid precision: 0.736200, valid loss: 464.243949
epoch: 3955, train precision: 0.810267, train loss: 75.637482, valid precision: 0.703400, valid loss: 194.745511
epoch: 3956, train precision: 0.879022, train loss: 44.774561, valid precision: 0.729400, valid loss: 450.647942
epoch: 3957, train precision: 0.857689, train loss: 54.492977, valid precision: 0.718000, valid loss: 435.491946
epoch: 3958, train precision: 0.887444, train loss: 43.782880, valid precision: 0.749600, valid loss: 558.081720
epoch: 3959, train precision: 0.912333, train loss: 34.753090, valid precision: 0.746200, valid loss: 505.065524
epoch: 3960, train precision: 0.683022, train loss: 149.276761, valid precision: 0.628000, valid loss: 254.046619
epoch: 3961, train precision: 0.901178, train loss: 39.578184, valid precision: 0.735800, valid loss: 621.828529
epoch: 3962, train precision: 0.909311, train loss: 34.980628, valid precision: 0.745200, valid loss: 467.722937
epoch: 3963, train precision: 0.329200, train loss: 230.457143, valid precision: 0.343200, valid loss: 230.216253
epoch: 3964, train precision: 0.819711, train loss: 68.162726, valid precision: 0.710600, valid loss: 335.953360
epoch: 3965, train precision: 0.698978, train loss: 131.978742, valid precision: 0.635600, valid loss: 962.203498
epoch: 3966, train precision: 0.749244, train loss: 100.408398, valid precision: 0.676800, valid loss: 919.459546
epoch: 3967, train precision: 0.876378, train loss: 47.379288, valid precision: 0.730800, valid loss: 142.911751
epoch: 3968, train precision: 0.720689, train loss: 111.816008, valid precision: 0.657000, valid loss: 160.197988
epoch: 3969, train precision: 0.894156, train loss: 39.985601, valid precision: 0.730800, valid loss: 149.714803
epoch: 3970, train precision: 0.897689, train loss: 40.293514, valid precision: 0.735800, valid loss: 157.812584
epoch: 3971, train precision: 0.899756, train loss: 38.163511, valid precision: 0.734200, valid loss: 195.604612
epoch: 3972, train precision: 0.317933, train loss: 266.321046, valid precision: 0.318400, valid loss: 285.845325
epoch: 3973, train precision: 0.889978, train loss: 51.047642, valid precision: 0.736000, valid loss: 154.269167
epoch: 3974, train precision: 0.867711, train loss: 48.124355, valid precision: 0.720800, valid loss: 167.653281
epoch: 3975, train precision: 0.619667, train loss: 147.862122, valid precision: 0.570400, valid loss: 185.474337
epoch: 3976, train precision: 0.846733, train loss: 58.615403, valid precision: 0.703800, valid loss: 190.913173
epoch: 3977, train precision: 0.905333, train loss: 36.962361, valid precision: 0.740400, valid loss: 170.032403
epoch: 3978, train precision: 0.844600, train loss: 62.235850, valid precision: 0.727400, valid loss: 158.601123
epoch: 3979, train precision: 0.216733, train loss: 449.010436, valid precision: 0.210000, valid loss: 455.079179
epoch: 3980, train precision: 0.277778, train loss: 234.124120, valid precision: 0.289600, valid loss: 234.414194
epoch: 3981, train precision: 0.339022, train loss: 206.877780, valid precision: 0.341400, valid loss: 214.093899
epoch: 3982, train precision: 0.701133, train loss: 150.086258, valid precision: 0.647400, valid loss: 192.946818
epoch: 3983, train precision: 0.751311, train loss: 112.919560, valid precision: 0.681600, valid loss: 183.851661
epoch: 3984, train precision: 0.870289, train loss: 51.678664, valid precision: 0.728400, valid loss: 162.065410
epoch: 3985, train precision: 0.903156, train loss: 39.631498, valid precision: 0.740600, valid loss: 157.751129
epoch: 3986, train precision: 0.896022, train loss: 40.049869, valid precision: 0.738600, valid loss: 168.233272
epoch: 3987, train precision: 0.867622, train loss: 53.065980, valid precision: 0.732000, valid loss: 144.737842
epoch: 3988, train precision: 0.841556, train loss: 61.957447, valid precision: 0.715400, valid loss: 148.296713
epoch: 3989, train precision: 0.860467, train loss: 54.593375, valid precision: 0.731000, valid loss: 145.584199
epoch: 3990, train precision: 0.373222, train loss: 281.961298, valid precision: 0.374200, valid loss: 279.257287
epoch: 3991, train precision: 0.889378, train loss: 43.464292, valid precision: 0.742000, valid loss: 140.888863
epoch: 3992, train precision: 0.908089, train loss: 35.706865, valid precision: 0.743800, valid loss: 148.197495
epoch: 3993, train precision: 0.394822, train loss: 235.283636, valid precision: 0.385000, valid loss: 244.657982
epoch: 3994, train precision: 0.842089, train loss: 63.067150, valid precision: 0.724000, valid loss: 152.187879
epoch: 3995, train precision: 0.881067, train loss: 45.364793, valid precision: 0.733600, valid loss: 156.199454
epoch: 3996, train precision: 0.901044, train loss: 38.773181, valid precision: 0.739200, valid loss: 154.612704
epoch: 3997, train precision: 0.899622, train loss: 40.150879, valid precision: 0.736200, valid loss: 174.666650
epoch: 3998, train precision: 0.915244, train loss: 33.895044, valid precision: 0.747000, valid loss: 150.598940
epoch: 3999, train precision: 0.914178, train loss: 33.856531, valid precision: 0.739200, valid loss: 163.814072
epoch: 4000, train precision: 0.841467, train loss: 62.478493, valid precision: 0.708200, valid loss: 169.356393
epoch: 4001, train precision: 0.894956, train loss: 39.661822, valid precision: 0.734800, valid loss: 172.128318
epoch: 4002, train precision: 0.877200, train loss: 48.361962, valid precision: 0.727600, valid loss: 171.098792
epoch: 4003, train precision: 0.895600, train loss: 40.718354, valid precision: 0.729600, valid loss: 160.003408
epoch: 4004, train precision: 0.907156, train loss: 36.679520, valid precision: 0.740200, valid loss: 157.063473
epoch: 4005, train precision: 0.696467, train loss: 121.311683, valid precision: 0.647400, valid loss: 159.092822
epoch: 4006, train precision: 0.885733, train loss: 44.569645, valid precision: 0.729000, valid loss: 151.357022
epoch: 4007, train precision: 0.623800, train loss: 150.182440, valid precision: 0.580600, valid loss: 188.407256
epoch: 4008, train precision: 0.880022, train loss: 45.973858, valid precision: 0.729800, valid loss: 145.331782
epoch: 4009, train precision: 0.880044, train loss: 45.965236, valid precision: 0.726600, valid loss: 177.759339
epoch: 4010, train precision: 0.883889, train loss: 44.750717, valid precision: 0.725200, valid loss: 159.988635
epoch: 4011, train precision: 0.877800, train loss: 47.434522, valid precision: 0.725600, valid loss: 167.643102
epoch: 4012, train precision: 0.885133, train loss: 45.229591, valid precision: 0.739800, valid loss: 151.833258
epoch: 4013, train precision: 0.884467, train loss: 45.534376, valid precision: 0.733200, valid loss: 151.574166
epoch: 4014, train precision: 0.919689, train loss: 31.957544, valid precision: 0.750400, valid loss: 156.925282
epoch: 4015, train precision: 0.586089, train loss: 150.785277, valid precision: 0.567000, valid loss: 168.858417
epoch: 4016, train precision: 0.757267, train loss: 99.516824, valid precision: 0.681800, valid loss: 159.970555
epoch: 4017, train precision: 0.717578, train loss: 150.993844, valid precision: 0.667400, valid loss: 148.154983
epoch: 4018, train precision: 0.825533, train loss: 67.205757, valid precision: 0.707600, valid loss: 147.594031
epoch: 4019, train precision: 0.830778, train loss: 62.535379, valid precision: 0.710200, valid loss: 182.785203
epoch: 4020, train precision: 0.259800, train loss: 306.744079, valid precision: 0.264400, valid loss: 396.912225
epoch: 4021, train precision: 0.799600, train loss: 94.385520, valid precision: 0.722000, valid loss: 160.475550
epoch: 4022, train precision: 0.817311, train loss: 71.516138, valid precision: 0.710800, valid loss: 239.636296
epoch: 4023, train precision: 0.878267, train loss: 48.665722, valid precision: 0.724600, valid loss: 357.635636
epoch: 4024, train precision: 0.862089, train loss: 55.992660, valid precision: 0.719600, valid loss: 247.320576
epoch: 4025, train precision: 0.676844, train loss: 121.549278, valid precision: 0.634600, valid loss: 224.715376
epoch: 4026, train precision: 0.873578, train loss: 50.790529, valid precision: 0.729000, valid loss: 214.423661
epoch: 4027, train precision: 0.846089, train loss: 57.817391, valid precision: 0.712800, valid loss: 194.814065
epoch: 4028, train precision: 0.904400, train loss: 38.399849, valid precision: 0.738800, valid loss: 197.110381
epoch: 4029, train precision: 0.906422, train loss: 36.376380, valid precision: 0.737200, valid loss: 171.649620
epoch: 4030, train precision: 0.871844, train loss: 50.995237, valid precision: 0.733000, valid loss: 181.348139
epoch: 4031, train precision: 0.877711, train loss: 47.912719, valid precision: 0.721200, valid loss: 260.277664
epoch: 4032, train precision: 0.503667, train loss: 181.830363, valid precision: 0.477600, valid loss: 259.106419
epoch: 4033, train precision: 0.771311, train loss: 90.908607, valid precision: 0.680200, valid loss: 256.594567
epoch: 4034, train precision: 0.885467, train loss: 44.654882, valid precision: 0.736000, valid loss: 182.279498
epoch: 4035, train precision: 0.892467, train loss: 41.027005, valid precision: 0.736800, valid loss: 182.947819
epoch: 4036, train precision: 0.906311, train loss: 36.097025, valid precision: 0.737000, valid loss: 211.154956
epoch: 4037, train precision: 0.907800, train loss: 42.984296, valid precision: 0.734400, valid loss: 231.804194
epoch: 4038, train precision: 0.906911, train loss: 47.118696, valid precision: 0.737000, valid loss: 257.671806
epoch: 4039, train precision: 0.879822, train loss: 48.601448, valid precision: 0.730400, valid loss: 217.677057
epoch: 4040, train precision: 0.865667, train loss: 50.356676, valid precision: 0.714400, valid loss: 217.564882
epoch: 4041, train precision: 0.590889, train loss: 170.989018, valid precision: 0.563200, valid loss: 208.367447
epoch: 4042, train precision: 0.871911, train loss: 53.118020, valid precision: 0.731800, valid loss: 180.018004
epoch: 4043, train precision: 0.878289, train loss: 46.302158, valid precision: 0.729800, valid loss: 191.855072
epoch: 4044, train precision: 0.717200, train loss: 113.362354, valid precision: 0.661000, valid loss: 156.544996
epoch: 4045, train precision: 0.890178, train loss: 43.956119, valid precision: 0.741200, valid loss: 213.406241
epoch: 4046, train precision: 0.899689, train loss: 39.963334, valid precision: 0.736000, valid loss: 212.899239
epoch: 4047, train precision: 0.909178, train loss: 37.151337, valid precision: 0.742000, valid loss: 211.238243
epoch: 4048, train precision: 0.890467, train loss: 42.111558, valid precision: 0.731600, valid loss: 278.003258
epoch: 4049, train precision: 0.238311, train loss: 249.513231, valid precision: 0.258400, valid loss: 246.035957
epoch: 4050, train precision: 0.310422, train loss: 228.825869, valid precision: 0.310200, valid loss: 231.356564
epoch: 4051, train precision: 0.459267, train loss: 195.782723, valid precision: 0.460600, valid loss: 205.961204
epoch: 4052, train precision: 0.514044, train loss: 163.390444, valid precision: 0.508800, valid loss: 179.562588
epoch: 4053, train precision: 0.698778, train loss: 111.228778, valid precision: 0.634000, valid loss: 247.837875
epoch: 4054, train precision: 0.867800, train loss: 58.992787, valid precision: 0.740200, valid loss: 170.296225
epoch: 4055, train precision: 0.871178, train loss: 51.415448, valid precision: 0.730800, valid loss: 138.732644
epoch: 4056, train precision: 0.897489, train loss: 40.156586, valid precision: 0.738200, valid loss: 147.028647
epoch: 4057, train precision: 0.902356, train loss: 38.926787, valid precision: 0.746400, valid loss: 154.629357
epoch: 4058, train precision: 0.894711, train loss: 40.668796, valid precision: 0.733800, valid loss: 175.030480
epoch: 4059, train precision: 0.900156, train loss: 37.949029, valid precision: 0.734800, valid loss: 162.386480
epoch: 4060, train precision: 0.910422, train loss: 35.375296, valid precision: 0.749600, valid loss: 167.387364
epoch: 4061, train precision: 0.188933, train loss: 454.779472, valid precision: 0.199600, valid loss: 445.777453
epoch: 4062, train precision: 0.238400, train loss: 252.803270, valid precision: 0.245000, valid loss: 253.173513
epoch: 4063, train precision: 0.274689, train loss: 244.046981, valid precision: 0.280600, valid loss: 246.337299
epoch: 4064, train precision: 0.297044, train loss: 222.628536, valid precision: 0.299200, valid loss: 226.332840
epoch: 4065, train precision: 0.312689, train loss: 217.709106, valid precision: 0.306600, valid loss: 224.888338
epoch: 4066, train precision: 0.350911, train loss: 206.726863, valid precision: 0.343600, valid loss: 221.888918
epoch: 4067, train precision: 0.261333, train loss: 247.721753, valid precision: 0.269400, valid loss: 242.256516
epoch: 4068, train precision: 0.347800, train loss: 212.660846, valid precision: 0.352200, valid loss: 225.653877
epoch: 4069, train precision: 0.401400, train loss: 190.973417, valid precision: 0.390400, valid loss: 200.955951
epoch: 4070, train precision: 0.571556, train loss: 144.085937, valid precision: 0.531800, valid loss: 261.371004
epoch: 4071, train precision: 0.562000, train loss: 149.951111, valid precision: 0.548800, valid loss: 383.535690
epoch: 4072, train precision: 0.650378, train loss: 128.290677, valid precision: 0.587000, valid loss: 2010.920779
epoch: 4073, train precision: 0.825600, train loss: 67.647230, valid precision: 0.701200, valid loss: 1020.094362
epoch: 4074, train precision: 0.873178, train loss: 49.877080, valid precision: 0.723800, valid loss: 541.451399
epoch: 4075, train precision: 0.870289, train loss: 60.052666, valid precision: 0.716600, valid loss: 488.498679
epoch: 4076, train precision: 0.832244, train loss: 67.392361, valid precision: 0.703800, valid loss: 182.219039
epoch: 4077, train precision: 0.880044, train loss: 48.017463, valid precision: 0.735200, valid loss: 152.833961
epoch: 4078, train precision: 0.884911, train loss: 45.374350, valid precision: 0.730000, valid loss: 211.700581
epoch: 4079, train precision: 0.895022, train loss: 41.382655, valid precision: 0.738200, valid loss: 149.928117
epoch: 4080, train precision: 0.880644, train loss: 46.377516, valid precision: 0.739600, valid loss: 195.731269
epoch: 4081, train precision: 0.288333, train loss: 239.336045, valid precision: 0.299400, valid loss: 307.707212
epoch: 4082, train precision: 0.544422, train loss: 136.330617, valid precision: 0.518200, valid loss: 379.697122
epoch: 4083, train precision: 0.880533, train loss: 47.245321, valid precision: 0.738800, valid loss: 240.871472
epoch: 4084, train precision: 0.902533, train loss: 39.266475, valid precision: 0.735200, valid loss: 413.361339
epoch: 4085, train precision: 0.886311, train loss: 44.884120, valid precision: 0.734000, valid loss: 471.495516
epoch: 4086, train precision: 0.701844, train loss: 130.264406, valid precision: 0.632200, valid loss: 176.985154
epoch: 4087, train precision: 0.751244, train loss: 94.170295, valid precision: 0.670400, valid loss: 149.324756
epoch: 4088, train precision: 0.864133, train loss: 52.498284, valid precision: 0.733200, valid loss: 145.006867
epoch: 4089, train precision: 0.868533, train loss: 51.041800, valid precision: 0.720000, valid loss: 174.234973
epoch: 4090, train precision: 0.792933, train loss: 81.236807, valid precision: 0.700000, valid loss: 144.591844
epoch: 4091, train precision: 0.850067, train loss: 56.272610, valid precision: 0.716200, valid loss: 150.071254
epoch: 4092, train precision: 0.190200, train loss: 306.145837, valid precision: 0.198800, valid loss: 305.154058
epoch: 4093, train precision: 0.285511, train loss: 234.169450, valid precision: 0.287600, valid loss: 235.655873
epoch: 4094, train precision: 0.593800, train loss: 156.204855, valid precision: 0.557200, valid loss: 174.914250
epoch: 4095, train precision: 0.861133, train loss: 54.558238, valid precision: 0.718200, valid loss: 168.449372
epoch: 4096, train precision: 0.889644, train loss: 42.909851, valid precision: 0.729600, valid loss: 156.766477
epoch: 4097, train precision: 0.902022, train loss: 38.391961, valid precision: 0.737000, valid loss: 166.101412
epoch: 4098, train precision: 0.873689, train loss: 48.808371, valid precision: 0.732000, valid loss: 149.768908
epoch: 4099, train precision: 0.878756, train loss: 48.463007, valid precision: 0.721800, valid loss: 175.013773
epoch: 4100, train precision: 0.879911, train loss: 47.654315, valid precision: 0.727200, valid loss: 174.117504
epoch: 4101, train precision: 0.865889, train loss: 53.222423, valid precision: 0.718800, valid loss: 181.188355
epoch: 4102, train precision: 0.908422, train loss: 36.902061, valid precision: 0.749200, valid loss: 168.624325
epoch: 4103, train precision: 0.914422, train loss: 36.357901, valid precision: 0.744800, valid loss: 178.007169
epoch: 4104, train precision: 0.878022, train loss: 50.366159, valid precision: 0.728400, valid loss: 161.780350
epoch: 4105, train precision: 0.897533, train loss: 40.674334, valid precision: 0.732800, valid loss: 179.819729
epoch: 4106, train precision: 0.857889, train loss: 56.802037, valid precision: 0.710600, valid loss: 229.141334
epoch: 4107, train precision: 0.596000, train loss: 164.176005, valid precision: 0.565600, valid loss: 194.365870
epoch: 4108, train precision: 0.810178, train loss: 99.889552, valid precision: 0.703200, valid loss: 157.076541
epoch: 4109, train precision: 0.852644, train loss: 59.451455, valid precision: 0.713200, valid loss: 202.182116
epoch: 4110, train precision: 0.662756, train loss: 132.284339, valid precision: 0.636600, valid loss: 160.118726
epoch: 4111, train precision: 0.795222, train loss: 88.553072, valid precision: 0.696600, valid loss: 149.795738
epoch: 4112, train precision: 0.375311, train loss: 209.908566, valid precision: 0.383800, valid loss: 210.017263
epoch: 4113, train precision: 0.468756, train loss: 173.549080, valid precision: 0.460400, valid loss: 188.346476
epoch: 4114, train precision: 0.758778, train loss: 94.961653, valid precision: 0.669400, valid loss: 158.100038
epoch: 4115, train precision: 0.869644, train loss: 51.539895, valid precision: 0.726200, valid loss: 145.112150
epoch: 4116, train precision: 0.753289, train loss: 96.472824, valid precision: 0.662800, valid loss: 171.355202
epoch: 4117, train precision: 0.867556, train loss: 50.943381, valid precision: 0.727000, valid loss: 158.543214
epoch: 4118, train precision: 0.891733, train loss: 42.631372, valid precision: 0.734800, valid loss: 167.187799
epoch: 4119, train precision: 0.889800, train loss: 43.844843, valid precision: 0.723800, valid loss: 164.924874
epoch: 4120, train precision: 0.896444, train loss: 42.353360, valid precision: 0.744400, valid loss: 170.500024
epoch: 4121, train precision: 0.679578, train loss: 122.710260, valid precision: 0.632400, valid loss: 156.295163
epoch: 4122, train precision: 0.873911, train loss: 49.423122, valid precision: 0.717400, valid loss: 149.775986
epoch: 4123, train precision: 0.898133, train loss: 40.966938, valid precision: 0.731800, valid loss: 162.177175
epoch: 4124, train precision: 0.916467, train loss: 33.244656, valid precision: 0.744600, valid loss: 150.793035
epoch: 4125, train precision: 0.871822, train loss: 49.202385, valid precision: 0.719400, valid loss: 179.249876
epoch: 4126, train precision: 0.906844, train loss: 36.598931, valid precision: 0.733800, valid loss: 208.619045
epoch: 4127, train precision: 0.907778, train loss: 36.684152, valid precision: 0.732200, valid loss: 170.376926
epoch: 4128, train precision: 0.905156, train loss: 37.745368, valid precision: 0.736600, valid loss: 207.668283
epoch: 4129, train precision: 0.882111, train loss: 47.013910, valid precision: 0.731600, valid loss: 159.718246
epoch: 4130, train precision: 0.321867, train loss: 318.197308, valid precision: 0.320400, valid loss: 327.899742
epoch: 4131, train precision: 0.620200, train loss: 149.024478, valid precision: 0.582400, valid loss: 180.331082
epoch: 4132, train precision: 0.821222, train loss: 67.859613, valid precision: 0.701600, valid loss: 301.692417
epoch: 4133, train precision: 0.696289, train loss: 116.179876, valid precision: 0.641400, valid loss: 161.787552
epoch: 4134, train precision: 0.811356, train loss: 77.235629, valid precision: 0.700800, valid loss: 423.879005
epoch: 4135, train precision: 0.879222, train loss: 48.795910, valid precision: 0.723800, valid loss: 517.966792
epoch: 4136, train precision: 0.559556, train loss: 167.267777, valid precision: 0.544000, valid loss: 192.546604
epoch: 4137, train precision: 0.864133, train loss: 51.572195, valid precision: 0.722800, valid loss: 559.510874
epoch: 4138, train precision: 0.899356, train loss: 39.193127, valid precision: 0.732200, valid loss: 609.970846
epoch: 4139, train precision: 0.886644, train loss: 48.595519, valid precision: 0.733200, valid loss: 212.119502
epoch: 4140, train precision: 0.890311, train loss: 43.886761, valid precision: 0.728600, valid loss: 218.837812
epoch: 4141, train precision: 0.758378, train loss: 94.479598, valid precision: 0.683600, valid loss: 139.746249
epoch: 4142, train precision: 0.840467, train loss: 62.185616, valid precision: 0.715200, valid loss: 150.909950
epoch: 4143, train precision: 0.540822, train loss: 181.805203, valid precision: 0.506600, valid loss: 210.336307
epoch: 4144, train precision: 0.895289, train loss: 42.198618, valid precision: 0.738800, valid loss: 157.030788
epoch: 4145, train precision: 0.880044, train loss: 46.557871, valid precision: 0.737600, valid loss: 168.037632
epoch: 4146, train precision: 0.745778, train loss: 96.502880, valid precision: 0.658800, valid loss: 304.960807
epoch: 4147, train precision: 0.879067, train loss: 49.077228, valid precision: 0.724400, valid loss: 502.926942
epoch: 4148, train precision: 0.906200, train loss: 37.401078, valid precision: 0.743600, valid loss: 165.056633
epoch: 4149, train precision: 0.902044, train loss: 36.399469, valid precision: 0.739400, valid loss: 149.008219
epoch: 4150, train precision: 0.852400, train loss: 59.621407, valid precision: 0.725600, valid loss: 145.979159
epoch: 4151, train precision: 0.886667, train loss: 44.422117, valid precision: 0.735600, valid loss: 187.239388
epoch: 4152, train precision: 0.905578, train loss: 42.797600, valid precision: 0.741800, valid loss: 215.733325
epoch: 4153, train precision: 0.904444, train loss: 37.708888, valid precision: 0.742800, valid loss: 205.566320
epoch: 4154, train precision: 0.906267, train loss: 37.285077, valid precision: 0.738000, valid loss: 195.596123
epoch: 4155, train precision: 0.897222, train loss: 40.547494, valid precision: 0.734600, valid loss: 175.585632
epoch: 4156, train precision: 0.909133, train loss: 38.372804, valid precision: 0.744800, valid loss: 244.795243
epoch: 4157, train precision: 0.895444, train loss: 41.086376, valid precision: 0.726200, valid loss: 447.342122
epoch: 4158, train precision: 0.523200, train loss: 297.107159, valid precision: 0.507400, valid loss: 323.986627
epoch: 4159, train precision: 0.704200, train loss: 115.648649, valid precision: 0.668800, valid loss: 149.814998
epoch: 4160, train precision: 0.903378, train loss: 38.994364, valid precision: 0.746400, valid loss: 2099.312347
epoch: 4161, train precision: 0.900911, train loss: 39.799247, valid precision: 0.734800, valid loss: 2313.837593
epoch: 4162, train precision: 0.909711, train loss: 35.827225, valid precision: 0.739000, valid loss: 2361.011140
epoch: 4163, train precision: 0.905178, train loss: 37.063879, valid precision: 0.742600, valid loss: 3433.754207
epoch: 4164, train precision: 0.818644, train loss: 76.868827, valid precision: 0.705800, valid loss: 728.711388
epoch: 4165, train precision: 0.903311, train loss: 43.523885, valid precision: 0.740000, valid loss: 697.257276
epoch: 4166, train precision: 0.600622, train loss: 136.806931, valid precision: 0.553800, valid loss: 556.287622
epoch: 4167, train precision: 0.890867, train loss: 42.209144, valid precision: 0.743400, valid loss: 188.879376
epoch: 4168, train precision: 0.644222, train loss: 140.965719, valid precision: 0.583200, valid loss: 370.234307
epoch: 4169, train precision: 0.908444, train loss: 38.289970, valid precision: 0.748400, valid loss: 981.996361
epoch: 4170, train precision: 0.923756, train loss: 31.029169, valid precision: 0.754200, valid loss: 1125.590820
epoch: 4171, train precision: 0.655689, train loss: 148.403385, valid precision: 0.610600, valid loss: 172.094227
epoch: 4172, train precision: 0.856267, train loss: 55.835076, valid precision: 0.720000, valid loss: 146.908367
epoch: 4173, train precision: 0.836778, train loss: 64.236082, valid precision: 0.727800, valid loss: 142.143371
epoch: 4174, train precision: 0.876422, train loss: 47.994062, valid precision: 0.726600, valid loss: 149.201749
epoch: 4175, train precision: 0.905689, train loss: 37.340596, valid precision: 0.742600, valid loss: 159.331767
epoch: 4176, train precision: 0.171044, train loss: 304.229004, valid precision: 0.174800, valid loss: 301.621923
epoch: 4177, train precision: 0.247111, train loss: 264.028201, valid precision: 0.242800, valid loss: 267.096007
epoch: 4178, train precision: 0.272089, train loss: 242.804537, valid precision: 0.273600, valid loss: 245.873964
epoch: 4179, train precision: 0.314222, train loss: 212.099260, valid precision: 0.309600, valid loss: 216.806799
epoch: 4180, train precision: 0.378844, train loss: 196.262001, valid precision: 0.375800, valid loss: 206.797639
epoch: 4181, train precision: 0.389778, train loss: 188.489981, valid precision: 0.374800, valid loss: 207.533683
epoch: 4182, train precision: 0.570111, train loss: 149.355340, valid precision: 0.532800, valid loss: 182.035551
epoch: 4183, train precision: 0.657556, train loss: 118.392526, valid precision: 0.572600, valid loss: 466.645331
epoch: 4184, train precision: 0.708533, train loss: 102.466297, valid precision: 0.614600, valid loss: 224.626456
epoch: 4185, train precision: 0.678822, train loss: 110.234821, valid precision: 0.598400, valid loss: 206.956784
epoch: 4186, train precision: 0.900978, train loss: 42.814373, valid precision: 0.741800, valid loss: 330.400644
epoch: 4187, train precision: 0.851000, train loss: 62.613380, valid precision: 0.727800, valid loss: 372.078266
epoch: 4188, train precision: 0.890978, train loss: 43.714374, valid precision: 0.731600, valid loss: 200.825015
epoch: 4189, train precision: 0.894067, train loss: 41.326446, valid precision: 0.734600, valid loss: 155.335802
epoch: 4190, train precision: 0.844778, train loss: 59.328827, valid precision: 0.719600, valid loss: 150.605247
epoch: 4191, train precision: 0.911578, train loss: 38.072661, valid precision: 0.749200, valid loss: 160.266387
epoch: 4192, train precision: 0.900400, train loss: 39.327904, valid precision: 0.732000, valid loss: 178.834209
epoch: 4193, train precision: 0.794889, train loss: 83.240963, valid precision: 0.701600, valid loss: 153.514156
epoch: 4194, train precision: 0.889800, train loss: 43.322693, valid precision: 0.739200, valid loss: 170.798875
epoch: 4195, train precision: 0.907333, train loss: 36.310182, valid precision: 0.744400, valid loss: 231.811890
epoch: 4196, train precision: 0.918489, train loss: 32.635261, valid precision: 0.753400, valid loss: 1492.297932
epoch: 4197, train precision: 0.864289, train loss: 64.770790, valid precision: 0.732200, valid loss: 1443.316792
epoch: 4198, train precision: 0.899378, train loss: 41.899786, valid precision: 0.742400, valid loss: 718.964441
epoch: 4199, train precision: 0.628200, train loss: 141.994752, valid precision: 0.596000, valid loss: 217.580681
epoch: 4200, train precision: 0.868933, train loss: 53.174279, valid precision: 0.729400, valid loss: 1315.385618
epoch: 4201, train precision: 0.892800, train loss: 41.902848, valid precision: 0.741800, valid loss: 846.945421
epoch: 4202, train precision: 0.904622, train loss: 37.057812, valid precision: 0.746200, valid loss: 1181.014302
epoch: 4203, train precision: 0.897556, train loss: 41.569131, valid precision: 0.736600, valid loss: 851.694164
epoch: 4204, train precision: 0.910267, train loss: 40.298603, valid precision: 0.745800, valid loss: 533.664901
epoch: 4205, train precision: 0.917844, train loss: 34.370401, valid precision: 0.744600, valid loss: 1340.566215
epoch: 4206, train precision: 0.475244, train loss: 176.504492, valid precision: 0.475800, valid loss: 199.364940
epoch: 4207, train precision: 0.589956, train loss: 139.637739, valid precision: 0.550000, valid loss: 336.298217
epoch: 4208, train precision: 0.680089, train loss: 120.028329, valid precision: 0.633600, valid loss: 152.520049
epoch: 4209, train precision: 0.880800, train loss: 46.812359, valid precision: 0.737200, valid loss: 149.114270
epoch: 4210, train precision: 0.812467, train loss: 78.772536, valid precision: 0.718600, valid loss: 149.859425
epoch: 4211, train precision: 0.902533, train loss: 39.063489, valid precision: 0.746600, valid loss: 151.280732
epoch: 4212, train precision: 0.910289, train loss: 35.976302, valid precision: 0.743400, valid loss: 149.319452
epoch: 4213, train precision: 0.751556, train loss: 103.670884, valid precision: 0.668800, valid loss: 156.791800
epoch: 4214, train precision: 0.887867, train loss: 44.845634, valid precision: 0.737800, valid loss: 153.441126
epoch: 4215, train precision: 0.900867, train loss: 39.419826, valid precision: 0.736200, valid loss: 158.803830
epoch: 4216, train precision: 0.549489, train loss: 158.694429, valid precision: 0.529400, valid loss: 181.809412
epoch: 4217, train precision: 0.857911, train loss: 56.961816, valid precision: 0.728600, valid loss: 142.734762
epoch: 4218, train precision: 0.875378, train loss: 48.804986, valid precision: 0.731400, valid loss: 152.473268
epoch: 4219, train precision: 0.908200, train loss: 36.786767, valid precision: 0.745200, valid loss: 153.834593
epoch: 4220, train precision: 0.894778, train loss: 43.768008, valid precision: 0.734800, valid loss: 165.074479
epoch: 4221, train precision: 0.902400, train loss: 39.008259, valid precision: 0.742400, valid loss: 168.752632
epoch: 4222, train precision: 0.901844, train loss: 44.512942, valid precision: 0.738200, valid loss: 175.213062
epoch: 4223, train precision: 0.108844, train loss: 824.505269, valid precision: 0.106800, valid loss: 827.421805
epoch: 4224, train precision: 0.414178, train loss: 213.600365, valid precision: 0.411400, valid loss: 218.840748
epoch: 4225, train precision: 0.549778, train loss: 149.945949, valid precision: 0.522400, valid loss: 177.576179
epoch: 4226, train precision: 0.893600, train loss: 47.587472, valid precision: 0.738800, valid loss: 150.426011
epoch: 4227, train precision: 0.773933, train loss: 92.497077, valid precision: 0.690600, valid loss: 153.566597
epoch: 4228, train precision: 0.503533, train loss: 182.873766, valid precision: 0.493200, valid loss: 195.994659
epoch: 4229, train precision: 0.805889, train loss: 77.688480, valid precision: 0.710600, valid loss: 147.313751
epoch: 4230, train precision: 0.511933, train loss: 194.715234, valid precision: 0.493000, valid loss: 209.319224
epoch: 4231, train precision: 0.823600, train loss: 71.314868, valid precision: 0.717200, valid loss: 160.679053
epoch: 4232, train precision: 0.895667, train loss: 42.847215, valid precision: 0.742600, valid loss: 156.933727
epoch: 4233, train precision: 0.623200, train loss: 197.464098, valid precision: 0.594200, valid loss: 243.361121
epoch: 4234, train precision: 0.906711, train loss: 37.529876, valid precision: 0.741800, valid loss: 153.306531
epoch: 4235, train precision: 0.881089, train loss: 49.586195, valid precision: 0.725400, valid loss: 235.854052
epoch: 4236, train precision: 0.905533, train loss: 37.893407, valid precision: 0.736000, valid loss: 309.293819
epoch: 4237, train precision: 0.693089, train loss: 131.943160, valid precision: 0.636400, valid loss: 186.116097
epoch: 4238, train precision: 0.891667, train loss: 44.530157, valid precision: 0.737600, valid loss: 166.623203
epoch: 4239, train precision: 0.903600, train loss: 38.093776, valid precision: 0.734800, valid loss: 244.132441
epoch: 4240, train precision: 0.898089, train loss: 39.272126, valid precision: 0.730400, valid loss: 192.687330
epoch: 4241, train precision: 0.902467, train loss: 40.212956, valid precision: 0.740600, valid loss: 173.716612
epoch: 4242, train precision: 0.697444, train loss: 115.674363, valid precision: 0.633200, valid loss: 159.397840
epoch: 4243, train precision: 0.884778, train loss: 45.785347, valid precision: 0.737200, valid loss: 191.918073
epoch: 4244, train precision: 0.912044, train loss: 34.452404, valid precision: 0.740200, valid loss: 163.752101
epoch: 4245, train precision: 0.905311, train loss: 37.337738, valid precision: 0.735200, valid loss: 195.135261
epoch: 4246, train precision: 0.917533, train loss: 33.629982, valid precision: 0.749400, valid loss: 251.382496
epoch: 4247, train precision: 0.710689, train loss: 120.394172, valid precision: 0.586800, valid loss: 304.257398
epoch: 4248, train precision: 0.858622, train loss: 53.884773, valid precision: 0.716600, valid loss: 179.537447
epoch: 4249, train precision: 0.890622, train loss: 43.165887, valid precision: 0.729000, valid loss: 212.346976
epoch: 4250, train precision: 0.436689, train loss: 214.898319, valid precision: 0.427800, valid loss: 229.100367
epoch: 4251, train precision: 0.774978, train loss: 86.103126, valid precision: 0.680800, valid loss: 272.290955
epoch: 4252, train precision: 0.881867, train loss: 47.854401, valid precision: 0.722200, valid loss: 977.827004
epoch: 4253, train precision: 0.307311, train loss: 236.494637, valid precision: 0.304000, valid loss: 257.996868
epoch: 4254, train precision: 0.722467, train loss: 110.579701, valid precision: 0.655800, valid loss: 163.781617
epoch: 4255, train precision: 0.885733, train loss: 44.907806, valid precision: 0.738000, valid loss: 228.938584
epoch: 4256, train precision: 0.911378, train loss: 35.914526, valid precision: 0.739400, valid loss: 210.744692
epoch: 4257, train precision: 0.905756, train loss: 38.922711, valid precision: 0.725000, valid loss: 290.954393
epoch: 4258, train precision: 0.630156, train loss: 147.167431, valid precision: 0.598000, valid loss: 347.159009
epoch: 4259, train precision: 0.875222, train loss: 49.052857, valid precision: 0.722000, valid loss: 331.665289
epoch: 4260, train precision: 0.916133, train loss: 33.833173, valid precision: 0.745400, valid loss: 507.611529
epoch: 4261, train precision: 0.886311, train loss: 44.660498, valid precision: 0.734000, valid loss: 240.943568
epoch: 4262, train precision: 0.899800, train loss: 40.082548, valid precision: 0.741200, valid loss: 295.508873
epoch: 4263, train precision: 0.902356, train loss: 38.591138, valid precision: 0.738000, valid loss: 445.356711
epoch: 4264, train precision: 0.910756, train loss: 35.988225, valid precision: 0.743400, valid loss: 731.637189
epoch: 4265, train precision: 0.912756, train loss: 35.070613, valid precision: 0.741200, valid loss: 296.798978
epoch: 4266, train precision: 0.896733, train loss: 43.087073, valid precision: 0.739000, valid loss: 282.461918
epoch: 4267, train precision: 0.918778, train loss: 33.526907, valid precision: 0.747600, valid loss: 449.126851
epoch: 4268, train precision: 0.836400, train loss: 70.213208, valid precision: 0.716400, valid loss: 459.025263
epoch: 4269, train precision: 0.923356, train loss: 30.591595, valid precision: 0.749400, valid loss: 346.142275
epoch: 4270, train precision: 0.878156, train loss: 45.525562, valid precision: 0.724200, valid loss: 724.848055
epoch: 4271, train precision: 0.923889, train loss: 30.637786, valid precision: 0.741000, valid loss: 365.500238
epoch: 4272, train precision: 0.235778, train loss: 268.196512, valid precision: 0.252400, valid loss: 265.502768
epoch: 4273, train precision: 0.435111, train loss: 176.755365, valid precision: 0.415400, valid loss: 191.919269
epoch: 4274, train precision: 0.832222, train loss: 65.416161, valid precision: 0.705200, valid loss: 320.184525
epoch: 4275, train precision: 0.842378, train loss: 61.585750, valid precision: 0.720600, valid loss: 181.703058
epoch: 4276, train precision: 0.894711, train loss: 41.382786, valid precision: 0.726800, valid loss: 400.382482
epoch: 4277, train precision: 0.239333, train loss: 266.966913, valid precision: 0.246800, valid loss: 268.763444
epoch: 4278, train precision: 0.624600, train loss: 162.338971, valid precision: 0.592000, valid loss: 241.582841
epoch: 4279, train precision: 0.852422, train loss: 59.590059, valid precision: 0.715400, valid loss: 235.052392
epoch: 4280, train precision: 0.905956, train loss: 37.023443, valid precision: 0.735600, valid loss: 217.144358
epoch: 4281, train precision: 0.924689, train loss: 31.205744, valid precision: 0.748800, valid loss: 227.657524
epoch: 4282, train precision: 0.786644, train loss: 86.971869, valid precision: 0.680800, valid loss: 195.237827
epoch: 4283, train precision: 0.893844, train loss: 42.366074, valid precision: 0.739000, valid loss: 207.535047
epoch: 4284, train precision: 0.845533, train loss: 61.497234, valid precision: 0.726000, valid loss: 146.169697
epoch: 4285, train precision: 0.891667, train loss: 41.612040, valid precision: 0.728000, valid loss: 208.768357
epoch: 4286, train precision: 0.909400, train loss: 36.042146, valid precision: 0.739800, valid loss: 311.582511
epoch: 4287, train precision: 0.901089, train loss: 38.790907, valid precision: 0.728400, valid loss: 600.490697
epoch: 4288, train precision: 0.888756, train loss: 43.590051, valid precision: 0.725600, valid loss: 1003.197304
epoch: 4289, train precision: 0.879667, train loss: 49.415174, valid precision: 0.716800, valid loss: 1304.337174
epoch: 4290, train precision: 0.917022, train loss: 38.031558, valid precision: 0.745000, valid loss: 1137.375491
epoch: 4291, train precision: 0.912222, train loss: 35.037610, valid precision: 0.736400, valid loss: 1067.208403
epoch: 4292, train precision: 0.875778, train loss: 49.274458, valid precision: 0.735400, valid loss: 247.475438
epoch: 4293, train precision: 0.865400, train loss: 53.141739, valid precision: 0.713800, valid loss: 319.664324
epoch: 4294, train precision: 0.904044, train loss: 36.894185, valid precision: 0.740000, valid loss: 383.052825
epoch: 4295, train precision: 0.901178, train loss: 39.558590, valid precision: 0.732000, valid loss: 769.989039
epoch: 4296, train precision: 0.901778, train loss: 39.707043, valid precision: 0.726600, valid loss: 1016.553436
epoch: 4297, train precision: 0.857600, train loss: 54.724729, valid precision: 0.698200, valid loss: 907.687332
epoch: 4298, train precision: 0.304156, train loss: 221.413525, valid precision: 0.302800, valid loss: 227.495113
epoch: 4299, train precision: 0.829333, train loss: 77.740556, valid precision: 0.698000, valid loss: 746.560211
epoch: 4300, train precision: 0.459022, train loss: 204.290405, valid precision: 0.449200, valid loss: 216.073085
epoch: 4301, train precision: 0.629800, train loss: 141.259456, valid precision: 0.611800, valid loss: 158.850474
epoch: 4302, train precision: 0.735333, train loss: 103.550443, valid precision: 0.677200, valid loss: 153.107445
epoch: 4303, train precision: 0.340333, train loss: 232.111676, valid precision: 0.345800, valid loss: 233.542270
epoch: 4304, train precision: 0.723178, train loss: 105.609778, valid precision: 0.669800, valid loss: 152.858870
epoch: 4305, train precision: 0.860644, train loss: 54.435964, valid precision: 0.726400, valid loss: 166.971302
epoch: 4306, train precision: 0.790333, train loss: 84.406497, valid precision: 0.699600, valid loss: 161.802453
epoch: 4307, train precision: 0.880067, train loss: 46.251478, valid precision: 0.734400, valid loss: 178.301992
epoch: 4308, train precision: 0.903867, train loss: 40.353713, valid precision: 0.738000, valid loss: 182.655890
epoch: 4309, train precision: 0.846000, train loss: 60.050662, valid precision: 0.718000, valid loss: 170.950293
epoch: 4310, train precision: 0.917178, train loss: 33.238393, valid precision: 0.744400, valid loss: 185.532423
epoch: 4311, train precision: 0.899867, train loss: 40.384964, valid precision: 0.734200, valid loss: 232.168298
epoch: 4312, train precision: 0.827800, train loss: 68.085492, valid precision: 0.694000, valid loss: 184.216173
epoch: 4313, train precision: 0.892933, train loss: 43.263378, valid precision: 0.747000, valid loss: 360.435009
epoch: 4314, train precision: 0.665444, train loss: 131.837594, valid precision: 0.616000, valid loss: 226.712873
epoch: 4315, train precision: 0.725022, train loss: 109.331376, valid precision: 0.674600, valid loss: 190.551735
epoch: 4316, train precision: 0.863333, train loss: 51.236356, valid precision: 0.728600, valid loss: 183.870652
epoch: 4317, train precision: 0.768778, train loss: 96.078803, valid precision: 0.693800, valid loss: 160.716695
epoch: 4318, train precision: 0.905600, train loss: 37.254242, valid precision: 0.745000, valid loss: 204.976602
epoch: 4319, train precision: 0.686533, train loss: 117.964316, valid precision: 0.626400, valid loss: 175.431277
epoch: 4320, train precision: 0.911844, train loss: 35.227882, valid precision: 0.729200, valid loss: 204.565388
epoch: 4321, train precision: 0.921311, train loss: 31.562311, valid precision: 0.745000, valid loss: 197.286732
epoch: 4322, train precision: 0.185444, train loss: 2760.189891, valid precision: 0.188000, valid loss: 387.623050
epoch: 4323, train precision: 0.211911, train loss: 270.180506, valid precision: 0.214400, valid loss: 271.555179
epoch: 4324, train precision: 0.260800, train loss: 244.867324, valid precision: 0.272400, valid loss: 241.847008
epoch: 4325, train precision: 0.427556, train loss: 213.506109, valid precision: 0.443200, valid loss: 213.056465
epoch: 4326, train precision: 0.421956, train loss: 189.846091, valid precision: 0.416800, valid loss: 215.106359
epoch: 4327, train precision: 0.674200, train loss: 123.291818, valid precision: 0.627000, valid loss: 168.768185
epoch: 4328, train precision: 0.321533, train loss: 246.193918, valid precision: 0.320400, valid loss: 244.811303
epoch: 4329, train precision: 0.644533, train loss: 135.196372, valid precision: 0.610800, valid loss: 159.908811
epoch: 4330, train precision: 0.809022, train loss: 75.131542, valid precision: 0.699200, valid loss: 147.335022
epoch: 4331, train precision: 0.893378, train loss: 41.657254, valid precision: 0.739400, valid loss: 167.113460
epoch: 4332, train precision: 0.906956, train loss: 38.264269, valid precision: 0.741800, valid loss: 254.136266
epoch: 4333, train precision: 0.902956, train loss: 38.305525, valid precision: 0.736000, valid loss: 286.338811
epoch: 4334, train precision: 0.338156, train loss: 227.370570, valid precision: 0.329800, valid loss: 235.756432
epoch: 4335, train precision: 0.643133, train loss: 135.480275, valid precision: 0.617400, valid loss: 163.898603
epoch: 4336, train precision: 0.754156, train loss: 95.598111, valid precision: 0.693000, valid loss: 170.868777
epoch: 4337, train precision: 0.782333, train loss: 84.517151, valid precision: 0.694200, valid loss: 216.418626
epoch: 4338, train precision: 0.851956, train loss: 58.625053, valid precision: 0.726000, valid loss: 292.661096
epoch: 4339, train precision: 0.341089, train loss: 253.639762, valid precision: 0.336200, valid loss: 256.319468
epoch: 4340, train precision: 0.788356, train loss: 82.255236, valid precision: 0.712000, valid loss: 330.571971
epoch: 4341, train precision: 0.873667, train loss: 49.846310, valid precision: 0.731000, valid loss: 180.166904
epoch: 4342, train precision: 0.296200, train loss: 225.823940, valid precision: 0.297000, valid loss: 245.403427
epoch: 4343, train precision: 0.457222, train loss: 188.312576, valid precision: 0.450200, valid loss: 242.080538
epoch: 4344, train precision: 0.534422, train loss: 161.918478, valid precision: 0.511400, valid loss: 237.913347
epoch: 4345, train precision: 0.650133, train loss: 131.046328, valid precision: 0.608000, valid loss: 226.800506
epoch: 4346, train precision: 0.726111, train loss: 105.254120, valid precision: 0.662800, valid loss: 224.716591
epoch: 4347, train precision: 0.715978, train loss: 106.574320, valid precision: 0.652400, valid loss: 207.734712
epoch: 4348, train precision: 0.765778, train loss: 94.143556, valid precision: 0.677400, valid loss: 239.518905
epoch: 4349, train precision: 0.757689, train loss: 95.860570, valid precision: 0.681800, valid loss: 198.667443
epoch: 4350, train precision: 0.812156, train loss: 74.513138, valid precision: 0.704800, valid loss: 179.292820
epoch: 4351, train precision: 0.838356, train loss: 63.805040, valid precision: 0.724200, valid loss: 169.145200
epoch: 4352, train precision: 0.831111, train loss: 63.611517, valid precision: 0.708000, valid loss: 190.746422
epoch: 4353, train precision: 0.821889, train loss: 69.956610, valid precision: 0.720800, valid loss: 200.601525
epoch: 4354, train precision: 0.881667, train loss: 47.138588, valid precision: 0.734600, valid loss: 338.494149
epoch: 4355, train precision: 0.338400, train loss: 220.438219, valid precision: 0.342400, valid loss: 230.543577
epoch: 4356, train precision: 0.815667, train loss: 72.093570, valid precision: 0.710600, valid loss: 170.287084
epoch: 4357, train precision: 0.857778, train loss: 55.284330, valid precision: 0.719600, valid loss: 369.348804
epoch: 4358, train precision: 0.870889, train loss: 55.796035, valid precision: 0.738600, valid loss: 153.644169
epoch: 4359, train precision: 0.506667, train loss: 190.056121, valid precision: 0.488400, valid loss: 388.040277
epoch: 4360, train precision: 0.839911, train loss: 64.154625, valid precision: 0.722800, valid loss: 147.754818
epoch: 4361, train precision: 0.789311, train loss: 78.174511, valid precision: 0.696200, valid loss: 156.375768
epoch: 4362, train precision: 0.843933, train loss: 60.805378, valid precision: 0.719400, valid loss: 160.657495
epoch: 4363, train precision: 0.886889, train loss: 44.363004, valid precision: 0.739400, valid loss: 145.766704
epoch: 4364, train precision: 0.838178, train loss: 73.976357, valid precision: 0.688600, valid loss: 193.932484
epoch: 4365, train precision: 0.900578, train loss: 40.328559, valid precision: 0.739400, valid loss: 152.244188
epoch: 4366, train precision: 0.100267, train loss: 715.100554, valid precision: 0.097600, valid loss: 717.211394
epoch: 4367, train precision: 0.100267, train loss: 640.318874, valid precision: 0.097600, valid loss: 642.448102
epoch: 4368, train precision: 0.100267, train loss: 588.149195, valid precision: 0.097600, valid loss: 590.237415
epoch: 4369, train precision: 0.100267, train loss: 542.262109, valid precision: 0.097600, valid loss: 544.244884
epoch: 4370, train precision: 0.100289, train loss: 500.014745, valid precision: 0.097600, valid loss: 501.869696
epoch: 4371, train precision: 0.100267, train loss: 461.456836, valid precision: 0.097600, valid loss: 463.155870
epoch: 4372, train precision: 0.100289, train loss: 427.178505, valid precision: 0.097600, valid loss: 428.707488
epoch: 4373, train precision: 0.100267, train loss: 397.523665, valid precision: 0.097600, valid loss: 398.841087
epoch: 4374, train precision: 0.100267, train loss: 372.226468, valid precision: 0.097600, valid loss: 373.306352
epoch: 4375, train precision: 0.100267, train loss: 351.071087, valid precision: 0.097600, valid loss: 351.661746
epoch: 4376, train precision: 0.100267, train loss: 334.160699, valid precision: 0.097600, valid loss: 334.461143
epoch: 4377, train precision: 0.100267, train loss: 321.338011, valid precision: 0.097600, valid loss: 321.432953
epoch: 4378, train precision: 0.100267, train loss: 311.940552, valid precision: 0.097600, valid loss: 311.886257
epoch: 4379, train precision: 0.100267, train loss: 305.207278, valid precision: 0.097600, valid loss: 305.060849
epoch: 4380, train precision: 0.100289, train loss: 300.579674, valid precision: 0.097600, valid loss: 300.393602
epoch: 4381, train precision: 0.100267, train loss: 297.654549, valid precision: 0.097600, valid loss: 297.446126
epoch: 4382, train precision: 0.100267, train loss: 295.979720, valid precision: 0.097600, valid loss: 295.770371
epoch: 4383, train precision: 0.100289, train loss: 295.122301, valid precision: 0.097600, valid loss: 294.922927
epoch: 4384, train precision: 0.100267, train loss: 294.746993, valid precision: 0.097600, valid loss: 294.543598
epoch: 4385, train precision: 0.100267, train loss: 294.596395, valid precision: 0.097600, valid loss: 294.392561
epoch: 4386, train precision: 0.100267, train loss: 294.544382, valid precision: 0.097600, valid loss: 294.338057
epoch: 4387, train precision: 0.100267, train loss: 294.528755, valid precision: 0.097600, valid loss: 294.319427
epoch: 4388, train precision: 0.100267, train loss: 294.524833, valid precision: 0.097600, valid loss: 294.313040
epoch: 4389, train precision: 0.100556, train loss: 294.524068, valid precision: 0.095000, valid loss: 294.310654
epoch: 4390, train precision: 0.100556, train loss: 294.524016, valid precision: 0.095000, valid loss: 294.309710
epoch: 4391, train precision: 0.100556, train loss: 294.524045, valid precision: 0.095000, valid loss: 294.309294
epoch: 4392, train precision: 0.100556, train loss: 294.524059, valid precision: 0.095000, valid loss: 294.309102
epoch: 4393, train precision: 0.100556, train loss: 294.524063, valid precision: 0.095000, valid loss: 294.309006
epoch: 4394, train precision: 0.100556, train loss: 294.524075, valid precision: 0.095000, valid loss: 294.308967
epoch: 4395, train precision: 0.100556, train loss: 294.524091, valid precision: 0.095000, valid loss: 294.308959
epoch: 4396, train precision: 0.100556, train loss: 294.524088, valid precision: 0.095000, valid loss: 294.308929
epoch: 4397, train precision: 0.100578, train loss: 294.517559, valid precision: 0.095000, valid loss: 294.308776
epoch: 4398, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308875
epoch: 4399, train precision: 0.100556, train loss: 294.524120, valid precision: 0.095000, valid loss: 294.308915
epoch: 4400, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308906
epoch: 4401, train precision: 0.100578, train loss: 294.517554, valid precision: 0.095000, valid loss: 294.308739
epoch: 4402, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308845
epoch: 4403, train precision: 0.100556, train loss: 294.524103, valid precision: 0.095000, valid loss: 294.308885
epoch: 4404, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308881
epoch: 4405, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308881
epoch: 4406, train precision: 0.100556, train loss: 294.524114, valid precision: 0.095000, valid loss: 294.308896
epoch: 4407, train precision: 0.100556, train loss: 294.524115, valid precision: 0.095000, valid loss: 294.308898
epoch: 4408, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308881
epoch: 4409, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4410, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308880
epoch: 4411, train precision: 0.100556, train loss: 294.524112, valid precision: 0.095000, valid loss: 294.308896
epoch: 4412, train precision: 0.100556, train loss: 294.524092, valid precision: 0.095000, valid loss: 294.308870
epoch: 4413, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308887
epoch: 4414, train precision: 0.100578, train loss: 294.517574, valid precision: 0.095000, valid loss: 294.308749
epoch: 4415, train precision: 0.100556, train loss: 294.524125, valid precision: 0.095000, valid loss: 294.308868
epoch: 4416, train precision: 0.100556, train loss: 294.524121, valid precision: 0.095000, valid loss: 294.308894
epoch: 4417, train precision: 0.100556, train loss: 294.524095, valid precision: 0.095000, valid loss: 294.308872
epoch: 4418, train precision: 0.100556, train loss: 294.524099, valid precision: 0.095000, valid loss: 294.308882
epoch: 4419, train precision: 0.100556, train loss: 294.524120, valid precision: 0.095000, valid loss: 294.308900
epoch: 4420, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308894
epoch: 4421, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308889
epoch: 4422, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308873
epoch: 4423, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308886
epoch: 4424, train precision: 0.100556, train loss: 294.524110, valid precision: 0.095000, valid loss: 294.308887
epoch: 4425, train precision: 0.100556, train loss: 294.524110, valid precision: 0.095000, valid loss: 294.308890
epoch: 4426, train precision: 0.100556, train loss: 294.524110, valid precision: 0.095000, valid loss: 294.308890
epoch: 4427, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308889
epoch: 4428, train precision: 0.100578, train loss: 294.517573, valid precision: 0.095000, valid loss: 294.308748
epoch: 4429, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308867
epoch: 4430, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308897
epoch: 4431, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308875
epoch: 4432, train precision: 0.100556, train loss: 294.524097, valid precision: 0.095000, valid loss: 294.308876
epoch: 4433, train precision: 0.100556, train loss: 294.524118, valid precision: 0.095000, valid loss: 294.308898
epoch: 4434, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308886
epoch: 4435, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308886
epoch: 4436, train precision: 0.100556, train loss: 294.524099, valid precision: 0.095000, valid loss: 294.308880
epoch: 4437, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308883
epoch: 4438, train precision: 0.100578, train loss: 294.517574, valid precision: 0.095000, valid loss: 294.308748
epoch: 4439, train precision: 0.100556, train loss: 294.524103, valid precision: 0.095000, valid loss: 294.308847
epoch: 4440, train precision: 0.100556, train loss: 294.524097, valid precision: 0.095000, valid loss: 294.308865
epoch: 4441, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308883
epoch: 4442, train precision: 0.100556, train loss: 294.524114, valid precision: 0.095000, valid loss: 294.308896
epoch: 4443, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308885
epoch: 4444, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308879
epoch: 4445, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308888
epoch: 4446, train precision: 0.100578, train loss: 294.517583, valid precision: 0.095000, valid loss: 294.308758
epoch: 4447, train precision: 0.100578, train loss: 294.517572, valid precision: 0.095000, valid loss: 294.308712
epoch: 4448, train precision: 0.100556, train loss: 294.524130, valid precision: 0.095000, valid loss: 294.308862
epoch: 4449, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308890
epoch: 4450, train precision: 0.100556, train loss: 294.524094, valid precision: 0.095000, valid loss: 294.308874
epoch: 4451, train precision: 0.100556, train loss: 294.524090, valid precision: 0.095000, valid loss: 294.308870
epoch: 4452, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308880
epoch: 4453, train precision: 0.100578, train loss: 294.517565, valid precision: 0.095000, valid loss: 294.308741
epoch: 4454, train precision: 0.100556, train loss: 294.524099, valid precision: 0.095000, valid loss: 294.308843
epoch: 4455, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308883
epoch: 4456, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308889
epoch: 4457, train precision: 0.100556, train loss: 294.524118, valid precision: 0.095000, valid loss: 294.308897
epoch: 4458, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308878
epoch: 4459, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308882
epoch: 4460, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308887
epoch: 4461, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308888
epoch: 4462, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308887
epoch: 4463, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308883
epoch: 4464, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4465, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308887
epoch: 4466, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4467, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308884
epoch: 4468, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4469, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308885
epoch: 4470, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4471, train precision: 0.100578, train loss: 294.517564, valid precision: 0.095000, valid loss: 294.308737
epoch: 4472, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308869
epoch: 4473, train precision: 0.100556, train loss: 294.524115, valid precision: 0.095000, valid loss: 294.308886
epoch: 4474, train precision: 0.100578, train loss: 294.517576, valid precision: 0.095000, valid loss: 294.308752
epoch: 4475, train precision: 0.100556, train loss: 294.524114, valid precision: 0.095000, valid loss: 294.308860
epoch: 4476, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308871
epoch: 4477, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308888
epoch: 4478, train precision: 0.100578, train loss: 294.517583, valid precision: 0.095000, valid loss: 294.308756
epoch: 4479, train precision: 0.100556, train loss: 294.524128, valid precision: 0.095000, valid loss: 294.308872
epoch: 4480, train precision: 0.100578, train loss: 294.517568, valid precision: 0.095000, valid loss: 294.308734
epoch: 4481, train precision: 0.100556, train loss: 294.524118, valid precision: 0.095000, valid loss: 294.308859
epoch: 4482, train precision: 0.100556, train loss: 294.524119, valid precision: 0.095000, valid loss: 294.308889
epoch: 4483, train precision: 0.100556, train loss: 294.524095, valid precision: 0.095000, valid loss: 294.308872
epoch: 4484, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308883
epoch: 4485, train precision: 0.100556, train loss: 294.524112, valid precision: 0.095000, valid loss: 294.308893
epoch: 4486, train precision: 0.100556, train loss: 294.524118, valid precision: 0.095000, valid loss: 294.308897
epoch: 4487, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308879
epoch: 4488, train precision: 0.100556, train loss: 294.524112, valid precision: 0.095000, valid loss: 294.308890
epoch: 4489, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308886
epoch: 4490, train precision: 0.100556, train loss: 294.524094, valid precision: 0.095000, valid loss: 294.308873
epoch: 4491, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308889
epoch: 4492, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308890
epoch: 4493, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308888
epoch: 4494, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308886
epoch: 4495, train precision: 0.100578, train loss: 294.517565, valid precision: 0.095000, valid loss: 294.308741
epoch: 4496, train precision: 0.100556, train loss: 294.524121, valid precision: 0.095000, valid loss: 294.308868
epoch: 4497, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308895
epoch: 4498, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308874
epoch: 4499, train precision: 0.100556, train loss: 294.524097, valid precision: 0.095000, valid loss: 294.308878
epoch: 4500, train precision: 0.100556, train loss: 294.524118, valid precision: 0.095000, valid loss: 294.308898
epoch: 4501, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308885
epoch: 4502, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308885
epoch: 4503, train precision: 0.100556, train loss: 294.524095, valid precision: 0.095000, valid loss: 294.308873
epoch: 4504, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308879
epoch: 4505, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308890
epoch: 4506, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308889
epoch: 4507, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308887
epoch: 4508, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4509, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308886
epoch: 4510, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4511, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308889
epoch: 4512, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308886
epoch: 4513, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308887
epoch: 4514, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4515, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4516, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4517, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308887
epoch: 4518, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4519, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4520, train precision: 0.100578, train loss: 294.517564, valid precision: 0.095000, valid loss: 294.308739
epoch: 4521, train precision: 0.100556, train loss: 294.524120, valid precision: 0.095000, valid loss: 294.308864
epoch: 4522, train precision: 0.100556, train loss: 294.524113, valid precision: 0.095000, valid loss: 294.308887
epoch: 4523, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308884
epoch: 4524, train precision: 0.100556, train loss: 294.524116, valid precision: 0.095000, valid loss: 294.308895
epoch: 4525, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308880
epoch: 4526, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308878
epoch: 4527, train precision: 0.100556, train loss: 294.524112, valid precision: 0.095000, valid loss: 294.308890
epoch: 4528, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308888
epoch: 4529, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308882
epoch: 4530, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308891
epoch: 4531, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4532, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308883
epoch: 4533, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4534, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308890
epoch: 4535, train precision: 0.100578, train loss: 294.517565, valid precision: 0.095000, valid loss: 294.308740
epoch: 4536, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308868
epoch: 4537, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308896
epoch: 4538, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308872
epoch: 4539, train precision: 0.100556, train loss: 294.524097, valid precision: 0.095000, valid loss: 294.308879
epoch: 4540, train precision: 0.100578, train loss: 294.517578, valid precision: 0.095000, valid loss: 294.308751
epoch: 4541, train precision: 0.100556, train loss: 294.524112, valid precision: 0.095000, valid loss: 294.308857
epoch: 4542, train precision: 0.100556, train loss: 294.524097, valid precision: 0.095000, valid loss: 294.308870
epoch: 4543, train precision: 0.100556, train loss: 294.524103, valid precision: 0.095000, valid loss: 294.308882
epoch: 4544, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4545, train precision: 0.100556, train loss: 294.524098, valid precision: 0.095000, valid loss: 294.308875
epoch: 4546, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308883
epoch: 4547, train precision: 0.100556, train loss: 294.524103, valid precision: 0.095000, valid loss: 294.308885
epoch: 4548, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308890
epoch: 4549, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308890
epoch: 4550, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308890
epoch: 4551, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4552, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308890
epoch: 4553, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308886
epoch: 4554, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308889
epoch: 4555, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308889
epoch: 4556, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308890
epoch: 4557, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4558, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308889
epoch: 4559, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4560, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308884
epoch: 4561, train precision: 0.100578, train loss: 294.517565, valid precision: 0.095000, valid loss: 294.308740
epoch: 4562, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308866
epoch: 4563, train precision: 0.100578, train loss: 294.517567, valid precision: 0.095000, valid loss: 294.308733
epoch: 4564, train precision: 0.100556, train loss: 294.524126, valid precision: 0.095000, valid loss: 294.308865
epoch: 4565, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308876
epoch: 4566, train precision: 0.100556, train loss: 294.524117, valid precision: 0.095000, valid loss: 294.308894
epoch: 4567, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308904
epoch: 4568, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308886
epoch: 4569, train precision: 0.100556, train loss: 294.524099, valid precision: 0.095000, valid loss: 294.308878
epoch: 4570, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308879
epoch: 4571, train precision: 0.100556, train loss: 294.524112, valid precision: 0.095000, valid loss: 294.308890
epoch: 4572, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4573, train precision: 0.100556, train loss: 294.524093, valid precision: 0.095000, valid loss: 294.308873
epoch: 4574, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308886
epoch: 4575, train precision: 0.100578, train loss: 294.517565, valid precision: 0.095000, valid loss: 294.308738
epoch: 4576, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308869
epoch: 4577, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308897
epoch: 4578, train precision: 0.100578, train loss: 294.517564, valid precision: 0.095000, valid loss: 294.308741
epoch: 4579, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308842
epoch: 4580, train precision: 0.100556, train loss: 294.524116, valid precision: 0.095000, valid loss: 294.308887
epoch: 4581, train precision: 0.100556, train loss: 294.524093, valid precision: 0.095000, valid loss: 294.308872
epoch: 4582, train precision: 0.100578, train loss: 294.517586, valid precision: 0.095000, valid loss: 294.308762
epoch: 4583, train precision: 0.100578, train loss: 294.517581, valid precision: 0.095000, valid loss: 294.308719
epoch: 4584, train precision: 0.100556, train loss: 294.524093, valid precision: 0.095000, valid loss: 294.308827
epoch: 4585, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308870
epoch: 4586, train precision: 0.100556, train loss: 294.524090, valid precision: 0.095000, valid loss: 294.308869
epoch: 4587, train precision: 0.100556, train loss: 294.524098, valid precision: 0.095000, valid loss: 294.308876
epoch: 4588, train precision: 0.100556, train loss: 294.524114, valid precision: 0.095000, valid loss: 294.308890
epoch: 4589, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308885
epoch: 4590, train precision: 0.100556, train loss: 294.524119, valid precision: 0.095000, valid loss: 294.308899
epoch: 4591, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4592, train precision: 0.100556, train loss: 294.524099, valid precision: 0.095000, valid loss: 294.308878
epoch: 4593, train precision: 0.100578, train loss: 294.517582, valid precision: 0.095000, valid loss: 294.308756
epoch: 4594, train precision: 0.100578, train loss: 294.517572, valid precision: 0.095000, valid loss: 294.308712
epoch: 4595, train precision: 0.100556, train loss: 294.524128, valid precision: 0.095000, valid loss: 294.308862
epoch: 4596, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308892
epoch: 4597, train precision: 0.100578, train loss: 294.517580, valid precision: 0.095000, valid loss: 294.308755
epoch: 4598, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308851
epoch: 4599, train precision: 0.100556, train loss: 294.524089, valid precision: 0.095000, valid loss: 294.308856
epoch: 4600, train precision: 0.100556, train loss: 294.524103, valid precision: 0.095000, valid loss: 294.308880
epoch: 4601, train precision: 0.100556, train loss: 294.524110, valid precision: 0.095000, valid loss: 294.308888
epoch: 4602, train precision: 0.100556, train loss: 294.524098, valid precision: 0.095000, valid loss: 294.308876
epoch: 4603, train precision: 0.100578, train loss: 294.517560, valid precision: 0.095000, valid loss: 294.308737
epoch: 4604, train precision: 0.100556, train loss: 294.524099, valid precision: 0.095000, valid loss: 294.308843
epoch: 4605, train precision: 0.100556, train loss: 294.524112, valid precision: 0.095000, valid loss: 294.308885
epoch: 4606, train precision: 0.100556, train loss: 294.524118, valid precision: 0.095000, valid loss: 294.308896
epoch: 4607, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308901
epoch: 4608, train precision: 0.100556, train loss: 294.524116, valid precision: 0.095000, valid loss: 294.308898
epoch: 4609, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308884
epoch: 4610, train precision: 0.100578, train loss: 294.517570, valid precision: 0.095000, valid loss: 294.308743
epoch: 4611, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308847
epoch: 4612, train precision: 0.100556, train loss: 294.524120, valid precision: 0.095000, valid loss: 294.308893
epoch: 4613, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308883
epoch: 4614, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308880
epoch: 4615, train precision: 0.100556, train loss: 294.524118, valid precision: 0.095000, valid loss: 294.308899
epoch: 4616, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4617, train precision: 0.100556, train loss: 294.524110, valid precision: 0.095000, valid loss: 294.308892
epoch: 4618, train precision: 0.100556, train loss: 294.524099, valid precision: 0.095000, valid loss: 294.308877
epoch: 4619, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308891
epoch: 4620, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308889
epoch: 4621, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4622, train precision: 0.100578, train loss: 294.517565, valid precision: 0.095000, valid loss: 294.308737
epoch: 4623, train precision: 0.100578, train loss: 294.517583, valid precision: 0.095000, valid loss: 294.308720
epoch: 4624, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308839
epoch: 4625, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308878
epoch: 4626, train precision: 0.100556, train loss: 294.524088, valid precision: 0.095000, valid loss: 294.308867
epoch: 4627, train precision: 0.100556, train loss: 294.524094, valid precision: 0.095000, valid loss: 294.308875
epoch: 4628, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308879
epoch: 4629, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308879
epoch: 4630, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4631, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308888
epoch: 4632, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308876
epoch: 4633, train precision: 0.100578, train loss: 294.517576, valid precision: 0.095000, valid loss: 294.308750
epoch: 4634, train precision: 0.100556, train loss: 294.524103, valid precision: 0.095000, valid loss: 294.308843
epoch: 4635, train precision: 0.100556, train loss: 294.524094, valid precision: 0.095000, valid loss: 294.308865
epoch: 4636, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308881
epoch: 4637, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308887
epoch: 4638, train precision: 0.100556, train loss: 294.524118, valid precision: 0.095000, valid loss: 294.308897
epoch: 4639, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308889
epoch: 4640, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308885
epoch: 4641, train precision: 0.100556, train loss: 294.524098, valid precision: 0.095000, valid loss: 294.308878
epoch: 4642, train precision: 0.100578, train loss: 294.517574, valid precision: 0.095000, valid loss: 294.308744
epoch: 4643, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308843
epoch: 4644, train precision: 0.100556, train loss: 294.524095, valid precision: 0.095000, valid loss: 294.308865
epoch: 4645, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308877
epoch: 4646, train precision: 0.100578, train loss: 294.517594, valid precision: 0.095000, valid loss: 294.308768
epoch: 4647, train precision: 0.100556, train loss: 294.524130, valid precision: 0.095000, valid loss: 294.308873
epoch: 4648, train precision: 0.100556, train loss: 294.524113, valid precision: 0.095000, valid loss: 294.308887
epoch: 4649, train precision: 0.100556, train loss: 294.524094, valid precision: 0.095000, valid loss: 294.308872
epoch: 4650, train precision: 0.100556, train loss: 294.524121, valid precision: 0.095000, valid loss: 294.308904
epoch: 4651, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308878
epoch: 4652, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308887
epoch: 4653, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308887
epoch: 4654, train precision: 0.100556, train loss: 294.524112, valid precision: 0.095000, valid loss: 294.308891
epoch: 4655, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308891
epoch: 4656, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308884
epoch: 4657, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4658, train precision: 0.100578, train loss: 294.517568, valid precision: 0.095000, valid loss: 294.308742
epoch: 4659, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308866
epoch: 4660, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308894
epoch: 4661, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308873
epoch: 4662, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308872
epoch: 4663, train precision: 0.100556, train loss: 294.524119, valid precision: 0.095000, valid loss: 294.308897
epoch: 4664, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4665, train precision: 0.100578, train loss: 294.517570, valid precision: 0.095000, valid loss: 294.308742
epoch: 4666, train precision: 0.100556, train loss: 294.524103, valid precision: 0.095000, valid loss: 294.308844
epoch: 4667, train precision: 0.100556, train loss: 294.524091, valid precision: 0.095000, valid loss: 294.308859
epoch: 4668, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308882
epoch: 4669, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308879
epoch: 4670, train precision: 0.100556, train loss: 294.524118, valid precision: 0.095000, valid loss: 294.308897
epoch: 4671, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308886
epoch: 4672, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308885
epoch: 4673, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308879
epoch: 4674, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308883
epoch: 4675, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308889
epoch: 4676, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308888
epoch: 4677, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308887
epoch: 4678, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308885
epoch: 4679, train precision: 0.100578, train loss: 294.517564, valid precision: 0.095000, valid loss: 294.308738
epoch: 4680, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308868
epoch: 4681, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308895
epoch: 4682, train precision: 0.100556, train loss: 294.524095, valid precision: 0.095000, valid loss: 294.308874
epoch: 4683, train precision: 0.100556, train loss: 294.524097, valid precision: 0.095000, valid loss: 294.308876
epoch: 4684, train precision: 0.100556, train loss: 294.524118, valid precision: 0.095000, valid loss: 294.308899
epoch: 4685, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308885
epoch: 4686, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308880
epoch: 4687, train precision: 0.100556, train loss: 294.524093, valid precision: 0.095000, valid loss: 294.308874
epoch: 4688, train precision: 0.100556, train loss: 294.524103, valid precision: 0.095000, valid loss: 294.308880
epoch: 4689, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308889
epoch: 4690, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4691, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308890
epoch: 4692, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4693, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308887
epoch: 4694, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4695, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308889
epoch: 4696, train precision: 0.100578, train loss: 294.517564, valid precision: 0.095000, valid loss: 294.308740
epoch: 4697, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308868
epoch: 4698, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308897
epoch: 4699, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308874
epoch: 4700, train precision: 0.100578, train loss: 294.517563, valid precision: 0.095000, valid loss: 294.308740
epoch: 4701, train precision: 0.100556, train loss: 294.524132, valid precision: 0.095000, valid loss: 294.308878
epoch: 4702, train precision: 0.100556, train loss: 294.524117, valid precision: 0.095000, valid loss: 294.308890
epoch: 4703, train precision: 0.100556, train loss: 294.524095, valid precision: 0.095000, valid loss: 294.308872
epoch: 4704, train precision: 0.100556, train loss: 294.524121, valid precision: 0.095000, valid loss: 294.308904
epoch: 4705, train precision: 0.100556, train loss: 294.524099, valid precision: 0.095000, valid loss: 294.308879
epoch: 4706, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308889
epoch: 4707, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308887
epoch: 4708, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308890
epoch: 4709, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308890
epoch: 4710, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308883
epoch: 4711, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308888
epoch: 4712, train precision: 0.100578, train loss: 294.517564, valid precision: 0.095000, valid loss: 294.308740
epoch: 4713, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308867
epoch: 4714, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308895
epoch: 4715, train precision: 0.100578, train loss: 294.517568, valid precision: 0.095000, valid loss: 294.308745
epoch: 4716, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308839
epoch: 4717, train precision: 0.100556, train loss: 294.524116, valid precision: 0.095000, valid loss: 294.308887
epoch: 4718, train precision: 0.100556, train loss: 294.524094, valid precision: 0.095000, valid loss: 294.308871
epoch: 4719, train precision: 0.100556, train loss: 294.524098, valid precision: 0.095000, valid loss: 294.308875
epoch: 4720, train precision: 0.100556, train loss: 294.524116, valid precision: 0.095000, valid loss: 294.308895
epoch: 4721, train precision: 0.100556, train loss: 294.524119, valid precision: 0.095000, valid loss: 294.308900
epoch: 4722, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4723, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308878
epoch: 4724, train precision: 0.100578, train loss: 294.517579, valid precision: 0.095000, valid loss: 294.308753
epoch: 4725, train precision: 0.100578, train loss: 294.517564, valid precision: 0.095000, valid loss: 294.308705
epoch: 4726, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308840
epoch: 4727, train precision: 0.100556, train loss: 294.524115, valid precision: 0.095000, valid loss: 294.308882
epoch: 4728, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308897
epoch: 4729, train precision: 0.100556, train loss: 294.524117, valid precision: 0.095000, valid loss: 294.308897
epoch: 4730, train precision: 0.100556, train loss: 294.524099, valid precision: 0.095000, valid loss: 294.308874
epoch: 4731, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308879
epoch: 4732, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308883
epoch: 4733, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308882
epoch: 4734, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308889
epoch: 4735, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308892
epoch: 4736, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308881
epoch: 4737, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308886
epoch: 4738, train precision: 0.100578, train loss: 294.517567, valid precision: 0.095000, valid loss: 294.308739
epoch: 4739, train precision: 0.100556, train loss: 294.524121, valid precision: 0.095000, valid loss: 294.308868
epoch: 4740, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308895
epoch: 4741, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308872
epoch: 4742, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308875
epoch: 4743, train precision: 0.100556, train loss: 294.524113, valid precision: 0.095000, valid loss: 294.308893
epoch: 4744, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308885
epoch: 4745, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308881
epoch: 4746, train precision: 0.100556, train loss: 294.524110, valid precision: 0.095000, valid loss: 294.308889
epoch: 4747, train precision: 0.100556, train loss: 294.524097, valid precision: 0.095000, valid loss: 294.308877
epoch: 4748, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308887
epoch: 4749, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4750, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308887
epoch: 4751, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308890
epoch: 4752, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4753, train precision: 0.100578, train loss: 294.517564, valid precision: 0.095000, valid loss: 294.308741
epoch: 4754, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308869
epoch: 4755, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308897
epoch: 4756, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308875
epoch: 4757, train precision: 0.100556, train loss: 294.524098, valid precision: 0.095000, valid loss: 294.308876
epoch: 4758, train precision: 0.100556, train loss: 294.524118, valid precision: 0.095000, valid loss: 294.308901
epoch: 4759, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4760, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308881
epoch: 4761, train precision: 0.100556, train loss: 294.524094, valid precision: 0.095000, valid loss: 294.308874
epoch: 4762, train precision: 0.100578, train loss: 294.517574, valid precision: 0.095000, valid loss: 294.308746
epoch: 4763, train precision: 0.100556, train loss: 294.524103, valid precision: 0.095000, valid loss: 294.308843
epoch: 4764, train precision: 0.100556, train loss: 294.524095, valid precision: 0.095000, valid loss: 294.308861
epoch: 4765, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308876
epoch: 4766, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308874
epoch: 4767, train precision: 0.100556, train loss: 294.524118, valid precision: 0.095000, valid loss: 294.308900
epoch: 4768, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4769, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308884
epoch: 4770, train precision: 0.100556, train loss: 294.524099, valid precision: 0.095000, valid loss: 294.308876
epoch: 4771, train precision: 0.100578, train loss: 294.517574, valid precision: 0.095000, valid loss: 294.308747
epoch: 4772, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308847
epoch: 4773, train precision: 0.100556, train loss: 294.524094, valid precision: 0.095000, valid loss: 294.308862
epoch: 4774, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308874
epoch: 4775, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308873
epoch: 4776, train precision: 0.100556, train loss: 294.524119, valid precision: 0.095000, valid loss: 294.308901
epoch: 4777, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308889
epoch: 4778, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308883
epoch: 4779, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308879
epoch: 4780, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308881
epoch: 4781, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308890
epoch: 4782, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4783, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308884
epoch: 4784, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4785, train precision: 0.100578, train loss: 294.517564, valid precision: 0.095000, valid loss: 294.308737
epoch: 4786, train precision: 0.100556, train loss: 294.524121, valid precision: 0.095000, valid loss: 294.308867
epoch: 4787, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308896
epoch: 4788, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308873
epoch: 4789, train precision: 0.100578, train loss: 294.517563, valid precision: 0.095000, valid loss: 294.308737
epoch: 4790, train precision: 0.100556, train loss: 294.524132, valid precision: 0.095000, valid loss: 294.308876
epoch: 4791, train precision: 0.100556, train loss: 294.524117, valid precision: 0.095000, valid loss: 294.308889
epoch: 4792, train precision: 0.100578, train loss: 294.517566, valid precision: 0.095000, valid loss: 294.308741
epoch: 4793, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308856
epoch: 4794, train precision: 0.100556, train loss: 294.524093, valid precision: 0.095000, valid loss: 294.308864
epoch: 4795, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308881
epoch: 4796, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308892
epoch: 4797, train precision: 0.100556, train loss: 294.524094, valid precision: 0.095000, valid loss: 294.308871
epoch: 4798, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308902
epoch: 4799, train precision: 0.100556, train loss: 294.524114, valid precision: 0.095000, valid loss: 294.308891
epoch: 4800, train precision: 0.100578, train loss: 294.517582, valid precision: 0.095000, valid loss: 294.308755
epoch: 4801, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308840
epoch: 4802, train precision: 0.100556, train loss: 294.524110, valid precision: 0.095000, valid loss: 294.308881
epoch: 4803, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308883
epoch: 4804, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308879
epoch: 4805, train precision: 0.100556, train loss: 294.524118, valid precision: 0.095000, valid loss: 294.308897
epoch: 4806, train precision: 0.100556, train loss: 294.524110, valid precision: 0.095000, valid loss: 294.308890
epoch: 4807, train precision: 0.100556, train loss: 294.524110, valid precision: 0.095000, valid loss: 294.308890
epoch: 4808, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308877
epoch: 4809, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308884
epoch: 4810, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308888
epoch: 4811, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4812, train precision: 0.100578, train loss: 294.517568, valid precision: 0.095000, valid loss: 294.308741
epoch: 4813, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308869
epoch: 4814, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308895
epoch: 4815, train precision: 0.100556, train loss: 294.524097, valid precision: 0.095000, valid loss: 294.308876
epoch: 4816, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308875
epoch: 4817, train precision: 0.100578, train loss: 294.517571, valid precision: 0.095000, valid loss: 294.308748
epoch: 4818, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308849
epoch: 4819, train precision: 0.100578, train loss: 294.517556, valid precision: 0.095000, valid loss: 294.308721
epoch: 4820, train precision: 0.100556, train loss: 294.524114, valid precision: 0.095000, valid loss: 294.308850
epoch: 4821, train precision: 0.100556, train loss: 294.524115, valid precision: 0.095000, valid loss: 294.308883
epoch: 4822, train precision: 0.100556, train loss: 294.524117, valid precision: 0.095000, valid loss: 294.308895
epoch: 4823, train precision: 0.100556, train loss: 294.524121, valid precision: 0.095000, valid loss: 294.308908
epoch: 4824, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308880
epoch: 4825, train precision: 0.100578, train loss: 294.517560, valid precision: 0.095000, valid loss: 294.308736
epoch: 4826, train precision: 0.100556, train loss: 294.524099, valid precision: 0.095000, valid loss: 294.308840
epoch: 4827, train precision: 0.100556, train loss: 294.524112, valid precision: 0.095000, valid loss: 294.308886
epoch: 4828, train precision: 0.100556, train loss: 294.524117, valid precision: 0.095000, valid loss: 294.308895
epoch: 4829, train precision: 0.100556, train loss: 294.524117, valid precision: 0.095000, valid loss: 294.308901
epoch: 4830, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308884
epoch: 4831, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308887
epoch: 4832, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308885
epoch: 4833, train precision: 0.100578, train loss: 294.517586, valid precision: 0.095000, valid loss: 294.308758
epoch: 4834, train precision: 0.100556, train loss: 294.524119, valid precision: 0.095000, valid loss: 294.308865
epoch: 4835, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308882
epoch: 4836, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308884
epoch: 4837, train precision: 0.100556, train loss: 294.524115, valid precision: 0.095000, valid loss: 294.308894
epoch: 4838, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308885
epoch: 4839, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308878
epoch: 4840, train precision: 0.100556, train loss: 294.524112, valid precision: 0.095000, valid loss: 294.308891
epoch: 4841, train precision: 0.100556, train loss: 294.524110, valid precision: 0.095000, valid loss: 294.308890
epoch: 4842, train precision: 0.100556, train loss: 294.524099, valid precision: 0.095000, valid loss: 294.308878
epoch: 4843, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308890
epoch: 4844, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4845, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308889
epoch: 4846, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4847, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4848, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4849, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4850, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308889
epoch: 4851, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308886
epoch: 4852, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308886
epoch: 4853, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4854, train precision: 0.100578, train loss: 294.517564, valid precision: 0.095000, valid loss: 294.308741
epoch: 4855, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308868
epoch: 4856, train precision: 0.100556, train loss: 294.524115, valid precision: 0.095000, valid loss: 294.308887
epoch: 4857, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308884
epoch: 4858, train precision: 0.100556, train loss: 294.524114, valid precision: 0.095000, valid loss: 294.308897
epoch: 4859, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308878
epoch: 4860, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308879
epoch: 4861, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308889
epoch: 4862, train precision: 0.100556, train loss: 294.524110, valid precision: 0.095000, valid loss: 294.308890
epoch: 4863, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308882
epoch: 4864, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308889
epoch: 4865, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308888
epoch: 4866, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4867, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4868, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4869, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4870, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308890
epoch: 4871, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308888
epoch: 4872, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308889
epoch: 4873, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308889
epoch: 4874, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4875, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4876, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4877, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308886
epoch: 4878, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4879, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4880, train precision: 0.100578, train loss: 294.517564, valid precision: 0.095000, valid loss: 294.308737
epoch: 4881, train precision: 0.100556, train loss: 294.524120, valid precision: 0.095000, valid loss: 294.308865
epoch: 4882, train precision: 0.100556, train loss: 294.524112, valid precision: 0.095000, valid loss: 294.308884
epoch: 4883, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308882
epoch: 4884, train precision: 0.100556, train loss: 294.524115, valid precision: 0.095000, valid loss: 294.308894
epoch: 4885, train precision: 0.100556, train loss: 294.524103, valid precision: 0.095000, valid loss: 294.308880
epoch: 4886, train precision: 0.100556, train loss: 294.524114, valid precision: 0.095000, valid loss: 294.308898
epoch: 4887, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308887
epoch: 4888, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308890
epoch: 4889, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308882
epoch: 4890, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308890
epoch: 4891, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4892, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308885
epoch: 4893, train precision: 0.100578, train loss: 294.517565, valid precision: 0.095000, valid loss: 294.308738
epoch: 4894, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308868
epoch: 4895, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308895
epoch: 4896, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308877
epoch: 4897, train precision: 0.100578, train loss: 294.517564, valid precision: 0.095000, valid loss: 294.308736
epoch: 4898, train precision: 0.100556, train loss: 294.524132, valid precision: 0.095000, valid loss: 294.308876
epoch: 4899, train precision: 0.100556, train loss: 294.524116, valid precision: 0.095000, valid loss: 294.308887
epoch: 4900, train precision: 0.100556, train loss: 294.524095, valid precision: 0.095000, valid loss: 294.308872
epoch: 4901, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308880
epoch: 4902, train precision: 0.100556, train loss: 294.524115, valid precision: 0.095000, valid loss: 294.308897
epoch: 4903, train precision: 0.100556, train loss: 294.524118, valid precision: 0.095000, valid loss: 294.308898
epoch: 4904, train precision: 0.100556, train loss: 294.524110, valid precision: 0.095000, valid loss: 294.308892
epoch: 4905, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308879
epoch: 4906, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4907, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308884
epoch: 4908, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308887
epoch: 4909, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308888
epoch: 4910, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308886
epoch: 4911, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4912, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4913, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308890
epoch: 4914, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4915, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4916, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308886
epoch: 4917, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4918, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4919, train precision: 0.100578, train loss: 294.517565, valid precision: 0.095000, valid loss: 294.308741
epoch: 4920, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308869
epoch: 4921, train precision: 0.100556, train loss: 294.524114, valid precision: 0.095000, valid loss: 294.308887
epoch: 4922, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308883
epoch: 4923, train precision: 0.100556, train loss: 294.524114, valid precision: 0.095000, valid loss: 294.308897
epoch: 4924, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308880
epoch: 4925, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308877
epoch: 4926, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308893
epoch: 4927, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308888
epoch: 4928, train precision: 0.100578, train loss: 294.517573, valid precision: 0.095000, valid loss: 294.308747
epoch: 4929, train precision: 0.100578, train loss: 294.517565, valid precision: 0.095000, valid loss: 294.308708
epoch: 4930, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308839
epoch: 4931, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308876
epoch: 4932, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308876
epoch: 4933, train precision: 0.100556, train loss: 294.524094, valid precision: 0.095000, valid loss: 294.308873
epoch: 4934, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308880
epoch: 4935, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308881
epoch: 4936, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308890
epoch: 4937, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308892
epoch: 4938, train precision: 0.100556, train loss: 294.524094, valid precision: 0.095000, valid loss: 294.308872
epoch: 4939, train precision: 0.100556, train loss: 294.524110, valid precision: 0.095000, valid loss: 294.308887
epoch: 4940, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308882
epoch: 4941, train precision: 0.100556, train loss: 294.524107, valid precision: 0.095000, valid loss: 294.308890
epoch: 4942, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308885
epoch: 4943, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308885
epoch: 4944, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308886
epoch: 4945, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308885
epoch: 4946, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4947, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4948, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308889
epoch: 4949, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4950, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4951, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308887
epoch: 4952, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308886
epoch: 4953, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4954, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4955, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308888
epoch: 4956, train precision: 0.100578, train loss: 294.517565, valid precision: 0.095000, valid loss: 294.308741
epoch: 4957, train precision: 0.100556, train loss: 294.524122, valid precision: 0.095000, valid loss: 294.308867
epoch: 4958, train precision: 0.100556, train loss: 294.524115, valid precision: 0.095000, valid loss: 294.308887
epoch: 4959, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308883
epoch: 4960, train precision: 0.100556, train loss: 294.524114, valid precision: 0.095000, valid loss: 294.308894
epoch: 4961, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308878
epoch: 4962, train precision: 0.100556, train loss: 294.524114, valid precision: 0.095000, valid loss: 294.308897
epoch: 4963, train precision: 0.100556, train loss: 294.524112, valid precision: 0.095000, valid loss: 294.308890
epoch: 4964, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4965, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308883
epoch: 4966, train precision: 0.100578, train loss: 294.517573, valid precision: 0.095000, valid loss: 294.308747
epoch: 4967, train precision: 0.100556, train loss: 294.524103, valid precision: 0.095000, valid loss: 294.308843
epoch: 4968, train precision: 0.100556, train loss: 294.524097, valid precision: 0.095000, valid loss: 294.308865
epoch: 4969, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308885
epoch: 4970, train precision: 0.100556, train loss: 294.524115, valid precision: 0.095000, valid loss: 294.308895
epoch: 4971, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308885
epoch: 4972, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308878
epoch: 4973, train precision: 0.100556, train loss: 294.524112, valid precision: 0.095000, valid loss: 294.308893
epoch: 4974, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308889
epoch: 4975, train precision: 0.100556, train loss: 294.524094, valid precision: 0.095000, valid loss: 294.308873
epoch: 4976, train precision: 0.100556, train loss: 294.524102, valid precision: 0.095000, valid loss: 294.308883
epoch: 4977, train precision: 0.100578, train loss: 294.517571, valid precision: 0.095000, valid loss: 294.308745
epoch: 4978, train precision: 0.100556, train loss: 294.524100, valid precision: 0.095000, valid loss: 294.308839
epoch: 4979, train precision: 0.100556, train loss: 294.524097, valid precision: 0.095000, valid loss: 294.308865
epoch: 4980, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308886
epoch: 4981, train precision: 0.100556, train loss: 294.524115, valid precision: 0.095000, valid loss: 294.308893
epoch: 4982, train precision: 0.100556, train loss: 294.524105, valid precision: 0.095000, valid loss: 294.308885
epoch: 4983, train precision: 0.100556, train loss: 294.524101, valid precision: 0.095000, valid loss: 294.308879
epoch: 4984, train precision: 0.100556, train loss: 294.524111, valid precision: 0.095000, valid loss: 294.308890
epoch: 4985, train precision: 0.100556, train loss: 294.524110, valid precision: 0.095000, valid loss: 294.308889
epoch: 4986, train precision: 0.100556, train loss: 294.524098, valid precision: 0.095000, valid loss: 294.308876
epoch: 4987, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4988, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308887
epoch: 4989, train precision: 0.100556, train loss: 294.524106, valid precision: 0.095000, valid loss: 294.308883
epoch: 4990, train precision: 0.100578, train loss: 294.517565, valid precision: 0.095000, valid loss: 294.308738
epoch: 4991, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308868
epoch: 4992, train precision: 0.100556, train loss: 294.524123, valid precision: 0.095000, valid loss: 294.308894
epoch: 4993, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308873
epoch: 4994, train precision: 0.100556, train loss: 294.524096, valid precision: 0.095000, valid loss: 294.308878
epoch: 4995, train precision: 0.100556, train loss: 294.524119, valid precision: 0.095000, valid loss: 294.308898
epoch: 4996, train precision: 0.100556, train loss: 294.524108, valid precision: 0.095000, valid loss: 294.308887
epoch: 4997, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308879
epoch: 4998, train precision: 0.100556, train loss: 294.524094, valid precision: 0.095000, valid loss: 294.308876
epoch: 4999, train precision: 0.100556, train loss: 294.524104, valid precision: 0.095000, valid loss: 294.308881
epoch: 5000, train precision: 0.100556, train loss: 294.524109, valid precision: 0.095000, valid loss: 294.308889
