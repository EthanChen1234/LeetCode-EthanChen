nohup: ignoring input
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:82:00.0
Total memory: 11.90GiB
Free memory: 7.77GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:82:00.0)
epoch: 0, train precision: 0.537533, train loss: 165.770603, valid precision: 0.556600, valid loss: 159.246196
epoch: 1, train precision: 0.619800, train loss: 137.793074, valid precision: 0.632600, valid loss: 133.110803
epoch: 2, train precision: 0.659733, train loss: 122.595575, valid precision: 0.672000, valid loss: 120.231950
epoch: 3, train precision: 0.706022, train loss: 108.258409, valid precision: 0.708400, valid loss: 107.428951
epoch: 4, train precision: 0.726022, train loss: 101.174074, valid precision: 0.727400, valid loss: 101.349846
epoch: 5, train precision: 0.740689, train loss: 95.316309, valid precision: 0.735800, valid loss: 96.868224
epoch: 6, train precision: 0.757311, train loss: 89.979568, valid precision: 0.748200, valid loss: 92.536849
epoch: 7, train precision: 0.768400, train loss: 85.371205, valid precision: 0.750600, valid loss: 90.699991
epoch: 8, train precision: 0.791889, train loss: 77.626380, valid precision: 0.774400, valid loss: 84.115412
epoch: 9, train precision: 0.797311, train loss: 76.446105, valid precision: 0.773000, valid loss: 84.986460
epoch: 10, train precision: 0.801889, train loss: 73.914633, valid precision: 0.776800, valid loss: 82.075611
epoch: 11, train precision: 0.815800, train loss: 69.157510, valid precision: 0.782800, valid loss: 79.727379
epoch: 12, train precision: 0.827089, train loss: 65.589004, valid precision: 0.788600, valid loss: 77.203670
epoch: 13, train precision: 0.834467, train loss: 62.730224, valid precision: 0.797400, valid loss: 75.552776
epoch: 14, train precision: 0.842467, train loss: 59.554313, valid precision: 0.800600, valid loss: 72.966205
epoch: 15, train precision: 0.851289, train loss: 56.587082, valid precision: 0.803400, valid loss: 72.710597
epoch: 16, train precision: 0.849556, train loss: 57.132715, valid precision: 0.803200, valid loss: 71.956079
epoch: 17, train precision: 0.857467, train loss: 54.250466, valid precision: 0.810800, valid loss: 71.580248
epoch: 18, train precision: 0.858533, train loss: 53.945709, valid precision: 0.810400, valid loss: 71.000521
epoch: 19, train precision: 0.871778, train loss: 49.723955, valid precision: 0.816400, valid loss: 68.051389
epoch: 20, train precision: 0.872311, train loss: 48.962182, valid precision: 0.815600, valid loss: 67.991535
epoch: 21, train precision: 0.874556, train loss: 47.808426, valid precision: 0.811600, valid loss: 68.162133
epoch: 22, train precision: 0.881311, train loss: 46.251439, valid precision: 0.816600, valid loss: 66.286424
epoch: 23, train precision: 0.879400, train loss: 47.087791, valid precision: 0.816000, valid loss: 68.543609
epoch: 24, train precision: 0.889400, train loss: 42.845060, valid precision: 0.816400, valid loss: 67.261784
epoch: 25, train precision: 0.898444, train loss: 40.691228, valid precision: 0.820000, valid loss: 65.375160
epoch: 26, train precision: 0.897067, train loss: 40.846730, valid precision: 0.819800, valid loss: 65.129405
epoch: 27, train precision: 0.903356, train loss: 38.863976, valid precision: 0.830400, valid loss: 63.018086
epoch: 28, train precision: 0.900622, train loss: 38.980707, valid precision: 0.831600, valid loss: 63.296595
epoch: 29, train precision: 0.902733, train loss: 38.419068, valid precision: 0.826000, valid loss: 64.474657
epoch: 30, train precision: 0.911756, train loss: 35.725940, valid precision: 0.835000, valid loss: 61.906468
epoch: 31, train precision: 0.910511, train loss: 35.277431, valid precision: 0.828400, valid loss: 61.988757
epoch: 32, train precision: 0.911756, train loss: 34.657193, valid precision: 0.828600, valid loss: 64.369128
epoch: 33, train precision: 0.916511, train loss: 33.643231, valid precision: 0.835400, valid loss: 61.232598
epoch: 34, train precision: 0.923844, train loss: 31.876117, valid precision: 0.838200, valid loss: 60.460396
epoch: 35, train precision: 0.921689, train loss: 32.274553, valid precision: 0.835200, valid loss: 60.869661
epoch: 36, train precision: 0.922289, train loss: 31.490801, valid precision: 0.834200, valid loss: 61.539909
epoch: 37, train precision: 0.926911, train loss: 29.610580, valid precision: 0.836400, valid loss: 60.630238
epoch: 38, train precision: 0.926600, train loss: 29.833098, valid precision: 0.842600, valid loss: 60.200050
epoch: 39, train precision: 0.928133, train loss: 29.384774, valid precision: 0.834400, valid loss: 61.488376
epoch: 40, train precision: 0.929000, train loss: 29.024936, valid precision: 0.836800, valid loss: 60.439947
epoch: 41, train precision: 0.933978, train loss: 27.880327, valid precision: 0.841000, valid loss: 59.314127
epoch: 42, train precision: 0.933133, train loss: 27.059228, valid precision: 0.838800, valid loss: 59.574781
epoch: 43, train precision: 0.935578, train loss: 26.768423, valid precision: 0.842000, valid loss: 59.778773
epoch: 44, train precision: 0.937400, train loss: 26.258163, valid precision: 0.838800, valid loss: 60.612151
epoch: 45, train precision: 0.939467, train loss: 25.682819, valid precision: 0.841000, valid loss: 60.087410
epoch: 46, train precision: 0.937200, train loss: 26.270521, valid precision: 0.842800, valid loss: 59.772425
epoch: 47, train precision: 0.940933, train loss: 24.768614, valid precision: 0.840200, valid loss: 60.066116
epoch: 48, train precision: 0.945044, train loss: 23.624973, valid precision: 0.845800, valid loss: 58.645913
epoch: 49, train precision: 0.948644, train loss: 22.771089, valid precision: 0.843400, valid loss: 59.071549
epoch: 50, train precision: 0.944689, train loss: 23.636709, valid precision: 0.840400, valid loss: 60.675930
epoch: 51, train precision: 0.947311, train loss: 22.549415, valid precision: 0.846000, valid loss: 59.338089
epoch: 52, train precision: 0.951978, train loss: 21.664354, valid precision: 0.845200, valid loss: 58.759099
epoch: 53, train precision: 0.950200, train loss: 21.553726, valid precision: 0.850000, valid loss: 59.185553
epoch: 54, train precision: 0.949756, train loss: 21.657122, valid precision: 0.843600, valid loss: 58.852356
epoch: 55, train precision: 0.953756, train loss: 20.250264, valid precision: 0.847800, valid loss: 58.460270
epoch: 56, train precision: 0.956022, train loss: 19.892659, valid precision: 0.850200, valid loss: 58.734697
epoch: 57, train precision: 0.956378, train loss: 19.913716, valid precision: 0.850400, valid loss: 57.350778
epoch: 58, train precision: 0.954578, train loss: 20.106464, valid precision: 0.843200, valid loss: 58.702185
epoch: 59, train precision: 0.959467, train loss: 19.041407, valid precision: 0.854000, valid loss: 57.602819
epoch: 60, train precision: 0.954733, train loss: 20.182997, valid precision: 0.842800, valid loss: 60.240540
epoch: 61, train precision: 0.960267, train loss: 18.602093, valid precision: 0.852600, valid loss: 59.149147
epoch: 62, train precision: 0.960800, train loss: 18.462104, valid precision: 0.849800, valid loss: 58.421386
epoch: 63, train precision: 0.960756, train loss: 18.112690, valid precision: 0.850800, valid loss: 58.704608
epoch: 64, train precision: 0.962311, train loss: 17.206388, valid precision: 0.849800, valid loss: 59.565416
epoch: 65, train precision: 0.959378, train loss: 18.234491, valid precision: 0.851600, valid loss: 58.268295
epoch: 66, train precision: 0.963956, train loss: 16.835810, valid precision: 0.846400, valid loss: 59.277795
epoch: 67, train precision: 0.962578, train loss: 17.706550, valid precision: 0.847800, valid loss: 60.122624
epoch: 68, train precision: 0.965511, train loss: 16.659124, valid precision: 0.851600, valid loss: 59.000473
epoch: 69, train precision: 0.964311, train loss: 16.686065, valid precision: 0.858200, valid loss: 58.986833
epoch: 70, train precision: 0.963356, train loss: 16.744105, valid precision: 0.852000, valid loss: 59.530121
epoch: 71, train precision: 0.964756, train loss: 16.404872, valid precision: 0.854600, valid loss: 59.739073
epoch: 72, train precision: 0.962133, train loss: 17.247084, valid precision: 0.849000, valid loss: 59.135100
epoch: 73, train precision: 0.967622, train loss: 15.670081, valid precision: 0.852200, valid loss: 59.195592
epoch: 74, train precision: 0.963489, train loss: 16.510425, valid precision: 0.851600, valid loss: 61.012839
epoch: 75, train precision: 0.970733, train loss: 14.867106, valid precision: 0.851200, valid loss: 59.574490
epoch: 76, train precision: 0.968689, train loss: 15.254553, valid precision: 0.850200, valid loss: 61.156273
epoch: 77, train precision: 0.968756, train loss: 14.927654, valid precision: 0.846400, valid loss: 59.538561
epoch: 78, train precision: 0.970089, train loss: 14.397136, valid precision: 0.849800, valid loss: 59.964648
epoch: 79, train precision: 0.969378, train loss: 14.898107, valid precision: 0.851800, valid loss: 59.284147
epoch: 80, train precision: 0.972667, train loss: 13.855938, valid precision: 0.852600, valid loss: 58.706570
epoch: 81, train precision: 0.972356, train loss: 13.936876, valid precision: 0.851400, valid loss: 57.856563
epoch: 82, train precision: 0.969600, train loss: 14.323966, valid precision: 0.845200, valid loss: 59.968041
epoch: 83, train precision: 0.972244, train loss: 13.797187, valid precision: 0.853200, valid loss: 59.120779
epoch: 84, train precision: 0.971356, train loss: 13.773575, valid precision: 0.854600, valid loss: 59.088327
epoch: 85, train precision: 0.971044, train loss: 14.152785, valid precision: 0.849400, valid loss: 60.050755
epoch: 86, train precision: 0.973333, train loss: 13.429486, valid precision: 0.853200, valid loss: 59.727248
epoch: 87, train precision: 0.971911, train loss: 13.706336, valid precision: 0.854000, valid loss: 59.501064
epoch: 88, train precision: 0.976200, train loss: 12.662629, valid precision: 0.853400, valid loss: 59.954177
epoch: 89, train precision: 0.973111, train loss: 13.238658, valid precision: 0.857600, valid loss: 59.029044
epoch: 90, train precision: 0.973756, train loss: 13.193019, valid precision: 0.851800, valid loss: 60.704632
epoch: 91, train precision: 0.977333, train loss: 12.084775, valid precision: 0.858400, valid loss: 58.824693
epoch: 92, train precision: 0.975822, train loss: 12.722339, valid precision: 0.850000, valid loss: 62.061445
epoch: 93, train precision: 0.977533, train loss: 11.933937, valid precision: 0.855600, valid loss: 61.348750
epoch: 94, train precision: 0.975333, train loss: 12.557824, valid precision: 0.850000, valid loss: 61.986636
epoch: 95, train precision: 0.976622, train loss: 12.032963, valid precision: 0.857000, valid loss: 60.172070
epoch: 96, train precision: 0.978133, train loss: 12.091310, valid precision: 0.859600, valid loss: 58.759006
epoch: 97, train precision: 0.979000, train loss: 11.552940, valid precision: 0.855400, valid loss: 58.888720
epoch: 98, train precision: 0.977467, train loss: 11.865835, valid precision: 0.860000, valid loss: 60.624907
epoch: 99, train precision: 0.977822, train loss: 11.824623, valid precision: 0.849400, valid loss: 61.168442
epoch: 100, train precision: 0.979867, train loss: 11.179372, valid precision: 0.856000, valid loss: 60.986976
epoch: 101, train precision: 0.977756, train loss: 11.791530, valid precision: 0.856000, valid loss: 62.497814
epoch: 102, train precision: 0.981378, train loss: 10.729070, valid precision: 0.856800, valid loss: 63.164894
epoch: 103, train precision: 0.978422, train loss: 11.008198, valid precision: 0.857200, valid loss: 61.890779
epoch: 104, train precision: 0.978444, train loss: 11.325528, valid precision: 0.855800, valid loss: 62.207428
epoch: 105, train precision: 0.980556, train loss: 10.975979, valid precision: 0.853600, valid loss: 62.136078
epoch: 106, train precision: 0.982800, train loss: 10.152144, valid precision: 0.855800, valid loss: 61.657433
epoch: 107, train precision: 0.980911, train loss: 10.528442, valid precision: 0.859000, valid loss: 61.953083
epoch: 108, train precision: 0.981511, train loss: 10.414987, valid precision: 0.850800, valid loss: 62.660283
epoch: 109, train precision: 0.980778, train loss: 10.638696, valid precision: 0.860000, valid loss: 61.839058
epoch: 110, train precision: 0.981844, train loss: 10.444635, valid precision: 0.856400, valid loss: 62.152221
epoch: 111, train precision: 0.980889, train loss: 10.710628, valid precision: 0.855400, valid loss: 62.111763
epoch: 112, train precision: 0.981111, train loss: 10.497712, valid precision: 0.853000, valid loss: 64.717114
epoch: 113, train precision: 0.982000, train loss: 10.354676, valid precision: 0.851800, valid loss: 61.187198
epoch: 114, train precision: 0.983711, train loss: 9.909414, valid precision: 0.856200, valid loss: 62.669211
epoch: 115, train precision: 0.984578, train loss: 9.492105, valid precision: 0.857800, valid loss: 60.338102
epoch: 116, train precision: 0.982067, train loss: 9.875857, valid precision: 0.854000, valid loss: 62.788663
epoch: 117, train precision: 0.984022, train loss: 9.572815, valid precision: 0.860200, valid loss: 61.392495
epoch: 118, train precision: 0.983822, train loss: 9.676296, valid precision: 0.854400, valid loss: 61.728094
epoch: 119, train precision: 0.984689, train loss: 9.290399, valid precision: 0.861400, valid loss: 59.989501
epoch: 120, train precision: 0.985267, train loss: 9.195003, valid precision: 0.864000, valid loss: 60.803022
epoch: 121, train precision: 0.983244, train loss: 9.845598, valid precision: 0.859800, valid loss: 62.179130
epoch: 122, train precision: 0.984267, train loss: 9.378839, valid precision: 0.860000, valid loss: 59.527617
epoch: 123, train precision: 0.981889, train loss: 9.998644, valid precision: 0.858600, valid loss: 63.260347
epoch: 124, train precision: 0.985333, train loss: 8.882063, valid precision: 0.869000, valid loss: 61.104766
epoch: 125, train precision: 0.985400, train loss: 8.914092, valid precision: 0.862600, valid loss: 61.683359
epoch: 126, train precision: 0.986356, train loss: 8.789018, valid precision: 0.858800, valid loss: 62.735414
epoch: 127, train precision: 0.985978, train loss: 8.809948, valid precision: 0.859600, valid loss: 61.798761
epoch: 128, train precision: 0.985444, train loss: 8.825827, valid precision: 0.866600, valid loss: 61.776849
epoch: 129, train precision: 0.985756, train loss: 8.751342, valid precision: 0.864000, valid loss: 60.569862
epoch: 130, train precision: 0.985511, train loss: 8.992046, valid precision: 0.860200, valid loss: 61.327323
epoch: 131, train precision: 0.987622, train loss: 8.348461, valid precision: 0.858400, valid loss: 61.593319
epoch: 132, train precision: 0.986422, train loss: 8.819760, valid precision: 0.859600, valid loss: 62.054402
epoch: 133, train precision: 0.986911, train loss: 8.571877, valid precision: 0.861600, valid loss: 62.156589
epoch: 134, train precision: 0.987444, train loss: 8.507033, valid precision: 0.858000, valid loss: 62.742422
epoch: 135, train precision: 0.988067, train loss: 8.077434, valid precision: 0.862000, valid loss: 61.223341
epoch: 136, train precision: 0.987644, train loss: 7.986059, valid precision: 0.866800, valid loss: 60.769456
epoch: 137, train precision: 0.985756, train loss: 8.860192, valid precision: 0.858400, valid loss: 61.364674
epoch: 138, train precision: 0.988956, train loss: 7.917624, valid precision: 0.858400, valid loss: 62.787171
epoch: 139, train precision: 0.989044, train loss: 7.846819, valid precision: 0.860400, valid loss: 62.889414
epoch: 140, train precision: 0.987578, train loss: 8.229577, valid precision: 0.861000, valid loss: 64.405446
epoch: 141, train precision: 0.987178, train loss: 8.126146, valid precision: 0.858800, valid loss: 64.452513
epoch: 142, train precision: 0.989956, train loss: 7.640679, valid precision: 0.860200, valid loss: 64.497199
epoch: 143, train precision: 0.989356, train loss: 7.678744, valid precision: 0.861400, valid loss: 62.393324
epoch: 144, train precision: 0.988267, train loss: 7.918362, valid precision: 0.861800, valid loss: 62.896390
epoch: 145, train precision: 0.988244, train loss: 7.987102, valid precision: 0.861800, valid loss: 62.623137
epoch: 146, train precision: 0.988178, train loss: 7.973975, valid precision: 0.861800, valid loss: 62.483947
epoch: 147, train precision: 0.989600, train loss: 7.652278, valid precision: 0.863400, valid loss: 62.218358
epoch: 148, train precision: 0.988467, train loss: 7.851444, valid precision: 0.864400, valid loss: 64.199215
epoch: 149, train precision: 0.988844, train loss: 7.746040, valid precision: 0.871200, valid loss: 61.661853
epoch: 150, train precision: 0.989311, train loss: 7.589262, valid precision: 0.864400, valid loss: 62.106256
epoch: 151, train precision: 0.986733, train loss: 8.435094, valid precision: 0.862800, valid loss: 64.759084
epoch: 152, train precision: 0.987333, train loss: 8.077520, valid precision: 0.863600, valid loss: 63.585254
epoch: 153, train precision: 0.990733, train loss: 7.149089, valid precision: 0.866600, valid loss: 61.673594
epoch: 154, train precision: 0.988267, train loss: 8.028469, valid precision: 0.864600, valid loss: 62.917274
epoch: 155, train precision: 0.989556, train loss: 7.528327, valid precision: 0.866000, valid loss: 62.385639
epoch: 156, train precision: 0.989622, train loss: 7.633019, valid precision: 0.865000, valid loss: 62.893284
epoch: 157, train precision: 0.989911, train loss: 7.466506, valid precision: 0.865000, valid loss: 63.239960
epoch: 158, train precision: 0.990422, train loss: 7.282341, valid precision: 0.869000, valid loss: 62.170687
epoch: 159, train precision: 0.989822, train loss: 7.464213, valid precision: 0.864800, valid loss: 63.969692
epoch: 160, train precision: 0.990733, train loss: 7.144207, valid precision: 0.863600, valid loss: 64.901077
epoch: 161, train precision: 0.990667, train loss: 7.166625, valid precision: 0.865400, valid loss: 63.336154
epoch: 162, train precision: 0.988400, train loss: 7.719663, valid precision: 0.867200, valid loss: 63.398643
epoch: 163, train precision: 0.991711, train loss: 6.904698, valid precision: 0.867800, valid loss: 63.085779
epoch: 164, train precision: 0.991022, train loss: 6.975007, valid precision: 0.862800, valid loss: 64.234113
epoch: 165, train precision: 0.990022, train loss: 7.331698, valid precision: 0.865200, valid loss: 64.010594
epoch: 166, train precision: 0.990822, train loss: 7.094446, valid precision: 0.867400, valid loss: 62.713933
epoch: 167, train precision: 0.991756, train loss: 6.838439, valid precision: 0.867200, valid loss: 62.771462
epoch: 168, train precision: 0.990978, train loss: 7.008570, valid precision: 0.862200, valid loss: 65.048439
epoch: 169, train precision: 0.991156, train loss: 6.906698, valid precision: 0.862000, valid loss: 65.325668
epoch: 170, train precision: 0.990467, train loss: 7.093433, valid precision: 0.869200, valid loss: 63.433933
epoch: 171, train precision: 0.992200, train loss: 6.818385, valid precision: 0.867800, valid loss: 63.580749
epoch: 172, train precision: 0.990800, train loss: 7.227020, valid precision: 0.864200, valid loss: 63.845904
epoch: 173, train precision: 0.990622, train loss: 6.978799, valid precision: 0.865800, valid loss: 65.981914
epoch: 174, train precision: 0.991044, train loss: 7.088584, valid precision: 0.870600, valid loss: 63.529940
epoch: 175, train precision: 0.991022, train loss: 7.018088, valid precision: 0.867400, valid loss: 64.316202
epoch: 176, train precision: 0.991178, train loss: 7.097449, valid precision: 0.861000, valid loss: 65.527924
epoch: 177, train precision: 0.990422, train loss: 7.025185, valid precision: 0.866800, valid loss: 65.336888
epoch: 178, train precision: 0.992267, train loss: 6.712478, valid precision: 0.863200, valid loss: 65.969329
epoch: 179, train precision: 0.991311, train loss: 6.890231, valid precision: 0.861800, valid loss: 65.275256
epoch: 180, train precision: 0.991889, train loss: 6.849162, valid precision: 0.865800, valid loss: 66.605023
epoch: 181, train precision: 0.991778, train loss: 7.092071, valid precision: 0.862200, valid loss: 66.233180
epoch: 182, train precision: 0.992756, train loss: 6.520080, valid precision: 0.863600, valid loss: 65.004935
epoch: 183, train precision: 0.991200, train loss: 6.912539, valid precision: 0.863800, valid loss: 65.150083
epoch: 184, train precision: 0.991378, train loss: 6.791726, valid precision: 0.868200, valid loss: 65.177043
epoch: 185, train precision: 0.992756, train loss: 6.494305, valid precision: 0.864600, valid loss: 66.406526
epoch: 186, train precision: 0.991800, train loss: 6.681402, valid precision: 0.867200, valid loss: 66.550573
epoch: 187, train precision: 0.993178, train loss: 6.344430, valid precision: 0.868400, valid loss: 64.999375
epoch: 188, train precision: 0.992533, train loss: 6.543724, valid precision: 0.866200, valid loss: 65.821407
epoch: 189, train precision: 0.991533, train loss: 6.873228, valid precision: 0.869000, valid loss: 65.935091
epoch: 190, train precision: 0.992689, train loss: 6.493591, valid precision: 0.868000, valid loss: 63.690555
epoch: 191, train precision: 0.991756, train loss: 6.715048, valid precision: 0.866200, valid loss: 66.373831
epoch: 192, train precision: 0.992378, train loss: 6.630789, valid precision: 0.862000, valid loss: 66.609405
epoch: 193, train precision: 0.992156, train loss: 6.611727, valid precision: 0.868800, valid loss: 65.805525
epoch: 194, train precision: 0.992644, train loss: 6.529516, valid precision: 0.866400, valid loss: 66.546031
epoch: 195, train precision: 0.992778, train loss: 6.396611, valid precision: 0.868200, valid loss: 66.118369
epoch: 196, train precision: 0.994111, train loss: 6.185706, valid precision: 0.864200, valid loss: 64.609533
epoch: 197, train precision: 0.993556, train loss: 6.160270, valid precision: 0.866600, valid loss: 64.633806
epoch: 198, train precision: 0.992889, train loss: 6.444919, valid precision: 0.863800, valid loss: 64.862828
epoch: 199, train precision: 0.993778, train loss: 6.191182, valid precision: 0.864200, valid loss: 66.750283
epoch: 200, train precision: 0.992556, train loss: 6.529806, valid precision: 0.863600, valid loss: 66.487363
epoch: 201, train precision: 0.993800, train loss: 6.136712, valid precision: 0.866000, valid loss: 66.008224
epoch: 202, train precision: 0.992844, train loss: 6.316891, valid precision: 0.861800, valid loss: 65.602087
epoch: 203, train precision: 0.992467, train loss: 6.419859, valid precision: 0.864000, valid loss: 68.172788
epoch: 204, train precision: 0.994111, train loss: 6.005172, valid precision: 0.864600, valid loss: 66.111093
epoch: 205, train precision: 0.993156, train loss: 6.376002, valid precision: 0.870000, valid loss: 65.240830
epoch: 206, train precision: 0.993978, train loss: 6.179779, valid precision: 0.863200, valid loss: 66.749364
epoch: 207, train precision: 0.993333, train loss: 6.239633, valid precision: 0.867400, valid loss: 65.725139
epoch: 208, train precision: 0.993733, train loss: 6.086521, valid precision: 0.867400, valid loss: 66.309340
epoch: 209, train precision: 0.994333, train loss: 5.978970, valid precision: 0.863800, valid loss: 66.096174
epoch: 210, train precision: 0.992911, train loss: 6.384386, valid precision: 0.866600, valid loss: 67.372313
epoch: 211, train precision: 0.991000, train loss: 7.087051, valid precision: 0.861000, valid loss: 68.896569
epoch: 212, train precision: 0.993867, train loss: 6.204977, valid precision: 0.864600, valid loss: 68.877850
epoch: 213, train precision: 0.993778, train loss: 6.247758, valid precision: 0.863600, valid loss: 68.003215
epoch: 214, train precision: 0.994289, train loss: 5.863732, valid precision: 0.863400, valid loss: 68.721580
epoch: 215, train precision: 0.994178, train loss: 6.015196, valid precision: 0.860600, valid loss: 68.349299
epoch: 216, train precision: 0.993133, train loss: 6.368260, valid precision: 0.864400, valid loss: 69.258238
epoch: 217, train precision: 0.994689, train loss: 5.845733, valid precision: 0.864800, valid loss: 68.795234
epoch: 218, train precision: 0.994200, train loss: 5.930643, valid precision: 0.866600, valid loss: 68.035771
epoch: 219, train precision: 0.994400, train loss: 5.995955, valid precision: 0.867200, valid loss: 68.667683
epoch: 220, train precision: 0.993867, train loss: 6.208059, valid precision: 0.868800, valid loss: 67.861065
epoch: 221, train precision: 0.994022, train loss: 5.973706, valid precision: 0.866600, valid loss: 69.858338
epoch: 222, train precision: 0.993644, train loss: 6.186853, valid precision: 0.863400, valid loss: 70.198718
epoch: 223, train precision: 0.993933, train loss: 6.039782, valid precision: 0.868400, valid loss: 68.143629
epoch: 224, train precision: 0.994756, train loss: 5.880968, valid precision: 0.868200, valid loss: 68.012282
epoch: 225, train precision: 0.994333, train loss: 6.080440, valid precision: 0.866200, valid loss: 66.921988
epoch: 226, train precision: 0.994600, train loss: 5.838610, valid precision: 0.863800, valid loss: 67.179185
epoch: 227, train precision: 0.994200, train loss: 6.179719, valid precision: 0.864600, valid loss: 67.964893
epoch: 228, train precision: 0.994778, train loss: 5.861726, valid precision: 0.866800, valid loss: 67.366277
epoch: 229, train precision: 0.994400, train loss: 5.948172, valid precision: 0.870200, valid loss: 69.119887
epoch: 230, train precision: 0.994978, train loss: 5.696911, valid precision: 0.864000, valid loss: 70.096624
epoch: 231, train precision: 0.995111, train loss: 5.720129, valid precision: 0.866200, valid loss: 68.976521
epoch: 232, train precision: 0.993689, train loss: 5.963617, valid precision: 0.863600, valid loss: 70.495020
epoch: 233, train precision: 0.994489, train loss: 5.908463, valid precision: 0.867200, valid loss: 69.628009
epoch: 234, train precision: 0.994556, train loss: 5.813846, valid precision: 0.865000, valid loss: 69.245521
epoch: 235, train precision: 0.995156, train loss: 5.788102, valid precision: 0.863400, valid loss: 70.078740
epoch: 236, train precision: 0.994778, train loss: 5.693861, valid precision: 0.863000, valid loss: 69.967135
epoch: 237, train precision: 0.995422, train loss: 5.664100, valid precision: 0.865200, valid loss: 70.310027
epoch: 238, train precision: 0.995244, train loss: 5.637028, valid precision: 0.863400, valid loss: 70.244359
epoch: 239, train precision: 0.994844, train loss: 5.816677, valid precision: 0.868200, valid loss: 68.485377
epoch: 240, train precision: 0.994822, train loss: 5.832153, valid precision: 0.865400, valid loss: 70.745514
epoch: 241, train precision: 0.995689, train loss: 5.566865, valid precision: 0.864600, valid loss: 70.277121
epoch: 242, train precision: 0.995889, train loss: 5.482671, valid precision: 0.870000, valid loss: 69.894075
epoch: 243, train precision: 0.995044, train loss: 5.828699, valid precision: 0.867200, valid loss: 71.238094
epoch: 244, train precision: 0.995267, train loss: 5.718377, valid precision: 0.862600, valid loss: 70.604423
epoch: 245, train precision: 0.995200, train loss: 5.661521, valid precision: 0.867800, valid loss: 72.405918
epoch: 246, train precision: 0.994844, train loss: 5.818875, valid precision: 0.864400, valid loss: 71.879000
epoch: 247, train precision: 0.994289, train loss: 5.892951, valid precision: 0.866400, valid loss: 72.448362
epoch: 248, train precision: 0.995689, train loss: 5.537494, valid precision: 0.866000, valid loss: 72.851791
epoch: 249, train precision: 0.995422, train loss: 5.644687, valid precision: 0.863600, valid loss: 71.517542
epoch: 250, train precision: 0.994756, train loss: 5.866346, valid precision: 0.869400, valid loss: 68.481566
epoch: 251, train precision: 0.995133, train loss: 5.613062, valid precision: 0.865200, valid loss: 71.593695
epoch: 252, train precision: 0.995978, train loss: 5.561306, valid precision: 0.870000, valid loss: 68.353087
epoch: 253, train precision: 0.994756, train loss: 5.696829, valid precision: 0.868400, valid loss: 68.722357
epoch: 254, train precision: 0.994711, train loss: 5.795575, valid precision: 0.870000, valid loss: 67.893378
epoch: 255, train precision: 0.996000, train loss: 5.460271, valid precision: 0.869800, valid loss: 71.742476
epoch: 256, train precision: 0.995644, train loss: 5.529979, valid precision: 0.872000, valid loss: 69.300735
epoch: 257, train precision: 0.995333, train loss: 5.533378, valid precision: 0.873200, valid loss: 69.879890
epoch: 258, train precision: 0.996222, train loss: 5.422190, valid precision: 0.869800, valid loss: 70.449425
epoch: 259, train precision: 0.995711, train loss: 5.541265, valid precision: 0.870600, valid loss: 69.252575
epoch: 260, train precision: 0.996222, train loss: 5.378790, valid precision: 0.873000, valid loss: 69.266271
epoch: 261, train precision: 0.994733, train loss: 5.867505, valid precision: 0.870400, valid loss: 70.920065
epoch: 262, train precision: 0.995244, train loss: 5.702427, valid precision: 0.870200, valid loss: 70.578112
epoch: 263, train precision: 0.995333, train loss: 5.545355, valid precision: 0.872800, valid loss: 70.028823
epoch: 264, train precision: 0.995867, train loss: 5.455357, valid precision: 0.874800, valid loss: 69.065951
epoch: 265, train precision: 0.995867, train loss: 5.514269, valid precision: 0.869400, valid loss: 69.869340
epoch: 266, train precision: 0.995333, train loss: 5.811986, valid precision: 0.868800, valid loss: 70.809309
epoch: 267, train precision: 0.995956, train loss: 5.582281, valid precision: 0.870800, valid loss: 67.641495
epoch: 268, train precision: 0.995689, train loss: 5.578767, valid precision: 0.873600, valid loss: 68.657827
epoch: 269, train precision: 0.996400, train loss: 5.384185, valid precision: 0.869400, valid loss: 69.693814
epoch: 270, train precision: 0.995844, train loss: 5.484235, valid precision: 0.871800, valid loss: 71.454485
epoch: 271, train precision: 0.995444, train loss: 5.691067, valid precision: 0.866200, valid loss: 70.800805
epoch: 272, train precision: 0.996289, train loss: 5.356001, valid precision: 0.867000, valid loss: 69.818118
epoch: 273, train precision: 0.995822, train loss: 5.623555, valid precision: 0.869800, valid loss: 69.340412
epoch: 274, train precision: 0.996467, train loss: 5.307506, valid precision: 0.875800, valid loss: 67.590664
epoch: 275, train precision: 0.995956, train loss: 5.401241, valid precision: 0.870400, valid loss: 70.223799
epoch: 276, train precision: 0.996044, train loss: 5.496821, valid precision: 0.869400, valid loss: 69.628582
epoch: 277, train precision: 0.995889, train loss: 5.515910, valid precision: 0.866400, valid loss: 70.105395
epoch: 278, train precision: 0.996511, train loss: 5.429135, valid precision: 0.871000, valid loss: 69.028700
epoch: 279, train precision: 0.996022, train loss: 5.566007, valid precision: 0.867600, valid loss: 68.631946
epoch: 280, train precision: 0.995822, train loss: 5.642573, valid precision: 0.873400, valid loss: 69.519434
epoch: 281, train precision: 0.996467, train loss: 5.367452, valid precision: 0.871600, valid loss: 70.140765
epoch: 282, train precision: 0.995600, train loss: 5.608351, valid precision: 0.865800, valid loss: 68.970250
epoch: 283, train precision: 0.996111, train loss: 5.520606, valid precision: 0.867800, valid loss: 71.256667
epoch: 284, train precision: 0.995756, train loss: 5.555418, valid precision: 0.870000, valid loss: 71.546331
epoch: 285, train precision: 0.997067, train loss: 5.162774, valid precision: 0.872600, valid loss: 70.651778
epoch: 286, train precision: 0.996956, train loss: 5.270102, valid precision: 0.870800, valid loss: 70.231994
epoch: 287, train precision: 0.995978, train loss: 5.394962, valid precision: 0.870800, valid loss: 72.226839
epoch: 288, train precision: 0.995889, train loss: 5.631550, valid precision: 0.869600, valid loss: 72.602370
epoch: 289, train precision: 0.996267, train loss: 5.454401, valid precision: 0.876200, valid loss: 70.134367
epoch: 290, train precision: 0.996333, train loss: 5.393007, valid precision: 0.875800, valid loss: 70.724477
epoch: 291, train precision: 0.995978, train loss: 5.457630, valid precision: 0.870400, valid loss: 70.421308
epoch: 292, train precision: 0.995578, train loss: 5.661440, valid precision: 0.872000, valid loss: 71.299557
epoch: 293, train precision: 0.996111, train loss: 5.475695, valid precision: 0.872200, valid loss: 69.817316
epoch: 294, train precision: 0.996511, train loss: 5.326646, valid precision: 0.874200, valid loss: 70.024926
epoch: 295, train precision: 0.996933, train loss: 5.274293, valid precision: 0.873000, valid loss: 69.684772
epoch: 296, train precision: 0.996133, train loss: 5.470265, valid precision: 0.869000, valid loss: 70.531153
epoch: 297, train precision: 0.996578, train loss: 5.261976, valid precision: 0.871400, valid loss: 71.138040
epoch: 298, train precision: 0.995933, train loss: 5.477724, valid precision: 0.870000, valid loss: 71.843281
epoch: 299, train precision: 0.997000, train loss: 5.250201, valid precision: 0.869000, valid loss: 72.005176
epoch: 300, train precision: 0.996689, train loss: 5.281427, valid precision: 0.871000, valid loss: 72.608139
epoch: 301, train precision: 0.996867, train loss: 5.347592, valid precision: 0.868800, valid loss: 71.847018
epoch: 302, train precision: 0.996778, train loss: 5.258237, valid precision: 0.867400, valid loss: 72.665810
epoch: 303, train precision: 0.996756, train loss: 5.239736, valid precision: 0.872000, valid loss: 70.062748
epoch: 304, train precision: 0.996756, train loss: 5.152131, valid precision: 0.874000, valid loss: 71.789065
epoch: 305, train precision: 0.996289, train loss: 5.381691, valid precision: 0.871800, valid loss: 70.127497
epoch: 306, train precision: 0.996800, train loss: 5.348666, valid precision: 0.871600, valid loss: 69.462640
epoch: 307, train precision: 0.997022, train loss: 5.174919, valid precision: 0.874600, valid loss: 71.268976
epoch: 308, train precision: 0.997200, train loss: 5.147642, valid precision: 0.873000, valid loss: 69.307159
epoch: 309, train precision: 0.996200, train loss: 5.451958, valid precision: 0.872200, valid loss: 70.561537
epoch: 310, train precision: 0.996067, train loss: 5.447062, valid precision: 0.871800, valid loss: 70.236971
epoch: 311, train precision: 0.996844, train loss: 5.228146, valid precision: 0.871600, valid loss: 70.847138
epoch: 312, train precision: 0.996422, train loss: 5.385296, valid precision: 0.869600, valid loss: 69.793712
epoch: 313, train precision: 0.996733, train loss: 5.337810, valid precision: 0.872800, valid loss: 70.523470
epoch: 314, train precision: 0.996667, train loss: 5.229256, valid precision: 0.871200, valid loss: 72.590393
epoch: 315, train precision: 0.997067, train loss: 5.236609, valid precision: 0.871000, valid loss: 71.021627
epoch: 316, train precision: 0.996533, train loss: 5.296206, valid precision: 0.868400, valid loss: 72.362729
epoch: 317, train precision: 0.997311, train loss: 5.251328, valid precision: 0.873000, valid loss: 71.841398
epoch: 318, train precision: 0.995622, train loss: 5.634060, valid precision: 0.869600, valid loss: 74.763359
epoch: 319, train precision: 0.996822, train loss: 5.341351, valid precision: 0.872600, valid loss: 73.499636
epoch: 320, train precision: 0.996022, train loss: 5.503680, valid precision: 0.867600, valid loss: 74.857055
epoch: 321, train precision: 0.996756, train loss: 5.297842, valid precision: 0.869600, valid loss: 72.581456
epoch: 322, train precision: 0.996578, train loss: 5.285354, valid precision: 0.867800, valid loss: 73.385152
epoch: 323, train precision: 0.996800, train loss: 5.201054, valid precision: 0.873200, valid loss: 71.598344
epoch: 324, train precision: 0.996311, train loss: 5.405579, valid precision: 0.872800, valid loss: 71.950349
epoch: 325, train precision: 0.996578, train loss: 5.443266, valid precision: 0.868800, valid loss: 73.364959
epoch: 326, train precision: 0.997000, train loss: 5.288539, valid precision: 0.867200, valid loss: 71.387595
epoch: 327, train precision: 0.996756, train loss: 5.293034, valid precision: 0.868800, valid loss: 72.065252
epoch: 328, train precision: 0.997178, train loss: 5.175690, valid precision: 0.868400, valid loss: 70.843730
epoch: 329, train precision: 0.997689, train loss: 5.087870, valid precision: 0.871200, valid loss: 72.412079
epoch: 330, train precision: 0.996667, train loss: 5.250843, valid precision: 0.870000, valid loss: 70.716197
epoch: 331, train precision: 0.996667, train loss: 5.381727, valid precision: 0.868400, valid loss: 72.254059
epoch: 332, train precision: 0.997089, train loss: 5.196085, valid precision: 0.872800, valid loss: 72.512165
epoch: 333, train precision: 0.997378, train loss: 5.173811, valid precision: 0.871800, valid loss: 71.600537
epoch: 334, train precision: 0.997289, train loss: 5.175171, valid precision: 0.870200, valid loss: 73.680333
epoch: 335, train precision: 0.997022, train loss: 5.278543, valid precision: 0.866000, valid loss: 74.438579
epoch: 336, train precision: 0.996333, train loss: 5.501441, valid precision: 0.863400, valid loss: 72.041051
epoch: 337, train precision: 0.997533, train loss: 5.139547, valid precision: 0.868000, valid loss: 72.911340
epoch: 338, train precision: 0.997244, train loss: 5.234501, valid precision: 0.869800, valid loss: 71.896055
epoch: 339, train precision: 0.996533, train loss: 5.406555, valid precision: 0.868000, valid loss: 72.498016
epoch: 340, train precision: 0.997022, train loss: 5.253983, valid precision: 0.869200, valid loss: 71.897180
epoch: 341, train precision: 0.997156, train loss: 5.305390, valid precision: 0.866200, valid loss: 70.598710
epoch: 342, train precision: 0.996933, train loss: 5.427407, valid precision: 0.869400, valid loss: 72.606616
epoch: 343, train precision: 0.996889, train loss: 5.385071, valid precision: 0.868800, valid loss: 71.393821
epoch: 344, train precision: 0.996356, train loss: 5.400146, valid precision: 0.872600, valid loss: 70.564269
epoch: 345, train precision: 0.996578, train loss: 5.452335, valid precision: 0.875400, valid loss: 71.017029
epoch: 346, train precision: 0.997511, train loss: 5.176893, valid precision: 0.869600, valid loss: 71.676745
epoch: 347, train precision: 0.996089, train loss: 5.617458, valid precision: 0.866000, valid loss: 73.334868
epoch: 348, train precision: 0.997533, train loss: 5.144132, valid precision: 0.868400, valid loss: 73.515752
epoch: 349, train precision: 0.997044, train loss: 5.290703, valid precision: 0.869200, valid loss: 72.620375
epoch: 350, train precision: 0.996800, train loss: 5.219979, valid precision: 0.876200, valid loss: 71.270320
epoch: 351, train precision: 0.997667, train loss: 5.088584, valid precision: 0.875400, valid loss: 72.118973
epoch: 352, train precision: 0.997133, train loss: 5.290370, valid precision: 0.871400, valid loss: 71.811003
epoch: 353, train precision: 0.996644, train loss: 5.401928, valid precision: 0.874400, valid loss: 71.957718
epoch: 354, train precision: 0.997644, train loss: 5.139176, valid precision: 0.872200, valid loss: 71.193530
epoch: 355, train precision: 0.997111, train loss: 5.229983, valid precision: 0.872600, valid loss: 71.444238
epoch: 356, train precision: 0.996711, train loss: 5.297812, valid precision: 0.873000, valid loss: 72.010123
epoch: 357, train precision: 0.997067, train loss: 5.390926, valid precision: 0.871200, valid loss: 71.096421
epoch: 358, train precision: 0.996356, train loss: 5.443226, valid precision: 0.867600, valid loss: 72.214198
epoch: 359, train precision: 0.997422, train loss: 5.106750, valid precision: 0.871000, valid loss: 72.779282
epoch: 360, train precision: 0.997778, train loss: 5.034662, valid precision: 0.868600, valid loss: 73.128795
epoch: 361, train precision: 0.997444, train loss: 5.177088, valid precision: 0.869800, valid loss: 75.022527
epoch: 362, train precision: 0.997667, train loss: 5.068590, valid precision: 0.869200, valid loss: 74.444673
epoch: 363, train precision: 0.997111, train loss: 5.247705, valid precision: 0.870600, valid loss: 73.944592
epoch: 364, train precision: 0.997378, train loss: 5.189394, valid precision: 0.865600, valid loss: 73.227597
epoch: 365, train precision: 0.996778, train loss: 5.362047, valid precision: 0.870400, valid loss: 71.744831
epoch: 366, train precision: 0.997267, train loss: 5.271942, valid precision: 0.873000, valid loss: 71.698338
epoch: 367, train precision: 0.998289, train loss: 5.010920, valid precision: 0.872800, valid loss: 72.496480
epoch: 368, train precision: 0.997667, train loss: 5.165075, valid precision: 0.874400, valid loss: 71.061630
epoch: 369, train precision: 0.997400, train loss: 5.143859, valid precision: 0.875200, valid loss: 72.475327
epoch: 370, train precision: 0.997422, train loss: 5.156982, valid precision: 0.872400, valid loss: 72.218177
epoch: 371, train precision: 0.996844, train loss: 5.292437, valid precision: 0.868600, valid loss: 73.806134
epoch: 372, train precision: 0.997200, train loss: 5.213149, valid precision: 0.874400, valid loss: 72.944407
epoch: 373, train precision: 0.997378, train loss: 5.217721, valid precision: 0.875200, valid loss: 71.576545
epoch: 374, train precision: 0.997756, train loss: 5.080376, valid precision: 0.875200, valid loss: 71.741423
epoch: 375, train precision: 0.997511, train loss: 5.175260, valid precision: 0.870200, valid loss: 72.426901
epoch: 376, train precision: 0.997133, train loss: 5.159120, valid precision: 0.869000, valid loss: 74.053399
epoch: 377, train precision: 0.996978, train loss: 5.341735, valid precision: 0.870600, valid loss: 74.105065
epoch: 378, train precision: 0.997644, train loss: 5.101058, valid precision: 0.869200, valid loss: 74.326894
epoch: 379, train precision: 0.997778, train loss: 5.101273, valid precision: 0.871200, valid loss: 73.508581
epoch: 380, train precision: 0.997556, train loss: 5.188766, valid precision: 0.871000, valid loss: 73.569624
epoch: 381, train precision: 0.997133, train loss: 5.297242, valid precision: 0.871400, valid loss: 74.180837
epoch: 382, train precision: 0.996689, train loss: 5.480583, valid precision: 0.872800, valid loss: 71.308651
epoch: 383, train precision: 0.997111, train loss: 5.410629, valid precision: 0.867800, valid loss: 72.549696
epoch: 384, train precision: 0.997533, train loss: 5.184286, valid precision: 0.872000, valid loss: 73.504986
epoch: 385, train precision: 0.997311, train loss: 5.195423, valid precision: 0.871400, valid loss: 73.821613
epoch: 386, train precision: 0.997533, train loss: 5.144253, valid precision: 0.869600, valid loss: 72.827261
epoch: 387, train precision: 0.998222, train loss: 4.983555, valid precision: 0.871800, valid loss: 74.249572
epoch: 388, train precision: 0.997956, train loss: 5.081417, valid precision: 0.870400, valid loss: 73.592761
epoch: 389, train precision: 0.997600, train loss: 5.102956, valid precision: 0.870800, valid loss: 75.588733
epoch: 390, train precision: 0.997578, train loss: 5.219584, valid precision: 0.873600, valid loss: 74.742446
epoch: 391, train precision: 0.997511, train loss: 5.261121, valid precision: 0.873200, valid loss: 75.720777
epoch: 392, train precision: 0.996489, train loss: 5.477059, valid precision: 0.868800, valid loss: 77.898037
epoch: 393, train precision: 0.998222, train loss: 5.023410, valid precision: 0.870800, valid loss: 73.966327
epoch: 394, train precision: 0.997733, train loss: 5.105430, valid precision: 0.870400, valid loss: 73.846898
epoch: 395, train precision: 0.998022, train loss: 5.118230, valid precision: 0.873200, valid loss: 73.460625
epoch: 396, train precision: 0.997822, train loss: 5.086757, valid precision: 0.872400, valid loss: 73.050802
epoch: 397, train precision: 0.996689, train loss: 5.596360, valid precision: 0.865600, valid loss: 76.700320
epoch: 398, train precision: 0.998022, train loss: 5.154723, valid precision: 0.871600, valid loss: 73.265174
epoch: 399, train precision: 0.997000, train loss: 5.312953, valid precision: 0.871800, valid loss: 74.962954
epoch: 400, train precision: 0.997644, train loss: 5.175613, valid precision: 0.867800, valid loss: 75.866751
epoch: 401, train precision: 0.997378, train loss: 5.251221, valid precision: 0.873800, valid loss: 75.599752
epoch: 402, train precision: 0.997911, train loss: 5.085203, valid precision: 0.869000, valid loss: 74.155463
epoch: 403, train precision: 0.997644, train loss: 5.223765, valid precision: 0.871400, valid loss: 73.998061
epoch: 404, train precision: 0.998133, train loss: 5.100339, valid precision: 0.870400, valid loss: 74.199707
epoch: 405, train precision: 0.998222, train loss: 5.001633, valid precision: 0.870400, valid loss: 72.937926
epoch: 406, train precision: 0.998022, train loss: 5.165512, valid precision: 0.871600, valid loss: 75.078415
epoch: 407, train precision: 0.997378, train loss: 5.230344, valid precision: 0.870200, valid loss: 75.716333
epoch: 408, train precision: 0.998044, train loss: 5.092302, valid precision: 0.869200, valid loss: 75.323074
epoch: 409, train precision: 0.997244, train loss: 5.265764, valid precision: 0.869800, valid loss: 74.501370
epoch: 410, train precision: 0.997778, train loss: 5.123855, valid precision: 0.871200, valid loss: 73.376586
epoch: 411, train precision: 0.997689, train loss: 5.086321, valid precision: 0.873200, valid loss: 73.606534
epoch: 412, train precision: 0.997311, train loss: 5.188930, valid precision: 0.871400, valid loss: 74.129854
epoch: 413, train precision: 0.997289, train loss: 5.366466, valid precision: 0.872200, valid loss: 75.297160
epoch: 414, train precision: 0.997978, train loss: 5.170941, valid precision: 0.870600, valid loss: 76.537280
epoch: 415, train precision: 0.997956, train loss: 5.152014, valid precision: 0.875000, valid loss: 73.055016
epoch: 416, train precision: 0.997933, train loss: 5.118280, valid precision: 0.870000, valid loss: 75.080739
epoch: 417, train precision: 0.998222, train loss: 5.006054, valid precision: 0.870200, valid loss: 74.797665
epoch: 418, train precision: 0.997711, train loss: 5.148876, valid precision: 0.874600, valid loss: 75.676320
epoch: 419, train precision: 0.997711, train loss: 5.094405, valid precision: 0.867800, valid loss: 76.168213
epoch: 420, train precision: 0.997622, train loss: 5.280892, valid precision: 0.869400, valid loss: 74.897950
epoch: 421, train precision: 0.998644, train loss: 5.073835, valid precision: 0.873600, valid loss: 73.559151
epoch: 422, train precision: 0.997867, train loss: 5.185284, valid precision: 0.875400, valid loss: 75.029111
epoch: 423, train precision: 0.997467, train loss: 5.219379, valid precision: 0.871800, valid loss: 74.987362
epoch: 424, train precision: 0.997956, train loss: 5.176216, valid precision: 0.870800, valid loss: 75.980079
epoch: 425, train precision: 0.997956, train loss: 5.164714, valid precision: 0.868200, valid loss: 75.805859
epoch: 426, train precision: 0.998333, train loss: 4.965346, valid precision: 0.871800, valid loss: 74.879129
epoch: 427, train precision: 0.997956, train loss: 5.074221, valid precision: 0.872600, valid loss: 75.273100
epoch: 428, train precision: 0.997778, train loss: 5.204733, valid precision: 0.871400, valid loss: 76.522413
epoch: 429, train precision: 0.998178, train loss: 5.053866, valid precision: 0.869200, valid loss: 77.128496
epoch: 430, train precision: 0.998267, train loss: 5.034826, valid precision: 0.871000, valid loss: 75.701186
epoch: 431, train precision: 0.998244, train loss: 5.066032, valid precision: 0.869600, valid loss: 76.484263
epoch: 432, train precision: 0.997689, train loss: 5.167144, valid precision: 0.869400, valid loss: 78.444327
epoch: 433, train precision: 0.997378, train loss: 5.283666, valid precision: 0.869000, valid loss: 77.775245
epoch: 434, train precision: 0.997156, train loss: 5.335206, valid precision: 0.871000, valid loss: 76.595902
epoch: 435, train precision: 0.997356, train loss: 5.248913, valid precision: 0.866600, valid loss: 78.918559
epoch: 436, train precision: 0.997556, train loss: 5.282972, valid precision: 0.871000, valid loss: 78.765808
epoch: 437, train precision: 0.998022, train loss: 5.101366, valid precision: 0.871400, valid loss: 76.252899
epoch: 438, train precision: 0.998000, train loss: 5.135604, valid precision: 0.872400, valid loss: 77.388385
epoch: 439, train precision: 0.998356, train loss: 5.067922, valid precision: 0.873000, valid loss: 77.812764
epoch: 440, train precision: 0.997978, train loss: 5.118976, valid precision: 0.871800, valid loss: 77.932351
epoch: 441, train precision: 0.998178, train loss: 5.069085, valid precision: 0.872000, valid loss: 79.107877
epoch: 442, train precision: 0.997800, train loss: 5.133910, valid precision: 0.866800, valid loss: 77.600959
epoch: 443, train precision: 0.998200, train loss: 5.137080, valid precision: 0.870000, valid loss: 76.537852
epoch: 444, train precision: 0.997978, train loss: 5.226857, valid precision: 0.871200, valid loss: 77.945159
epoch: 445, train precision: 0.998178, train loss: 5.039171, valid precision: 0.872800, valid loss: 76.793675
epoch: 446, train precision: 0.997667, train loss: 5.186246, valid precision: 0.869400, valid loss: 76.731776
epoch: 447, train precision: 0.998267, train loss: 5.075418, valid precision: 0.873200, valid loss: 77.723721
epoch: 448, train precision: 0.997933, train loss: 5.092854, valid precision: 0.873000, valid loss: 78.310074
epoch: 449, train precision: 0.998000, train loss: 5.163889, valid precision: 0.875200, valid loss: 79.183700
epoch: 450, train precision: 0.998222, train loss: 5.115324, valid precision: 0.873600, valid loss: 76.218835
epoch: 451, train precision: 0.998022, train loss: 5.100883, valid precision: 0.873200, valid loss: 76.839404
epoch: 452, train precision: 0.998200, train loss: 5.115078, valid precision: 0.876200, valid loss: 78.944091
epoch: 453, train precision: 0.997756, train loss: 5.212895, valid precision: 0.871600, valid loss: 78.161125
epoch: 454, train precision: 0.998222, train loss: 5.060149, valid precision: 0.875000, valid loss: 76.377820
epoch: 455, train precision: 0.997844, train loss: 5.191328, valid precision: 0.867400, valid loss: 78.585701
epoch: 456, train precision: 0.998756, train loss: 4.962634, valid precision: 0.872600, valid loss: 76.922970
epoch: 457, train precision: 0.997889, train loss: 5.190093, valid precision: 0.869600, valid loss: 76.082159
epoch: 458, train precision: 0.998111, train loss: 5.150108, valid precision: 0.871800, valid loss: 75.462576
epoch: 459, train precision: 0.998289, train loss: 5.122374, valid precision: 0.875800, valid loss: 73.994558
epoch: 460, train precision: 0.998511, train loss: 4.983544, valid precision: 0.872200, valid loss: 77.412305
epoch: 461, train precision: 0.998356, train loss: 5.041850, valid precision: 0.871600, valid loss: 77.085361
epoch: 462, train precision: 0.997844, train loss: 5.204079, valid precision: 0.869000, valid loss: 76.665149
epoch: 463, train precision: 0.998111, train loss: 5.203146, valid precision: 0.874600, valid loss: 76.169176
epoch: 464, train precision: 0.998356, train loss: 5.005524, valid precision: 0.872000, valid loss: 78.010100
epoch: 465, train precision: 0.998022, train loss: 5.162639, valid precision: 0.869200, valid loss: 77.781247
epoch: 466, train precision: 0.997889, train loss: 5.255221, valid precision: 0.872600, valid loss: 78.254154
epoch: 467, train precision: 0.998733, train loss: 5.025116, valid precision: 0.871200, valid loss: 77.579705
epoch: 468, train precision: 0.998511, train loss: 5.111485, valid precision: 0.870600, valid loss: 77.988659
epoch: 469, train precision: 0.998200, train loss: 5.192429, valid precision: 0.872800, valid loss: 76.826311
epoch: 470, train precision: 0.998667, train loss: 5.079878, valid precision: 0.871000, valid loss: 76.610049
epoch: 471, train precision: 0.998244, train loss: 5.120259, valid precision: 0.870000, valid loss: 77.952423
epoch: 472, train precision: 0.998467, train loss: 5.073733, valid precision: 0.872400, valid loss: 76.700616
epoch: 473, train precision: 0.999133, train loss: 4.919681, valid precision: 0.875800, valid loss: 73.532984
epoch: 474, train precision: 0.997378, train loss: 5.487902, valid precision: 0.872400, valid loss: 77.328509
epoch: 475, train precision: 0.998133, train loss: 5.151606, valid precision: 0.873000, valid loss: 77.951558
epoch: 476, train precision: 0.998600, train loss: 4.986786, valid precision: 0.877400, valid loss: 75.476064
epoch: 477, train precision: 0.998378, train loss: 5.045658, valid precision: 0.876400, valid loss: 76.549278
epoch: 478, train precision: 0.998222, train loss: 5.166014, valid precision: 0.876800, valid loss: 75.638505
epoch: 479, train precision: 0.997267, train loss: 5.473374, valid precision: 0.868800, valid loss: 79.298584
epoch: 480, train precision: 0.998511, train loss: 5.088449, valid precision: 0.874600, valid loss: 76.042414
epoch: 481, train precision: 0.998644, train loss: 4.993199, valid precision: 0.870600, valid loss: 78.066209
epoch: 482, train precision: 0.998200, train loss: 5.159454, valid precision: 0.871600, valid loss: 77.602075
epoch: 483, train precision: 0.998489, train loss: 5.011857, valid precision: 0.874800, valid loss: 77.929578
epoch: 484, train precision: 0.998333, train loss: 5.120924, valid precision: 0.872600, valid loss: 77.970691
epoch: 485, train precision: 0.998156, train loss: 5.210405, valid precision: 0.870000, valid loss: 78.322177
epoch: 486, train precision: 0.998556, train loss: 5.072990, valid precision: 0.875400, valid loss: 76.920929
epoch: 487, train precision: 0.998200, train loss: 5.211114, valid precision: 0.872000, valid loss: 77.999022
epoch: 488, train precision: 0.998356, train loss: 5.095042, valid precision: 0.871000, valid loss: 77.990437
epoch: 489, train precision: 0.997800, train loss: 5.243462, valid precision: 0.873600, valid loss: 76.279790
epoch: 490, train precision: 0.998822, train loss: 5.001126, valid precision: 0.875000, valid loss: 74.665175
epoch: 491, train precision: 0.998378, train loss: 5.157836, valid precision: 0.872400, valid loss: 77.572225
epoch: 492, train precision: 0.998311, train loss: 5.199936, valid precision: 0.871800, valid loss: 77.789104
epoch: 493, train precision: 0.998600, train loss: 5.135714, valid precision: 0.871000, valid loss: 76.322454
epoch: 494, train precision: 0.997644, train loss: 5.304385, valid precision: 0.876600, valid loss: 76.424770
epoch: 495, train precision: 0.998622, train loss: 5.032530, valid precision: 0.875200, valid loss: 77.559703
epoch: 496, train precision: 0.998533, train loss: 5.058824, valid precision: 0.871600, valid loss: 77.916454
epoch: 497, train precision: 0.998356, train loss: 5.179024, valid precision: 0.871200, valid loss: 75.821934
epoch: 498, train precision: 0.998356, train loss: 5.169954, valid precision: 0.873800, valid loss: 77.728765
epoch: 499, train precision: 0.998422, train loss: 5.145083, valid precision: 0.873200, valid loss: 75.980400
epoch: 500, train precision: 0.998444, train loss: 5.162346, valid precision: 0.868000, valid loss: 76.308211
epoch: 501, train precision: 0.998111, train loss: 5.213573, valid precision: 0.875000, valid loss: 76.550723
epoch: 502, train precision: 0.998333, train loss: 5.161816, valid precision: 0.874600, valid loss: 77.460696
epoch: 503, train precision: 0.998022, train loss: 5.241034, valid precision: 0.873000, valid loss: 78.182064
epoch: 504, train precision: 0.998178, train loss: 5.180317, valid precision: 0.874800, valid loss: 76.920323
epoch: 505, train precision: 0.998778, train loss: 5.056458, valid precision: 0.871400, valid loss: 77.543234
epoch: 506, train precision: 0.997867, train loss: 5.268596, valid precision: 0.872200, valid loss: 78.981569
epoch: 507, train precision: 0.998200, train loss: 5.271200, valid precision: 0.870800, valid loss: 77.401151
epoch: 508, train precision: 0.998400, train loss: 5.157557, valid precision: 0.871800, valid loss: 78.794733
epoch: 509, train precision: 0.998467, train loss: 5.084851, valid precision: 0.873600, valid loss: 77.131950
epoch: 510, train precision: 0.998778, train loss: 5.008455, valid precision: 0.873400, valid loss: 77.736509
epoch: 511, train precision: 0.998333, train loss: 5.144973, valid precision: 0.872400, valid loss: 80.326431
epoch: 512, train precision: 0.998533, train loss: 5.095405, valid precision: 0.873200, valid loss: 78.616653
epoch: 513, train precision: 0.998533, train loss: 5.058480, valid precision: 0.873200, valid loss: 79.858468
epoch: 514, train precision: 0.998267, train loss: 5.184955, valid precision: 0.872600, valid loss: 78.909162
epoch: 515, train precision: 0.998400, train loss: 5.191509, valid precision: 0.873600, valid loss: 78.930842
epoch: 516, train precision: 0.998222, train loss: 5.154042, valid precision: 0.872200, valid loss: 79.155689
epoch: 517, train precision: 0.998244, train loss: 5.248832, valid precision: 0.871400, valid loss: 78.307911
epoch: 518, train precision: 0.998267, train loss: 5.153589, valid precision: 0.872000, valid loss: 81.572967
epoch: 519, train precision: 0.998511, train loss: 5.109275, valid precision: 0.875000, valid loss: 75.854025
epoch: 520, train precision: 0.998178, train loss: 5.305208, valid precision: 0.875000, valid loss: 78.413699
epoch: 521, train precision: 0.998667, train loss: 5.074020, valid precision: 0.871400, valid loss: 77.386359
epoch: 522, train precision: 0.998644, train loss: 5.040502, valid precision: 0.871000, valid loss: 77.916741
epoch: 523, train precision: 0.998556, train loss: 5.158982, valid precision: 0.875600, valid loss: 78.319377
epoch: 524, train precision: 0.998733, train loss: 5.117866, valid precision: 0.871600, valid loss: 77.515223
epoch: 525, train precision: 0.998489, train loss: 5.136706, valid precision: 0.872000, valid loss: 76.156440
epoch: 526, train precision: 0.998578, train loss: 5.153156, valid precision: 0.876000, valid loss: 75.514017
epoch: 527, train precision: 0.998089, train loss: 5.341695, valid precision: 0.875600, valid loss: 77.147885
epoch: 528, train precision: 0.998044, train loss: 5.272155, valid precision: 0.874800, valid loss: 77.251874
epoch: 529, train precision: 0.998578, train loss: 5.141166, valid precision: 0.869200, valid loss: 78.141280
epoch: 530, train precision: 0.998289, train loss: 5.253324, valid precision: 0.871800, valid loss: 76.552018
epoch: 531, train precision: 0.998867, train loss: 5.019524, valid precision: 0.873800, valid loss: 76.236892
epoch: 532, train precision: 0.998444, train loss: 5.182257, valid precision: 0.872600, valid loss: 76.548958
epoch: 533, train precision: 0.998867, train loss: 5.061993, valid precision: 0.874000, valid loss: 77.094709
epoch: 534, train precision: 0.998244, train loss: 5.201142, valid precision: 0.876600, valid loss: 75.478119
epoch: 535, train precision: 0.998822, train loss: 5.062691, valid precision: 0.876000, valid loss: 74.607194
epoch: 536, train precision: 0.998578, train loss: 5.074659, valid precision: 0.875000, valid loss: 74.779686
epoch: 537, train precision: 0.998689, train loss: 5.128001, valid precision: 0.875200, valid loss: 76.342905
epoch: 538, train precision: 0.998600, train loss: 5.121927, valid precision: 0.874200, valid loss: 78.697483
epoch: 539, train precision: 0.998311, train loss: 5.251196, valid precision: 0.873400, valid loss: 78.255599
epoch: 540, train precision: 0.998089, train loss: 5.262112, valid precision: 0.870800, valid loss: 80.460112
epoch: 541, train precision: 0.998667, train loss: 5.083397, valid precision: 0.873200, valid loss: 77.460906
epoch: 542, train precision: 0.998533, train loss: 5.184738, valid precision: 0.872400, valid loss: 77.805727
epoch: 543, train precision: 0.998533, train loss: 5.204982, valid precision: 0.875000, valid loss: 77.295820
epoch: 544, train precision: 0.998578, train loss: 5.202309, valid precision: 0.871800, valid loss: 77.909987
epoch: 545, train precision: 0.998533, train loss: 5.121652, valid precision: 0.873800, valid loss: 77.384568
epoch: 546, train precision: 0.998756, train loss: 5.059811, valid precision: 0.870400, valid loss: 79.924772
epoch: 547, train precision: 0.998178, train loss: 5.231017, valid precision: 0.870600, valid loss: 80.912702
epoch: 548, train precision: 0.998533, train loss: 5.241670, valid precision: 0.871800, valid loss: 79.358282
epoch: 549, train precision: 0.998444, train loss: 5.164264, valid precision: 0.878000, valid loss: 78.482276
epoch: 550, train precision: 0.998667, train loss: 5.117046, valid precision: 0.873800, valid loss: 77.089903
epoch: 551, train precision: 0.998133, train loss: 5.286545, valid precision: 0.873600, valid loss: 78.330329
epoch: 552, train precision: 0.998867, train loss: 5.040574, valid precision: 0.873400, valid loss: 77.862832
epoch: 553, train precision: 0.998422, train loss: 5.189135, valid precision: 0.873600, valid loss: 77.526465
epoch: 554, train precision: 0.998756, train loss: 5.111946, valid precision: 0.877800, valid loss: 75.835378
epoch: 555, train precision: 0.998556, train loss: 5.122198, valid precision: 0.876400, valid loss: 76.929761
epoch: 556, train precision: 0.998378, train loss: 5.192459, valid precision: 0.873600, valid loss: 79.905692
epoch: 557, train precision: 0.998222, train loss: 5.281598, valid precision: 0.876600, valid loss: 77.202907
epoch: 558, train precision: 0.998489, train loss: 5.186576, valid precision: 0.876000, valid loss: 78.312432
epoch: 559, train precision: 0.998644, train loss: 5.133936, valid precision: 0.873600, valid loss: 79.517100
epoch: 560, train precision: 0.998444, train loss: 5.204502, valid precision: 0.873000, valid loss: 80.856455
epoch: 561, train precision: 0.998711, train loss: 5.040320, valid precision: 0.875200, valid loss: 77.728947
epoch: 562, train precision: 0.998867, train loss: 5.095202, valid precision: 0.873400, valid loss: 80.601763
epoch: 563, train precision: 0.998267, train loss: 5.262671, valid precision: 0.871400, valid loss: 80.727318
epoch: 564, train precision: 0.998867, train loss: 5.082761, valid precision: 0.870000, valid loss: 77.921084
epoch: 565, train precision: 0.998778, train loss: 5.070264, valid precision: 0.875000, valid loss: 80.187786
epoch: 566, train precision: 0.998889, train loss: 5.094232, valid precision: 0.878200, valid loss: 78.408888
epoch: 567, train precision: 0.998489, train loss: 5.177343, valid precision: 0.869800, valid loss: 78.450229
epoch: 568, train precision: 0.998556, train loss: 5.226823, valid precision: 0.869200, valid loss: 79.664005
epoch: 569, train precision: 0.998733, train loss: 5.240421, valid precision: 0.871200, valid loss: 78.799803
epoch: 570, train precision: 0.998844, train loss: 5.079352, valid precision: 0.875000, valid loss: 76.669559
epoch: 571, train precision: 0.998578, train loss: 5.203802, valid precision: 0.874400, valid loss: 77.746410
epoch: 572, train precision: 0.998711, train loss: 5.145550, valid precision: 0.876400, valid loss: 78.872586
epoch: 573, train precision: 0.998378, train loss: 5.269424, valid precision: 0.872400, valid loss: 81.391244
epoch: 574, train precision: 0.998733, train loss: 5.153300, valid precision: 0.875200, valid loss: 77.743521
epoch: 575, train precision: 0.998311, train loss: 5.168010, valid precision: 0.874000, valid loss: 79.371453
epoch: 576, train precision: 0.998911, train loss: 5.054914, valid precision: 0.874400, valid loss: 79.042327
epoch: 577, train precision: 0.998867, train loss: 5.129714, valid precision: 0.874200, valid loss: 78.677178
epoch: 578, train precision: 0.998756, train loss: 5.129364, valid precision: 0.880200, valid loss: 77.151324
epoch: 579, train precision: 0.998578, train loss: 5.233415, valid precision: 0.874800, valid loss: 79.289455
epoch: 580, train precision: 0.999022, train loss: 5.084764, valid precision: 0.875400, valid loss: 76.932274
epoch: 581, train precision: 0.998400, train loss: 5.218379, valid precision: 0.877600, valid loss: 78.508615
epoch: 582, train precision: 0.998622, train loss: 5.189191, valid precision: 0.878400, valid loss: 78.281076
epoch: 583, train precision: 0.998644, train loss: 5.183929, valid precision: 0.878200, valid loss: 76.805274
epoch: 584, train precision: 0.998556, train loss: 5.235059, valid precision: 0.873600, valid loss: 80.680236
epoch: 585, train precision: 0.998511, train loss: 5.233120, valid precision: 0.874800, valid loss: 79.006199
epoch: 586, train precision: 0.998111, train loss: 5.350769, valid precision: 0.875200, valid loss: 78.156008
epoch: 587, train precision: 0.998778, train loss: 5.092833, valid precision: 0.874600, valid loss: 78.364753
epoch: 588, train precision: 0.998533, train loss: 5.171972, valid precision: 0.875000, valid loss: 77.695641
epoch: 589, train precision: 0.998533, train loss: 5.181513, valid precision: 0.876200, valid loss: 78.373441
epoch: 590, train precision: 0.998956, train loss: 5.133270, valid precision: 0.873800, valid loss: 78.643677
epoch: 591, train precision: 0.998222, train loss: 5.305798, valid precision: 0.875600, valid loss: 78.183714
epoch: 592, train precision: 0.998844, train loss: 5.167745, valid precision: 0.871600, valid loss: 79.155646
epoch: 593, train precision: 0.998089, train loss: 5.364863, valid precision: 0.875600, valid loss: 78.261400
epoch: 594, train precision: 0.998733, train loss: 5.195876, valid precision: 0.878600, valid loss: 78.222012
epoch: 595, train precision: 0.998400, train loss: 5.259435, valid precision: 0.874400, valid loss: 79.355874
epoch: 596, train precision: 0.998044, train loss: 5.363689, valid precision: 0.875000, valid loss: 78.635191
epoch: 597, train precision: 0.999378, train loss: 5.049789, valid precision: 0.878600, valid loss: 78.496839
epoch: 598, train precision: 0.998822, train loss: 5.152379, valid precision: 0.880000, valid loss: 76.583008
epoch: 599, train precision: 0.998622, train loss: 5.190574, valid precision: 0.871400, valid loss: 78.541493
epoch: 600, train precision: 0.998800, train loss: 5.144674, valid precision: 0.873800, valid loss: 80.631496
epoch: 601, train precision: 0.998711, train loss: 5.214475, valid precision: 0.871600, valid loss: 80.415098
epoch: 602, train precision: 0.998711, train loss: 5.174191, valid precision: 0.874800, valid loss: 79.166419
epoch: 603, train precision: 0.998956, train loss: 5.097325, valid precision: 0.875200, valid loss: 78.355761
epoch: 604, train precision: 0.998667, train loss: 5.147898, valid precision: 0.874200, valid loss: 79.552346
epoch: 605, train precision: 0.998111, train loss: 5.401818, valid precision: 0.870600, valid loss: 80.046838
epoch: 606, train precision: 0.998711, train loss: 5.176072, valid precision: 0.869800, valid loss: 79.037272
epoch: 607, train precision: 0.998800, train loss: 5.149726, valid precision: 0.871600, valid loss: 78.475215
epoch: 608, train precision: 0.998644, train loss: 5.211207, valid precision: 0.872000, valid loss: 78.751525
epoch: 609, train precision: 0.998689, train loss: 5.184558, valid precision: 0.875000, valid loss: 77.911225
epoch: 610, train precision: 0.999067, train loss: 5.133922, valid precision: 0.882400, valid loss: 77.477750
epoch: 611, train precision: 0.998756, train loss: 5.144125, valid precision: 0.873800, valid loss: 78.571950
epoch: 612, train precision: 0.998867, train loss: 5.153216, valid precision: 0.880000, valid loss: 79.473069
epoch: 613, train precision: 0.998622, train loss: 5.227584, valid precision: 0.873400, valid loss: 80.845241
epoch: 614, train precision: 0.998333, train loss: 5.303105, valid precision: 0.875400, valid loss: 77.137649
epoch: 615, train precision: 0.998867, train loss: 5.203962, valid precision: 0.874000, valid loss: 77.946252
epoch: 616, train precision: 0.998711, train loss: 5.220959, valid precision: 0.874200, valid loss: 78.205830
epoch: 617, train precision: 0.998622, train loss: 5.287323, valid precision: 0.875000, valid loss: 79.437418
epoch: 618, train precision: 0.998333, train loss: 5.342244, valid precision: 0.874000, valid loss: 78.597634
epoch: 619, train precision: 0.999133, train loss: 5.147220, valid precision: 0.875000, valid loss: 77.920772
epoch: 620, train precision: 0.998467, train loss: 5.333099, valid precision: 0.869200, valid loss: 82.452831
epoch: 621, train precision: 0.998911, train loss: 5.224612, valid precision: 0.871200, valid loss: 81.982138
epoch: 622, train precision: 0.998889, train loss: 5.193457, valid precision: 0.874400, valid loss: 82.093159
epoch: 623, train precision: 0.998622, train loss: 5.232018, valid precision: 0.871200, valid loss: 81.387912
epoch: 624, train precision: 0.999156, train loss: 5.082524, valid precision: 0.869800, valid loss: 81.377304
epoch: 625, train precision: 0.998822, train loss: 5.164940, valid precision: 0.873200, valid loss: 80.777446
epoch: 626, train precision: 0.999067, train loss: 5.155895, valid precision: 0.873600, valid loss: 79.493823
epoch: 627, train precision: 0.998978, train loss: 5.091321, valid precision: 0.872600, valid loss: 78.957429
epoch: 628, train precision: 0.998556, train loss: 5.297008, valid precision: 0.873400, valid loss: 79.124781
epoch: 629, train precision: 0.999067, train loss: 5.112067, valid precision: 0.875200, valid loss: 80.426912
epoch: 630, train precision: 0.998667, train loss: 5.237371, valid precision: 0.872800, valid loss: 80.589007
epoch: 631, train precision: 0.998800, train loss: 5.248360, valid precision: 0.875400, valid loss: 78.276178
epoch: 632, train precision: 0.998333, train loss: 5.309120, valid precision: 0.869400, valid loss: 81.845146
epoch: 633, train precision: 0.998867, train loss: 5.163309, valid precision: 0.873800, valid loss: 78.925844
epoch: 634, train precision: 0.998378, train loss: 5.309187, valid precision: 0.873800, valid loss: 81.570646
epoch: 635, train precision: 0.998800, train loss: 5.188598, valid precision: 0.872400, valid loss: 80.822679
epoch: 636, train precision: 0.998689, train loss: 5.222424, valid precision: 0.874200, valid loss: 81.927810
epoch: 637, train precision: 0.998911, train loss: 5.265523, valid precision: 0.874600, valid loss: 82.173481
epoch: 638, train precision: 0.998667, train loss: 5.252628, valid precision: 0.874400, valid loss: 78.286261
epoch: 639, train precision: 0.998444, train loss: 5.320410, valid precision: 0.878000, valid loss: 78.271184
epoch: 640, train precision: 0.998556, train loss: 5.241841, valid precision: 0.875200, valid loss: 77.650585
epoch: 641, train precision: 0.998867, train loss: 5.205442, valid precision: 0.876000, valid loss: 78.076606
epoch: 642, train precision: 0.998867, train loss: 5.198086, valid precision: 0.878600, valid loss: 78.695945
epoch: 643, train precision: 0.998600, train loss: 5.335930, valid precision: 0.874400, valid loss: 80.837520
epoch: 644, train precision: 0.999022, train loss: 5.136406, valid precision: 0.872600, valid loss: 78.593952
epoch: 645, train precision: 0.998689, train loss: 5.173648, valid precision: 0.877800, valid loss: 80.390029
epoch: 646, train precision: 0.999044, train loss: 5.143035, valid precision: 0.877400, valid loss: 77.092137
epoch: 647, train precision: 0.998467, train loss: 5.358184, valid precision: 0.877200, valid loss: 78.286213
epoch: 648, train precision: 0.999156, train loss: 5.112843, valid precision: 0.875200, valid loss: 78.904342
epoch: 649, train precision: 0.998778, train loss: 5.241823, valid precision: 0.875400, valid loss: 79.571506
epoch: 650, train precision: 0.998556, train loss: 5.263945, valid precision: 0.879600, valid loss: 79.406094
epoch: 651, train precision: 0.998578, train loss: 5.259765, valid precision: 0.874400, valid loss: 80.591705
epoch: 652, train precision: 0.998778, train loss: 5.244870, valid precision: 0.872800, valid loss: 81.289457
epoch: 653, train precision: 0.999022, train loss: 5.160456, valid precision: 0.875400, valid loss: 79.739896
epoch: 654, train precision: 0.998689, train loss: 5.265976, valid precision: 0.875200, valid loss: 81.997220
epoch: 655, train precision: 0.998889, train loss: 5.223566, valid precision: 0.874400, valid loss: 81.424185
epoch: 656, train precision: 0.998911, train loss: 5.187106, valid precision: 0.875800, valid loss: 80.362088
epoch: 657, train precision: 0.998489, train loss: 5.409338, valid precision: 0.873600, valid loss: 81.653425
epoch: 658, train precision: 0.999178, train loss: 5.177755, valid precision: 0.876600, valid loss: 78.913438
epoch: 659, train precision: 0.998622, train loss: 5.339798, valid precision: 0.876200, valid loss: 78.602947
epoch: 660, train precision: 0.998511, train loss: 5.366589, valid precision: 0.872400, valid loss: 81.467107
epoch: 661, train precision: 0.998956, train loss: 5.195466, valid precision: 0.875600, valid loss: 79.940739
epoch: 662, train precision: 0.998333, train loss: 5.349008, valid precision: 0.873400, valid loss: 81.215330
epoch: 663, train precision: 0.999111, train loss: 5.173184, valid precision: 0.871600, valid loss: 79.917606
epoch: 664, train precision: 0.998267, train loss: 5.419250, valid precision: 0.870000, valid loss: 83.093909
epoch: 665, train precision: 0.998867, train loss: 5.234017, valid precision: 0.873200, valid loss: 80.442951
epoch: 666, train precision: 0.999000, train loss: 5.177622, valid precision: 0.873000, valid loss: 81.559929
epoch: 667, train precision: 0.998622, train loss: 5.321616, valid precision: 0.877400, valid loss: 80.400632
epoch: 668, train precision: 0.999000, train loss: 5.244099, valid precision: 0.875800, valid loss: 78.520605
epoch: 669, train precision: 0.998489, train loss: 5.341292, valid precision: 0.875200, valid loss: 79.967202
epoch: 670, train precision: 0.999044, train loss: 5.182430, valid precision: 0.878400, valid loss: 77.900808
epoch: 671, train precision: 0.998556, train loss: 5.291659, valid precision: 0.875000, valid loss: 81.237469
epoch: 672, train precision: 0.999156, train loss: 5.173330, valid precision: 0.874000, valid loss: 78.448305
epoch: 673, train precision: 0.998578, train loss: 5.331840, valid precision: 0.874000, valid loss: 82.004732
epoch: 674, train precision: 0.999022, train loss: 5.208274, valid precision: 0.872200, valid loss: 80.276565
epoch: 675, train precision: 0.998733, train loss: 5.234334, valid precision: 0.876200, valid loss: 78.484934
epoch: 676, train precision: 0.999000, train loss: 5.211412, valid precision: 0.872400, valid loss: 81.258640
epoch: 677, train precision: 0.998867, train loss: 5.243125, valid precision: 0.877000, valid loss: 79.234012
epoch: 678, train precision: 0.999200, train loss: 5.187531, valid precision: 0.873200, valid loss: 83.482181
epoch: 679, train precision: 0.999022, train loss: 5.251528, valid precision: 0.875200, valid loss: 81.374924
epoch: 680, train precision: 0.998778, train loss: 5.308580, valid precision: 0.872600, valid loss: 81.817380
epoch: 681, train precision: 0.998844, train loss: 5.242870, valid precision: 0.869200, valid loss: 80.684319
epoch: 682, train precision: 0.998800, train loss: 5.229692, valid precision: 0.870800, valid loss: 80.654195
epoch: 683, train precision: 0.998933, train loss: 5.233935, valid precision: 0.868200, valid loss: 82.474990
epoch: 684, train precision: 0.998978, train loss: 5.247694, valid precision: 0.872000, valid loss: 80.906161
epoch: 685, train precision: 0.998867, train loss: 5.243615, valid precision: 0.872200, valid loss: 79.815587
epoch: 686, train precision: 0.999200, train loss: 5.155076, valid precision: 0.876600, valid loss: 79.981262
epoch: 687, train precision: 0.998911, train loss: 5.231466, valid precision: 0.871800, valid loss: 82.379240
epoch: 688, train precision: 0.998756, train loss: 5.270396, valid precision: 0.871800, valid loss: 82.524403
epoch: 689, train precision: 0.999044, train loss: 5.163839, valid precision: 0.874400, valid loss: 80.778134
epoch: 690, train precision: 0.998867, train loss: 5.193315, valid precision: 0.874400, valid loss: 82.456394
epoch: 691, train precision: 0.998822, train loss: 5.232558, valid precision: 0.869800, valid loss: 84.488357
epoch: 692, train precision: 0.999044, train loss: 5.175885, valid precision: 0.871000, valid loss: 83.396919
epoch: 693, train precision: 0.999200, train loss: 5.121882, valid precision: 0.875400, valid loss: 81.165022
epoch: 694, train precision: 0.998667, train loss: 5.356991, valid precision: 0.873200, valid loss: 82.928058
epoch: 695, train precision: 0.998889, train loss: 5.279646, valid precision: 0.874600, valid loss: 80.100207
epoch: 696, train precision: 0.998978, train loss: 5.206752, valid precision: 0.872000, valid loss: 81.711145
epoch: 697, train precision: 0.999044, train loss: 5.210635, valid precision: 0.875600, valid loss: 81.422581
epoch: 698, train precision: 0.999022, train loss: 5.211125, valid precision: 0.877000, valid loss: 81.163461
epoch: 699, train precision: 0.999378, train loss: 5.186176, valid precision: 0.872200, valid loss: 81.651457
epoch: 700, train precision: 0.998911, train loss: 5.261241, valid precision: 0.872600, valid loss: 82.223046
epoch: 701, train precision: 0.999044, train loss: 5.212743, valid precision: 0.872800, valid loss: 82.071513
epoch: 702, train precision: 0.999089, train loss: 5.162462, valid precision: 0.870200, valid loss: 84.207788
epoch: 703, train precision: 0.999133, train loss: 5.121410, valid precision: 0.871000, valid loss: 83.053678
epoch: 704, train precision: 0.999000, train loss: 5.253028, valid precision: 0.870400, valid loss: 83.443233
epoch: 705, train precision: 0.998956, train loss: 5.217242, valid precision: 0.872200, valid loss: 81.399752
epoch: 706, train precision: 0.999000, train loss: 5.216651, valid precision: 0.873400, valid loss: 81.563143
epoch: 707, train precision: 0.998956, train loss: 5.240110, valid precision: 0.872200, valid loss: 81.121365
epoch: 708, train precision: 0.998689, train loss: 5.302043, valid precision: 0.871600, valid loss: 82.537428
epoch: 709, train precision: 0.999133, train loss: 5.226168, valid precision: 0.871200, valid loss: 83.157215
epoch: 710, train precision: 0.999000, train loss: 5.269501, valid precision: 0.873000, valid loss: 82.393197
epoch: 711, train precision: 0.998956, train loss: 5.315225, valid precision: 0.873800, valid loss: 85.295300
epoch: 712, train precision: 0.998644, train loss: 5.346834, valid precision: 0.872400, valid loss: 84.938311
epoch: 713, train precision: 0.999133, train loss: 5.183284, valid precision: 0.878000, valid loss: 81.775743
epoch: 714, train precision: 0.998533, train loss: 5.378274, valid precision: 0.875400, valid loss: 84.934445
epoch: 715, train precision: 0.998956, train loss: 5.289985, valid precision: 0.871800, valid loss: 83.777731
epoch: 716, train precision: 0.999178, train loss: 5.217074, valid precision: 0.877200, valid loss: 82.472392
epoch: 717, train precision: 0.999089, train loss: 5.211141, valid precision: 0.875200, valid loss: 82.702751
epoch: 718, train precision: 0.999178, train loss: 5.223615, valid precision: 0.873600, valid loss: 83.325857
epoch: 719, train precision: 0.998844, train loss: 5.290638, valid precision: 0.873200, valid loss: 83.345758
epoch: 720, train precision: 0.998911, train loss: 5.237079, valid precision: 0.876000, valid loss: 82.197953
epoch: 721, train precision: 0.998756, train loss: 5.329198, valid precision: 0.876200, valid loss: 83.537956
epoch: 722, train precision: 0.998822, train loss: 5.349517, valid precision: 0.879000, valid loss: 82.676488
epoch: 723, train precision: 0.999222, train loss: 5.236162, valid precision: 0.878000, valid loss: 83.328055
epoch: 724, train precision: 0.998978, train loss: 5.294290, valid precision: 0.877200, valid loss: 83.154907
epoch: 725, train precision: 0.999089, train loss: 5.246812, valid precision: 0.879600, valid loss: 83.338384
epoch: 726, train precision: 0.998622, train loss: 5.392699, valid precision: 0.875200, valid loss: 83.864397
epoch: 727, train precision: 0.999244, train loss: 5.241290, valid precision: 0.872000, valid loss: 82.903570
epoch: 728, train precision: 0.999244, train loss: 5.181003, valid precision: 0.876800, valid loss: 82.346938
epoch: 729, train precision: 0.998978, train loss: 5.286922, valid precision: 0.876400, valid loss: 82.202424
epoch: 730, train precision: 0.999089, train loss: 5.225331, valid precision: 0.873000, valid loss: 84.733049
epoch: 731, train precision: 0.998511, train loss: 5.347610, valid precision: 0.871200, valid loss: 85.117776
epoch: 732, train precision: 0.998956, train loss: 5.336013, valid precision: 0.872400, valid loss: 84.027035
epoch: 733, train precision: 0.998711, train loss: 5.387756, valid precision: 0.872200, valid loss: 86.871030
epoch: 734, train precision: 0.998889, train loss: 5.278090, valid precision: 0.872400, valid loss: 84.518151
epoch: 735, train precision: 0.998933, train loss: 5.247737, valid precision: 0.872600, valid loss: 83.844956
epoch: 736, train precision: 0.999111, train loss: 5.285202, valid precision: 0.871000, valid loss: 83.420324
epoch: 737, train precision: 0.998844, train loss: 5.281149, valid precision: 0.873800, valid loss: 84.121403
epoch: 738, train precision: 0.998933, train loss: 5.274739, valid precision: 0.874000, valid loss: 84.374393
epoch: 739, train precision: 0.999022, train loss: 5.321699, valid precision: 0.873600, valid loss: 85.465710
epoch: 740, train precision: 0.998911, train loss: 5.267447, valid precision: 0.874400, valid loss: 85.344929
epoch: 741, train precision: 0.998622, train loss: 5.345123, valid precision: 0.871200, valid loss: 86.887781
epoch: 742, train precision: 0.999222, train loss: 5.225982, valid precision: 0.872000, valid loss: 85.174284
epoch: 743, train precision: 0.999222, train loss: 5.206353, valid precision: 0.875200, valid loss: 83.651256
epoch: 744, train precision: 0.999000, train loss: 5.274552, valid precision: 0.872400, valid loss: 85.657978
epoch: 745, train precision: 0.998556, train loss: 5.382618, valid precision: 0.872000, valid loss: 85.055716
epoch: 746, train precision: 0.999022, train loss: 5.278353, valid precision: 0.869000, valid loss: 86.045025
epoch: 747, train precision: 0.999156, train loss: 5.268866, valid precision: 0.873400, valid loss: 83.740571
epoch: 748, train precision: 0.998867, train loss: 5.303107, valid precision: 0.873400, valid loss: 85.172311
epoch: 749, train precision: 0.998889, train loss: 5.328066, valid precision: 0.874600, valid loss: 84.588048
epoch: 750, train precision: 0.999067, train loss: 5.244906, valid precision: 0.874600, valid loss: 83.434714
epoch: 751, train precision: 0.999556, train loss: 5.163454, valid precision: 0.871000, valid loss: 84.415003
epoch: 752, train precision: 0.999156, train loss: 5.227732, valid precision: 0.874600, valid loss: 82.227192
epoch: 753, train precision: 0.998622, train loss: 5.448940, valid precision: 0.871200, valid loss: 84.776261
epoch: 754, train precision: 0.998511, train loss: 5.372024, valid precision: 0.873200, valid loss: 85.218175
epoch: 755, train precision: 0.998889, train loss: 5.324357, valid precision: 0.871800, valid loss: 83.693260
epoch: 756, train precision: 0.998978, train loss: 5.304984, valid precision: 0.874600, valid loss: 83.362614
epoch: 757, train precision: 0.998978, train loss: 5.290753, valid precision: 0.873200, valid loss: 83.987673
epoch: 758, train precision: 0.999267, train loss: 5.256758, valid precision: 0.871000, valid loss: 85.732406
epoch: 759, train precision: 0.999044, train loss: 5.242408, valid precision: 0.871800, valid loss: 85.005294
epoch: 760, train precision: 0.999111, train loss: 5.241563, valid precision: 0.871400, valid loss: 84.428189
epoch: 761, train precision: 0.998956, train loss: 5.279412, valid precision: 0.869800, valid loss: 84.686895
epoch: 762, train precision: 0.999044, train loss: 5.268054, valid precision: 0.868400, valid loss: 85.454573
epoch: 763, train precision: 0.999156, train loss: 5.250861, valid precision: 0.870800, valid loss: 86.573808
epoch: 764, train precision: 0.998822, train loss: 5.343890, valid precision: 0.870200, valid loss: 86.108987
epoch: 765, train precision: 0.999178, train loss: 5.239019, valid precision: 0.875200, valid loss: 84.593502
epoch: 766, train precision: 0.999178, train loss: 5.273167, valid precision: 0.871800, valid loss: 83.215243
epoch: 767, train precision: 0.999022, train loss: 5.299466, valid precision: 0.872200, valid loss: 85.737021
epoch: 768, train precision: 0.998778, train loss: 5.415760, valid precision: 0.868600, valid loss: 83.698419
epoch: 769, train precision: 0.998844, train loss: 5.365745, valid precision: 0.870200, valid loss: 84.358442
epoch: 770, train precision: 0.999156, train loss: 5.329627, valid precision: 0.871200, valid loss: 84.900665
epoch: 771, train precision: 0.999267, train loss: 5.259215, valid precision: 0.875200, valid loss: 82.330075
epoch: 772, train precision: 0.999267, train loss: 5.177488, valid precision: 0.874000, valid loss: 82.479954
epoch: 773, train precision: 0.999400, train loss: 5.177542, valid precision: 0.875600, valid loss: 82.196421
epoch: 774, train precision: 0.999222, train loss: 5.288739, valid precision: 0.873400, valid loss: 82.027904
epoch: 775, train precision: 0.999222, train loss: 5.267350, valid precision: 0.876800, valid loss: 81.294049
epoch: 776, train precision: 0.999044, train loss: 5.311771, valid precision: 0.873200, valid loss: 82.903075
epoch: 777, train precision: 0.999156, train loss: 5.315175, valid precision: 0.870000, valid loss: 83.806571
epoch: 778, train precision: 0.998978, train loss: 5.312783, valid precision: 0.875200, valid loss: 84.542847
epoch: 779, train precision: 0.998978, train loss: 5.308968, valid precision: 0.871200, valid loss: 83.172086
epoch: 780, train precision: 0.999156, train loss: 5.267770, valid precision: 0.875600, valid loss: 84.646578
epoch: 781, train precision: 0.999200, train loss: 5.227080, valid precision: 0.877400, valid loss: 84.358080
epoch: 782, train precision: 0.998956, train loss: 5.283031, valid precision: 0.876200, valid loss: 86.880266
epoch: 783, train precision: 0.998956, train loss: 5.285523, valid precision: 0.875600, valid loss: 86.831231
epoch: 784, train precision: 0.998778, train loss: 5.390589, valid precision: 0.874400, valid loss: 83.941134
epoch: 785, train precision: 0.998933, train loss: 5.285519, valid precision: 0.876600, valid loss: 83.465654
epoch: 786, train precision: 0.999044, train loss: 5.290973, valid precision: 0.874800, valid loss: 84.070111
epoch: 787, train precision: 0.999289, train loss: 5.260793, valid precision: 0.875400, valid loss: 83.809446
epoch: 788, train precision: 0.999133, train loss: 5.254340, valid precision: 0.875000, valid loss: 83.486323
epoch: 789, train precision: 0.999244, train loss: 5.293602, valid precision: 0.871000, valid loss: 83.675807
epoch: 790, train precision: 0.998933, train loss: 5.320351, valid precision: 0.873000, valid loss: 84.859808
epoch: 791, train precision: 0.999222, train loss: 5.255705, valid precision: 0.876800, valid loss: 82.371810
epoch: 792, train precision: 0.998956, train loss: 5.365655, valid precision: 0.878600, valid loss: 82.312462
epoch: 793, train precision: 0.999489, train loss: 5.176340, valid precision: 0.871400, valid loss: 83.893933
epoch: 794, train precision: 0.998844, train loss: 5.347686, valid precision: 0.871800, valid loss: 82.749191
epoch: 795, train precision: 0.999178, train loss: 5.296354, valid precision: 0.872800, valid loss: 87.143400
epoch: 796, train precision: 0.999311, train loss: 5.247515, valid precision: 0.870000, valid loss: 85.542080
epoch: 797, train precision: 0.998978, train loss: 5.293626, valid precision: 0.872600, valid loss: 85.087121
epoch: 798, train precision: 0.998911, train loss: 5.357307, valid precision: 0.874800, valid loss: 86.428064
epoch: 799, train precision: 0.999111, train loss: 5.329378, valid precision: 0.872400, valid loss: 84.443778
epoch: 800, train precision: 0.999200, train loss: 5.253424, valid precision: 0.874000, valid loss: 85.056665
epoch: 801, train precision: 0.998844, train loss: 5.436606, valid precision: 0.874600, valid loss: 86.204941
epoch: 802, train precision: 0.999267, train loss: 5.240442, valid precision: 0.874800, valid loss: 87.242873
epoch: 803, train precision: 0.999200, train loss: 5.239565, valid precision: 0.876800, valid loss: 84.512306
epoch: 804, train precision: 0.998822, train loss: 5.382897, valid precision: 0.875200, valid loss: 86.022207
epoch: 805, train precision: 0.999089, train loss: 5.347299, valid precision: 0.875200, valid loss: 84.521865
epoch: 806, train precision: 0.998889, train loss: 5.395970, valid precision: 0.874600, valid loss: 85.453782
epoch: 807, train precision: 0.999000, train loss: 5.328994, valid precision: 0.875400, valid loss: 84.077597
epoch: 808, train precision: 0.999200, train loss: 5.246384, valid precision: 0.872200, valid loss: 86.834220
epoch: 809, train precision: 0.999111, train loss: 5.278434, valid precision: 0.875800, valid loss: 85.832805
epoch: 810, train precision: 0.998822, train loss: 5.376351, valid precision: 0.873000, valid loss: 86.638353
epoch: 811, train precision: 0.999178, train loss: 5.294337, valid precision: 0.874200, valid loss: 84.808566
epoch: 812, train precision: 0.999244, train loss: 5.294948, valid precision: 0.873800, valid loss: 85.840969
epoch: 813, train precision: 0.998844, train loss: 5.416119, valid precision: 0.873000, valid loss: 86.231374
epoch: 814, train precision: 0.999333, train loss: 5.261656, valid precision: 0.875400, valid loss: 84.468086
epoch: 815, train precision: 0.999400, train loss: 5.287152, valid precision: 0.874200, valid loss: 85.666586
epoch: 816, train precision: 0.998933, train loss: 5.406411, valid precision: 0.877800, valid loss: 86.763923
epoch: 817, train precision: 0.998822, train loss: 5.456402, valid precision: 0.871800, valid loss: 87.859113
epoch: 818, train precision: 0.998733, train loss: 5.414034, valid precision: 0.878600, valid loss: 87.259363
epoch: 819, train precision: 0.999000, train loss: 5.327454, valid precision: 0.872600, valid loss: 88.904633
epoch: 820, train precision: 0.999289, train loss: 5.273764, valid precision: 0.874400, valid loss: 85.033305
epoch: 821, train precision: 0.999311, train loss: 5.284168, valid precision: 0.874600, valid loss: 86.396958
epoch: 822, train precision: 0.999089, train loss: 5.305882, valid precision: 0.872000, valid loss: 87.247237
epoch: 823, train precision: 0.999067, train loss: 5.368775, valid precision: 0.872800, valid loss: 87.043880
epoch: 824, train precision: 0.998867, train loss: 5.395273, valid precision: 0.875600, valid loss: 85.386794
epoch: 825, train precision: 0.999244, train loss: 5.238452, valid precision: 0.873200, valid loss: 85.354846
epoch: 826, train precision: 0.999289, train loss: 5.224975, valid precision: 0.873200, valid loss: 86.354501
epoch: 827, train precision: 0.998867, train loss: 5.321115, valid precision: 0.876600, valid loss: 85.252596
epoch: 828, train precision: 0.999156, train loss: 5.272321, valid precision: 0.876600, valid loss: 83.757625
epoch: 829, train precision: 0.999111, train loss: 5.324467, valid precision: 0.875200, valid loss: 82.840362
epoch: 830, train precision: 0.999000, train loss: 5.415000, valid precision: 0.874800, valid loss: 83.719957
epoch: 831, train precision: 0.999222, train loss: 5.325281, valid precision: 0.875800, valid loss: 84.490915
epoch: 832, train precision: 0.999244, train loss: 5.272322, valid precision: 0.876200, valid loss: 83.648370
epoch: 833, train precision: 0.999067, train loss: 5.354489, valid precision: 0.872800, valid loss: 85.827566
epoch: 834, train precision: 0.998844, train loss: 5.401482, valid precision: 0.875000, valid loss: 83.208358
epoch: 835, train precision: 0.999356, train loss: 5.253321, valid precision: 0.874000, valid loss: 85.161902
epoch: 836, train precision: 0.998978, train loss: 5.356211, valid precision: 0.875600, valid loss: 82.810448
epoch: 837, train precision: 0.999222, train loss: 5.273452, valid precision: 0.879600, valid loss: 82.776500
epoch: 838, train precision: 0.999244, train loss: 5.315134, valid precision: 0.877000, valid loss: 83.146294
epoch: 839, train precision: 0.999267, train loss: 5.279477, valid precision: 0.880000, valid loss: 81.899788
epoch: 840, train precision: 0.999000, train loss: 5.374485, valid precision: 0.873200, valid loss: 82.922223
epoch: 841, train precision: 0.999244, train loss: 5.318867, valid precision: 0.872600, valid loss: 85.230274
epoch: 842, train precision: 0.999000, train loss: 5.393543, valid precision: 0.874000, valid loss: 84.545830
epoch: 843, train precision: 0.999089, train loss: 5.345440, valid precision: 0.874800, valid loss: 84.539240
epoch: 844, train precision: 0.998978, train loss: 5.330251, valid precision: 0.879800, valid loss: 83.548881
epoch: 845, train precision: 0.999133, train loss: 5.306444, valid precision: 0.874800, valid loss: 84.652281
epoch: 846, train precision: 0.999222, train loss: 5.307809, valid precision: 0.876000, valid loss: 82.320607
epoch: 847, train precision: 0.998800, train loss: 5.507648, valid precision: 0.877000, valid loss: 84.165981
epoch: 848, train precision: 0.999178, train loss: 5.310428, valid precision: 0.877400, valid loss: 83.563314
epoch: 849, train precision: 0.999156, train loss: 5.380660, valid precision: 0.875600, valid loss: 82.066168
epoch: 850, train precision: 0.998800, train loss: 5.390125, valid precision: 0.871800, valid loss: 83.968058
epoch: 851, train precision: 0.999156, train loss: 5.386518, valid precision: 0.873400, valid loss: 83.483633
epoch: 852, train precision: 0.999000, train loss: 5.422196, valid precision: 0.877400, valid loss: 82.888290
epoch: 853, train precision: 0.998978, train loss: 5.335436, valid precision: 0.878200, valid loss: 85.287848
epoch: 854, train precision: 0.998933, train loss: 5.378128, valid precision: 0.876600, valid loss: 84.181283
epoch: 855, train precision: 0.999267, train loss: 5.327018, valid precision: 0.875200, valid loss: 84.393480
epoch: 856, train precision: 0.998933, train loss: 5.454647, valid precision: 0.874800, valid loss: 84.847348
epoch: 857, train precision: 0.998800, train loss: 5.455217, valid precision: 0.879000, valid loss: 82.888971
epoch: 858, train precision: 0.998933, train loss: 5.402639, valid precision: 0.874000, valid loss: 85.373051
epoch: 859, train precision: 0.998911, train loss: 5.416368, valid precision: 0.876200, valid loss: 86.554524
epoch: 860, train precision: 0.999156, train loss: 5.373803, valid precision: 0.876000, valid loss: 85.607645
epoch: 861, train precision: 0.999267, train loss: 5.362976, valid precision: 0.878400, valid loss: 85.092562
epoch: 862, train precision: 0.999178, train loss: 5.309779, valid precision: 0.874600, valid loss: 86.328019
epoch: 863, train precision: 0.999267, train loss: 5.336126, valid precision: 0.878000, valid loss: 84.545688
epoch: 864, train precision: 0.999178, train loss: 5.337260, valid precision: 0.873000, valid loss: 85.942198
epoch: 865, train precision: 0.999311, train loss: 5.328824, valid precision: 0.875400, valid loss: 85.725929
epoch: 866, train precision: 0.998844, train loss: 5.449242, valid precision: 0.875600, valid loss: 84.667671
epoch: 867, train precision: 0.999311, train loss: 5.331551, valid precision: 0.875800, valid loss: 85.575058
epoch: 868, train precision: 0.999267, train loss: 5.289100, valid precision: 0.875200, valid loss: 84.726948
epoch: 869, train precision: 0.999200, train loss: 5.338004, valid precision: 0.874600, valid loss: 85.450870
epoch: 870, train precision: 0.999289, train loss: 5.350442, valid precision: 0.874200, valid loss: 85.654972
epoch: 871, train precision: 0.999067, train loss: 5.373762, valid precision: 0.868400, valid loss: 86.588641
epoch: 872, train precision: 0.999089, train loss: 5.391820, valid precision: 0.876400, valid loss: 84.442298
epoch: 873, train precision: 0.999156, train loss: 5.359593, valid precision: 0.875400, valid loss: 82.046198
epoch: 874, train precision: 0.999422, train loss: 5.294083, valid precision: 0.878200, valid loss: 82.251870
epoch: 875, train precision: 0.998667, train loss: 5.513799, valid precision: 0.873200, valid loss: 85.301084
epoch: 876, train precision: 0.999356, train loss: 5.306079, valid precision: 0.877200, valid loss: 83.860535
epoch: 877, train precision: 0.999133, train loss: 5.347076, valid precision: 0.873400, valid loss: 84.250174
epoch: 878, train precision: 0.999222, train loss: 5.310105, valid precision: 0.873600, valid loss: 86.025006
epoch: 879, train precision: 0.999022, train loss: 5.439237, valid precision: 0.872400, valid loss: 86.801997
epoch: 880, train precision: 0.999333, train loss: 5.267681, valid precision: 0.874000, valid loss: 86.133467
epoch: 881, train precision: 0.999333, train loss: 5.302746, valid precision: 0.876000, valid loss: 85.517575
epoch: 882, train precision: 0.999356, train loss: 5.305578, valid precision: 0.876000, valid loss: 83.886167
epoch: 883, train precision: 0.999467, train loss: 5.277541, valid precision: 0.877200, valid loss: 83.090163
epoch: 884, train precision: 0.999000, train loss: 5.490932, valid precision: 0.874200, valid loss: 86.313112
epoch: 885, train precision: 0.999022, train loss: 5.412827, valid precision: 0.875200, valid loss: 80.915521
epoch: 886, train precision: 0.999289, train loss: 5.331521, valid precision: 0.872200, valid loss: 84.242194
epoch: 887, train precision: 0.999156, train loss: 5.386716, valid precision: 0.873200, valid loss: 86.519269
epoch: 888, train precision: 0.999156, train loss: 5.325761, valid precision: 0.876000, valid loss: 86.958122
epoch: 889, train precision: 0.999289, train loss: 5.319323, valid precision: 0.876000, valid loss: 86.260039
epoch: 890, train precision: 0.999222, train loss: 5.401838, valid precision: 0.873600, valid loss: 86.597613
epoch: 891, train precision: 0.999311, train loss: 5.337632, valid precision: 0.872600, valid loss: 87.001912
epoch: 892, train precision: 0.999200, train loss: 5.366869, valid precision: 0.870800, valid loss: 89.529462
epoch: 893, train precision: 0.999178, train loss: 5.335701, valid precision: 0.872000, valid loss: 86.898032
epoch: 894, train precision: 0.999489, train loss: 5.256128, valid precision: 0.876000, valid loss: 85.485878
epoch: 895, train precision: 0.998889, train loss: 5.462185, valid precision: 0.873600, valid loss: 87.064315
epoch: 896, train precision: 0.999267, train loss: 5.342101, valid precision: 0.873400, valid loss: 87.779908
epoch: 897, train precision: 0.999444, train loss: 5.290782, valid precision: 0.871400, valid loss: 86.046486
epoch: 898, train precision: 0.999133, train loss: 5.387003, valid precision: 0.873800, valid loss: 84.420119
epoch: 899, train precision: 0.999222, train loss: 5.381505, valid precision: 0.872600, valid loss: 85.551078
epoch: 900, train precision: 0.999022, train loss: 5.429224, valid precision: 0.871000, valid loss: 86.553699
epoch: 901, train precision: 0.999089, train loss: 5.440288, valid precision: 0.867600, valid loss: 87.515265
epoch: 902, train precision: 0.999267, train loss: 5.406526, valid precision: 0.867400, valid loss: 88.670061
epoch: 903, train precision: 0.999378, train loss: 5.335418, valid precision: 0.874000, valid loss: 85.665181
epoch: 904, train precision: 0.999422, train loss: 5.346980, valid precision: 0.879800, valid loss: 82.784119
epoch: 905, train precision: 0.999400, train loss: 5.302135, valid precision: 0.875200, valid loss: 83.144215
epoch: 906, train precision: 0.999378, train loss: 5.355587, valid precision: 0.873800, valid loss: 85.832612
epoch: 907, train precision: 0.999022, train loss: 5.451075, valid precision: 0.874200, valid loss: 84.232225
epoch: 908, train precision: 0.999356, train loss: 5.306891, valid precision: 0.873600, valid loss: 85.658776
epoch: 909, train precision: 0.999511, train loss: 5.325736, valid precision: 0.875400, valid loss: 85.399579
epoch: 910, train precision: 0.999467, train loss: 5.304432, valid precision: 0.874000, valid loss: 86.694116
epoch: 911, train precision: 0.999022, train loss: 5.501093, valid precision: 0.872200, valid loss: 85.232423
epoch: 912, train precision: 0.999244, train loss: 5.369013, valid precision: 0.870600, valid loss: 88.080391
epoch: 913, train precision: 0.998911, train loss: 5.468488, valid precision: 0.872000, valid loss: 87.024907
epoch: 914, train precision: 0.999111, train loss: 5.409351, valid precision: 0.871400, valid loss: 86.382202
epoch: 915, train precision: 0.999178, train loss: 5.473925, valid precision: 0.875800, valid loss: 85.931401
epoch: 916, train precision: 0.999244, train loss: 5.367994, valid precision: 0.879000, valid loss: 87.115230
epoch: 917, train precision: 0.999222, train loss: 5.413814, valid precision: 0.875400, valid loss: 86.568469
epoch: 918, train precision: 0.999089, train loss: 5.447502, valid precision: 0.874800, valid loss: 85.971807
epoch: 919, train precision: 0.999311, train loss: 5.360636, valid precision: 0.879200, valid loss: 85.984444
epoch: 920, train precision: 0.999467, train loss: 5.281569, valid precision: 0.875200, valid loss: 86.819165
epoch: 921, train precision: 0.999067, train loss: 5.429273, valid precision: 0.874200, valid loss: 87.029852
epoch: 922, train precision: 0.999267, train loss: 5.385914, valid precision: 0.875800, valid loss: 87.091173
epoch: 923, train precision: 0.999267, train loss: 5.348997, valid precision: 0.878800, valid loss: 84.981940
epoch: 924, train precision: 0.999244, train loss: 5.375484, valid precision: 0.872600, valid loss: 87.075660
epoch: 925, train precision: 0.999067, train loss: 5.462305, valid precision: 0.873800, valid loss: 87.516474
epoch: 926, train precision: 0.999244, train loss: 5.359864, valid precision: 0.874200, valid loss: 86.923072
epoch: 927, train precision: 0.999267, train loss: 5.347988, valid precision: 0.879000, valid loss: 86.975374
epoch: 928, train precision: 0.999244, train loss: 5.420680, valid precision: 0.872600, valid loss: 87.549163
epoch: 929, train precision: 0.999267, train loss: 5.333030, valid precision: 0.877600, valid loss: 86.650538
epoch: 930, train precision: 0.999111, train loss: 5.408488, valid precision: 0.876800, valid loss: 88.099826
epoch: 931, train precision: 0.999022, train loss: 5.480080, valid precision: 0.873600, valid loss: 88.393708
epoch: 932, train precision: 0.999200, train loss: 5.423611, valid precision: 0.876200, valid loss: 85.752376
epoch: 933, train precision: 0.999422, train loss: 5.344719, valid precision: 0.873400, valid loss: 85.376591
epoch: 934, train precision: 0.999333, train loss: 5.410581, valid precision: 0.873800, valid loss: 85.576499
epoch: 935, train precision: 0.999356, train loss: 5.319419, valid precision: 0.876600, valid loss: 84.335214
epoch: 936, train precision: 0.999489, train loss: 5.321025, valid precision: 0.874800, valid loss: 85.739669
epoch: 937, train precision: 0.999578, train loss: 5.315379, valid precision: 0.876000, valid loss: 86.106415
epoch: 938, train precision: 0.999067, train loss: 5.429942, valid precision: 0.874200, valid loss: 86.521872
epoch: 939, train precision: 0.999267, train loss: 5.382443, valid precision: 0.872600, valid loss: 84.637994
epoch: 940, train precision: 0.999067, train loss: 5.443591, valid precision: 0.875600, valid loss: 84.431626
epoch: 941, train precision: 0.999400, train loss: 5.349172, valid precision: 0.878800, valid loss: 84.352967
epoch: 942, train precision: 0.999067, train loss: 5.472636, valid precision: 0.871200, valid loss: 85.306199
epoch: 943, train precision: 0.999311, train loss: 5.341491, valid precision: 0.876200, valid loss: 85.120464
epoch: 944, train precision: 0.999422, train loss: 5.347606, valid precision: 0.876400, valid loss: 86.615362
epoch: 945, train precision: 0.999289, train loss: 5.408042, valid precision: 0.875000, valid loss: 86.763616
epoch: 946, train precision: 0.999311, train loss: 5.382536, valid precision: 0.876800, valid loss: 84.040286
epoch: 947, train precision: 0.999422, train loss: 5.297802, valid precision: 0.880600, valid loss: 82.558855
epoch: 948, train precision: 0.999133, train loss: 5.379576, valid precision: 0.876200, valid loss: 86.060326
epoch: 949, train precision: 0.999267, train loss: 5.360245, valid precision: 0.876800, valid loss: 84.436924
epoch: 950, train precision: 0.998889, train loss: 5.537368, valid precision: 0.876800, valid loss: 85.409837
epoch: 951, train precision: 0.999200, train loss: 5.410724, valid precision: 0.878000, valid loss: 83.072946
epoch: 952, train precision: 0.999311, train loss: 5.385125, valid precision: 0.878000, valid loss: 84.788305
epoch: 953, train precision: 0.998978, train loss: 5.486437, valid precision: 0.871400, valid loss: 87.593363
epoch: 954, train precision: 0.999444, train loss: 5.333091, valid precision: 0.877400, valid loss: 85.248787
epoch: 955, train precision: 0.999400, train loss: 5.365551, valid precision: 0.878600, valid loss: 86.057155
epoch: 956, train precision: 0.999444, train loss: 5.336903, valid precision: 0.878000, valid loss: 86.328400
epoch: 957, train precision: 0.999244, train loss: 5.365946, valid precision: 0.874400, valid loss: 87.657889
epoch: 958, train precision: 0.999489, train loss: 5.350092, valid precision: 0.875600, valid loss: 86.710024
epoch: 959, train precision: 0.999067, train loss: 5.429513, valid precision: 0.877000, valid loss: 86.752609
epoch: 960, train precision: 0.999244, train loss: 5.394006, valid precision: 0.877600, valid loss: 85.935517
epoch: 961, train precision: 0.998733, train loss: 5.550127, valid precision: 0.874800, valid loss: 86.854354
epoch: 962, train precision: 0.999067, train loss: 5.487018, valid precision: 0.873200, valid loss: 87.762899
epoch: 963, train precision: 0.999200, train loss: 5.393928, valid precision: 0.875600, valid loss: 86.192929
epoch: 964, train precision: 0.998800, train loss: 5.534532, valid precision: 0.871800, valid loss: 89.450332
epoch: 965, train precision: 0.999378, train loss: 5.403194, valid precision: 0.878800, valid loss: 88.400757
epoch: 966, train precision: 0.999267, train loss: 5.388696, valid precision: 0.877600, valid loss: 87.806249
epoch: 967, train precision: 0.999289, train loss: 5.363379, valid precision: 0.872000, valid loss: 85.712961
epoch: 968, train precision: 0.999422, train loss: 5.369166, valid precision: 0.876800, valid loss: 87.343080
epoch: 969, train precision: 0.999200, train loss: 5.408755, valid precision: 0.872200, valid loss: 89.048232
epoch: 970, train precision: 0.999000, train loss: 5.456383, valid precision: 0.870400, valid loss: 90.262867
epoch: 971, train precision: 0.999311, train loss: 5.385314, valid precision: 0.877200, valid loss: 86.723484
epoch: 972, train precision: 0.999400, train loss: 5.341177, valid precision: 0.873600, valid loss: 87.378874
epoch: 973, train precision: 0.999356, train loss: 5.393555, valid precision: 0.872800, valid loss: 87.828378
epoch: 974, train precision: 0.999356, train loss: 5.406093, valid precision: 0.873400, valid loss: 87.337233
epoch: 975, train precision: 0.999378, train loss: 5.360794, valid precision: 0.874000, valid loss: 87.709520
epoch: 976, train precision: 0.999222, train loss: 5.432816, valid precision: 0.876000, valid loss: 87.647180
epoch: 977, train precision: 0.999289, train loss: 5.383005, valid precision: 0.878400, valid loss: 86.264271
epoch: 978, train precision: 0.999244, train loss: 5.425251, valid precision: 0.873400, valid loss: 88.581298
epoch: 979, train precision: 0.999244, train loss: 5.374850, valid precision: 0.873400, valid loss: 88.406208
epoch: 980, train precision: 0.999000, train loss: 5.478774, valid precision: 0.871400, valid loss: 88.773944
epoch: 981, train precision: 0.999289, train loss: 5.365421, valid precision: 0.874400, valid loss: 87.789200
epoch: 982, train precision: 0.999200, train loss: 5.448134, valid precision: 0.873000, valid loss: 87.431311
epoch: 983, train precision: 0.999556, train loss: 5.359210, valid precision: 0.873200, valid loss: 85.649996
epoch: 984, train precision: 0.999311, train loss: 5.387584, valid precision: 0.876000, valid loss: 87.223531
epoch: 985, train precision: 0.999444, train loss: 5.355750, valid precision: 0.876200, valid loss: 87.741511
epoch: 986, train precision: 0.999400, train loss: 5.396772, valid precision: 0.872800, valid loss: 87.512024
epoch: 987, train precision: 0.998844, train loss: 5.548675, valid precision: 0.875000, valid loss: 87.534780
epoch: 988, train precision: 0.999156, train loss: 5.434718, valid precision: 0.878000, valid loss: 85.450612
epoch: 989, train precision: 0.999400, train loss: 5.419079, valid precision: 0.876000, valid loss: 86.593611
epoch: 990, train precision: 0.999378, train loss: 5.396700, valid precision: 0.879000, valid loss: 87.089986
epoch: 991, train precision: 0.999244, train loss: 5.413123, valid precision: 0.873400, valid loss: 85.297374
epoch: 992, train precision: 0.999444, train loss: 5.335315, valid precision: 0.874800, valid loss: 87.561280
epoch: 993, train precision: 0.999400, train loss: 5.396012, valid precision: 0.875600, valid loss: 88.478784
epoch: 994, train precision: 0.999378, train loss: 5.358937, valid precision: 0.876600, valid loss: 88.232993
epoch: 995, train precision: 0.999289, train loss: 5.400642, valid precision: 0.877200, valid loss: 88.476329
epoch: 996, train precision: 0.999444, train loss: 5.402974, valid precision: 0.876000, valid loss: 87.685825
epoch: 997, train precision: 0.999244, train loss: 5.431365, valid precision: 0.873200, valid loss: 88.385723
epoch: 998, train precision: 0.999444, train loss: 5.384592, valid precision: 0.873800, valid loss: 88.602995
epoch: 999, train precision: 0.999422, train loss: 5.371582, valid precision: 0.875200, valid loss: 88.466752
epoch: 1000, train precision: 0.999422, train loss: 5.387505, valid precision: 0.875200, valid loss: 89.599465
epoch: 1001, train precision: 0.999133, train loss: 5.447039, valid precision: 0.875400, valid loss: 89.340960
epoch: 1002, train precision: 0.999422, train loss: 5.439500, valid precision: 0.871000, valid loss: 88.916648
epoch: 1003, train precision: 0.999244, train loss: 5.454515, valid precision: 0.876200, valid loss: 87.133124
epoch: 1004, train precision: 0.999267, train loss: 5.431032, valid precision: 0.876000, valid loss: 86.146996
epoch: 1005, train precision: 0.998889, train loss: 5.503738, valid precision: 0.875800, valid loss: 88.428433
epoch: 1006, train precision: 0.999467, train loss: 5.435679, valid precision: 0.874400, valid loss: 84.607382
epoch: 1007, train precision: 0.999311, train loss: 5.369954, valid precision: 0.876400, valid loss: 86.581051
epoch: 1008, train precision: 0.999244, train loss: 5.414566, valid precision: 0.876800, valid loss: 87.824782
epoch: 1009, train precision: 0.999356, train loss: 5.354581, valid precision: 0.872800, valid loss: 91.212545
epoch: 1010, train precision: 0.999000, train loss: 5.483542, valid precision: 0.874200, valid loss: 89.001528
epoch: 1011, train precision: 0.999289, train loss: 5.430629, valid precision: 0.873800, valid loss: 88.807910
epoch: 1012, train precision: 0.999289, train loss: 5.417591, valid precision: 0.875000, valid loss: 89.592211
epoch: 1013, train precision: 0.999333, train loss: 5.363344, valid precision: 0.874000, valid loss: 87.411555
epoch: 1014, train precision: 0.999422, train loss: 5.384522, valid precision: 0.876200, valid loss: 89.026841
epoch: 1015, train precision: 0.999422, train loss: 5.384480, valid precision: 0.872200, valid loss: 87.674350
epoch: 1016, train precision: 0.999333, train loss: 5.423947, valid precision: 0.874600, valid loss: 89.471004
epoch: 1017, train precision: 0.999378, train loss: 5.346442, valid precision: 0.875400, valid loss: 89.279144
epoch: 1018, train precision: 0.999244, train loss: 5.438836, valid precision: 0.872600, valid loss: 90.293135
epoch: 1019, train precision: 0.999467, train loss: 5.348349, valid precision: 0.874800, valid loss: 89.133183
epoch: 1020, train precision: 0.999667, train loss: 5.295340, valid precision: 0.877600, valid loss: 88.378445
epoch: 1021, train precision: 0.999533, train loss: 5.364516, valid precision: 0.873600, valid loss: 90.067242
epoch: 1022, train precision: 0.999533, train loss: 5.333796, valid precision: 0.869600, valid loss: 90.343981
epoch: 1023, train precision: 0.999244, train loss: 5.454825, valid precision: 0.872200, valid loss: 87.922438
epoch: 1024, train precision: 0.999667, train loss: 5.320860, valid precision: 0.873000, valid loss: 87.341489
epoch: 1025, train precision: 0.999267, train loss: 5.449037, valid precision: 0.873800, valid loss: 90.350962
epoch: 1026, train precision: 0.999267, train loss: 5.432610, valid precision: 0.872800, valid loss: 91.262999
epoch: 1027, train precision: 0.999333, train loss: 5.480564, valid precision: 0.873200, valid loss: 89.947368
epoch: 1028, train precision: 0.999378, train loss: 5.402398, valid precision: 0.872000, valid loss: 90.941883
epoch: 1029, train precision: 0.999267, train loss: 5.430424, valid precision: 0.871200, valid loss: 91.806484
epoch: 1030, train precision: 0.999511, train loss: 5.362971, valid precision: 0.872000, valid loss: 89.744908
epoch: 1031, train precision: 0.999222, train loss: 5.437028, valid precision: 0.871800, valid loss: 92.380345
epoch: 1032, train precision: 0.999378, train loss: 5.432422, valid precision: 0.872600, valid loss: 91.999817
epoch: 1033, train precision: 0.999244, train loss: 5.464453, valid precision: 0.873600, valid loss: 90.642876
epoch: 1034, train precision: 0.999422, train loss: 5.398235, valid precision: 0.871600, valid loss: 88.957985
epoch: 1035, train precision: 0.999267, train loss: 5.450532, valid precision: 0.871800, valid loss: 89.775117
epoch: 1036, train precision: 0.999400, train loss: 5.366216, valid precision: 0.873200, valid loss: 90.726766
epoch: 1037, train precision: 0.999622, train loss: 5.346870, valid precision: 0.872000, valid loss: 92.709008
epoch: 1038, train precision: 0.998800, train loss: 5.579745, valid precision: 0.870200, valid loss: 92.810158
epoch: 1039, train precision: 0.999467, train loss: 5.409671, valid precision: 0.871400, valid loss: 88.996273
epoch: 1040, train precision: 0.999022, train loss: 5.520056, valid precision: 0.871800, valid loss: 91.214708
epoch: 1041, train precision: 0.999356, train loss: 5.389099, valid precision: 0.873600, valid loss: 91.148972
epoch: 1042, train precision: 0.999533, train loss: 5.391572, valid precision: 0.873800, valid loss: 90.663608
epoch: 1043, train precision: 0.999444, train loss: 5.407374, valid precision: 0.874800, valid loss: 90.192399
epoch: 1044, train precision: 0.999156, train loss: 5.454633, valid precision: 0.876400, valid loss: 90.299452
epoch: 1045, train precision: 0.999356, train loss: 5.384684, valid precision: 0.878000, valid loss: 88.136204
epoch: 1046, train precision: 0.999156, train loss: 5.513204, valid precision: 0.871600, valid loss: 91.406695
epoch: 1047, train precision: 0.999244, train loss: 5.428038, valid precision: 0.872600, valid loss: 89.395959
epoch: 1048, train precision: 0.999578, train loss: 5.356561, valid precision: 0.872400, valid loss: 89.741033
epoch: 1049, train precision: 0.999400, train loss: 5.410377, valid precision: 0.875200, valid loss: 89.207167
epoch: 1050, train precision: 0.999400, train loss: 5.413826, valid precision: 0.877000, valid loss: 88.021791
epoch: 1051, train precision: 0.999333, train loss: 5.452850, valid precision: 0.873800, valid loss: 89.144119
epoch: 1052, train precision: 0.999333, train loss: 5.442868, valid precision: 0.871600, valid loss: 89.703508
epoch: 1053, train precision: 0.999578, train loss: 5.355280, valid precision: 0.873000, valid loss: 91.209801
epoch: 1054, train precision: 0.999111, train loss: 5.494978, valid precision: 0.872200, valid loss: 90.826168
epoch: 1055, train precision: 0.999089, train loss: 5.427011, valid precision: 0.873600, valid loss: 89.389358
epoch: 1056, train precision: 0.999533, train loss: 5.360800, valid precision: 0.874200, valid loss: 87.579398
epoch: 1057, train precision: 0.999511, train loss: 5.360482, valid precision: 0.876200, valid loss: 87.722251
epoch: 1058, train precision: 0.999467, train loss: 5.405180, valid precision: 0.875600, valid loss: 89.115711
epoch: 1059, train precision: 0.999667, train loss: 5.372406, valid precision: 0.870000, valid loss: 91.367109
epoch: 1060, train precision: 0.999422, train loss: 5.385042, valid precision: 0.874400, valid loss: 88.382644
epoch: 1061, train precision: 0.999044, train loss: 5.497111, valid precision: 0.876400, valid loss: 89.323490
epoch: 1062, train precision: 0.999422, train loss: 5.402614, valid precision: 0.878000, valid loss: 85.994417
epoch: 1063, train precision: 0.999578, train loss: 5.375096, valid precision: 0.871400, valid loss: 89.085727
epoch: 1064, train precision: 0.999400, train loss: 5.398635, valid precision: 0.875800, valid loss: 89.908216
epoch: 1065, train precision: 0.999378, train loss: 5.427518, valid precision: 0.874200, valid loss: 90.285844
epoch: 1066, train precision: 0.998867, train loss: 5.540140, valid precision: 0.872800, valid loss: 90.777341
epoch: 1067, train precision: 0.999400, train loss: 5.436204, valid precision: 0.871400, valid loss: 89.783139
epoch: 1068, train precision: 0.999600, train loss: 5.350176, valid precision: 0.871200, valid loss: 90.996583
epoch: 1069, train precision: 0.999422, train loss: 5.414521, valid precision: 0.873000, valid loss: 92.100170
epoch: 1070, train precision: 0.999467, train loss: 5.382991, valid precision: 0.871400, valid loss: 91.856473
epoch: 1071, train precision: 0.999333, train loss: 5.487304, valid precision: 0.875000, valid loss: 89.683559
epoch: 1072, train precision: 0.999533, train loss: 5.386127, valid precision: 0.874800, valid loss: 89.475682
epoch: 1073, train precision: 0.999356, train loss: 5.436606, valid precision: 0.876400, valid loss: 88.493572
epoch: 1074, train precision: 0.999400, train loss: 5.430498, valid precision: 0.875600, valid loss: 89.900157
epoch: 1075, train precision: 0.999178, train loss: 5.469451, valid precision: 0.876800, valid loss: 90.816764
epoch: 1076, train precision: 0.999333, train loss: 5.438693, valid precision: 0.874800, valid loss: 91.795120
epoch: 1077, train precision: 0.999489, train loss: 5.390987, valid precision: 0.871800, valid loss: 90.503118
epoch: 1078, train precision: 0.999089, train loss: 5.483143, valid precision: 0.870600, valid loss: 92.178346
epoch: 1079, train precision: 0.999244, train loss: 5.424619, valid precision: 0.869000, valid loss: 91.278877
epoch: 1080, train precision: 0.999178, train loss: 5.526975, valid precision: 0.872600, valid loss: 90.341721
epoch: 1081, train precision: 0.999289, train loss: 5.396950, valid precision: 0.873200, valid loss: 91.387635
epoch: 1082, train precision: 0.999400, train loss: 5.410628, valid precision: 0.876400, valid loss: 88.893554
epoch: 1083, train precision: 0.999378, train loss: 5.417778, valid precision: 0.877600, valid loss: 90.277166
epoch: 1084, train precision: 0.999289, train loss: 5.413027, valid precision: 0.874200, valid loss: 90.853537
epoch: 1085, train precision: 0.999444, train loss: 5.359262, valid precision: 0.872400, valid loss: 93.197767
epoch: 1086, train precision: 0.999378, train loss: 5.438592, valid precision: 0.876000, valid loss: 91.171163
epoch: 1087, train precision: 0.999378, train loss: 5.462552, valid precision: 0.876600, valid loss: 91.785379
epoch: 1088, train precision: 0.999289, train loss: 5.508324, valid precision: 0.873600, valid loss: 90.566344
epoch: 1089, train precision: 0.999156, train loss: 5.520812, valid precision: 0.874200, valid loss: 89.150964
epoch: 1090, train precision: 0.999267, train loss: 5.446408, valid precision: 0.878200, valid loss: 87.888182
epoch: 1091, train precision: 0.999178, train loss: 5.490705, valid precision: 0.875600, valid loss: 89.835728
epoch: 1092, train precision: 0.999444, train loss: 5.385190, valid precision: 0.878600, valid loss: 87.453520
epoch: 1093, train precision: 0.999444, train loss: 5.404483, valid precision: 0.876200, valid loss: 88.547109
epoch: 1094, train precision: 0.999311, train loss: 5.441944, valid precision: 0.878200, valid loss: 88.392451
epoch: 1095, train precision: 0.999400, train loss: 5.411855, valid precision: 0.877600, valid loss: 89.013964
epoch: 1096, train precision: 0.999556, train loss: 5.399990, valid precision: 0.878000, valid loss: 87.873536
epoch: 1097, train precision: 0.999244, train loss: 5.503242, valid precision: 0.879800, valid loss: 88.458042
epoch: 1098, train precision: 0.999311, train loss: 5.457700, valid precision: 0.880200, valid loss: 88.036959
epoch: 1099, train precision: 0.999356, train loss: 5.450079, valid precision: 0.877800, valid loss: 88.177745
epoch: 1100, train precision: 0.999178, train loss: 5.530529, valid precision: 0.877200, valid loss: 86.471131
epoch: 1101, train precision: 0.999000, train loss: 5.561582, valid precision: 0.877200, valid loss: 87.843638
epoch: 1102, train precision: 0.999267, train loss: 5.471200, valid precision: 0.876000, valid loss: 88.054411
epoch: 1103, train precision: 0.999422, train loss: 5.437044, valid precision: 0.872200, valid loss: 89.345831
epoch: 1104, train precision: 0.999333, train loss: 5.499983, valid precision: 0.878400, valid loss: 88.373725
epoch: 1105, train precision: 0.999311, train loss: 5.462168, valid precision: 0.876800, valid loss: 87.768520
epoch: 1106, train precision: 0.999689, train loss: 5.374056, valid precision: 0.875600, valid loss: 87.933625
epoch: 1107, train precision: 0.999267, train loss: 5.503115, valid precision: 0.871200, valid loss: 89.067484
epoch: 1108, train precision: 0.999400, train loss: 5.410972, valid precision: 0.877800, valid loss: 89.730174
epoch: 1109, train precision: 0.999311, train loss: 5.433295, valid precision: 0.877600, valid loss: 87.480579
epoch: 1110, train precision: 0.999467, train loss: 5.412560, valid precision: 0.876000, valid loss: 89.752876
epoch: 1111, train precision: 0.999156, train loss: 5.498486, valid precision: 0.872600, valid loss: 90.746427
epoch: 1112, train precision: 0.999400, train loss: 5.419407, valid precision: 0.876200, valid loss: 91.525672
epoch: 1113, train precision: 0.999378, train loss: 5.417653, valid precision: 0.875800, valid loss: 89.971988
epoch: 1114, train precision: 0.998800, train loss: 5.588679, valid precision: 0.877600, valid loss: 88.105976
epoch: 1115, train precision: 0.999489, train loss: 5.412742, valid precision: 0.875600, valid loss: 89.426422
epoch: 1116, train precision: 0.999156, train loss: 5.552918, valid precision: 0.874600, valid loss: 92.134040
epoch: 1117, train precision: 0.999533, train loss: 5.421351, valid precision: 0.881200, valid loss: 87.339583
epoch: 1118, train precision: 0.999333, train loss: 5.502961, valid precision: 0.874600, valid loss: 90.598042
epoch: 1119, train precision: 0.999022, train loss: 5.472345, valid precision: 0.876600, valid loss: 90.210564
epoch: 1120, train precision: 0.999222, train loss: 5.474097, valid precision: 0.875800, valid loss: 91.059187
epoch: 1121, train precision: 0.999178, train loss: 5.483711, valid precision: 0.875200, valid loss: 90.343654
epoch: 1122, train precision: 0.999311, train loss: 5.459201, valid precision: 0.875800, valid loss: 89.826599
epoch: 1123, train precision: 0.999467, train loss: 5.408943, valid precision: 0.873200, valid loss: 90.306994
epoch: 1124, train precision: 0.999356, train loss: 5.460522, valid precision: 0.874600, valid loss: 89.973067
epoch: 1125, train precision: 0.998956, train loss: 5.601689, valid precision: 0.870400, valid loss: 89.268941
epoch: 1126, train precision: 0.999244, train loss: 5.458930, valid precision: 0.875400, valid loss: 88.211455
epoch: 1127, train precision: 0.999133, train loss: 5.498300, valid precision: 0.875400, valid loss: 89.815601
epoch: 1128, train precision: 0.999178, train loss: 5.481978, valid precision: 0.874400, valid loss: 90.533297
epoch: 1129, train precision: 0.999600, train loss: 5.382335, valid precision: 0.875000, valid loss: 89.930543
epoch: 1130, train precision: 0.999578, train loss: 5.389789, valid precision: 0.874600, valid loss: 89.534531
epoch: 1131, train precision: 0.999267, train loss: 5.486417, valid precision: 0.874800, valid loss: 89.069841
epoch: 1132, train precision: 0.999667, train loss: 5.384750, valid precision: 0.874600, valid loss: 87.741067
epoch: 1133, train precision: 0.999356, train loss: 5.495818, valid precision: 0.872400, valid loss: 88.501056
epoch: 1134, train precision: 0.999200, train loss: 5.480931, valid precision: 0.876400, valid loss: 85.845418
epoch: 1135, train precision: 0.999289, train loss: 5.454439, valid precision: 0.875200, valid loss: 90.159589
epoch: 1136, train precision: 0.999333, train loss: 5.445803, valid precision: 0.877200, valid loss: 86.869854
epoch: 1137, train precision: 0.999200, train loss: 5.541241, valid precision: 0.874400, valid loss: 88.137282
epoch: 1138, train precision: 0.999378, train loss: 5.427635, valid precision: 0.874400, valid loss: 86.970780
epoch: 1139, train precision: 0.999511, train loss: 5.388521, valid precision: 0.878200, valid loss: 87.684796
epoch: 1140, train precision: 0.999400, train loss: 5.459346, valid precision: 0.879200, valid loss: 89.755599
epoch: 1141, train precision: 0.999444, train loss: 5.432297, valid precision: 0.876800, valid loss: 89.694030
epoch: 1142, train precision: 0.999244, train loss: 5.490694, valid precision: 0.874200, valid loss: 90.337814
epoch: 1143, train precision: 0.999422, train loss: 5.459673, valid precision: 0.875200, valid loss: 90.354991
epoch: 1144, train precision: 0.999044, train loss: 5.561582, valid precision: 0.872600, valid loss: 92.084648
epoch: 1145, train precision: 0.999444, train loss: 5.431819, valid precision: 0.875800, valid loss: 88.487657
epoch: 1146, train precision: 0.999422, train loss: 5.426786, valid precision: 0.874400, valid loss: 89.848834
epoch: 1147, train precision: 0.999244, train loss: 5.491112, valid precision: 0.874000, valid loss: 91.556903
epoch: 1148, train precision: 0.999556, train loss: 5.421460, valid precision: 0.874400, valid loss: 90.969170
epoch: 1149, train precision: 0.999644, train loss: 5.385785, valid precision: 0.877600, valid loss: 88.766576
epoch: 1150, train precision: 0.999311, train loss: 5.460938, valid precision: 0.875000, valid loss: 90.931360
epoch: 1151, train precision: 0.999489, train loss: 5.437325, valid precision: 0.876200, valid loss: 89.777253
epoch: 1152, train precision: 0.999156, train loss: 5.537974, valid precision: 0.875400, valid loss: 92.487348
epoch: 1153, train precision: 0.999533, train loss: 5.451161, valid precision: 0.872800, valid loss: 90.623970
epoch: 1154, train precision: 0.999511, train loss: 5.427219, valid precision: 0.877600, valid loss: 91.312704
epoch: 1155, train precision: 0.999156, train loss: 5.526951, valid precision: 0.873400, valid loss: 90.286412
epoch: 1156, train precision: 0.999289, train loss: 5.497347, valid precision: 0.874800, valid loss: 90.149527
epoch: 1157, train precision: 0.999511, train loss: 5.429585, valid precision: 0.876400, valid loss: 87.745559
epoch: 1158, train precision: 0.999533, train loss: 5.443585, valid precision: 0.876200, valid loss: 91.175211
epoch: 1159, train precision: 0.999200, train loss: 5.497111, valid precision: 0.874000, valid loss: 89.780680
epoch: 1160, train precision: 0.999356, train loss: 5.454755, valid precision: 0.872400, valid loss: 91.749309
epoch: 1161, train precision: 0.999289, train loss: 5.464965, valid precision: 0.875600, valid loss: 89.293036
epoch: 1162, train precision: 0.999556, train loss: 5.405130, valid precision: 0.878400, valid loss: 87.933516
epoch: 1163, train precision: 0.999289, train loss: 5.462404, valid precision: 0.876800, valid loss: 89.609477
epoch: 1164, train precision: 0.999422, train loss: 5.450600, valid precision: 0.873800, valid loss: 91.041441
epoch: 1165, train precision: 0.999333, train loss: 5.464680, valid precision: 0.876600, valid loss: 91.716760
epoch: 1166, train precision: 0.999622, train loss: 5.432198, valid precision: 0.874400, valid loss: 91.994252
epoch: 1167, train precision: 0.999156, train loss: 5.522965, valid precision: 0.872800, valid loss: 94.159564
epoch: 1168, train precision: 0.999533, train loss: 5.426661, valid precision: 0.877000, valid loss: 90.775805
epoch: 1169, train precision: 0.999689, train loss: 5.409823, valid precision: 0.875800, valid loss: 90.194701
epoch: 1170, train precision: 0.999311, train loss: 5.470213, valid precision: 0.873800, valid loss: 90.942697
epoch: 1171, train precision: 0.999422, train loss: 5.469452, valid precision: 0.876800, valid loss: 90.371943
epoch: 1172, train precision: 0.999400, train loss: 5.418001, valid precision: 0.876000, valid loss: 91.543037
epoch: 1173, train precision: 0.999422, train loss: 5.460525, valid precision: 0.875800, valid loss: 90.079984
epoch: 1174, train precision: 0.999511, train loss: 5.403101, valid precision: 0.873800, valid loss: 91.646190
epoch: 1175, train precision: 0.999333, train loss: 5.517296, valid precision: 0.879200, valid loss: 91.190534
epoch: 1176, train precision: 0.999533, train loss: 5.429707, valid precision: 0.877400, valid loss: 89.555617
epoch: 1177, train precision: 0.999444, train loss: 5.433762, valid precision: 0.873400, valid loss: 93.141556
epoch: 1178, train precision: 0.999044, train loss: 5.613923, valid precision: 0.875600, valid loss: 90.629202
epoch: 1179, train precision: 0.999556, train loss: 5.392578, valid precision: 0.875800, valid loss: 91.218782
epoch: 1180, train precision: 0.999356, train loss: 5.456371, valid precision: 0.874800, valid loss: 91.458036
epoch: 1181, train precision: 0.999378, train loss: 5.555969, valid precision: 0.875200, valid loss: 92.302724
epoch: 1182, train precision: 0.998822, train loss: 5.573055, valid precision: 0.875000, valid loss: 92.203522
epoch: 1183, train precision: 0.999289, train loss: 5.473702, valid precision: 0.873200, valid loss: 92.397020
epoch: 1184, train precision: 0.999000, train loss: 5.542148, valid precision: 0.874800, valid loss: 90.178928
epoch: 1185, train precision: 0.999356, train loss: 5.519783, valid precision: 0.874800, valid loss: 90.346961
epoch: 1186, train precision: 0.999578, train loss: 5.473129, valid precision: 0.873200, valid loss: 90.588283
epoch: 1187, train precision: 0.999489, train loss: 5.448954, valid precision: 0.877000, valid loss: 89.761945
epoch: 1188, train precision: 0.999244, train loss: 5.499141, valid precision: 0.876400, valid loss: 88.910169
epoch: 1189, train precision: 0.999467, train loss: 5.510040, valid precision: 0.879200, valid loss: 88.995098
epoch: 1190, train precision: 0.999378, train loss: 5.478518, valid precision: 0.875600, valid loss: 89.807040
epoch: 1191, train precision: 0.999333, train loss: 5.513935, valid precision: 0.875000, valid loss: 88.792296
epoch: 1192, train precision: 0.999422, train loss: 5.454500, valid precision: 0.876600, valid loss: 89.534498
epoch: 1193, train precision: 0.999089, train loss: 5.535854, valid precision: 0.875600, valid loss: 92.136482
epoch: 1194, train precision: 0.999511, train loss: 5.437171, valid precision: 0.878000, valid loss: 92.471486
epoch: 1195, train precision: 0.999578, train loss: 5.413005, valid precision: 0.877000, valid loss: 91.143425
epoch: 1196, train precision: 0.999533, train loss: 5.448718, valid precision: 0.874000, valid loss: 92.223503
epoch: 1197, train precision: 0.999178, train loss: 5.523123, valid precision: 0.874600, valid loss: 91.851853
epoch: 1198, train precision: 0.999667, train loss: 5.436791, valid precision: 0.875800, valid loss: 90.460238
epoch: 1199, train precision: 0.999378, train loss: 5.463155, valid precision: 0.876600, valid loss: 89.318788
epoch: 1200, train precision: 0.999400, train loss: 5.511953, valid precision: 0.878200, valid loss: 90.204876
epoch: 1201, train precision: 0.999356, train loss: 5.465030, valid precision: 0.878400, valid loss: 89.401028
epoch: 1202, train precision: 0.999400, train loss: 5.492496, valid precision: 0.873400, valid loss: 91.791678
epoch: 1203, train precision: 0.999422, train loss: 5.480495, valid precision: 0.877600, valid loss: 92.793148
epoch: 1204, train precision: 0.999267, train loss: 5.479573, valid precision: 0.876800, valid loss: 93.670443
epoch: 1205, train precision: 0.999511, train loss: 5.455587, valid precision: 0.878200, valid loss: 93.163898
epoch: 1206, train precision: 0.999578, train loss: 5.458380, valid precision: 0.876600, valid loss: 91.597084
epoch: 1207, train precision: 0.999178, train loss: 5.502102, valid precision: 0.876000, valid loss: 94.173076
epoch: 1208, train precision: 0.999333, train loss: 5.492009, valid precision: 0.875200, valid loss: 93.587704
epoch: 1209, train precision: 0.999556, train loss: 5.447771, valid precision: 0.875800, valid loss: 91.598158
epoch: 1210, train precision: 0.999644, train loss: 5.410799, valid precision: 0.875000, valid loss: 92.309132
epoch: 1211, train precision: 0.999578, train loss: 5.438967, valid precision: 0.873000, valid loss: 90.649115
epoch: 1212, train precision: 0.999356, train loss: 5.469608, valid precision: 0.874800, valid loss: 94.012761
epoch: 1213, train precision: 0.999244, train loss: 5.553504, valid precision: 0.872000, valid loss: 94.042985
epoch: 1214, train precision: 0.999289, train loss: 5.514363, valid precision: 0.872800, valid loss: 92.626753
epoch: 1215, train precision: 0.999556, train loss: 5.461975, valid precision: 0.876000, valid loss: 90.033288
epoch: 1216, train precision: 0.999422, train loss: 5.492466, valid precision: 0.875600, valid loss: 90.377450
epoch: 1217, train precision: 0.999556, train loss: 5.427836, valid precision: 0.874400, valid loss: 93.437102
epoch: 1218, train precision: 0.999156, train loss: 5.537746, valid precision: 0.879200, valid loss: 91.092348
epoch: 1219, train precision: 0.999578, train loss: 5.461054, valid precision: 0.877000, valid loss: 88.937264
epoch: 1220, train precision: 0.999622, train loss: 5.419114, valid precision: 0.875200, valid loss: 91.819980
epoch: 1221, train precision: 0.999356, train loss: 5.529488, valid precision: 0.878800, valid loss: 91.087499
epoch: 1222, train precision: 0.999200, train loss: 5.511908, valid precision: 0.875400, valid loss: 89.801825
epoch: 1223, train precision: 0.999178, train loss: 5.558498, valid precision: 0.872600, valid loss: 94.341607
epoch: 1224, train precision: 0.999244, train loss: 5.529716, valid precision: 0.874600, valid loss: 90.086600
epoch: 1225, train precision: 0.999467, train loss: 5.452738, valid precision: 0.878000, valid loss: 90.870867
epoch: 1226, train precision: 0.999578, train loss: 5.426920, valid precision: 0.878000, valid loss: 91.757176
epoch: 1227, train precision: 0.999422, train loss: 5.460343, valid precision: 0.876400, valid loss: 90.647053
epoch: 1228, train precision: 0.999333, train loss: 5.515110, valid precision: 0.873600, valid loss: 93.507951
epoch: 1229, train precision: 0.999422, train loss: 5.486873, valid precision: 0.875800, valid loss: 91.710185
epoch: 1230, train precision: 0.999444, train loss: 5.515384, valid precision: 0.873400, valid loss: 95.020715
epoch: 1231, train precision: 0.999511, train loss: 5.427618, valid precision: 0.875800, valid loss: 90.847862
epoch: 1232, train precision: 0.999578, train loss: 5.460666, valid precision: 0.872800, valid loss: 91.744477
epoch: 1233, train precision: 0.999533, train loss: 5.452244, valid precision: 0.877200, valid loss: 92.735417
epoch: 1234, train precision: 0.999422, train loss: 5.459576, valid precision: 0.877000, valid loss: 92.177893
epoch: 1235, train precision: 0.999333, train loss: 5.532397, valid precision: 0.875800, valid loss: 94.070531
epoch: 1236, train precision: 0.999356, train loss: 5.475146, valid precision: 0.877800, valid loss: 89.873678
epoch: 1237, train precision: 0.999600, train loss: 5.468506, valid precision: 0.877200, valid loss: 90.635315
epoch: 1238, train precision: 0.999600, train loss: 5.442059, valid precision: 0.878400, valid loss: 92.130146
epoch: 1239, train precision: 0.999511, train loss: 5.428869, valid precision: 0.875400, valid loss: 92.261869
epoch: 1240, train precision: 0.999467, train loss: 5.479208, valid precision: 0.877400, valid loss: 92.882252
epoch: 1241, train precision: 0.999689, train loss: 5.414393, valid precision: 0.874000, valid loss: 92.619907
epoch: 1242, train precision: 0.999622, train loss: 5.404626, valid precision: 0.877000, valid loss: 89.986809
epoch: 1243, train precision: 0.999444, train loss: 5.548735, valid precision: 0.875000, valid loss: 90.738561
epoch: 1244, train precision: 0.999333, train loss: 5.513048, valid precision: 0.877000, valid loss: 92.188740
epoch: 1245, train precision: 0.999289, train loss: 5.533807, valid precision: 0.874800, valid loss: 92.931937
epoch: 1246, train precision: 0.999444, train loss: 5.489260, valid precision: 0.875800, valid loss: 90.213175
epoch: 1247, train precision: 0.999511, train loss: 5.426404, valid precision: 0.876600, valid loss: 90.666707
epoch: 1248, train precision: 0.999444, train loss: 5.469254, valid precision: 0.876800, valid loss: 90.856062
epoch: 1249, train precision: 0.999400, train loss: 5.512355, valid precision: 0.877400, valid loss: 90.625744
epoch: 1250, train precision: 0.999644, train loss: 5.425846, valid precision: 0.873200, valid loss: 91.414567
epoch: 1251, train precision: 0.999511, train loss: 5.457222, valid precision: 0.874000, valid loss: 95.052281
epoch: 1252, train precision: 0.999556, train loss: 5.484102, valid precision: 0.871800, valid loss: 89.991685
epoch: 1253, train precision: 0.999600, train loss: 5.443335, valid precision: 0.872400, valid loss: 89.729909
epoch: 1254, train precision: 0.999444, train loss: 5.483137, valid precision: 0.872600, valid loss: 91.351921
epoch: 1255, train precision: 0.999422, train loss: 5.456802, valid precision: 0.875600, valid loss: 91.905602
epoch: 1256, train precision: 0.999556, train loss: 5.473084, valid precision: 0.872200, valid loss: 92.141887
epoch: 1257, train precision: 0.999200, train loss: 5.584332, valid precision: 0.868800, valid loss: 95.140201
epoch: 1258, train precision: 0.999267, train loss: 5.527517, valid precision: 0.872800, valid loss: 91.819508
epoch: 1259, train precision: 0.999556, train loss: 5.450524, valid precision: 0.873000, valid loss: 89.649286
epoch: 1260, train precision: 0.999489, train loss: 5.456680, valid precision: 0.877600, valid loss: 91.896872
epoch: 1261, train precision: 0.999533, train loss: 5.464271, valid precision: 0.875000, valid loss: 91.790671
epoch: 1262, train precision: 0.999378, train loss: 5.508802, valid precision: 0.874000, valid loss: 92.662941
epoch: 1263, train precision: 0.999778, train loss: 5.381822, valid precision: 0.875400, valid loss: 90.772959
epoch: 1264, train precision: 0.999444, train loss: 5.484682, valid precision: 0.873800, valid loss: 91.814675
epoch: 1265, train precision: 0.999267, train loss: 5.555823, valid precision: 0.875400, valid loss: 92.577785
epoch: 1266, train precision: 0.999622, train loss: 5.476243, valid precision: 0.873800, valid loss: 91.016034
epoch: 1267, train precision: 0.999378, train loss: 5.492238, valid precision: 0.875000, valid loss: 91.813855
epoch: 1268, train precision: 0.999644, train loss: 5.456109, valid precision: 0.873800, valid loss: 92.629251
epoch: 1269, train precision: 0.999378, train loss: 5.503705, valid precision: 0.873800, valid loss: 90.873738
epoch: 1270, train precision: 0.999378, train loss: 5.515822, valid precision: 0.872000, valid loss: 91.675080
epoch: 1271, train precision: 0.999467, train loss: 5.455580, valid precision: 0.873200, valid loss: 91.951658
epoch: 1272, train precision: 0.999356, train loss: 5.505854, valid precision: 0.873000, valid loss: 91.501166
epoch: 1273, train precision: 0.999622, train loss: 5.466575, valid precision: 0.877200, valid loss: 89.524038
epoch: 1274, train precision: 0.999467, train loss: 5.460494, valid precision: 0.877600, valid loss: 88.821675
epoch: 1275, train precision: 0.999578, train loss: 5.447556, valid precision: 0.874800, valid loss: 89.820441
epoch: 1276, train precision: 0.999711, train loss: 5.428461, valid precision: 0.876400, valid loss: 88.591338
epoch: 1277, train precision: 0.999378, train loss: 5.485564, valid precision: 0.875800, valid loss: 91.077549
epoch: 1278, train precision: 0.999511, train loss: 5.462495, valid precision: 0.870200, valid loss: 89.220797
epoch: 1279, train precision: 0.999422, train loss: 5.478122, valid precision: 0.873400, valid loss: 88.909698
epoch: 1280, train precision: 0.999089, train loss: 5.604302, valid precision: 0.875800, valid loss: 89.456309
epoch: 1281, train precision: 0.999400, train loss: 5.528007, valid precision: 0.875400, valid loss: 89.217093
epoch: 1282, train precision: 0.999622, train loss: 5.499610, valid precision: 0.876200, valid loss: 89.955710
epoch: 1283, train precision: 0.999422, train loss: 5.519727, valid precision: 0.875400, valid loss: 90.353853
epoch: 1284, train precision: 0.999600, train loss: 5.475953, valid precision: 0.875000, valid loss: 91.461738
epoch: 1285, train precision: 0.999511, train loss: 5.454533, valid precision: 0.875000, valid loss: 91.472718
epoch: 1286, train precision: 0.999422, train loss: 5.478872, valid precision: 0.877000, valid loss: 91.855848
epoch: 1287, train precision: 0.999267, train loss: 5.530075, valid precision: 0.878600, valid loss: 93.549529
epoch: 1288, train precision: 0.999333, train loss: 5.494086, valid precision: 0.874400, valid loss: 92.334633
epoch: 1289, train precision: 0.999356, train loss: 5.480600, valid precision: 0.872600, valid loss: 90.414812
epoch: 1290, train precision: 0.999378, train loss: 5.539493, valid precision: 0.874200, valid loss: 91.466126
epoch: 1291, train precision: 0.999422, train loss: 5.490273, valid precision: 0.877000, valid loss: 90.519956
epoch: 1292, train precision: 0.999222, train loss: 5.542830, valid precision: 0.875800, valid loss: 91.339090
epoch: 1293, train precision: 0.999667, train loss: 5.413117, valid precision: 0.875800, valid loss: 90.719401
epoch: 1294, train precision: 0.999511, train loss: 5.508762, valid precision: 0.878600, valid loss: 92.255006
epoch: 1295, train precision: 0.999511, train loss: 5.470875, valid precision: 0.877600, valid loss: 93.693696
epoch: 1296, train precision: 0.999511, train loss: 5.467551, valid precision: 0.878200, valid loss: 90.010391
epoch: 1297, train precision: 0.999378, train loss: 5.505736, valid precision: 0.877800, valid loss: 91.374505
epoch: 1298, train precision: 0.999444, train loss: 5.498511, valid precision: 0.879400, valid loss: 91.564027
epoch: 1299, train precision: 0.999378, train loss: 5.500783, valid precision: 0.877400, valid loss: 90.018722
epoch: 1300, train precision: 0.999178, train loss: 5.620280, valid precision: 0.875200, valid loss: 92.512851
epoch: 1301, train precision: 0.999711, train loss: 5.450949, valid precision: 0.879400, valid loss: 90.623174
epoch: 1302, train precision: 0.999444, train loss: 5.479080, valid precision: 0.876800, valid loss: 91.862232
epoch: 1303, train precision: 0.999178, train loss: 5.538932, valid precision: 0.876800, valid loss: 91.272421
epoch: 1304, train precision: 0.999422, train loss: 5.522256, valid precision: 0.878400, valid loss: 91.004704
epoch: 1305, train precision: 0.999533, train loss: 5.491247, valid precision: 0.876400, valid loss: 90.855405
epoch: 1306, train precision: 0.999511, train loss: 5.491621, valid precision: 0.873200, valid loss: 94.511801
epoch: 1307, train precision: 0.999556, train loss: 5.470509, valid precision: 0.876200, valid loss: 92.041702
epoch: 1308, train precision: 0.999267, train loss: 5.512254, valid precision: 0.875400, valid loss: 91.822209
epoch: 1309, train precision: 0.999644, train loss: 5.437005, valid precision: 0.879000, valid loss: 88.090584
epoch: 1310, train precision: 0.999467, train loss: 5.463096, valid precision: 0.873600, valid loss: 93.673428
epoch: 1311, train precision: 0.999422, train loss: 5.524134, valid precision: 0.875600, valid loss: 92.645843
epoch: 1312, train precision: 0.999533, train loss: 5.484429, valid precision: 0.872000, valid loss: 91.874583
epoch: 1313, train precision: 0.999311, train loss: 5.536909, valid precision: 0.873600, valid loss: 92.404723
epoch: 1314, train precision: 0.999689, train loss: 5.437138, valid precision: 0.879600, valid loss: 91.751970
epoch: 1315, train precision: 0.999600, train loss: 5.439480, valid precision: 0.876600, valid loss: 90.143850
epoch: 1316, train precision: 0.999711, train loss: 5.436308, valid precision: 0.877600, valid loss: 90.608144
epoch: 1317, train precision: 0.999467, train loss: 5.506538, valid precision: 0.872200, valid loss: 93.778676
epoch: 1318, train precision: 0.999378, train loss: 5.470672, valid precision: 0.875000, valid loss: 94.012585
epoch: 1319, train precision: 0.999422, train loss: 5.507377, valid precision: 0.874800, valid loss: 94.855579
epoch: 1320, train precision: 0.999556, train loss: 5.482317, valid precision: 0.876800, valid loss: 92.469307
epoch: 1321, train precision: 0.999333, train loss: 5.526292, valid precision: 0.872800, valid loss: 94.578773
epoch: 1322, train precision: 0.999667, train loss: 5.435562, valid precision: 0.871800, valid loss: 92.654989
epoch: 1323, train precision: 0.999267, train loss: 5.544870, valid precision: 0.873000, valid loss: 91.032788
epoch: 1324, train precision: 0.999133, train loss: 5.622722, valid precision: 0.875400, valid loss: 92.651951
epoch: 1325, train precision: 0.999533, train loss: 5.473583, valid precision: 0.879000, valid loss: 91.156012
epoch: 1326, train precision: 0.999422, train loss: 5.515283, valid precision: 0.878800, valid loss: 88.887836
epoch: 1327, train precision: 0.999644, train loss: 5.471004, valid precision: 0.875400, valid loss: 88.814230
epoch: 1328, train precision: 0.999733, train loss: 5.420755, valid precision: 0.876000, valid loss: 91.091828
epoch: 1329, train precision: 0.999289, train loss: 5.526764, valid precision: 0.873600, valid loss: 92.519940
epoch: 1330, train precision: 0.999622, train loss: 5.449220, valid precision: 0.874800, valid loss: 90.928090
epoch: 1331, train precision: 0.999467, train loss: 5.475922, valid precision: 0.874600, valid loss: 94.247228
epoch: 1332, train precision: 0.999600, train loss: 5.477003, valid precision: 0.873200, valid loss: 95.446632
epoch: 1333, train precision: 0.999422, train loss: 5.496521, valid precision: 0.875000, valid loss: 94.550419
epoch: 1334, train precision: 0.999444, train loss: 5.493460, valid precision: 0.877000, valid loss: 93.328368
epoch: 1335, train precision: 0.999222, train loss: 5.549330, valid precision: 0.874600, valid loss: 92.178769
epoch: 1336, train precision: 0.999533, train loss: 5.503505, valid precision: 0.873800, valid loss: 92.736161
epoch: 1337, train precision: 0.999578, train loss: 5.441194, valid precision: 0.872800, valid loss: 95.242420
epoch: 1338, train precision: 0.999578, train loss: 5.467385, valid precision: 0.877200, valid loss: 93.673907
epoch: 1339, train precision: 0.999422, train loss: 5.504100, valid precision: 0.875800, valid loss: 92.706938
epoch: 1340, train precision: 0.999422, train loss: 5.512539, valid precision: 0.871800, valid loss: 94.124044
epoch: 1341, train precision: 0.999556, train loss: 5.450202, valid precision: 0.872000, valid loss: 93.577425
epoch: 1342, train precision: 0.999467, train loss: 5.484402, valid precision: 0.875600, valid loss: 91.779722
epoch: 1343, train precision: 0.999600, train loss: 5.480697, valid precision: 0.872800, valid loss: 92.302049
epoch: 1344, train precision: 0.999578, train loss: 5.454773, valid precision: 0.875400, valid loss: 91.955948
epoch: 1345, train precision: 0.999578, train loss: 5.454912, valid precision: 0.875600, valid loss: 93.726718
epoch: 1346, train precision: 0.999356, train loss: 5.524554, valid precision: 0.872000, valid loss: 94.746399
epoch: 1347, train precision: 0.999156, train loss: 5.581682, valid precision: 0.872600, valid loss: 95.734419
epoch: 1348, train precision: 0.999733, train loss: 5.398749, valid precision: 0.875600, valid loss: 94.580996
epoch: 1349, train precision: 0.999489, train loss: 5.475077, valid precision: 0.876600, valid loss: 93.106719
epoch: 1350, train precision: 0.999600, train loss: 5.449470, valid precision: 0.874800, valid loss: 91.721596
epoch: 1351, train precision: 0.999511, train loss: 5.473856, valid precision: 0.874000, valid loss: 94.779881
epoch: 1352, train precision: 0.999267, train loss: 5.526589, valid precision: 0.874600, valid loss: 93.822375
epoch: 1353, train precision: 0.999489, train loss: 5.507935, valid precision: 0.870200, valid loss: 96.976768
epoch: 1354, train precision: 0.999267, train loss: 5.562248, valid precision: 0.873800, valid loss: 97.540844
epoch: 1355, train precision: 0.999333, train loss: 5.555580, valid precision: 0.876200, valid loss: 93.229824
epoch: 1356, train precision: 0.999644, train loss: 5.456312, valid precision: 0.871800, valid loss: 95.105210
epoch: 1357, train precision: 0.999600, train loss: 5.465283, valid precision: 0.876400, valid loss: 94.704634
epoch: 1358, train precision: 0.999400, train loss: 5.503969, valid precision: 0.873400, valid loss: 91.909853
epoch: 1359, train precision: 0.999467, train loss: 5.534083, valid precision: 0.876000, valid loss: 91.060121
epoch: 1360, train precision: 0.999644, train loss: 5.450889, valid precision: 0.878000, valid loss: 91.421364
epoch: 1361, train precision: 0.999378, train loss: 5.552935, valid precision: 0.875600, valid loss: 92.067291
epoch: 1362, train precision: 0.999333, train loss: 5.530954, valid precision: 0.876000, valid loss: 95.652814
epoch: 1363, train precision: 0.999133, train loss: 5.619534, valid precision: 0.876200, valid loss: 94.715592
epoch: 1364, train precision: 0.999467, train loss: 5.480058, valid precision: 0.875600, valid loss: 91.672694
epoch: 1365, train precision: 0.999400, train loss: 5.522251, valid precision: 0.874800, valid loss: 93.752418
epoch: 1366, train precision: 0.999556, train loss: 5.516369, valid precision: 0.873000, valid loss: 90.249389
epoch: 1367, train precision: 0.999778, train loss: 5.428968, valid precision: 0.874600, valid loss: 91.229113
epoch: 1368, train precision: 0.999556, train loss: 5.476845, valid precision: 0.876400, valid loss: 91.602766
epoch: 1369, train precision: 0.999511, train loss: 5.483378, valid precision: 0.877600, valid loss: 93.788134
epoch: 1370, train precision: 0.999267, train loss: 5.608480, valid precision: 0.870400, valid loss: 94.265751
epoch: 1371, train precision: 0.999422, train loss: 5.522944, valid precision: 0.876600, valid loss: 92.903399
epoch: 1372, train precision: 0.999400, train loss: 5.570940, valid precision: 0.875200, valid loss: 91.516613
epoch: 1373, train precision: 0.999333, train loss: 5.516231, valid precision: 0.876000, valid loss: 91.830045
epoch: 1374, train precision: 0.999356, train loss: 5.511361, valid precision: 0.873000, valid loss: 92.447458
epoch: 1375, train precision: 0.999511, train loss: 5.521221, valid precision: 0.870600, valid loss: 93.744772
epoch: 1376, train precision: 0.999689, train loss: 5.449455, valid precision: 0.873000, valid loss: 91.973726
epoch: 1377, train precision: 0.999489, train loss: 5.487758, valid precision: 0.876600, valid loss: 91.550805
epoch: 1378, train precision: 0.999444, train loss: 5.478240, valid precision: 0.875400, valid loss: 92.057234
epoch: 1379, train precision: 0.999667, train loss: 5.444753, valid precision: 0.876800, valid loss: 90.517404
epoch: 1380, train precision: 0.999467, train loss: 5.464344, valid precision: 0.877600, valid loss: 93.783686
epoch: 1381, train precision: 0.999533, train loss: 5.525619, valid precision: 0.873000, valid loss: 92.421370
epoch: 1382, train precision: 0.999578, train loss: 5.451489, valid precision: 0.877000, valid loss: 90.430822
epoch: 1383, train precision: 0.999489, train loss: 5.501909, valid precision: 0.878800, valid loss: 90.469960
epoch: 1384, train precision: 0.999711, train loss: 5.492040, valid precision: 0.872800, valid loss: 94.331112
epoch: 1385, train precision: 0.999289, train loss: 5.543260, valid precision: 0.875800, valid loss: 93.784049
epoch: 1386, train precision: 0.999489, train loss: 5.480102, valid precision: 0.875000, valid loss: 93.228651
epoch: 1387, train precision: 0.999356, train loss: 5.544480, valid precision: 0.873800, valid loss: 94.198283
epoch: 1388, train precision: 0.999422, train loss: 5.531757, valid precision: 0.874600, valid loss: 95.137678
epoch: 1389, train precision: 0.999533, train loss: 5.473171, valid precision: 0.873800, valid loss: 93.183282
epoch: 1390, train precision: 0.999578, train loss: 5.463758, valid precision: 0.875200, valid loss: 93.891884
epoch: 1391, train precision: 0.999556, train loss: 5.484729, valid precision: 0.874600, valid loss: 93.899984
epoch: 1392, train precision: 0.999644, train loss: 5.440214, valid precision: 0.876800, valid loss: 93.441506
epoch: 1393, train precision: 0.999489, train loss: 5.501417, valid precision: 0.871600, valid loss: 94.824170
epoch: 1394, train precision: 0.999311, train loss: 5.585697, valid precision: 0.872200, valid loss: 96.651719
epoch: 1395, train precision: 0.999533, train loss: 5.505283, valid precision: 0.873600, valid loss: 94.302221
epoch: 1396, train precision: 0.999067, train loss: 5.617935, valid precision: 0.871800, valid loss: 96.045564
epoch: 1397, train precision: 0.999333, train loss: 5.548219, valid precision: 0.875200, valid loss: 92.591459
epoch: 1398, train precision: 0.999667, train loss: 5.456006, valid precision: 0.880000, valid loss: 91.358512
epoch: 1399, train precision: 0.999556, train loss: 5.514487, valid precision: 0.877200, valid loss: 92.554194
epoch: 1400, train precision: 0.999333, train loss: 5.550621, valid precision: 0.873200, valid loss: 91.510055
epoch: 1401, train precision: 0.999667, train loss: 5.491062, valid precision: 0.874400, valid loss: 90.890495
epoch: 1402, train precision: 0.999667, train loss: 5.448124, valid precision: 0.875000, valid loss: 90.920729
epoch: 1403, train precision: 0.999556, train loss: 5.495875, valid precision: 0.873800, valid loss: 91.934205
epoch: 1404, train precision: 0.999267, train loss: 5.546128, valid precision: 0.873800, valid loss: 91.727731
epoch: 1405, train precision: 0.999578, train loss: 5.474208, valid precision: 0.873200, valid loss: 91.831103
epoch: 1406, train precision: 0.999667, train loss: 5.440600, valid precision: 0.874000, valid loss: 91.865846
epoch: 1407, train precision: 0.999467, train loss: 5.522116, valid precision: 0.875800, valid loss: 91.089589
epoch: 1408, train precision: 0.999400, train loss: 5.520484, valid precision: 0.873400, valid loss: 92.953618
epoch: 1409, train precision: 0.999178, train loss: 5.572765, valid precision: 0.873800, valid loss: 94.812111
epoch: 1410, train precision: 0.999711, train loss: 5.440464, valid precision: 0.874600, valid loss: 94.000241
epoch: 1411, train precision: 0.999511, train loss: 5.482593, valid precision: 0.875200, valid loss: 92.934918
epoch: 1412, train precision: 0.999400, train loss: 5.536570, valid precision: 0.872800, valid loss: 96.084056
epoch: 1413, train precision: 0.999356, train loss: 5.566222, valid precision: 0.879800, valid loss: 91.917420
epoch: 1414, train precision: 0.999511, train loss: 5.491217, valid precision: 0.875000, valid loss: 92.188101
epoch: 1415, train precision: 0.999600, train loss: 5.491829, valid precision: 0.875600, valid loss: 92.218658
epoch: 1416, train precision: 0.999311, train loss: 5.557094, valid precision: 0.876600, valid loss: 91.466930
epoch: 1417, train precision: 0.999733, train loss: 5.419708, valid precision: 0.878800, valid loss: 90.840353
epoch: 1418, train precision: 0.999511, train loss: 5.500782, valid precision: 0.879000, valid loss: 88.710826
epoch: 1419, train precision: 0.999422, train loss: 5.553677, valid precision: 0.878000, valid loss: 91.216709
epoch: 1420, train precision: 0.999356, train loss: 5.591529, valid precision: 0.875800, valid loss: 92.173657
epoch: 1421, train precision: 0.999600, train loss: 5.466897, valid precision: 0.878000, valid loss: 91.476235
epoch: 1422, train precision: 0.999511, train loss: 5.493257, valid precision: 0.874600, valid loss: 92.601315
epoch: 1423, train precision: 0.999711, train loss: 5.442256, valid precision: 0.879400, valid loss: 91.431455
epoch: 1424, train precision: 0.999711, train loss: 5.496265, valid precision: 0.875800, valid loss: 92.505296
epoch: 1425, train precision: 0.999511, train loss: 5.492842, valid precision: 0.876400, valid loss: 92.207813
epoch: 1426, train precision: 0.999622, train loss: 5.449703, valid precision: 0.875400, valid loss: 92.389423
epoch: 1427, train precision: 0.999622, train loss: 5.525534, valid precision: 0.875800, valid loss: 93.213367
epoch: 1428, train precision: 0.999067, train loss: 5.646142, valid precision: 0.873000, valid loss: 93.779679
epoch: 1429, train precision: 0.999533, train loss: 5.489202, valid precision: 0.874600, valid loss: 94.098414
epoch: 1430, train precision: 0.999667, train loss: 5.465253, valid precision: 0.876800, valid loss: 92.372415
epoch: 1431, train precision: 0.999622, train loss: 5.481896, valid precision: 0.873400, valid loss: 93.970244
epoch: 1432, train precision: 0.999511, train loss: 5.526588, valid precision: 0.873400, valid loss: 92.862464
epoch: 1433, train precision: 0.999311, train loss: 5.587448, valid precision: 0.871400, valid loss: 95.799706
epoch: 1434, train precision: 0.999533, train loss: 5.478567, valid precision: 0.873400, valid loss: 96.245726
epoch: 1435, train precision: 0.999622, train loss: 5.471374, valid precision: 0.877400, valid loss: 95.048022
epoch: 1436, train precision: 0.999400, train loss: 5.543879, valid precision: 0.875000, valid loss: 96.300572
epoch: 1437, train precision: 0.999689, train loss: 5.447036, valid precision: 0.875600, valid loss: 95.462972
epoch: 1438, train precision: 0.999511, train loss: 5.519001, valid precision: 0.876600, valid loss: 95.145264
epoch: 1439, train precision: 0.999711, train loss: 5.467125, valid precision: 0.877400, valid loss: 92.300753
epoch: 1440, train precision: 0.999444, train loss: 5.529757, valid precision: 0.874400, valid loss: 94.874424
epoch: 1441, train precision: 0.999533, train loss: 5.489974, valid precision: 0.874400, valid loss: 94.872549
epoch: 1442, train precision: 0.999267, train loss: 5.593289, valid precision: 0.871800, valid loss: 95.763413
epoch: 1443, train precision: 0.999244, train loss: 5.550196, valid precision: 0.874800, valid loss: 95.546554
epoch: 1444, train precision: 0.999244, train loss: 5.617291, valid precision: 0.876400, valid loss: 95.154896
epoch: 1445, train precision: 0.999511, train loss: 5.514046, valid precision: 0.872600, valid loss: 93.815736
epoch: 1446, train precision: 0.999556, train loss: 5.515334, valid precision: 0.873200, valid loss: 96.772424
epoch: 1447, train precision: 0.999867, train loss: 5.433884, valid precision: 0.874000, valid loss: 92.624570
epoch: 1448, train precision: 0.999489, train loss: 5.496759, valid precision: 0.873000, valid loss: 96.888559
epoch: 1449, train precision: 0.999378, train loss: 5.538060, valid precision: 0.874200, valid loss: 95.524004
epoch: 1450, train precision: 0.999489, train loss: 5.532097, valid precision: 0.880200, valid loss: 93.642599
epoch: 1451, train precision: 0.999400, train loss: 5.497290, valid precision: 0.875200, valid loss: 96.390186
epoch: 1452, train precision: 0.999444, train loss: 5.563283, valid precision: 0.873400, valid loss: 94.329271
epoch: 1453, train precision: 0.999756, train loss: 5.453658, valid precision: 0.878600, valid loss: 92.381159
epoch: 1454, train precision: 0.999422, train loss: 5.508991, valid precision: 0.876000, valid loss: 89.442286
epoch: 1455, train precision: 0.999311, train loss: 5.557665, valid precision: 0.873600, valid loss: 94.432690
epoch: 1456, train precision: 0.999178, train loss: 5.638845, valid precision: 0.874200, valid loss: 96.421948
epoch: 1457, train precision: 0.999467, train loss: 5.544316, valid precision: 0.875800, valid loss: 92.205269
epoch: 1458, train precision: 0.999533, train loss: 5.522225, valid precision: 0.873600, valid loss: 94.052898
epoch: 1459, train precision: 0.999378, train loss: 5.531754, valid precision: 0.875200, valid loss: 92.207382
epoch: 1460, train precision: 0.999400, train loss: 5.511630, valid precision: 0.873400, valid loss: 96.969436
epoch: 1461, train precision: 0.999311, train loss: 5.550935, valid precision: 0.870600, valid loss: 95.138886
epoch: 1462, train precision: 0.999489, train loss: 5.495232, valid precision: 0.870200, valid loss: 98.477086
epoch: 1463, train precision: 0.999622, train loss: 5.452620, valid precision: 0.874000, valid loss: 95.316884
epoch: 1464, train precision: 0.999578, train loss: 5.488164, valid precision: 0.872000, valid loss: 95.550880
epoch: 1465, train precision: 0.999667, train loss: 5.479379, valid precision: 0.875200, valid loss: 95.174079
epoch: 1466, train precision: 0.999444, train loss: 5.499001, valid precision: 0.874800, valid loss: 92.154857
epoch: 1467, train precision: 0.999333, train loss: 5.559948, valid precision: 0.870000, valid loss: 94.388407
epoch: 1468, train precision: 0.999511, train loss: 5.559986, valid precision: 0.874000, valid loss: 93.529220
epoch: 1469, train precision: 0.999644, train loss: 5.470020, valid precision: 0.874600, valid loss: 93.347210
epoch: 1470, train precision: 0.999600, train loss: 5.491699, valid precision: 0.870800, valid loss: 94.713498
epoch: 1471, train precision: 0.999600, train loss: 5.482662, valid precision: 0.873000, valid loss: 92.177605
epoch: 1472, train precision: 0.999556, train loss: 5.486651, valid precision: 0.872200, valid loss: 95.072357
epoch: 1473, train precision: 0.999511, train loss: 5.560797, valid precision: 0.868600, valid loss: 100.157729
epoch: 1474, train precision: 0.999511, train loss: 5.512923, valid precision: 0.869600, valid loss: 96.717096
epoch: 1475, train precision: 0.999133, train loss: 5.656316, valid precision: 0.871000, valid loss: 97.812689
epoch: 1476, train precision: 0.999600, train loss: 5.492873, valid precision: 0.873800, valid loss: 95.632788
epoch: 1477, train precision: 0.999444, train loss: 5.540570, valid precision: 0.874000, valid loss: 92.952007
epoch: 1478, train precision: 0.999689, train loss: 5.481443, valid precision: 0.872800, valid loss: 93.229327
epoch: 1479, train precision: 0.999644, train loss: 5.470071, valid precision: 0.874800, valid loss: 92.789788
epoch: 1480, train precision: 0.999556, train loss: 5.532025, valid precision: 0.872000, valid loss: 97.530122
epoch: 1481, train precision: 0.999444, train loss: 5.540282, valid precision: 0.871800, valid loss: 93.135392
epoch: 1482, train precision: 0.999733, train loss: 5.449463, valid precision: 0.873600, valid loss: 95.354243
epoch: 1483, train precision: 0.999644, train loss: 5.457820, valid precision: 0.874200, valid loss: 94.740303
epoch: 1484, train precision: 0.999689, train loss: 5.486056, valid precision: 0.874800, valid loss: 96.382279
epoch: 1485, train precision: 0.999644, train loss: 5.496363, valid precision: 0.871400, valid loss: 96.844596
epoch: 1486, train precision: 0.999400, train loss: 5.552065, valid precision: 0.872200, valid loss: 96.314737
epoch: 1487, train precision: 0.999622, train loss: 5.452719, valid precision: 0.875800, valid loss: 95.112323
epoch: 1488, train precision: 0.999356, train loss: 5.547773, valid precision: 0.876600, valid loss: 93.232800
epoch: 1489, train precision: 0.999511, train loss: 5.526074, valid precision: 0.872600, valid loss: 95.663702
epoch: 1490, train precision: 0.999444, train loss: 5.526473, valid precision: 0.875200, valid loss: 93.812199
epoch: 1491, train precision: 0.999356, train loss: 5.548818, valid precision: 0.873600, valid loss: 94.385809
epoch: 1492, train precision: 0.999667, train loss: 5.456218, valid precision: 0.877800, valid loss: 93.877144
epoch: 1493, train precision: 0.999489, train loss: 5.519588, valid precision: 0.878000, valid loss: 95.556949
epoch: 1494, train precision: 0.999578, train loss: 5.501149, valid precision: 0.874600, valid loss: 96.148585
epoch: 1495, train precision: 0.999556, train loss: 5.508259, valid precision: 0.871000, valid loss: 96.010086
epoch: 1496, train precision: 0.999356, train loss: 5.537788, valid precision: 0.877200, valid loss: 94.856551
epoch: 1497, train precision: 0.999533, train loss: 5.529825, valid precision: 0.874000, valid loss: 95.052182
epoch: 1498, train precision: 0.999578, train loss: 5.542198, valid precision: 0.875400, valid loss: 96.602217
epoch: 1499, train precision: 0.999578, train loss: 5.483056, valid precision: 0.877200, valid loss: 95.136997
epoch: 1500, train precision: 0.999667, train loss: 5.511784, valid precision: 0.876400, valid loss: 93.980778
epoch: 1501, train precision: 0.999311, train loss: 5.575732, valid precision: 0.873000, valid loss: 95.648036
epoch: 1502, train precision: 0.999444, train loss: 5.535222, valid precision: 0.874200, valid loss: 95.039412
epoch: 1503, train precision: 0.999511, train loss: 5.530082, valid precision: 0.873400, valid loss: 93.152336
epoch: 1504, train precision: 0.999622, train loss: 5.523227, valid precision: 0.875600, valid loss: 94.509340
epoch: 1505, train precision: 0.999222, train loss: 5.595866, valid precision: 0.873800, valid loss: 94.285594
epoch: 1506, train precision: 0.999600, train loss: 5.475734, valid precision: 0.874400, valid loss: 94.665368
epoch: 1507, train precision: 0.999533, train loss: 5.538107, valid precision: 0.878800, valid loss: 93.353384
epoch: 1508, train precision: 0.999644, train loss: 5.490878, valid precision: 0.873000, valid loss: 95.260315
epoch: 1509, train precision: 0.999378, train loss: 5.544144, valid precision: 0.874800, valid loss: 95.498484
epoch: 1510, train precision: 0.999378, train loss: 5.575882, valid precision: 0.877400, valid loss: 92.438423
epoch: 1511, train precision: 0.999467, train loss: 5.539331, valid precision: 0.875200, valid loss: 94.809486
epoch: 1512, train precision: 0.999378, train loss: 5.605082, valid precision: 0.874600, valid loss: 94.532358
epoch: 1513, train precision: 0.999556, train loss: 5.502020, valid precision: 0.875000, valid loss: 91.719423
epoch: 1514, train precision: 0.999511, train loss: 5.503994, valid precision: 0.878000, valid loss: 95.078930
epoch: 1515, train precision: 0.999578, train loss: 5.494425, valid precision: 0.877600, valid loss: 92.614131
epoch: 1516, train precision: 0.999556, train loss: 5.490827, valid precision: 0.875600, valid loss: 93.966576
epoch: 1517, train precision: 0.999444, train loss: 5.567400, valid precision: 0.876000, valid loss: 93.246941
epoch: 1518, train precision: 0.999444, train loss: 5.533181, valid precision: 0.875400, valid loss: 93.464648
epoch: 1519, train precision: 0.999733, train loss: 5.492360, valid precision: 0.876800, valid loss: 91.042706
epoch: 1520, train precision: 0.999622, train loss: 5.465871, valid precision: 0.878600, valid loss: 93.153200
epoch: 1521, train precision: 0.999733, train loss: 5.489081, valid precision: 0.878200, valid loss: 93.603425
epoch: 1522, train precision: 0.999622, train loss: 5.475463, valid precision: 0.877000, valid loss: 93.709809
epoch: 1523, train precision: 0.999600, train loss: 5.513107, valid precision: 0.871600, valid loss: 92.611377
epoch: 1524, train precision: 0.999644, train loss: 5.517512, valid precision: 0.875800, valid loss: 95.361166
epoch: 1525, train precision: 0.999467, train loss: 5.517225, valid precision: 0.872600, valid loss: 93.891793
epoch: 1526, train precision: 0.999533, train loss: 5.514955, valid precision: 0.877600, valid loss: 94.371824
epoch: 1527, train precision: 0.999244, train loss: 5.583007, valid precision: 0.871800, valid loss: 96.724109
epoch: 1528, train precision: 0.999578, train loss: 5.506569, valid precision: 0.876600, valid loss: 94.366018
epoch: 1529, train precision: 0.999200, train loss: 5.610968, valid precision: 0.878000, valid loss: 96.223726
epoch: 1530, train precision: 0.999356, train loss: 5.572498, valid precision: 0.876200, valid loss: 94.326549
epoch: 1531, train precision: 0.999622, train loss: 5.472025, valid precision: 0.879000, valid loss: 92.378743
epoch: 1532, train precision: 0.999578, train loss: 5.479946, valid precision: 0.876200, valid loss: 92.100577
epoch: 1533, train precision: 0.999578, train loss: 5.526922, valid precision: 0.875600, valid loss: 95.204202
epoch: 1534, train precision: 0.999333, train loss: 5.550773, valid precision: 0.877200, valid loss: 94.561491
epoch: 1535, train precision: 0.999489, train loss: 5.557054, valid precision: 0.874800, valid loss: 95.629591
epoch: 1536, train precision: 0.999600, train loss: 5.473047, valid precision: 0.877400, valid loss: 94.937585
epoch: 1537, train precision: 0.999467, train loss: 5.543381, valid precision: 0.872400, valid loss: 95.949980
epoch: 1538, train precision: 0.999467, train loss: 5.545653, valid precision: 0.877000, valid loss: 91.806391
epoch: 1539, train precision: 0.999467, train loss: 5.550192, valid precision: 0.872600, valid loss: 94.648377
epoch: 1540, train precision: 0.999556, train loss: 5.520634, valid precision: 0.872600, valid loss: 96.221083
epoch: 1541, train precision: 0.999556, train loss: 5.502048, valid precision: 0.875000, valid loss: 94.090617
epoch: 1542, train precision: 0.999333, train loss: 5.546550, valid precision: 0.872200, valid loss: 92.654378
epoch: 1543, train precision: 0.999489, train loss: 5.546546, valid precision: 0.878200, valid loss: 92.938878
epoch: 1544, train precision: 0.999422, train loss: 5.560938, valid precision: 0.873800, valid loss: 95.227776
epoch: 1545, train precision: 0.999711, train loss: 5.482612, valid precision: 0.875000, valid loss: 96.283760
epoch: 1546, train precision: 0.999533, train loss: 5.540734, valid precision: 0.879800, valid loss: 93.486632
epoch: 1547, train precision: 0.999511, train loss: 5.497516, valid precision: 0.877800, valid loss: 91.416905
epoch: 1548, train precision: 0.999689, train loss: 5.480407, valid precision: 0.877200, valid loss: 92.810461
epoch: 1549, train precision: 0.999600, train loss: 5.523404, valid precision: 0.876200, valid loss: 94.322403
epoch: 1550, train precision: 0.999644, train loss: 5.446795, valid precision: 0.878000, valid loss: 95.272399
epoch: 1551, train precision: 0.999644, train loss: 5.480674, valid precision: 0.877600, valid loss: 93.491140
epoch: 1552, train precision: 0.999689, train loss: 5.453213, valid precision: 0.877800, valid loss: 94.918903
epoch: 1553, train precision: 0.999111, train loss: 5.648984, valid precision: 0.875200, valid loss: 94.146983
epoch: 1554, train precision: 0.999600, train loss: 5.472738, valid precision: 0.875400, valid loss: 94.003051
epoch: 1555, train precision: 0.999267, train loss: 5.594397, valid precision: 0.877800, valid loss: 92.697559
epoch: 1556, train precision: 0.999311, train loss: 5.533216, valid precision: 0.876200, valid loss: 94.855524
epoch: 1557, train precision: 0.999378, train loss: 5.524399, valid precision: 0.871600, valid loss: 95.722084
epoch: 1558, train precision: 0.999378, train loss: 5.555812, valid precision: 0.875400, valid loss: 95.457622
epoch: 1559, train precision: 0.999511, train loss: 5.543911, valid precision: 0.874600, valid loss: 93.852817
epoch: 1560, train precision: 0.999489, train loss: 5.513421, valid precision: 0.877000, valid loss: 96.196945
epoch: 1561, train precision: 0.999600, train loss: 5.493023, valid precision: 0.876800, valid loss: 95.032379
epoch: 1562, train precision: 0.999711, train loss: 5.463363, valid precision: 0.874200, valid loss: 93.952783
epoch: 1563, train precision: 0.999622, train loss: 5.467258, valid precision: 0.877200, valid loss: 92.924441
epoch: 1564, train precision: 0.999667, train loss: 5.469277, valid precision: 0.873600, valid loss: 95.472294
epoch: 1565, train precision: 0.999556, train loss: 5.501530, valid precision: 0.876800, valid loss: 91.730519
epoch: 1566, train precision: 0.999600, train loss: 5.526457, valid precision: 0.873200, valid loss: 95.897084
epoch: 1567, train precision: 0.999422, train loss: 5.555798, valid precision: 0.874400, valid loss: 94.405554
epoch: 1568, train precision: 0.999578, train loss: 5.487460, valid precision: 0.872200, valid loss: 94.455647
epoch: 1569, train precision: 0.999644, train loss: 5.492657, valid precision: 0.875800, valid loss: 92.415997
epoch: 1570, train precision: 0.999578, train loss: 5.495054, valid precision: 0.872200, valid loss: 94.401898
epoch: 1571, train precision: 0.999533, train loss: 5.525864, valid precision: 0.875000, valid loss: 94.145930
epoch: 1572, train precision: 0.999578, train loss: 5.517621, valid precision: 0.874600, valid loss: 91.883995
epoch: 1573, train precision: 0.999600, train loss: 5.499749, valid precision: 0.875600, valid loss: 91.714446
epoch: 1574, train precision: 0.999467, train loss: 5.517695, valid precision: 0.875400, valid loss: 94.099062
epoch: 1575, train precision: 0.999356, train loss: 5.508224, valid precision: 0.880200, valid loss: 93.915601
epoch: 1576, train precision: 0.999378, train loss: 5.555128, valid precision: 0.876000, valid loss: 91.995979
epoch: 1577, train precision: 0.999600, train loss: 5.487319, valid precision: 0.875600, valid loss: 94.101942
epoch: 1578, train precision: 0.999622, train loss: 5.530249, valid precision: 0.872000, valid loss: 92.201286
epoch: 1579, train precision: 0.999267, train loss: 5.632807, valid precision: 0.873200, valid loss: 91.601867
epoch: 1580, train precision: 0.999667, train loss: 5.459915, valid precision: 0.876600, valid loss: 91.535207
epoch: 1581, train precision: 0.999444, train loss: 5.608527, valid precision: 0.877400, valid loss: 92.294669
epoch: 1582, train precision: 0.999578, train loss: 5.557552, valid precision: 0.875400, valid loss: 94.042729
epoch: 1583, train precision: 0.999622, train loss: 5.478007, valid precision: 0.876800, valid loss: 94.186821
epoch: 1584, train precision: 0.999556, train loss: 5.551036, valid precision: 0.877000, valid loss: 97.321035
epoch: 1585, train precision: 0.999600, train loss: 5.530757, valid precision: 0.876000, valid loss: 92.996583
epoch: 1586, train precision: 0.999578, train loss: 5.552307, valid precision: 0.877800, valid loss: 93.499584
epoch: 1587, train precision: 0.999556, train loss: 5.559685, valid precision: 0.878400, valid loss: 93.212978
epoch: 1588, train precision: 0.999689, train loss: 5.470080, valid precision: 0.876200, valid loss: 91.832164
epoch: 1589, train precision: 0.999667, train loss: 5.464870, valid precision: 0.878400, valid loss: 94.632026
epoch: 1590, train precision: 0.999422, train loss: 5.552748, valid precision: 0.878200, valid loss: 95.299862
epoch: 1591, train precision: 0.999600, train loss: 5.520867, valid precision: 0.876400, valid loss: 94.306102
epoch: 1592, train precision: 0.999800, train loss: 5.449059, valid precision: 0.875800, valid loss: 92.850277
epoch: 1593, train precision: 0.999444, train loss: 5.581339, valid precision: 0.876800, valid loss: 95.726374
epoch: 1594, train precision: 0.999533, train loss: 5.512751, valid precision: 0.876600, valid loss: 95.969876
epoch: 1595, train precision: 0.999533, train loss: 5.536758, valid precision: 0.877000, valid loss: 94.024738
epoch: 1596, train precision: 0.999578, train loss: 5.535346, valid precision: 0.876200, valid loss: 94.891767
epoch: 1597, train precision: 0.999489, train loss: 5.517669, valid precision: 0.875200, valid loss: 94.948424
epoch: 1598, train precision: 0.999644, train loss: 5.487014, valid precision: 0.879600, valid loss: 95.218952
epoch: 1599, train precision: 0.999578, train loss: 5.500942, valid precision: 0.877400, valid loss: 95.521644
epoch: 1600, train precision: 0.999511, train loss: 5.562945, valid precision: 0.871200, valid loss: 97.683051
epoch: 1601, train precision: 0.999422, train loss: 5.626858, valid precision: 0.876000, valid loss: 96.246553
epoch: 1602, train precision: 0.999400, train loss: 5.576977, valid precision: 0.876000, valid loss: 94.347169
epoch: 1603, train precision: 0.999533, train loss: 5.519597, valid precision: 0.871800, valid loss: 92.837333
epoch: 1604, train precision: 0.999422, train loss: 5.531967, valid precision: 0.875000, valid loss: 91.858934
epoch: 1605, train precision: 0.999578, train loss: 5.502476, valid precision: 0.875800, valid loss: 93.469196
epoch: 1606, train precision: 0.999533, train loss: 5.556275, valid precision: 0.875400, valid loss: 93.349326
epoch: 1607, train precision: 0.999578, train loss: 5.482172, valid precision: 0.877800, valid loss: 94.888880
epoch: 1608, train precision: 0.999489, train loss: 5.547177, valid precision: 0.877400, valid loss: 93.429079
epoch: 1609, train precision: 0.999644, train loss: 5.518812, valid precision: 0.875800, valid loss: 93.818241
epoch: 1610, train precision: 0.999556, train loss: 5.513810, valid precision: 0.876400, valid loss: 92.924640
epoch: 1611, train precision: 0.999578, train loss: 5.525941, valid precision: 0.874000, valid loss: 94.655505
epoch: 1612, train precision: 0.999556, train loss: 5.504797, valid precision: 0.873800, valid loss: 92.788228
epoch: 1613, train precision: 0.999467, train loss: 5.534766, valid precision: 0.876400, valid loss: 94.864218
epoch: 1614, train precision: 0.999556, train loss: 5.509854, valid precision: 0.874600, valid loss: 98.087497
epoch: 1615, train precision: 0.999600, train loss: 5.518907, valid precision: 0.873200, valid loss: 94.857787
epoch: 1616, train precision: 0.999600, train loss: 5.503338, valid precision: 0.875600, valid loss: 95.171965
epoch: 1617, train precision: 0.999333, train loss: 5.537748, valid precision: 0.875600, valid loss: 95.149866
epoch: 1618, train precision: 0.999289, train loss: 5.582884, valid precision: 0.875800, valid loss: 92.242805
epoch: 1619, train precision: 0.999689, train loss: 5.506309, valid precision: 0.877800, valid loss: 92.645430
epoch: 1620, train precision: 0.999600, train loss: 5.521285, valid precision: 0.872200, valid loss: 95.237214
epoch: 1621, train precision: 0.999356, train loss: 5.585112, valid precision: 0.870400, valid loss: 97.271117
epoch: 1622, train precision: 0.999644, train loss: 5.503260, valid precision: 0.872200, valid loss: 95.068425
epoch: 1623, train precision: 0.999622, train loss: 5.516065, valid precision: 0.876200, valid loss: 93.384181
epoch: 1624, train precision: 0.999622, train loss: 5.490645, valid precision: 0.869600, valid loss: 96.559263
epoch: 1625, train precision: 0.999444, train loss: 5.531685, valid precision: 0.871200, valid loss: 96.147723
epoch: 1626, train precision: 0.999600, train loss: 5.479670, valid precision: 0.875400, valid loss: 94.991110
epoch: 1627, train precision: 0.999244, train loss: 5.567899, valid precision: 0.872600, valid loss: 97.203810
epoch: 1628, train precision: 0.999667, train loss: 5.489234, valid precision: 0.874400, valid loss: 94.532907
epoch: 1629, train precision: 0.999867, train loss: 5.453975, valid precision: 0.876400, valid loss: 96.417220
epoch: 1630, train precision: 0.999533, train loss: 5.516735, valid precision: 0.874200, valid loss: 94.545624
epoch: 1631, train precision: 0.999600, train loss: 5.524965, valid precision: 0.874200, valid loss: 95.634870
epoch: 1632, train precision: 0.999711, train loss: 5.489142, valid precision: 0.875200, valid loss: 92.786771
epoch: 1633, train precision: 0.999533, train loss: 5.531721, valid precision: 0.874200, valid loss: 96.060350
epoch: 1634, train precision: 0.999444, train loss: 5.570773, valid precision: 0.874000, valid loss: 100.086395
epoch: 1635, train precision: 0.999333, train loss: 5.593000, valid precision: 0.871800, valid loss: 97.476445
epoch: 1636, train precision: 0.999422, train loss: 5.538580, valid precision: 0.875400, valid loss: 95.855144
epoch: 1637, train precision: 0.999600, train loss: 5.508152, valid precision: 0.874400, valid loss: 95.801995
epoch: 1638, train precision: 0.999444, train loss: 5.565090, valid precision: 0.872200, valid loss: 95.573390
epoch: 1639, train precision: 0.999511, train loss: 5.529893, valid precision: 0.869400, valid loss: 95.903970
epoch: 1640, train precision: 0.999600, train loss: 5.520164, valid precision: 0.876200, valid loss: 95.061749
epoch: 1641, train precision: 0.999556, train loss: 5.512372, valid precision: 0.875000, valid loss: 96.445559
epoch: 1642, train precision: 0.999378, train loss: 5.566086, valid precision: 0.873200, valid loss: 97.203420
epoch: 1643, train precision: 0.999778, train loss: 5.459949, valid precision: 0.872400, valid loss: 97.898543
epoch: 1644, train precision: 0.999756, train loss: 5.464541, valid precision: 0.872400, valid loss: 96.366947
epoch: 1645, train precision: 0.999533, train loss: 5.502133, valid precision: 0.875400, valid loss: 96.086250
epoch: 1646, train precision: 0.999511, train loss: 5.563301, valid precision: 0.870000, valid loss: 96.559180
epoch: 1647, train precision: 0.999556, train loss: 5.525430, valid precision: 0.875000, valid loss: 95.996722
epoch: 1648, train precision: 0.999778, train loss: 5.445373, valid precision: 0.873400, valid loss: 97.599300
epoch: 1649, train precision: 0.999533, train loss: 5.517367, valid precision: 0.873400, valid loss: 97.138084
epoch: 1650, train precision: 0.999378, train loss: 5.555016, valid precision: 0.871800, valid loss: 99.230652
epoch: 1651, train precision: 0.999756, train loss: 5.461272, valid precision: 0.872200, valid loss: 97.231687
epoch: 1652, train precision: 0.999556, train loss: 5.524108, valid precision: 0.867800, valid loss: 99.381463
epoch: 1653, train precision: 0.999733, train loss: 5.504466, valid precision: 0.873400, valid loss: 98.449359
epoch: 1654, train precision: 0.999600, train loss: 5.512437, valid precision: 0.872400, valid loss: 97.300635
epoch: 1655, train precision: 0.999044, train loss: 5.680285, valid precision: 0.875600, valid loss: 96.868977
epoch: 1656, train precision: 0.999667, train loss: 5.482712, valid precision: 0.874800, valid loss: 97.515428
epoch: 1657, train precision: 0.999733, train loss: 5.473676, valid precision: 0.875200, valid loss: 98.099015
epoch: 1658, train precision: 0.999800, train loss: 5.474712, valid precision: 0.872200, valid loss: 97.474578
epoch: 1659, train precision: 0.999444, train loss: 5.512504, valid precision: 0.872600, valid loss: 98.644389
epoch: 1660, train precision: 0.999511, train loss: 5.521059, valid precision: 0.875200, valid loss: 96.020503
epoch: 1661, train precision: 0.999667, train loss: 5.491287, valid precision: 0.877400, valid loss: 93.973889
epoch: 1662, train precision: 0.999422, train loss: 5.534460, valid precision: 0.873600, valid loss: 96.700023
epoch: 1663, train precision: 0.999622, train loss: 5.507416, valid precision: 0.878000, valid loss: 95.656124
epoch: 1664, train precision: 0.999600, train loss: 5.505365, valid precision: 0.875800, valid loss: 95.997883
epoch: 1665, train precision: 0.999422, train loss: 5.553665, valid precision: 0.875400, valid loss: 96.222050
epoch: 1666, train precision: 0.999711, train loss: 5.470482, valid precision: 0.878600, valid loss: 93.089939
epoch: 1667, train precision: 0.999578, train loss: 5.507971, valid precision: 0.878000, valid loss: 95.980691
epoch: 1668, train precision: 0.999800, train loss: 5.444742, valid precision: 0.878600, valid loss: 93.134207
epoch: 1669, train precision: 0.999356, train loss: 5.643947, valid precision: 0.881600, valid loss: 95.215301
epoch: 1670, train precision: 0.999556, train loss: 5.528777, valid precision: 0.876600, valid loss: 93.602251
epoch: 1671, train precision: 0.999578, train loss: 5.517941, valid precision: 0.880800, valid loss: 92.917797
epoch: 1672, train precision: 0.999400, train loss: 5.535826, valid precision: 0.878200, valid loss: 95.186796
epoch: 1673, train precision: 0.999400, train loss: 5.541362, valid precision: 0.878800, valid loss: 92.637550
epoch: 1674, train precision: 0.999533, train loss: 5.544808, valid precision: 0.880200, valid loss: 93.990924
epoch: 1675, train precision: 0.999711, train loss: 5.483339, valid precision: 0.878000, valid loss: 92.143561
epoch: 1676, train precision: 0.999489, train loss: 5.556245, valid precision: 0.876600, valid loss: 94.241866
epoch: 1677, train precision: 0.999578, train loss: 5.501963, valid precision: 0.880600, valid loss: 91.800078
epoch: 1678, train precision: 0.999800, train loss: 5.441105, valid precision: 0.878000, valid loss: 92.449320
epoch: 1679, train precision: 0.999689, train loss: 5.481761, valid precision: 0.879000, valid loss: 92.948476
epoch: 1680, train precision: 0.999600, train loss: 5.511716, valid precision: 0.880200, valid loss: 91.684113
epoch: 1681, train precision: 0.999444, train loss: 5.518859, valid precision: 0.879200, valid loss: 95.795543
epoch: 1682, train precision: 0.999644, train loss: 5.485435, valid precision: 0.878800, valid loss: 93.080258
epoch: 1683, train precision: 0.999600, train loss: 5.505647, valid precision: 0.877400, valid loss: 95.173749
epoch: 1684, train precision: 0.999689, train loss: 5.507037, valid precision: 0.881600, valid loss: 91.865347
epoch: 1685, train precision: 0.999711, train loss: 5.459780, valid precision: 0.878200, valid loss: 94.085623
epoch: 1686, train precision: 0.999578, train loss: 5.492844, valid precision: 0.876400, valid loss: 96.798188
epoch: 1687, train precision: 0.999467, train loss: 5.524714, valid precision: 0.878200, valid loss: 95.020166
epoch: 1688, train precision: 0.999533, train loss: 5.504263, valid precision: 0.876000, valid loss: 94.485371
epoch: 1689, train precision: 0.999578, train loss: 5.518454, valid precision: 0.876600, valid loss: 96.085151
epoch: 1690, train precision: 0.999467, train loss: 5.520127, valid precision: 0.877200, valid loss: 93.820540
epoch: 1691, train precision: 0.999644, train loss: 5.473725, valid precision: 0.878800, valid loss: 94.159724
epoch: 1692, train precision: 0.999044, train loss: 5.623585, valid precision: 0.874800, valid loss: 97.755038
epoch: 1693, train precision: 0.999556, train loss: 5.522527, valid precision: 0.875400, valid loss: 96.178621
epoch: 1694, train precision: 0.999378, train loss: 5.549819, valid precision: 0.875800, valid loss: 94.489240
epoch: 1695, train precision: 0.999511, train loss: 5.534666, valid precision: 0.874800, valid loss: 95.288243
epoch: 1696, train precision: 0.999600, train loss: 5.498261, valid precision: 0.878000, valid loss: 95.356234
epoch: 1697, train precision: 0.999600, train loss: 5.487983, valid precision: 0.874400, valid loss: 93.954025
epoch: 1698, train precision: 0.999644, train loss: 5.482366, valid precision: 0.875800, valid loss: 93.703417
epoch: 1699, train precision: 0.999689, train loss: 5.469592, valid precision: 0.876200, valid loss: 93.219821
epoch: 1700, train precision: 0.999644, train loss: 5.518987, valid precision: 0.878200, valid loss: 93.484278
epoch: 1701, train precision: 0.999556, train loss: 5.555133, valid precision: 0.877400, valid loss: 91.047384
epoch: 1702, train precision: 0.999578, train loss: 5.536355, valid precision: 0.875800, valid loss: 93.867648
epoch: 1703, train precision: 0.999578, train loss: 5.546667, valid precision: 0.875400, valid loss: 92.513027
epoch: 1704, train precision: 0.999689, train loss: 5.490515, valid precision: 0.873600, valid loss: 93.387537
epoch: 1705, train precision: 0.999667, train loss: 5.491815, valid precision: 0.876600, valid loss: 93.641641
epoch: 1706, train precision: 0.999511, train loss: 5.514228, valid precision: 0.875200, valid loss: 94.621312
epoch: 1707, train precision: 0.999467, train loss: 5.495562, valid precision: 0.876800, valid loss: 92.783196
epoch: 1708, train precision: 0.999578, train loss: 5.495826, valid precision: 0.877600, valid loss: 93.875078
epoch: 1709, train precision: 0.999667, train loss: 5.551158, valid precision: 0.876600, valid loss: 96.962507
epoch: 1710, train precision: 0.999644, train loss: 5.497902, valid precision: 0.875000, valid loss: 95.725013
epoch: 1711, train precision: 0.999578, train loss: 5.547255, valid precision: 0.872200, valid loss: 98.269573
epoch: 1712, train precision: 0.999489, train loss: 5.539761, valid precision: 0.872200, valid loss: 95.294866
epoch: 1713, train precision: 0.999311, train loss: 5.623374, valid precision: 0.874600, valid loss: 99.582029
epoch: 1714, train precision: 0.999733, train loss: 5.490085, valid precision: 0.881400, valid loss: 94.995832
epoch: 1715, train precision: 0.999511, train loss: 5.548379, valid precision: 0.877600, valid loss: 92.275875
epoch: 1716, train precision: 0.999489, train loss: 5.583772, valid precision: 0.873400, valid loss: 93.616165
epoch: 1717, train precision: 0.999533, train loss: 5.533882, valid precision: 0.877400, valid loss: 92.780184
epoch: 1718, train precision: 0.999689, train loss: 5.528506, valid precision: 0.875800, valid loss: 92.382362
epoch: 1719, train precision: 0.999533, train loss: 5.561400, valid precision: 0.872400, valid loss: 92.496358
epoch: 1720, train precision: 0.999533, train loss: 5.543015, valid precision: 0.875200, valid loss: 95.082975
epoch: 1721, train precision: 0.999711, train loss: 5.500047, valid precision: 0.876000, valid loss: 92.913998
epoch: 1722, train precision: 0.999489, train loss: 5.562703, valid precision: 0.872400, valid loss: 93.903019
epoch: 1723, train precision: 0.999756, train loss: 5.460095, valid precision: 0.879000, valid loss: 94.889635
epoch: 1724, train precision: 0.999600, train loss: 5.525235, valid precision: 0.878800, valid loss: 93.770360
epoch: 1725, train precision: 0.999711, train loss: 5.515677, valid precision: 0.878600, valid loss: 94.775651
epoch: 1726, train precision: 0.999622, train loss: 5.493098, valid precision: 0.874400, valid loss: 93.731946
epoch: 1727, train precision: 0.999289, train loss: 5.650448, valid precision: 0.877400, valid loss: 93.927579
epoch: 1728, train precision: 0.999711, train loss: 5.469178, valid precision: 0.878600, valid loss: 91.709519
epoch: 1729, train precision: 0.999689, train loss: 5.498480, valid precision: 0.876400, valid loss: 92.545649
epoch: 1730, train precision: 0.999622, train loss: 5.552382, valid precision: 0.879600, valid loss: 94.868164
epoch: 1731, train precision: 0.999511, train loss: 5.527339, valid precision: 0.873400, valid loss: 94.300518
epoch: 1732, train precision: 0.999600, train loss: 5.496047, valid precision: 0.880000, valid loss: 91.579121
epoch: 1733, train precision: 0.999444, train loss: 5.562265, valid precision: 0.875200, valid loss: 95.525254
epoch: 1734, train precision: 0.999689, train loss: 5.479142, valid precision: 0.876800, valid loss: 94.665312
epoch: 1735, train precision: 0.999333, train loss: 5.643039, valid precision: 0.878600, valid loss: 94.917958
epoch: 1736, train precision: 0.999667, train loss: 5.497881, valid precision: 0.879000, valid loss: 97.167768
epoch: 1737, train precision: 0.999756, train loss: 5.458920, valid precision: 0.879400, valid loss: 95.873030
epoch: 1738, train precision: 0.999444, train loss: 5.568529, valid precision: 0.876600, valid loss: 96.578728
epoch: 1739, train precision: 0.999467, train loss: 5.527324, valid precision: 0.880800, valid loss: 95.632460
epoch: 1740, train precision: 0.999444, train loss: 5.523618, valid precision: 0.881400, valid loss: 93.282917
epoch: 1741, train precision: 0.999622, train loss: 5.543665, valid precision: 0.877800, valid loss: 94.191976
epoch: 1742, train precision: 0.999644, train loss: 5.507439, valid precision: 0.879200, valid loss: 92.633817
epoch: 1743, train precision: 0.999600, train loss: 5.521149, valid precision: 0.882200, valid loss: 91.985649
epoch: 1744, train precision: 0.999311, train loss: 5.590180, valid precision: 0.877400, valid loss: 95.335535
epoch: 1745, train precision: 0.999444, train loss: 5.580370, valid precision: 0.877600, valid loss: 93.739127
epoch: 1746, train precision: 0.999489, train loss: 5.520252, valid precision: 0.877800, valid loss: 94.931415
epoch: 1747, train precision: 0.999444, train loss: 5.546868, valid precision: 0.876800, valid loss: 93.027445
epoch: 1748, train precision: 0.999667, train loss: 5.519994, valid precision: 0.877600, valid loss: 90.660032
epoch: 1749, train precision: 0.999711, train loss: 5.491259, valid precision: 0.876600, valid loss: 93.649213
epoch: 1750, train precision: 0.999778, train loss: 5.480152, valid precision: 0.876600, valid loss: 93.159923
epoch: 1751, train precision: 0.999644, train loss: 5.482786, valid precision: 0.878600, valid loss: 90.611806
epoch: 1752, train precision: 0.999400, train loss: 5.546023, valid precision: 0.877400, valid loss: 95.602150
epoch: 1753, train precision: 0.999711, train loss: 5.514778, valid precision: 0.877200, valid loss: 91.309216
epoch: 1754, train precision: 0.999533, train loss: 5.528431, valid precision: 0.878400, valid loss: 90.172980
epoch: 1755, train precision: 0.999489, train loss: 5.522729, valid precision: 0.878400, valid loss: 90.666870
epoch: 1756, train precision: 0.999644, train loss: 5.522274, valid precision: 0.879200, valid loss: 92.547150
epoch: 1757, train precision: 0.999489, train loss: 5.523573, valid precision: 0.877000, valid loss: 94.143700
epoch: 1758, train precision: 0.999378, train loss: 5.605643, valid precision: 0.875400, valid loss: 94.070921
epoch: 1759, train precision: 0.999667, train loss: 5.500639, valid precision: 0.877400, valid loss: 92.874172
epoch: 1760, train precision: 0.999444, train loss: 5.577254, valid precision: 0.874000, valid loss: 94.488376
epoch: 1761, train precision: 0.999600, train loss: 5.521804, valid precision: 0.872800, valid loss: 97.877570
epoch: 1762, train precision: 0.999600, train loss: 5.493078, valid precision: 0.877400, valid loss: 93.678105
epoch: 1763, train precision: 0.999778, train loss: 5.459103, valid precision: 0.874800, valid loss: 95.094408
epoch: 1764, train precision: 0.999644, train loss: 5.512131, valid precision: 0.877000, valid loss: 94.826768
epoch: 1765, train precision: 0.999533, train loss: 5.511870, valid precision: 0.876800, valid loss: 94.605205
epoch: 1766, train precision: 0.999578, train loss: 5.523642, valid precision: 0.877800, valid loss: 95.148372
epoch: 1767, train precision: 0.999756, train loss: 5.473898, valid precision: 0.877000, valid loss: 93.535294
epoch: 1768, train precision: 0.999667, train loss: 5.496213, valid precision: 0.875200, valid loss: 95.548660
epoch: 1769, train precision: 0.999533, train loss: 5.529202, valid precision: 0.874600, valid loss: 95.717315
epoch: 1770, train precision: 0.999600, train loss: 5.505863, valid precision: 0.874800, valid loss: 96.415662
epoch: 1771, train precision: 0.999667, train loss: 5.508097, valid precision: 0.873000, valid loss: 96.675241
epoch: 1772, train precision: 0.999622, train loss: 5.502816, valid precision: 0.877400, valid loss: 95.316805
epoch: 1773, train precision: 0.999578, train loss: 5.490017, valid precision: 0.880600, valid loss: 92.505391
epoch: 1774, train precision: 0.999622, train loss: 5.521202, valid precision: 0.877200, valid loss: 93.249941
epoch: 1775, train precision: 0.999711, train loss: 5.473566, valid precision: 0.876400, valid loss: 94.599348
epoch: 1776, train precision: 0.999556, train loss: 5.523630, valid precision: 0.876000, valid loss: 94.964994
epoch: 1777, train precision: 0.999467, train loss: 5.557499, valid precision: 0.875200, valid loss: 97.583174
epoch: 1778, train precision: 0.999622, train loss: 5.507051, valid precision: 0.874800, valid loss: 94.067922
epoch: 1779, train precision: 0.999822, train loss: 5.459220, valid precision: 0.880000, valid loss: 91.623418
epoch: 1780, train precision: 0.999711, train loss: 5.492722, valid precision: 0.878600, valid loss: 92.589861
epoch: 1781, train precision: 0.999622, train loss: 5.487427, valid precision: 0.876400, valid loss: 93.644826
epoch: 1782, train precision: 0.999533, train loss: 5.532159, valid precision: 0.875600, valid loss: 94.154742
epoch: 1783, train precision: 0.999600, train loss: 5.519268, valid precision: 0.879000, valid loss: 91.491873
epoch: 1784, train precision: 0.999644, train loss: 5.524833, valid precision: 0.877000, valid loss: 95.586068
epoch: 1785, train precision: 0.999667, train loss: 5.489382, valid precision: 0.874200, valid loss: 94.409227
epoch: 1786, train precision: 0.999511, train loss: 5.561752, valid precision: 0.876000, valid loss: 95.648815
epoch: 1787, train precision: 0.999733, train loss: 5.470568, valid precision: 0.878800, valid loss: 92.500328
epoch: 1788, train precision: 0.999489, train loss: 5.524723, valid precision: 0.879600, valid loss: 92.131375
epoch: 1789, train precision: 0.999667, train loss: 5.464450, valid precision: 0.877600, valid loss: 95.706290
epoch: 1790, train precision: 0.999733, train loss: 5.454429, valid precision: 0.878200, valid loss: 95.589236
epoch: 1791, train precision: 0.999578, train loss: 5.522898, valid precision: 0.876400, valid loss: 95.279091
epoch: 1792, train precision: 0.999578, train loss: 5.523502, valid precision: 0.881000, valid loss: 93.227466
epoch: 1793, train precision: 0.999556, train loss: 5.538337, valid precision: 0.876200, valid loss: 95.968099
epoch: 1794, train precision: 0.999511, train loss: 5.571056, valid precision: 0.877200, valid loss: 96.386529
epoch: 1795, train precision: 0.999622, train loss: 5.545193, valid precision: 0.875400, valid loss: 96.139218
epoch: 1796, train precision: 0.999733, train loss: 5.467943, valid precision: 0.876800, valid loss: 93.944562
epoch: 1797, train precision: 0.999733, train loss: 5.495211, valid precision: 0.877600, valid loss: 92.702474
epoch: 1798, train precision: 0.999444, train loss: 5.560140, valid precision: 0.878800, valid loss: 93.980573
epoch: 1799, train precision: 0.999644, train loss: 5.491693, valid precision: 0.874400, valid loss: 95.155552
epoch: 1800, train precision: 0.999533, train loss: 5.594832, valid precision: 0.879800, valid loss: 93.903896
epoch: 1801, train precision: 0.999622, train loss: 5.505791, valid precision: 0.876600, valid loss: 94.009344
epoch: 1802, train precision: 0.999667, train loss: 5.485932, valid precision: 0.879200, valid loss: 93.210859
epoch: 1803, train precision: 0.999756, train loss: 5.494234, valid precision: 0.877800, valid loss: 92.612479
epoch: 1804, train precision: 0.999578, train loss: 5.519130, valid precision: 0.875200, valid loss: 93.512127
epoch: 1805, train precision: 0.999578, train loss: 5.514770, valid precision: 0.875800, valid loss: 92.578365
epoch: 1806, train precision: 0.999489, train loss: 5.551219, valid precision: 0.876000, valid loss: 97.208604
epoch: 1807, train precision: 0.999356, train loss: 5.548922, valid precision: 0.880400, valid loss: 93.548057
epoch: 1808, train precision: 0.999533, train loss: 5.498765, valid precision: 0.879600, valid loss: 93.746071
epoch: 1809, train precision: 0.999667, train loss: 5.507722, valid precision: 0.876200, valid loss: 94.481574
epoch: 1810, train precision: 0.999711, train loss: 5.525948, valid precision: 0.876600, valid loss: 92.058206
epoch: 1811, train precision: 0.999467, train loss: 5.566118, valid precision: 0.876800, valid loss: 93.560880
epoch: 1812, train precision: 0.999711, train loss: 5.463114, valid precision: 0.879200, valid loss: 92.695786
epoch: 1813, train precision: 0.999356, train loss: 5.609867, valid precision: 0.875000, valid loss: 92.826285
epoch: 1814, train precision: 0.999467, train loss: 5.537811, valid precision: 0.876000, valid loss: 93.576074
epoch: 1815, train precision: 0.999644, train loss: 5.526768, valid precision: 0.874600, valid loss: 96.089544
epoch: 1816, train precision: 0.999556, train loss: 5.511886, valid precision: 0.878800, valid loss: 94.441806
epoch: 1817, train precision: 0.999778, train loss: 5.465245, valid precision: 0.879600, valid loss: 93.997648
epoch: 1818, train precision: 0.999733, train loss: 5.494400, valid precision: 0.876200, valid loss: 95.062943
epoch: 1819, train precision: 0.999622, train loss: 5.508789, valid precision: 0.877400, valid loss: 94.660481
epoch: 1820, train precision: 0.999778, train loss: 5.493888, valid precision: 0.877200, valid loss: 92.209956
epoch: 1821, train precision: 0.999533, train loss: 5.496863, valid precision: 0.877800, valid loss: 93.790581
epoch: 1822, train precision: 0.999533, train loss: 5.501497, valid precision: 0.875400, valid loss: 93.142874
epoch: 1823, train precision: 0.999600, train loss: 5.510420, valid precision: 0.874600, valid loss: 94.009760
epoch: 1824, train precision: 0.999667, train loss: 5.503314, valid precision: 0.874600, valid loss: 94.923662
epoch: 1825, train precision: 0.999644, train loss: 5.475890, valid precision: 0.873000, valid loss: 95.592162
epoch: 1826, train precision: 0.999422, train loss: 5.556908, valid precision: 0.875000, valid loss: 95.634804
epoch: 1827, train precision: 0.999822, train loss: 5.444328, valid precision: 0.876000, valid loss: 95.157100
epoch: 1828, train precision: 0.999667, train loss: 5.504405, valid precision: 0.876200, valid loss: 95.518851
epoch: 1829, train precision: 0.999333, train loss: 5.547320, valid precision: 0.871600, valid loss: 95.284459
epoch: 1830, train precision: 0.999600, train loss: 5.513580, valid precision: 0.871200, valid loss: 96.913330
epoch: 1831, train precision: 0.999556, train loss: 5.509981, valid precision: 0.873200, valid loss: 94.732787
epoch: 1832, train precision: 0.999467, train loss: 5.564704, valid precision: 0.871800, valid loss: 94.537198
epoch: 1833, train precision: 0.999556, train loss: 5.528394, valid precision: 0.871200, valid loss: 94.335135
epoch: 1834, train precision: 0.999444, train loss: 5.555146, valid precision: 0.874000, valid loss: 94.668554
epoch: 1835, train precision: 0.999511, train loss: 5.549390, valid precision: 0.874000, valid loss: 96.147943
epoch: 1836, train precision: 0.999600, train loss: 5.482483, valid precision: 0.878200, valid loss: 94.421257
epoch: 1837, train precision: 0.999644, train loss: 5.496660, valid precision: 0.877400, valid loss: 96.796077
epoch: 1838, train precision: 0.999444, train loss: 5.551359, valid precision: 0.876800, valid loss: 96.977865
epoch: 1839, train precision: 0.999711, train loss: 5.494350, valid precision: 0.874400, valid loss: 95.672040
epoch: 1840, train precision: 0.999622, train loss: 5.491675, valid precision: 0.871800, valid loss: 95.222889
epoch: 1841, train precision: 0.999644, train loss: 5.533973, valid precision: 0.873600, valid loss: 96.529436
epoch: 1842, train precision: 0.999422, train loss: 5.535340, valid precision: 0.875000, valid loss: 97.056603
epoch: 1843, train precision: 0.999711, train loss: 5.486886, valid precision: 0.879800, valid loss: 95.006110
epoch: 1844, train precision: 0.999600, train loss: 5.484885, valid precision: 0.878200, valid loss: 96.381139
epoch: 1845, train precision: 0.999667, train loss: 5.511343, valid precision: 0.876800, valid loss: 94.554500
epoch: 1846, train precision: 0.999511, train loss: 5.537382, valid precision: 0.872000, valid loss: 94.471181
epoch: 1847, train precision: 0.999533, train loss: 5.521905, valid precision: 0.875600, valid loss: 95.383866
epoch: 1848, train precision: 0.999444, train loss: 5.540513, valid precision: 0.876200, valid loss: 94.703077
epoch: 1849, train precision: 0.999511, train loss: 5.557303, valid precision: 0.871600, valid loss: 96.270356
epoch: 1850, train precision: 0.999511, train loss: 5.555548, valid precision: 0.874600, valid loss: 95.133263
epoch: 1851, train precision: 0.999644, train loss: 5.533515, valid precision: 0.875800, valid loss: 97.027895
epoch: 1852, train precision: 0.999600, train loss: 5.534457, valid precision: 0.874400, valid loss: 96.299464
epoch: 1853, train precision: 0.999578, train loss: 5.498836, valid precision: 0.875200, valid loss: 94.202685
epoch: 1854, train precision: 0.999533, train loss: 5.531161, valid precision: 0.872800, valid loss: 95.604063
epoch: 1855, train precision: 0.999667, train loss: 5.480730, valid precision: 0.875800, valid loss: 96.099422
epoch: 1856, train precision: 0.999756, train loss: 5.504327, valid precision: 0.876800, valid loss: 94.651894
epoch: 1857, train precision: 0.999600, train loss: 5.538003, valid precision: 0.873800, valid loss: 96.047475
epoch: 1858, train precision: 0.999489, train loss: 5.555993, valid precision: 0.874400, valid loss: 97.677070
epoch: 1859, train precision: 0.999644, train loss: 5.499140, valid precision: 0.874400, valid loss: 96.315508
epoch: 1860, train precision: 0.999600, train loss: 5.517654, valid precision: 0.872800, valid loss: 98.517537
epoch: 1861, train precision: 0.999467, train loss: 5.559750, valid precision: 0.876600, valid loss: 95.131524
epoch: 1862, train precision: 0.999667, train loss: 5.476239, valid precision: 0.878400, valid loss: 96.259463
epoch: 1863, train precision: 0.999711, train loss: 5.452126, valid precision: 0.871400, valid loss: 96.223230
epoch: 1864, train precision: 0.999756, train loss: 5.489130, valid precision: 0.876600, valid loss: 93.623523
epoch: 1865, train precision: 0.999467, train loss: 5.560820, valid precision: 0.877600, valid loss: 94.284055
epoch: 1866, train precision: 0.999533, train loss: 5.513935, valid precision: 0.876600, valid loss: 94.875426
epoch: 1867, train precision: 0.999600, train loss: 5.516757, valid precision: 0.872600, valid loss: 96.755640
epoch: 1868, train precision: 0.999444, train loss: 5.578785, valid precision: 0.873400, valid loss: 94.401565
epoch: 1869, train precision: 0.999733, train loss: 5.518505, valid precision: 0.877600, valid loss: 93.749800
epoch: 1870, train precision: 0.999822, train loss: 5.494992, valid precision: 0.873600, valid loss: 93.716886
epoch: 1871, train precision: 0.999867, train loss: 5.457508, valid precision: 0.874400, valid loss: 95.429794
epoch: 1872, train precision: 0.999489, train loss: 5.540744, valid precision: 0.873600, valid loss: 95.792926
epoch: 1873, train precision: 0.999578, train loss: 5.553559, valid precision: 0.874800, valid loss: 94.505119
epoch: 1874, train precision: 0.999644, train loss: 5.508139, valid precision: 0.875800, valid loss: 95.478242
epoch: 1875, train precision: 0.999622, train loss: 5.500869, valid precision: 0.871600, valid loss: 96.773246
epoch: 1876, train precision: 0.999600, train loss: 5.517642, valid precision: 0.877400, valid loss: 93.226947
epoch: 1877, train precision: 0.999533, train loss: 5.549579, valid precision: 0.876200, valid loss: 93.747277
epoch: 1878, train precision: 0.999533, train loss: 5.532917, valid precision: 0.878000, valid loss: 96.271419
epoch: 1879, train precision: 0.999689, train loss: 5.480742, valid precision: 0.876800, valid loss: 94.826517
epoch: 1880, train precision: 0.999444, train loss: 5.571871, valid precision: 0.877600, valid loss: 93.736027
epoch: 1881, train precision: 0.999733, train loss: 5.482030, valid precision: 0.876600, valid loss: 91.960396
epoch: 1882, train precision: 0.999778, train loss: 5.463035, valid precision: 0.880600, valid loss: 92.361293
epoch: 1883, train precision: 0.999622, train loss: 5.516548, valid precision: 0.876600, valid loss: 95.528914
epoch: 1884, train precision: 0.999667, train loss: 5.499359, valid precision: 0.880200, valid loss: 93.589632
epoch: 1885, train precision: 0.999511, train loss: 5.547132, valid precision: 0.878600, valid loss: 93.652416
epoch: 1886, train precision: 0.999644, train loss: 5.520001, valid precision: 0.874000, valid loss: 93.892623
epoch: 1887, train precision: 0.999511, train loss: 5.518614, valid precision: 0.876400, valid loss: 93.924462
epoch: 1888, train precision: 0.999467, train loss: 5.571284, valid precision: 0.877800, valid loss: 92.430761
epoch: 1889, train precision: 0.999600, train loss: 5.516692, valid precision: 0.874800, valid loss: 95.812332
epoch: 1890, train precision: 0.999578, train loss: 5.524561, valid precision: 0.874400, valid loss: 92.829564
epoch: 1891, train precision: 0.999844, train loss: 5.467126, valid precision: 0.876400, valid loss: 93.967369
epoch: 1892, train precision: 0.999622, train loss: 5.534054, valid precision: 0.876200, valid loss: 93.270357
epoch: 1893, train precision: 0.999689, train loss: 5.474670, valid precision: 0.873800, valid loss: 93.477437
epoch: 1894, train precision: 0.999644, train loss: 5.501631, valid precision: 0.875600, valid loss: 92.806180
epoch: 1895, train precision: 0.999578, train loss: 5.511220, valid precision: 0.876600, valid loss: 93.431083
epoch: 1896, train precision: 0.999644, train loss: 5.518205, valid precision: 0.871000, valid loss: 94.400710
epoch: 1897, train precision: 0.999733, train loss: 5.498244, valid precision: 0.873400, valid loss: 94.435941
epoch: 1898, train precision: 0.999422, train loss: 5.560910, valid precision: 0.874000, valid loss: 92.973287
epoch: 1899, train precision: 0.999511, train loss: 5.572214, valid precision: 0.871200, valid loss: 95.398673
epoch: 1900, train precision: 0.999644, train loss: 5.538395, valid precision: 0.875000, valid loss: 92.592892
epoch: 1901, train precision: 0.999578, train loss: 5.530676, valid precision: 0.877400, valid loss: 93.613516
epoch: 1902, train precision: 0.999533, train loss: 5.545649, valid precision: 0.871200, valid loss: 96.112439
epoch: 1903, train precision: 0.999689, train loss: 5.493840, valid precision: 0.873200, valid loss: 95.500250
epoch: 1904, train precision: 0.999600, train loss: 5.494292, valid precision: 0.878200, valid loss: 94.630087
epoch: 1905, train precision: 0.999711, train loss: 5.535537, valid precision: 0.876400, valid loss: 96.294386
epoch: 1906, train precision: 0.999578, train loss: 5.533103, valid precision: 0.875000, valid loss: 97.147789
epoch: 1907, train precision: 0.999489, train loss: 5.523400, valid precision: 0.873400, valid loss: 97.023900
epoch: 1908, train precision: 0.999578, train loss: 5.526378, valid precision: 0.876400, valid loss: 95.693229
epoch: 1909, train precision: 0.999422, train loss: 5.564130, valid precision: 0.876000, valid loss: 94.247784
epoch: 1910, train precision: 0.999200, train loss: 5.580536, valid precision: 0.873800, valid loss: 96.231612
epoch: 1911, train precision: 0.999689, train loss: 5.476714, valid precision: 0.873800, valid loss: 93.833292
epoch: 1912, train precision: 0.999267, train loss: 5.611907, valid precision: 0.872800, valid loss: 98.476257
epoch: 1913, train precision: 0.999467, train loss: 5.556360, valid precision: 0.871600, valid loss: 99.668593
epoch: 1914, train precision: 0.999733, train loss: 5.482901, valid precision: 0.874000, valid loss: 98.023677
epoch: 1915, train precision: 0.999378, train loss: 5.555076, valid precision: 0.877000, valid loss: 97.380218
epoch: 1916, train precision: 0.999600, train loss: 5.514617, valid precision: 0.875400, valid loss: 95.878199
epoch: 1917, train precision: 0.999467, train loss: 5.521801, valid precision: 0.873600, valid loss: 95.873035
epoch: 1918, train precision: 0.999400, train loss: 5.587010, valid precision: 0.872400, valid loss: 97.672435
epoch: 1919, train precision: 0.999578, train loss: 5.491422, valid precision: 0.871000, valid loss: 96.240312
epoch: 1920, train precision: 0.999556, train loss: 5.513884, valid precision: 0.875600, valid loss: 96.305749
epoch: 1921, train precision: 0.999578, train loss: 5.545183, valid precision: 0.876400, valid loss: 95.614052
epoch: 1922, train precision: 0.999689, train loss: 5.475990, valid precision: 0.878600, valid loss: 93.545724
epoch: 1923, train precision: 0.999489, train loss: 5.568560, valid precision: 0.874800, valid loss: 94.355214
epoch: 1924, train precision: 0.999689, train loss: 5.510779, valid precision: 0.875000, valid loss: 92.735295
epoch: 1925, train precision: 0.999489, train loss: 5.549231, valid precision: 0.872400, valid loss: 93.986036
epoch: 1926, train precision: 0.999711, train loss: 5.472505, valid precision: 0.876800, valid loss: 93.874401
epoch: 1927, train precision: 0.999667, train loss: 5.512855, valid precision: 0.875800, valid loss: 95.114821
epoch: 1928, train precision: 0.999822, train loss: 5.455747, valid precision: 0.875800, valid loss: 92.238162
epoch: 1929, train precision: 0.999489, train loss: 5.512975, valid precision: 0.875400, valid loss: 92.493430
epoch: 1930, train precision: 0.999622, train loss: 5.495056, valid precision: 0.875200, valid loss: 94.201638
epoch: 1931, train precision: 0.999622, train loss: 5.533644, valid precision: 0.874800, valid loss: 95.872636
epoch: 1932, train precision: 0.999533, train loss: 5.542728, valid precision: 0.874000, valid loss: 95.160695
epoch: 1933, train precision: 0.999689, train loss: 5.469988, valid precision: 0.875200, valid loss: 93.753638
epoch: 1934, train precision: 0.999600, train loss: 5.540555, valid precision: 0.872000, valid loss: 96.265889
epoch: 1935, train precision: 0.999444, train loss: 5.556094, valid precision: 0.873200, valid loss: 94.262406
epoch: 1936, train precision: 0.999578, train loss: 5.517817, valid precision: 0.873200, valid loss: 94.967484
epoch: 1937, train precision: 0.999622, train loss: 5.494513, valid precision: 0.876600, valid loss: 98.765981
epoch: 1938, train precision: 0.999556, train loss: 5.540022, valid precision: 0.874000, valid loss: 98.084020
epoch: 1939, train precision: 0.999689, train loss: 5.495059, valid precision: 0.873800, valid loss: 96.348460
epoch: 1940, train precision: 0.999467, train loss: 5.516087, valid precision: 0.872200, valid loss: 99.177135
epoch: 1941, train precision: 0.999756, train loss: 5.475500, valid precision: 0.876400, valid loss: 96.481077
epoch: 1942, train precision: 0.999667, train loss: 5.510762, valid precision: 0.874400, valid loss: 94.997181
epoch: 1943, train precision: 0.999756, train loss: 5.467974, valid precision: 0.875400, valid loss: 95.656557
epoch: 1944, train precision: 0.999467, train loss: 5.567604, valid precision: 0.873600, valid loss: 98.881799
epoch: 1945, train precision: 0.999467, train loss: 5.565052, valid precision: 0.873200, valid loss: 100.608947
epoch: 1946, train precision: 0.999778, train loss: 5.446947, valid precision: 0.876400, valid loss: 96.251692
epoch: 1947, train precision: 0.999578, train loss: 5.529789, valid precision: 0.875200, valid loss: 98.166878
epoch: 1948, train precision: 0.999444, train loss: 5.549279, valid precision: 0.872800, valid loss: 98.581359
epoch: 1949, train precision: 0.999689, train loss: 5.493439, valid precision: 0.870800, valid loss: 97.400813
epoch: 1950, train precision: 0.999756, train loss: 5.462108, valid precision: 0.871600, valid loss: 97.694935
epoch: 1951, train precision: 0.999667, train loss: 5.512903, valid precision: 0.874000, valid loss: 97.505698
epoch: 1952, train precision: 0.999467, train loss: 5.582616, valid precision: 0.874800, valid loss: 99.829186
epoch: 1953, train precision: 0.999644, train loss: 5.496681, valid precision: 0.872000, valid loss: 97.847450
epoch: 1954, train precision: 0.999667, train loss: 5.543717, valid precision: 0.872000, valid loss: 97.705740
epoch: 1955, train precision: 0.999400, train loss: 5.541560, valid precision: 0.874600, valid loss: 95.184520
epoch: 1956, train precision: 0.999689, train loss: 5.466009, valid precision: 0.873200, valid loss: 98.127042
epoch: 1957, train precision: 0.999533, train loss: 5.516918, valid precision: 0.873400, valid loss: 95.368908
epoch: 1958, train precision: 0.999756, train loss: 5.467684, valid precision: 0.873200, valid loss: 95.481852
epoch: 1959, train precision: 0.999644, train loss: 5.501522, valid precision: 0.875400, valid loss: 95.356344
epoch: 1960, train precision: 0.999622, train loss: 5.536443, valid precision: 0.872200, valid loss: 96.364710
epoch: 1961, train precision: 0.999489, train loss: 5.532304, valid precision: 0.876200, valid loss: 96.226196
epoch: 1962, train precision: 0.999644, train loss: 5.500730, valid precision: 0.872800, valid loss: 96.899430
epoch: 1963, train precision: 0.999822, train loss: 5.448777, valid precision: 0.874200, valid loss: 95.748305
epoch: 1964, train precision: 0.999689, train loss: 5.461176, valid precision: 0.873400, valid loss: 98.120721
epoch: 1965, train precision: 0.999800, train loss: 5.488427, valid precision: 0.872800, valid loss: 97.973315
epoch: 1966, train precision: 0.999467, train loss: 5.577250, valid precision: 0.875000, valid loss: 94.903855
epoch: 1967, train precision: 0.999733, train loss: 5.482744, valid precision: 0.871800, valid loss: 95.412807
epoch: 1968, train precision: 0.999600, train loss: 5.488904, valid precision: 0.874200, valid loss: 96.132466
epoch: 1969, train precision: 0.999578, train loss: 5.529196, valid precision: 0.871800, valid loss: 94.977400
epoch: 1970, train precision: 0.999822, train loss: 5.504371, valid precision: 0.872600, valid loss: 92.769836
epoch: 1971, train precision: 0.999667, train loss: 5.489360, valid precision: 0.874000, valid loss: 96.418410
epoch: 1972, train precision: 0.999422, train loss: 5.533712, valid precision: 0.871200, valid loss: 93.810757
epoch: 1973, train precision: 0.999644, train loss: 5.502028, valid precision: 0.878200, valid loss: 93.991964
epoch: 1974, train precision: 0.999733, train loss: 5.449014, valid precision: 0.875400, valid loss: 94.237841
epoch: 1975, train precision: 0.999711, train loss: 5.462653, valid precision: 0.872600, valid loss: 95.034809
epoch: 1976, train precision: 0.999689, train loss: 5.505196, valid precision: 0.876200, valid loss: 93.553765
epoch: 1977, train precision: 0.999689, train loss: 5.501075, valid precision: 0.873800, valid loss: 97.915339
epoch: 1978, train precision: 0.999622, train loss: 5.488286, valid precision: 0.869000, valid loss: 96.277254
epoch: 1979, train precision: 0.999622, train loss: 5.485258, valid precision: 0.877200, valid loss: 96.781565
epoch: 1980, train precision: 0.999689, train loss: 5.504787, valid precision: 0.877000, valid loss: 92.901129
epoch: 1981, train precision: 0.999533, train loss: 5.511000, valid precision: 0.880000, valid loss: 93.122885
epoch: 1982, train precision: 0.999578, train loss: 5.532063, valid precision: 0.873600, valid loss: 96.347697
epoch: 1983, train precision: 0.999622, train loss: 5.517165, valid precision: 0.874200, valid loss: 96.825088
epoch: 1984, train precision: 0.999489, train loss: 5.550427, valid precision: 0.870000, valid loss: 94.811435
epoch: 1985, train precision: 0.999622, train loss: 5.510087, valid precision: 0.875600, valid loss: 92.095806
epoch: 1986, train precision: 0.999333, train loss: 5.552991, valid precision: 0.870200, valid loss: 97.341090
epoch: 1987, train precision: 0.999578, train loss: 5.498793, valid precision: 0.877600, valid loss: 96.670083
epoch: 1988, train precision: 0.999711, train loss: 5.443139, valid precision: 0.873600, valid loss: 94.340623
epoch: 1989, train precision: 0.999556, train loss: 5.526795, valid precision: 0.875200, valid loss: 96.743654
epoch: 1990, train precision: 0.999667, train loss: 5.505895, valid precision: 0.874400, valid loss: 95.133839
epoch: 1991, train precision: 0.999578, train loss: 5.545322, valid precision: 0.872200, valid loss: 95.337751
epoch: 1992, train precision: 0.999822, train loss: 5.446215, valid precision: 0.875000, valid loss: 94.880384
epoch: 1993, train precision: 0.999489, train loss: 5.569852, valid precision: 0.874600, valid loss: 97.962568
epoch: 1994, train precision: 0.999311, train loss: 5.612659, valid precision: 0.877800, valid loss: 93.774552
epoch: 1995, train precision: 0.999622, train loss: 5.489057, valid precision: 0.878000, valid loss: 92.976930
epoch: 1996, train precision: 0.999511, train loss: 5.559502, valid precision: 0.877000, valid loss: 92.825283
epoch: 1997, train precision: 0.999778, train loss: 5.485144, valid precision: 0.872400, valid loss: 93.608365
epoch: 1998, train precision: 0.999667, train loss: 5.526624, valid precision: 0.872000, valid loss: 96.099923
epoch: 1999, train precision: 0.999467, train loss: 5.554692, valid precision: 0.872800, valid loss: 96.785437
epoch: 2000, train precision: 0.999667, train loss: 5.529818, valid precision: 0.873600, valid loss: 96.823974
epoch: 2001, train precision: 0.999489, train loss: 5.533009, valid precision: 0.873800, valid loss: 98.396512
epoch: 2002, train precision: 0.999533, train loss: 5.553218, valid precision: 0.873600, valid loss: 97.090466
epoch: 2003, train precision: 0.999689, train loss: 5.522177, valid precision: 0.876400, valid loss: 97.412629
epoch: 2004, train precision: 0.999578, train loss: 5.537436, valid precision: 0.874200, valid loss: 95.624383
epoch: 2005, train precision: 0.999622, train loss: 5.466797, valid precision: 0.875800, valid loss: 94.203282
epoch: 2006, train precision: 0.999444, train loss: 5.560505, valid precision: 0.876800, valid loss: 96.555788
epoch: 2007, train precision: 0.999800, train loss: 5.456215, valid precision: 0.875400, valid loss: 96.961393
epoch: 2008, train precision: 0.999356, train loss: 5.559696, valid precision: 0.875400, valid loss: 99.329074
epoch: 2009, train precision: 0.999711, train loss: 5.476377, valid precision: 0.873800, valid loss: 95.017126
epoch: 2010, train precision: 0.999578, train loss: 5.500924, valid precision: 0.874200, valid loss: 96.815064
epoch: 2011, train precision: 0.999444, train loss: 5.548929, valid precision: 0.877000, valid loss: 97.668134
epoch: 2012, train precision: 0.999733, train loss: 5.502206, valid precision: 0.872200, valid loss: 96.387044
epoch: 2013, train precision: 0.999267, train loss: 5.592518, valid precision: 0.876200, valid loss: 97.424281
epoch: 2014, train precision: 0.999689, train loss: 5.511817, valid precision: 0.872600, valid loss: 97.025737
epoch: 2015, train precision: 0.999822, train loss: 5.442566, valid precision: 0.874000, valid loss: 95.920033
epoch: 2016, train precision: 0.999756, train loss: 5.474675, valid precision: 0.869600, valid loss: 100.412651
epoch: 2017, train precision: 0.999644, train loss: 5.470093, valid precision: 0.873600, valid loss: 94.705116
epoch: 2018, train precision: 0.999644, train loss: 5.496059, valid precision: 0.869800, valid loss: 94.149169
epoch: 2019, train precision: 0.999489, train loss: 5.554387, valid precision: 0.874600, valid loss: 98.067770
epoch: 2020, train precision: 0.999600, train loss: 5.514325, valid precision: 0.872000, valid loss: 96.487375
epoch: 2021, train precision: 0.999800, train loss: 5.459040, valid precision: 0.876000, valid loss: 95.268272
epoch: 2022, train precision: 0.999667, train loss: 5.467587, valid precision: 0.873800, valid loss: 93.258041
epoch: 2023, train precision: 0.999844, train loss: 5.424336, valid precision: 0.874800, valid loss: 94.774781
epoch: 2024, train precision: 0.999533, train loss: 5.529445, valid precision: 0.873600, valid loss: 93.377910
epoch: 2025, train precision: 0.999578, train loss: 5.479071, valid precision: 0.875000, valid loss: 96.028812
epoch: 2026, train precision: 0.999667, train loss: 5.497443, valid precision: 0.873600, valid loss: 96.322569
epoch: 2027, train precision: 0.999511, train loss: 5.530003, valid precision: 0.872000, valid loss: 99.590161
epoch: 2028, train precision: 0.999667, train loss: 5.497784, valid precision: 0.874400, valid loss: 96.670124
epoch: 2029, train precision: 0.999289, train loss: 5.640715, valid precision: 0.873400, valid loss: 97.081158
epoch: 2030, train precision: 0.999889, train loss: 5.454378, valid precision: 0.873600, valid loss: 94.940248
epoch: 2031, train precision: 0.999600, train loss: 5.526447, valid precision: 0.873800, valid loss: 96.416153
epoch: 2032, train precision: 0.999667, train loss: 5.510657, valid precision: 0.873400, valid loss: 95.975323
epoch: 2033, train precision: 0.999800, train loss: 5.450407, valid precision: 0.869200, valid loss: 98.149974
epoch: 2034, train precision: 0.999578, train loss: 5.511127, valid precision: 0.874600, valid loss: 97.118661
epoch: 2035, train precision: 0.999622, train loss: 5.519460, valid precision: 0.875000, valid loss: 98.681194
epoch: 2036, train precision: 0.999556, train loss: 5.514307, valid precision: 0.869000, valid loss: 98.703503
epoch: 2037, train precision: 0.999400, train loss: 5.590616, valid precision: 0.872200, valid loss: 96.725207
epoch: 2038, train precision: 0.999556, train loss: 5.538492, valid precision: 0.875600, valid loss: 93.130858
epoch: 2039, train precision: 0.999689, train loss: 5.457298, valid precision: 0.873600, valid loss: 96.727600
epoch: 2040, train precision: 0.999511, train loss: 5.538728, valid precision: 0.872000, valid loss: 98.682098
epoch: 2041, train precision: 0.999711, train loss: 5.515473, valid precision: 0.873600, valid loss: 98.487303
epoch: 2042, train precision: 0.999578, train loss: 5.490224, valid precision: 0.876800, valid loss: 95.061541
epoch: 2043, train precision: 0.999556, train loss: 5.529645, valid precision: 0.876800, valid loss: 98.933573
epoch: 2044, train precision: 0.999667, train loss: 5.530747, valid precision: 0.873200, valid loss: 97.857709
epoch: 2045, train precision: 0.999800, train loss: 5.448468, valid precision: 0.876400, valid loss: 94.994808
epoch: 2046, train precision: 0.999733, train loss: 5.464927, valid precision: 0.877800, valid loss: 94.412141
epoch: 2047, train precision: 0.999556, train loss: 5.511122, valid precision: 0.878400, valid loss: 95.217833
epoch: 2048, train precision: 0.999622, train loss: 5.501049, valid precision: 0.877200, valid loss: 93.103902
epoch: 2049, train precision: 0.999533, train loss: 5.517913, valid precision: 0.874000, valid loss: 96.818067
epoch: 2050, train precision: 0.999756, train loss: 5.456786, valid precision: 0.876600, valid loss: 94.442926
epoch: 2051, train precision: 0.999756, train loss: 5.466453, valid precision: 0.876200, valid loss: 93.952926
epoch: 2052, train precision: 0.999689, train loss: 5.446375, valid precision: 0.876000, valid loss: 99.128399
epoch: 2053, train precision: 0.999511, train loss: 5.534579, valid precision: 0.870800, valid loss: 99.234337
epoch: 2054, train precision: 0.999556, train loss: 5.509367, valid precision: 0.874800, valid loss: 97.546205
epoch: 2055, train precision: 0.999667, train loss: 5.501349, valid precision: 0.873000, valid loss: 97.552693
epoch: 2056, train precision: 0.999667, train loss: 5.502343, valid precision: 0.875800, valid loss: 97.088034
epoch: 2057, train precision: 0.999600, train loss: 5.520197, valid precision: 0.875400, valid loss: 98.370827
epoch: 2058, train precision: 0.999667, train loss: 5.503245, valid precision: 0.879600, valid loss: 94.819440
epoch: 2059, train precision: 0.999378, train loss: 5.594249, valid precision: 0.875400, valid loss: 97.502898
epoch: 2060, train precision: 0.999644, train loss: 5.478382, valid precision: 0.876000, valid loss: 95.510459
epoch: 2061, train precision: 0.999778, train loss: 5.431727, valid precision: 0.875000, valid loss: 96.717834
epoch: 2062, train precision: 0.999422, train loss: 5.554985, valid precision: 0.875600, valid loss: 98.834426
epoch: 2063, train precision: 0.999689, train loss: 5.448406, valid precision: 0.872600, valid loss: 99.507081
epoch: 2064, train precision: 0.999600, train loss: 5.506665, valid precision: 0.872800, valid loss: 97.508697
epoch: 2065, train precision: 0.999356, train loss: 5.554644, valid precision: 0.871800, valid loss: 98.245464
epoch: 2066, train precision: 0.999733, train loss: 5.483748, valid precision: 0.873400, valid loss: 96.280736
epoch: 2067, train precision: 0.999756, train loss: 5.457932, valid precision: 0.874000, valid loss: 95.938464
epoch: 2068, train precision: 0.999622, train loss: 5.503617, valid precision: 0.873400, valid loss: 96.039141
epoch: 2069, train precision: 0.999756, train loss: 5.467902, valid precision: 0.873800, valid loss: 96.397582
epoch: 2070, train precision: 0.999533, train loss: 5.519575, valid precision: 0.875200, valid loss: 97.073787
epoch: 2071, train precision: 0.999444, train loss: 5.559421, valid precision: 0.871400, valid loss: 97.098178
epoch: 2072, train precision: 0.999422, train loss: 5.552364, valid precision: 0.874200, valid loss: 96.721486
epoch: 2073, train precision: 0.999667, train loss: 5.493763, valid precision: 0.876200, valid loss: 95.555666
epoch: 2074, train precision: 0.999511, train loss: 5.528570, valid precision: 0.874800, valid loss: 97.794265
epoch: 2075, train precision: 0.999511, train loss: 5.528662, valid precision: 0.871600, valid loss: 99.936976
epoch: 2076, train precision: 0.999644, train loss: 5.504480, valid precision: 0.874400, valid loss: 97.955088
epoch: 2077, train precision: 0.999556, train loss: 5.523020, valid precision: 0.875600, valid loss: 98.964991
epoch: 2078, train precision: 0.999667, train loss: 5.491950, valid precision: 0.873800, valid loss: 99.729113
epoch: 2079, train precision: 0.999644, train loss: 5.496665, valid precision: 0.874000, valid loss: 99.108803
epoch: 2080, train precision: 0.999644, train loss: 5.475023, valid precision: 0.876200, valid loss: 97.184036
epoch: 2081, train precision: 0.999578, train loss: 5.516860, valid precision: 0.874400, valid loss: 99.083058
epoch: 2082, train precision: 0.999800, train loss: 5.461235, valid precision: 0.872000, valid loss: 97.986300
epoch: 2083, train precision: 0.999711, train loss: 5.464310, valid precision: 0.875600, valid loss: 97.857778
epoch: 2084, train precision: 0.999800, train loss: 5.457434, valid precision: 0.873800, valid loss: 98.653962
epoch: 2085, train precision: 0.999733, train loss: 5.461265, valid precision: 0.872000, valid loss: 98.065854
epoch: 2086, train precision: 0.999667, train loss: 5.462135, valid precision: 0.875000, valid loss: 99.199738
epoch: 2087, train precision: 0.999733, train loss: 5.460421, valid precision: 0.873000, valid loss: 96.761626
epoch: 2088, train precision: 0.999667, train loss: 5.534290, valid precision: 0.870000, valid loss: 95.332518
epoch: 2089, train precision: 0.999556, train loss: 5.530671, valid precision: 0.871400, valid loss: 97.406895
epoch: 2090, train precision: 0.999711, train loss: 5.465144, valid precision: 0.871400, valid loss: 96.547040
epoch: 2091, train precision: 0.999689, train loss: 5.517479, valid precision: 0.872000, valid loss: 98.462290
epoch: 2092, train precision: 0.999578, train loss: 5.549067, valid precision: 0.874200, valid loss: 98.079388
epoch: 2093, train precision: 0.999733, train loss: 5.491180, valid precision: 0.871800, valid loss: 98.576761
epoch: 2094, train precision: 0.999400, train loss: 5.534233, valid precision: 0.873200, valid loss: 97.007795
epoch: 2095, train precision: 0.999711, train loss: 5.469696, valid precision: 0.871200, valid loss: 97.975983
epoch: 2096, train precision: 0.999511, train loss: 5.549212, valid precision: 0.873400, valid loss: 96.950149
epoch: 2097, train precision: 0.999600, train loss: 5.491537, valid precision: 0.873400, valid loss: 99.229445
epoch: 2098, train precision: 0.999778, train loss: 5.455796, valid precision: 0.874000, valid loss: 96.946931
epoch: 2099, train precision: 0.999733, train loss: 5.463868, valid precision: 0.875200, valid loss: 98.001746
epoch: 2100, train precision: 0.999511, train loss: 5.526868, valid precision: 0.871400, valid loss: 101.916794
epoch: 2101, train precision: 0.999556, train loss: 5.520463, valid precision: 0.875400, valid loss: 97.006362
epoch: 2102, train precision: 0.999622, train loss: 5.466977, valid precision: 0.878200, valid loss: 95.589501
epoch: 2103, train precision: 0.999489, train loss: 5.558570, valid precision: 0.872200, valid loss: 98.096447
epoch: 2104, train precision: 0.999578, train loss: 5.518405, valid precision: 0.875000, valid loss: 96.260647
epoch: 2105, train precision: 0.999600, train loss: 5.516611, valid precision: 0.874800, valid loss: 96.941328
epoch: 2106, train precision: 0.999556, train loss: 5.578067, valid precision: 0.871000, valid loss: 99.210805
epoch: 2107, train precision: 0.999600, train loss: 5.505497, valid precision: 0.875800, valid loss: 94.617416
epoch: 2108, train precision: 0.999533, train loss: 5.541137, valid precision: 0.875200, valid loss: 96.459452
epoch: 2109, train precision: 0.999711, train loss: 5.458500, valid precision: 0.878000, valid loss: 95.136563
epoch: 2110, train precision: 0.999689, train loss: 5.504000, valid precision: 0.876000, valid loss: 95.543376
epoch: 2111, train precision: 0.999333, train loss: 5.555388, valid precision: 0.878600, valid loss: 97.138776
epoch: 2112, train precision: 0.999378, train loss: 5.584022, valid precision: 0.870200, valid loss: 97.045167
epoch: 2113, train precision: 0.999711, train loss: 5.456106, valid precision: 0.874200, valid loss: 97.940704
epoch: 2114, train precision: 0.999667, train loss: 5.527343, valid precision: 0.875000, valid loss: 95.063993
epoch: 2115, train precision: 0.999644, train loss: 5.509312, valid precision: 0.874000, valid loss: 96.021623
epoch: 2116, train precision: 0.999489, train loss: 5.559324, valid precision: 0.876200, valid loss: 96.816700
epoch: 2117, train precision: 0.999756, train loss: 5.486949, valid precision: 0.876000, valid loss: 95.944873
epoch: 2118, train precision: 0.999578, train loss: 5.481305, valid precision: 0.878200, valid loss: 95.133110
epoch: 2119, train precision: 0.999444, train loss: 5.539920, valid precision: 0.875200, valid loss: 95.564960
epoch: 2120, train precision: 0.999711, train loss: 5.464625, valid precision: 0.872400, valid loss: 94.201677
epoch: 2121, train precision: 0.999511, train loss: 5.522591, valid precision: 0.875800, valid loss: 95.746597
epoch: 2122, train precision: 0.999711, train loss: 5.495395, valid precision: 0.875200, valid loss: 93.784266
epoch: 2123, train precision: 0.999622, train loss: 5.480573, valid precision: 0.875200, valid loss: 96.868168
epoch: 2124, train precision: 0.999622, train loss: 5.516568, valid precision: 0.877000, valid loss: 95.989130
epoch: 2125, train precision: 0.999533, train loss: 5.533648, valid precision: 0.875000, valid loss: 97.733766
epoch: 2126, train precision: 0.999356, train loss: 5.564250, valid precision: 0.871000, valid loss: 94.864544
epoch: 2127, train precision: 0.999756, train loss: 5.467405, valid precision: 0.878400, valid loss: 96.674277
epoch: 2128, train precision: 0.999578, train loss: 5.532944, valid precision: 0.875000, valid loss: 97.098163
epoch: 2129, train precision: 0.999533, train loss: 5.538320, valid precision: 0.872000, valid loss: 96.417711
epoch: 2130, train precision: 0.999689, train loss: 5.497710, valid precision: 0.877400, valid loss: 95.059159
epoch: 2131, train precision: 0.999667, train loss: 5.521266, valid precision: 0.871600, valid loss: 96.597602
epoch: 2132, train precision: 0.999622, train loss: 5.500973, valid precision: 0.875000, valid loss: 94.403061
epoch: 2133, train precision: 0.999578, train loss: 5.508996, valid precision: 0.875200, valid loss: 98.529462
epoch: 2134, train precision: 0.999711, train loss: 5.465098, valid precision: 0.872400, valid loss: 97.363916
epoch: 2135, train precision: 0.999822, train loss: 5.465228, valid precision: 0.872600, valid loss: 99.001933
epoch: 2136, train precision: 0.999711, train loss: 5.459480, valid precision: 0.872200, valid loss: 99.350865
epoch: 2137, train precision: 0.999622, train loss: 5.510367, valid precision: 0.871600, valid loss: 97.577860
epoch: 2138, train precision: 0.999800, train loss: 5.503201, valid precision: 0.873400, valid loss: 98.898836
epoch: 2139, train precision: 0.999733, train loss: 5.478821, valid precision: 0.876600, valid loss: 94.968646
epoch: 2140, train precision: 0.999711, train loss: 5.488785, valid precision: 0.873800, valid loss: 94.651895
epoch: 2141, train precision: 0.999644, train loss: 5.510633, valid precision: 0.874400, valid loss: 97.649648
epoch: 2142, train precision: 0.999533, train loss: 5.552305, valid precision: 0.873600, valid loss: 98.984198
epoch: 2143, train precision: 0.999556, train loss: 5.527045, valid precision: 0.871600, valid loss: 97.105598
epoch: 2144, train precision: 0.999511, train loss: 5.543776, valid precision: 0.875000, valid loss: 94.618920
epoch: 2145, train precision: 0.999244, train loss: 5.581424, valid precision: 0.874600, valid loss: 96.966463
epoch: 2146, train precision: 0.999600, train loss: 5.475835, valid precision: 0.875000, valid loss: 97.362367
epoch: 2147, train precision: 0.999733, train loss: 5.480919, valid precision: 0.872600, valid loss: 96.303446
epoch: 2148, train precision: 0.999600, train loss: 5.483901, valid precision: 0.873200, valid loss: 94.900734
epoch: 2149, train precision: 0.999489, train loss: 5.513570, valid precision: 0.877600, valid loss: 96.697019
epoch: 2150, train precision: 0.999489, train loss: 5.538709, valid precision: 0.875400, valid loss: 97.295334
epoch: 2151, train precision: 0.999733, train loss: 5.441710, valid precision: 0.876800, valid loss: 94.743325
epoch: 2152, train precision: 0.999578, train loss: 5.467126, valid precision: 0.875200, valid loss: 95.726053
epoch: 2153, train precision: 0.999400, train loss: 5.570237, valid precision: 0.874600, valid loss: 98.380921
epoch: 2154, train precision: 0.999756, train loss: 5.472811, valid precision: 0.877000, valid loss: 95.810035
epoch: 2155, train precision: 0.999556, train loss: 5.557014, valid precision: 0.877200, valid loss: 96.223172
epoch: 2156, train precision: 0.999711, train loss: 5.474132, valid precision: 0.878600, valid loss: 93.540864
epoch: 2157, train precision: 0.999711, train loss: 5.515322, valid precision: 0.876400, valid loss: 97.048679
epoch: 2158, train precision: 0.999578, train loss: 5.508172, valid precision: 0.879200, valid loss: 95.242909
epoch: 2159, train precision: 0.999711, train loss: 5.479554, valid precision: 0.880400, valid loss: 94.140991
epoch: 2160, train precision: 0.999467, train loss: 5.555287, valid precision: 0.876400, valid loss: 99.566159
epoch: 2161, train precision: 0.999533, train loss: 5.519762, valid precision: 0.877800, valid loss: 95.833748
epoch: 2162, train precision: 0.999556, train loss: 5.508982, valid precision: 0.876000, valid loss: 98.141901
epoch: 2163, train precision: 0.999400, train loss: 5.617889, valid precision: 0.877800, valid loss: 95.278747
epoch: 2164, train precision: 0.999689, train loss: 5.468839, valid precision: 0.873800, valid loss: 94.928805
epoch: 2165, train precision: 0.999600, train loss: 5.486518, valid precision: 0.873800, valid loss: 94.174633
epoch: 2166, train precision: 0.999644, train loss: 5.503013, valid precision: 0.874200, valid loss: 96.462403
epoch: 2167, train precision: 0.999733, train loss: 5.496912, valid precision: 0.876800, valid loss: 95.133254
epoch: 2168, train precision: 0.999711, train loss: 5.494726, valid precision: 0.876200, valid loss: 94.161614
epoch: 2169, train precision: 0.999689, train loss: 5.474325, valid precision: 0.879600, valid loss: 94.772204
epoch: 2170, train precision: 0.999778, train loss: 5.442610, valid precision: 0.875800, valid loss: 95.909828
epoch: 2171, train precision: 0.999689, train loss: 5.462732, valid precision: 0.875400, valid loss: 97.576785
epoch: 2172, train precision: 0.999511, train loss: 5.539616, valid precision: 0.879200, valid loss: 96.394722
epoch: 2173, train precision: 0.999622, train loss: 5.505746, valid precision: 0.874000, valid loss: 97.309063
epoch: 2174, train precision: 0.999733, train loss: 5.493242, valid precision: 0.876600, valid loss: 94.714032
epoch: 2175, train precision: 0.999711, train loss: 5.453611, valid precision: 0.875400, valid loss: 96.851783
epoch: 2176, train precision: 0.999822, train loss: 5.469323, valid precision: 0.876000, valid loss: 95.040257
epoch: 2177, train precision: 0.999511, train loss: 5.515483, valid precision: 0.878600, valid loss: 94.833520
epoch: 2178, train precision: 0.999822, train loss: 5.445854, valid precision: 0.874600, valid loss: 94.255844
epoch: 2179, train precision: 0.999556, train loss: 5.530710, valid precision: 0.879200, valid loss: 93.125687
epoch: 2180, train precision: 0.999578, train loss: 5.533643, valid precision: 0.877800, valid loss: 94.567054
epoch: 2181, train precision: 0.999756, train loss: 5.464519, valid precision: 0.874400, valid loss: 96.011903
epoch: 2182, train precision: 0.999667, train loss: 5.491309, valid precision: 0.875200, valid loss: 94.363577
epoch: 2183, train precision: 0.999556, train loss: 5.515272, valid precision: 0.874600, valid loss: 97.281961
epoch: 2184, train precision: 0.999467, train loss: 5.549779, valid precision: 0.874400, valid loss: 94.794516
epoch: 2185, train precision: 0.999778, train loss: 5.450863, valid precision: 0.875800, valid loss: 95.907851
epoch: 2186, train precision: 0.999622, train loss: 5.473074, valid precision: 0.876600, valid loss: 96.303045
epoch: 2187, train precision: 0.999622, train loss: 5.509603, valid precision: 0.875000, valid loss: 97.407261
epoch: 2188, train precision: 0.999644, train loss: 5.490220, valid precision: 0.877200, valid loss: 98.049360
epoch: 2189, train precision: 0.999822, train loss: 5.456018, valid precision: 0.875000, valid loss: 96.305028
epoch: 2190, train precision: 0.999733, train loss: 5.477028, valid precision: 0.876000, valid loss: 97.240137
epoch: 2191, train precision: 0.999644, train loss: 5.526254, valid precision: 0.873600, valid loss: 97.338434
epoch: 2192, train precision: 0.999533, train loss: 5.518920, valid precision: 0.876200, valid loss: 96.854692
epoch: 2193, train precision: 0.999711, train loss: 5.465173, valid precision: 0.874000, valid loss: 97.998561
epoch: 2194, train precision: 0.999689, train loss: 5.468279, valid precision: 0.877400, valid loss: 96.376114
epoch: 2195, train precision: 0.999533, train loss: 5.477036, valid precision: 0.876200, valid loss: 95.100664
epoch: 2196, train precision: 0.999622, train loss: 5.474751, valid precision: 0.876000, valid loss: 96.367868
epoch: 2197, train precision: 0.999689, train loss: 5.428748, valid precision: 0.874600, valid loss: 98.146745
epoch: 2198, train precision: 0.999689, train loss: 5.458045, valid precision: 0.874600, valid loss: 97.530349
epoch: 2199, train precision: 0.999822, train loss: 5.478139, valid precision: 0.875600, valid loss: 95.314537
epoch: 2200, train precision: 0.999800, train loss: 5.452024, valid precision: 0.874200, valid loss: 93.597027
epoch: 2201, train precision: 0.999511, train loss: 5.522285, valid precision: 0.877800, valid loss: 96.343425
epoch: 2202, train precision: 0.999711, train loss: 5.515829, valid precision: 0.875600, valid loss: 94.165813
epoch: 2203, train precision: 0.999778, train loss: 5.447881, valid precision: 0.877800, valid loss: 95.992921
epoch: 2204, train precision: 0.999667, train loss: 5.474052, valid precision: 0.875800, valid loss: 96.564860
epoch: 2205, train precision: 0.999733, train loss: 5.444458, valid precision: 0.876400, valid loss: 96.470131
epoch: 2206, train precision: 0.999600, train loss: 5.479652, valid precision: 0.874400, valid loss: 97.970319
epoch: 2207, train precision: 0.999800, train loss: 5.454046, valid precision: 0.874000, valid loss: 96.343171
epoch: 2208, train precision: 0.999689, train loss: 5.491395, valid precision: 0.872200, valid loss: 98.103421
epoch: 2209, train precision: 0.999533, train loss: 5.549223, valid precision: 0.876400, valid loss: 96.784986
epoch: 2210, train precision: 0.999467, train loss: 5.548121, valid precision: 0.873400, valid loss: 101.645623
epoch: 2211, train precision: 0.999600, train loss: 5.509227, valid precision: 0.876000, valid loss: 98.978984
epoch: 2212, train precision: 0.999778, train loss: 5.436271, valid precision: 0.873600, valid loss: 98.960765
epoch: 2213, train precision: 0.999356, train loss: 5.560815, valid precision: 0.874600, valid loss: 98.614395
epoch: 2214, train precision: 0.999778, train loss: 5.440017, valid precision: 0.876000, valid loss: 97.535545
epoch: 2215, train precision: 0.999400, train loss: 5.563157, valid precision: 0.877000, valid loss: 99.101428
epoch: 2216, train precision: 0.999800, train loss: 5.468046, valid precision: 0.874800, valid loss: 99.590423
epoch: 2217, train precision: 0.999756, train loss: 5.463708, valid precision: 0.875000, valid loss: 95.625380
epoch: 2218, train precision: 0.999667, train loss: 5.502535, valid precision: 0.878800, valid loss: 96.444614
epoch: 2219, train precision: 0.999600, train loss: 5.497325, valid precision: 0.878400, valid loss: 95.624234
epoch: 2220, train precision: 0.999444, train loss: 5.530553, valid precision: 0.879200, valid loss: 92.967110
epoch: 2221, train precision: 0.999600, train loss: 5.532806, valid precision: 0.877800, valid loss: 95.349471
epoch: 2222, train precision: 0.999600, train loss: 5.513174, valid precision: 0.878400, valid loss: 97.678251
epoch: 2223, train precision: 0.999667, train loss: 5.469271, valid precision: 0.876600, valid loss: 95.718415
epoch: 2224, train precision: 0.999533, train loss: 5.480707, valid precision: 0.873200, valid loss: 95.582024
epoch: 2225, train precision: 0.999556, train loss: 5.518448, valid precision: 0.876200, valid loss: 95.331140
epoch: 2226, train precision: 0.999578, train loss: 5.517239, valid precision: 0.877600, valid loss: 97.873933
epoch: 2227, train precision: 0.999578, train loss: 5.504589, valid precision: 0.876600, valid loss: 97.192929
epoch: 2228, train precision: 0.999511, train loss: 5.501806, valid precision: 0.874800, valid loss: 98.095870
epoch: 2229, train precision: 0.999689, train loss: 5.476711, valid precision: 0.877200, valid loss: 95.656074
epoch: 2230, train precision: 0.999689, train loss: 5.473750, valid precision: 0.873800, valid loss: 95.878088
epoch: 2231, train precision: 0.999667, train loss: 5.495285, valid precision: 0.873600, valid loss: 99.016419
epoch: 2232, train precision: 0.999733, train loss: 5.465335, valid precision: 0.872400, valid loss: 98.639035
epoch: 2233, train precision: 0.999511, train loss: 5.542968, valid precision: 0.872400, valid loss: 97.692717
epoch: 2234, train precision: 0.999644, train loss: 5.481858, valid precision: 0.876200, valid loss: 93.381965
epoch: 2235, train precision: 0.999511, train loss: 5.497656, valid precision: 0.876200, valid loss: 92.924859
epoch: 2236, train precision: 0.999511, train loss: 5.550344, valid precision: 0.872600, valid loss: 95.286320
epoch: 2237, train precision: 0.999667, train loss: 5.503512, valid precision: 0.879600, valid loss: 94.444196
epoch: 2238, train precision: 0.999622, train loss: 5.476838, valid precision: 0.875800, valid loss: 94.636878
epoch: 2239, train precision: 0.999578, train loss: 5.517403, valid precision: 0.875400, valid loss: 94.572083
epoch: 2240, train precision: 0.999711, train loss: 5.505532, valid precision: 0.880200, valid loss: 96.290819
epoch: 2241, train precision: 0.999578, train loss: 5.518545, valid precision: 0.875600, valid loss: 95.459899
epoch: 2242, train precision: 0.999356, train loss: 5.556476, valid precision: 0.875000, valid loss: 95.598198
epoch: 2243, train precision: 0.999711, train loss: 5.495215, valid precision: 0.879200, valid loss: 95.438687
epoch: 2244, train precision: 0.999733, train loss: 5.496419, valid precision: 0.879600, valid loss: 94.814449
epoch: 2245, train precision: 0.999511, train loss: 5.499683, valid precision: 0.877000, valid loss: 95.118589
epoch: 2246, train precision: 0.999600, train loss: 5.491785, valid precision: 0.878000, valid loss: 93.260653
epoch: 2247, train precision: 0.999844, train loss: 5.449334, valid precision: 0.878200, valid loss: 96.980990
epoch: 2248, train precision: 0.999778, train loss: 5.443150, valid precision: 0.879800, valid loss: 96.121081
epoch: 2249, train precision: 0.999467, train loss: 5.535461, valid precision: 0.875600, valid loss: 96.172997
epoch: 2250, train precision: 0.999600, train loss: 5.494112, valid precision: 0.876800, valid loss: 95.712660
epoch: 2251, train precision: 0.999689, train loss: 5.523095, valid precision: 0.875800, valid loss: 95.315476
epoch: 2252, train precision: 0.999644, train loss: 5.507344, valid precision: 0.877800, valid loss: 95.503349
epoch: 2253, train precision: 0.999667, train loss: 5.498267, valid precision: 0.879000, valid loss: 97.076698
epoch: 2254, train precision: 0.999689, train loss: 5.483765, valid precision: 0.873600, valid loss: 98.643760
epoch: 2255, train precision: 0.999711, train loss: 5.471253, valid precision: 0.873600, valid loss: 99.673407
epoch: 2256, train precision: 0.999756, train loss: 5.477998, valid precision: 0.873200, valid loss: 99.148127
epoch: 2257, train precision: 0.999578, train loss: 5.516333, valid precision: 0.876600, valid loss: 97.866960
epoch: 2258, train precision: 0.999578, train loss: 5.536974, valid precision: 0.874600, valid loss: 100.231803
epoch: 2259, train precision: 0.999778, train loss: 5.461181, valid precision: 0.878000, valid loss: 96.470276
epoch: 2260, train precision: 0.999711, train loss: 5.467076, valid precision: 0.875200, valid loss: 98.552026
epoch: 2261, train precision: 0.999600, train loss: 5.507849, valid precision: 0.875600, valid loss: 96.117575
epoch: 2262, train precision: 0.999044, train loss: 5.623838, valid precision: 0.872200, valid loss: 100.848079
epoch: 2263, train precision: 0.999733, train loss: 5.450986, valid precision: 0.873400, valid loss: 99.650281
epoch: 2264, train precision: 0.999578, train loss: 5.475118, valid precision: 0.874800, valid loss: 99.878402
epoch: 2265, train precision: 0.999800, train loss: 5.470112, valid precision: 0.872400, valid loss: 97.195255
epoch: 2266, train precision: 0.999556, train loss: 5.495739, valid precision: 0.880000, valid loss: 95.243870
epoch: 2267, train precision: 0.999689, train loss: 5.482848, valid precision: 0.875400, valid loss: 95.650057
epoch: 2268, train precision: 0.999667, train loss: 5.514128, valid precision: 0.875800, valid loss: 95.820250
epoch: 2269, train precision: 0.999489, train loss: 5.560779, valid precision: 0.873800, valid loss: 98.033628
epoch: 2270, train precision: 0.999733, train loss: 5.474644, valid precision: 0.872400, valid loss: 97.326784
epoch: 2271, train precision: 0.999600, train loss: 5.506805, valid precision: 0.874200, valid loss: 97.736663
epoch: 2272, train precision: 0.999622, train loss: 5.498991, valid precision: 0.877200, valid loss: 96.526544
epoch: 2273, train precision: 0.999644, train loss: 5.472300, valid precision: 0.873000, valid loss: 97.928585
epoch: 2274, train precision: 0.999600, train loss: 5.475564, valid precision: 0.877400, valid loss: 96.295057
epoch: 2275, train precision: 0.999511, train loss: 5.514670, valid precision: 0.879000, valid loss: 95.794672
epoch: 2276, train precision: 0.999644, train loss: 5.485841, valid precision: 0.877400, valid loss: 97.758540
epoch: 2277, train precision: 0.999444, train loss: 5.548754, valid precision: 0.876600, valid loss: 100.188986
epoch: 2278, train precision: 0.999511, train loss: 5.488287, valid precision: 0.877800, valid loss: 98.215784
epoch: 2279, train precision: 0.999644, train loss: 5.490259, valid precision: 0.876200, valid loss: 96.430719
epoch: 2280, train precision: 0.999756, train loss: 5.456120, valid precision: 0.877200, valid loss: 96.419600
epoch: 2281, train precision: 0.999800, train loss: 5.448658, valid precision: 0.879400, valid loss: 97.267738
epoch: 2282, train precision: 0.999711, train loss: 5.479098, valid precision: 0.878800, valid loss: 95.498844
epoch: 2283, train precision: 0.999667, train loss: 5.522409, valid precision: 0.878200, valid loss: 96.062159
epoch: 2284, train precision: 0.999711, train loss: 5.471892, valid precision: 0.877400, valid loss: 96.390595
epoch: 2285, train precision: 0.999400, train loss: 5.521849, valid precision: 0.879200, valid loss: 96.303231
epoch: 2286, train precision: 0.999689, train loss: 5.456106, valid precision: 0.878200, valid loss: 95.181298
epoch: 2287, train precision: 0.999689, train loss: 5.512189, valid precision: 0.877200, valid loss: 92.641200
epoch: 2288, train precision: 0.999533, train loss: 5.536879, valid precision: 0.880400, valid loss: 94.805554
epoch: 2289, train precision: 0.999578, train loss: 5.488851, valid precision: 0.879600, valid loss: 94.816341
epoch: 2290, train precision: 0.999622, train loss: 5.504110, valid precision: 0.877000, valid loss: 96.874235
epoch: 2291, train precision: 0.999578, train loss: 5.495695, valid precision: 0.878800, valid loss: 94.828249
epoch: 2292, train precision: 0.999822, train loss: 5.430442, valid precision: 0.876000, valid loss: 96.975549
epoch: 2293, train precision: 0.999733, train loss: 5.467108, valid precision: 0.876800, valid loss: 96.613649
epoch: 2294, train precision: 0.999844, train loss: 5.430154, valid precision: 0.875400, valid loss: 96.026685
epoch: 2295, train precision: 0.999556, train loss: 5.561995, valid precision: 0.876600, valid loss: 98.015131
epoch: 2296, train precision: 0.999711, train loss: 5.483123, valid precision: 0.872800, valid loss: 96.877868
epoch: 2297, train precision: 0.999644, train loss: 5.477781, valid precision: 0.877200, valid loss: 96.824049
epoch: 2298, train precision: 0.999600, train loss: 5.513614, valid precision: 0.876200, valid loss: 97.861756
epoch: 2299, train precision: 0.999578, train loss: 5.501305, valid precision: 0.874800, valid loss: 96.548484
epoch: 2300, train precision: 0.999644, train loss: 5.493080, valid precision: 0.881400, valid loss: 93.470497
epoch: 2301, train precision: 0.999644, train loss: 5.495988, valid precision: 0.877400, valid loss: 95.066774
epoch: 2302, train precision: 0.999578, train loss: 5.503367, valid precision: 0.869800, valid loss: 98.027396
epoch: 2303, train precision: 0.999778, train loss: 5.488931, valid precision: 0.874000, valid loss: 97.312705
epoch: 2304, train precision: 0.999644, train loss: 5.530468, valid precision: 0.871000, valid loss: 99.976441
epoch: 2305, train precision: 0.999600, train loss: 5.515049, valid precision: 0.878200, valid loss: 98.730027
epoch: 2306, train precision: 0.999289, train loss: 5.594042, valid precision: 0.872400, valid loss: 97.347269
epoch: 2307, train precision: 0.999644, train loss: 5.500981, valid precision: 0.875200, valid loss: 96.615915
epoch: 2308, train precision: 0.999667, train loss: 5.494149, valid precision: 0.877600, valid loss: 95.316248
epoch: 2309, train precision: 0.999600, train loss: 5.493012, valid precision: 0.876600, valid loss: 94.495911
epoch: 2310, train precision: 0.999600, train loss: 5.505709, valid precision: 0.876000, valid loss: 96.002284
epoch: 2311, train precision: 0.999733, train loss: 5.469902, valid precision: 0.875200, valid loss: 98.338604
epoch: 2312, train precision: 0.999600, train loss: 5.474094, valid precision: 0.873600, valid loss: 98.167888
epoch: 2313, train precision: 0.999644, train loss: 5.476365, valid precision: 0.876800, valid loss: 97.793300
epoch: 2314, train precision: 0.999578, train loss: 5.491260, valid precision: 0.876400, valid loss: 97.325136
epoch: 2315, train precision: 0.999600, train loss: 5.514840, valid precision: 0.873800, valid loss: 101.425887
epoch: 2316, train precision: 0.999556, train loss: 5.566749, valid precision: 0.872800, valid loss: 99.834493
epoch: 2317, train precision: 0.999600, train loss: 5.542475, valid precision: 0.874000, valid loss: 97.809205
epoch: 2318, train precision: 0.999756, train loss: 5.433151, valid precision: 0.876400, valid loss: 96.734936
epoch: 2319, train precision: 0.999622, train loss: 5.499144, valid precision: 0.874800, valid loss: 100.269601
epoch: 2320, train precision: 0.999778, train loss: 5.435433, valid precision: 0.877800, valid loss: 95.981611
epoch: 2321, train precision: 0.999733, train loss: 5.470273, valid precision: 0.877800, valid loss: 97.295421
epoch: 2322, train precision: 0.999711, train loss: 5.485806, valid precision: 0.876000, valid loss: 97.517371
epoch: 2323, train precision: 0.999556, train loss: 5.515623, valid precision: 0.875600, valid loss: 97.145639
epoch: 2324, train precision: 0.999711, train loss: 5.457490, valid precision: 0.875400, valid loss: 100.525299
epoch: 2325, train precision: 0.999667, train loss: 5.456196, valid precision: 0.872600, valid loss: 100.797035
epoch: 2326, train precision: 0.999733, train loss: 5.434991, valid precision: 0.873400, valid loss: 99.432905
epoch: 2327, train precision: 0.999689, train loss: 5.477972, valid precision: 0.877600, valid loss: 98.138150
epoch: 2328, train precision: 0.999733, train loss: 5.449963, valid precision: 0.877600, valid loss: 96.561114
epoch: 2329, train precision: 0.999644, train loss: 5.479521, valid precision: 0.877000, valid loss: 97.190118
epoch: 2330, train precision: 0.999622, train loss: 5.485977, valid precision: 0.877400, valid loss: 98.318777
epoch: 2331, train precision: 0.999400, train loss: 5.562252, valid precision: 0.870000, valid loss: 95.894669
epoch: 2332, train precision: 0.999756, train loss: 5.453693, valid precision: 0.874400, valid loss: 96.206705
epoch: 2333, train precision: 0.999711, train loss: 5.490083, valid precision: 0.872800, valid loss: 97.859249
epoch: 2334, train precision: 0.999578, train loss: 5.547181, valid precision: 0.873200, valid loss: 98.170547
epoch: 2335, train precision: 0.999444, train loss: 5.552797, valid precision: 0.871200, valid loss: 94.265815
epoch: 2336, train precision: 0.999733, train loss: 5.448238, valid precision: 0.876800, valid loss: 97.104238
epoch: 2337, train precision: 0.999778, train loss: 5.481288, valid precision: 0.873000, valid loss: 94.282515
epoch: 2338, train precision: 0.999689, train loss: 5.474729, valid precision: 0.875000, valid loss: 96.755653
epoch: 2339, train precision: 0.999600, train loss: 5.481459, valid precision: 0.872200, valid loss: 96.284270
epoch: 2340, train precision: 0.999711, train loss: 5.460472, valid precision: 0.874000, valid loss: 94.752030
epoch: 2341, train precision: 0.999644, train loss: 5.465297, valid precision: 0.877000, valid loss: 95.684913
epoch: 2342, train precision: 0.999622, train loss: 5.511828, valid precision: 0.872400, valid loss: 96.862944
epoch: 2343, train precision: 0.999733, train loss: 5.435563, valid precision: 0.875000, valid loss: 96.815680
epoch: 2344, train precision: 0.999556, train loss: 5.504613, valid precision: 0.873200, valid loss: 95.180560
epoch: 2345, train precision: 0.999622, train loss: 5.482011, valid precision: 0.872000, valid loss: 97.883659
epoch: 2346, train precision: 0.999711, train loss: 5.474748, valid precision: 0.874000, valid loss: 95.805011
epoch: 2347, train precision: 0.999644, train loss: 5.522635, valid precision: 0.874200, valid loss: 95.889963
epoch: 2348, train precision: 0.999689, train loss: 5.475176, valid precision: 0.873800, valid loss: 96.011238
epoch: 2349, train precision: 0.999667, train loss: 5.464615, valid precision: 0.876000, valid loss: 96.942360
epoch: 2350, train precision: 0.999711, train loss: 5.482725, valid precision: 0.876400, valid loss: 93.415524
epoch: 2351, train precision: 0.999667, train loss: 5.517680, valid precision: 0.874400, valid loss: 96.134059
epoch: 2352, train precision: 0.999600, train loss: 5.516315, valid precision: 0.874200, valid loss: 98.302871
epoch: 2353, train precision: 0.999689, train loss: 5.473658, valid precision: 0.876600, valid loss: 97.586494
epoch: 2354, train precision: 0.999600, train loss: 5.506809, valid precision: 0.875200, valid loss: 95.602264
epoch: 2355, train precision: 0.999689, train loss: 5.496819, valid precision: 0.875200, valid loss: 95.393780
epoch: 2356, train precision: 0.999578, train loss: 5.495896, valid precision: 0.876200, valid loss: 93.971072
epoch: 2357, train precision: 0.999778, train loss: 5.466942, valid precision: 0.875600, valid loss: 96.043926
epoch: 2358, train precision: 0.999733, train loss: 5.460581, valid precision: 0.878400, valid loss: 94.822598
epoch: 2359, train precision: 0.999622, train loss: 5.506432, valid precision: 0.876200, valid loss: 96.998885
epoch: 2360, train precision: 0.999733, train loss: 5.462545, valid precision: 0.874600, valid loss: 96.761052
epoch: 2361, train precision: 0.999667, train loss: 5.471049, valid precision: 0.875000, valid loss: 96.832445
epoch: 2362, train precision: 0.999533, train loss: 5.474886, valid precision: 0.880800, valid loss: 94.988087
epoch: 2363, train precision: 0.999600, train loss: 5.505047, valid precision: 0.878800, valid loss: 96.254722
epoch: 2364, train precision: 0.999778, train loss: 5.438831, valid precision: 0.877800, valid loss: 94.328297
epoch: 2365, train precision: 0.999711, train loss: 5.461419, valid precision: 0.876800, valid loss: 92.851326
epoch: 2366, train precision: 0.999733, train loss: 5.444752, valid precision: 0.877600, valid loss: 95.683110
epoch: 2367, train precision: 0.999422, train loss: 5.560573, valid precision: 0.874800, valid loss: 97.722109
epoch: 2368, train precision: 0.999600, train loss: 5.495953, valid precision: 0.877000, valid loss: 98.094230
epoch: 2369, train precision: 0.999467, train loss: 5.560804, valid precision: 0.874600, valid loss: 99.009411
epoch: 2370, train precision: 0.999600, train loss: 5.477497, valid precision: 0.879000, valid loss: 98.796481
epoch: 2371, train precision: 0.999689, train loss: 5.468796, valid precision: 0.877400, valid loss: 98.097753
epoch: 2372, train precision: 0.999622, train loss: 5.514806, valid precision: 0.874600, valid loss: 97.241285
epoch: 2373, train precision: 0.999556, train loss: 5.531880, valid precision: 0.876000, valid loss: 95.304578
epoch: 2374, train precision: 0.999733, train loss: 5.459670, valid precision: 0.875000, valid loss: 95.448752
epoch: 2375, train precision: 0.999733, train loss: 5.454681, valid precision: 0.873200, valid loss: 97.531757
epoch: 2376, train precision: 0.999600, train loss: 5.516121, valid precision: 0.875200, valid loss: 97.111124
epoch: 2377, train precision: 0.999533, train loss: 5.515935, valid precision: 0.878200, valid loss: 96.648362
epoch: 2378, train precision: 0.999667, train loss: 5.508535, valid precision: 0.878800, valid loss: 94.897601
epoch: 2379, train precision: 0.999644, train loss: 5.474240, valid precision: 0.875000, valid loss: 97.947977
epoch: 2380, train precision: 0.999711, train loss: 5.468973, valid precision: 0.878600, valid loss: 95.596424
epoch: 2381, train precision: 0.999644, train loss: 5.491809, valid precision: 0.878200, valid loss: 95.299220
epoch: 2382, train precision: 0.999711, train loss: 5.486159, valid precision: 0.872400, valid loss: 96.635653
epoch: 2383, train precision: 0.999600, train loss: 5.496552, valid precision: 0.876200, valid loss: 96.610974
epoch: 2384, train precision: 0.999667, train loss: 5.480992, valid precision: 0.876600, valid loss: 95.129635
epoch: 2385, train precision: 0.999644, train loss: 5.473116, valid precision: 0.878600, valid loss: 96.602329
epoch: 2386, train precision: 0.999756, train loss: 5.451254, valid precision: 0.876400, valid loss: 95.087668
epoch: 2387, train precision: 0.999422, train loss: 5.566694, valid precision: 0.878600, valid loss: 96.898658
epoch: 2388, train precision: 0.999756, train loss: 5.462795, valid precision: 0.875800, valid loss: 96.839414
epoch: 2389, train precision: 0.999533, train loss: 5.526224, valid precision: 0.875200, valid loss: 93.280848
epoch: 2390, train precision: 0.999689, train loss: 5.470302, valid precision: 0.877600, valid loss: 94.697210
epoch: 2391, train precision: 0.999556, train loss: 5.485752, valid precision: 0.878600, valid loss: 95.183081
epoch: 2392, train precision: 0.999644, train loss: 5.457508, valid precision: 0.874800, valid loss: 97.796063
epoch: 2393, train precision: 0.999667, train loss: 5.456967, valid precision: 0.877000, valid loss: 95.691372
epoch: 2394, train precision: 0.999644, train loss: 5.474968, valid precision: 0.876400, valid loss: 94.505039
epoch: 2395, train precision: 0.999578, train loss: 5.493175, valid precision: 0.879000, valid loss: 96.333139
epoch: 2396, train precision: 0.999778, train loss: 5.461541, valid precision: 0.879200, valid loss: 95.353463
epoch: 2397, train precision: 0.999733, train loss: 5.424732, valid precision: 0.876400, valid loss: 94.509039
epoch: 2398, train precision: 0.999711, train loss: 5.450179, valid precision: 0.876400, valid loss: 95.988781
epoch: 2399, train precision: 0.999844, train loss: 5.430042, valid precision: 0.876000, valid loss: 95.659388
epoch: 2400, train precision: 0.999622, train loss: 5.484156, valid precision: 0.879800, valid loss: 93.977596
epoch: 2401, train precision: 0.999689, train loss: 5.467389, valid precision: 0.877000, valid loss: 92.315092
epoch: 2402, train precision: 0.999489, train loss: 5.531875, valid precision: 0.874800, valid loss: 94.115004
epoch: 2403, train precision: 0.999444, train loss: 5.522883, valid precision: 0.871600, valid loss: 94.576350
epoch: 2404, train precision: 0.999733, train loss: 5.492063, valid precision: 0.876200, valid loss: 92.279279
epoch: 2405, train precision: 0.999578, train loss: 5.529590, valid precision: 0.873600, valid loss: 92.681398
epoch: 2406, train precision: 0.999733, train loss: 5.442332, valid precision: 0.874400, valid loss: 94.964272
epoch: 2407, train precision: 0.999689, train loss: 5.442528, valid precision: 0.875600, valid loss: 97.044737
epoch: 2408, train precision: 0.999689, train loss: 5.475549, valid precision: 0.874200, valid loss: 98.144437
epoch: 2409, train precision: 0.999578, train loss: 5.554245, valid precision: 0.873800, valid loss: 97.073034
epoch: 2410, train precision: 0.999756, train loss: 5.459135, valid precision: 0.875200, valid loss: 96.952005
epoch: 2411, train precision: 0.999778, train loss: 5.465058, valid precision: 0.877400, valid loss: 94.651511
epoch: 2412, train precision: 0.999778, train loss: 5.463330, valid precision: 0.872400, valid loss: 98.502670
epoch: 2413, train precision: 0.999822, train loss: 5.443084, valid precision: 0.874200, valid loss: 95.737211
epoch: 2414, train precision: 0.999778, train loss: 5.451407, valid precision: 0.875200, valid loss: 96.424535
epoch: 2415, train precision: 0.999756, train loss: 5.436873, valid precision: 0.875800, valid loss: 98.801386
epoch: 2416, train precision: 0.999711, train loss: 5.446343, valid precision: 0.875800, valid loss: 98.444063
epoch: 2417, train precision: 0.999667, train loss: 5.447549, valid precision: 0.874400, valid loss: 100.812600
epoch: 2418, train precision: 0.999667, train loss: 5.433435, valid precision: 0.877000, valid loss: 96.161123
epoch: 2419, train precision: 0.999667, train loss: 5.487621, valid precision: 0.875400, valid loss: 98.527569
epoch: 2420, train precision: 0.999556, train loss: 5.493602, valid precision: 0.873000, valid loss: 98.152243
epoch: 2421, train precision: 0.999578, train loss: 5.504208, valid precision: 0.875200, valid loss: 96.934680
epoch: 2422, train precision: 0.999644, train loss: 5.447006, valid precision: 0.878800, valid loss: 95.851675
epoch: 2423, train precision: 0.999622, train loss: 5.450924, valid precision: 0.876400, valid loss: 97.418904
epoch: 2424, train precision: 0.999733, train loss: 5.465256, valid precision: 0.876200, valid loss: 95.337288
epoch: 2425, train precision: 0.999511, train loss: 5.532042, valid precision: 0.872000, valid loss: 100.326483
epoch: 2426, train precision: 0.999511, train loss: 5.544551, valid precision: 0.873600, valid loss: 95.067006
epoch: 2427, train precision: 0.999822, train loss: 5.420853, valid precision: 0.873200, valid loss: 96.324431
epoch: 2428, train precision: 0.999733, train loss: 5.427538, valid precision: 0.872200, valid loss: 98.156964
epoch: 2429, train precision: 0.999644, train loss: 5.502877, valid precision: 0.877400, valid loss: 97.783630
epoch: 2430, train precision: 0.999556, train loss: 5.486061, valid precision: 0.872800, valid loss: 97.452670
epoch: 2431, train precision: 0.999378, train loss: 5.537660, valid precision: 0.875600, valid loss: 97.671222
epoch: 2432, train precision: 0.999778, train loss: 5.459536, valid precision: 0.876400, valid loss: 95.382255
epoch: 2433, train precision: 0.999422, train loss: 5.537686, valid precision: 0.874000, valid loss: 96.746566
epoch: 2434, train precision: 0.999733, train loss: 5.434388, valid precision: 0.872800, valid loss: 96.670541
epoch: 2435, train precision: 0.999600, train loss: 5.470270, valid precision: 0.877200, valid loss: 95.713047
epoch: 2436, train precision: 0.999733, train loss: 5.447233, valid precision: 0.874800, valid loss: 98.727713
epoch: 2437, train precision: 0.999822, train loss: 5.464230, valid precision: 0.875400, valid loss: 96.600240
epoch: 2438, train precision: 0.999733, train loss: 5.445338, valid precision: 0.878400, valid loss: 94.022758
epoch: 2439, train precision: 0.999711, train loss: 5.453038, valid precision: 0.871200, valid loss: 98.888873
epoch: 2440, train precision: 0.999556, train loss: 5.462068, valid precision: 0.876400, valid loss: 97.573579
epoch: 2441, train precision: 0.999644, train loss: 5.458835, valid precision: 0.875600, valid loss: 99.289450
epoch: 2442, train precision: 0.999222, train loss: 5.608675, valid precision: 0.871000, valid loss: 101.324113
epoch: 2443, train precision: 0.999578, train loss: 5.478296, valid precision: 0.870400, valid loss: 98.024643
epoch: 2444, train precision: 0.999644, train loss: 5.494966, valid precision: 0.872800, valid loss: 96.935872
epoch: 2445, train precision: 0.999756, train loss: 5.426645, valid precision: 0.873800, valid loss: 92.490239
epoch: 2446, train precision: 0.999756, train loss: 5.442719, valid precision: 0.877400, valid loss: 96.157151
epoch: 2447, train precision: 0.999622, train loss: 5.469964, valid precision: 0.876600, valid loss: 95.869248
epoch: 2448, train precision: 0.999311, train loss: 5.572275, valid precision: 0.875800, valid loss: 100.408045
epoch: 2449, train precision: 0.999689, train loss: 5.458247, valid precision: 0.876400, valid loss: 94.386965
epoch: 2450, train precision: 0.999644, train loss: 5.492759, valid precision: 0.875600, valid loss: 92.571099
epoch: 2451, train precision: 0.999800, train loss: 5.442295, valid precision: 0.871600, valid loss: 97.743519
epoch: 2452, train precision: 0.999778, train loss: 5.431654, valid precision: 0.874800, valid loss: 94.602147
epoch: 2453, train precision: 0.999756, train loss: 5.457028, valid precision: 0.877800, valid loss: 95.735991
epoch: 2454, train precision: 0.999622, train loss: 5.499919, valid precision: 0.871800, valid loss: 97.992561
epoch: 2455, train precision: 0.999533, train loss: 5.481117, valid precision: 0.875400, valid loss: 99.922440
epoch: 2456, train precision: 0.999511, train loss: 5.508099, valid precision: 0.874600, valid loss: 99.708070
epoch: 2457, train precision: 0.999622, train loss: 5.457009, valid precision: 0.873600, valid loss: 96.366561
epoch: 2458, train precision: 0.999778, train loss: 5.435222, valid precision: 0.879200, valid loss: 94.343711
epoch: 2459, train precision: 0.999578, train loss: 5.496592, valid precision: 0.879000, valid loss: 96.376718
epoch: 2460, train precision: 0.999756, train loss: 5.459352, valid precision: 0.876000, valid loss: 96.636157
epoch: 2461, train precision: 0.999667, train loss: 5.486106, valid precision: 0.880200, valid loss: 95.110648
epoch: 2462, train precision: 0.999689, train loss: 5.445195, valid precision: 0.876800, valid loss: 96.610903
epoch: 2463, train precision: 0.999600, train loss: 5.475530, valid precision: 0.877800, valid loss: 96.617593
epoch: 2464, train precision: 0.999644, train loss: 5.470716, valid precision: 0.874400, valid loss: 94.737768
epoch: 2465, train precision: 0.999600, train loss: 5.488143, valid precision: 0.877200, valid loss: 95.272006
epoch: 2466, train precision: 0.999622, train loss: 5.470263, valid precision: 0.876400, valid loss: 91.816619
epoch: 2467, train precision: 0.999622, train loss: 5.474778, valid precision: 0.878800, valid loss: 93.623978
epoch: 2468, train precision: 0.999778, train loss: 5.440037, valid precision: 0.880400, valid loss: 95.739327
epoch: 2469, train precision: 0.999733, train loss: 5.472939, valid precision: 0.873200, valid loss: 96.127487
epoch: 2470, train precision: 0.999689, train loss: 5.448561, valid precision: 0.876600, valid loss: 93.674658
epoch: 2471, train precision: 0.999578, train loss: 5.499555, valid precision: 0.878600, valid loss: 95.894598
epoch: 2472, train precision: 0.999622, train loss: 5.448708, valid precision: 0.879400, valid loss: 94.282353
epoch: 2473, train precision: 0.999667, train loss: 5.479755, valid precision: 0.877600, valid loss: 94.051347
epoch: 2474, train precision: 0.999489, train loss: 5.529127, valid precision: 0.877200, valid loss: 95.121198
epoch: 2475, train precision: 0.999689, train loss: 5.466210, valid precision: 0.877400, valid loss: 94.118954
epoch: 2476, train precision: 0.999667, train loss: 5.450932, valid precision: 0.877600, valid loss: 95.378896
epoch: 2477, train precision: 0.999644, train loss: 5.447528, valid precision: 0.877000, valid loss: 95.899614
epoch: 2478, train precision: 0.999733, train loss: 5.450612, valid precision: 0.875000, valid loss: 95.005991
epoch: 2479, train precision: 0.999733, train loss: 5.462563, valid precision: 0.875800, valid loss: 96.452837
epoch: 2480, train precision: 0.999778, train loss: 5.438642, valid precision: 0.878400, valid loss: 96.497389
epoch: 2481, train precision: 0.999444, train loss: 5.566640, valid precision: 0.877200, valid loss: 93.843047
epoch: 2482, train precision: 0.999733, train loss: 5.457856, valid precision: 0.876600, valid loss: 94.105194
epoch: 2483, train precision: 0.999556, train loss: 5.467710, valid precision: 0.877400, valid loss: 95.171325
epoch: 2484, train precision: 0.999733, train loss: 5.468517, valid precision: 0.876600, valid loss: 93.499742
epoch: 2485, train precision: 0.999600, train loss: 5.451807, valid precision: 0.877200, valid loss: 93.304886
epoch: 2486, train precision: 0.999644, train loss: 5.462525, valid precision: 0.875200, valid loss: 93.822602
epoch: 2487, train precision: 0.999578, train loss: 5.509183, valid precision: 0.872800, valid loss: 99.243090
epoch: 2488, train precision: 0.999733, train loss: 5.438015, valid precision: 0.877600, valid loss: 95.575979
epoch: 2489, train precision: 0.999644, train loss: 5.461252, valid precision: 0.875000, valid loss: 95.061973
epoch: 2490, train precision: 0.999689, train loss: 5.493998, valid precision: 0.875200, valid loss: 96.009844
epoch: 2491, train precision: 0.999667, train loss: 5.480055, valid precision: 0.880600, valid loss: 90.839675
epoch: 2492, train precision: 0.999644, train loss: 5.461049, valid precision: 0.877000, valid loss: 93.701363
epoch: 2493, train precision: 0.999844, train loss: 5.407960, valid precision: 0.876200, valid loss: 92.669398
epoch: 2494, train precision: 0.999778, train loss: 5.427395, valid precision: 0.875000, valid loss: 94.480306
epoch: 2495, train precision: 0.999667, train loss: 5.461492, valid precision: 0.876600, valid loss: 96.436608
epoch: 2496, train precision: 0.999489, train loss: 5.518612, valid precision: 0.875400, valid loss: 95.934219
epoch: 2497, train precision: 0.999489, train loss: 5.511479, valid precision: 0.876200, valid loss: 96.059549
epoch: 2498, train precision: 0.999689, train loss: 5.443468, valid precision: 0.876800, valid loss: 92.397099
epoch: 2499, train precision: 0.999711, train loss: 5.450338, valid precision: 0.880200, valid loss: 91.829642
epoch: 2500, train precision: 0.999667, train loss: 5.472257, valid precision: 0.878400, valid loss: 95.128034
epoch: 2501, train precision: 0.999644, train loss: 5.476725, valid precision: 0.876200, valid loss: 95.046644
epoch: 2502, train precision: 0.999733, train loss: 5.458377, valid precision: 0.876800, valid loss: 91.238702
epoch: 2503, train precision: 0.999711, train loss: 5.454795, valid precision: 0.876800, valid loss: 94.480632
epoch: 2504, train precision: 0.999733, train loss: 5.427006, valid precision: 0.874800, valid loss: 94.753005
epoch: 2505, train precision: 0.999756, train loss: 5.432533, valid precision: 0.875400, valid loss: 95.870708
epoch: 2506, train precision: 0.999578, train loss: 5.474162, valid precision: 0.878600, valid loss: 96.050761
epoch: 2507, train precision: 0.999667, train loss: 5.503269, valid precision: 0.877200, valid loss: 92.822787
epoch: 2508, train precision: 0.999578, train loss: 5.504342, valid precision: 0.879600, valid loss: 92.886285
epoch: 2509, train precision: 0.999667, train loss: 5.446070, valid precision: 0.876000, valid loss: 96.169576
epoch: 2510, train precision: 0.999756, train loss: 5.422904, valid precision: 0.875600, valid loss: 98.285568
epoch: 2511, train precision: 0.999622, train loss: 5.466234, valid precision: 0.876800, valid loss: 98.049939
epoch: 2512, train precision: 0.999556, train loss: 5.492442, valid precision: 0.878200, valid loss: 97.706010
epoch: 2513, train precision: 0.999578, train loss: 5.455595, valid precision: 0.876600, valid loss: 99.061233
epoch: 2514, train precision: 0.999667, train loss: 5.468684, valid precision: 0.874800, valid loss: 97.861261
epoch: 2515, train precision: 0.999778, train loss: 5.424692, valid precision: 0.879400, valid loss: 96.239468
epoch: 2516, train precision: 0.999711, train loss: 5.436254, valid precision: 0.878200, valid loss: 95.799456
epoch: 2517, train precision: 0.999644, train loss: 5.457513, valid precision: 0.877400, valid loss: 95.209957
epoch: 2518, train precision: 0.999578, train loss: 5.463791, valid precision: 0.875800, valid loss: 96.637316
epoch: 2519, train precision: 0.999644, train loss: 5.477621, valid precision: 0.874800, valid loss: 98.238535
epoch: 2520, train precision: 0.999556, train loss: 5.475057, valid precision: 0.874200, valid loss: 96.024056
epoch: 2521, train precision: 0.999644, train loss: 5.462024, valid precision: 0.877600, valid loss: 94.852801
epoch: 2522, train precision: 0.999267, train loss: 5.554832, valid precision: 0.872400, valid loss: 98.214351
epoch: 2523, train precision: 0.999867, train loss: 5.417416, valid precision: 0.875000, valid loss: 95.663578
epoch: 2524, train precision: 0.999556, train loss: 5.482425, valid precision: 0.877000, valid loss: 94.451857
epoch: 2525, train precision: 0.999867, train loss: 5.396564, valid precision: 0.873800, valid loss: 94.802777
epoch: 2526, train precision: 0.999844, train loss: 5.415494, valid precision: 0.875400, valid loss: 95.549736
epoch: 2527, train precision: 0.999578, train loss: 5.488577, valid precision: 0.873800, valid loss: 96.635683
epoch: 2528, train precision: 0.999667, train loss: 5.440377, valid precision: 0.877400, valid loss: 96.000520
epoch: 2529, train precision: 0.999511, train loss: 5.454634, valid precision: 0.872800, valid loss: 96.357195
epoch: 2530, train precision: 0.999711, train loss: 5.439889, valid precision: 0.874800, valid loss: 97.961965
epoch: 2531, train precision: 0.999622, train loss: 5.466666, valid precision: 0.873000, valid loss: 98.827550
epoch: 2532, train precision: 0.999644, train loss: 5.469432, valid precision: 0.874400, valid loss: 97.799343
epoch: 2533, train precision: 0.999378, train loss: 5.554138, valid precision: 0.874600, valid loss: 99.729374
epoch: 2534, train precision: 0.999644, train loss: 5.475114, valid precision: 0.873600, valid loss: 94.549552
epoch: 2535, train precision: 0.999467, train loss: 5.507492, valid precision: 0.873800, valid loss: 97.916146
epoch: 2536, train precision: 0.999556, train loss: 5.538785, valid precision: 0.874600, valid loss: 97.603809
epoch: 2537, train precision: 0.999644, train loss: 5.473194, valid precision: 0.874200, valid loss: 99.310871
epoch: 2538, train precision: 0.999622, train loss: 5.488616, valid precision: 0.874000, valid loss: 97.086472
epoch: 2539, train precision: 0.999711, train loss: 5.475541, valid precision: 0.874400, valid loss: 96.681292
epoch: 2540, train precision: 0.999689, train loss: 5.449510, valid precision: 0.877800, valid loss: 96.177695
epoch: 2541, train precision: 0.999622, train loss: 5.480198, valid precision: 0.876600, valid loss: 96.776380
epoch: 2542, train precision: 0.999733, train loss: 5.422869, valid precision: 0.878000, valid loss: 96.090525
epoch: 2543, train precision: 0.999711, train loss: 5.456492, valid precision: 0.871600, valid loss: 94.098777
epoch: 2544, train precision: 0.999844, train loss: 5.427996, valid precision: 0.870400, valid loss: 95.085606
epoch: 2545, train precision: 0.999867, train loss: 5.424405, valid precision: 0.873000, valid loss: 96.237786
epoch: 2546, train precision: 0.999600, train loss: 5.427311, valid precision: 0.876200, valid loss: 96.300073
epoch: 2547, train precision: 0.999511, train loss: 5.532964, valid precision: 0.873400, valid loss: 95.488361
epoch: 2548, train precision: 0.999689, train loss: 5.487781, valid precision: 0.875400, valid loss: 96.366649
epoch: 2549, train precision: 0.999800, train loss: 5.434092, valid precision: 0.872200, valid loss: 96.798465
epoch: 2550, train precision: 0.999778, train loss: 5.423091, valid precision: 0.875400, valid loss: 95.708740
epoch: 2551, train precision: 0.999733, train loss: 5.471765, valid precision: 0.876000, valid loss: 96.295174
epoch: 2552, train precision: 0.999756, train loss: 5.424193, valid precision: 0.873600, valid loss: 97.659091
epoch: 2553, train precision: 0.999556, train loss: 5.474957, valid precision: 0.873000, valid loss: 99.103558
epoch: 2554, train precision: 0.999733, train loss: 5.466914, valid precision: 0.874200, valid loss: 96.864092
epoch: 2555, train precision: 0.999644, train loss: 5.501873, valid precision: 0.869600, valid loss: 98.075946
epoch: 2556, train precision: 0.999644, train loss: 5.467250, valid precision: 0.873200, valid loss: 97.841733
epoch: 2557, train precision: 0.999756, train loss: 5.447093, valid precision: 0.874400, valid loss: 96.677934
epoch: 2558, train precision: 0.999600, train loss: 5.504534, valid precision: 0.874600, valid loss: 97.330969
epoch: 2559, train precision: 0.999578, train loss: 5.466465, valid precision: 0.872800, valid loss: 95.967030
epoch: 2560, train precision: 0.999711, train loss: 5.461538, valid precision: 0.875200, valid loss: 95.263651
epoch: 2561, train precision: 0.999644, train loss: 5.469922, valid precision: 0.875000, valid loss: 98.284205
epoch: 2562, train precision: 0.999822, train loss: 5.399535, valid precision: 0.870800, valid loss: 95.362281
epoch: 2563, train precision: 0.999800, train loss: 5.428406, valid precision: 0.871200, valid loss: 96.566269
epoch: 2564, train precision: 0.999778, train loss: 5.443411, valid precision: 0.872600, valid loss: 97.640412
epoch: 2565, train precision: 0.999556, train loss: 5.487567, valid precision: 0.874400, valid loss: 99.909761
epoch: 2566, train precision: 0.999711, train loss: 5.455572, valid precision: 0.874000, valid loss: 99.434459
epoch: 2567, train precision: 0.999822, train loss: 5.418041, valid precision: 0.871800, valid loss: 100.580253
epoch: 2568, train precision: 0.999756, train loss: 5.431868, valid precision: 0.875400, valid loss: 97.468259
epoch: 2569, train precision: 0.999800, train loss: 5.421651, valid precision: 0.875000, valid loss: 97.299053
epoch: 2570, train precision: 0.999644, train loss: 5.448557, valid precision: 0.870600, valid loss: 98.852164
epoch: 2571, train precision: 0.999644, train loss: 5.468071, valid precision: 0.871600, valid loss: 98.068565
epoch: 2572, train precision: 0.999622, train loss: 5.462803, valid precision: 0.873600, valid loss: 98.029073
epoch: 2573, train precision: 0.999667, train loss: 5.459739, valid precision: 0.874400, valid loss: 95.490997
epoch: 2574, train precision: 0.999644, train loss: 5.453017, valid precision: 0.873800, valid loss: 97.666651
epoch: 2575, train precision: 0.999511, train loss: 5.501526, valid precision: 0.874800, valid loss: 98.906245
epoch: 2576, train precision: 0.999422, train loss: 5.524172, valid precision: 0.874200, valid loss: 98.677240
epoch: 2577, train precision: 0.999756, train loss: 5.420051, valid precision: 0.876200, valid loss: 97.381451
epoch: 2578, train precision: 0.999667, train loss: 5.460322, valid precision: 0.879600, valid loss: 94.669534
epoch: 2579, train precision: 0.999733, train loss: 5.462911, valid precision: 0.877200, valid loss: 94.492649
epoch: 2580, train precision: 0.999756, train loss: 5.441521, valid precision: 0.878200, valid loss: 95.097543
epoch: 2581, train precision: 0.999800, train loss: 5.446642, valid precision: 0.878800, valid loss: 94.290098
epoch: 2582, train precision: 0.999822, train loss: 5.418289, valid precision: 0.876800, valid loss: 96.484771
epoch: 2583, train precision: 0.999778, train loss: 5.449344, valid precision: 0.876000, valid loss: 95.706330
epoch: 2584, train precision: 0.999778, train loss: 5.430267, valid precision: 0.877400, valid loss: 95.677836
epoch: 2585, train precision: 0.999822, train loss: 5.429009, valid precision: 0.873200, valid loss: 96.830293
epoch: 2586, train precision: 0.999667, train loss: 5.437118, valid precision: 0.875200, valid loss: 97.468285
epoch: 2587, train precision: 0.999822, train loss: 5.413739, valid precision: 0.876200, valid loss: 96.002319
epoch: 2588, train precision: 0.999644, train loss: 5.451437, valid precision: 0.871800, valid loss: 98.729394
epoch: 2589, train precision: 0.999644, train loss: 5.444902, valid precision: 0.875600, valid loss: 96.136210
epoch: 2590, train precision: 0.999844, train loss: 5.408026, valid precision: 0.877400, valid loss: 93.621469
epoch: 2591, train precision: 0.999511, train loss: 5.477174, valid precision: 0.871800, valid loss: 99.284527
epoch: 2592, train precision: 0.999600, train loss: 5.465080, valid precision: 0.880400, valid loss: 98.378743
epoch: 2593, train precision: 0.999622, train loss: 5.439739, valid precision: 0.874800, valid loss: 98.565067
epoch: 2594, train precision: 0.999689, train loss: 5.449627, valid precision: 0.874600, valid loss: 97.872946
epoch: 2595, train precision: 0.999556, train loss: 5.511049, valid precision: 0.874800, valid loss: 102.072739
epoch: 2596, train precision: 0.999800, train loss: 5.448575, valid precision: 0.873600, valid loss: 98.549786
epoch: 2597, train precision: 0.999578, train loss: 5.494482, valid precision: 0.873600, valid loss: 98.174691
epoch: 2598, train precision: 0.999667, train loss: 5.465793, valid precision: 0.871600, valid loss: 98.606361
epoch: 2599, train precision: 0.999733, train loss: 5.426185, valid precision: 0.875200, valid loss: 96.931998
epoch: 2600, train precision: 0.999800, train loss: 5.411004, valid precision: 0.869400, valid loss: 98.961901
epoch: 2601, train precision: 0.999689, train loss: 5.475543, valid precision: 0.875000, valid loss: 99.061526
epoch: 2602, train precision: 0.999689, train loss: 5.418196, valid precision: 0.877200, valid loss: 99.685356
epoch: 2603, train precision: 0.999667, train loss: 5.452257, valid precision: 0.876400, valid loss: 98.451596
epoch: 2604, train precision: 0.999578, train loss: 5.486833, valid precision: 0.877600, valid loss: 96.463807
epoch: 2605, train precision: 0.999600, train loss: 5.465160, valid precision: 0.876600, valid loss: 98.645144
epoch: 2606, train precision: 0.999711, train loss: 5.425899, valid precision: 0.876800, valid loss: 96.174413
epoch: 2607, train precision: 0.999756, train loss: 5.423576, valid precision: 0.870800, valid loss: 99.288320
epoch: 2608, train precision: 0.999711, train loss: 5.445407, valid precision: 0.870800, valid loss: 98.815464
epoch: 2609, train precision: 0.999689, train loss: 5.445247, valid precision: 0.874200, valid loss: 94.080301
epoch: 2610, train precision: 0.999800, train loss: 5.401869, valid precision: 0.876000, valid loss: 99.649356
epoch: 2611, train precision: 0.999644, train loss: 5.463013, valid precision: 0.874200, valid loss: 97.958632
epoch: 2612, train precision: 0.999533, train loss: 5.463827, valid precision: 0.876000, valid loss: 97.103701
epoch: 2613, train precision: 0.999578, train loss: 5.467068, valid precision: 0.874600, valid loss: 97.349016
epoch: 2614, train precision: 0.999667, train loss: 5.478776, valid precision: 0.875000, valid loss: 99.337632
epoch: 2615, train precision: 0.999667, train loss: 5.477664, valid precision: 0.874400, valid loss: 98.552643
epoch: 2616, train precision: 0.999733, train loss: 5.420377, valid precision: 0.878600, valid loss: 100.228756
epoch: 2617, train precision: 0.999600, train loss: 5.452799, valid precision: 0.879200, valid loss: 99.738091
epoch: 2618, train precision: 0.999467, train loss: 5.468209, valid precision: 0.872800, valid loss: 103.049282
epoch: 2619, train precision: 0.999600, train loss: 5.479217, valid precision: 0.874800, valid loss: 99.744082
epoch: 2620, train precision: 0.999556, train loss: 5.495298, valid precision: 0.870000, valid loss: 98.595028
epoch: 2621, train precision: 0.999600, train loss: 5.462772, valid precision: 0.873800, valid loss: 99.167137
epoch: 2622, train precision: 0.999844, train loss: 5.390788, valid precision: 0.876600, valid loss: 97.439340
epoch: 2623, train precision: 0.999578, train loss: 5.495203, valid precision: 0.874800, valid loss: 100.310730
epoch: 2624, train precision: 0.999756, train loss: 5.434653, valid precision: 0.876600, valid loss: 99.678859
epoch: 2625, train precision: 0.999644, train loss: 5.456311, valid precision: 0.876800, valid loss: 96.668304
epoch: 2626, train precision: 0.999467, train loss: 5.563984, valid precision: 0.872800, valid loss: 100.915626
epoch: 2627, train precision: 0.999756, train loss: 5.411617, valid precision: 0.876800, valid loss: 97.753988
epoch: 2628, train precision: 0.999400, train loss: 5.526487, valid precision: 0.876400, valid loss: 99.279515
epoch: 2629, train precision: 0.999444, train loss: 5.508669, valid precision: 0.876800, valid loss: 98.029043
epoch: 2630, train precision: 0.999644, train loss: 5.509559, valid precision: 0.876000, valid loss: 96.302601
epoch: 2631, train precision: 0.999578, train loss: 5.458560, valid precision: 0.876000, valid loss: 97.794456
epoch: 2632, train precision: 0.999556, train loss: 5.506721, valid precision: 0.876200, valid loss: 97.969076
epoch: 2633, train precision: 0.999689, train loss: 5.442652, valid precision: 0.879600, valid loss: 97.522834
epoch: 2634, train precision: 0.999622, train loss: 5.440524, valid precision: 0.876200, valid loss: 97.147134
epoch: 2635, train precision: 0.999622, train loss: 5.474566, valid precision: 0.878800, valid loss: 96.265211
epoch: 2636, train precision: 0.999644, train loss: 5.455451, valid precision: 0.876400, valid loss: 96.393632
epoch: 2637, train precision: 0.999422, train loss: 5.539940, valid precision: 0.876400, valid loss: 96.146025
epoch: 2638, train precision: 0.999644, train loss: 5.486215, valid precision: 0.878200, valid loss: 94.883791
epoch: 2639, train precision: 0.999778, train loss: 5.414627, valid precision: 0.882000, valid loss: 94.882347
epoch: 2640, train precision: 0.999644, train loss: 5.476262, valid precision: 0.879800, valid loss: 97.330016
epoch: 2641, train precision: 0.999600, train loss: 5.478565, valid precision: 0.877600, valid loss: 98.579432
epoch: 2642, train precision: 0.999667, train loss: 5.476336, valid precision: 0.877600, valid loss: 98.504515
epoch: 2643, train precision: 0.999600, train loss: 5.471457, valid precision: 0.876600, valid loss: 99.658300
epoch: 2644, train precision: 0.999600, train loss: 5.442089, valid precision: 0.876600, valid loss: 97.599644
epoch: 2645, train precision: 0.999711, train loss: 5.424216, valid precision: 0.878800, valid loss: 95.646887
epoch: 2646, train precision: 0.999822, train loss: 5.396803, valid precision: 0.879000, valid loss: 97.324598
epoch: 2647, train precision: 0.999511, train loss: 5.511381, valid precision: 0.878600, valid loss: 98.899240
epoch: 2648, train precision: 0.999733, train loss: 5.425396, valid precision: 0.879400, valid loss: 99.085010
epoch: 2649, train precision: 0.999756, train loss: 5.435766, valid precision: 0.881800, valid loss: 95.826078
epoch: 2650, train precision: 0.999756, train loss: 5.429319, valid precision: 0.878600, valid loss: 97.268843
epoch: 2651, train precision: 0.999733, train loss: 5.435275, valid precision: 0.880400, valid loss: 96.958135
epoch: 2652, train precision: 0.999644, train loss: 5.425980, valid precision: 0.879000, valid loss: 96.282476
epoch: 2653, train precision: 0.999689, train loss: 5.447683, valid precision: 0.885400, valid loss: 95.090740
epoch: 2654, train precision: 0.999689, train loss: 5.462301, valid precision: 0.881000, valid loss: 99.495054
epoch: 2655, train precision: 0.999600, train loss: 5.484124, valid precision: 0.878400, valid loss: 98.747900
epoch: 2656, train precision: 0.999733, train loss: 5.428451, valid precision: 0.877600, valid loss: 99.722838
epoch: 2657, train precision: 0.999578, train loss: 5.453211, valid precision: 0.876800, valid loss: 99.080894
epoch: 2658, train precision: 0.999689, train loss: 5.460716, valid precision: 0.873600, valid loss: 98.818692
epoch: 2659, train precision: 0.999600, train loss: 5.436859, valid precision: 0.878800, valid loss: 98.339385
epoch: 2660, train precision: 0.999733, train loss: 5.427148, valid precision: 0.879400, valid loss: 98.505471
epoch: 2661, train precision: 0.999667, train loss: 5.483317, valid precision: 0.875400, valid loss: 99.556919
epoch: 2662, train precision: 0.999600, train loss: 5.507489, valid precision: 0.876400, valid loss: 97.780440
epoch: 2663, train precision: 0.999578, train loss: 5.476922, valid precision: 0.877000, valid loss: 97.410710
epoch: 2664, train precision: 0.999711, train loss: 5.459517, valid precision: 0.878000, valid loss: 99.349690
epoch: 2665, train precision: 0.999622, train loss: 5.482725, valid precision: 0.875000, valid loss: 100.604481
epoch: 2666, train precision: 0.999733, train loss: 5.438770, valid precision: 0.872800, valid loss: 98.150579
epoch: 2667, train precision: 0.999756, train loss: 5.439515, valid precision: 0.874200, valid loss: 100.905370
epoch: 2668, train precision: 0.999711, train loss: 5.430983, valid precision: 0.875400, valid loss: 98.732664
epoch: 2669, train precision: 0.999600, train loss: 5.436215, valid precision: 0.873800, valid loss: 96.820928
epoch: 2670, train precision: 0.999644, train loss: 5.470752, valid precision: 0.875400, valid loss: 98.898963
epoch: 2671, train precision: 0.999644, train loss: 5.469969, valid precision: 0.876200, valid loss: 99.024018
epoch: 2672, train precision: 0.999600, train loss: 5.492313, valid precision: 0.876000, valid loss: 97.890143
epoch: 2673, train precision: 0.999711, train loss: 5.440906, valid precision: 0.875400, valid loss: 99.186795
epoch: 2674, train precision: 0.999600, train loss: 5.498042, valid precision: 0.875000, valid loss: 98.736759
epoch: 2675, train precision: 0.999711, train loss: 5.414386, valid precision: 0.874400, valid loss: 99.139486
epoch: 2676, train precision: 0.999822, train loss: 5.389370, valid precision: 0.873400, valid loss: 97.558797
epoch: 2677, train precision: 0.999422, train loss: 5.500222, valid precision: 0.870600, valid loss: 103.056265
epoch: 2678, train precision: 0.999778, train loss: 5.435288, valid precision: 0.871600, valid loss: 99.314382
epoch: 2679, train precision: 0.999422, train loss: 5.591261, valid precision: 0.871000, valid loss: 99.341852
epoch: 2680, train precision: 0.999667, train loss: 5.453851, valid precision: 0.870600, valid loss: 100.774105
epoch: 2681, train precision: 0.999711, train loss: 5.442181, valid precision: 0.872200, valid loss: 99.066761
epoch: 2682, train precision: 0.999689, train loss: 5.441462, valid precision: 0.873600, valid loss: 97.609009
epoch: 2683, train precision: 0.999489, train loss: 5.490922, valid precision: 0.873400, valid loss: 99.323182
epoch: 2684, train precision: 0.999622, train loss: 5.453641, valid precision: 0.869600, valid loss: 98.059350
epoch: 2685, train precision: 0.999778, train loss: 5.423719, valid precision: 0.870800, valid loss: 96.381067
epoch: 2686, train precision: 0.999689, train loss: 5.463152, valid precision: 0.872200, valid loss: 97.183237
epoch: 2687, train precision: 0.999689, train loss: 5.464043, valid precision: 0.870000, valid loss: 101.155493
epoch: 2688, train precision: 0.999689, train loss: 5.438137, valid precision: 0.872600, valid loss: 95.846788
epoch: 2689, train precision: 0.999711, train loss: 5.450013, valid precision: 0.871800, valid loss: 97.341730
epoch: 2690, train precision: 0.999667, train loss: 5.452842, valid precision: 0.871800, valid loss: 97.176994
epoch: 2691, train precision: 0.999689, train loss: 5.451222, valid precision: 0.869200, valid loss: 98.532937
epoch: 2692, train precision: 0.999778, train loss: 5.448287, valid precision: 0.870600, valid loss: 101.589809
epoch: 2693, train precision: 0.999711, train loss: 5.453293, valid precision: 0.869200, valid loss: 99.677351
epoch: 2694, train precision: 0.999556, train loss: 5.470253, valid precision: 0.868600, valid loss: 100.664426
epoch: 2695, train precision: 0.999578, train loss: 5.470258, valid precision: 0.873600, valid loss: 101.315839
epoch: 2696, train precision: 0.999889, train loss: 5.416972, valid precision: 0.868800, valid loss: 101.303423
epoch: 2697, train precision: 0.999578, train loss: 5.449655, valid precision: 0.872400, valid loss: 98.010996
epoch: 2698, train precision: 0.999733, train loss: 5.430366, valid precision: 0.874200, valid loss: 99.809104
epoch: 2699, train precision: 0.999600, train loss: 5.464868, valid precision: 0.874200, valid loss: 98.034983
epoch: 2700, train precision: 0.999644, train loss: 5.482080, valid precision: 0.872000, valid loss: 99.390660
epoch: 2701, train precision: 0.999622, train loss: 5.491766, valid precision: 0.870600, valid loss: 101.432895
epoch: 2702, train precision: 0.999600, train loss: 5.499640, valid precision: 0.871600, valid loss: 101.921984
epoch: 2703, train precision: 0.999667, train loss: 5.411632, valid precision: 0.871000, valid loss: 99.030617
epoch: 2704, train precision: 0.999689, train loss: 5.425205, valid precision: 0.871800, valid loss: 98.373396
epoch: 2705, train precision: 0.999644, train loss: 5.454504, valid precision: 0.876400, valid loss: 96.549897
epoch: 2706, train precision: 0.999689, train loss: 5.462466, valid precision: 0.878000, valid loss: 97.918169
epoch: 2707, train precision: 0.999644, train loss: 5.450209, valid precision: 0.869400, valid loss: 99.497799
epoch: 2708, train precision: 0.999778, train loss: 5.439496, valid precision: 0.873600, valid loss: 98.125952
epoch: 2709, train precision: 0.999800, train loss: 5.417483, valid precision: 0.875400, valid loss: 98.249766
epoch: 2710, train precision: 0.999600, train loss: 5.458394, valid precision: 0.872000, valid loss: 100.325252
epoch: 2711, train precision: 0.999800, train loss: 5.435770, valid precision: 0.874800, valid loss: 100.545123
epoch: 2712, train precision: 0.999622, train loss: 5.430561, valid precision: 0.875600, valid loss: 97.836146
epoch: 2713, train precision: 0.999667, train loss: 5.449565, valid precision: 0.875800, valid loss: 96.354729
epoch: 2714, train precision: 0.999733, train loss: 5.466438, valid precision: 0.878400, valid loss: 96.951688
epoch: 2715, train precision: 0.999689, train loss: 5.470774, valid precision: 0.875600, valid loss: 96.604157
epoch: 2716, train precision: 0.999644, train loss: 5.450345, valid precision: 0.878400, valid loss: 97.421512
epoch: 2717, train precision: 0.999800, train loss: 5.425760, valid precision: 0.875000, valid loss: 95.944466
epoch: 2718, train precision: 0.999711, train loss: 5.441682, valid precision: 0.873400, valid loss: 97.450040
epoch: 2719, train precision: 0.999689, train loss: 5.430812, valid precision: 0.874400, valid loss: 98.521214
epoch: 2720, train precision: 0.999667, train loss: 5.430069, valid precision: 0.872000, valid loss: 98.947258
epoch: 2721, train precision: 0.999422, train loss: 5.509427, valid precision: 0.872800, valid loss: 97.000170
epoch: 2722, train precision: 0.999933, train loss: 5.396571, valid precision: 0.874200, valid loss: 98.217270
epoch: 2723, train precision: 0.999644, train loss: 5.443849, valid precision: 0.871200, valid loss: 96.066482
epoch: 2724, train precision: 0.999711, train loss: 5.440070, valid precision: 0.875200, valid loss: 96.320366
epoch: 2725, train precision: 0.999711, train loss: 5.438153, valid precision: 0.873000, valid loss: 93.819594
epoch: 2726, train precision: 0.999778, train loss: 5.412005, valid precision: 0.872800, valid loss: 95.542144
epoch: 2727, train precision: 0.999733, train loss: 5.459590, valid precision: 0.874800, valid loss: 96.722821
epoch: 2728, train precision: 0.999822, train loss: 5.426262, valid precision: 0.875000, valid loss: 97.671616
epoch: 2729, train precision: 0.999778, train loss: 5.412507, valid precision: 0.875200, valid loss: 97.768216
epoch: 2730, train precision: 0.999711, train loss: 5.412424, valid precision: 0.877000, valid loss: 97.168855
epoch: 2731, train precision: 0.999356, train loss: 5.572158, valid precision: 0.872200, valid loss: 98.985646
epoch: 2732, train precision: 0.999733, train loss: 5.452393, valid precision: 0.871800, valid loss: 98.693008
epoch: 2733, train precision: 0.999556, train loss: 5.469961, valid precision: 0.871800, valid loss: 98.359744
epoch: 2734, train precision: 0.999644, train loss: 5.472895, valid precision: 0.875200, valid loss: 99.958909
epoch: 2735, train precision: 0.999733, train loss: 5.429982, valid precision: 0.875400, valid loss: 99.135336
epoch: 2736, train precision: 0.999644, train loss: 5.466534, valid precision: 0.876000, valid loss: 100.347980
epoch: 2737, train precision: 0.999689, train loss: 5.434660, valid precision: 0.877800, valid loss: 100.673350
epoch: 2738, train precision: 0.999667, train loss: 5.452286, valid precision: 0.874200, valid loss: 99.478148
epoch: 2739, train precision: 0.999644, train loss: 5.461753, valid precision: 0.876200, valid loss: 98.442623
epoch: 2740, train precision: 0.999778, train loss: 5.414725, valid precision: 0.872400, valid loss: 103.087909
epoch: 2741, train precision: 0.999644, train loss: 5.438085, valid precision: 0.875400, valid loss: 100.637716
epoch: 2742, train precision: 0.999822, train loss: 5.411399, valid precision: 0.876400, valid loss: 98.584580
epoch: 2743, train precision: 0.999689, train loss: 5.452297, valid precision: 0.874000, valid loss: 100.143468
epoch: 2744, train precision: 0.999689, train loss: 5.442200, valid precision: 0.874400, valid loss: 99.768098
epoch: 2745, train precision: 0.999644, train loss: 5.428792, valid precision: 0.876000, valid loss: 98.848201
epoch: 2746, train precision: 0.999733, train loss: 5.400687, valid precision: 0.873800, valid loss: 100.500017
epoch: 2747, train precision: 0.999733, train loss: 5.459424, valid precision: 0.870600, valid loss: 102.307178
epoch: 2748, train precision: 0.999644, train loss: 5.415923, valid precision: 0.874200, valid loss: 99.766091
epoch: 2749, train precision: 0.999556, train loss: 5.477885, valid precision: 0.871200, valid loss: 98.881616
epoch: 2750, train precision: 0.999778, train loss: 5.414499, valid precision: 0.874000, valid loss: 97.155689
epoch: 2751, train precision: 0.999600, train loss: 5.454727, valid precision: 0.875000, valid loss: 96.406734
epoch: 2752, train precision: 0.999689, train loss: 5.428592, valid precision: 0.873000, valid loss: 98.797576
epoch: 2753, train precision: 0.999356, train loss: 5.534298, valid precision: 0.870200, valid loss: 101.213035
epoch: 2754, train precision: 0.999711, train loss: 5.451023, valid precision: 0.874200, valid loss: 97.892561
epoch: 2755, train precision: 0.999778, train loss: 5.411628, valid precision: 0.873600, valid loss: 96.198808
epoch: 2756, train precision: 0.999622, train loss: 5.453366, valid precision: 0.875000, valid loss: 96.799014
epoch: 2757, train precision: 0.999756, train loss: 5.431358, valid precision: 0.872600, valid loss: 97.683021
epoch: 2758, train precision: 0.999489, train loss: 5.472533, valid precision: 0.874400, valid loss: 97.815394
epoch: 2759, train precision: 0.999711, train loss: 5.417826, valid precision: 0.873400, valid loss: 98.468127
epoch: 2760, train precision: 0.999822, train loss: 5.401231, valid precision: 0.873200, valid loss: 98.037309
epoch: 2761, train precision: 0.999800, train loss: 5.416436, valid precision: 0.871000, valid loss: 100.631425
epoch: 2762, train precision: 0.999600, train loss: 5.459789, valid precision: 0.872000, valid loss: 96.253766
epoch: 2763, train precision: 0.999689, train loss: 5.442926, valid precision: 0.871400, valid loss: 99.697485
epoch: 2764, train precision: 0.999622, train loss: 5.458375, valid precision: 0.874000, valid loss: 98.228007
epoch: 2765, train precision: 0.999644, train loss: 5.447028, valid precision: 0.874200, valid loss: 96.862254
epoch: 2766, train precision: 0.999667, train loss: 5.499481, valid precision: 0.872400, valid loss: 99.068088
epoch: 2767, train precision: 0.999644, train loss: 5.455343, valid precision: 0.872400, valid loss: 98.042623
epoch: 2768, train precision: 0.999800, train loss: 5.407368, valid precision: 0.871400, valid loss: 99.065268
epoch: 2769, train precision: 0.999578, train loss: 5.495750, valid precision: 0.871600, valid loss: 98.504837
epoch: 2770, train precision: 0.999867, train loss: 5.375919, valid precision: 0.874400, valid loss: 98.292109
epoch: 2771, train precision: 0.999689, train loss: 5.485409, valid precision: 0.871400, valid loss: 96.640646
epoch: 2772, train precision: 0.999756, train loss: 5.419164, valid precision: 0.875600, valid loss: 99.418456
epoch: 2773, train precision: 0.999711, train loss: 5.469113, valid precision: 0.874400, valid loss: 99.567451
epoch: 2774, train precision: 0.999556, train loss: 5.471818, valid precision: 0.873400, valid loss: 100.280742
epoch: 2775, train precision: 0.999644, train loss: 5.436923, valid precision: 0.877000, valid loss: 99.609269
epoch: 2776, train precision: 0.999689, train loss: 5.445063, valid precision: 0.877000, valid loss: 98.500807
epoch: 2777, train precision: 0.999644, train loss: 5.460335, valid precision: 0.875000, valid loss: 98.149872
epoch: 2778, train precision: 0.999644, train loss: 5.438433, valid precision: 0.875200, valid loss: 97.251595
epoch: 2779, train precision: 0.999756, train loss: 5.431432, valid precision: 0.870000, valid loss: 100.575836
epoch: 2780, train precision: 0.999400, train loss: 5.493175, valid precision: 0.874200, valid loss: 98.697089
epoch: 2781, train precision: 0.999667, train loss: 5.427899, valid precision: 0.872200, valid loss: 97.800265
epoch: 2782, train precision: 0.999622, train loss: 5.428303, valid precision: 0.877800, valid loss: 98.035764
epoch: 2783, train precision: 0.999733, train loss: 5.435668, valid precision: 0.877800, valid loss: 98.301592
epoch: 2784, train precision: 0.999756, train loss: 5.410331, valid precision: 0.877000, valid loss: 97.025879
epoch: 2785, train precision: 0.999644, train loss: 5.448078, valid precision: 0.874800, valid loss: 99.690174
epoch: 2786, train precision: 0.999533, train loss: 5.479622, valid precision: 0.872000, valid loss: 98.644674
epoch: 2787, train precision: 0.999600, train loss: 5.480072, valid precision: 0.874600, valid loss: 98.536988
epoch: 2788, train precision: 0.999844, train loss: 5.381203, valid precision: 0.875000, valid loss: 98.215726
epoch: 2789, train precision: 0.999733, train loss: 5.442022, valid precision: 0.874600, valid loss: 99.530410
epoch: 2790, train precision: 0.999644, train loss: 5.428159, valid precision: 0.873800, valid loss: 97.030481
epoch: 2791, train precision: 0.999578, train loss: 5.438174, valid precision: 0.875000, valid loss: 99.273114
epoch: 2792, train precision: 0.999733, train loss: 5.409030, valid precision: 0.874600, valid loss: 99.904136
epoch: 2793, train precision: 0.999689, train loss: 5.392643, valid precision: 0.873200, valid loss: 98.941175
epoch: 2794, train precision: 0.999667, train loss: 5.477306, valid precision: 0.870000, valid loss: 102.776274
epoch: 2795, train precision: 0.999711, train loss: 5.459726, valid precision: 0.871800, valid loss: 101.978394
epoch: 2796, train precision: 0.999733, train loss: 5.408622, valid precision: 0.874600, valid loss: 100.647302
epoch: 2797, train precision: 0.999622, train loss: 5.452358, valid precision: 0.877400, valid loss: 99.356997
epoch: 2798, train precision: 0.999689, train loss: 5.431071, valid precision: 0.874400, valid loss: 100.458971
epoch: 2799, train precision: 0.999600, train loss: 5.482535, valid precision: 0.876800, valid loss: 99.327960
epoch: 2800, train precision: 0.999600, train loss: 5.489246, valid precision: 0.874600, valid loss: 102.098402
epoch: 2801, train precision: 0.999644, train loss: 5.458683, valid precision: 0.877400, valid loss: 96.532464
epoch: 2802, train precision: 0.999756, train loss: 5.433967, valid precision: 0.874000, valid loss: 97.829689
epoch: 2803, train precision: 0.999689, train loss: 5.423784, valid precision: 0.874600, valid loss: 101.238558
epoch: 2804, train precision: 0.999844, train loss: 5.392805, valid precision: 0.875600, valid loss: 99.316884
epoch: 2805, train precision: 0.999511, train loss: 5.481867, valid precision: 0.875400, valid loss: 101.395154
epoch: 2806, train precision: 0.999644, train loss: 5.457313, valid precision: 0.874800, valid loss: 100.073986
epoch: 2807, train precision: 0.999667, train loss: 5.480039, valid precision: 0.871600, valid loss: 98.685069
epoch: 2808, train precision: 0.999667, train loss: 5.449052, valid precision: 0.875400, valid loss: 98.053122
epoch: 2809, train precision: 0.999556, train loss: 5.465892, valid precision: 0.875400, valid loss: 100.051021
epoch: 2810, train precision: 0.999689, train loss: 5.440280, valid precision: 0.875200, valid loss: 102.123547
epoch: 2811, train precision: 0.999622, train loss: 5.473423, valid precision: 0.867000, valid loss: 102.034935
epoch: 2812, train precision: 0.999667, train loss: 5.440615, valid precision: 0.875200, valid loss: 98.996214
epoch: 2813, train precision: 0.999489, train loss: 5.500285, valid precision: 0.872800, valid loss: 99.986480
epoch: 2814, train precision: 0.999733, train loss: 5.432631, valid precision: 0.875000, valid loss: 100.642260
epoch: 2815, train precision: 0.999622, train loss: 5.446993, valid precision: 0.874800, valid loss: 98.931919
epoch: 2816, train precision: 0.999578, train loss: 5.460244, valid precision: 0.872800, valid loss: 99.505809
epoch: 2817, train precision: 0.999733, train loss: 5.447235, valid precision: 0.874400, valid loss: 96.633566
epoch: 2818, train precision: 0.999756, train loss: 5.435292, valid precision: 0.874400, valid loss: 101.813294
epoch: 2819, train precision: 0.999644, train loss: 5.426268, valid precision: 0.872800, valid loss: 100.200065
epoch: 2820, train precision: 0.999756, train loss: 5.389608, valid precision: 0.876000, valid loss: 99.936844
epoch: 2821, train precision: 0.999778, train loss: 5.385241, valid precision: 0.875400, valid loss: 98.621701
epoch: 2822, train precision: 0.999556, train loss: 5.473775, valid precision: 0.874000, valid loss: 101.649724
epoch: 2823, train precision: 0.999822, train loss: 5.395354, valid precision: 0.872200, valid loss: 100.898103
epoch: 2824, train precision: 0.999578, train loss: 5.508977, valid precision: 0.875400, valid loss: 99.024378
epoch: 2825, train precision: 0.999622, train loss: 5.472173, valid precision: 0.870400, valid loss: 103.496638
epoch: 2826, train precision: 0.999756, train loss: 5.409987, valid precision: 0.875600, valid loss: 98.609299
epoch: 2827, train precision: 0.999756, train loss: 5.427318, valid precision: 0.876000, valid loss: 97.354162
epoch: 2828, train precision: 0.999667, train loss: 5.412218, valid precision: 0.875800, valid loss: 98.394127
epoch: 2829, train precision: 0.999689, train loss: 5.453760, valid precision: 0.876600, valid loss: 99.613496
epoch: 2830, train precision: 0.999756, train loss: 5.429056, valid precision: 0.874400, valid loss: 101.289941
epoch: 2831, train precision: 0.999778, train loss: 5.407509, valid precision: 0.878200, valid loss: 97.466886
epoch: 2832, train precision: 0.999844, train loss: 5.393726, valid precision: 0.871800, valid loss: 100.826811
epoch: 2833, train precision: 0.999578, train loss: 5.441489, valid precision: 0.876400, valid loss: 97.974812
epoch: 2834, train precision: 0.999622, train loss: 5.469265, valid precision: 0.875200, valid loss: 100.910115
epoch: 2835, train precision: 0.999667, train loss: 5.421169, valid precision: 0.874400, valid loss: 100.373824
epoch: 2836, train precision: 0.999800, train loss: 5.406295, valid precision: 0.875200, valid loss: 100.044920
epoch: 2837, train precision: 0.999711, train loss: 5.428873, valid precision: 0.873400, valid loss: 98.947564
epoch: 2838, train precision: 0.999467, train loss: 5.487347, valid precision: 0.874000, valid loss: 100.954168
epoch: 2839, train precision: 0.999689, train loss: 5.432087, valid precision: 0.873600, valid loss: 99.191444
epoch: 2840, train precision: 0.999756, train loss: 5.437199, valid precision: 0.875400, valid loss: 99.705838
epoch: 2841, train precision: 0.999667, train loss: 5.436065, valid precision: 0.874600, valid loss: 100.154788
epoch: 2842, train precision: 0.999689, train loss: 5.448738, valid precision: 0.872800, valid loss: 99.144173
epoch: 2843, train precision: 0.999800, train loss: 5.362549, valid precision: 0.874000, valid loss: 98.416000
epoch: 2844, train precision: 0.999756, train loss: 5.400863, valid precision: 0.869200, valid loss: 101.054815
epoch: 2845, train precision: 0.999533, train loss: 5.474330, valid precision: 0.872000, valid loss: 101.999258
epoch: 2846, train precision: 0.999800, train loss: 5.426480, valid precision: 0.875600, valid loss: 101.328393
epoch: 2847, train precision: 0.999667, train loss: 5.435081, valid precision: 0.876000, valid loss: 99.694165
epoch: 2848, train precision: 0.999644, train loss: 5.433128, valid precision: 0.872000, valid loss: 101.047227
epoch: 2849, train precision: 0.999667, train loss: 5.445106, valid precision: 0.871000, valid loss: 100.687780
epoch: 2850, train precision: 0.999467, train loss: 5.441079, valid precision: 0.871800, valid loss: 103.162229
epoch: 2851, train precision: 0.999689, train loss: 5.440890, valid precision: 0.874200, valid loss: 101.694977
epoch: 2852, train precision: 0.999578, train loss: 5.432619, valid precision: 0.871400, valid loss: 101.829841
epoch: 2853, train precision: 0.999600, train loss: 5.435541, valid precision: 0.873000, valid loss: 101.298496
epoch: 2854, train precision: 0.999622, train loss: 5.434268, valid precision: 0.870800, valid loss: 101.189538
epoch: 2855, train precision: 0.999733, train loss: 5.411262, valid precision: 0.875800, valid loss: 102.283472
epoch: 2856, train precision: 0.999711, train loss: 5.444182, valid precision: 0.877000, valid loss: 99.766521
epoch: 2857, train precision: 0.999711, train loss: 5.411173, valid precision: 0.875800, valid loss: 98.737480
epoch: 2858, train precision: 0.999756, train loss: 5.411057, valid precision: 0.872000, valid loss: 98.432587
epoch: 2859, train precision: 0.999622, train loss: 5.471486, valid precision: 0.871000, valid loss: 98.686468
epoch: 2860, train precision: 0.999689, train loss: 5.434560, valid precision: 0.874000, valid loss: 100.403228
epoch: 2861, train precision: 0.999622, train loss: 5.466577, valid precision: 0.873800, valid loss: 100.891768
epoch: 2862, train precision: 0.999667, train loss: 5.436351, valid precision: 0.875000, valid loss: 98.709121
epoch: 2863, train precision: 0.999756, train loss: 5.409030, valid precision: 0.875200, valid loss: 101.550801
epoch: 2864, train precision: 0.999533, train loss: 5.470225, valid precision: 0.873200, valid loss: 100.845775
epoch: 2865, train precision: 0.999667, train loss: 5.468104, valid precision: 0.873000, valid loss: 98.834334
epoch: 2866, train precision: 0.999556, train loss: 5.446796, valid precision: 0.873600, valid loss: 99.301263
epoch: 2867, train precision: 0.999822, train loss: 5.386755, valid precision: 0.872400, valid loss: 99.829049
epoch: 2868, train precision: 0.999733, train loss: 5.394806, valid precision: 0.875000, valid loss: 99.083221
epoch: 2869, train precision: 0.999733, train loss: 5.424998, valid precision: 0.872800, valid loss: 100.952955
epoch: 2870, train precision: 0.999733, train loss: 5.418189, valid precision: 0.876400, valid loss: 98.047091
epoch: 2871, train precision: 0.999667, train loss: 5.452168, valid precision: 0.875400, valid loss: 96.080319
epoch: 2872, train precision: 0.999600, train loss: 5.444037, valid precision: 0.878400, valid loss: 96.715571
epoch: 2873, train precision: 0.999667, train loss: 5.453028, valid precision: 0.876400, valid loss: 99.820515
epoch: 2874, train precision: 0.999600, train loss: 5.486822, valid precision: 0.876000, valid loss: 96.462410
epoch: 2875, train precision: 0.999733, train loss: 5.418529, valid precision: 0.877200, valid loss: 100.350075
epoch: 2876, train precision: 0.999711, train loss: 5.449617, valid precision: 0.877200, valid loss: 97.828652
epoch: 2877, train precision: 0.999733, train loss: 5.398900, valid precision: 0.876800, valid loss: 100.726537
epoch: 2878, train precision: 0.999422, train loss: 5.561439, valid precision: 0.878000, valid loss: 103.183015
epoch: 2879, train precision: 0.999667, train loss: 5.415089, valid precision: 0.877400, valid loss: 101.564941
epoch: 2880, train precision: 0.999844, train loss: 5.391154, valid precision: 0.878400, valid loss: 98.033490
epoch: 2881, train precision: 0.999533, train loss: 5.504010, valid precision: 0.871800, valid loss: 102.657957
epoch: 2882, train precision: 0.999711, train loss: 5.437857, valid precision: 0.871000, valid loss: 98.638754
epoch: 2883, train precision: 0.999578, train loss: 5.469862, valid precision: 0.875800, valid loss: 98.334967
epoch: 2884, train precision: 0.999822, train loss: 5.419542, valid precision: 0.875600, valid loss: 97.121026
epoch: 2885, train precision: 0.999733, train loss: 5.415365, valid precision: 0.875200, valid loss: 99.208108
epoch: 2886, train precision: 0.999644, train loss: 5.438086, valid precision: 0.873600, valid loss: 99.523488
epoch: 2887, train precision: 0.999800, train loss: 5.402276, valid precision: 0.874200, valid loss: 99.986676
epoch: 2888, train precision: 0.999689, train loss: 5.418526, valid precision: 0.871800, valid loss: 100.673745
epoch: 2889, train precision: 0.999600, train loss: 5.423973, valid precision: 0.875000, valid loss: 98.003406
epoch: 2890, train precision: 0.999778, train loss: 5.384733, valid precision: 0.875000, valid loss: 98.432421
epoch: 2891, train precision: 0.999511, train loss: 5.474407, valid precision: 0.875800, valid loss: 99.685513
epoch: 2892, train precision: 0.999756, train loss: 5.413849, valid precision: 0.878200, valid loss: 100.328287
epoch: 2893, train precision: 0.999578, train loss: 5.438761, valid precision: 0.873000, valid loss: 98.612991
epoch: 2894, train precision: 0.999622, train loss: 5.432790, valid precision: 0.875800, valid loss: 99.944086
epoch: 2895, train precision: 0.999556, train loss: 5.457695, valid precision: 0.873200, valid loss: 99.141696
epoch: 2896, train precision: 0.999533, train loss: 5.478330, valid precision: 0.873800, valid loss: 96.440508
epoch: 2897, train precision: 0.999689, train loss: 5.419488, valid precision: 0.872600, valid loss: 98.230142
epoch: 2898, train precision: 0.999711, train loss: 5.409758, valid precision: 0.872800, valid loss: 95.553287
epoch: 2899, train precision: 0.999733, train loss: 5.440229, valid precision: 0.876400, valid loss: 97.852396
epoch: 2900, train precision: 0.999689, train loss: 5.450305, valid precision: 0.876600, valid loss: 98.663075
epoch: 2901, train precision: 0.999711, train loss: 5.445722, valid precision: 0.874600, valid loss: 99.080608
epoch: 2902, train precision: 0.999600, train loss: 5.434997, valid precision: 0.875200, valid loss: 97.770880
epoch: 2903, train precision: 0.999667, train loss: 5.409696, valid precision: 0.873200, valid loss: 99.046894
epoch: 2904, train precision: 0.999733, train loss: 5.448306, valid precision: 0.875000, valid loss: 97.811318
epoch: 2905, train precision: 0.999667, train loss: 5.424451, valid precision: 0.877000, valid loss: 96.012003
epoch: 2906, train precision: 0.999778, train loss: 5.389215, valid precision: 0.875200, valid loss: 97.830766
epoch: 2907, train precision: 0.999622, train loss: 5.420630, valid precision: 0.876000, valid loss: 99.203367
epoch: 2908, train precision: 0.999711, train loss: 5.421500, valid precision: 0.874800, valid loss: 100.795160
epoch: 2909, train precision: 0.999689, train loss: 5.425303, valid precision: 0.872800, valid loss: 99.016495
epoch: 2910, train precision: 0.999778, train loss: 5.389600, valid precision: 0.874400, valid loss: 98.870257
epoch: 2911, train precision: 0.999511, train loss: 5.449905, valid precision: 0.870400, valid loss: 100.817093
epoch: 2912, train precision: 0.999867, train loss: 5.388951, valid precision: 0.873800, valid loss: 100.111727
epoch: 2913, train precision: 0.999733, train loss: 5.410031, valid precision: 0.874600, valid loss: 98.240718
epoch: 2914, train precision: 0.999667, train loss: 5.405361, valid precision: 0.877200, valid loss: 99.659463
epoch: 2915, train precision: 0.999711, train loss: 5.418247, valid precision: 0.876200, valid loss: 97.738423
epoch: 2916, train precision: 0.999667, train loss: 5.436453, valid precision: 0.878200, valid loss: 101.542664
epoch: 2917, train precision: 0.999622, train loss: 5.452144, valid precision: 0.875200, valid loss: 103.077236
epoch: 2918, train precision: 0.999756, train loss: 5.426877, valid precision: 0.874600, valid loss: 97.172644
epoch: 2919, train precision: 0.999644, train loss: 5.465016, valid precision: 0.871600, valid loss: 101.789797
epoch: 2920, train precision: 0.999689, train loss: 5.440453, valid precision: 0.875600, valid loss: 100.593236
epoch: 2921, train precision: 0.999778, train loss: 5.418762, valid precision: 0.876000, valid loss: 97.289072
epoch: 2922, train precision: 0.999711, train loss: 5.417136, valid precision: 0.877800, valid loss: 95.617578
epoch: 2923, train precision: 0.999622, train loss: 5.473758, valid precision: 0.875600, valid loss: 99.479968
epoch: 2924, train precision: 0.999778, train loss: 5.425472, valid precision: 0.873800, valid loss: 98.524055
epoch: 2925, train precision: 0.999644, train loss: 5.412133, valid precision: 0.875600, valid loss: 98.163568
epoch: 2926, train precision: 0.999556, train loss: 5.435338, valid precision: 0.874400, valid loss: 98.065898
epoch: 2927, train precision: 0.999622, train loss: 5.418396, valid precision: 0.876800, valid loss: 97.859701
epoch: 2928, train precision: 0.999644, train loss: 5.452715, valid precision: 0.877800, valid loss: 97.346623
epoch: 2929, train precision: 0.999644, train loss: 5.421566, valid precision: 0.876200, valid loss: 94.333500
epoch: 2930, train precision: 0.999533, train loss: 5.453708, valid precision: 0.871600, valid loss: 98.409984
epoch: 2931, train precision: 0.999800, train loss: 5.408212, valid precision: 0.872600, valid loss: 97.755776
epoch: 2932, train precision: 0.999889, train loss: 5.376394, valid precision: 0.877600, valid loss: 93.870675
epoch: 2933, train precision: 0.999733, train loss: 5.417489, valid precision: 0.876000, valid loss: 96.865313
epoch: 2934, train precision: 0.999667, train loss: 5.413777, valid precision: 0.873800, valid loss: 94.898414
epoch: 2935, train precision: 0.999800, train loss: 5.391859, valid precision: 0.877000, valid loss: 96.478349
epoch: 2936, train precision: 0.999600, train loss: 5.423581, valid precision: 0.876600, valid loss: 96.311637
epoch: 2937, train precision: 0.999578, train loss: 5.459650, valid precision: 0.871600, valid loss: 100.989579
epoch: 2938, train precision: 0.999667, train loss: 5.412563, valid precision: 0.872400, valid loss: 101.480156
epoch: 2939, train precision: 0.999644, train loss: 5.416569, valid precision: 0.873200, valid loss: 99.435906
epoch: 2940, train precision: 0.999711, train loss: 5.462078, valid precision: 0.876200, valid loss: 99.680760
epoch: 2941, train precision: 0.999778, train loss: 5.417931, valid precision: 0.873200, valid loss: 98.269516
epoch: 2942, train precision: 0.999622, train loss: 5.418487, valid precision: 0.875400, valid loss: 97.238113
epoch: 2943, train precision: 0.999644, train loss: 5.452227, valid precision: 0.873200, valid loss: 98.697547
epoch: 2944, train precision: 0.999756, train loss: 5.416017, valid precision: 0.874200, valid loss: 95.571529
epoch: 2945, train precision: 0.999733, train loss: 5.406070, valid precision: 0.872400, valid loss: 98.004689
epoch: 2946, train precision: 0.999800, train loss: 5.394982, valid precision: 0.871600, valid loss: 97.313935
epoch: 2947, train precision: 0.999644, train loss: 5.433782, valid precision: 0.874200, valid loss: 97.240585
epoch: 2948, train precision: 0.999711, train loss: 5.437673, valid precision: 0.874800, valid loss: 100.089688
epoch: 2949, train precision: 0.999733, train loss: 5.405257, valid precision: 0.873600, valid loss: 101.491740
epoch: 2950, train precision: 0.999711, train loss: 5.418556, valid precision: 0.871400, valid loss: 101.847558
epoch: 2951, train precision: 0.999533, train loss: 5.463808, valid precision: 0.873800, valid loss: 102.166911
epoch: 2952, train precision: 0.999711, train loss: 5.426315, valid precision: 0.871400, valid loss: 100.420338
epoch: 2953, train precision: 0.999644, train loss: 5.413187, valid precision: 0.875000, valid loss: 100.203488
epoch: 2954, train precision: 0.999667, train loss: 5.445557, valid precision: 0.872400, valid loss: 98.047371
epoch: 2955, train precision: 0.999622, train loss: 5.419338, valid precision: 0.872000, valid loss: 97.966978
epoch: 2956, train precision: 0.999733, train loss: 5.377028, valid precision: 0.872600, valid loss: 97.881538
epoch: 2957, train precision: 0.999644, train loss: 5.434771, valid precision: 0.873800, valid loss: 97.214427
epoch: 2958, train precision: 0.999467, train loss: 5.473289, valid precision: 0.875600, valid loss: 97.877989
epoch: 2959, train precision: 0.999733, train loss: 5.403982, valid precision: 0.873200, valid loss: 97.231666
epoch: 2960, train precision: 0.999867, train loss: 5.383831, valid precision: 0.870800, valid loss: 98.199950
epoch: 2961, train precision: 0.999556, train loss: 5.428242, valid precision: 0.873400, valid loss: 99.549375
epoch: 2962, train precision: 0.999667, train loss: 5.407888, valid precision: 0.875000, valid loss: 96.870765
epoch: 2963, train precision: 0.999778, train loss: 5.387548, valid precision: 0.874000, valid loss: 96.587226
epoch: 2964, train precision: 0.999778, train loss: 5.378923, valid precision: 0.873800, valid loss: 98.263641
epoch: 2965, train precision: 0.999800, train loss: 5.388882, valid precision: 0.874600, valid loss: 98.225939
epoch: 2966, train precision: 0.999600, train loss: 5.411002, valid precision: 0.872800, valid loss: 99.062048
epoch: 2967, train precision: 0.999489, train loss: 5.466928, valid precision: 0.876600, valid loss: 96.912900
epoch: 2968, train precision: 0.999511, train loss: 5.463876, valid precision: 0.874800, valid loss: 96.407996
epoch: 2969, train precision: 0.999733, train loss: 5.421952, valid precision: 0.871600, valid loss: 98.803338
epoch: 2970, train precision: 0.999600, train loss: 5.436110, valid precision: 0.874000, valid loss: 102.167467
epoch: 2971, train precision: 0.999800, train loss: 5.377756, valid precision: 0.875800, valid loss: 97.946132
epoch: 2972, train precision: 0.999689, train loss: 5.434123, valid precision: 0.872000, valid loss: 98.825495
epoch: 2973, train precision: 0.999822, train loss: 5.366924, valid precision: 0.873800, valid loss: 96.180809
epoch: 2974, train precision: 0.999533, train loss: 5.505850, valid precision: 0.869200, valid loss: 98.247592
epoch: 2975, train precision: 0.999711, train loss: 5.406023, valid precision: 0.870800, valid loss: 99.574216
epoch: 2976, train precision: 0.999867, train loss: 5.366306, valid precision: 0.871000, valid loss: 99.732063
epoch: 2977, train precision: 0.999733, train loss: 5.382813, valid precision: 0.874000, valid loss: 101.879061
epoch: 2978, train precision: 0.999711, train loss: 5.379961, valid precision: 0.871200, valid loss: 103.344821
epoch: 2979, train precision: 0.999556, train loss: 5.405096, valid precision: 0.873800, valid loss: 100.836939
epoch: 2980, train precision: 0.999689, train loss: 5.412055, valid precision: 0.874200, valid loss: 98.135464
epoch: 2981, train precision: 0.999644, train loss: 5.432271, valid precision: 0.877000, valid loss: 99.399804
epoch: 2982, train precision: 0.999667, train loss: 5.432574, valid precision: 0.872600, valid loss: 99.015696
epoch: 2983, train precision: 0.999489, train loss: 5.481390, valid precision: 0.871000, valid loss: 100.589514
epoch: 2984, train precision: 0.999733, train loss: 5.408642, valid precision: 0.877400, valid loss: 95.695942
epoch: 2985, train precision: 0.999489, train loss: 5.517424, valid precision: 0.873200, valid loss: 96.287851
epoch: 2986, train precision: 0.999578, train loss: 5.457330, valid precision: 0.873600, valid loss: 96.612049
epoch: 2987, train precision: 0.999422, train loss: 5.529729, valid precision: 0.870400, valid loss: 101.776890
epoch: 2988, train precision: 0.999689, train loss: 5.408713, valid precision: 0.871400, valid loss: 101.033496
epoch: 2989, train precision: 0.999733, train loss: 5.400681, valid precision: 0.872200, valid loss: 98.529852
epoch: 2990, train precision: 0.999778, train loss: 5.403641, valid precision: 0.876200, valid loss: 97.702891
epoch: 2991, train precision: 0.999644, train loss: 5.456479, valid precision: 0.874800, valid loss: 98.557534
epoch: 2992, train precision: 0.999644, train loss: 5.463731, valid precision: 0.873200, valid loss: 96.475852
epoch: 2993, train precision: 0.999756, train loss: 5.401513, valid precision: 0.877200, valid loss: 96.144319
epoch: 2994, train precision: 0.999800, train loss: 5.393371, valid precision: 0.879800, valid loss: 94.037472
epoch: 2995, train precision: 0.999844, train loss: 5.388504, valid precision: 0.874800, valid loss: 97.036358
epoch: 2996, train precision: 0.999778, train loss: 5.409917, valid precision: 0.873800, valid loss: 98.484741
epoch: 2997, train precision: 0.999711, train loss: 5.423310, valid precision: 0.873400, valid loss: 97.352365
epoch: 2998, train precision: 0.999778, train loss: 5.403322, valid precision: 0.874600, valid loss: 95.786336
epoch: 2999, train precision: 0.999733, train loss: 5.387549, valid precision: 0.873000, valid loss: 97.498883
epoch: 3000, train precision: 0.999511, train loss: 5.449893, valid precision: 0.870400, valid loss: 95.282016
epoch: 3001, train precision: 0.999689, train loss: 5.415993, valid precision: 0.871200, valid loss: 98.397181
epoch: 3002, train precision: 0.999711, train loss: 5.403771, valid precision: 0.874000, valid loss: 95.729032
epoch: 3003, train precision: 0.999556, train loss: 5.453184, valid precision: 0.872800, valid loss: 94.895354
epoch: 3004, train precision: 0.999756, train loss: 5.426356, valid precision: 0.871600, valid loss: 97.276884
epoch: 3005, train precision: 0.999733, train loss: 5.403937, valid precision: 0.872600, valid loss: 97.039245
epoch: 3006, train precision: 0.999644, train loss: 5.422051, valid precision: 0.875200, valid loss: 96.626345
epoch: 3007, train precision: 0.999667, train loss: 5.423673, valid precision: 0.874800, valid loss: 93.488171
epoch: 3008, train precision: 0.999778, train loss: 5.399018, valid precision: 0.873400, valid loss: 93.833850
epoch: 3009, train precision: 0.999778, train loss: 5.408592, valid precision: 0.875800, valid loss: 96.981995
epoch: 3010, train precision: 0.999578, train loss: 5.439165, valid precision: 0.875800, valid loss: 97.189205
epoch: 3011, train precision: 0.999756, train loss: 5.406394, valid precision: 0.880400, valid loss: 96.839984
epoch: 3012, train precision: 0.999667, train loss: 5.447502, valid precision: 0.875000, valid loss: 96.609403
epoch: 3013, train precision: 0.999578, train loss: 5.496723, valid precision: 0.876200, valid loss: 96.379486
epoch: 3014, train precision: 0.999622, train loss: 5.451497, valid precision: 0.874400, valid loss: 96.051057
epoch: 3015, train precision: 0.999689, train loss: 5.400242, valid precision: 0.879800, valid loss: 97.964178
epoch: 3016, train precision: 0.999556, train loss: 5.448453, valid precision: 0.878200, valid loss: 98.886196
epoch: 3017, train precision: 0.999733, train loss: 5.413078, valid precision: 0.879600, valid loss: 99.404533
epoch: 3018, train precision: 0.999578, train loss: 5.412465, valid precision: 0.873800, valid loss: 99.821595
epoch: 3019, train precision: 0.999844, train loss: 5.355561, valid precision: 0.875400, valid loss: 97.390847
epoch: 3020, train precision: 0.999711, train loss: 5.417641, valid precision: 0.877000, valid loss: 93.886399
epoch: 3021, train precision: 0.999822, train loss: 5.403189, valid precision: 0.874000, valid loss: 97.830091
epoch: 3022, train precision: 0.999778, train loss: 5.410105, valid precision: 0.874800, valid loss: 98.340675
epoch: 3023, train precision: 0.999622, train loss: 5.427949, valid precision: 0.870200, valid loss: 99.170220
epoch: 3024, train precision: 0.999600, train loss: 5.437590, valid precision: 0.872200, valid loss: 93.619597
epoch: 3025, train precision: 0.999756, train loss: 5.417218, valid precision: 0.872800, valid loss: 97.363798
epoch: 3026, train precision: 0.999711, train loss: 5.427277, valid precision: 0.871000, valid loss: 97.220169
epoch: 3027, train precision: 0.999600, train loss: 5.445940, valid precision: 0.870200, valid loss: 99.068123
epoch: 3028, train precision: 0.999600, train loss: 5.447400, valid precision: 0.875200, valid loss: 94.082380
epoch: 3029, train precision: 0.999600, train loss: 5.441626, valid precision: 0.874200, valid loss: 97.811089
epoch: 3030, train precision: 0.999556, train loss: 5.456671, valid precision: 0.870000, valid loss: 97.303059
epoch: 3031, train precision: 0.999689, train loss: 5.401391, valid precision: 0.874600, valid loss: 98.039195
epoch: 3032, train precision: 0.999756, train loss: 5.434860, valid precision: 0.872600, valid loss: 98.220267
epoch: 3033, train precision: 0.999622, train loss: 5.420190, valid precision: 0.876200, valid loss: 96.837414
epoch: 3034, train precision: 0.999844, train loss: 5.365399, valid precision: 0.874000, valid loss: 96.677707
epoch: 3035, train precision: 0.999622, train loss: 5.460755, valid precision: 0.873800, valid loss: 97.763485
epoch: 3036, train precision: 0.999644, train loss: 5.438615, valid precision: 0.872800, valid loss: 97.374508
epoch: 3037, train precision: 0.999733, train loss: 5.398071, valid precision: 0.874000, valid loss: 99.471562
epoch: 3038, train precision: 0.999600, train loss: 5.430918, valid precision: 0.873600, valid loss: 100.046600
epoch: 3039, train precision: 0.999600, train loss: 5.443874, valid precision: 0.876600, valid loss: 100.077875
epoch: 3040, train precision: 0.999578, train loss: 5.465357, valid precision: 0.874000, valid loss: 98.242749
epoch: 3041, train precision: 0.999600, train loss: 5.502683, valid precision: 0.875400, valid loss: 99.189895
epoch: 3042, train precision: 0.999822, train loss: 5.389238, valid precision: 0.873000, valid loss: 96.438377
epoch: 3043, train precision: 0.999622, train loss: 5.413012, valid precision: 0.874600, valid loss: 99.406586
epoch: 3044, train precision: 0.999667, train loss: 5.408820, valid precision: 0.873600, valid loss: 96.924438
epoch: 3045, train precision: 0.999800, train loss: 5.367263, valid precision: 0.874800, valid loss: 95.910414
epoch: 3046, train precision: 0.999711, train loss: 5.387854, valid precision: 0.877400, valid loss: 97.197290
epoch: 3047, train precision: 0.999733, train loss: 5.386021, valid precision: 0.876600, valid loss: 97.559448
epoch: 3048, train precision: 0.999622, train loss: 5.414062, valid precision: 0.876800, valid loss: 99.357050
epoch: 3049, train precision: 0.999778, train loss: 5.381145, valid precision: 0.875800, valid loss: 96.881661
epoch: 3050, train precision: 0.999689, train loss: 5.390434, valid precision: 0.877600, valid loss: 96.601549
epoch: 3051, train precision: 0.999556, train loss: 5.480836, valid precision: 0.873600, valid loss: 99.334183
epoch: 3052, train precision: 0.999667, train loss: 5.407364, valid precision: 0.874000, valid loss: 97.999955
epoch: 3053, train precision: 0.999844, train loss: 5.380712, valid precision: 0.875200, valid loss: 98.725382
epoch: 3054, train precision: 0.999600, train loss: 5.441993, valid precision: 0.872000, valid loss: 99.415650
epoch: 3055, train precision: 0.999533, train loss: 5.426964, valid precision: 0.872000, valid loss: 99.477373
epoch: 3056, train precision: 0.999822, train loss: 5.363746, valid precision: 0.873600, valid loss: 101.667504
epoch: 3057, train precision: 0.999578, train loss: 5.445662, valid precision: 0.875200, valid loss: 97.502802
epoch: 3058, train precision: 0.999733, train loss: 5.386180, valid precision: 0.873800, valid loss: 96.370767
epoch: 3059, train precision: 0.999689, train loss: 5.410737, valid precision: 0.874200, valid loss: 94.750796
epoch: 3060, train precision: 0.999644, train loss: 5.454213, valid precision: 0.874400, valid loss: 95.827037
epoch: 3061, train precision: 0.999689, train loss: 5.403244, valid precision: 0.875600, valid loss: 96.904812
epoch: 3062, train precision: 0.999600, train loss: 5.442066, valid precision: 0.876000, valid loss: 100.305068
epoch: 3063, train precision: 0.999600, train loss: 5.455204, valid precision: 0.873400, valid loss: 98.499367
epoch: 3064, train precision: 0.999489, train loss: 5.474082, valid precision: 0.872000, valid loss: 100.136602
epoch: 3065, train precision: 0.999644, train loss: 5.410884, valid precision: 0.874200, valid loss: 99.400516
epoch: 3066, train precision: 0.999822, train loss: 5.409022, valid precision: 0.874400, valid loss: 98.227548
epoch: 3067, train precision: 0.999778, train loss: 5.400987, valid precision: 0.875000, valid loss: 97.381734
epoch: 3068, train precision: 0.999667, train loss: 5.445615, valid precision: 0.873600, valid loss: 98.526004
epoch: 3069, train precision: 0.999778, train loss: 5.370926, valid precision: 0.872800, valid loss: 98.272241
epoch: 3070, train precision: 0.999733, train loss: 5.385654, valid precision: 0.873000, valid loss: 94.787076
epoch: 3071, train precision: 0.999444, train loss: 5.465121, valid precision: 0.877000, valid loss: 95.185098
epoch: 3072, train precision: 0.999800, train loss: 5.368048, valid precision: 0.877000, valid loss: 95.130043
epoch: 3073, train precision: 0.999867, train loss: 5.354901, valid precision: 0.873800, valid loss: 94.146402
epoch: 3074, train precision: 0.999733, train loss: 5.412508, valid precision: 0.874200, valid loss: 98.051551
epoch: 3075, train precision: 0.999667, train loss: 5.375467, valid precision: 0.876600, valid loss: 96.167996
epoch: 3076, train precision: 0.999600, train loss: 5.427835, valid precision: 0.876200, valid loss: 95.548424
epoch: 3077, train precision: 0.999800, train loss: 5.375951, valid precision: 0.872400, valid loss: 98.544699
epoch: 3078, train precision: 0.999867, train loss: 5.369268, valid precision: 0.876200, valid loss: 96.557416
epoch: 3079, train precision: 0.999778, train loss: 5.376091, valid precision: 0.876200, valid loss: 99.787674
epoch: 3080, train precision: 0.999489, train loss: 5.474901, valid precision: 0.872800, valid loss: 98.783092
epoch: 3081, train precision: 0.999822, train loss: 5.372418, valid precision: 0.873600, valid loss: 98.558860
epoch: 3082, train precision: 0.999778, train loss: 5.360032, valid precision: 0.874600, valid loss: 100.109691
epoch: 3083, train precision: 0.999667, train loss: 5.393510, valid precision: 0.877200, valid loss: 99.900104
epoch: 3084, train precision: 0.999756, train loss: 5.379954, valid precision: 0.879400, valid loss: 97.144486
epoch: 3085, train precision: 0.999511, train loss: 5.466065, valid precision: 0.878400, valid loss: 97.765455
epoch: 3086, train precision: 0.999756, train loss: 5.377433, valid precision: 0.876400, valid loss: 96.395853
epoch: 3087, train precision: 0.999689, train loss: 5.429846, valid precision: 0.879600, valid loss: 97.522140
epoch: 3088, train precision: 0.999711, train loss: 5.391033, valid precision: 0.876200, valid loss: 98.228143
epoch: 3089, train precision: 0.999911, train loss: 5.329456, valid precision: 0.878800, valid loss: 94.895704
epoch: 3090, train precision: 0.999822, train loss: 5.415783, valid precision: 0.876800, valid loss: 99.087211
epoch: 3091, train precision: 0.999511, train loss: 5.449618, valid precision: 0.876800, valid loss: 97.158362
epoch: 3092, train precision: 0.999356, train loss: 5.452713, valid precision: 0.876600, valid loss: 100.651560
epoch: 3093, train precision: 0.999511, train loss: 5.461826, valid precision: 0.876800, valid loss: 100.629896
epoch: 3094, train precision: 0.999711, train loss: 5.379192, valid precision: 0.876800, valid loss: 96.507592
epoch: 3095, train precision: 0.999556, train loss: 5.433632, valid precision: 0.875600, valid loss: 97.126952
epoch: 3096, train precision: 0.999711, train loss: 5.393618, valid precision: 0.874400, valid loss: 97.810116
epoch: 3097, train precision: 0.999600, train loss: 5.393723, valid precision: 0.878000, valid loss: 96.479356
epoch: 3098, train precision: 0.999667, train loss: 5.451292, valid precision: 0.874600, valid loss: 97.750621
epoch: 3099, train precision: 0.999689, train loss: 5.409733, valid precision: 0.873200, valid loss: 98.650248
epoch: 3100, train precision: 0.999867, train loss: 5.361019, valid precision: 0.873000, valid loss: 97.992691
epoch: 3101, train precision: 0.999711, train loss: 5.398324, valid precision: 0.875000, valid loss: 97.511426
epoch: 3102, train precision: 0.999578, train loss: 5.427549, valid precision: 0.872800, valid loss: 97.721722
epoch: 3103, train precision: 0.999578, train loss: 5.430222, valid precision: 0.876400, valid loss: 97.408587
epoch: 3104, train precision: 0.999667, train loss: 5.410538, valid precision: 0.876400, valid loss: 98.674009
epoch: 3105, train precision: 0.999756, train loss: 5.390743, valid precision: 0.873800, valid loss: 98.892643
epoch: 3106, train precision: 0.999800, train loss: 5.372881, valid precision: 0.877400, valid loss: 98.050182
epoch: 3107, train precision: 0.999689, train loss: 5.413108, valid precision: 0.876800, valid loss: 95.670132
epoch: 3108, train precision: 0.999778, train loss: 5.369720, valid precision: 0.875000, valid loss: 97.806658
epoch: 3109, train precision: 0.999600, train loss: 5.454150, valid precision: 0.872800, valid loss: 98.741918
epoch: 3110, train precision: 0.999444, train loss: 5.460027, valid precision: 0.876000, valid loss: 93.779334
epoch: 3111, train precision: 0.999733, train loss: 5.384964, valid precision: 0.877000, valid loss: 97.061939
epoch: 3112, train precision: 0.999800, train loss: 5.360429, valid precision: 0.878600, valid loss: 100.707980
epoch: 3113, train precision: 0.999622, train loss: 5.397370, valid precision: 0.878800, valid loss: 99.984306
epoch: 3114, train precision: 0.999800, train loss: 5.385089, valid precision: 0.878000, valid loss: 98.324421
epoch: 3115, train precision: 0.999667, train loss: 5.423526, valid precision: 0.877400, valid loss: 99.448146
epoch: 3116, train precision: 0.999644, train loss: 5.422750, valid precision: 0.878400, valid loss: 98.326461
epoch: 3117, train precision: 0.999600, train loss: 5.415275, valid precision: 0.877400, valid loss: 99.478783
epoch: 3118, train precision: 0.999756, train loss: 5.388364, valid precision: 0.876600, valid loss: 100.808206
epoch: 3119, train precision: 0.999800, train loss: 5.369071, valid precision: 0.876800, valid loss: 100.723863
epoch: 3120, train precision: 0.999333, train loss: 5.477657, valid precision: 0.877800, valid loss: 100.154845
epoch: 3121, train precision: 0.999533, train loss: 5.432269, valid precision: 0.873400, valid loss: 99.126501
epoch: 3122, train precision: 0.999733, train loss: 5.417852, valid precision: 0.874600, valid loss: 99.615092
epoch: 3123, train precision: 0.999578, train loss: 5.428739, valid precision: 0.876600, valid loss: 97.548361
epoch: 3124, train precision: 0.999733, train loss: 5.403899, valid precision: 0.873800, valid loss: 99.046262
epoch: 3125, train precision: 0.999511, train loss: 5.484955, valid precision: 0.876000, valid loss: 97.015791
epoch: 3126, train precision: 0.999556, train loss: 5.461104, valid precision: 0.874000, valid loss: 96.217124
epoch: 3127, train precision: 0.999556, train loss: 5.458379, valid precision: 0.874000, valid loss: 96.972664
epoch: 3128, train precision: 0.999733, train loss: 5.406611, valid precision: 0.873000, valid loss: 96.660328
epoch: 3129, train precision: 0.999467, train loss: 5.454802, valid precision: 0.875800, valid loss: 98.966212
epoch: 3130, train precision: 0.999733, train loss: 5.431780, valid precision: 0.870000, valid loss: 96.796207
epoch: 3131, train precision: 0.999756, train loss: 5.400041, valid precision: 0.873200, valid loss: 98.467710
epoch: 3132, train precision: 0.999644, train loss: 5.413113, valid precision: 0.871800, valid loss: 98.544297
epoch: 3133, train precision: 0.999578, train loss: 5.414453, valid precision: 0.874600, valid loss: 101.225389
epoch: 3134, train precision: 0.999600, train loss: 5.431983, valid precision: 0.872200, valid loss: 98.301580
epoch: 3135, train precision: 0.999756, train loss: 5.389637, valid precision: 0.879400, valid loss: 98.636069
epoch: 3136, train precision: 0.999689, train loss: 5.385106, valid precision: 0.876400, valid loss: 95.831169
epoch: 3137, train precision: 0.999778, train loss: 5.402400, valid precision: 0.875000, valid loss: 97.394595
epoch: 3138, train precision: 0.999689, train loss: 5.388409, valid precision: 0.874400, valid loss: 96.064711
epoch: 3139, train precision: 0.999556, train loss: 5.417423, valid precision: 0.875800, valid loss: 97.615394
epoch: 3140, train precision: 0.999800, train loss: 5.369212, valid precision: 0.876400, valid loss: 96.904837
epoch: 3141, train precision: 0.999533, train loss: 5.432310, valid precision: 0.875600, valid loss: 96.269590
epoch: 3142, train precision: 0.999533, train loss: 5.462119, valid precision: 0.874800, valid loss: 97.819148
epoch: 3143, train precision: 0.999600, train loss: 5.425229, valid precision: 0.875400, valid loss: 98.960372
epoch: 3144, train precision: 0.999778, train loss: 5.382283, valid precision: 0.874000, valid loss: 97.663696
epoch: 3145, train precision: 0.999778, train loss: 5.395966, valid precision: 0.879600, valid loss: 95.827968
epoch: 3146, train precision: 0.999556, train loss: 5.427760, valid precision: 0.873000, valid loss: 96.981425
epoch: 3147, train precision: 0.999556, train loss: 5.424783, valid precision: 0.878400, valid loss: 96.906202
epoch: 3148, train precision: 0.999689, train loss: 5.394483, valid precision: 0.873400, valid loss: 97.542092
epoch: 3149, train precision: 0.999622, train loss: 5.400113, valid precision: 0.878000, valid loss: 95.937959
epoch: 3150, train precision: 0.999689, train loss: 5.410920, valid precision: 0.873800, valid loss: 96.943472
epoch: 3151, train precision: 0.999778, train loss: 5.393960, valid precision: 0.875400, valid loss: 97.337659
epoch: 3152, train precision: 0.999578, train loss: 5.440261, valid precision: 0.876200, valid loss: 96.772700
epoch: 3153, train precision: 0.999733, train loss: 5.413986, valid precision: 0.878200, valid loss: 95.394981
epoch: 3154, train precision: 0.999667, train loss: 5.414153, valid precision: 0.876000, valid loss: 96.417840
epoch: 3155, train precision: 0.999756, train loss: 5.383364, valid precision: 0.874000, valid loss: 96.739329
epoch: 3156, train precision: 0.999644, train loss: 5.432886, valid precision: 0.876200, valid loss: 97.162032
epoch: 3157, train precision: 0.999800, train loss: 5.360187, valid precision: 0.874200, valid loss: 98.103827
epoch: 3158, train precision: 0.999800, train loss: 5.378664, valid precision: 0.876000, valid loss: 96.069145
epoch: 3159, train precision: 0.999622, train loss: 5.409890, valid precision: 0.876400, valid loss: 94.964412
epoch: 3160, train precision: 0.999511, train loss: 5.425910, valid precision: 0.877000, valid loss: 98.062927
epoch: 3161, train precision: 0.999578, train loss: 5.419180, valid precision: 0.872800, valid loss: 101.716536
epoch: 3162, train precision: 0.999667, train loss: 5.365691, valid precision: 0.875800, valid loss: 96.623720
epoch: 3163, train precision: 0.999778, train loss: 5.386063, valid precision: 0.877000, valid loss: 97.516502
epoch: 3164, train precision: 0.999667, train loss: 5.424599, valid precision: 0.877400, valid loss: 97.509867
epoch: 3165, train precision: 0.999689, train loss: 5.391257, valid precision: 0.877000, valid loss: 99.006240
epoch: 3166, train precision: 0.999622, train loss: 5.425887, valid precision: 0.877200, valid loss: 99.656756
epoch: 3167, train precision: 0.999556, train loss: 5.416637, valid precision: 0.878600, valid loss: 97.606150
epoch: 3168, train precision: 0.999644, train loss: 5.401510, valid precision: 0.877200, valid loss: 99.275139
epoch: 3169, train precision: 0.999800, train loss: 5.375172, valid precision: 0.877000, valid loss: 99.513854
epoch: 3170, train precision: 0.999600, train loss: 5.468311, valid precision: 0.876000, valid loss: 101.880920
epoch: 3171, train precision: 0.999711, train loss: 5.395256, valid precision: 0.873400, valid loss: 100.863714
epoch: 3172, train precision: 0.999756, train loss: 5.397703, valid precision: 0.875200, valid loss: 100.187773
epoch: 3173, train precision: 0.999711, train loss: 5.380331, valid precision: 0.879600, valid loss: 97.586423
epoch: 3174, train precision: 0.999467, train loss: 5.459891, valid precision: 0.874800, valid loss: 99.455578
epoch: 3175, train precision: 0.999733, train loss: 5.404937, valid precision: 0.877800, valid loss: 96.218826
epoch: 3176, train precision: 0.999644, train loss: 5.417765, valid precision: 0.874200, valid loss: 96.799048
epoch: 3177, train precision: 0.999889, train loss: 5.364641, valid precision: 0.874600, valid loss: 93.777478
epoch: 3178, train precision: 0.999733, train loss: 5.390033, valid precision: 0.875200, valid loss: 97.915409
epoch: 3179, train precision: 0.999600, train loss: 5.414735, valid precision: 0.877200, valid loss: 97.412723
epoch: 3180, train precision: 0.999667, train loss: 5.418117, valid precision: 0.876800, valid loss: 96.491688
epoch: 3181, train precision: 0.999667, train loss: 5.400249, valid precision: 0.876800, valid loss: 95.102149
epoch: 3182, train precision: 0.999733, train loss: 5.383327, valid precision: 0.875400, valid loss: 96.977352
epoch: 3183, train precision: 0.999689, train loss: 5.388416, valid precision: 0.874600, valid loss: 99.205939
epoch: 3184, train precision: 0.999822, train loss: 5.366268, valid precision: 0.874000, valid loss: 99.837920
epoch: 3185, train precision: 0.999556, train loss: 5.437851, valid precision: 0.874000, valid loss: 98.956890
epoch: 3186, train precision: 0.999800, train loss: 5.362238, valid precision: 0.874200, valid loss: 100.141001
epoch: 3187, train precision: 0.999911, train loss: 5.330700, valid precision: 0.875000, valid loss: 97.303043
epoch: 3188, train precision: 0.999600, train loss: 5.389643, valid precision: 0.872000, valid loss: 100.178068
epoch: 3189, train precision: 0.999600, train loss: 5.430828, valid precision: 0.876200, valid loss: 101.537068
epoch: 3190, train precision: 0.999822, train loss: 5.343281, valid precision: 0.874800, valid loss: 99.717558
epoch: 3191, train precision: 0.999600, train loss: 5.423371, valid precision: 0.873800, valid loss: 98.128842
epoch: 3192, train precision: 0.999733, train loss: 5.390001, valid precision: 0.875600, valid loss: 97.912998
epoch: 3193, train precision: 0.999689, train loss: 5.414916, valid precision: 0.875800, valid loss: 95.522349
epoch: 3194, train precision: 0.999711, train loss: 5.383971, valid precision: 0.877000, valid loss: 98.365654
epoch: 3195, train precision: 0.999622, train loss: 5.416481, valid precision: 0.871200, valid loss: 100.921737
epoch: 3196, train precision: 0.999556, train loss: 5.416146, valid precision: 0.877800, valid loss: 97.356934
epoch: 3197, train precision: 0.999733, train loss: 5.353578, valid precision: 0.873600, valid loss: 97.781441
epoch: 3198, train precision: 0.999556, train loss: 5.441392, valid precision: 0.873200, valid loss: 99.192223
epoch: 3199, train precision: 0.999711, train loss: 5.383959, valid precision: 0.874800, valid loss: 97.814344
epoch: 3200, train precision: 0.999533, train loss: 5.426042, valid precision: 0.877000, valid loss: 96.027850
epoch: 3201, train precision: 0.999778, train loss: 5.374571, valid precision: 0.874200, valid loss: 97.464766
epoch: 3202, train precision: 0.999711, train loss: 5.424294, valid precision: 0.872600, valid loss: 98.781098
epoch: 3203, train precision: 0.999600, train loss: 5.432004, valid precision: 0.875600, valid loss: 101.311707
epoch: 3204, train precision: 0.999756, train loss: 5.388941, valid precision: 0.875000, valid loss: 99.948626
epoch: 3205, train precision: 0.999822, train loss: 5.368031, valid precision: 0.874200, valid loss: 98.593175
epoch: 3206, train precision: 0.999800, train loss: 5.387478, valid precision: 0.874400, valid loss: 95.520703
epoch: 3207, train precision: 0.999711, train loss: 5.359575, valid precision: 0.876600, valid loss: 96.954346
epoch: 3208, train precision: 0.999578, train loss: 5.421349, valid precision: 0.878200, valid loss: 97.355892
epoch: 3209, train precision: 0.999644, train loss: 5.416824, valid precision: 0.875600, valid loss: 98.744255
epoch: 3210, train precision: 0.999489, train loss: 5.448001, valid precision: 0.872000, valid loss: 98.638770
epoch: 3211, train precision: 0.999644, train loss: 5.375355, valid precision: 0.876000, valid loss: 98.718584
epoch: 3212, train precision: 0.999400, train loss: 5.460074, valid precision: 0.876000, valid loss: 96.775750
epoch: 3213, train precision: 0.999444, train loss: 5.467862, valid precision: 0.878400, valid loss: 94.154614
epoch: 3214, train precision: 0.999644, train loss: 5.438750, valid precision: 0.878400, valid loss: 94.030078
epoch: 3215, train precision: 0.999822, train loss: 5.350168, valid precision: 0.874800, valid loss: 95.022861
epoch: 3216, train precision: 0.999733, train loss: 5.409455, valid precision: 0.878200, valid loss: 96.418819
epoch: 3217, train precision: 0.999622, train loss: 5.408925, valid precision: 0.875800, valid loss: 97.311127
epoch: 3218, train precision: 0.999711, train loss: 5.372392, valid precision: 0.872200, valid loss: 102.601761
epoch: 3219, train precision: 0.999667, train loss: 5.413558, valid precision: 0.873600, valid loss: 96.227525
epoch: 3220, train precision: 0.999756, train loss: 5.406291, valid precision: 0.876800, valid loss: 95.997509
epoch: 3221, train precision: 0.999733, train loss: 5.414043, valid precision: 0.875800, valid loss: 98.144440
epoch: 3222, train precision: 0.999711, train loss: 5.383180, valid precision: 0.878400, valid loss: 97.583367
epoch: 3223, train precision: 0.999667, train loss: 5.401980, valid precision: 0.875400, valid loss: 97.302076
epoch: 3224, train precision: 0.999711, train loss: 5.390383, valid precision: 0.872200, valid loss: 99.313385
epoch: 3225, train precision: 0.999578, train loss: 5.414951, valid precision: 0.873200, valid loss: 97.186644
epoch: 3226, train precision: 0.999667, train loss: 5.393593, valid precision: 0.875400, valid loss: 95.741652
epoch: 3227, train precision: 0.999733, train loss: 5.405442, valid precision: 0.871600, valid loss: 95.342277
epoch: 3228, train precision: 0.999711, train loss: 5.387516, valid precision: 0.875200, valid loss: 96.638269
epoch: 3229, train precision: 0.999533, train loss: 5.430229, valid precision: 0.875800, valid loss: 97.450211
epoch: 3230, train precision: 0.999578, train loss: 5.452525, valid precision: 0.875600, valid loss: 95.452239
epoch: 3231, train precision: 0.999689, train loss: 5.375748, valid precision: 0.876000, valid loss: 94.739239
epoch: 3232, train precision: 0.999822, train loss: 5.381867, valid precision: 0.875400, valid loss: 94.643173
epoch: 3233, train precision: 0.999622, train loss: 5.411665, valid precision: 0.875600, valid loss: 96.806668
epoch: 3234, train precision: 0.999711, train loss: 5.367768, valid precision: 0.875400, valid loss: 96.237678
epoch: 3235, train precision: 0.999711, train loss: 5.378241, valid precision: 0.875800, valid loss: 97.238608
epoch: 3236, train precision: 0.999800, train loss: 5.359851, valid precision: 0.874600, valid loss: 97.402948
epoch: 3237, train precision: 0.999711, train loss: 5.414052, valid precision: 0.874000, valid loss: 96.955171
epoch: 3238, train precision: 0.999778, train loss: 5.373292, valid precision: 0.872600, valid loss: 96.350358
epoch: 3239, train precision: 0.999667, train loss: 5.398245, valid precision: 0.875000, valid loss: 96.704724
epoch: 3240, train precision: 0.999711, train loss: 5.389918, valid precision: 0.873000, valid loss: 98.581319
epoch: 3241, train precision: 0.999778, train loss: 5.358909, valid precision: 0.871000, valid loss: 98.243317
epoch: 3242, train precision: 0.999822, train loss: 5.352295, valid precision: 0.874400, valid loss: 98.743653
epoch: 3243, train precision: 0.999756, train loss: 5.367541, valid precision: 0.876000, valid loss: 97.074194
epoch: 3244, train precision: 0.999489, train loss: 5.503327, valid precision: 0.874200, valid loss: 97.457052
epoch: 3245, train precision: 0.999756, train loss: 5.366782, valid precision: 0.877000, valid loss: 97.111316
epoch: 3246, train precision: 0.999800, train loss: 5.370697, valid precision: 0.876600, valid loss: 97.125337
epoch: 3247, train precision: 0.999711, train loss: 5.409132, valid precision: 0.875600, valid loss: 95.793898
epoch: 3248, train precision: 0.999667, train loss: 5.414258, valid precision: 0.875800, valid loss: 98.447190
epoch: 3249, train precision: 0.999822, train loss: 5.366465, valid precision: 0.878000, valid loss: 95.291099
epoch: 3250, train precision: 0.999733, train loss: 5.379859, valid precision: 0.876600, valid loss: 95.410079
epoch: 3251, train precision: 0.999800, train loss: 5.356413, valid precision: 0.874400, valid loss: 97.253941
epoch: 3252, train precision: 0.999733, train loss: 5.383163, valid precision: 0.871800, valid loss: 99.452919
epoch: 3253, train precision: 0.999756, train loss: 5.358346, valid precision: 0.875600, valid loss: 96.984270
epoch: 3254, train precision: 0.999689, train loss: 5.364224, valid precision: 0.877600, valid loss: 96.942718
epoch: 3255, train precision: 0.999622, train loss: 5.394971, valid precision: 0.877600, valid loss: 96.998349
epoch: 3256, train precision: 0.999711, train loss: 5.393645, valid precision: 0.876800, valid loss: 98.053689
epoch: 3257, train precision: 0.999578, train loss: 5.428096, valid precision: 0.875800, valid loss: 99.867530
epoch: 3258, train precision: 0.999511, train loss: 5.460852, valid precision: 0.873400, valid loss: 98.780966
epoch: 3259, train precision: 0.999711, train loss: 5.367654, valid precision: 0.873000, valid loss: 97.092393
epoch: 3260, train precision: 0.999733, train loss: 5.375382, valid precision: 0.873200, valid loss: 99.027849
epoch: 3261, train precision: 0.999711, train loss: 5.354173, valid precision: 0.876000, valid loss: 96.129871
epoch: 3262, train precision: 0.999578, train loss: 5.470161, valid precision: 0.876200, valid loss: 97.485135
epoch: 3263, train precision: 0.999600, train loss: 5.432861, valid precision: 0.874600, valid loss: 101.540946
epoch: 3264, train precision: 0.999822, train loss: 5.351801, valid precision: 0.875200, valid loss: 97.215985
epoch: 3265, train precision: 0.999644, train loss: 5.410083, valid precision: 0.873600, valid loss: 98.032635
epoch: 3266, train precision: 0.999844, train loss: 5.367582, valid precision: 0.872000, valid loss: 97.447703
epoch: 3267, train precision: 0.999578, train loss: 5.437989, valid precision: 0.878000, valid loss: 97.848377
epoch: 3268, train precision: 0.999733, train loss: 5.390126, valid precision: 0.872600, valid loss: 99.638347
epoch: 3269, train precision: 0.999644, train loss: 5.401210, valid precision: 0.876000, valid loss: 97.458444
epoch: 3270, train precision: 0.999800, train loss: 5.349343, valid precision: 0.877000, valid loss: 97.862965
epoch: 3271, train precision: 0.999578, train loss: 5.434324, valid precision: 0.875600, valid loss: 99.917138
epoch: 3272, train precision: 0.999800, train loss: 5.358977, valid precision: 0.873400, valid loss: 97.473351
epoch: 3273, train precision: 0.999511, train loss: 5.434950, valid precision: 0.874400, valid loss: 97.103670
epoch: 3274, train precision: 0.999667, train loss: 5.379495, valid precision: 0.872800, valid loss: 98.684862
epoch: 3275, train precision: 0.999800, train loss: 5.358943, valid precision: 0.872800, valid loss: 97.114573
epoch: 3276, train precision: 0.999733, train loss: 5.399553, valid precision: 0.871000, valid loss: 98.060310
epoch: 3277, train precision: 0.999800, train loss: 5.372746, valid precision: 0.874200, valid loss: 94.675692
epoch: 3278, train precision: 0.999667, train loss: 5.419252, valid precision: 0.873800, valid loss: 98.749672
epoch: 3279, train precision: 0.999644, train loss: 5.400380, valid precision: 0.876200, valid loss: 96.547172
epoch: 3280, train precision: 0.999600, train loss: 5.404180, valid precision: 0.873000, valid loss: 95.727817
epoch: 3281, train precision: 0.999644, train loss: 5.379608, valid precision: 0.871200, valid loss: 98.926543
epoch: 3282, train precision: 0.999622, train loss: 5.383898, valid precision: 0.881200, valid loss: 97.432473
epoch: 3283, train precision: 0.999667, train loss: 5.385445, valid precision: 0.874600, valid loss: 98.737724
epoch: 3284, train precision: 0.999578, train loss: 5.388889, valid precision: 0.877800, valid loss: 98.040053
epoch: 3285, train precision: 0.999822, train loss: 5.356699, valid precision: 0.874600, valid loss: 97.783311
epoch: 3286, train precision: 0.999689, train loss: 5.378978, valid precision: 0.876800, valid loss: 96.974499
epoch: 3287, train precision: 0.999622, train loss: 5.420092, valid precision: 0.872200, valid loss: 100.331580
epoch: 3288, train precision: 0.999600, train loss: 5.398529, valid precision: 0.871800, valid loss: 103.478810
epoch: 3289, train precision: 0.999756, train loss: 5.380335, valid precision: 0.873000, valid loss: 101.538589
epoch: 3290, train precision: 0.999578, train loss: 5.408267, valid precision: 0.869800, valid loss: 99.221377
epoch: 3291, train precision: 0.999689, train loss: 5.356305, valid precision: 0.868000, valid loss: 103.121391
epoch: 3292, train precision: 0.999778, train loss: 5.355705, valid precision: 0.871000, valid loss: 102.592042
epoch: 3293, train precision: 0.999756, train loss: 5.348502, valid precision: 0.871600, valid loss: 103.152694
epoch: 3294, train precision: 0.999733, train loss: 5.385623, valid precision: 0.874200, valid loss: 102.111289
epoch: 3295, train precision: 0.999711, train loss: 5.371053, valid precision: 0.871600, valid loss: 101.189259
epoch: 3296, train precision: 0.999711, train loss: 5.395851, valid precision: 0.869600, valid loss: 102.752568
epoch: 3297, train precision: 0.999689, train loss: 5.402879, valid precision: 0.874400, valid loss: 99.914737
epoch: 3298, train precision: 0.999556, train loss: 5.422720, valid precision: 0.871800, valid loss: 100.788288
epoch: 3299, train precision: 0.999689, train loss: 5.395593, valid precision: 0.874000, valid loss: 98.663871
epoch: 3300, train precision: 0.999778, train loss: 5.370963, valid precision: 0.872800, valid loss: 99.582136
epoch: 3301, train precision: 0.999800, train loss: 5.386654, valid precision: 0.872200, valid loss: 99.763440
epoch: 3302, train precision: 0.999689, train loss: 5.402076, valid precision: 0.875800, valid loss: 97.462028
epoch: 3303, train precision: 0.999622, train loss: 5.388024, valid precision: 0.876200, valid loss: 97.857325
epoch: 3304, train precision: 0.999689, train loss: 5.398944, valid precision: 0.870200, valid loss: 102.643600
epoch: 3305, train precision: 0.999689, train loss: 5.371416, valid precision: 0.874400, valid loss: 99.965722
epoch: 3306, train precision: 0.999511, train loss: 5.379511, valid precision: 0.872600, valid loss: 100.492408
epoch: 3307, train precision: 0.999467, train loss: 5.448335, valid precision: 0.870800, valid loss: 101.530454
epoch: 3308, train precision: 0.999578, train loss: 5.402994, valid precision: 0.869400, valid loss: 101.025805
epoch: 3309, train precision: 0.999489, train loss: 5.438866, valid precision: 0.875400, valid loss: 101.676061
epoch: 3310, train precision: 0.999622, train loss: 5.414951, valid precision: 0.872600, valid loss: 104.253533
epoch: 3311, train precision: 0.999600, train loss: 5.402969, valid precision: 0.871200, valid loss: 103.395940
epoch: 3312, train precision: 0.999711, train loss: 5.381875, valid precision: 0.869200, valid loss: 101.436491
epoch: 3313, train precision: 0.999689, train loss: 5.376456, valid precision: 0.872800, valid loss: 101.886295
epoch: 3314, train precision: 0.999667, train loss: 5.397299, valid precision: 0.869600, valid loss: 100.567379
epoch: 3315, train precision: 0.999556, train loss: 5.411997, valid precision: 0.871800, valid loss: 100.145972
epoch: 3316, train precision: 0.999733, train loss: 5.361411, valid precision: 0.871600, valid loss: 99.963533
epoch: 3317, train precision: 0.999800, train loss: 5.349923, valid precision: 0.873200, valid loss: 97.472696
epoch: 3318, train precision: 0.999644, train loss: 5.411335, valid precision: 0.870200, valid loss: 99.366121
epoch: 3319, train precision: 0.999644, train loss: 5.414979, valid precision: 0.870000, valid loss: 101.210623
epoch: 3320, train precision: 0.999733, train loss: 5.366009, valid precision: 0.869200, valid loss: 102.101292
epoch: 3321, train precision: 0.999756, train loss: 5.361455, valid precision: 0.869000, valid loss: 101.421916
epoch: 3322, train precision: 0.999644, train loss: 5.394085, valid precision: 0.872400, valid loss: 101.186291
epoch: 3323, train precision: 0.999733, train loss: 5.355474, valid precision: 0.873200, valid loss: 96.793784
epoch: 3324, train precision: 0.999733, train loss: 5.369898, valid precision: 0.873600, valid loss: 100.703698
epoch: 3325, train precision: 0.999756, train loss: 5.360910, valid precision: 0.872800, valid loss: 99.707245
epoch: 3326, train precision: 0.999489, train loss: 5.432954, valid precision: 0.869800, valid loss: 99.808923
epoch: 3327, train precision: 0.999778, train loss: 5.358362, valid precision: 0.875200, valid loss: 100.318943
epoch: 3328, train precision: 0.999644, train loss: 5.398517, valid precision: 0.874400, valid loss: 100.858327
epoch: 3329, train precision: 0.999778, train loss: 5.368978, valid precision: 0.874600, valid loss: 103.981517
epoch: 3330, train precision: 0.999778, train loss: 5.349256, valid precision: 0.876000, valid loss: 100.320882
epoch: 3331, train precision: 0.999667, train loss: 5.360879, valid precision: 0.874600, valid loss: 99.112499
epoch: 3332, train precision: 0.999644, train loss: 5.444392, valid precision: 0.874400, valid loss: 100.642813
epoch: 3333, train precision: 0.999600, train loss: 5.408979, valid precision: 0.873400, valid loss: 100.029255
epoch: 3334, train precision: 0.999800, train loss: 5.351107, valid precision: 0.871200, valid loss: 101.475240
epoch: 3335, train precision: 0.999822, train loss: 5.365327, valid precision: 0.875000, valid loss: 100.815526
epoch: 3336, train precision: 0.999489, train loss: 5.437354, valid precision: 0.875800, valid loss: 98.540549
epoch: 3337, train precision: 0.999733, train loss: 5.368982, valid precision: 0.876800, valid loss: 101.803862
epoch: 3338, train precision: 0.999667, train loss: 5.413392, valid precision: 0.874600, valid loss: 100.360337
epoch: 3339, train precision: 0.999600, train loss: 5.371899, valid precision: 0.872600, valid loss: 99.602350
epoch: 3340, train precision: 0.999689, train loss: 5.383446, valid precision: 0.874000, valid loss: 100.616826
epoch: 3341, train precision: 0.999733, train loss: 5.386222, valid precision: 0.871600, valid loss: 102.493451
epoch: 3342, train precision: 0.999711, train loss: 5.362953, valid precision: 0.877200, valid loss: 96.510313
epoch: 3343, train precision: 0.999778, train loss: 5.340077, valid precision: 0.875800, valid loss: 100.112772
epoch: 3344, train precision: 0.999689, train loss: 5.363345, valid precision: 0.875800, valid loss: 101.880312
epoch: 3345, train precision: 0.999600, train loss: 5.364237, valid precision: 0.876600, valid loss: 101.101674
epoch: 3346, train precision: 0.999622, train loss: 5.379592, valid precision: 0.875000, valid loss: 101.340532
epoch: 3347, train precision: 0.999622, train loss: 5.383368, valid precision: 0.873400, valid loss: 104.277190
epoch: 3348, train precision: 0.999600, train loss: 5.445659, valid precision: 0.870600, valid loss: 103.634858
epoch: 3349, train precision: 0.999778, train loss: 5.348056, valid precision: 0.873000, valid loss: 102.837861
epoch: 3350, train precision: 0.999711, train loss: 5.364797, valid precision: 0.870800, valid loss: 102.785248
epoch: 3351, train precision: 0.999867, train loss: 5.336815, valid precision: 0.874200, valid loss: 100.068588
epoch: 3352, train precision: 0.999667, train loss: 5.388041, valid precision: 0.872000, valid loss: 101.173747
epoch: 3353, train precision: 0.999644, train loss: 5.386096, valid precision: 0.872400, valid loss: 97.697490
epoch: 3354, train precision: 0.999733, train loss: 5.373628, valid precision: 0.872800, valid loss: 99.288646
epoch: 3355, train precision: 0.999667, train loss: 5.416528, valid precision: 0.873200, valid loss: 97.123481
epoch: 3356, train precision: 0.999689, train loss: 5.420660, valid precision: 0.876200, valid loss: 95.161626
epoch: 3357, train precision: 0.999844, train loss: 5.339837, valid precision: 0.870600, valid loss: 96.959622
epoch: 3358, train precision: 0.999644, train loss: 5.417064, valid precision: 0.872000, valid loss: 100.946195
epoch: 3359, train precision: 0.999622, train loss: 5.414697, valid precision: 0.876400, valid loss: 99.832878
epoch: 3360, train precision: 0.999756, train loss: 5.379001, valid precision: 0.873200, valid loss: 98.448706
epoch: 3361, train precision: 0.999756, train loss: 5.355803, valid precision: 0.868800, valid loss: 100.845689
epoch: 3362, train precision: 0.999511, train loss: 5.466924, valid precision: 0.871000, valid loss: 101.227279
epoch: 3363, train precision: 0.999689, train loss: 5.388182, valid precision: 0.877200, valid loss: 100.233851
epoch: 3364, train precision: 0.999622, train loss: 5.385192, valid precision: 0.872000, valid loss: 103.366496
epoch: 3365, train precision: 0.999844, train loss: 5.314405, valid precision: 0.872000, valid loss: 103.409391
epoch: 3366, train precision: 0.999756, train loss: 5.346314, valid precision: 0.873800, valid loss: 101.137998
epoch: 3367, train precision: 0.999511, train loss: 5.414632, valid precision: 0.871400, valid loss: 103.679186
epoch: 3368, train precision: 0.999778, train loss: 5.351663, valid precision: 0.875200, valid loss: 100.211255
epoch: 3369, train precision: 0.999800, train loss: 5.339560, valid precision: 0.876400, valid loss: 100.507721
epoch: 3370, train precision: 0.999800, train loss: 5.352491, valid precision: 0.877200, valid loss: 102.845162
epoch: 3371, train precision: 0.999622, train loss: 5.383641, valid precision: 0.869600, valid loss: 105.721056
epoch: 3372, train precision: 0.999622, train loss: 5.382303, valid precision: 0.871600, valid loss: 102.247283
epoch: 3373, train precision: 0.999600, train loss: 5.403787, valid precision: 0.875200, valid loss: 103.271210
epoch: 3374, train precision: 0.999489, train loss: 5.439990, valid precision: 0.874400, valid loss: 99.696314
epoch: 3375, train precision: 0.999556, train loss: 5.403342, valid precision: 0.876400, valid loss: 102.530935
epoch: 3376, train precision: 0.999778, train loss: 5.368651, valid precision: 0.875600, valid loss: 99.112788
epoch: 3377, train precision: 0.999844, train loss: 5.331384, valid precision: 0.874000, valid loss: 99.631276
epoch: 3378, train precision: 0.999511, train loss: 5.421349, valid precision: 0.871800, valid loss: 102.776600
epoch: 3379, train precision: 0.999733, train loss: 5.343841, valid precision: 0.875400, valid loss: 99.714338
epoch: 3380, train precision: 0.999778, train loss: 5.343686, valid precision: 0.875400, valid loss: 99.614801
epoch: 3381, train precision: 0.999822, train loss: 5.359685, valid precision: 0.872400, valid loss: 103.234024
epoch: 3382, train precision: 0.999600, train loss: 5.363180, valid precision: 0.873600, valid loss: 100.387154
epoch: 3383, train precision: 0.999600, train loss: 5.410513, valid precision: 0.875600, valid loss: 100.386192
epoch: 3384, train precision: 0.999600, train loss: 5.372714, valid precision: 0.875400, valid loss: 101.222756
epoch: 3385, train precision: 0.999400, train loss: 5.473442, valid precision: 0.875000, valid loss: 97.014790
epoch: 3386, train precision: 0.999533, train loss: 5.380359, valid precision: 0.877400, valid loss: 97.855781
epoch: 3387, train precision: 0.999444, train loss: 5.446070, valid precision: 0.871600, valid loss: 102.400997
epoch: 3388, train precision: 0.999756, train loss: 5.371087, valid precision: 0.868400, valid loss: 100.782851
epoch: 3389, train precision: 0.999733, train loss: 5.368169, valid precision: 0.873600, valid loss: 99.906009
epoch: 3390, train precision: 0.999533, train loss: 5.388422, valid precision: 0.874200, valid loss: 98.432174
epoch: 3391, train precision: 0.999800, train loss: 5.336194, valid precision: 0.871600, valid loss: 99.386556
epoch: 3392, train precision: 0.999711, train loss: 5.364904, valid precision: 0.873200, valid loss: 101.628402
epoch: 3393, train precision: 0.999689, train loss: 5.365531, valid precision: 0.876600, valid loss: 101.920858
epoch: 3394, train precision: 0.999689, train loss: 5.347378, valid precision: 0.877000, valid loss: 99.674314
epoch: 3395, train precision: 0.999689, train loss: 5.376024, valid precision: 0.871800, valid loss: 99.802226
epoch: 3396, train precision: 0.999689, train loss: 5.374667, valid precision: 0.873400, valid loss: 101.810757
epoch: 3397, train precision: 0.999689, train loss: 5.354731, valid precision: 0.874600, valid loss: 100.729432
epoch: 3398, train precision: 0.999756, train loss: 5.376171, valid precision: 0.873200, valid loss: 101.073497
epoch: 3399, train precision: 0.999756, train loss: 5.342164, valid precision: 0.876000, valid loss: 100.105210
epoch: 3400, train precision: 0.999667, train loss: 5.375961, valid precision: 0.874400, valid loss: 101.398380
epoch: 3401, train precision: 0.999667, train loss: 5.369522, valid precision: 0.877400, valid loss: 100.358825
epoch: 3402, train precision: 0.999533, train loss: 5.403678, valid precision: 0.873000, valid loss: 100.375869
epoch: 3403, train precision: 0.999600, train loss: 5.418909, valid precision: 0.875000, valid loss: 105.108304
epoch: 3404, train precision: 0.999311, train loss: 5.464176, valid precision: 0.872200, valid loss: 104.864364
epoch: 3405, train precision: 0.999889, train loss: 5.319397, valid precision: 0.875200, valid loss: 102.132008
epoch: 3406, train precision: 0.999756, train loss: 5.334325, valid precision: 0.873000, valid loss: 101.036159
epoch: 3407, train precision: 0.999489, train loss: 5.377097, valid precision: 0.877200, valid loss: 98.346362
epoch: 3408, train precision: 0.999644, train loss: 5.355334, valid precision: 0.878000, valid loss: 101.172059
epoch: 3409, train precision: 0.999644, train loss: 5.368748, valid precision: 0.872200, valid loss: 100.971642
epoch: 3410, train precision: 0.999756, train loss: 5.361978, valid precision: 0.873200, valid loss: 103.389062
epoch: 3411, train precision: 0.999600, train loss: 5.418233, valid precision: 0.871800, valid loss: 102.445828
epoch: 3412, train precision: 0.999667, train loss: 5.406629, valid precision: 0.870600, valid loss: 99.684187
epoch: 3413, train precision: 0.999689, train loss: 5.374453, valid precision: 0.872400, valid loss: 100.333170
epoch: 3414, train precision: 0.999800, train loss: 5.351833, valid precision: 0.873200, valid loss: 99.166585
epoch: 3415, train precision: 0.999689, train loss: 5.400029, valid precision: 0.874400, valid loss: 98.771882
epoch: 3416, train precision: 0.999511, train loss: 5.432396, valid precision: 0.876800, valid loss: 102.056126
epoch: 3417, train precision: 0.999578, train loss: 5.398949, valid precision: 0.872200, valid loss: 101.716182
epoch: 3418, train precision: 0.999756, train loss: 5.359694, valid precision: 0.874600, valid loss: 101.838853
epoch: 3419, train precision: 0.999644, train loss: 5.398128, valid precision: 0.871600, valid loss: 100.902668
epoch: 3420, train precision: 0.999711, train loss: 5.367883, valid precision: 0.872800, valid loss: 100.997301
epoch: 3421, train precision: 0.999800, train loss: 5.345873, valid precision: 0.872600, valid loss: 100.728146
epoch: 3422, train precision: 0.999622, train loss: 5.402623, valid precision: 0.872400, valid loss: 102.623086
epoch: 3423, train precision: 0.999644, train loss: 5.392872, valid precision: 0.872000, valid loss: 100.589940
epoch: 3424, train precision: 0.999733, train loss: 5.371526, valid precision: 0.872600, valid loss: 100.144400
epoch: 3425, train precision: 0.999622, train loss: 5.379846, valid precision: 0.871800, valid loss: 102.693955
epoch: 3426, train precision: 0.999822, train loss: 5.343685, valid precision: 0.873400, valid loss: 100.413530
epoch: 3427, train precision: 0.999711, train loss: 5.365977, valid precision: 0.872200, valid loss: 97.279609
epoch: 3428, train precision: 0.999822, train loss: 5.345248, valid precision: 0.876600, valid loss: 97.371032
epoch: 3429, train precision: 0.999800, train loss: 5.338398, valid precision: 0.875400, valid loss: 96.919849
epoch: 3430, train precision: 0.999778, train loss: 5.342332, valid precision: 0.872400, valid loss: 100.279609
epoch: 3431, train precision: 0.999778, train loss: 5.359666, valid precision: 0.875600, valid loss: 101.336034
epoch: 3432, train precision: 0.999733, train loss: 5.356154, valid precision: 0.875800, valid loss: 100.001728
epoch: 3433, train precision: 0.999689, train loss: 5.367801, valid precision: 0.871200, valid loss: 98.311897
epoch: 3434, train precision: 0.999778, train loss: 5.345528, valid precision: 0.872800, valid loss: 100.260934
epoch: 3435, train precision: 0.999489, train loss: 5.429406, valid precision: 0.873000, valid loss: 100.994598
epoch: 3436, train precision: 0.999667, train loss: 5.370050, valid precision: 0.876200, valid loss: 100.379767
epoch: 3437, train precision: 0.999733, train loss: 5.379914, valid precision: 0.873600, valid loss: 98.853451
epoch: 3438, train precision: 0.999756, train loss: 5.365354, valid precision: 0.872200, valid loss: 100.633711
epoch: 3439, train precision: 0.999756, train loss: 5.330262, valid precision: 0.874200, valid loss: 99.058287
epoch: 3440, train precision: 0.999800, train loss: 5.338379, valid precision: 0.873200, valid loss: 102.521584
epoch: 3441, train precision: 0.999733, train loss: 5.362835, valid precision: 0.873200, valid loss: 100.781778
epoch: 3442, train precision: 0.999733, train loss: 5.356372, valid precision: 0.872400, valid loss: 102.177236
epoch: 3443, train precision: 0.999778, train loss: 5.341685, valid precision: 0.876200, valid loss: 99.049393
epoch: 3444, train precision: 0.999689, train loss: 5.367449, valid precision: 0.873600, valid loss: 99.690860
epoch: 3445, train precision: 0.999667, train loss: 5.380562, valid precision: 0.875000, valid loss: 100.127461
epoch: 3446, train precision: 0.999733, train loss: 5.369940, valid precision: 0.871600, valid loss: 100.731949
epoch: 3447, train precision: 0.999489, train loss: 5.405004, valid precision: 0.875000, valid loss: 101.743097
epoch: 3448, train precision: 0.999711, train loss: 5.355983, valid precision: 0.872800, valid loss: 100.376450
epoch: 3449, train precision: 0.999756, train loss: 5.352052, valid precision: 0.873200, valid loss: 98.020942
epoch: 3450, train precision: 0.999889, train loss: 5.296960, valid precision: 0.875600, valid loss: 97.461409
epoch: 3451, train precision: 0.999556, train loss: 5.398191, valid precision: 0.876200, valid loss: 99.447199
epoch: 3452, train precision: 0.999667, train loss: 5.400047, valid precision: 0.871600, valid loss: 102.914266
epoch: 3453, train precision: 0.999756, train loss: 5.383488, valid precision: 0.876400, valid loss: 102.154725
epoch: 3454, train precision: 0.999711, train loss: 5.363091, valid precision: 0.875800, valid loss: 101.054154
epoch: 3455, train precision: 0.999667, train loss: 5.393287, valid precision: 0.874600, valid loss: 101.546171
epoch: 3456, train precision: 0.999800, train loss: 5.356148, valid precision: 0.872400, valid loss: 101.352205
epoch: 3457, train precision: 0.999689, train loss: 5.393428, valid precision: 0.872800, valid loss: 98.740003
epoch: 3458, train precision: 0.999644, train loss: 5.367009, valid precision: 0.870200, valid loss: 101.706230
epoch: 3459, train precision: 0.999711, train loss: 5.341515, valid precision: 0.875800, valid loss: 99.632808
epoch: 3460, train precision: 0.999733, train loss: 5.355561, valid precision: 0.871200, valid loss: 102.023943
epoch: 3461, train precision: 0.999756, train loss: 5.365441, valid precision: 0.871600, valid loss: 100.189104
epoch: 3462, train precision: 0.999667, train loss: 5.388404, valid precision: 0.871800, valid loss: 99.029522
epoch: 3463, train precision: 0.999733, train loss: 5.362320, valid precision: 0.872000, valid loss: 97.887059
epoch: 3464, train precision: 0.999733, train loss: 5.349005, valid precision: 0.872600, valid loss: 98.687468
epoch: 3465, train precision: 0.999756, train loss: 5.371456, valid precision: 0.875200, valid loss: 99.866419
epoch: 3466, train precision: 0.999756, train loss: 5.347362, valid precision: 0.872800, valid loss: 100.684868
epoch: 3467, train precision: 0.999689, train loss: 5.348655, valid precision: 0.872600, valid loss: 100.118427
epoch: 3468, train precision: 0.999556, train loss: 5.406499, valid precision: 0.879000, valid loss: 97.885363
epoch: 3469, train precision: 0.999778, train loss: 5.354382, valid precision: 0.873200, valid loss: 102.579528
epoch: 3470, train precision: 0.999533, train loss: 5.395583, valid precision: 0.872000, valid loss: 100.996832
epoch: 3471, train precision: 0.999689, train loss: 5.384875, valid precision: 0.874000, valid loss: 95.831793
epoch: 3472, train precision: 0.999533, train loss: 5.426104, valid precision: 0.873600, valid loss: 99.350695
epoch: 3473, train precision: 0.999644, train loss: 5.373000, valid precision: 0.875600, valid loss: 98.044592
epoch: 3474, train precision: 0.999667, train loss: 5.375738, valid precision: 0.872800, valid loss: 97.354370
epoch: 3475, train precision: 0.999844, train loss: 5.337856, valid precision: 0.872400, valid loss: 97.358033
epoch: 3476, train precision: 0.999822, train loss: 5.328323, valid precision: 0.874400, valid loss: 96.441283
epoch: 3477, train precision: 0.999644, train loss: 5.385356, valid precision: 0.870600, valid loss: 98.781667
epoch: 3478, train precision: 0.999756, train loss: 5.335867, valid precision: 0.873800, valid loss: 98.732749
epoch: 3479, train precision: 0.999622, train loss: 5.406845, valid precision: 0.873600, valid loss: 97.664889
epoch: 3480, train precision: 0.999511, train loss: 5.422535, valid precision: 0.874800, valid loss: 96.040805
epoch: 3481, train precision: 0.999556, train loss: 5.413415, valid precision: 0.875800, valid loss: 95.997970
epoch: 3482, train precision: 0.999756, train loss: 5.379542, valid precision: 0.870000, valid loss: 98.241564
epoch: 3483, train precision: 0.999822, train loss: 5.331991, valid precision: 0.875800, valid loss: 96.397810
epoch: 3484, train precision: 0.999600, train loss: 5.376115, valid precision: 0.875600, valid loss: 93.341049
epoch: 3485, train precision: 0.999622, train loss: 5.384371, valid precision: 0.876000, valid loss: 96.319373
epoch: 3486, train precision: 0.999667, train loss: 5.373713, valid precision: 0.875800, valid loss: 98.660798
epoch: 3487, train precision: 0.999622, train loss: 5.384623, valid precision: 0.875800, valid loss: 96.751795
epoch: 3488, train precision: 0.999556, train loss: 5.378988, valid precision: 0.877200, valid loss: 97.681983
epoch: 3489, train precision: 0.999756, train loss: 5.341955, valid precision: 0.872000, valid loss: 97.609084
epoch: 3490, train precision: 0.999778, train loss: 5.378562, valid precision: 0.872400, valid loss: 99.109870
epoch: 3491, train precision: 0.999689, train loss: 5.374357, valid precision: 0.875800, valid loss: 96.358581
epoch: 3492, train precision: 0.999578, train loss: 5.450240, valid precision: 0.873600, valid loss: 95.378766
epoch: 3493, train precision: 0.999756, train loss: 5.351713, valid precision: 0.876000, valid loss: 100.051782
epoch: 3494, train precision: 0.999644, train loss: 5.400607, valid precision: 0.872400, valid loss: 98.912169
epoch: 3495, train precision: 0.999644, train loss: 5.397835, valid precision: 0.874600, valid loss: 98.782331
epoch: 3496, train precision: 0.999756, train loss: 5.357755, valid precision: 0.875400, valid loss: 98.240124
epoch: 3497, train precision: 0.999800, train loss: 5.359555, valid precision: 0.873800, valid loss: 96.735391
epoch: 3498, train precision: 0.999689, train loss: 5.356193, valid precision: 0.875600, valid loss: 98.993236
epoch: 3499, train precision: 0.999689, train loss: 5.388812, valid precision: 0.873200, valid loss: 102.372991
epoch: 3500, train precision: 0.999267, train loss: 5.469562, valid precision: 0.871200, valid loss: 100.704625
epoch: 3501, train precision: 0.999733, train loss: 5.385141, valid precision: 0.873800, valid loss: 98.746166
epoch: 3502, train precision: 0.999778, train loss: 5.395787, valid precision: 0.870400, valid loss: 98.929386
epoch: 3503, train precision: 0.999733, train loss: 5.370264, valid precision: 0.872800, valid loss: 98.206824
epoch: 3504, train precision: 0.999822, train loss: 5.357561, valid precision: 0.874000, valid loss: 96.254322
epoch: 3505, train precision: 0.999689, train loss: 5.364837, valid precision: 0.874400, valid loss: 96.035810
epoch: 3506, train precision: 0.999622, train loss: 5.363813, valid precision: 0.874600, valid loss: 97.082334
epoch: 3507, train precision: 0.999756, train loss: 5.335183, valid precision: 0.874400, valid loss: 101.102996
epoch: 3508, train precision: 0.999689, train loss: 5.379556, valid precision: 0.874200, valid loss: 100.572789
epoch: 3509, train precision: 0.999644, train loss: 5.341371, valid precision: 0.874000, valid loss: 93.980884
epoch: 3510, train precision: 0.999733, train loss: 5.339856, valid precision: 0.876800, valid loss: 97.761221
epoch: 3511, train precision: 0.999711, train loss: 5.364245, valid precision: 0.877400, valid loss: 95.627349
epoch: 3512, train precision: 0.999622, train loss: 5.431278, valid precision: 0.874400, valid loss: 97.764293
epoch: 3513, train precision: 0.999844, train loss: 5.348955, valid precision: 0.877000, valid loss: 96.433350
epoch: 3514, train precision: 0.999778, train loss: 5.361055, valid precision: 0.874000, valid loss: 97.169650
epoch: 3515, train precision: 0.999711, train loss: 5.338145, valid precision: 0.876200, valid loss: 98.008727
epoch: 3516, train precision: 0.999822, train loss: 5.328156, valid precision: 0.875800, valid loss: 97.876390
epoch: 3517, train precision: 0.999733, train loss: 5.367594, valid precision: 0.870600, valid loss: 97.716301
epoch: 3518, train precision: 0.999844, train loss: 5.325288, valid precision: 0.873600, valid loss: 98.575269
epoch: 3519, train precision: 0.999711, train loss: 5.357125, valid precision: 0.877000, valid loss: 96.661906
epoch: 3520, train precision: 0.999800, train loss: 5.361220, valid precision: 0.871600, valid loss: 99.204101
epoch: 3521, train precision: 0.999600, train loss: 5.382422, valid precision: 0.875200, valid loss: 96.958359
epoch: 3522, train precision: 0.999578, train loss: 5.398386, valid precision: 0.873200, valid loss: 98.213906
epoch: 3523, train precision: 0.999822, train loss: 5.333084, valid precision: 0.874200, valid loss: 98.438937
epoch: 3524, train precision: 0.999667, train loss: 5.387758, valid precision: 0.870000, valid loss: 97.525681
epoch: 3525, train precision: 0.999800, train loss: 5.351356, valid precision: 0.877600, valid loss: 96.174535
epoch: 3526, train precision: 0.999844, train loss: 5.317243, valid precision: 0.874600, valid loss: 99.912787
epoch: 3527, train precision: 0.999644, train loss: 5.399733, valid precision: 0.874400, valid loss: 102.327194
epoch: 3528, train precision: 0.999644, train loss: 5.383765, valid precision: 0.872400, valid loss: 99.597920
epoch: 3529, train precision: 0.999667, train loss: 5.401570, valid precision: 0.872200, valid loss: 100.265306
epoch: 3530, train precision: 0.999800, train loss: 5.342073, valid precision: 0.871200, valid loss: 100.692646
epoch: 3531, train precision: 0.999533, train loss: 5.388239, valid precision: 0.873000, valid loss: 99.814544
epoch: 3532, train precision: 0.999622, train loss: 5.401573, valid precision: 0.870000, valid loss: 100.651131
epoch: 3533, train precision: 0.999622, train loss: 5.384602, valid precision: 0.877400, valid loss: 93.657165
epoch: 3534, train precision: 0.999556, train loss: 5.413479, valid precision: 0.875000, valid loss: 96.624772
epoch: 3535, train precision: 0.999756, train loss: 5.356511, valid precision: 0.874800, valid loss: 97.872625
epoch: 3536, train precision: 0.999733, train loss: 5.369889, valid precision: 0.873600, valid loss: 95.670111
epoch: 3537, train precision: 0.999711, train loss: 5.361535, valid precision: 0.874600, valid loss: 97.097513
epoch: 3538, train precision: 0.999822, train loss: 5.331865, valid precision: 0.875200, valid loss: 96.572097
epoch: 3539, train precision: 0.999644, train loss: 5.380872, valid precision: 0.873800, valid loss: 96.495411
epoch: 3540, train precision: 0.999622, train loss: 5.386253, valid precision: 0.874800, valid loss: 99.683316
epoch: 3541, train precision: 0.999667, train loss: 5.369314, valid precision: 0.874200, valid loss: 98.446027
epoch: 3542, train precision: 0.999667, train loss: 5.387995, valid precision: 0.875200, valid loss: 98.539481
epoch: 3543, train precision: 0.999822, train loss: 5.296392, valid precision: 0.874600, valid loss: 98.611357
epoch: 3544, train precision: 0.999822, train loss: 5.325547, valid precision: 0.873400, valid loss: 98.997272
epoch: 3545, train precision: 0.999622, train loss: 5.372759, valid precision: 0.873600, valid loss: 97.292881
epoch: 3546, train precision: 0.999600, train loss: 5.396708, valid precision: 0.872800, valid loss: 97.783050
epoch: 3547, train precision: 0.999733, train loss: 5.379589, valid precision: 0.876200, valid loss: 97.547673
epoch: 3548, train precision: 0.999733, train loss: 5.330602, valid precision: 0.874800, valid loss: 96.100986
epoch: 3549, train precision: 0.999689, train loss: 5.351735, valid precision: 0.876000, valid loss: 96.105522
epoch: 3550, train precision: 0.999689, train loss: 5.394574, valid precision: 0.874200, valid loss: 100.219143
epoch: 3551, train precision: 0.999711, train loss: 5.333998, valid precision: 0.872800, valid loss: 96.974974
epoch: 3552, train precision: 0.999644, train loss: 5.350744, valid precision: 0.873000, valid loss: 102.281579
epoch: 3553, train precision: 0.999422, train loss: 5.426152, valid precision: 0.872400, valid loss: 100.382754
epoch: 3554, train precision: 0.999733, train loss: 5.380985, valid precision: 0.874400, valid loss: 98.027138
epoch: 3555, train precision: 0.999667, train loss: 5.355485, valid precision: 0.875200, valid loss: 96.445537
epoch: 3556, train precision: 0.999756, train loss: 5.353893, valid precision: 0.876000, valid loss: 98.778298
epoch: 3557, train precision: 0.999644, train loss: 5.375266, valid precision: 0.875800, valid loss: 96.667542
epoch: 3558, train precision: 0.999733, train loss: 5.332329, valid precision: 0.878200, valid loss: 96.003331
epoch: 3559, train precision: 0.999844, train loss: 5.324722, valid precision: 0.874000, valid loss: 97.359716
epoch: 3560, train precision: 0.999600, train loss: 5.415808, valid precision: 0.870200, valid loss: 101.273862
epoch: 3561, train precision: 0.999800, train loss: 5.337175, valid precision: 0.875800, valid loss: 98.535274
epoch: 3562, train precision: 0.999756, train loss: 5.352342, valid precision: 0.871000, valid loss: 99.970743
epoch: 3563, train precision: 0.999644, train loss: 5.384871, valid precision: 0.869400, valid loss: 100.117572
epoch: 3564, train precision: 0.999778, train loss: 5.331595, valid precision: 0.870400, valid loss: 100.377039
epoch: 3565, train precision: 0.999756, train loss: 5.351528, valid precision: 0.869200, valid loss: 101.251627
epoch: 3566, train precision: 0.999711, train loss: 5.352982, valid precision: 0.870400, valid loss: 101.972879
epoch: 3567, train precision: 0.999800, train loss: 5.340766, valid precision: 0.871600, valid loss: 101.153448
epoch: 3568, train precision: 0.999822, train loss: 5.333412, valid precision: 0.874800, valid loss: 98.428595
epoch: 3569, train precision: 0.999489, train loss: 5.414565, valid precision: 0.872000, valid loss: 98.912104
epoch: 3570, train precision: 0.999511, train loss: 5.404337, valid precision: 0.869800, valid loss: 103.012862
epoch: 3571, train precision: 0.999689, train loss: 5.355235, valid precision: 0.874400, valid loss: 99.668572
epoch: 3572, train precision: 0.999800, train loss: 5.350557, valid precision: 0.875400, valid loss: 97.492123
epoch: 3573, train precision: 0.999600, train loss: 5.401904, valid precision: 0.872800, valid loss: 100.396696
epoch: 3574, train precision: 0.999533, train loss: 5.440785, valid precision: 0.873000, valid loss: 99.884361
epoch: 3575, train precision: 0.999556, train loss: 5.444869, valid precision: 0.871600, valid loss: 99.799195
epoch: 3576, train precision: 0.999778, train loss: 5.334569, valid precision: 0.870000, valid loss: 99.988394
epoch: 3577, train precision: 0.999600, train loss: 5.409247, valid precision: 0.871000, valid loss: 99.054375
epoch: 3578, train precision: 0.999644, train loss: 5.374331, valid precision: 0.872000, valid loss: 98.965910
epoch: 3579, train precision: 0.999578, train loss: 5.385171, valid precision: 0.873400, valid loss: 98.349151
epoch: 3580, train precision: 0.999711, train loss: 5.360247, valid precision: 0.874000, valid loss: 98.700203
epoch: 3581, train precision: 0.999756, train loss: 5.342035, valid precision: 0.872400, valid loss: 98.709578
epoch: 3582, train precision: 0.999444, train loss: 5.437431, valid precision: 0.870200, valid loss: 102.387973
epoch: 3583, train precision: 0.999711, train loss: 5.350265, valid precision: 0.873800, valid loss: 102.020320
epoch: 3584, train precision: 0.999667, train loss: 5.368911, valid precision: 0.873400, valid loss: 103.879730
epoch: 3585, train precision: 0.999778, train loss: 5.329048, valid precision: 0.872600, valid loss: 101.866754
epoch: 3586, train precision: 0.999689, train loss: 5.349234, valid precision: 0.872600, valid loss: 100.718346
epoch: 3587, train precision: 0.999689, train loss: 5.377545, valid precision: 0.874000, valid loss: 98.227946
epoch: 3588, train precision: 0.999711, train loss: 5.359810, valid precision: 0.873800, valid loss: 98.145114
epoch: 3589, train precision: 0.999889, train loss: 5.326086, valid precision: 0.873800, valid loss: 97.726132
epoch: 3590, train precision: 0.999733, train loss: 5.345924, valid precision: 0.870800, valid loss: 102.267604
epoch: 3591, train precision: 0.999711, train loss: 5.368581, valid precision: 0.870600, valid loss: 100.667389
epoch: 3592, train precision: 0.999578, train loss: 5.392557, valid precision: 0.870600, valid loss: 102.801320
epoch: 3593, train precision: 0.999711, train loss: 5.351861, valid precision: 0.871200, valid loss: 99.401418
epoch: 3594, train precision: 0.999822, train loss: 5.340106, valid precision: 0.872200, valid loss: 100.789685
epoch: 3595, train precision: 0.999711, train loss: 5.355208, valid precision: 0.869000, valid loss: 101.292712
epoch: 3596, train precision: 0.999733, train loss: 5.382456, valid precision: 0.871400, valid loss: 100.066403
epoch: 3597, train precision: 0.999889, train loss: 5.324853, valid precision: 0.871200, valid loss: 103.343054
epoch: 3598, train precision: 0.999667, train loss: 5.400460, valid precision: 0.870600, valid loss: 102.115020
epoch: 3599, train precision: 0.999733, train loss: 5.380378, valid precision: 0.867000, valid loss: 101.947953
epoch: 3600, train precision: 0.999689, train loss: 5.355464, valid precision: 0.873400, valid loss: 98.293430
epoch: 3601, train precision: 0.999756, train loss: 5.364774, valid precision: 0.871000, valid loss: 98.731503
epoch: 3602, train precision: 0.999778, train loss: 5.347218, valid precision: 0.872600, valid loss: 97.142011
epoch: 3603, train precision: 0.999689, train loss: 5.333854, valid precision: 0.873800, valid loss: 98.570529
epoch: 3604, train precision: 0.999800, train loss: 5.381383, valid precision: 0.870400, valid loss: 99.949353
epoch: 3605, train precision: 0.999844, train loss: 5.330968, valid precision: 0.874200, valid loss: 97.743352
epoch: 3606, train precision: 0.999733, train loss: 5.352110, valid precision: 0.874000, valid loss: 99.876590
epoch: 3607, train precision: 0.999667, train loss: 5.373665, valid precision: 0.871200, valid loss: 98.567163
epoch: 3608, train precision: 0.999667, train loss: 5.368194, valid precision: 0.871600, valid loss: 100.364124
epoch: 3609, train precision: 0.999889, train loss: 5.324832, valid precision: 0.873800, valid loss: 98.492720
epoch: 3610, train precision: 0.999778, train loss: 5.320300, valid precision: 0.874000, valid loss: 99.117231
epoch: 3611, train precision: 0.999756, train loss: 5.357392, valid precision: 0.871600, valid loss: 99.347529
epoch: 3612, train precision: 0.999667, train loss: 5.369831, valid precision: 0.871800, valid loss: 104.085070
epoch: 3613, train precision: 0.999711, train loss: 5.351265, valid precision: 0.869800, valid loss: 102.022258
epoch: 3614, train precision: 0.999667, train loss: 5.378899, valid precision: 0.872000, valid loss: 98.408748
epoch: 3615, train precision: 0.999667, train loss: 5.393988, valid precision: 0.871800, valid loss: 100.604386
epoch: 3616, train precision: 0.999800, train loss: 5.336938, valid precision: 0.876600, valid loss: 98.503543
epoch: 3617, train precision: 0.999556, train loss: 5.412327, valid precision: 0.870200, valid loss: 101.716701
epoch: 3618, train precision: 0.999756, train loss: 5.350491, valid precision: 0.874600, valid loss: 98.710000
epoch: 3619, train precision: 0.999600, train loss: 5.373331, valid precision: 0.874600, valid loss: 98.620191
epoch: 3620, train precision: 0.999733, train loss: 5.352266, valid precision: 0.874200, valid loss: 98.476140
epoch: 3621, train precision: 0.999711, train loss: 5.381053, valid precision: 0.870000, valid loss: 101.233379
epoch: 3622, train precision: 0.999800, train loss: 5.346528, valid precision: 0.873600, valid loss: 96.141518
epoch: 3623, train precision: 0.999511, train loss: 5.401765, valid precision: 0.871200, valid loss: 102.975236
epoch: 3624, train precision: 0.999844, train loss: 5.341390, valid precision: 0.872400, valid loss: 96.893939
epoch: 3625, train precision: 0.999822, train loss: 5.321191, valid precision: 0.877600, valid loss: 95.800383
epoch: 3626, train precision: 0.999733, train loss: 5.348930, valid precision: 0.873600, valid loss: 98.696256
epoch: 3627, train precision: 0.999733, train loss: 5.328303, valid precision: 0.875600, valid loss: 98.031605
epoch: 3628, train precision: 0.999911, train loss: 5.318505, valid precision: 0.876400, valid loss: 97.628649
epoch: 3629, train precision: 0.999711, train loss: 5.346095, valid precision: 0.873800, valid loss: 99.109738
epoch: 3630, train precision: 0.999644, train loss: 5.357934, valid precision: 0.872800, valid loss: 100.439804
epoch: 3631, train precision: 0.999778, train loss: 5.363884, valid precision: 0.876600, valid loss: 100.482199
epoch: 3632, train precision: 0.999733, train loss: 5.328429, valid precision: 0.873400, valid loss: 98.837485
epoch: 3633, train precision: 0.999756, train loss: 5.327219, valid precision: 0.874400, valid loss: 100.295695
epoch: 3634, train precision: 0.999756, train loss: 5.336153, valid precision: 0.876200, valid loss: 100.519103
epoch: 3635, train precision: 0.999911, train loss: 5.301112, valid precision: 0.875200, valid loss: 98.532282
epoch: 3636, train precision: 0.999778, train loss: 5.355440, valid precision: 0.870400, valid loss: 101.418162
epoch: 3637, train precision: 0.999689, train loss: 5.369796, valid precision: 0.872800, valid loss: 99.422085
epoch: 3638, train precision: 0.999622, train loss: 5.384348, valid precision: 0.875800, valid loss: 99.505584
epoch: 3639, train precision: 0.999756, train loss: 5.336814, valid precision: 0.875200, valid loss: 98.264269
epoch: 3640, train precision: 0.999533, train loss: 5.394743, valid precision: 0.871600, valid loss: 96.091232
epoch: 3641, train precision: 0.999689, train loss: 5.365388, valid precision: 0.874800, valid loss: 95.909483
epoch: 3642, train precision: 0.999667, train loss: 5.355716, valid precision: 0.872200, valid loss: 97.834308
epoch: 3643, train precision: 0.999644, train loss: 5.358847, valid precision: 0.874800, valid loss: 97.577038
epoch: 3644, train precision: 0.999578, train loss: 5.394602, valid precision: 0.873400, valid loss: 98.781445
epoch: 3645, train precision: 0.999844, train loss: 5.308197, valid precision: 0.872400, valid loss: 95.814421
epoch: 3646, train precision: 0.999733, train loss: 5.353386, valid precision: 0.872000, valid loss: 98.649342
epoch: 3647, train precision: 0.999644, train loss: 5.374164, valid precision: 0.873000, valid loss: 97.990464
epoch: 3648, train precision: 0.999711, train loss: 5.364537, valid precision: 0.876000, valid loss: 101.594086
epoch: 3649, train precision: 0.999756, train loss: 5.324833, valid precision: 0.876400, valid loss: 100.146869
epoch: 3650, train precision: 0.999556, train loss: 5.412312, valid precision: 0.874000, valid loss: 100.426334
epoch: 3651, train precision: 0.999711, train loss: 5.348749, valid precision: 0.876200, valid loss: 100.192485
epoch: 3652, train precision: 0.999600, train loss: 5.377490, valid precision: 0.874200, valid loss: 100.009368
epoch: 3653, train precision: 0.999844, train loss: 5.308822, valid precision: 0.873600, valid loss: 101.492514
epoch: 3654, train precision: 0.999622, train loss: 5.359159, valid precision: 0.872800, valid loss: 101.212262
epoch: 3655, train precision: 0.999933, train loss: 5.310729, valid precision: 0.873600, valid loss: 100.092309
epoch: 3656, train precision: 0.999689, train loss: 5.364406, valid precision: 0.871600, valid loss: 97.755892
epoch: 3657, train precision: 0.999844, train loss: 5.330030, valid precision: 0.874600, valid loss: 99.265620
epoch: 3658, train precision: 0.999622, train loss: 5.366553, valid precision: 0.871600, valid loss: 98.763005
epoch: 3659, train precision: 0.999667, train loss: 5.379151, valid precision: 0.874600, valid loss: 99.215348
epoch: 3660, train precision: 0.999711, train loss: 5.331532, valid precision: 0.869400, valid loss: 101.714910
epoch: 3661, train precision: 0.999711, train loss: 5.349098, valid precision: 0.871400, valid loss: 102.126834
epoch: 3662, train precision: 0.999756, train loss: 5.342544, valid precision: 0.870200, valid loss: 103.286642
epoch: 3663, train precision: 0.999644, train loss: 5.390342, valid precision: 0.867800, valid loss: 101.023388
epoch: 3664, train precision: 0.999667, train loss: 5.356785, valid precision: 0.871600, valid loss: 95.309376
epoch: 3665, train precision: 0.999822, train loss: 5.337605, valid precision: 0.870800, valid loss: 96.893212
epoch: 3666, train precision: 0.999889, train loss: 5.302251, valid precision: 0.874600, valid loss: 99.375433
epoch: 3667, train precision: 0.999578, train loss: 5.370468, valid precision: 0.874600, valid loss: 97.066456
epoch: 3668, train precision: 0.999711, train loss: 5.322310, valid precision: 0.872600, valid loss: 99.146702
epoch: 3669, train precision: 0.999667, train loss: 5.336622, valid precision: 0.874800, valid loss: 100.790554
epoch: 3670, train precision: 0.999711, train loss: 5.348535, valid precision: 0.873600, valid loss: 102.593254
epoch: 3671, train precision: 0.999822, train loss: 5.338216, valid precision: 0.873000, valid loss: 99.837002
epoch: 3672, train precision: 0.999800, train loss: 5.346384, valid precision: 0.871200, valid loss: 99.634760
epoch: 3673, train precision: 0.999756, train loss: 5.336989, valid precision: 0.873600, valid loss: 96.760504
epoch: 3674, train precision: 0.999756, train loss: 5.320138, valid precision: 0.871600, valid loss: 100.013102
epoch: 3675, train precision: 0.999667, train loss: 5.338796, valid precision: 0.875200, valid loss: 98.078783
epoch: 3676, train precision: 0.999756, train loss: 5.325441, valid precision: 0.872800, valid loss: 98.229579
epoch: 3677, train precision: 0.999733, train loss: 5.327174, valid precision: 0.870600, valid loss: 97.950153
epoch: 3678, train precision: 0.999556, train loss: 5.385066, valid precision: 0.870200, valid loss: 98.671785
epoch: 3679, train precision: 0.999622, train loss: 5.375845, valid precision: 0.869600, valid loss: 100.502647
epoch: 3680, train precision: 0.999667, train loss: 5.369584, valid precision: 0.873200, valid loss: 97.798917
epoch: 3681, train precision: 0.999711, train loss: 5.357633, valid precision: 0.870000, valid loss: 98.026746
epoch: 3682, train precision: 0.999822, train loss: 5.332498, valid precision: 0.873800, valid loss: 97.523914
epoch: 3683, train precision: 0.999756, train loss: 5.332464, valid precision: 0.873800, valid loss: 97.126171
epoch: 3684, train precision: 0.999778, train loss: 5.326708, valid precision: 0.876400, valid loss: 94.847765
epoch: 3685, train precision: 0.999889, train loss: 5.309053, valid precision: 0.873400, valid loss: 97.723516
epoch: 3686, train precision: 0.999644, train loss: 5.363671, valid precision: 0.875400, valid loss: 95.563177
epoch: 3687, train precision: 0.999622, train loss: 5.351048, valid precision: 0.874800, valid loss: 96.256338
epoch: 3688, train precision: 0.999733, train loss: 5.334141, valid precision: 0.875600, valid loss: 97.790849
epoch: 3689, train precision: 0.999622, train loss: 5.360712, valid precision: 0.874800, valid loss: 98.488452
epoch: 3690, train precision: 0.999867, train loss: 5.299355, valid precision: 0.878400, valid loss: 95.826433
epoch: 3691, train precision: 0.999822, train loss: 5.329165, valid precision: 0.871200, valid loss: 95.775242
epoch: 3692, train precision: 0.999578, train loss: 5.373400, valid precision: 0.874400, valid loss: 98.968704
epoch: 3693, train precision: 0.999711, train loss: 5.361641, valid precision: 0.873400, valid loss: 100.925866
epoch: 3694, train precision: 0.999622, train loss: 5.333919, valid precision: 0.872000, valid loss: 99.271061
epoch: 3695, train precision: 0.999689, train loss: 5.355265, valid precision: 0.875800, valid loss: 100.167118
epoch: 3696, train precision: 0.999444, train loss: 5.382645, valid precision: 0.872400, valid loss: 98.079998
epoch: 3697, train precision: 0.999667, train loss: 5.371431, valid precision: 0.874800, valid loss: 97.941697
epoch: 3698, train precision: 0.999711, train loss: 5.322350, valid precision: 0.873600, valid loss: 99.492529
epoch: 3699, train precision: 0.999778, train loss: 5.366753, valid precision: 0.871200, valid loss: 102.203644
epoch: 3700, train precision: 0.999644, train loss: 5.350029, valid precision: 0.872800, valid loss: 98.158992
epoch: 3701, train precision: 0.999889, train loss: 5.314048, valid precision: 0.874200, valid loss: 97.331867
epoch: 3702, train precision: 0.999711, train loss: 5.364140, valid precision: 0.872800, valid loss: 100.240449
epoch: 3703, train precision: 0.999600, train loss: 5.395518, valid precision: 0.876200, valid loss: 99.534256
epoch: 3704, train precision: 0.999556, train loss: 5.384681, valid precision: 0.875800, valid loss: 99.593981
epoch: 3705, train precision: 0.999689, train loss: 5.350784, valid precision: 0.874200, valid loss: 96.126128
epoch: 3706, train precision: 0.999689, train loss: 5.340187, valid precision: 0.874200, valid loss: 100.338487
epoch: 3707, train precision: 0.999689, train loss: 5.343267, valid precision: 0.876400, valid loss: 98.001764
epoch: 3708, train precision: 0.999533, train loss: 5.361203, valid precision: 0.877200, valid loss: 97.156578
epoch: 3709, train precision: 0.999733, train loss: 5.337237, valid precision: 0.874200, valid loss: 99.736902
epoch: 3710, train precision: 0.999600, train loss: 5.362213, valid precision: 0.876600, valid loss: 96.902722
epoch: 3711, train precision: 0.999933, train loss: 5.310877, valid precision: 0.873400, valid loss: 97.704231
epoch: 3712, train precision: 0.999733, train loss: 5.356625, valid precision: 0.874000, valid loss: 97.915729
epoch: 3713, train precision: 0.999689, train loss: 5.350109, valid precision: 0.876800, valid loss: 93.836510
epoch: 3714, train precision: 0.999733, train loss: 5.339150, valid precision: 0.872400, valid loss: 97.513219
epoch: 3715, train precision: 0.999733, train loss: 5.343452, valid precision: 0.878800, valid loss: 97.221636
epoch: 3716, train precision: 0.999689, train loss: 5.371648, valid precision: 0.874200, valid loss: 101.537856
epoch: 3717, train precision: 0.999756, train loss: 5.349207, valid precision: 0.872600, valid loss: 102.620638
epoch: 3718, train precision: 0.999733, train loss: 5.330484, valid precision: 0.872800, valid loss: 100.387318
epoch: 3719, train precision: 0.999756, train loss: 5.323335, valid precision: 0.873400, valid loss: 100.929609
epoch: 3720, train precision: 0.999822, train loss: 5.312481, valid precision: 0.875400, valid loss: 100.149988
epoch: 3721, train precision: 0.999733, train loss: 5.373404, valid precision: 0.872400, valid loss: 99.643501
epoch: 3722, train precision: 0.999844, train loss: 5.312118, valid precision: 0.871800, valid loss: 101.257775
epoch: 3723, train precision: 0.999711, train loss: 5.384551, valid precision: 0.869800, valid loss: 100.781531
epoch: 3724, train precision: 0.999644, train loss: 5.388956, valid precision: 0.873000, valid loss: 100.540870
epoch: 3725, train precision: 0.999711, train loss: 5.365172, valid precision: 0.873800, valid loss: 101.618945
epoch: 3726, train precision: 0.999800, train loss: 5.316903, valid precision: 0.874600, valid loss: 100.625014
epoch: 3727, train precision: 0.999556, train loss: 5.372728, valid precision: 0.873000, valid loss: 100.447628
epoch: 3728, train precision: 0.999644, train loss: 5.335408, valid precision: 0.872600, valid loss: 98.342185
epoch: 3729, train precision: 0.999667, train loss: 5.359803, valid precision: 0.878600, valid loss: 98.305932
epoch: 3730, train precision: 0.999667, train loss: 5.350273, valid precision: 0.876200, valid loss: 100.424083
epoch: 3731, train precision: 0.999756, train loss: 5.305710, valid precision: 0.875200, valid loss: 98.262379
epoch: 3732, train precision: 0.999689, train loss: 5.368352, valid precision: 0.877800, valid loss: 98.330762
epoch: 3733, train precision: 0.999667, train loss: 5.363794, valid precision: 0.875000, valid loss: 95.027679
epoch: 3734, train precision: 0.999778, train loss: 5.332155, valid precision: 0.873400, valid loss: 97.539849
epoch: 3735, train precision: 0.999667, train loss: 5.354758, valid precision: 0.873400, valid loss: 99.276376
epoch: 3736, train precision: 0.999756, train loss: 5.338640, valid precision: 0.871200, valid loss: 96.679678
epoch: 3737, train precision: 0.999622, train loss: 5.357190, valid precision: 0.872600, valid loss: 100.455960
epoch: 3738, train precision: 0.999756, train loss: 5.316613, valid precision: 0.870800, valid loss: 101.188618
epoch: 3739, train precision: 0.999822, train loss: 5.308013, valid precision: 0.872800, valid loss: 100.211106
epoch: 3740, train precision: 0.999578, train loss: 5.411435, valid precision: 0.871000, valid loss: 102.233705
epoch: 3741, train precision: 0.999756, train loss: 5.321828, valid precision: 0.871400, valid loss: 100.634925
epoch: 3742, train precision: 0.999644, train loss: 5.360347, valid precision: 0.870800, valid loss: 101.840340
epoch: 3743, train precision: 0.999511, train loss: 5.368125, valid precision: 0.874000, valid loss: 99.844058
epoch: 3744, train precision: 0.999711, train loss: 5.331060, valid precision: 0.871000, valid loss: 99.029023
epoch: 3745, train precision: 0.999756, train loss: 5.331058, valid precision: 0.873400, valid loss: 100.313864
epoch: 3746, train precision: 0.999689, train loss: 5.339375, valid precision: 0.873600, valid loss: 99.876599
epoch: 3747, train precision: 0.999711, train loss: 5.347850, valid precision: 0.872600, valid loss: 102.078765
epoch: 3748, train precision: 0.999600, train loss: 5.389675, valid precision: 0.874600, valid loss: 100.966992
epoch: 3749, train precision: 0.999533, train loss: 5.327048, valid precision: 0.875600, valid loss: 99.555450
epoch: 3750, train precision: 0.999689, train loss: 5.335322, valid precision: 0.875600, valid loss: 102.215312
epoch: 3751, train precision: 0.999822, train loss: 5.317802, valid precision: 0.872600, valid loss: 101.924541
epoch: 3752, train precision: 0.999600, train loss: 5.351817, valid precision: 0.873800, valid loss: 98.610851
epoch: 3753, train precision: 0.999600, train loss: 5.368661, valid precision: 0.870200, valid loss: 100.105236
epoch: 3754, train precision: 0.999689, train loss: 5.327243, valid precision: 0.874000, valid loss: 99.352658
epoch: 3755, train precision: 0.999600, train loss: 5.364264, valid precision: 0.871200, valid loss: 99.774034
epoch: 3756, train precision: 0.999733, train loss: 5.358563, valid precision: 0.872000, valid loss: 97.404389
epoch: 3757, train precision: 0.999800, train loss: 5.317190, valid precision: 0.874000, valid loss: 98.749894
epoch: 3758, train precision: 0.999756, train loss: 5.318158, valid precision: 0.873000, valid loss: 100.489612
epoch: 3759, train precision: 0.999667, train loss: 5.336194, valid precision: 0.876200, valid loss: 96.841181
epoch: 3760, train precision: 0.999800, train loss: 5.359255, valid precision: 0.874200, valid loss: 100.382273
epoch: 3761, train precision: 0.999733, train loss: 5.326841, valid precision: 0.877600, valid loss: 99.911127
epoch: 3762, train precision: 0.999667, train loss: 5.343431, valid precision: 0.874200, valid loss: 100.958596
epoch: 3763, train precision: 0.999822, train loss: 5.310318, valid precision: 0.873200, valid loss: 101.775966
epoch: 3764, train precision: 0.999756, train loss: 5.327050, valid precision: 0.872400, valid loss: 98.737985
epoch: 3765, train precision: 0.999578, train loss: 5.387409, valid precision: 0.873800, valid loss: 99.970527
epoch: 3766, train precision: 0.999622, train loss: 5.379724, valid precision: 0.874600, valid loss: 98.946056
epoch: 3767, train precision: 0.999711, train loss: 5.346954, valid precision: 0.876400, valid loss: 96.976766
epoch: 3768, train precision: 0.999822, train loss: 5.304534, valid precision: 0.877800, valid loss: 95.110796
epoch: 3769, train precision: 0.999756, train loss: 5.321442, valid precision: 0.874400, valid loss: 98.530109
epoch: 3770, train precision: 0.999733, train loss: 5.329537, valid precision: 0.875600, valid loss: 99.024420
epoch: 3771, train precision: 0.999622, train loss: 5.356820, valid precision: 0.875200, valid loss: 97.259060
epoch: 3772, train precision: 0.999667, train loss: 5.354248, valid precision: 0.876400, valid loss: 97.427228
epoch: 3773, train precision: 0.999689, train loss: 5.349314, valid precision: 0.873400, valid loss: 100.844090
epoch: 3774, train precision: 0.999756, train loss: 5.342991, valid precision: 0.877000, valid loss: 99.181644
epoch: 3775, train precision: 0.999733, train loss: 5.358654, valid precision: 0.881400, valid loss: 95.513463
epoch: 3776, train precision: 0.999711, train loss: 5.323383, valid precision: 0.877400, valid loss: 97.724650
epoch: 3777, train precision: 0.999711, train loss: 5.337657, valid precision: 0.876800, valid loss: 99.680295
epoch: 3778, train precision: 0.999756, train loss: 5.301757, valid precision: 0.878000, valid loss: 96.900968
epoch: 3779, train precision: 0.999689, train loss: 5.351930, valid precision: 0.879200, valid loss: 97.764929
epoch: 3780, train precision: 0.999711, train loss: 5.314473, valid precision: 0.879000, valid loss: 98.473630
epoch: 3781, train precision: 0.999756, train loss: 5.326845, valid precision: 0.875400, valid loss: 100.228168
epoch: 3782, train precision: 0.999556, train loss: 5.411529, valid precision: 0.876000, valid loss: 98.321719
epoch: 3783, train precision: 0.999600, train loss: 5.405020, valid precision: 0.876000, valid loss: 99.583001
epoch: 3784, train precision: 0.999844, train loss: 5.322067, valid precision: 0.876800, valid loss: 96.341298
epoch: 3785, train precision: 0.999733, train loss: 5.353793, valid precision: 0.872600, valid loss: 98.333883
epoch: 3786, train precision: 0.999800, train loss: 5.288864, valid precision: 0.875400, valid loss: 98.488468
epoch: 3787, train precision: 0.999844, train loss: 5.290910, valid precision: 0.879600, valid loss: 98.594389
epoch: 3788, train precision: 0.999689, train loss: 5.360923, valid precision: 0.875000, valid loss: 100.045554
epoch: 3789, train precision: 0.999778, train loss: 5.351058, valid precision: 0.873600, valid loss: 100.605949
epoch: 3790, train precision: 0.999489, train loss: 5.369120, valid precision: 0.875200, valid loss: 98.237562
epoch: 3791, train precision: 0.999467, train loss: 5.376648, valid precision: 0.874400, valid loss: 98.536407
epoch: 3792, train precision: 0.999622, train loss: 5.349972, valid precision: 0.875200, valid loss: 95.947366
epoch: 3793, train precision: 0.999600, train loss: 5.365357, valid precision: 0.874200, valid loss: 99.230953
epoch: 3794, train precision: 0.999756, train loss: 5.320807, valid precision: 0.878000, valid loss: 96.618555
epoch: 3795, train precision: 0.999711, train loss: 5.311857, valid precision: 0.876600, valid loss: 99.414231
epoch: 3796, train precision: 0.999889, train loss: 5.305575, valid precision: 0.878200, valid loss: 96.142105
epoch: 3797, train precision: 0.999689, train loss: 5.389956, valid precision: 0.877800, valid loss: 98.682127
epoch: 3798, train precision: 0.999800, train loss: 5.314487, valid precision: 0.874200, valid loss: 99.740628
epoch: 3799, train precision: 0.999867, train loss: 5.283948, valid precision: 0.878400, valid loss: 100.735235
epoch: 3800, train precision: 0.999867, train loss: 5.282221, valid precision: 0.874200, valid loss: 101.102894
epoch: 3801, train precision: 0.999844, train loss: 5.279226, valid precision: 0.873800, valid loss: 103.351682
epoch: 3802, train precision: 0.999533, train loss: 5.390578, valid precision: 0.877000, valid loss: 99.646452
epoch: 3803, train precision: 0.999533, train loss: 5.352661, valid precision: 0.877200, valid loss: 100.025079
epoch: 3804, train precision: 0.999822, train loss: 5.332723, valid precision: 0.874000, valid loss: 100.637361
epoch: 3805, train precision: 0.999733, train loss: 5.333840, valid precision: 0.875000, valid loss: 100.565160
epoch: 3806, train precision: 0.999733, train loss: 5.327027, valid precision: 0.873400, valid loss: 101.147295
epoch: 3807, train precision: 0.999756, train loss: 5.330362, valid precision: 0.872200, valid loss: 103.988321
epoch: 3808, train precision: 0.999844, train loss: 5.293346, valid precision: 0.872400, valid loss: 101.672246
epoch: 3809, train precision: 0.999778, train loss: 5.348560, valid precision: 0.878200, valid loss: 101.068135
epoch: 3810, train precision: 0.999778, train loss: 5.309579, valid precision: 0.875800, valid loss: 100.347569
epoch: 3811, train precision: 0.999667, train loss: 5.362398, valid precision: 0.875600, valid loss: 100.030123
epoch: 3812, train precision: 0.999689, train loss: 5.321807, valid precision: 0.871400, valid loss: 103.018515
epoch: 3813, train precision: 0.999822, train loss: 5.287298, valid precision: 0.873800, valid loss: 100.465407
epoch: 3814, train precision: 0.999800, train loss: 5.292545, valid precision: 0.873600, valid loss: 100.490217
epoch: 3815, train precision: 0.999667, train loss: 5.345006, valid precision: 0.876000, valid loss: 100.531544
epoch: 3816, train precision: 0.999356, train loss: 5.434754, valid precision: 0.869200, valid loss: 104.834193
epoch: 3817, train precision: 0.999844, train loss: 5.301088, valid precision: 0.872600, valid loss: 100.606968
epoch: 3818, train precision: 0.999511, train loss: 5.384943, valid precision: 0.872200, valid loss: 101.355102
epoch: 3819, train precision: 0.999533, train loss: 5.372815, valid precision: 0.871400, valid loss: 100.041839
epoch: 3820, train precision: 0.999711, train loss: 5.319850, valid precision: 0.874600, valid loss: 100.143541
epoch: 3821, train precision: 0.999467, train loss: 5.400257, valid precision: 0.875000, valid loss: 102.719563
epoch: 3822, train precision: 0.999644, train loss: 5.359279, valid precision: 0.872000, valid loss: 104.798516
epoch: 3823, train precision: 0.999644, train loss: 5.342371, valid precision: 0.872800, valid loss: 104.157325
epoch: 3824, train precision: 0.999889, train loss: 5.305404, valid precision: 0.872800, valid loss: 101.916562
epoch: 3825, train precision: 0.999711, train loss: 5.326718, valid precision: 0.875200, valid loss: 100.601197
epoch: 3826, train precision: 0.999689, train loss: 5.335928, valid precision: 0.874400, valid loss: 99.057583
epoch: 3827, train precision: 0.999711, train loss: 5.338510, valid precision: 0.874600, valid loss: 97.201507
epoch: 3828, train precision: 0.999667, train loss: 5.327830, valid precision: 0.873600, valid loss: 98.054715
epoch: 3829, train precision: 0.999711, train loss: 5.322725, valid precision: 0.873600, valid loss: 100.808919
epoch: 3830, train precision: 0.999578, train loss: 5.354356, valid precision: 0.871200, valid loss: 99.009622
epoch: 3831, train precision: 0.999711, train loss: 5.317096, valid precision: 0.873400, valid loss: 100.156721
epoch: 3832, train precision: 0.999556, train loss: 5.359358, valid precision: 0.875200, valid loss: 99.643831
epoch: 3833, train precision: 0.999533, train loss: 5.459532, valid precision: 0.872400, valid loss: 98.423629
epoch: 3834, train precision: 0.999733, train loss: 5.339183, valid precision: 0.874400, valid loss: 97.989247
epoch: 3835, train precision: 0.999844, train loss: 5.304255, valid precision: 0.877200, valid loss: 101.606380
epoch: 3836, train precision: 0.999556, train loss: 5.386843, valid precision: 0.874600, valid loss: 101.868028
epoch: 3837, train precision: 0.999689, train loss: 5.311187, valid precision: 0.876000, valid loss: 100.355655
epoch: 3838, train precision: 0.999533, train loss: 5.377321, valid precision: 0.875800, valid loss: 99.489618
epoch: 3839, train precision: 0.999711, train loss: 5.315683, valid precision: 0.875600, valid loss: 100.022634
epoch: 3840, train precision: 0.999778, train loss: 5.317724, valid precision: 0.875600, valid loss: 99.051881
epoch: 3841, train precision: 0.999489, train loss: 5.364433, valid precision: 0.873400, valid loss: 103.611155
epoch: 3842, train precision: 0.999622, train loss: 5.353691, valid precision: 0.871200, valid loss: 102.800940
epoch: 3843, train precision: 0.999711, train loss: 5.330883, valid precision: 0.877200, valid loss: 98.755723
epoch: 3844, train precision: 0.999267, train loss: 5.442955, valid precision: 0.876400, valid loss: 101.223666
epoch: 3845, train precision: 0.999689, train loss: 5.326313, valid precision: 0.877800, valid loss: 99.302124
epoch: 3846, train precision: 0.999756, train loss: 5.324805, valid precision: 0.876800, valid loss: 100.716905
epoch: 3847, train precision: 0.999778, train loss: 5.329869, valid precision: 0.878400, valid loss: 101.002244
epoch: 3848, train precision: 0.999711, train loss: 5.301444, valid precision: 0.877000, valid loss: 100.429995
epoch: 3849, train precision: 0.999756, train loss: 5.322909, valid precision: 0.878000, valid loss: 96.763816
epoch: 3850, train precision: 0.999733, train loss: 5.311612, valid precision: 0.877400, valid loss: 97.251184
epoch: 3851, train precision: 0.999733, train loss: 5.308426, valid precision: 0.878200, valid loss: 98.786646
epoch: 3852, train precision: 0.999711, train loss: 5.311310, valid precision: 0.875400, valid loss: 98.856644
epoch: 3853, train precision: 0.999533, train loss: 5.343016, valid precision: 0.879400, valid loss: 98.513637
epoch: 3854, train precision: 0.999711, train loss: 5.313658, valid precision: 0.877600, valid loss: 97.670066
epoch: 3855, train precision: 0.999756, train loss: 5.315108, valid precision: 0.876600, valid loss: 99.541153
epoch: 3856, train precision: 0.999756, train loss: 5.315553, valid precision: 0.874800, valid loss: 97.913397
epoch: 3857, train precision: 0.999578, train loss: 5.367979, valid precision: 0.875800, valid loss: 98.053608
epoch: 3858, train precision: 0.999644, train loss: 5.368432, valid precision: 0.875600, valid loss: 96.484716
epoch: 3859, train precision: 0.999733, train loss: 5.309376, valid precision: 0.875800, valid loss: 97.918633
epoch: 3860, train precision: 0.999689, train loss: 5.323495, valid precision: 0.873000, valid loss: 98.540382
epoch: 3861, train precision: 0.999756, train loss: 5.300837, valid precision: 0.875200, valid loss: 98.010104
epoch: 3862, train precision: 0.999733, train loss: 5.333318, valid precision: 0.876400, valid loss: 100.016617
epoch: 3863, train precision: 0.999511, train loss: 5.424894, valid precision: 0.880400, valid loss: 99.167251
epoch: 3864, train precision: 0.999667, train loss: 5.351286, valid precision: 0.877200, valid loss: 99.578632
epoch: 3865, train precision: 0.999711, train loss: 5.331733, valid precision: 0.875200, valid loss: 100.173339
epoch: 3866, train precision: 0.999622, train loss: 5.346647, valid precision: 0.875800, valid loss: 99.298602
epoch: 3867, train precision: 0.999711, train loss: 5.330880, valid precision: 0.876800, valid loss: 100.794595
epoch: 3868, train precision: 0.999600, train loss: 5.344141, valid precision: 0.876600, valid loss: 99.236125
epoch: 3869, train precision: 0.999778, train loss: 5.299350, valid precision: 0.880600, valid loss: 98.879165
epoch: 3870, train precision: 0.999822, train loss: 5.298621, valid precision: 0.873800, valid loss: 100.843316
epoch: 3871, train precision: 0.999711, train loss: 5.326412, valid precision: 0.877000, valid loss: 101.919857
epoch: 3872, train precision: 0.999689, train loss: 5.328296, valid precision: 0.877600, valid loss: 99.806284
epoch: 3873, train precision: 0.999822, train loss: 5.294591, valid precision: 0.878800, valid loss: 98.106211
epoch: 3874, train precision: 0.999733, train loss: 5.331383, valid precision: 0.876200, valid loss: 99.870910
epoch: 3875, train precision: 0.999756, train loss: 5.313998, valid precision: 0.876200, valid loss: 100.428638
epoch: 3876, train precision: 0.999822, train loss: 5.310630, valid precision: 0.876400, valid loss: 100.490903
epoch: 3877, train precision: 0.999778, train loss: 5.311169, valid precision: 0.877600, valid loss: 99.909551
epoch: 3878, train precision: 0.999778, train loss: 5.310409, valid precision: 0.874200, valid loss: 101.107102
epoch: 3879, train precision: 0.999711, train loss: 5.351457, valid precision: 0.876200, valid loss: 102.731888
epoch: 3880, train precision: 0.999578, train loss: 5.385670, valid precision: 0.871000, valid loss: 102.764841
epoch: 3881, train precision: 0.999756, train loss: 5.322931, valid precision: 0.878800, valid loss: 101.157368
epoch: 3882, train precision: 0.999778, train loss: 5.301315, valid precision: 0.873400, valid loss: 102.989631
epoch: 3883, train precision: 0.999444, train loss: 5.373037, valid precision: 0.872800, valid loss: 101.837214
epoch: 3884, train precision: 0.999689, train loss: 5.358167, valid precision: 0.875200, valid loss: 100.318309
epoch: 3885, train precision: 0.999622, train loss: 5.393302, valid precision: 0.874000, valid loss: 98.102863
epoch: 3886, train precision: 0.999689, train loss: 5.361192, valid precision: 0.873400, valid loss: 99.831367
epoch: 3887, train precision: 0.999667, train loss: 5.338379, valid precision: 0.869400, valid loss: 103.873868
epoch: 3888, train precision: 0.999644, train loss: 5.331345, valid precision: 0.873800, valid loss: 102.652335
epoch: 3889, train precision: 0.999756, train loss: 5.326050, valid precision: 0.873800, valid loss: 102.029816
epoch: 3890, train precision: 0.999667, train loss: 5.338525, valid precision: 0.875400, valid loss: 102.077769
epoch: 3891, train precision: 0.999733, train loss: 5.316806, valid precision: 0.871800, valid loss: 102.796046
epoch: 3892, train precision: 0.999711, train loss: 5.315668, valid precision: 0.875000, valid loss: 101.963704
epoch: 3893, train precision: 0.999622, train loss: 5.370430, valid precision: 0.876000, valid loss: 101.933188
epoch: 3894, train precision: 0.999933, train loss: 5.270339, valid precision: 0.874400, valid loss: 102.801878
epoch: 3895, train precision: 0.999467, train loss: 5.396399, valid precision: 0.873200, valid loss: 101.123024
epoch: 3896, train precision: 0.999800, train loss: 5.294653, valid precision: 0.874600, valid loss: 99.466601
epoch: 3897, train precision: 0.999800, train loss: 5.289405, valid precision: 0.875600, valid loss: 99.422882
epoch: 3898, train precision: 0.999622, train loss: 5.324544, valid precision: 0.871400, valid loss: 102.052879
epoch: 3899, train precision: 0.999667, train loss: 5.339808, valid precision: 0.874600, valid loss: 101.361081
epoch: 3900, train precision: 0.999822, train loss: 5.287822, valid precision: 0.873800, valid loss: 101.278669
epoch: 3901, train precision: 0.999822, train loss: 5.284750, valid precision: 0.874800, valid loss: 102.252411
epoch: 3902, train precision: 0.999489, train loss: 5.381759, valid precision: 0.876800, valid loss: 101.930138
epoch: 3903, train precision: 0.999556, train loss: 5.350287, valid precision: 0.875200, valid loss: 100.346275
epoch: 3904, train precision: 0.999622, train loss: 5.334005, valid precision: 0.877800, valid loss: 97.609352
epoch: 3905, train precision: 0.999822, train loss: 5.307992, valid precision: 0.877400, valid loss: 102.454673
epoch: 3906, train precision: 0.999756, train loss: 5.290001, valid precision: 0.878800, valid loss: 101.296794
epoch: 3907, train precision: 0.999733, train loss: 5.290842, valid precision: 0.873200, valid loss: 102.244845
epoch: 3908, train precision: 0.999711, train loss: 5.335093, valid precision: 0.878400, valid loss: 101.711635
epoch: 3909, train precision: 0.999689, train loss: 5.363548, valid precision: 0.876600, valid loss: 100.334923
epoch: 3910, train precision: 0.999622, train loss: 5.337526, valid precision: 0.877800, valid loss: 99.038335
epoch: 3911, train precision: 0.999600, train loss: 5.324670, valid precision: 0.873400, valid loss: 100.579631
epoch: 3912, train precision: 0.999644, train loss: 5.384573, valid precision: 0.873000, valid loss: 101.949962
epoch: 3913, train precision: 0.999600, train loss: 5.346503, valid precision: 0.874800, valid loss: 100.737085
epoch: 3914, train precision: 0.999800, train loss: 5.282538, valid precision: 0.877200, valid loss: 103.156015
epoch: 3915, train precision: 0.999556, train loss: 5.360468, valid precision: 0.876600, valid loss: 99.102813
epoch: 3916, train precision: 0.999644, train loss: 5.378638, valid precision: 0.873600, valid loss: 100.408888
epoch: 3917, train precision: 0.999667, train loss: 5.326698, valid precision: 0.873400, valid loss: 99.573632
epoch: 3918, train precision: 0.999667, train loss: 5.337814, valid precision: 0.876200, valid loss: 98.010796
epoch: 3919, train precision: 0.999578, train loss: 5.385784, valid precision: 0.874600, valid loss: 100.001253
epoch: 3920, train precision: 0.999689, train loss: 5.337040, valid precision: 0.874800, valid loss: 100.958602
epoch: 3921, train precision: 0.999756, train loss: 5.294855, valid precision: 0.878800, valid loss: 98.764811
epoch: 3922, train precision: 0.999756, train loss: 5.302346, valid precision: 0.873800, valid loss: 101.249566
epoch: 3923, train precision: 0.999622, train loss: 5.341196, valid precision: 0.873600, valid loss: 102.212638
epoch: 3924, train precision: 0.999600, train loss: 5.328789, valid precision: 0.874200, valid loss: 98.213062
epoch: 3925, train precision: 0.999844, train loss: 5.291594, valid precision: 0.872600, valid loss: 99.933393
epoch: 3926, train precision: 0.999733, train loss: 5.341110, valid precision: 0.875400, valid loss: 98.793313
epoch: 3927, train precision: 0.999622, train loss: 5.353391, valid precision: 0.871600, valid loss: 100.389652
epoch: 3928, train precision: 0.999822, train loss: 5.276077, valid precision: 0.872200, valid loss: 99.009142
epoch: 3929, train precision: 0.999689, train loss: 5.345420, valid precision: 0.870800, valid loss: 102.975381
epoch: 3930, train precision: 0.999511, train loss: 5.378438, valid precision: 0.871600, valid loss: 101.356919
epoch: 3931, train precision: 0.999689, train loss: 5.315856, valid precision: 0.875800, valid loss: 97.102268
epoch: 3932, train precision: 0.999644, train loss: 5.354638, valid precision: 0.876400, valid loss: 98.566618
epoch: 3933, train precision: 0.999644, train loss: 5.348483, valid precision: 0.875200, valid loss: 97.196177
epoch: 3934, train precision: 0.999689, train loss: 5.334649, valid precision: 0.875800, valid loss: 96.113349
epoch: 3935, train precision: 0.999733, train loss: 5.320792, valid precision: 0.875800, valid loss: 99.573364
epoch: 3936, train precision: 0.999711, train loss: 5.323233, valid precision: 0.875200, valid loss: 97.306781
epoch: 3937, train precision: 0.999756, train loss: 5.310718, valid precision: 0.875200, valid loss: 97.066751
epoch: 3938, train precision: 0.999444, train loss: 5.390050, valid precision: 0.875200, valid loss: 96.834315
epoch: 3939, train precision: 0.999867, train loss: 5.286231, valid precision: 0.879000, valid loss: 97.096491
epoch: 3940, train precision: 0.999667, train loss: 5.335631, valid precision: 0.874400, valid loss: 99.896967
epoch: 3941, train precision: 0.999756, train loss: 5.321975, valid precision: 0.871400, valid loss: 97.070958
epoch: 3942, train precision: 0.999867, train loss: 5.306832, valid precision: 0.878000, valid loss: 98.924443
epoch: 3943, train precision: 0.999711, train loss: 5.329308, valid precision: 0.873000, valid loss: 99.872283
epoch: 3944, train precision: 0.999644, train loss: 5.359239, valid precision: 0.872200, valid loss: 101.065366
epoch: 3945, train precision: 0.999756, train loss: 5.301026, valid precision: 0.872000, valid loss: 100.924581
epoch: 3946, train precision: 0.999733, train loss: 5.332232, valid precision: 0.876400, valid loss: 99.973506
epoch: 3947, train precision: 0.999733, train loss: 5.292242, valid precision: 0.875600, valid loss: 99.825810
epoch: 3948, train precision: 0.999778, train loss: 5.326544, valid precision: 0.877000, valid loss: 98.894215
epoch: 3949, train precision: 0.999711, train loss: 5.354301, valid precision: 0.875600, valid loss: 98.893761
epoch: 3950, train precision: 0.999800, train loss: 5.308436, valid precision: 0.873000, valid loss: 100.687967
epoch: 3951, train precision: 0.999667, train loss: 5.354522, valid precision: 0.876200, valid loss: 99.161202
epoch: 3952, train precision: 0.999800, train loss: 5.342451, valid precision: 0.873000, valid loss: 100.358619
epoch: 3953, train precision: 0.999733, train loss: 5.338898, valid precision: 0.873800, valid loss: 101.499476
epoch: 3954, train precision: 0.999622, train loss: 5.325815, valid precision: 0.872400, valid loss: 101.453784
epoch: 3955, train precision: 0.999578, train loss: 5.354017, valid precision: 0.872000, valid loss: 100.694670
epoch: 3956, train precision: 0.999689, train loss: 5.321575, valid precision: 0.878800, valid loss: 99.420404
epoch: 3957, train precision: 0.999711, train loss: 5.315077, valid precision: 0.878000, valid loss: 96.659350
epoch: 3958, train precision: 0.999711, train loss: 5.317836, valid precision: 0.874000, valid loss: 101.019967
epoch: 3959, train precision: 0.999844, train loss: 5.288169, valid precision: 0.876200, valid loss: 97.406416
epoch: 3960, train precision: 0.999622, train loss: 5.388270, valid precision: 0.876200, valid loss: 100.629269
epoch: 3961, train precision: 0.999667, train loss: 5.327669, valid precision: 0.878600, valid loss: 98.364537
epoch: 3962, train precision: 0.999689, train loss: 5.331684, valid precision: 0.875400, valid loss: 101.249519
epoch: 3963, train precision: 0.999800, train loss: 5.313585, valid precision: 0.877600, valid loss: 97.736943
epoch: 3964, train precision: 0.999556, train loss: 5.391621, valid precision: 0.876400, valid loss: 103.026757
epoch: 3965, train precision: 0.999778, train loss: 5.285889, valid precision: 0.875800, valid loss: 101.676154
epoch: 3966, train precision: 0.999733, train loss: 5.339346, valid precision: 0.872200, valid loss: 101.965767
epoch: 3967, train precision: 0.999667, train loss: 5.317886, valid precision: 0.878000, valid loss: 97.978976
epoch: 3968, train precision: 0.999800, train loss: 5.313574, valid precision: 0.878200, valid loss: 96.768212
epoch: 3969, train precision: 0.999644, train loss: 5.316340, valid precision: 0.875800, valid loss: 97.431122
epoch: 3970, train precision: 0.999511, train loss: 5.371299, valid precision: 0.879200, valid loss: 97.311425
epoch: 3971, train precision: 0.999756, train loss: 5.301714, valid precision: 0.876000, valid loss: 99.184750
epoch: 3972, train precision: 0.999578, train loss: 5.360848, valid precision: 0.877200, valid loss: 98.193875
epoch: 3973, train precision: 0.999622, train loss: 5.365850, valid precision: 0.873000, valid loss: 102.285075
epoch: 3974, train precision: 0.999600, train loss: 5.343160, valid precision: 0.874000, valid loss: 99.778536
epoch: 3975, train precision: 0.999800, train loss: 5.320758, valid precision: 0.874200, valid loss: 100.963353
epoch: 3976, train precision: 0.999733, train loss: 5.304261, valid precision: 0.875000, valid loss: 103.267139
epoch: 3977, train precision: 0.999756, train loss: 5.293063, valid precision: 0.876800, valid loss: 98.684940
epoch: 3978, train precision: 0.999711, train loss: 5.313746, valid precision: 0.878000, valid loss: 98.178970
epoch: 3979, train precision: 0.999778, train loss: 5.305494, valid precision: 0.879600, valid loss: 99.276462
epoch: 3980, train precision: 0.999511, train loss: 5.351893, valid precision: 0.879400, valid loss: 99.202168
epoch: 3981, train precision: 0.999689, train loss: 5.320599, valid precision: 0.874600, valid loss: 100.166750
epoch: 3982, train precision: 0.999733, train loss: 5.338959, valid precision: 0.877000, valid loss: 102.298454
epoch: 3983, train precision: 0.999822, train loss: 5.322046, valid precision: 0.875400, valid loss: 99.353810
epoch: 3984, train precision: 0.999800, train loss: 5.311149, valid precision: 0.877200, valid loss: 98.476061
epoch: 3985, train precision: 0.999733, train loss: 5.347480, valid precision: 0.876800, valid loss: 99.796042
epoch: 3986, train precision: 0.999689, train loss: 5.298035, valid precision: 0.877600, valid loss: 99.892165
epoch: 3987, train precision: 0.999756, train loss: 5.308431, valid precision: 0.875000, valid loss: 99.649943
epoch: 3988, train precision: 0.999778, train loss: 5.300254, valid precision: 0.875200, valid loss: 99.192305
epoch: 3989, train precision: 0.999756, train loss: 5.321403, valid precision: 0.876600, valid loss: 100.087051
epoch: 3990, train precision: 0.999600, train loss: 5.385925, valid precision: 0.873200, valid loss: 100.286619
epoch: 3991, train precision: 0.999778, train loss: 5.306053, valid precision: 0.877200, valid loss: 97.870737
epoch: 3992, train precision: 0.999867, train loss: 5.282035, valid precision: 0.877200, valid loss: 98.302421
epoch: 3993, train precision: 0.999733, train loss: 5.341910, valid precision: 0.876200, valid loss: 100.281678
epoch: 3994, train precision: 0.999756, train loss: 5.283246, valid precision: 0.879800, valid loss: 97.733774
epoch: 3995, train precision: 0.999667, train loss: 5.361829, valid precision: 0.879000, valid loss: 98.556345
epoch: 3996, train precision: 0.999711, train loss: 5.307273, valid precision: 0.874800, valid loss: 97.820464
epoch: 3997, train precision: 0.999644, train loss: 5.336441, valid precision: 0.879200, valid loss: 98.130338
epoch: 3998, train precision: 0.999800, train loss: 5.306501, valid precision: 0.874400, valid loss: 97.574013
epoch: 3999, train precision: 0.999578, train loss: 5.332768, valid precision: 0.877400, valid loss: 96.755328
epoch: 4000, train precision: 0.999778, train loss: 5.302959, valid precision: 0.874600, valid loss: 99.495095
epoch: 4001, train precision: 0.999711, train loss: 5.328244, valid precision: 0.876400, valid loss: 98.452230
epoch: 4002, train precision: 0.999711, train loss: 5.303181, valid precision: 0.877800, valid loss: 98.991398
epoch: 4003, train precision: 0.999756, train loss: 5.280802, valid precision: 0.878200, valid loss: 100.090248
epoch: 4004, train precision: 0.999733, train loss: 5.295026, valid precision: 0.878200, valid loss: 97.121685
epoch: 4005, train precision: 0.999778, train loss: 5.318758, valid precision: 0.876800, valid loss: 97.169490
epoch: 4006, train precision: 0.999778, train loss: 5.284909, valid precision: 0.883000, valid loss: 96.629964
epoch: 4007, train precision: 0.999756, train loss: 5.309300, valid precision: 0.881400, valid loss: 96.159454
epoch: 4008, train precision: 0.999533, train loss: 5.333969, valid precision: 0.882000, valid loss: 94.621462
epoch: 4009, train precision: 0.999800, train loss: 5.295540, valid precision: 0.882200, valid loss: 93.689738
epoch: 4010, train precision: 0.999489, train loss: 5.391884, valid precision: 0.878400, valid loss: 97.498860
epoch: 4011, train precision: 0.999756, train loss: 5.302816, valid precision: 0.881600, valid loss: 95.944592
epoch: 4012, train precision: 0.999800, train loss: 5.300153, valid precision: 0.881600, valid loss: 97.226395
epoch: 4013, train precision: 0.999756, train loss: 5.280068, valid precision: 0.879600, valid loss: 98.268614
epoch: 4014, train precision: 0.999778, train loss: 5.292199, valid precision: 0.880000, valid loss: 99.399020
epoch: 4015, train precision: 0.999622, train loss: 5.358878, valid precision: 0.878000, valid loss: 98.756592
epoch: 4016, train precision: 0.999733, train loss: 5.329587, valid precision: 0.881400, valid loss: 98.654677
epoch: 4017, train precision: 0.999800, train loss: 5.314087, valid precision: 0.876200, valid loss: 98.593622
epoch: 4018, train precision: 0.999733, train loss: 5.334241, valid precision: 0.880000, valid loss: 96.616943
epoch: 4019, train precision: 0.999556, train loss: 5.344476, valid precision: 0.875200, valid loss: 101.543743
epoch: 4020, train precision: 0.999800, train loss: 5.296551, valid precision: 0.875600, valid loss: 101.005348
epoch: 4021, train precision: 0.999467, train loss: 5.359603, valid precision: 0.879400, valid loss: 102.829748
epoch: 4022, train precision: 0.999667, train loss: 5.324268, valid precision: 0.875600, valid loss: 102.327386
epoch: 4023, train precision: 0.999867, train loss: 5.274900, valid precision: 0.875000, valid loss: 98.367598
epoch: 4024, train precision: 0.999711, train loss: 5.297993, valid precision: 0.876400, valid loss: 100.254241
epoch: 4025, train precision: 0.999733, train loss: 5.310626, valid precision: 0.874200, valid loss: 100.747457
epoch: 4026, train precision: 0.999867, train loss: 5.307136, valid precision: 0.872000, valid loss: 102.340163
epoch: 4027, train precision: 0.999667, train loss: 5.344925, valid precision: 0.871400, valid loss: 103.483448
epoch: 4028, train precision: 0.999511, train loss: 5.374528, valid precision: 0.876600, valid loss: 97.326599
epoch: 4029, train precision: 0.999756, train loss: 5.302599, valid precision: 0.877400, valid loss: 99.389547
epoch: 4030, train precision: 0.999711, train loss: 5.309829, valid precision: 0.875000, valid loss: 100.490701
epoch: 4031, train precision: 0.999733, train loss: 5.308966, valid precision: 0.877000, valid loss: 96.847472
epoch: 4032, train precision: 0.999644, train loss: 5.356997, valid precision: 0.876800, valid loss: 97.636892
epoch: 4033, train precision: 0.999689, train loss: 5.302817, valid precision: 0.874200, valid loss: 101.506032
epoch: 4034, train precision: 0.999778, train loss: 5.284273, valid precision: 0.879600, valid loss: 98.594752
epoch: 4035, train precision: 0.999711, train loss: 5.319385, valid precision: 0.875400, valid loss: 98.627301
epoch: 4036, train precision: 0.999822, train loss: 5.286734, valid precision: 0.876400, valid loss: 98.787166
epoch: 4037, train precision: 0.999689, train loss: 5.306651, valid precision: 0.876400, valid loss: 98.690804
epoch: 4038, train precision: 0.999667, train loss: 5.308281, valid precision: 0.879200, valid loss: 97.781252
epoch: 4039, train precision: 0.999911, train loss: 5.279955, valid precision: 0.879400, valid loss: 98.316745
epoch: 4040, train precision: 0.999844, train loss: 5.283216, valid precision: 0.880000, valid loss: 99.654146
epoch: 4041, train precision: 0.999822, train loss: 5.290094, valid precision: 0.873000, valid loss: 98.487158
epoch: 4042, train precision: 0.999711, train loss: 5.330721, valid precision: 0.875800, valid loss: 98.886685
epoch: 4043, train precision: 0.999644, train loss: 5.335371, valid precision: 0.875000, valid loss: 97.114890
epoch: 4044, train precision: 0.999778, train loss: 5.302181, valid precision: 0.874400, valid loss: 99.169469
epoch: 4045, train precision: 0.999689, train loss: 5.323447, valid precision: 0.875200, valid loss: 97.878210
epoch: 4046, train precision: 0.999844, train loss: 5.299378, valid precision: 0.877000, valid loss: 98.500681
epoch: 4047, train precision: 0.999622, train loss: 5.342633, valid precision: 0.876400, valid loss: 99.550027
epoch: 4048, train precision: 0.999600, train loss: 5.350383, valid precision: 0.876400, valid loss: 103.332929
epoch: 4049, train precision: 0.999644, train loss: 5.348276, valid precision: 0.873200, valid loss: 99.357348
epoch: 4050, train precision: 0.999756, train loss: 5.302676, valid precision: 0.876600, valid loss: 98.988230
epoch: 4051, train precision: 0.999533, train loss: 5.399110, valid precision: 0.875000, valid loss: 99.631963
epoch: 4052, train precision: 0.999844, train loss: 5.274794, valid precision: 0.875400, valid loss: 98.802158
epoch: 4053, train precision: 0.999867, train loss: 5.276327, valid precision: 0.879400, valid loss: 97.381383
epoch: 4054, train precision: 0.999778, train loss: 5.303083, valid precision: 0.876000, valid loss: 100.466362
epoch: 4055, train precision: 0.999733, train loss: 5.304336, valid precision: 0.875600, valid loss: 98.280863
epoch: 4056, train precision: 0.999644, train loss: 5.322310, valid precision: 0.881600, valid loss: 97.662179
epoch: 4057, train precision: 0.999800, train loss: 5.290608, valid precision: 0.877000, valid loss: 100.033237
epoch: 4058, train precision: 0.999622, train loss: 5.335805, valid precision: 0.881400, valid loss: 97.794973
epoch: 4059, train precision: 0.999756, train loss: 5.306702, valid precision: 0.880200, valid loss: 98.482791
epoch: 4060, train precision: 0.999711, train loss: 5.305844, valid precision: 0.878200, valid loss: 97.785252
epoch: 4061, train precision: 0.999756, train loss: 5.290105, valid precision: 0.880000, valid loss: 98.528134
epoch: 4062, train precision: 0.999756, train loss: 5.305082, valid precision: 0.878600, valid loss: 100.020084
epoch: 4063, train precision: 0.999844, train loss: 5.305528, valid precision: 0.875600, valid loss: 99.112254
epoch: 4064, train precision: 0.999756, train loss: 5.287294, valid precision: 0.879600, valid loss: 99.770682
epoch: 4065, train precision: 0.999667, train loss: 5.334181, valid precision: 0.881600, valid loss: 99.116959
epoch: 4066, train precision: 0.999822, train loss: 5.277884, valid precision: 0.875200, valid loss: 101.442813
epoch: 4067, train precision: 0.999578, train loss: 5.335612, valid precision: 0.877600, valid loss: 99.980553
epoch: 4068, train precision: 0.999689, train loss: 5.316840, valid precision: 0.875000, valid loss: 100.798298
epoch: 4069, train precision: 0.999933, train loss: 5.247292, valid precision: 0.879000, valid loss: 98.793058
epoch: 4070, train precision: 0.999778, train loss: 5.330559, valid precision: 0.877200, valid loss: 97.638504
epoch: 4071, train precision: 0.999689, train loss: 5.299212, valid precision: 0.878000, valid loss: 96.450918
epoch: 4072, train precision: 0.999600, train loss: 5.331438, valid precision: 0.877200, valid loss: 97.639567
epoch: 4073, train precision: 0.999756, train loss: 5.300344, valid precision: 0.879200, valid loss: 97.170013
epoch: 4074, train precision: 0.999711, train loss: 5.289279, valid precision: 0.879600, valid loss: 97.811759
epoch: 4075, train precision: 0.999667, train loss: 5.312923, valid precision: 0.878200, valid loss: 97.295140
epoch: 4076, train precision: 0.999733, train loss: 5.303544, valid precision: 0.877400, valid loss: 101.334870
epoch: 4077, train precision: 0.999800, train loss: 5.311580, valid precision: 0.880800, valid loss: 98.478071
epoch: 4078, train precision: 0.999800, train loss: 5.283612, valid precision: 0.878000, valid loss: 99.949854
epoch: 4079, train precision: 0.999578, train loss: 5.350526, valid precision: 0.879200, valid loss: 102.934399
epoch: 4080, train precision: 0.999822, train loss: 5.279610, valid precision: 0.873600, valid loss: 99.554766
epoch: 4081, train precision: 0.999800, train loss: 5.318556, valid precision: 0.876600, valid loss: 98.395009
epoch: 4082, train precision: 0.999756, train loss: 5.311261, valid precision: 0.874000, valid loss: 98.599142
epoch: 4083, train precision: 0.999667, train loss: 5.342224, valid precision: 0.878800, valid loss: 97.683810
epoch: 4084, train precision: 0.999756, train loss: 5.291634, valid precision: 0.877600, valid loss: 97.123011
epoch: 4085, train precision: 0.999600, train loss: 5.343155, valid precision: 0.880400, valid loss: 97.365086
epoch: 4086, train precision: 0.999711, train loss: 5.281371, valid precision: 0.880200, valid loss: 97.444653
epoch: 4087, train precision: 0.999667, train loss: 5.329316, valid precision: 0.878400, valid loss: 100.184051
epoch: 4088, train precision: 0.999578, train loss: 5.337183, valid precision: 0.878000, valid loss: 101.395149
epoch: 4089, train precision: 0.999778, train loss: 5.302492, valid precision: 0.874400, valid loss: 98.750853
epoch: 4090, train precision: 0.999778, train loss: 5.275726, valid precision: 0.878400, valid loss: 98.054380
epoch: 4091, train precision: 0.999644, train loss: 5.317105, valid precision: 0.875000, valid loss: 98.752538
epoch: 4092, train precision: 0.999644, train loss: 5.294529, valid precision: 0.877400, valid loss: 101.031789
epoch: 4093, train precision: 0.999778, train loss: 5.284421, valid precision: 0.876200, valid loss: 99.435387
epoch: 4094, train precision: 0.999822, train loss: 5.278493, valid precision: 0.878200, valid loss: 99.279311
epoch: 4095, train precision: 0.999756, train loss: 5.303137, valid precision: 0.874200, valid loss: 96.524177
epoch: 4096, train precision: 0.999800, train loss: 5.268048, valid precision: 0.874200, valid loss: 96.447271
epoch: 4097, train precision: 0.999800, train loss: 5.286328, valid precision: 0.880000, valid loss: 97.929682
epoch: 4098, train precision: 0.999644, train loss: 5.335404, valid precision: 0.879000, valid loss: 98.498272
epoch: 4099, train precision: 0.999556, train loss: 5.338433, valid precision: 0.879400, valid loss: 99.059559
epoch: 4100, train precision: 0.999644, train loss: 5.311303, valid precision: 0.882000, valid loss: 98.833736
epoch: 4101, train precision: 0.999533, train loss: 5.372587, valid precision: 0.877800, valid loss: 98.953639
epoch: 4102, train precision: 0.999467, train loss: 5.382094, valid precision: 0.876800, valid loss: 98.930365
epoch: 4103, train precision: 0.999556, train loss: 5.347378, valid precision: 0.877000, valid loss: 97.266169
epoch: 4104, train precision: 0.999889, train loss: 5.261822, valid precision: 0.871400, valid loss: 99.496713
epoch: 4105, train precision: 0.999711, train loss: 5.323720, valid precision: 0.875400, valid loss: 99.874960
epoch: 4106, train precision: 0.999778, train loss: 5.282701, valid precision: 0.875600, valid loss: 97.949270
epoch: 4107, train precision: 0.999800, train loss: 5.305144, valid precision: 0.876400, valid loss: 97.351006
epoch: 4108, train precision: 0.999644, train loss: 5.332886, valid precision: 0.875600, valid loss: 97.485398
epoch: 4109, train precision: 0.999644, train loss: 5.350305, valid precision: 0.873600, valid loss: 99.425770
epoch: 4110, train precision: 0.999733, train loss: 5.284465, valid precision: 0.876200, valid loss: 98.664052
epoch: 4111, train precision: 0.999822, train loss: 5.287390, valid precision: 0.872600, valid loss: 99.315390
epoch: 4112, train precision: 0.999556, train loss: 5.320965, valid precision: 0.871000, valid loss: 99.626762
epoch: 4113, train precision: 0.999667, train loss: 5.320439, valid precision: 0.872000, valid loss: 97.841511
epoch: 4114, train precision: 0.999844, train loss: 5.289112, valid precision: 0.875800, valid loss: 97.851976
epoch: 4115, train precision: 0.999756, train loss: 5.307223, valid precision: 0.876000, valid loss: 102.557579
epoch: 4116, train precision: 0.999800, train loss: 5.315758, valid precision: 0.874800, valid loss: 98.313574
epoch: 4117, train precision: 0.999667, train loss: 5.328878, valid precision: 0.871200, valid loss: 100.542468
epoch: 4118, train precision: 0.999756, train loss: 5.297104, valid precision: 0.872600, valid loss: 102.309716
epoch: 4119, train precision: 0.999667, train loss: 5.323684, valid precision: 0.874400, valid loss: 99.419634
epoch: 4120, train precision: 0.999756, train loss: 5.302164, valid precision: 0.875800, valid loss: 98.731502
epoch: 4121, train precision: 0.999689, train loss: 5.342915, valid precision: 0.874000, valid loss: 100.339371
epoch: 4122, train precision: 0.999778, train loss: 5.292446, valid precision: 0.873400, valid loss: 99.323364
epoch: 4123, train precision: 0.999822, train loss: 5.286152, valid precision: 0.875200, valid loss: 98.531205
epoch: 4124, train precision: 0.999756, train loss: 5.297389, valid precision: 0.874200, valid loss: 99.962843
epoch: 4125, train precision: 0.999578, train loss: 5.348950, valid precision: 0.876200, valid loss: 100.929076
epoch: 4126, train precision: 0.999756, train loss: 5.305218, valid precision: 0.873800, valid loss: 100.584179
epoch: 4127, train precision: 0.999756, train loss: 5.287733, valid precision: 0.876400, valid loss: 99.596867
epoch: 4128, train precision: 0.999844, train loss: 5.252457, valid precision: 0.876200, valid loss: 98.348299
epoch: 4129, train precision: 0.999467, train loss: 5.372136, valid precision: 0.877800, valid loss: 98.724247
epoch: 4130, train precision: 0.999667, train loss: 5.297719, valid precision: 0.878600, valid loss: 99.501390
epoch: 4131, train precision: 0.999622, train loss: 5.350983, valid precision: 0.870600, valid loss: 100.447694
epoch: 4132, train precision: 0.999667, train loss: 5.321830, valid precision: 0.873800, valid loss: 102.531100
epoch: 4133, train precision: 0.999489, train loss: 5.351859, valid precision: 0.872800, valid loss: 103.097049
epoch: 4134, train precision: 0.999733, train loss: 5.288845, valid precision: 0.869600, valid loss: 100.390245
epoch: 4135, train precision: 0.999778, train loss: 5.278072, valid precision: 0.871800, valid loss: 100.123094
epoch: 4136, train precision: 0.999822, train loss: 5.273816, valid precision: 0.875800, valid loss: 98.144696
epoch: 4137, train precision: 0.999733, train loss: 5.300220, valid precision: 0.873200, valid loss: 100.490046
epoch: 4138, train precision: 0.999756, train loss: 5.296793, valid precision: 0.875800, valid loss: 100.061359
epoch: 4139, train precision: 0.999711, train loss: 5.325970, valid precision: 0.874600, valid loss: 97.771889
epoch: 4140, train precision: 0.999622, train loss: 5.341364, valid precision: 0.871400, valid loss: 101.626641
epoch: 4141, train precision: 0.999644, train loss: 5.309414, valid precision: 0.876000, valid loss: 98.908899
epoch: 4142, train precision: 0.999733, train loss: 5.312974, valid precision: 0.874200, valid loss: 97.433433
epoch: 4143, train precision: 0.999600, train loss: 5.340705, valid precision: 0.873200, valid loss: 99.675347
epoch: 4144, train precision: 0.999600, train loss: 5.342410, valid precision: 0.868800, valid loss: 100.881628
epoch: 4145, train precision: 0.999867, train loss: 5.260474, valid precision: 0.875400, valid loss: 99.439454
epoch: 4146, train precision: 0.999622, train loss: 5.332235, valid precision: 0.871800, valid loss: 97.827273
epoch: 4147, train precision: 0.999711, train loss: 5.309602, valid precision: 0.874800, valid loss: 98.481291
epoch: 4148, train precision: 0.999622, train loss: 5.315566, valid precision: 0.875000, valid loss: 98.510064
epoch: 4149, train precision: 0.999844, train loss: 5.277799, valid precision: 0.873800, valid loss: 97.234267
epoch: 4150, train precision: 0.999867, train loss: 5.275553, valid precision: 0.877600, valid loss: 95.246600
epoch: 4151, train precision: 0.999844, train loss: 5.280816, valid precision: 0.873400, valid loss: 94.506410
epoch: 4152, train precision: 0.999556, train loss: 5.335445, valid precision: 0.876200, valid loss: 96.304603
epoch: 4153, train precision: 0.999889, train loss: 5.242660, valid precision: 0.873800, valid loss: 96.529823
epoch: 4154, train precision: 0.999822, train loss: 5.257921, valid precision: 0.875200, valid loss: 95.853975
epoch: 4155, train precision: 0.999844, train loss: 5.274216, valid precision: 0.874600, valid loss: 96.493697
epoch: 4156, train precision: 0.999889, train loss: 5.292003, valid precision: 0.875600, valid loss: 96.810078
epoch: 4157, train precision: 0.999822, train loss: 5.290728, valid precision: 0.875800, valid loss: 95.895894
epoch: 4158, train precision: 0.999778, train loss: 5.293005, valid precision: 0.876400, valid loss: 95.539414
epoch: 4159, train precision: 0.999444, train loss: 5.397068, valid precision: 0.873200, valid loss: 101.202090
epoch: 4160, train precision: 0.999778, train loss: 5.292719, valid precision: 0.872600, valid loss: 96.925124
epoch: 4161, train precision: 0.999733, train loss: 5.283654, valid precision: 0.873200, valid loss: 97.854823
epoch: 4162, train precision: 0.999667, train loss: 5.310908, valid precision: 0.874000, valid loss: 100.353033
epoch: 4163, train precision: 0.999600, train loss: 5.347856, valid precision: 0.871400, valid loss: 99.124950
epoch: 4164, train precision: 0.999800, train loss: 5.256281, valid precision: 0.876600, valid loss: 97.909093
epoch: 4165, train precision: 0.999667, train loss: 5.313741, valid precision: 0.875200, valid loss: 94.612212
epoch: 4166, train precision: 0.999867, train loss: 5.274448, valid precision: 0.876200, valid loss: 97.481759
epoch: 4167, train precision: 0.999778, train loss: 5.273483, valid precision: 0.878800, valid loss: 99.156993
epoch: 4168, train precision: 0.999689, train loss: 5.351498, valid precision: 0.874400, valid loss: 97.389181
epoch: 4169, train precision: 0.999600, train loss: 5.347288, valid precision: 0.875400, valid loss: 95.468441
epoch: 4170, train precision: 0.999844, train loss: 5.287712, valid precision: 0.873800, valid loss: 96.073115
epoch: 4171, train precision: 0.999756, train loss: 5.271764, valid precision: 0.877400, valid loss: 96.154386
epoch: 4172, train precision: 0.999667, train loss: 5.343762, valid precision: 0.875800, valid loss: 98.054938
epoch: 4173, train precision: 0.999600, train loss: 5.351220, valid precision: 0.877800, valid loss: 99.662897
epoch: 4174, train precision: 0.999689, train loss: 5.319840, valid precision: 0.876800, valid loss: 95.860752
epoch: 4175, train precision: 0.999822, train loss: 5.290119, valid precision: 0.875600, valid loss: 94.424415
epoch: 4176, train precision: 0.999711, train loss: 5.336173, valid precision: 0.875000, valid loss: 95.787723
epoch: 4177, train precision: 0.999622, train loss: 5.334236, valid precision: 0.876000, valid loss: 95.710218
epoch: 4178, train precision: 0.999578, train loss: 5.345376, valid precision: 0.876600, valid loss: 95.332063
epoch: 4179, train precision: 0.999822, train loss: 5.281253, valid precision: 0.876600, valid loss: 97.123784
epoch: 4180, train precision: 0.999889, train loss: 5.275653, valid precision: 0.877000, valid loss: 95.778815
epoch: 4181, train precision: 0.999844, train loss: 5.272411, valid precision: 0.880400, valid loss: 96.251730
epoch: 4182, train precision: 0.999711, train loss: 5.279064, valid precision: 0.873200, valid loss: 98.610492
epoch: 4183, train precision: 0.999733, train loss: 5.287815, valid precision: 0.879000, valid loss: 96.831788
epoch: 4184, train precision: 0.999689, train loss: 5.310365, valid precision: 0.874600, valid loss: 98.476990
epoch: 4185, train precision: 0.999644, train loss: 5.312231, valid precision: 0.875800, valid loss: 101.387948
epoch: 4186, train precision: 0.999444, train loss: 5.431853, valid precision: 0.875600, valid loss: 96.640506
epoch: 4187, train precision: 0.999778, train loss: 5.268582, valid precision: 0.877800, valid loss: 97.246058
epoch: 4188, train precision: 0.999778, train loss: 5.285402, valid precision: 0.872400, valid loss: 98.770964
epoch: 4189, train precision: 0.999600, train loss: 5.312725, valid precision: 0.875400, valid loss: 98.445669
epoch: 4190, train precision: 0.999822, train loss: 5.285473, valid precision: 0.874400, valid loss: 97.480755
epoch: 4191, train precision: 0.999822, train loss: 5.271496, valid precision: 0.874400, valid loss: 97.868368
epoch: 4192, train precision: 0.999644, train loss: 5.348340, valid precision: 0.874200, valid loss: 100.601220
epoch: 4193, train precision: 0.999667, train loss: 5.312692, valid precision: 0.875400, valid loss: 98.111305
epoch: 4194, train precision: 0.999822, train loss: 5.266230, valid precision: 0.874000, valid loss: 99.873946
epoch: 4195, train precision: 0.999667, train loss: 5.323564, valid precision: 0.879400, valid loss: 94.670608
epoch: 4196, train precision: 0.999711, train loss: 5.294749, valid precision: 0.878400, valid loss: 97.658423
epoch: 4197, train precision: 0.999733, train loss: 5.309388, valid precision: 0.876600, valid loss: 100.190247
epoch: 4198, train precision: 0.999711, train loss: 5.329300, valid precision: 0.878200, valid loss: 98.995096
epoch: 4199, train precision: 0.999556, train loss: 5.388088, valid precision: 0.877600, valid loss: 97.344515
epoch: 4200, train precision: 0.999533, train loss: 5.350552, valid precision: 0.874400, valid loss: 99.126729
epoch: 4201, train precision: 0.999644, train loss: 5.328358, valid precision: 0.879400, valid loss: 97.644412
epoch: 4202, train precision: 0.999800, train loss: 5.269563, valid precision: 0.878000, valid loss: 95.698542
epoch: 4203, train precision: 0.999644, train loss: 5.306433, valid precision: 0.880800, valid loss: 96.364012
epoch: 4204, train precision: 0.999667, train loss: 5.308546, valid precision: 0.876600, valid loss: 97.884317
epoch: 4205, train precision: 0.999644, train loss: 5.330831, valid precision: 0.875200, valid loss: 96.936747
epoch: 4206, train precision: 0.999644, train loss: 5.333482, valid precision: 0.876400, valid loss: 96.348698
epoch: 4207, train precision: 0.999556, train loss: 5.330520, valid precision: 0.875400, valid loss: 99.025123
epoch: 4208, train precision: 0.999756, train loss: 5.271375, valid precision: 0.880200, valid loss: 97.588751
epoch: 4209, train precision: 0.999711, train loss: 5.297713, valid precision: 0.876200, valid loss: 97.816599
epoch: 4210, train precision: 0.999733, train loss: 5.292510, valid precision: 0.879200, valid loss: 94.049760
epoch: 4211, train precision: 0.999800, train loss: 5.296707, valid precision: 0.875800, valid loss: 95.001217
epoch: 4212, train precision: 0.999600, train loss: 5.337112, valid precision: 0.877000, valid loss: 93.987246
epoch: 4213, train precision: 0.999622, train loss: 5.296404, valid precision: 0.876600, valid loss: 97.446480
epoch: 4214, train precision: 0.999622, train loss: 5.313105, valid precision: 0.879200, valid loss: 97.979426
epoch: 4215, train precision: 0.999578, train loss: 5.344960, valid precision: 0.876600, valid loss: 98.525547
epoch: 4216, train precision: 0.999778, train loss: 5.280819, valid precision: 0.880000, valid loss: 94.776478
epoch: 4217, train precision: 0.999667, train loss: 5.324100, valid precision: 0.875800, valid loss: 96.746285
epoch: 4218, train precision: 0.999756, train loss: 5.300654, valid precision: 0.879000, valid loss: 96.239009
epoch: 4219, train precision: 0.999844, train loss: 5.270631, valid precision: 0.876200, valid loss: 95.218466
epoch: 4220, train precision: 0.999800, train loss: 5.301153, valid precision: 0.874000, valid loss: 95.781800
epoch: 4221, train precision: 0.999689, train loss: 5.267069, valid precision: 0.874600, valid loss: 97.681064
epoch: 4222, train precision: 0.999467, train loss: 5.369384, valid precision: 0.875000, valid loss: 96.405704
epoch: 4223, train precision: 0.999822, train loss: 5.278978, valid precision: 0.875200, valid loss: 97.632358
epoch: 4224, train precision: 0.999444, train loss: 5.377605, valid precision: 0.877800, valid loss: 97.825179
epoch: 4225, train precision: 0.999711, train loss: 5.311352, valid precision: 0.879200, valid loss: 99.168365
epoch: 4226, train precision: 0.999733, train loss: 5.293345, valid precision: 0.877200, valid loss: 97.695582
epoch: 4227, train precision: 0.999800, train loss: 5.289491, valid precision: 0.876400, valid loss: 96.779084
epoch: 4228, train precision: 0.999733, train loss: 5.332882, valid precision: 0.872600, valid loss: 101.437174
epoch: 4229, train precision: 0.999911, train loss: 5.267784, valid precision: 0.875200, valid loss: 98.671281
epoch: 4230, train precision: 0.999756, train loss: 5.300894, valid precision: 0.875600, valid loss: 97.081410
epoch: 4231, train precision: 0.999844, train loss: 5.281366, valid precision: 0.873600, valid loss: 98.706973
epoch: 4232, train precision: 0.999667, train loss: 5.294746, valid precision: 0.873400, valid loss: 100.140979
epoch: 4233, train precision: 0.999467, train loss: 5.367126, valid precision: 0.870600, valid loss: 100.840154
epoch: 4234, train precision: 0.999844, train loss: 5.238892, valid precision: 0.871000, valid loss: 99.746803
epoch: 4235, train precision: 0.999733, train loss: 5.297695, valid precision: 0.872400, valid loss: 98.972566
epoch: 4236, train precision: 0.999667, train loss: 5.343089, valid precision: 0.871400, valid loss: 100.925839
epoch: 4237, train precision: 0.999778, train loss: 5.281657, valid precision: 0.876400, valid loss: 99.823005
epoch: 4238, train precision: 0.999867, train loss: 5.259786, valid precision: 0.875600, valid loss: 97.261827
epoch: 4239, train precision: 0.999600, train loss: 5.336381, valid precision: 0.876000, valid loss: 95.734124
epoch: 4240, train precision: 0.999778, train loss: 5.291652, valid precision: 0.877400, valid loss: 95.910964
epoch: 4241, train precision: 0.999800, train loss: 5.308743, valid precision: 0.880400, valid loss: 96.285706
epoch: 4242, train precision: 0.999778, train loss: 5.293665, valid precision: 0.877800, valid loss: 97.703268
epoch: 4243, train precision: 0.999756, train loss: 5.281114, valid precision: 0.875600, valid loss: 97.694126
epoch: 4244, train precision: 0.999622, train loss: 5.321521, valid precision: 0.877200, valid loss: 96.439499
epoch: 4245, train precision: 0.999467, train loss: 5.355287, valid precision: 0.870000, valid loss: 99.423149
epoch: 4246, train precision: 0.999733, train loss: 5.264848, valid precision: 0.876200, valid loss: 98.223044
epoch: 4247, train precision: 0.999533, train loss: 5.356860, valid precision: 0.871400, valid loss: 101.652455
epoch: 4248, train precision: 0.999756, train loss: 5.301223, valid precision: 0.874800, valid loss: 97.271637
epoch: 4249, train precision: 0.999756, train loss: 5.296046, valid precision: 0.876200, valid loss: 96.955055
epoch: 4250, train precision: 0.999578, train loss: 5.356602, valid precision: 0.877600, valid loss: 98.111021
epoch: 4251, train precision: 0.999756, train loss: 5.275361, valid precision: 0.872400, valid loss: 100.126689
epoch: 4252, train precision: 0.999733, train loss: 5.283541, valid precision: 0.876000, valid loss: 96.635226
epoch: 4253, train precision: 0.999778, train loss: 5.281389, valid precision: 0.873400, valid loss: 99.035540
epoch: 4254, train precision: 0.999667, train loss: 5.313084, valid precision: 0.875800, valid loss: 98.804916
epoch: 4255, train precision: 0.999667, train loss: 5.311388, valid precision: 0.873600, valid loss: 96.018046
epoch: 4256, train precision: 0.999800, train loss: 5.325898, valid precision: 0.873400, valid loss: 98.039384
epoch: 4257, train precision: 0.999756, train loss: 5.294971, valid precision: 0.875800, valid loss: 95.853344
epoch: 4258, train precision: 0.999711, train loss: 5.327110, valid precision: 0.876400, valid loss: 97.118999
epoch: 4259, train precision: 0.999556, train loss: 5.317841, valid precision: 0.876600, valid loss: 99.078877
epoch: 4260, train precision: 0.999533, train loss: 5.316373, valid precision: 0.874800, valid loss: 98.272577
epoch: 4261, train precision: 0.999711, train loss: 5.293390, valid precision: 0.876400, valid loss: 96.793937
epoch: 4262, train precision: 0.999733, train loss: 5.289724, valid precision: 0.874600, valid loss: 102.066969
epoch: 4263, train precision: 0.999822, train loss: 5.274919, valid precision: 0.874000, valid loss: 97.414422
epoch: 4264, train precision: 0.999778, train loss: 5.294155, valid precision: 0.877400, valid loss: 97.808031
epoch: 4265, train precision: 0.999733, train loss: 5.308559, valid precision: 0.874800, valid loss: 100.703487
epoch: 4266, train precision: 0.999756, train loss: 5.303649, valid precision: 0.873800, valid loss: 100.716879
epoch: 4267, train precision: 0.999644, train loss: 5.349506, valid precision: 0.875000, valid loss: 101.602285
epoch: 4268, train precision: 0.999689, train loss: 5.297514, valid precision: 0.876000, valid loss: 98.699229
epoch: 4269, train precision: 0.999600, train loss: 5.359770, valid precision: 0.876800, valid loss: 101.858607
epoch: 4270, train precision: 0.999533, train loss: 5.349819, valid precision: 0.874800, valid loss: 97.924482
epoch: 4271, train precision: 0.999622, train loss: 5.326897, valid precision: 0.876800, valid loss: 99.026393
epoch: 4272, train precision: 0.999822, train loss: 5.283519, valid precision: 0.875200, valid loss: 99.581046
epoch: 4273, train precision: 0.999667, train loss: 5.308495, valid precision: 0.883000, valid loss: 97.278376
epoch: 4274, train precision: 0.999778, train loss: 5.276928, valid precision: 0.878600, valid loss: 99.060403
epoch: 4275, train precision: 0.999778, train loss: 5.268732, valid precision: 0.878200, valid loss: 99.194911
epoch: 4276, train precision: 0.999689, train loss: 5.289167, valid precision: 0.879800, valid loss: 99.491289
epoch: 4277, train precision: 0.999844, train loss: 5.273478, valid precision: 0.876600, valid loss: 102.991682
epoch: 4278, train precision: 0.999644, train loss: 5.326497, valid precision: 0.875000, valid loss: 100.609364
epoch: 4279, train precision: 0.999800, train loss: 5.256534, valid precision: 0.877000, valid loss: 99.923744
epoch: 4280, train precision: 0.999733, train loss: 5.294751, valid precision: 0.874000, valid loss: 101.485883
epoch: 4281, train precision: 0.999689, train loss: 5.311137, valid precision: 0.872400, valid loss: 102.805642
epoch: 4282, train precision: 0.999822, train loss: 5.277304, valid precision: 0.876200, valid loss: 99.770491
epoch: 4283, train precision: 0.999756, train loss: 5.293519, valid precision: 0.876200, valid loss: 98.856219
epoch: 4284, train precision: 0.999711, train loss: 5.277941, valid precision: 0.881000, valid loss: 98.528830
epoch: 4285, train precision: 0.999511, train loss: 5.329368, valid precision: 0.877000, valid loss: 99.106694
epoch: 4286, train precision: 0.999622, train loss: 5.349349, valid precision: 0.878200, valid loss: 96.109635
epoch: 4287, train precision: 0.999889, train loss: 5.261166, valid precision: 0.875600, valid loss: 98.394417
epoch: 4288, train precision: 0.999778, train loss: 5.273174, valid precision: 0.876200, valid loss: 100.770758
epoch: 4289, train precision: 0.999844, train loss: 5.249788, valid precision: 0.876400, valid loss: 101.673746
epoch: 4290, train precision: 0.999689, train loss: 5.297930, valid precision: 0.877200, valid loss: 101.659393
epoch: 4291, train precision: 0.999711, train loss: 5.296482, valid precision: 0.875200, valid loss: 99.725050
epoch: 4292, train precision: 0.999911, train loss: 5.258453, valid precision: 0.877400, valid loss: 98.378777
epoch: 4293, train precision: 0.999733, train loss: 5.302678, valid precision: 0.872400, valid loss: 101.596035
epoch: 4294, train precision: 0.999533, train loss: 5.324433, valid precision: 0.876000, valid loss: 101.503403
epoch: 4295, train precision: 0.999800, train loss: 5.290080, valid precision: 0.877600, valid loss: 99.874956
epoch: 4296, train precision: 0.999556, train loss: 5.341221, valid precision: 0.875800, valid loss: 100.101386
epoch: 4297, train precision: 0.999822, train loss: 5.271228, valid precision: 0.874600, valid loss: 98.660874
epoch: 4298, train precision: 0.999600, train loss: 5.298666, valid precision: 0.877200, valid loss: 100.056891
epoch: 4299, train precision: 0.999667, train loss: 5.361000, valid precision: 0.876800, valid loss: 99.000530
epoch: 4300, train precision: 0.999533, train loss: 5.334436, valid precision: 0.879200, valid loss: 96.728856
epoch: 4301, train precision: 0.999689, train loss: 5.320418, valid precision: 0.874800, valid loss: 98.377803
epoch: 4302, train precision: 0.999800, train loss: 5.258337, valid precision: 0.872600, valid loss: 97.623430
epoch: 4303, train precision: 0.999778, train loss: 5.296871, valid precision: 0.875400, valid loss: 100.451920
epoch: 4304, train precision: 0.999778, train loss: 5.293567, valid precision: 0.875200, valid loss: 98.849849
epoch: 4305, train precision: 0.999867, train loss: 5.279760, valid precision: 0.877800, valid loss: 97.343716
epoch: 4306, train precision: 0.999756, train loss: 5.297900, valid precision: 0.878600, valid loss: 94.501220
epoch: 4307, train precision: 0.999689, train loss: 5.296863, valid precision: 0.877000, valid loss: 95.694337
epoch: 4308, train precision: 0.999733, train loss: 5.312132, valid precision: 0.874200, valid loss: 98.925827
epoch: 4309, train precision: 0.999667, train loss: 5.314595, valid precision: 0.876200, valid loss: 99.507379
epoch: 4310, train precision: 0.999667, train loss: 5.314183, valid precision: 0.878400, valid loss: 96.307488
epoch: 4311, train precision: 0.999844, train loss: 5.258149, valid precision: 0.874600, valid loss: 98.257742
epoch: 4312, train precision: 0.999622, train loss: 5.324742, valid precision: 0.877600, valid loss: 98.867084
epoch: 4313, train precision: 0.999622, train loss: 5.301720, valid precision: 0.877400, valid loss: 95.355642
epoch: 4314, train precision: 0.999844, train loss: 5.287351, valid precision: 0.876600, valid loss: 101.634516
epoch: 4315, train precision: 0.999800, train loss: 5.264618, valid precision: 0.877400, valid loss: 98.428032
epoch: 4316, train precision: 0.999667, train loss: 5.315652, valid precision: 0.877600, valid loss: 96.516617
epoch: 4317, train precision: 0.999511, train loss: 5.357182, valid precision: 0.870400, valid loss: 99.514332
epoch: 4318, train precision: 0.999644, train loss: 5.336405, valid precision: 0.874400, valid loss: 100.588147
epoch: 4319, train precision: 0.999733, train loss: 5.279617, valid precision: 0.874600, valid loss: 98.577758
epoch: 4320, train precision: 0.999622, train loss: 5.340154, valid precision: 0.876400, valid loss: 98.186085
epoch: 4321, train precision: 0.999756, train loss: 5.321045, valid precision: 0.875200, valid loss: 100.437016
epoch: 4322, train precision: 0.999800, train loss: 5.266248, valid precision: 0.876200, valid loss: 98.405806
epoch: 4323, train precision: 0.999689, train loss: 5.321435, valid precision: 0.872600, valid loss: 97.944502
epoch: 4324, train precision: 0.999667, train loss: 5.307244, valid precision: 0.876400, valid loss: 100.341966
epoch: 4325, train precision: 0.999644, train loss: 5.337959, valid precision: 0.876600, valid loss: 100.026224
epoch: 4326, train precision: 0.999711, train loss: 5.286417, valid precision: 0.875400, valid loss: 99.160144
epoch: 4327, train precision: 0.999844, train loss: 5.275866, valid precision: 0.877400, valid loss: 98.645191
epoch: 4328, train precision: 0.999756, train loss: 5.284425, valid precision: 0.878000, valid loss: 100.073631
epoch: 4329, train precision: 0.999844, train loss: 5.292121, valid precision: 0.873000, valid loss: 100.395568
epoch: 4330, train precision: 0.999600, train loss: 5.350010, valid precision: 0.870600, valid loss: 101.484585
epoch: 4331, train precision: 0.999756, train loss: 5.285751, valid precision: 0.871000, valid loss: 101.287856
epoch: 4332, train precision: 0.999733, train loss: 5.293848, valid precision: 0.873200, valid loss: 100.720123
epoch: 4333, train precision: 0.999556, train loss: 5.328930, valid precision: 0.872400, valid loss: 101.394933
epoch: 4334, train precision: 0.999667, train loss: 5.293288, valid precision: 0.875000, valid loss: 99.122067
epoch: 4335, train precision: 0.999533, train loss: 5.346351, valid precision: 0.875200, valid loss: 100.160652
epoch: 4336, train precision: 0.999756, train loss: 5.291239, valid precision: 0.873800, valid loss: 100.557869
epoch: 4337, train precision: 0.999667, train loss: 5.315292, valid precision: 0.872600, valid loss: 99.632648
epoch: 4338, train precision: 0.999800, train loss: 5.266937, valid precision: 0.873000, valid loss: 100.817072
epoch: 4339, train precision: 0.999622, train loss: 5.345082, valid precision: 0.872200, valid loss: 102.399403
epoch: 4340, train precision: 0.999711, train loss: 5.295016, valid precision: 0.873400, valid loss: 100.315312
epoch: 4341, train precision: 0.999600, train loss: 5.308199, valid precision: 0.875600, valid loss: 99.748278
epoch: 4342, train precision: 0.999667, train loss: 5.312268, valid precision: 0.875000, valid loss: 98.978561
epoch: 4343, train precision: 0.999689, train loss: 5.265403, valid precision: 0.875000, valid loss: 99.390958
epoch: 4344, train precision: 0.999800, train loss: 5.266782, valid precision: 0.874800, valid loss: 100.575201
epoch: 4345, train precision: 0.999667, train loss: 5.330242, valid precision: 0.873600, valid loss: 99.591216
epoch: 4346, train precision: 0.999756, train loss: 5.294679, valid precision: 0.877200, valid loss: 98.389217
epoch: 4347, train precision: 0.999844, train loss: 5.259715, valid precision: 0.877600, valid loss: 98.328883
epoch: 4348, train precision: 0.999600, train loss: 5.301029, valid precision: 0.875200, valid loss: 101.060270
epoch: 4349, train precision: 0.999822, train loss: 5.258686, valid precision: 0.875200, valid loss: 97.614606
epoch: 4350, train precision: 0.999733, train loss: 5.281026, valid precision: 0.875600, valid loss: 99.000710
epoch: 4351, train precision: 0.999844, train loss: 5.257189, valid precision: 0.876000, valid loss: 99.233796
epoch: 4352, train precision: 0.999844, train loss: 5.258345, valid precision: 0.873200, valid loss: 100.287482
epoch: 4353, train precision: 0.999644, train loss: 5.309097, valid precision: 0.872800, valid loss: 102.601036
epoch: 4354, train precision: 0.999689, train loss: 5.329111, valid precision: 0.873200, valid loss: 101.452675
epoch: 4355, train precision: 0.999889, train loss: 5.253884, valid precision: 0.875200, valid loss: 98.416928
epoch: 4356, train precision: 0.999800, train loss: 5.279774, valid precision: 0.875600, valid loss: 100.877268
epoch: 4357, train precision: 0.999644, train loss: 5.356376, valid precision: 0.872400, valid loss: 99.976086
epoch: 4358, train precision: 0.999711, train loss: 5.307120, valid precision: 0.878000, valid loss: 100.098558
epoch: 4359, train precision: 0.999667, train loss: 5.320435, valid precision: 0.876200, valid loss: 98.409548
epoch: 4360, train precision: 0.999689, train loss: 5.317929, valid precision: 0.874600, valid loss: 97.772524
epoch: 4361, train precision: 0.999711, train loss: 5.282291, valid precision: 0.876200, valid loss: 97.660332
epoch: 4362, train precision: 0.999822, train loss: 5.276475, valid precision: 0.874200, valid loss: 98.258525
epoch: 4363, train precision: 0.999667, train loss: 5.292023, valid precision: 0.874000, valid loss: 98.892160
epoch: 4364, train precision: 0.999778, train loss: 5.268618, valid precision: 0.877200, valid loss: 94.934759
epoch: 4365, train precision: 0.999533, train loss: 5.327041, valid precision: 0.872600, valid loss: 96.142315
epoch: 4366, train precision: 0.999800, train loss: 5.280992, valid precision: 0.879600, valid loss: 96.125965
epoch: 4367, train precision: 0.999533, train loss: 5.332483, valid precision: 0.878600, valid loss: 98.193776
epoch: 4368, train precision: 0.999733, train loss: 5.279064, valid precision: 0.877600, valid loss: 97.660320
epoch: 4369, train precision: 0.999578, train loss: 5.303249, valid precision: 0.874800, valid loss: 100.423871
epoch: 4370, train precision: 0.999600, train loss: 5.311993, valid precision: 0.873000, valid loss: 103.111940
epoch: 4371, train precision: 0.999711, train loss: 5.283944, valid precision: 0.876000, valid loss: 99.045794
epoch: 4372, train precision: 0.999844, train loss: 5.255245, valid precision: 0.875000, valid loss: 100.861262
epoch: 4373, train precision: 0.999733, train loss: 5.305860, valid precision: 0.877600, valid loss: 99.937854
epoch: 4374, train precision: 0.999756, train loss: 5.277774, valid precision: 0.876000, valid loss: 101.296799
epoch: 4375, train precision: 0.999733, train loss: 5.291923, valid precision: 0.877400, valid loss: 99.553210
epoch: 4376, train precision: 0.999867, train loss: 5.244322, valid precision: 0.875600, valid loss: 101.704920
epoch: 4377, train precision: 0.999644, train loss: 5.335141, valid precision: 0.877400, valid loss: 99.747954
epoch: 4378, train precision: 0.999689, train loss: 5.310388, valid precision: 0.874800, valid loss: 100.025384
epoch: 4379, train precision: 0.999622, train loss: 5.312821, valid precision: 0.876600, valid loss: 98.308919
epoch: 4380, train precision: 0.999644, train loss: 5.304388, valid precision: 0.874600, valid loss: 98.572775
epoch: 4381, train precision: 0.999822, train loss: 5.257892, valid precision: 0.877600, valid loss: 98.083652
epoch: 4382, train precision: 0.999733, train loss: 5.309318, valid precision: 0.877600, valid loss: 99.313537
epoch: 4383, train precision: 0.999644, train loss: 5.322165, valid precision: 0.876400, valid loss: 98.236309
epoch: 4384, train precision: 0.999222, train loss: 5.425324, valid precision: 0.874200, valid loss: 101.543055
epoch: 4385, train precision: 0.999689, train loss: 5.307171, valid precision: 0.878000, valid loss: 98.752234
epoch: 4386, train precision: 0.999889, train loss: 5.243039, valid precision: 0.874600, valid loss: 101.227485
epoch: 4387, train precision: 0.999622, train loss: 5.319245, valid precision: 0.875400, valid loss: 99.017948
epoch: 4388, train precision: 0.999489, train loss: 5.366066, valid precision: 0.874600, valid loss: 102.755730
epoch: 4389, train precision: 0.999867, train loss: 5.257556, valid precision: 0.871800, valid loss: 99.069218
epoch: 4390, train precision: 0.999578, train loss: 5.283750, valid precision: 0.878400, valid loss: 97.594531
epoch: 4391, train precision: 0.999644, train loss: 5.314744, valid precision: 0.877000, valid loss: 98.489146
epoch: 4392, train precision: 0.999622, train loss: 5.330475, valid precision: 0.877000, valid loss: 98.113930
epoch: 4393, train precision: 0.999711, train loss: 5.284602, valid precision: 0.877800, valid loss: 97.761652
epoch: 4394, train precision: 0.999733, train loss: 5.291553, valid precision: 0.877600, valid loss: 97.233919
epoch: 4395, train precision: 0.999756, train loss: 5.272720, valid precision: 0.876200, valid loss: 99.368356
epoch: 4396, train precision: 0.999667, train loss: 5.301467, valid precision: 0.872400, valid loss: 98.327139
epoch: 4397, train precision: 0.999756, train loss: 5.243303, valid precision: 0.871600, valid loss: 101.042600
epoch: 4398, train precision: 0.999844, train loss: 5.243774, valid precision: 0.876400, valid loss: 99.759212
epoch: 4399, train precision: 0.999844, train loss: 5.265574, valid precision: 0.876200, valid loss: 98.610032
epoch: 4400, train precision: 0.999533, train loss: 5.330341, valid precision: 0.872000, valid loss: 103.454410
epoch: 4401, train precision: 0.999822, train loss: 5.259545, valid precision: 0.872000, valid loss: 99.950006
epoch: 4402, train precision: 0.999711, train loss: 5.263586, valid precision: 0.875200, valid loss: 100.405457
epoch: 4403, train precision: 0.999711, train loss: 5.278528, valid precision: 0.872400, valid loss: 103.631523
epoch: 4404, train precision: 0.999711, train loss: 5.279150, valid precision: 0.871200, valid loss: 99.783261
epoch: 4405, train precision: 0.999711, train loss: 5.278872, valid precision: 0.871400, valid loss: 99.132251
epoch: 4406, train precision: 0.999733, train loss: 5.305852, valid precision: 0.872600, valid loss: 101.828278
epoch: 4407, train precision: 0.999733, train loss: 5.293890, valid precision: 0.871600, valid loss: 102.013860
epoch: 4408, train precision: 0.999667, train loss: 5.314614, valid precision: 0.870400, valid loss: 102.992220
epoch: 4409, train precision: 0.999711, train loss: 5.279601, valid precision: 0.872600, valid loss: 102.431916
epoch: 4410, train precision: 0.999356, train loss: 5.416719, valid precision: 0.871200, valid loss: 102.300545
epoch: 4411, train precision: 0.999578, train loss: 5.305441, valid precision: 0.874000, valid loss: 101.648741
epoch: 4412, train precision: 0.999533, train loss: 5.380131, valid precision: 0.870400, valid loss: 103.047938
epoch: 4413, train precision: 0.999622, train loss: 5.283578, valid precision: 0.873400, valid loss: 100.773196
epoch: 4414, train precision: 0.999800, train loss: 5.275981, valid precision: 0.875400, valid loss: 98.065640
epoch: 4415, train precision: 0.999578, train loss: 5.315592, valid precision: 0.872600, valid loss: 101.028912
epoch: 4416, train precision: 0.999756, train loss: 5.277919, valid precision: 0.872000, valid loss: 100.882572
epoch: 4417, train precision: 0.999511, train loss: 5.339192, valid precision: 0.873200, valid loss: 102.668493
epoch: 4418, train precision: 0.999867, train loss: 5.226120, valid precision: 0.873000, valid loss: 100.427180
epoch: 4419, train precision: 0.999556, train loss: 5.332905, valid precision: 0.872600, valid loss: 100.791195
epoch: 4420, train precision: 0.999711, train loss: 5.270330, valid precision: 0.870600, valid loss: 100.947950
epoch: 4421, train precision: 0.999867, train loss: 5.248882, valid precision: 0.871800, valid loss: 97.788893
epoch: 4422, train precision: 0.999844, train loss: 5.256081, valid precision: 0.878800, valid loss: 97.888992
epoch: 4423, train precision: 0.999644, train loss: 5.300647, valid precision: 0.870800, valid loss: 102.254795
epoch: 4424, train precision: 0.999622, train loss: 5.310406, valid precision: 0.871800, valid loss: 101.048449
epoch: 4425, train precision: 0.999711, train loss: 5.299748, valid precision: 0.875000, valid loss: 98.815236
epoch: 4426, train precision: 0.999733, train loss: 5.257445, valid precision: 0.872600, valid loss: 99.146864
epoch: 4427, train precision: 0.999689, train loss: 5.308786, valid precision: 0.872000, valid loss: 103.191028
epoch: 4428, train precision: 0.999711, train loss: 5.279971, valid precision: 0.873400, valid loss: 97.608286
epoch: 4429, train precision: 0.999822, train loss: 5.235162, valid precision: 0.874000, valid loss: 99.582574
epoch: 4430, train precision: 0.999733, train loss: 5.273654, valid precision: 0.877000, valid loss: 98.328027
epoch: 4431, train precision: 0.999800, train loss: 5.257720, valid precision: 0.877200, valid loss: 97.195346
epoch: 4432, train precision: 0.999800, train loss: 5.232956, valid precision: 0.875200, valid loss: 98.880678
epoch: 4433, train precision: 0.999689, train loss: 5.275331, valid precision: 0.874400, valid loss: 99.087092
epoch: 4434, train precision: 0.999778, train loss: 5.261169, valid precision: 0.874200, valid loss: 97.486620
epoch: 4435, train precision: 0.999756, train loss: 5.274356, valid precision: 0.873200, valid loss: 99.825092
epoch: 4436, train precision: 0.999622, train loss: 5.295501, valid precision: 0.875600, valid loss: 103.724417
epoch: 4437, train precision: 0.999711, train loss: 5.306828, valid precision: 0.872600, valid loss: 100.673028
epoch: 4438, train precision: 0.999644, train loss: 5.344696, valid precision: 0.876800, valid loss: 96.475933
epoch: 4439, train precision: 0.999711, train loss: 5.274543, valid precision: 0.873400, valid loss: 100.085541
epoch: 4440, train precision: 0.999622, train loss: 5.308537, valid precision: 0.875800, valid loss: 95.083628
epoch: 4441, train precision: 0.999511, train loss: 5.406506, valid precision: 0.876800, valid loss: 92.433364
epoch: 4442, train precision: 0.999800, train loss: 5.270677, valid precision: 0.876600, valid loss: 95.351555
epoch: 4443, train precision: 0.999644, train loss: 5.309550, valid precision: 0.876000, valid loss: 98.140629
epoch: 4444, train precision: 0.999600, train loss: 5.310835, valid precision: 0.874600, valid loss: 99.983942
epoch: 4445, train precision: 0.999644, train loss: 5.270927, valid precision: 0.876000, valid loss: 97.301577
epoch: 4446, train precision: 0.999733, train loss: 5.293490, valid precision: 0.876600, valid loss: 96.931426
epoch: 4447, train precision: 0.999800, train loss: 5.251872, valid precision: 0.876800, valid loss: 98.697138
epoch: 4448, train precision: 0.999689, train loss: 5.316867, valid precision: 0.876600, valid loss: 99.526985
epoch: 4449, train precision: 0.999844, train loss: 5.253610, valid precision: 0.876400, valid loss: 99.753484
epoch: 4450, train precision: 0.999711, train loss: 5.285979, valid precision: 0.877200, valid loss: 96.132975
epoch: 4451, train precision: 0.999756, train loss: 5.245826, valid precision: 0.877200, valid loss: 100.176670
epoch: 4452, train precision: 0.999711, train loss: 5.261981, valid precision: 0.877400, valid loss: 95.493248
epoch: 4453, train precision: 0.999822, train loss: 5.266012, valid precision: 0.878600, valid loss: 94.656763
epoch: 4454, train precision: 0.999756, train loss: 5.304646, valid precision: 0.874800, valid loss: 97.071142
epoch: 4455, train precision: 0.999600, train loss: 5.271860, valid precision: 0.878800, valid loss: 96.178983
epoch: 4456, train precision: 0.999844, train loss: 5.246949, valid precision: 0.878400, valid loss: 98.984037
epoch: 4457, train precision: 0.999844, train loss: 5.274923, valid precision: 0.874000, valid loss: 99.157257
epoch: 4458, train precision: 0.999644, train loss: 5.279290, valid precision: 0.878400, valid loss: 97.171204
epoch: 4459, train precision: 0.999733, train loss: 5.305545, valid precision: 0.871600, valid loss: 99.443468
epoch: 4460, train precision: 0.999778, train loss: 5.273922, valid precision: 0.874600, valid loss: 99.420987
epoch: 4461, train precision: 0.999444, train loss: 5.366333, valid precision: 0.872400, valid loss: 102.683325
epoch: 4462, train precision: 0.999667, train loss: 5.314646, valid precision: 0.877800, valid loss: 101.877932
epoch: 4463, train precision: 0.999822, train loss: 5.273136, valid precision: 0.875600, valid loss: 100.064572
epoch: 4464, train precision: 0.999822, train loss: 5.260337, valid precision: 0.877000, valid loss: 101.144058
epoch: 4465, train precision: 0.999533, train loss: 5.316233, valid precision: 0.874600, valid loss: 99.903672
epoch: 4466, train precision: 0.999711, train loss: 5.284350, valid precision: 0.876600, valid loss: 98.955500
epoch: 4467, train precision: 0.999778, train loss: 5.256436, valid precision: 0.872600, valid loss: 101.239149
epoch: 4468, train precision: 0.999733, train loss: 5.265188, valid precision: 0.872800, valid loss: 100.695975
epoch: 4469, train precision: 0.999822, train loss: 5.267769, valid precision: 0.868200, valid loss: 103.431613
epoch: 4470, train precision: 0.999778, train loss: 5.257285, valid precision: 0.872200, valid loss: 101.371899
epoch: 4471, train precision: 0.999778, train loss: 5.248100, valid precision: 0.871800, valid loss: 101.301757
epoch: 4472, train precision: 0.999711, train loss: 5.274781, valid precision: 0.873800, valid loss: 99.961192
epoch: 4473, train precision: 0.999822, train loss: 5.255813, valid precision: 0.873200, valid loss: 103.161150
epoch: 4474, train precision: 0.999756, train loss: 5.279133, valid precision: 0.871600, valid loss: 101.489840
epoch: 4475, train precision: 0.999711, train loss: 5.267901, valid precision: 0.872200, valid loss: 102.008179
epoch: 4476, train precision: 0.999667, train loss: 5.304861, valid precision: 0.872000, valid loss: 101.290773
epoch: 4477, train precision: 0.999667, train loss: 5.305222, valid precision: 0.873800, valid loss: 100.973296
epoch: 4478, train precision: 0.999689, train loss: 5.287518, valid precision: 0.873600, valid loss: 100.329221
epoch: 4479, train precision: 0.999689, train loss: 5.265509, valid precision: 0.872000, valid loss: 101.657255
epoch: 4480, train precision: 0.999756, train loss: 5.245335, valid precision: 0.876400, valid loss: 100.505023
epoch: 4481, train precision: 0.999444, train loss: 5.352702, valid precision: 0.873600, valid loss: 101.938760
epoch: 4482, train precision: 0.999800, train loss: 5.251886, valid precision: 0.873800, valid loss: 104.275315
epoch: 4483, train precision: 0.999756, train loss: 5.291516, valid precision: 0.873600, valid loss: 101.731888
epoch: 4484, train precision: 0.999733, train loss: 5.254518, valid precision: 0.877200, valid loss: 101.932988
epoch: 4485, train precision: 0.999556, train loss: 5.320874, valid precision: 0.874800, valid loss: 99.329816
epoch: 4486, train precision: 0.999822, train loss: 5.281182, valid precision: 0.871800, valid loss: 101.665404
epoch: 4487, train precision: 0.999578, train loss: 5.340014, valid precision: 0.873400, valid loss: 101.062154
epoch: 4488, train precision: 0.999800, train loss: 5.281855, valid precision: 0.870400, valid loss: 102.008124
epoch: 4489, train precision: 0.999533, train loss: 5.333514, valid precision: 0.873400, valid loss: 101.652252
epoch: 4490, train precision: 0.999600, train loss: 5.309300, valid precision: 0.870600, valid loss: 100.342973
epoch: 4491, train precision: 0.999511, train loss: 5.338189, valid precision: 0.873600, valid loss: 99.237023
epoch: 4492, train precision: 0.999889, train loss: 5.249029, valid precision: 0.874000, valid loss: 105.788974
epoch: 4493, train precision: 0.999644, train loss: 5.271626, valid precision: 0.874600, valid loss: 102.030154
epoch: 4494, train precision: 0.999622, train loss: 5.271725, valid precision: 0.871400, valid loss: 104.677922
epoch: 4495, train precision: 0.999644, train loss: 5.282948, valid precision: 0.873800, valid loss: 103.100493
epoch: 4496, train precision: 0.999800, train loss: 5.259960, valid precision: 0.872800, valid loss: 103.269725
epoch: 4497, train precision: 0.999689, train loss: 5.299173, valid precision: 0.875000, valid loss: 102.983114
epoch: 4498, train precision: 0.999778, train loss: 5.259490, valid precision: 0.873000, valid loss: 102.914604
epoch: 4499, train precision: 0.999667, train loss: 5.312310, valid precision: 0.875000, valid loss: 104.137213
epoch: 4500, train precision: 0.999689, train loss: 5.280069, valid precision: 0.874400, valid loss: 102.404756
epoch: 4501, train precision: 0.999689, train loss: 5.284108, valid precision: 0.872000, valid loss: 101.728773
epoch: 4502, train precision: 0.999756, train loss: 5.267548, valid precision: 0.873800, valid loss: 104.363337
epoch: 4503, train precision: 0.999689, train loss: 5.257641, valid precision: 0.873600, valid loss: 100.442214
epoch: 4504, train precision: 0.999689, train loss: 5.285340, valid precision: 0.872600, valid loss: 100.953437
epoch: 4505, train precision: 0.999644, train loss: 5.290351, valid precision: 0.873800, valid loss: 103.087230
epoch: 4506, train precision: 0.999711, train loss: 5.272997, valid precision: 0.874200, valid loss: 101.080068
epoch: 4507, train precision: 0.999733, train loss: 5.258932, valid precision: 0.877600, valid loss: 98.818961
epoch: 4508, train precision: 0.999533, train loss: 5.322954, valid precision: 0.873400, valid loss: 100.071602
epoch: 4509, train precision: 0.999889, train loss: 5.243674, valid precision: 0.873000, valid loss: 99.711186
epoch: 4510, train precision: 0.999689, train loss: 5.272661, valid precision: 0.875800, valid loss: 97.288675
epoch: 4511, train precision: 0.999711, train loss: 5.263799, valid precision: 0.877800, valid loss: 98.247261
epoch: 4512, train precision: 0.999733, train loss: 5.277050, valid precision: 0.871200, valid loss: 99.046423
epoch: 4513, train precision: 0.999711, train loss: 5.284902, valid precision: 0.875400, valid loss: 97.726897
epoch: 4514, train precision: 0.999467, train loss: 5.336863, valid precision: 0.876200, valid loss: 99.936941
epoch: 4515, train precision: 0.999400, train loss: 5.346839, valid precision: 0.871800, valid loss: 101.340825
epoch: 4516, train precision: 0.999822, train loss: 5.244788, valid precision: 0.874400, valid loss: 97.152949
epoch: 4517, train precision: 0.999822, train loss: 5.243822, valid precision: 0.872000, valid loss: 100.003150
epoch: 4518, train precision: 0.999778, train loss: 5.267382, valid precision: 0.874600, valid loss: 101.515266
epoch: 4519, train precision: 0.999711, train loss: 5.264993, valid precision: 0.871000, valid loss: 100.537971
epoch: 4520, train precision: 0.999756, train loss: 5.287144, valid precision: 0.875600, valid loss: 98.201899
epoch: 4521, train precision: 0.999733, train loss: 5.264624, valid precision: 0.874600, valid loss: 97.888649
epoch: 4522, train precision: 0.999867, train loss: 5.229411, valid precision: 0.873600, valid loss: 96.945297
epoch: 4523, train precision: 0.999533, train loss: 5.336847, valid precision: 0.873600, valid loss: 99.780859
epoch: 4524, train precision: 0.999800, train loss: 5.234814, valid precision: 0.877400, valid loss: 98.573807
epoch: 4525, train precision: 0.999689, train loss: 5.288251, valid precision: 0.876000, valid loss: 96.961286
epoch: 4526, train precision: 0.999644, train loss: 5.292762, valid precision: 0.874400, valid loss: 100.277945
epoch: 4527, train precision: 0.999800, train loss: 5.239003, valid precision: 0.873400, valid loss: 100.350433
epoch: 4528, train precision: 0.999689, train loss: 5.291988, valid precision: 0.874400, valid loss: 98.508814
epoch: 4529, train precision: 0.999867, train loss: 5.241883, valid precision: 0.872600, valid loss: 98.821276
epoch: 4530, train precision: 0.999756, train loss: 5.277308, valid precision: 0.872000, valid loss: 100.719218
epoch: 4531, train precision: 0.999867, train loss: 5.228047, valid precision: 0.875600, valid loss: 98.534168
epoch: 4532, train precision: 0.999778, train loss: 5.274630, valid precision: 0.873200, valid loss: 99.199356
epoch: 4533, train precision: 0.999689, train loss: 5.274176, valid precision: 0.873200, valid loss: 101.673721
epoch: 4534, train precision: 0.999733, train loss: 5.268019, valid precision: 0.876800, valid loss: 98.239061
epoch: 4535, train precision: 0.999778, train loss: 5.238964, valid precision: 0.876200, valid loss: 102.388062
epoch: 4536, train precision: 0.999822, train loss: 5.246836, valid precision: 0.876000, valid loss: 98.214300
epoch: 4537, train precision: 0.999689, train loss: 5.260718, valid precision: 0.872800, valid loss: 102.101056
epoch: 4538, train precision: 0.999756, train loss: 5.268533, valid precision: 0.875000, valid loss: 98.537705
epoch: 4539, train precision: 0.999556, train loss: 5.316785, valid precision: 0.871600, valid loss: 104.007090
epoch: 4540, train precision: 0.999822, train loss: 5.236281, valid precision: 0.875200, valid loss: 100.593151
epoch: 4541, train precision: 0.999689, train loss: 5.250730, valid precision: 0.877400, valid loss: 99.400893
epoch: 4542, train precision: 0.999622, train loss: 5.269102, valid precision: 0.871800, valid loss: 101.853462
epoch: 4543, train precision: 0.999711, train loss: 5.284925, valid precision: 0.872200, valid loss: 99.982467
epoch: 4544, train precision: 0.999778, train loss: 5.255797, valid precision: 0.874800, valid loss: 98.330498
epoch: 4545, train precision: 0.999689, train loss: 5.246626, valid precision: 0.875200, valid loss: 101.440577
epoch: 4546, train precision: 0.999689, train loss: 5.237349, valid precision: 0.879400, valid loss: 98.254673
epoch: 4547, train precision: 0.999822, train loss: 5.233228, valid precision: 0.874400, valid loss: 99.854717
epoch: 4548, train precision: 0.999889, train loss: 5.237994, valid precision: 0.872200, valid loss: 98.656865
epoch: 4549, train precision: 0.999778, train loss: 5.249328, valid precision: 0.871200, valid loss: 100.665726
epoch: 4550, train precision: 0.999600, train loss: 5.271253, valid precision: 0.873600, valid loss: 98.049603
epoch: 4551, train precision: 0.999778, train loss: 5.240255, valid precision: 0.874800, valid loss: 100.665607
epoch: 4552, train precision: 0.999667, train loss: 5.279020, valid precision: 0.870600, valid loss: 99.345401
epoch: 4553, train precision: 0.999756, train loss: 5.294490, valid precision: 0.872200, valid loss: 104.179135
epoch: 4554, train precision: 0.999578, train loss: 5.303658, valid precision: 0.876000, valid loss: 100.092569
epoch: 4555, train precision: 0.999867, train loss: 5.239965, valid precision: 0.877600, valid loss: 100.137221
epoch: 4556, train precision: 0.999756, train loss: 5.273325, valid precision: 0.875400, valid loss: 101.206209
epoch: 4557, train precision: 0.999733, train loss: 5.263575, valid precision: 0.875400, valid loss: 100.433820
epoch: 4558, train precision: 0.999756, train loss: 5.243556, valid precision: 0.875000, valid loss: 98.757715
epoch: 4559, train precision: 0.999822, train loss: 5.239544, valid precision: 0.875600, valid loss: 98.434702
epoch: 4560, train precision: 0.999667, train loss: 5.305384, valid precision: 0.872400, valid loss: 101.382238
epoch: 4561, train precision: 0.999689, train loss: 5.268763, valid precision: 0.872400, valid loss: 99.961144
epoch: 4562, train precision: 0.999689, train loss: 5.264380, valid precision: 0.873600, valid loss: 102.327646
epoch: 4563, train precision: 0.999733, train loss: 5.283711, valid precision: 0.875600, valid loss: 100.989139
epoch: 4564, train precision: 0.999889, train loss: 5.261379, valid precision: 0.869400, valid loss: 101.452078
epoch: 4565, train precision: 0.999622, train loss: 5.328972, valid precision: 0.869400, valid loss: 101.688055
epoch: 4566, train precision: 0.999711, train loss: 5.281553, valid precision: 0.877800, valid loss: 99.634944
epoch: 4567, train precision: 0.999533, train loss: 5.362892, valid precision: 0.874600, valid loss: 100.688366
epoch: 4568, train precision: 0.999511, train loss: 5.285892, valid precision: 0.875800, valid loss: 100.870381
epoch: 4569, train precision: 0.999733, train loss: 5.267252, valid precision: 0.871600, valid loss: 101.383946
epoch: 4570, train precision: 0.999578, train loss: 5.325465, valid precision: 0.874400, valid loss: 103.823996
epoch: 4571, train precision: 0.999822, train loss: 5.230161, valid precision: 0.872200, valid loss: 101.854744
epoch: 4572, train precision: 0.999689, train loss: 5.312594, valid precision: 0.876800, valid loss: 100.682556
epoch: 4573, train precision: 0.999689, train loss: 5.279116, valid precision: 0.872000, valid loss: 99.161619
epoch: 4574, train precision: 0.999733, train loss: 5.229780, valid precision: 0.876200, valid loss: 99.426404
epoch: 4575, train precision: 0.999800, train loss: 5.268169, valid precision: 0.876600, valid loss: 99.793509
epoch: 4576, train precision: 0.999756, train loss: 5.261031, valid precision: 0.870400, valid loss: 100.748074
epoch: 4577, train precision: 0.999800, train loss: 5.250744, valid precision: 0.873800, valid loss: 100.809923
epoch: 4578, train precision: 0.999867, train loss: 5.240633, valid precision: 0.872400, valid loss: 103.184599
epoch: 4579, train precision: 0.999933, train loss: 5.201337, valid precision: 0.873400, valid loss: 100.486582
epoch: 4580, train precision: 0.999822, train loss: 5.245479, valid precision: 0.877600, valid loss: 100.355576
epoch: 4581, train precision: 0.999467, train loss: 5.353162, valid precision: 0.875400, valid loss: 98.943268
epoch: 4582, train precision: 0.999711, train loss: 5.264309, valid precision: 0.874200, valid loss: 104.031993
epoch: 4583, train precision: 0.999689, train loss: 5.293311, valid precision: 0.873400, valid loss: 102.940968
epoch: 4584, train precision: 0.999800, train loss: 5.250955, valid precision: 0.875800, valid loss: 100.995894
epoch: 4585, train precision: 0.999644, train loss: 5.255633, valid precision: 0.874200, valid loss: 100.427592
epoch: 4586, train precision: 0.999733, train loss: 5.275743, valid precision: 0.873600, valid loss: 102.317716
epoch: 4587, train precision: 0.999600, train loss: 5.322114, valid precision: 0.872600, valid loss: 100.625049
epoch: 4588, train precision: 0.999733, train loss: 5.267782, valid precision: 0.873200, valid loss: 101.365750
epoch: 4589, train precision: 0.999711, train loss: 5.265991, valid precision: 0.876000, valid loss: 95.937778
epoch: 4590, train precision: 0.999689, train loss: 5.256061, valid precision: 0.875200, valid loss: 96.424503
epoch: 4591, train precision: 0.999822, train loss: 5.235860, valid precision: 0.877000, valid loss: 97.982839
epoch: 4592, train precision: 0.999778, train loss: 5.278302, valid precision: 0.874400, valid loss: 96.767021
epoch: 4593, train precision: 0.999800, train loss: 5.261244, valid precision: 0.876800, valid loss: 97.702389
epoch: 4594, train precision: 0.999844, train loss: 5.253373, valid precision: 0.875200, valid loss: 98.014859
epoch: 4595, train precision: 0.999711, train loss: 5.283845, valid precision: 0.872600, valid loss: 100.000091
epoch: 4596, train precision: 0.999600, train loss: 5.292687, valid precision: 0.874400, valid loss: 98.662377
epoch: 4597, train precision: 0.999867, train loss: 5.244416, valid precision: 0.876000, valid loss: 100.517476
epoch: 4598, train precision: 0.999689, train loss: 5.300207, valid precision: 0.875400, valid loss: 99.443367
epoch: 4599, train precision: 0.999667, train loss: 5.286983, valid precision: 0.873200, valid loss: 101.734231
epoch: 4600, train precision: 0.999778, train loss: 5.265351, valid precision: 0.874400, valid loss: 102.112258
epoch: 4601, train precision: 0.999800, train loss: 5.233353, valid precision: 0.878000, valid loss: 99.180987
epoch: 4602, train precision: 0.999689, train loss: 5.292391, valid precision: 0.872800, valid loss: 100.160189
epoch: 4603, train precision: 0.999778, train loss: 5.267603, valid precision: 0.875600, valid loss: 100.062160
epoch: 4604, train precision: 0.999800, train loss: 5.212178, valid precision: 0.876800, valid loss: 101.068515
epoch: 4605, train precision: 0.999867, train loss: 5.215493, valid precision: 0.878200, valid loss: 99.414176
epoch: 4606, train precision: 0.999911, train loss: 5.199732, valid precision: 0.875800, valid loss: 96.228202
epoch: 4607, train precision: 0.999822, train loss: 5.237882, valid precision: 0.876600, valid loss: 98.089601
epoch: 4608, train precision: 0.999711, train loss: 5.276025, valid precision: 0.872000, valid loss: 102.193363
epoch: 4609, train precision: 0.999622, train loss: 5.291637, valid precision: 0.875400, valid loss: 102.014916
epoch: 4610, train precision: 0.999711, train loss: 5.262034, valid precision: 0.873400, valid loss: 101.809504
epoch: 4611, train precision: 0.999867, train loss: 5.232597, valid precision: 0.875000, valid loss: 100.645599
epoch: 4612, train precision: 0.999511, train loss: 5.335940, valid precision: 0.871600, valid loss: 101.881782
epoch: 4613, train precision: 0.999711, train loss: 5.271545, valid precision: 0.875200, valid loss: 103.999431
epoch: 4614, train precision: 0.999689, train loss: 5.250341, valid precision: 0.875000, valid loss: 101.625885
epoch: 4615, train precision: 0.999867, train loss: 5.231123, valid precision: 0.874800, valid loss: 101.608715
epoch: 4616, train precision: 0.999778, train loss: 5.237385, valid precision: 0.871600, valid loss: 101.934707
epoch: 4617, train precision: 0.999756, train loss: 5.230436, valid precision: 0.873800, valid loss: 102.060248
epoch: 4618, train precision: 0.999844, train loss: 5.224938, valid precision: 0.873400, valid loss: 104.519229
epoch: 4619, train precision: 0.999600, train loss: 5.285324, valid precision: 0.871200, valid loss: 104.789998
epoch: 4620, train precision: 0.999733, train loss: 5.259049, valid precision: 0.872200, valid loss: 103.940043
epoch: 4621, train precision: 0.999822, train loss: 5.228990, valid precision: 0.873000, valid loss: 102.031282
epoch: 4622, train precision: 0.999756, train loss: 5.237281, valid precision: 0.873200, valid loss: 98.687448
epoch: 4623, train precision: 0.999756, train loss: 5.217290, valid precision: 0.871600, valid loss: 100.027885
epoch: 4624, train precision: 0.999800, train loss: 5.236538, valid precision: 0.874400, valid loss: 98.533695
epoch: 4625, train precision: 0.999822, train loss: 5.222742, valid precision: 0.873200, valid loss: 98.555503
epoch: 4626, train precision: 0.999867, train loss: 5.234270, valid precision: 0.874200, valid loss: 100.763480
epoch: 4627, train precision: 0.999711, train loss: 5.247509, valid precision: 0.872600, valid loss: 99.125037
epoch: 4628, train precision: 0.999844, train loss: 5.239444, valid precision: 0.871000, valid loss: 101.683106
epoch: 4629, train precision: 0.999778, train loss: 5.248011, valid precision: 0.872000, valid loss: 98.646410
epoch: 4630, train precision: 0.999822, train loss: 5.238999, valid precision: 0.874800, valid loss: 97.213034
epoch: 4631, train precision: 0.999622, train loss: 5.259774, valid precision: 0.874600, valid loss: 99.135508
epoch: 4632, train precision: 0.999600, train loss: 5.302678, valid precision: 0.871000, valid loss: 100.514963
epoch: 4633, train precision: 0.999644, train loss: 5.276921, valid precision: 0.875200, valid loss: 99.836325
epoch: 4634, train precision: 0.999822, train loss: 5.212716, valid precision: 0.876800, valid loss: 99.346695
epoch: 4635, train precision: 0.999711, train loss: 5.270430, valid precision: 0.874400, valid loss: 98.693684
epoch: 4636, train precision: 0.999667, train loss: 5.293164, valid precision: 0.875200, valid loss: 97.368689
epoch: 4637, train precision: 0.999822, train loss: 5.235880, valid precision: 0.871200, valid loss: 97.950088
epoch: 4638, train precision: 0.999644, train loss: 5.280886, valid precision: 0.873400, valid loss: 100.173592
epoch: 4639, train precision: 0.999800, train loss: 5.222806, valid precision: 0.871600, valid loss: 99.023649
epoch: 4640, train precision: 0.999533, train loss: 5.284601, valid precision: 0.874800, valid loss: 99.888322
epoch: 4641, train precision: 0.999733, train loss: 5.269144, valid precision: 0.875200, valid loss: 97.701751
epoch: 4642, train precision: 0.999689, train loss: 5.263522, valid precision: 0.875600, valid loss: 99.962175
epoch: 4643, train precision: 0.999778, train loss: 5.247196, valid precision: 0.876000, valid loss: 98.005827
epoch: 4644, train precision: 0.999889, train loss: 5.222187, valid precision: 0.874800, valid loss: 99.029282
epoch: 4645, train precision: 0.999778, train loss: 5.256049, valid precision: 0.873600, valid loss: 100.930513
epoch: 4646, train precision: 0.999667, train loss: 5.250158, valid precision: 0.873600, valid loss: 100.846690
epoch: 4647, train precision: 0.999667, train loss: 5.257715, valid precision: 0.876200, valid loss: 99.954689
epoch: 4648, train precision: 0.999778, train loss: 5.260264, valid precision: 0.874000, valid loss: 98.268972
epoch: 4649, train precision: 0.999778, train loss: 5.253412, valid precision: 0.876200, valid loss: 102.197358
epoch: 4650, train precision: 0.999822, train loss: 5.223894, valid precision: 0.876400, valid loss: 101.714159
epoch: 4651, train precision: 0.999622, train loss: 5.257366, valid precision: 0.876600, valid loss: 99.881651
epoch: 4652, train precision: 0.999622, train loss: 5.257771, valid precision: 0.876000, valid loss: 105.452530
epoch: 4653, train precision: 0.999578, train loss: 5.323436, valid precision: 0.874800, valid loss: 100.416699
epoch: 4654, train precision: 0.999711, train loss: 5.253276, valid precision: 0.874200, valid loss: 100.444603
epoch: 4655, train precision: 0.999667, train loss: 5.271463, valid precision: 0.877800, valid loss: 96.754245
epoch: 4656, train precision: 0.999600, train loss: 5.299942, valid precision: 0.879400, valid loss: 97.811180
epoch: 4657, train precision: 0.999867, train loss: 5.232545, valid precision: 0.878800, valid loss: 97.938177
epoch: 4658, train precision: 0.999822, train loss: 5.244905, valid precision: 0.878400, valid loss: 98.133246
epoch: 4659, train precision: 0.999667, train loss: 5.299776, valid precision: 0.874600, valid loss: 100.168806
epoch: 4660, train precision: 0.999800, train loss: 5.228708, valid precision: 0.877600, valid loss: 96.255011
epoch: 4661, train precision: 0.999844, train loss: 5.221938, valid precision: 0.879400, valid loss: 97.714769
epoch: 4662, train precision: 0.999711, train loss: 5.258374, valid precision: 0.877400, valid loss: 100.200436
epoch: 4663, train precision: 0.999600, train loss: 5.280789, valid precision: 0.876000, valid loss: 98.367692
epoch: 4664, train precision: 0.999800, train loss: 5.260054, valid precision: 0.877400, valid loss: 96.360069
epoch: 4665, train precision: 0.999622, train loss: 5.293452, valid precision: 0.874200, valid loss: 99.737703
epoch: 4666, train precision: 0.999667, train loss: 5.253258, valid precision: 0.874800, valid loss: 99.471863
epoch: 4667, train precision: 0.999733, train loss: 5.258349, valid precision: 0.875800, valid loss: 100.253826
epoch: 4668, train precision: 0.999556, train loss: 5.334466, valid precision: 0.873400, valid loss: 103.117156
epoch: 4669, train precision: 0.999733, train loss: 5.285995, valid precision: 0.877600, valid loss: 99.735957
epoch: 4670, train precision: 0.999778, train loss: 5.241780, valid precision: 0.875200, valid loss: 99.202558
epoch: 4671, train precision: 0.999889, train loss: 5.203448, valid precision: 0.875000, valid loss: 101.221187
epoch: 4672, train precision: 0.999800, train loss: 5.241804, valid precision: 0.873200, valid loss: 101.485192
epoch: 4673, train precision: 0.999467, train loss: 5.333114, valid precision: 0.877400, valid loss: 101.376783
epoch: 4674, train precision: 0.999600, train loss: 5.283309, valid precision: 0.875600, valid loss: 103.095211
epoch: 4675, train precision: 0.999689, train loss: 5.290142, valid precision: 0.875400, valid loss: 100.224629
epoch: 4676, train precision: 0.999667, train loss: 5.275745, valid precision: 0.875600, valid loss: 102.040913
epoch: 4677, train precision: 0.999822, train loss: 5.247492, valid precision: 0.871400, valid loss: 102.608787
epoch: 4678, train precision: 0.999756, train loss: 5.256587, valid precision: 0.877200, valid loss: 98.299520
epoch: 4679, train precision: 0.999822, train loss: 5.256699, valid precision: 0.872400, valid loss: 101.546056
epoch: 4680, train precision: 0.999822, train loss: 5.224118, valid precision: 0.872000, valid loss: 101.028674
epoch: 4681, train precision: 0.999711, train loss: 5.258809, valid precision: 0.874200, valid loss: 99.598519
epoch: 4682, train precision: 0.999778, train loss: 5.239215, valid precision: 0.880600, valid loss: 98.715671
epoch: 4683, train precision: 0.999733, train loss: 5.240398, valid precision: 0.877400, valid loss: 101.793408
epoch: 4684, train precision: 0.999778, train loss: 5.251620, valid precision: 0.877200, valid loss: 97.671168
epoch: 4685, train precision: 0.999689, train loss: 5.269558, valid precision: 0.879400, valid loss: 95.884004
epoch: 4686, train precision: 0.999667, train loss: 5.258054, valid precision: 0.874400, valid loss: 97.575296
epoch: 4687, train precision: 0.999311, train loss: 5.375936, valid precision: 0.878800, valid loss: 99.777374
epoch: 4688, train precision: 0.999600, train loss: 5.267420, valid precision: 0.875400, valid loss: 98.525715
epoch: 4689, train precision: 0.999422, train loss: 5.359448, valid precision: 0.879200, valid loss: 98.144279
epoch: 4690, train precision: 0.999689, train loss: 5.285241, valid precision: 0.875200, valid loss: 98.898950
epoch: 4691, train precision: 0.999822, train loss: 5.225293, valid precision: 0.873600, valid loss: 98.352775
epoch: 4692, train precision: 0.999800, train loss: 5.241477, valid precision: 0.871200, valid loss: 102.354594
epoch: 4693, train precision: 0.999578, train loss: 5.275945, valid precision: 0.874400, valid loss: 100.306670
epoch: 4694, train precision: 0.999822, train loss: 5.240272, valid precision: 0.873800, valid loss: 97.115486
epoch: 4695, train precision: 0.999733, train loss: 5.254047, valid precision: 0.868600, valid loss: 100.156618
epoch: 4696, train precision: 0.999733, train loss: 5.249418, valid precision: 0.876600, valid loss: 99.955396
epoch: 4697, train precision: 0.999733, train loss: 5.249388, valid precision: 0.876600, valid loss: 98.207365
epoch: 4698, train precision: 0.999778, train loss: 5.244649, valid precision: 0.873400, valid loss: 100.046983
epoch: 4699, train precision: 0.999556, train loss: 5.283205, valid precision: 0.871200, valid loss: 103.262461
epoch: 4700, train precision: 0.999667, train loss: 5.280443, valid precision: 0.874800, valid loss: 98.092809
epoch: 4701, train precision: 0.999733, train loss: 5.268992, valid precision: 0.874600, valid loss: 99.455590
epoch: 4702, train precision: 0.999578, train loss: 5.286740, valid precision: 0.872200, valid loss: 102.871537
epoch: 4703, train precision: 0.999844, train loss: 5.230648, valid precision: 0.874000, valid loss: 102.705487
epoch: 4704, train precision: 0.999600, train loss: 5.299209, valid precision: 0.874000, valid loss: 102.574722
epoch: 4705, train precision: 0.999733, train loss: 5.276309, valid precision: 0.877200, valid loss: 98.884932
epoch: 4706, train precision: 0.999622, train loss: 5.248765, valid precision: 0.873400, valid loss: 101.991256
epoch: 4707, train precision: 0.999667, train loss: 5.242656, valid precision: 0.875400, valid loss: 102.567032
epoch: 4708, train precision: 0.999822, train loss: 5.244200, valid precision: 0.874200, valid loss: 101.956753
epoch: 4709, train precision: 0.999800, train loss: 5.228520, valid precision: 0.875000, valid loss: 103.579859
epoch: 4710, train precision: 0.999556, train loss: 5.295724, valid precision: 0.871800, valid loss: 103.576033
epoch: 4711, train precision: 0.999556, train loss: 5.296650, valid precision: 0.877200, valid loss: 102.874075
epoch: 4712, train precision: 0.999822, train loss: 5.238269, valid precision: 0.872600, valid loss: 100.148028
epoch: 4713, train precision: 0.999578, train loss: 5.284702, valid precision: 0.876000, valid loss: 97.968843
epoch: 4714, train precision: 0.999667, train loss: 5.274101, valid precision: 0.872200, valid loss: 102.351946
epoch: 4715, train precision: 0.999867, train loss: 5.227792, valid precision: 0.873200, valid loss: 102.549826
epoch: 4716, train precision: 0.999844, train loss: 5.200493, valid precision: 0.871800, valid loss: 102.308308
epoch: 4717, train precision: 0.999689, train loss: 5.250827, valid precision: 0.877800, valid loss: 101.208891
epoch: 4718, train precision: 0.999778, train loss: 5.234065, valid precision: 0.871200, valid loss: 100.920024
epoch: 4719, train precision: 0.999733, train loss: 5.227903, valid precision: 0.872400, valid loss: 103.977761
epoch: 4720, train precision: 0.999778, train loss: 5.241164, valid precision: 0.876200, valid loss: 102.202308
epoch: 4721, train precision: 0.999489, train loss: 5.318761, valid precision: 0.873000, valid loss: 103.962325
epoch: 4722, train precision: 0.999822, train loss: 5.216325, valid precision: 0.875400, valid loss: 101.173642
epoch: 4723, train precision: 0.999711, train loss: 5.236254, valid precision: 0.875000, valid loss: 103.445762
epoch: 4724, train precision: 0.999689, train loss: 5.252536, valid precision: 0.874400, valid loss: 99.247310
epoch: 4725, train precision: 0.999600, train loss: 5.314316, valid precision: 0.874400, valid loss: 100.074129
epoch: 4726, train precision: 0.999889, train loss: 5.202183, valid precision: 0.877600, valid loss: 102.090354
epoch: 4727, train precision: 0.999800, train loss: 5.224375, valid precision: 0.874000, valid loss: 103.096073
epoch: 4728, train precision: 0.999778, train loss: 5.245337, valid precision: 0.874000, valid loss: 97.977520
epoch: 4729, train precision: 0.999711, train loss: 5.267018, valid precision: 0.874600, valid loss: 98.461233
epoch: 4730, train precision: 0.999622, train loss: 5.291280, valid precision: 0.873800, valid loss: 101.802182
epoch: 4731, train precision: 0.999756, train loss: 5.227943, valid precision: 0.873800, valid loss: 98.995900
epoch: 4732, train precision: 0.999844, train loss: 5.233905, valid precision: 0.872600, valid loss: 96.987164
epoch: 4733, train precision: 0.999756, train loss: 5.237331, valid precision: 0.878000, valid loss: 98.767458
epoch: 4734, train precision: 0.999844, train loss: 5.224057, valid precision: 0.877200, valid loss: 96.823150
epoch: 4735, train precision: 0.999511, train loss: 5.318492, valid precision: 0.870800, valid loss: 98.610081
epoch: 4736, train precision: 0.999778, train loss: 5.249232, valid precision: 0.874800, valid loss: 95.697706
epoch: 4737, train precision: 0.999822, train loss: 5.241134, valid precision: 0.870800, valid loss: 99.489199
epoch: 4738, train precision: 0.999711, train loss: 5.250623, valid precision: 0.876400, valid loss: 96.340495
epoch: 4739, train precision: 0.999822, train loss: 5.220197, valid precision: 0.876200, valid loss: 98.360678
epoch: 4740, train precision: 0.999778, train loss: 5.230898, valid precision: 0.880000, valid loss: 98.305180
epoch: 4741, train precision: 0.999778, train loss: 5.226134, valid precision: 0.875400, valid loss: 101.381832
epoch: 4742, train precision: 0.999844, train loss: 5.232569, valid precision: 0.872600, valid loss: 100.262024
epoch: 4743, train precision: 0.999711, train loss: 5.253928, valid precision: 0.874000, valid loss: 99.187622
epoch: 4744, train precision: 0.999822, train loss: 5.238342, valid precision: 0.872600, valid loss: 101.154150
epoch: 4745, train precision: 0.999756, train loss: 5.257831, valid precision: 0.873800, valid loss: 100.599474
epoch: 4746, train precision: 0.999667, train loss: 5.257090, valid precision: 0.872600, valid loss: 102.951181
epoch: 4747, train precision: 0.999733, train loss: 5.260438, valid precision: 0.876000, valid loss: 101.317408
epoch: 4748, train precision: 0.999667, train loss: 5.295001, valid precision: 0.872800, valid loss: 101.901484
epoch: 4749, train precision: 0.999733, train loss: 5.235605, valid precision: 0.874400, valid loss: 102.094154
epoch: 4750, train precision: 0.999733, train loss: 5.260648, valid precision: 0.871000, valid loss: 101.344455
epoch: 4751, train precision: 0.999822, train loss: 5.202597, valid precision: 0.875400, valid loss: 102.721817
epoch: 4752, train precision: 0.999711, train loss: 5.244969, valid precision: 0.874800, valid loss: 103.371858
epoch: 4753, train precision: 0.999533, train loss: 5.289669, valid precision: 0.876200, valid loss: 101.993063
epoch: 4754, train precision: 0.999800, train loss: 5.227694, valid precision: 0.873200, valid loss: 100.652088
epoch: 4755, train precision: 0.999756, train loss: 5.243456, valid precision: 0.881000, valid loss: 98.077722
epoch: 4756, train precision: 0.999844, train loss: 5.227605, valid precision: 0.875200, valid loss: 100.995965
epoch: 4757, train precision: 0.999800, train loss: 5.231596, valid precision: 0.876200, valid loss: 98.091975
epoch: 4758, train precision: 0.999733, train loss: 5.226486, valid precision: 0.876600, valid loss: 100.312718
epoch: 4759, train precision: 0.999778, train loss: 5.220527, valid precision: 0.877000, valid loss: 98.965198
epoch: 4760, train precision: 0.999822, train loss: 5.221208, valid precision: 0.875200, valid loss: 104.473249
epoch: 4761, train precision: 0.999778, train loss: 5.228014, valid precision: 0.875200, valid loss: 101.673761
epoch: 4762, train precision: 0.999800, train loss: 5.202115, valid precision: 0.874600, valid loss: 101.222052
epoch: 4763, train precision: 0.999756, train loss: 5.241154, valid precision: 0.873400, valid loss: 100.640440
epoch: 4764, train precision: 0.999756, train loss: 5.259095, valid precision: 0.875200, valid loss: 99.952836
epoch: 4765, train precision: 0.999600, train loss: 5.270402, valid precision: 0.876400, valid loss: 101.351644
epoch: 4766, train precision: 0.999667, train loss: 5.263486, valid precision: 0.874400, valid loss: 103.053253
epoch: 4767, train precision: 0.999800, train loss: 5.248629, valid precision: 0.875400, valid loss: 100.144915
epoch: 4768, train precision: 0.999711, train loss: 5.270366, valid precision: 0.874400, valid loss: 101.966467
epoch: 4769, train precision: 0.999844, train loss: 5.229618, valid precision: 0.875800, valid loss: 100.432784
epoch: 4770, train precision: 0.999756, train loss: 5.254025, valid precision: 0.876600, valid loss: 101.005600
epoch: 4771, train precision: 0.999689, train loss: 5.247587, valid precision: 0.875600, valid loss: 100.494150
epoch: 4772, train precision: 0.999756, train loss: 5.219632, valid precision: 0.874400, valid loss: 102.185104
epoch: 4773, train precision: 0.999578, train loss: 5.266080, valid precision: 0.875000, valid loss: 100.922074
epoch: 4774, train precision: 0.999533, train loss: 5.299267, valid precision: 0.875200, valid loss: 101.353972
epoch: 4775, train precision: 0.999667, train loss: 5.254556, valid precision: 0.873400, valid loss: 102.948645
epoch: 4776, train precision: 0.999778, train loss: 5.221367, valid precision: 0.874000, valid loss: 103.286548
epoch: 4777, train precision: 0.999733, train loss: 5.247232, valid precision: 0.874000, valid loss: 103.056924
epoch: 4778, train precision: 0.999778, train loss: 5.256843, valid precision: 0.875600, valid loss: 102.497602
epoch: 4779, train precision: 0.999711, train loss: 5.255175, valid precision: 0.868600, valid loss: 103.397834
epoch: 4780, train precision: 0.999644, train loss: 5.292619, valid precision: 0.869600, valid loss: 102.528897
epoch: 4781, train precision: 0.999689, train loss: 5.244854, valid precision: 0.870800, valid loss: 104.397896
epoch: 4782, train precision: 0.999756, train loss: 5.219215, valid precision: 0.874800, valid loss: 103.116747
epoch: 4783, train precision: 0.999600, train loss: 5.286652, valid precision: 0.871600, valid loss: 103.039983
epoch: 4784, train precision: 0.999644, train loss: 5.260689, valid precision: 0.873400, valid loss: 100.137521
epoch: 4785, train precision: 0.999511, train loss: 5.304746, valid precision: 0.874800, valid loss: 103.325477
epoch: 4786, train precision: 0.999689, train loss: 5.263103, valid precision: 0.875800, valid loss: 103.061702
epoch: 4787, train precision: 0.999756, train loss: 5.262577, valid precision: 0.874000, valid loss: 100.305751
epoch: 4788, train precision: 0.999511, train loss: 5.325146, valid precision: 0.873200, valid loss: 102.265965
epoch: 4789, train precision: 0.999622, train loss: 5.275909, valid precision: 0.875200, valid loss: 101.327737
epoch: 4790, train precision: 0.999867, train loss: 5.204021, valid precision: 0.874200, valid loss: 98.987033
epoch: 4791, train precision: 0.999511, train loss: 5.309484, valid precision: 0.875800, valid loss: 101.704046
epoch: 4792, train precision: 1.000000, train loss: 5.182783, valid precision: 0.872600, valid loss: 99.750482
epoch: 4793, train precision: 0.999689, train loss: 5.282200, valid precision: 0.871600, valid loss: 100.501840
epoch: 4794, train precision: 0.999756, train loss: 5.238335, valid precision: 0.872600, valid loss: 100.763215
epoch: 4795, train precision: 0.999822, train loss: 5.240396, valid precision: 0.874800, valid loss: 98.840488
epoch: 4796, train precision: 0.999511, train loss: 5.288097, valid precision: 0.877800, valid loss: 102.082801
epoch: 4797, train precision: 0.999689, train loss: 5.252094, valid precision: 0.871400, valid loss: 102.384625
epoch: 4798, train precision: 0.999822, train loss: 5.234083, valid precision: 0.874600, valid loss: 103.992619
epoch: 4799, train precision: 0.999578, train loss: 5.273956, valid precision: 0.873400, valid loss: 104.281762
epoch: 4800, train precision: 0.999844, train loss: 5.232165, valid precision: 0.872600, valid loss: 104.922277
epoch: 4801, train precision: 0.999689, train loss: 5.253408, valid precision: 0.876600, valid loss: 101.955037
epoch: 4802, train precision: 0.999733, train loss: 5.222358, valid precision: 0.875000, valid loss: 101.916051
epoch: 4803, train precision: 0.999733, train loss: 5.251643, valid precision: 0.877000, valid loss: 101.518284
epoch: 4804, train precision: 0.999644, train loss: 5.286166, valid precision: 0.875800, valid loss: 100.254148
epoch: 4805, train precision: 0.999644, train loss: 5.277601, valid precision: 0.874800, valid loss: 103.066127
epoch: 4806, train precision: 0.999800, train loss: 5.242406, valid precision: 0.872400, valid loss: 103.439123
epoch: 4807, train precision: 0.999756, train loss: 5.247190, valid precision: 0.874600, valid loss: 99.391222
epoch: 4808, train precision: 0.999622, train loss: 5.251459, valid precision: 0.875000, valid loss: 98.391969
epoch: 4809, train precision: 0.999756, train loss: 5.238209, valid precision: 0.870800, valid loss: 100.972514
epoch: 4810, train precision: 0.999733, train loss: 5.235782, valid precision: 0.871600, valid loss: 102.456229
epoch: 4811, train precision: 0.999667, train loss: 5.247299, valid precision: 0.870800, valid loss: 101.764597
epoch: 4812, train precision: 0.999800, train loss: 5.203715, valid precision: 0.872400, valid loss: 103.149571
epoch: 4813, train precision: 0.999667, train loss: 5.258756, valid precision: 0.875400, valid loss: 98.517542
epoch: 4814, train precision: 0.999733, train loss: 5.236818, valid precision: 0.873000, valid loss: 102.967545
epoch: 4815, train precision: 0.999822, train loss: 5.225632, valid precision: 0.872600, valid loss: 102.135582
epoch: 4816, train precision: 0.999733, train loss: 5.240402, valid precision: 0.872000, valid loss: 99.985475
epoch: 4817, train precision: 0.999778, train loss: 5.242954, valid precision: 0.874600, valid loss: 101.492428
epoch: 4818, train precision: 0.999867, train loss: 5.203159, valid precision: 0.871000, valid loss: 101.397976
epoch: 4819, train precision: 0.999733, train loss: 5.221030, valid precision: 0.871200, valid loss: 103.096552
epoch: 4820, train precision: 0.999711, train loss: 5.251869, valid precision: 0.871600, valid loss: 102.729258
epoch: 4821, train precision: 0.999778, train loss: 5.273316, valid precision: 0.872200, valid loss: 101.700317
epoch: 4822, train precision: 0.999800, train loss: 5.231605, valid precision: 0.869600, valid loss: 100.913740
epoch: 4823, train precision: 0.999800, train loss: 5.227727, valid precision: 0.875200, valid loss: 101.645612
epoch: 4824, train precision: 0.999822, train loss: 5.224316, valid precision: 0.872600, valid loss: 100.961374
epoch: 4825, train precision: 0.999800, train loss: 5.220878, valid precision: 0.873200, valid loss: 103.505782
epoch: 4826, train precision: 0.999667, train loss: 5.255343, valid precision: 0.870800, valid loss: 100.752584
epoch: 4827, train precision: 0.999733, train loss: 5.254437, valid precision: 0.868000, valid loss: 103.237432
epoch: 4828, train precision: 0.999844, train loss: 5.221061, valid precision: 0.871000, valid loss: 99.394174
epoch: 4829, train precision: 0.999711, train loss: 5.245939, valid precision: 0.870400, valid loss: 99.137312
epoch: 4830, train precision: 0.999622, train loss: 5.277909, valid precision: 0.874200, valid loss: 98.547289
epoch: 4831, train precision: 0.999867, train loss: 5.216128, valid precision: 0.873800, valid loss: 100.484557
epoch: 4832, train precision: 0.999733, train loss: 5.221547, valid precision: 0.875400, valid loss: 99.872322
epoch: 4833, train precision: 0.999644, train loss: 5.268607, valid precision: 0.874000, valid loss: 98.347185
epoch: 4834, train precision: 0.999533, train loss: 5.280201, valid precision: 0.873800, valid loss: 100.558078
epoch: 4835, train precision: 0.999733, train loss: 5.260102, valid precision: 0.873600, valid loss: 102.862799
epoch: 4836, train precision: 0.999733, train loss: 5.228660, valid precision: 0.873000, valid loss: 100.579143
epoch: 4837, train precision: 0.999444, train loss: 5.338123, valid precision: 0.877000, valid loss: 100.404346
epoch: 4838, train precision: 0.999778, train loss: 5.232985, valid precision: 0.874200, valid loss: 101.639305
epoch: 4839, train precision: 0.999711, train loss: 5.252163, valid precision: 0.872400, valid loss: 102.217221
epoch: 4840, train precision: 0.999622, train loss: 5.283623, valid precision: 0.876400, valid loss: 99.964921
epoch: 4841, train precision: 0.999867, train loss: 5.210965, valid precision: 0.875000, valid loss: 98.114001
epoch: 4842, train precision: 0.999422, train loss: 5.304995, valid precision: 0.871200, valid loss: 101.349344
epoch: 4843, train precision: 0.999933, train loss: 5.188897, valid precision: 0.875600, valid loss: 98.298810
epoch: 4844, train precision: 0.999889, train loss: 5.209400, valid precision: 0.875800, valid loss: 98.339781
epoch: 4845, train precision: 0.999667, train loss: 5.241054, valid precision: 0.878400, valid loss: 96.819762
epoch: 4846, train precision: 0.999800, train loss: 5.235006, valid precision: 0.873000, valid loss: 98.286778
epoch: 4847, train precision: 0.999511, train loss: 5.341769, valid precision: 0.871800, valid loss: 101.766642
epoch: 4848, train precision: 0.999733, train loss: 5.233570, valid precision: 0.874800, valid loss: 99.037722
epoch: 4849, train precision: 0.999711, train loss: 5.258859, valid precision: 0.874200, valid loss: 97.150611
epoch: 4850, train precision: 0.999844, train loss: 5.238999, valid precision: 0.876400, valid loss: 95.832202
epoch: 4851, train precision: 0.999667, train loss: 5.302844, valid precision: 0.876200, valid loss: 101.480962
epoch: 4852, train precision: 0.999778, train loss: 5.237118, valid precision: 0.874800, valid loss: 99.659046
epoch: 4853, train precision: 0.999667, train loss: 5.250284, valid precision: 0.874800, valid loss: 100.166354
epoch: 4854, train precision: 0.999778, train loss: 5.219578, valid precision: 0.873600, valid loss: 99.641786
epoch: 4855, train precision: 0.999822, train loss: 5.209210, valid precision: 0.874200, valid loss: 100.183320
epoch: 4856, train precision: 0.999667, train loss: 5.248481, valid precision: 0.874800, valid loss: 100.977665
epoch: 4857, train precision: 0.999778, train loss: 5.232367, valid precision: 0.877600, valid loss: 101.335549
epoch: 4858, train precision: 0.999533, train loss: 5.320590, valid precision: 0.871200, valid loss: 101.781706
epoch: 4859, train precision: 0.999644, train loss: 5.277770, valid precision: 0.873800, valid loss: 102.467404
epoch: 4860, train precision: 0.999644, train loss: 5.301731, valid precision: 0.873600, valid loss: 104.783367
epoch: 4861, train precision: 0.999733, train loss: 5.257961, valid precision: 0.869800, valid loss: 104.046786
epoch: 4862, train precision: 0.999667, train loss: 5.271535, valid precision: 0.873000, valid loss: 102.717518
epoch: 4863, train precision: 0.999822, train loss: 5.239356, valid precision: 0.874800, valid loss: 99.995171
epoch: 4864, train precision: 0.999756, train loss: 5.230485, valid precision: 0.868000, valid loss: 105.470187
epoch: 4865, train precision: 0.999556, train loss: 5.252377, valid precision: 0.872200, valid loss: 102.292411
epoch: 4866, train precision: 0.999422, train loss: 5.297051, valid precision: 0.872400, valid loss: 101.958915
epoch: 4867, train precision: 0.999622, train loss: 5.285309, valid precision: 0.872400, valid loss: 102.628442
epoch: 4868, train precision: 0.999733, train loss: 5.215269, valid precision: 0.868600, valid loss: 103.279073
epoch: 4869, train precision: 0.999844, train loss: 5.229945, valid precision: 0.878400, valid loss: 100.780846
epoch: 4870, train precision: 0.999733, train loss: 5.238429, valid precision: 0.874000, valid loss: 102.464934
epoch: 4871, train precision: 0.999778, train loss: 5.217704, valid precision: 0.873400, valid loss: 103.672666
epoch: 4872, train precision: 0.999622, train loss: 5.258066, valid precision: 0.870200, valid loss: 104.551349
epoch: 4873, train precision: 0.999778, train loss: 5.226797, valid precision: 0.875400, valid loss: 103.254598
epoch: 4874, train precision: 0.999667, train loss: 5.256763, valid precision: 0.874400, valid loss: 99.239560
epoch: 4875, train precision: 0.999733, train loss: 5.248710, valid precision: 0.875200, valid loss: 103.145119
epoch: 4876, train precision: 0.999600, train loss: 5.241400, valid precision: 0.874200, valid loss: 104.805660
epoch: 4877, train precision: 0.999600, train loss: 5.343309, valid precision: 0.873800, valid loss: 103.721113
epoch: 4878, train precision: 0.999711, train loss: 5.251283, valid precision: 0.875200, valid loss: 102.757549
epoch: 4879, train precision: 0.999733, train loss: 5.235867, valid precision: 0.878200, valid loss: 101.937185
epoch: 4880, train precision: 0.999756, train loss: 5.234412, valid precision: 0.873000, valid loss: 101.976063
epoch: 4881, train precision: 0.999756, train loss: 5.217681, valid precision: 0.875000, valid loss: 101.242606
epoch: 4882, train precision: 0.999711, train loss: 5.236170, valid precision: 0.872000, valid loss: 105.869008
epoch: 4883, train precision: 0.999778, train loss: 5.215460, valid precision: 0.874400, valid loss: 104.775981
epoch: 4884, train precision: 0.999756, train loss: 5.235790, valid precision: 0.871200, valid loss: 103.260248
epoch: 4885, train precision: 0.999711, train loss: 5.256880, valid precision: 0.872200, valid loss: 106.948680
epoch: 4886, train precision: 0.999889, train loss: 5.189520, valid precision: 0.875600, valid loss: 102.794773
epoch: 4887, train precision: 0.999511, train loss: 5.289890, valid precision: 0.870000, valid loss: 102.574768
epoch: 4888, train precision: 0.999800, train loss: 5.234308, valid precision: 0.873600, valid loss: 100.842601
epoch: 4889, train precision: 0.999756, train loss: 5.224399, valid precision: 0.874600, valid loss: 101.354675
epoch: 4890, train precision: 0.999800, train loss: 5.208216, valid precision: 0.874200, valid loss: 101.480571
epoch: 4891, train precision: 0.999667, train loss: 5.257030, valid precision: 0.872200, valid loss: 101.024093
epoch: 4892, train precision: 0.999622, train loss: 5.255666, valid precision: 0.868800, valid loss: 103.335337
epoch: 4893, train precision: 0.999600, train loss: 5.290015, valid precision: 0.872000, valid loss: 101.425844
epoch: 4894, train precision: 0.999822, train loss: 5.222935, valid precision: 0.874600, valid loss: 102.546518
epoch: 4895, train precision: 0.999778, train loss: 5.224590, valid precision: 0.873400, valid loss: 103.311165
epoch: 4896, train precision: 0.999667, train loss: 5.215641, valid precision: 0.875400, valid loss: 103.839763
epoch: 4897, train precision: 0.999711, train loss: 5.242077, valid precision: 0.878200, valid loss: 102.352145
epoch: 4898, train precision: 0.999844, train loss: 5.220882, valid precision: 0.874400, valid loss: 101.104687
epoch: 4899, train precision: 0.999667, train loss: 5.265226, valid precision: 0.874600, valid loss: 101.947323
epoch: 4900, train precision: 0.999600, train loss: 5.288766, valid precision: 0.870600, valid loss: 101.739918
epoch: 4901, train precision: 0.999644, train loss: 5.251853, valid precision: 0.872800, valid loss: 103.488623
epoch: 4902, train precision: 0.999600, train loss: 5.257028, valid precision: 0.874200, valid loss: 102.300730
epoch: 4903, train precision: 0.999756, train loss: 5.209095, valid precision: 0.874400, valid loss: 101.219784
epoch: 4904, train precision: 0.999711, train loss: 5.250044, valid precision: 0.872600, valid loss: 105.228809
epoch: 4905, train precision: 0.999778, train loss: 5.204044, valid precision: 0.873400, valid loss: 99.831959
epoch: 4906, train precision: 0.999778, train loss: 5.239069, valid precision: 0.874400, valid loss: 100.315460
epoch: 4907, train precision: 0.999822, train loss: 5.229484, valid precision: 0.874600, valid loss: 101.801220
epoch: 4908, train precision: 0.999622, train loss: 5.272019, valid precision: 0.875400, valid loss: 102.150946
epoch: 4909, train precision: 0.999667, train loss: 5.249708, valid precision: 0.874400, valid loss: 99.676646
epoch: 4910, train precision: 0.999644, train loss: 5.248836, valid precision: 0.874600, valid loss: 101.969660
epoch: 4911, train precision: 0.999667, train loss: 5.249083, valid precision: 0.873400, valid loss: 102.665918
epoch: 4912, train precision: 0.999867, train loss: 5.198862, valid precision: 0.874800, valid loss: 103.064458
epoch: 4913, train precision: 0.999800, train loss: 5.229581, valid precision: 0.877000, valid loss: 100.813764
epoch: 4914, train precision: 0.999756, train loss: 5.209928, valid precision: 0.878200, valid loss: 100.868020
epoch: 4915, train precision: 0.999733, train loss: 5.238853, valid precision: 0.875400, valid loss: 103.522364
epoch: 4916, train precision: 0.999756, train loss: 5.251326, valid precision: 0.877600, valid loss: 102.069616
epoch: 4917, train precision: 0.999844, train loss: 5.204695, valid precision: 0.878000, valid loss: 100.787280
epoch: 4918, train precision: 0.999622, train loss: 5.290819, valid precision: 0.877800, valid loss: 100.653780
epoch: 4919, train precision: 0.999511, train loss: 5.322071, valid precision: 0.877800, valid loss: 100.212851
epoch: 4920, train precision: 0.999622, train loss: 5.255992, valid precision: 0.876200, valid loss: 104.434128
epoch: 4921, train precision: 0.999733, train loss: 5.267673, valid precision: 0.877000, valid loss: 99.527779
epoch: 4922, train precision: 0.999600, train loss: 5.279690, valid precision: 0.876800, valid loss: 100.137765
epoch: 4923, train precision: 0.999556, train loss: 5.271633, valid precision: 0.875800, valid loss: 101.131935
epoch: 4924, train precision: 0.999711, train loss: 5.236884, valid precision: 0.878200, valid loss: 100.391550
epoch: 4925, train precision: 0.999733, train loss: 5.225802, valid precision: 0.879400, valid loss: 101.817159
epoch: 4926, train precision: 0.999756, train loss: 5.207666, valid precision: 0.876400, valid loss: 103.844585
epoch: 4927, train precision: 0.999644, train loss: 5.286350, valid precision: 0.873200, valid loss: 106.507004
epoch: 4928, train precision: 0.999711, train loss: 5.201632, valid precision: 0.874200, valid loss: 102.936644
epoch: 4929, train precision: 0.999778, train loss: 5.214398, valid precision: 0.875600, valid loss: 104.496062
epoch: 4930, train precision: 0.999844, train loss: 5.194622, valid precision: 0.875200, valid loss: 102.477114
epoch: 4931, train precision: 0.999644, train loss: 5.298335, valid precision: 0.875000, valid loss: 101.354256
epoch: 4932, train precision: 0.999889, train loss: 5.207039, valid precision: 0.879000, valid loss: 97.636335
epoch: 4933, train precision: 0.999756, train loss: 5.235965, valid precision: 0.879600, valid loss: 100.822363
epoch: 4934, train precision: 0.999689, train loss: 5.251876, valid precision: 0.875200, valid loss: 100.076121
epoch: 4935, train precision: 0.999667, train loss: 5.234945, valid precision: 0.876800, valid loss: 97.411644
epoch: 4936, train precision: 0.999622, train loss: 5.285724, valid precision: 0.876600, valid loss: 98.554604
epoch: 4937, train precision: 0.999667, train loss: 5.232952, valid precision: 0.877800, valid loss: 100.913528
epoch: 4938, train precision: 0.999756, train loss: 5.242448, valid precision: 0.876800, valid loss: 99.084417
epoch: 4939, train precision: 0.999667, train loss: 5.249065, valid precision: 0.873400, valid loss: 102.326318
epoch: 4940, train precision: 0.999733, train loss: 5.240515, valid precision: 0.876000, valid loss: 100.816160
epoch: 4941, train precision: 0.999800, train loss: 5.233303, valid precision: 0.870000, valid loss: 102.338475
epoch: 4942, train precision: 0.999756, train loss: 5.226163, valid precision: 0.878000, valid loss: 102.161711
epoch: 4943, train precision: 0.999756, train loss: 5.240214, valid precision: 0.874000, valid loss: 99.605968
epoch: 4944, train precision: 0.999733, train loss: 5.227019, valid precision: 0.875200, valid loss: 101.022093
epoch: 4945, train precision: 0.999911, train loss: 5.176399, valid precision: 0.878000, valid loss: 98.291281
epoch: 4946, train precision: 0.999778, train loss: 5.247456, valid precision: 0.877600, valid loss: 99.942271
epoch: 4947, train precision: 0.999800, train loss: 5.222413, valid precision: 0.876800, valid loss: 99.955313
epoch: 4948, train precision: 0.999800, train loss: 5.260781, valid precision: 0.876400, valid loss: 100.385669
epoch: 4949, train precision: 0.999689, train loss: 5.246075, valid precision: 0.877800, valid loss: 99.639438
epoch: 4950, train precision: 0.999733, train loss: 5.214353, valid precision: 0.877200, valid loss: 99.308270
epoch: 4951, train precision: 0.999622, train loss: 5.265544, valid precision: 0.872600, valid loss: 102.542387
epoch: 4952, train precision: 0.999489, train loss: 5.307546, valid precision: 0.875200, valid loss: 98.203263
epoch: 4953, train precision: 0.999800, train loss: 5.197286, valid precision: 0.878600, valid loss: 97.858927
epoch: 4954, train precision: 0.999800, train loss: 5.226432, valid precision: 0.875400, valid loss: 96.500567
epoch: 4955, train precision: 0.999689, train loss: 5.238432, valid precision: 0.878800, valid loss: 100.003237
epoch: 4956, train precision: 0.999800, train loss: 5.248831, valid precision: 0.878000, valid loss: 98.855568
epoch: 4957, train precision: 0.999844, train loss: 5.239122, valid precision: 0.876000, valid loss: 98.859497
epoch: 4958, train precision: 0.999644, train loss: 5.242187, valid precision: 0.873400, valid loss: 101.064099
epoch: 4959, train precision: 0.999867, train loss: 5.213600, valid precision: 0.878400, valid loss: 99.036250
epoch: 4960, train precision: 0.999800, train loss: 5.222623, valid precision: 0.878600, valid loss: 99.648535
epoch: 4961, train precision: 0.999733, train loss: 5.242808, valid precision: 0.878200, valid loss: 96.828722
epoch: 4962, train precision: 0.999644, train loss: 5.268205, valid precision: 0.877000, valid loss: 99.218223
epoch: 4963, train precision: 0.999822, train loss: 5.209612, valid precision: 0.877600, valid loss: 99.420687
epoch: 4964, train precision: 0.999644, train loss: 5.252646, valid precision: 0.880400, valid loss: 99.520653
epoch: 4965, train precision: 0.999689, train loss: 5.255910, valid precision: 0.880000, valid loss: 95.686142
epoch: 4966, train precision: 0.999756, train loss: 5.236441, valid precision: 0.877600, valid loss: 97.756833
epoch: 4967, train precision: 0.999711, train loss: 5.246554, valid precision: 0.876800, valid loss: 103.896147
epoch: 4968, train precision: 0.999844, train loss: 5.227662, valid precision: 0.875400, valid loss: 98.604157
epoch: 4969, train precision: 0.999800, train loss: 5.221089, valid precision: 0.875000, valid loss: 102.749753
epoch: 4970, train precision: 0.999778, train loss: 5.199222, valid precision: 0.876400, valid loss: 99.765172
epoch: 4971, train precision: 0.999689, train loss: 5.267955, valid precision: 0.874800, valid loss: 100.777258
epoch: 4972, train precision: 0.999644, train loss: 5.269340, valid precision: 0.873800, valid loss: 99.820655
epoch: 4973, train precision: 0.999800, train loss: 5.243658, valid precision: 0.874200, valid loss: 98.805299
epoch: 4974, train precision: 0.999733, train loss: 5.203723, valid precision: 0.877800, valid loss: 98.313433
epoch: 4975, train precision: 0.999822, train loss: 5.198120, valid precision: 0.877200, valid loss: 99.840447
epoch: 4976, train precision: 0.999844, train loss: 5.216413, valid precision: 0.876600, valid loss: 98.922706
epoch: 4977, train precision: 0.999733, train loss: 5.248949, valid precision: 0.877600, valid loss: 98.312217
epoch: 4978, train precision: 0.999622, train loss: 5.275844, valid precision: 0.879000, valid loss: 96.073407
epoch: 4979, train precision: 0.999689, train loss: 5.258602, valid precision: 0.880400, valid loss: 97.133100
epoch: 4980, train precision: 0.999756, train loss: 5.236754, valid precision: 0.876200, valid loss: 98.219310
epoch: 4981, train precision: 0.999733, train loss: 5.229309, valid precision: 0.876400, valid loss: 100.037933
epoch: 4982, train precision: 0.999711, train loss: 5.233922, valid precision: 0.873800, valid loss: 99.241826
epoch: 4983, train precision: 0.999867, train loss: 5.209590, valid precision: 0.875600, valid loss: 98.555737
epoch: 4984, train precision: 0.999778, train loss: 5.206016, valid precision: 0.879000, valid loss: 99.051992
epoch: 4985, train precision: 0.999511, train loss: 5.260941, valid precision: 0.875600, valid loss: 103.612650
epoch: 4986, train precision: 0.999756, train loss: 5.235191, valid precision: 0.874400, valid loss: 100.906600
epoch: 4987, train precision: 0.999733, train loss: 5.236544, valid precision: 0.871600, valid loss: 101.681916
epoch: 4988, train precision: 0.999689, train loss: 5.227066, valid precision: 0.875400, valid loss: 100.373567
epoch: 4989, train precision: 0.999756, train loss: 5.228505, valid precision: 0.876000, valid loss: 99.888405
epoch: 4990, train precision: 0.999822, train loss: 5.224524, valid precision: 0.876400, valid loss: 97.581801
epoch: 4991, train precision: 0.999711, train loss: 5.252375, valid precision: 0.873000, valid loss: 100.449127
epoch: 4992, train precision: 0.999844, train loss: 5.214704, valid precision: 0.875400, valid loss: 99.490311
epoch: 4993, train precision: 0.999778, train loss: 5.227910, valid precision: 0.868400, valid loss: 104.036294
epoch: 4994, train precision: 0.999822, train loss: 5.206992, valid precision: 0.875400, valid loss: 100.226920
epoch: 4995, train precision: 0.999733, train loss: 5.220861, valid precision: 0.874000, valid loss: 98.719517
epoch: 4996, train precision: 0.999756, train loss: 5.231411, valid precision: 0.876800, valid loss: 99.195994
epoch: 4997, train precision: 0.999800, train loss: 5.207724, valid precision: 0.878200, valid loss: 99.683345
epoch: 4998, train precision: 0.999600, train loss: 5.274403, valid precision: 0.874200, valid loss: 99.942900
epoch: 4999, train precision: 0.999733, train loss: 5.215302, valid precision: 0.874800, valid loss: 99.607817
epoch: 5000, train precision: 0.999844, train loss: 5.234905, valid precision: 0.873800, valid loss: 100.900477
