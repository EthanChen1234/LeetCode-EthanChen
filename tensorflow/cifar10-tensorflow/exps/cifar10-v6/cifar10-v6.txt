nohup: ignoring input
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:83:00.0
Total memory: 11.90GiB
Free memory: 11.76GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:83:00.0)
epoch: 0, train precision: 0.582022, train loss: 151.827972, valid precision: 0.604200, valid loss: 143.864782
epoch: 1, train precision: 0.655089, train loss: 125.881802, valid precision: 0.666400, valid loss: 121.626445
epoch: 2, train precision: 0.720867, train loss: 104.205600, valid precision: 0.721600, valid loss: 104.444704
epoch: 3, train precision: 0.763533, train loss: 87.921536, valid precision: 0.745600, valid loss: 93.452674
epoch: 4, train precision: 0.782756, train loss: 81.269760, valid precision: 0.757800, valid loss: 88.514670
epoch: 5, train precision: 0.798000, train loss: 75.603317, valid precision: 0.765400, valid loss: 86.143936
epoch: 6, train precision: 0.806400, train loss: 71.715192, valid precision: 0.771400, valid loss: 84.330234
epoch: 7, train precision: 0.832489, train loss: 62.483747, valid precision: 0.784400, valid loss: 80.341166
epoch: 8, train precision: 0.841222, train loss: 59.965391, valid precision: 0.794000, valid loss: 77.820026
epoch: 9, train precision: 0.846400, train loss: 57.605295, valid precision: 0.799200, valid loss: 77.128853
epoch: 10, train precision: 0.857111, train loss: 54.605771, valid precision: 0.805000, valid loss: 76.240623
epoch: 11, train precision: 0.868356, train loss: 49.410170, valid precision: 0.807400, valid loss: 73.639781
epoch: 12, train precision: 0.878622, train loss: 47.585171, valid precision: 0.806200, valid loss: 72.202794
epoch: 13, train precision: 0.884956, train loss: 43.783364, valid precision: 0.812600, valid loss: 70.764083
epoch: 14, train precision: 0.895400, train loss: 42.197359, valid precision: 0.808200, valid loss: 70.236924
epoch: 15, train precision: 0.893000, train loss: 40.884364, valid precision: 0.813000, valid loss: 72.290757
epoch: 16, train precision: 0.892133, train loss: 40.631473, valid precision: 0.805800, valid loss: 76.833567
epoch: 17, train precision: 0.912178, train loss: 35.946008, valid precision: 0.811800, valid loss: 70.529744
epoch: 18, train precision: 0.917578, train loss: 32.705924, valid precision: 0.824200, valid loss: 69.150527
epoch: 19, train precision: 0.915044, train loss: 34.473877, valid precision: 0.825800, valid loss: 70.106530
epoch: 20, train precision: 0.915733, train loss: 33.428284, valid precision: 0.820200, valid loss: 72.059348
epoch: 21, train precision: 0.926822, train loss: 29.514729, valid precision: 0.829400, valid loss: 66.300743
epoch: 22, train precision: 0.933533, train loss: 27.787916, valid precision: 0.827000, valid loss: 68.213124
epoch: 23, train precision: 0.928489, train loss: 29.543855, valid precision: 0.832600, valid loss: 67.274073
epoch: 24, train precision: 0.928267, train loss: 29.359853, valid precision: 0.831600, valid loss: 69.640423
epoch: 25, train precision: 0.927022, train loss: 29.188007, valid precision: 0.821800, valid loss: 73.719864
epoch: 26, train precision: 0.940956, train loss: 24.804837, valid precision: 0.827400, valid loss: 72.276799
epoch: 27, train precision: 0.936200, train loss: 26.259601, valid precision: 0.821400, valid loss: 71.689388
epoch: 28, train precision: 0.934133, train loss: 26.527360, valid precision: 0.835800, valid loss: 71.980620
epoch: 29, train precision: 0.938756, train loss: 25.832056, valid precision: 0.824400, valid loss: 74.545527
epoch: 30, train precision: 0.938067, train loss: 26.281952, valid precision: 0.829400, valid loss: 72.799572
epoch: 31, train precision: 0.936378, train loss: 26.214428, valid precision: 0.821400, valid loss: 73.812243
epoch: 32, train precision: 0.934800, train loss: 26.277848, valid precision: 0.825200, valid loss: 75.077627
epoch: 33, train precision: 0.942422, train loss: 24.549441, valid precision: 0.821800, valid loss: 73.252948
epoch: 34, train precision: 0.935444, train loss: 25.905927, valid precision: 0.817800, valid loss: 76.590196
epoch: 35, train precision: 0.944400, train loss: 22.232151, valid precision: 0.829800, valid loss: 74.007948
epoch: 36, train precision: 0.950178, train loss: 21.349479, valid precision: 0.832000, valid loss: 72.407348
epoch: 37, train precision: 0.938422, train loss: 24.993025, valid precision: 0.818800, valid loss: 77.845129
epoch: 38, train precision: 0.948089, train loss: 22.356262, valid precision: 0.819600, valid loss: 76.026954
epoch: 39, train precision: 0.954489, train loss: 20.208481, valid precision: 0.833400, valid loss: 74.362140
epoch: 40, train precision: 0.949622, train loss: 21.225040, valid precision: 0.822800, valid loss: 75.967682
epoch: 41, train precision: 0.944311, train loss: 22.550470, valid precision: 0.820600, valid loss: 80.776508
epoch: 42, train precision: 0.950556, train loss: 20.396036, valid precision: 0.825400, valid loss: 77.778455
epoch: 43, train precision: 0.962933, train loss: 16.485905, valid precision: 0.833400, valid loss: 75.813994
epoch: 44, train precision: 0.944422, train loss: 22.182250, valid precision: 0.816800, valid loss: 82.900743
epoch: 45, train precision: 0.948222, train loss: 21.151663, valid precision: 0.829200, valid loss: 79.761626
epoch: 46, train precision: 0.961311, train loss: 17.680597, valid precision: 0.826000, valid loss: 77.321211
epoch: 47, train precision: 0.955422, train loss: 19.334087, valid precision: 0.829000, valid loss: 78.720814
epoch: 48, train precision: 0.958289, train loss: 18.151571, valid precision: 0.825800, valid loss: 81.401672
epoch: 49, train precision: 0.966178, train loss: 15.601591, valid precision: 0.832000, valid loss: 80.604940
epoch: 50, train precision: 0.957111, train loss: 18.291888, valid precision: 0.827200, valid loss: 83.790382
epoch: 51, train precision: 0.954267, train loss: 19.355034, valid precision: 0.825000, valid loss: 81.393598
epoch: 52, train precision: 0.953400, train loss: 19.505764, valid precision: 0.818200, valid loss: 82.713852
epoch: 53, train precision: 0.967622, train loss: 15.080263, valid precision: 0.834600, valid loss: 77.159798
epoch: 54, train precision: 0.965733, train loss: 15.655519, valid precision: 0.827200, valid loss: 78.987328
epoch: 55, train precision: 0.966667, train loss: 15.379814, valid precision: 0.830400, valid loss: 77.729349
epoch: 56, train precision: 0.971511, train loss: 13.253485, valid precision: 0.832200, valid loss: 83.601745
epoch: 57, train precision: 0.962889, train loss: 16.498193, valid precision: 0.828400, valid loss: 85.546842
epoch: 58, train precision: 0.965267, train loss: 15.214468, valid precision: 0.825800, valid loss: 87.338368
epoch: 59, train precision: 0.962622, train loss: 16.605080, valid precision: 0.823200, valid loss: 82.335359
epoch: 60, train precision: 0.961600, train loss: 16.124096, valid precision: 0.829800, valid loss: 89.438676
epoch: 61, train precision: 0.960578, train loss: 17.047779, valid precision: 0.826000, valid loss: 87.218611
epoch: 62, train precision: 0.970511, train loss: 13.533671, valid precision: 0.837000, valid loss: 81.510602
epoch: 63, train precision: 0.965711, train loss: 15.855250, valid precision: 0.829600, valid loss: 82.716117
epoch: 64, train precision: 0.964800, train loss: 15.636145, valid precision: 0.829800, valid loss: 84.335693
epoch: 65, train precision: 0.968511, train loss: 14.533338, valid precision: 0.833200, valid loss: 85.563163
epoch: 66, train precision: 0.963933, train loss: 15.173820, valid precision: 0.827600, valid loss: 90.151087
epoch: 67, train precision: 0.964733, train loss: 15.650509, valid precision: 0.830200, valid loss: 87.957539
epoch: 68, train precision: 0.971156, train loss: 13.685917, valid precision: 0.831400, valid loss: 84.437246
epoch: 69, train precision: 0.969978, train loss: 13.936464, valid precision: 0.830800, valid loss: 84.399794
epoch: 70, train precision: 0.968844, train loss: 14.325312, valid precision: 0.834400, valid loss: 82.129228
epoch: 71, train precision: 0.969578, train loss: 14.133090, valid precision: 0.833400, valid loss: 87.379630
epoch: 72, train precision: 0.963444, train loss: 16.377765, valid precision: 0.823200, valid loss: 87.326933
epoch: 73, train precision: 0.968489, train loss: 14.532788, valid precision: 0.834800, valid loss: 88.603329
epoch: 74, train precision: 0.969533, train loss: 14.195428, valid precision: 0.835000, valid loss: 87.057371
epoch: 75, train precision: 0.971178, train loss: 13.780294, valid precision: 0.828600, valid loss: 85.184504
epoch: 76, train precision: 0.971333, train loss: 13.327004, valid precision: 0.830200, valid loss: 88.803633
epoch: 77, train precision: 0.972867, train loss: 13.048176, valid precision: 0.840200, valid loss: 84.851441
epoch: 78, train precision: 0.965400, train loss: 15.385015, valid precision: 0.835200, valid loss: 87.328309
epoch: 79, train precision: 0.964311, train loss: 15.823883, valid precision: 0.834600, valid loss: 90.198124
epoch: 80, train precision: 0.960178, train loss: 16.821863, valid precision: 0.833800, valid loss: 91.310620
epoch: 81, train precision: 0.973800, train loss: 12.811224, valid precision: 0.837800, valid loss: 87.904737
epoch: 82, train precision: 0.967889, train loss: 14.305834, valid precision: 0.835200, valid loss: 92.030965
epoch: 83, train precision: 0.971600, train loss: 13.228613, valid precision: 0.836600, valid loss: 88.864932
epoch: 84, train precision: 0.970911, train loss: 13.402569, valid precision: 0.834800, valid loss: 88.262270
epoch: 85, train precision: 0.972911, train loss: 12.923791, valid precision: 0.837400, valid loss: 86.095166
epoch: 86, train precision: 0.969044, train loss: 13.952284, valid precision: 0.836400, valid loss: 92.671074
epoch: 87, train precision: 0.967778, train loss: 14.407946, valid precision: 0.831600, valid loss: 92.535038
epoch: 88, train precision: 0.971889, train loss: 13.163214, valid precision: 0.835000, valid loss: 94.050326
epoch: 89, train precision: 0.972333, train loss: 13.334296, valid precision: 0.839000, valid loss: 89.974217
epoch: 90, train precision: 0.967133, train loss: 14.736366, valid precision: 0.834400, valid loss: 92.928628
epoch: 91, train precision: 0.971044, train loss: 13.088806, valid precision: 0.834400, valid loss: 95.628104
epoch: 92, train precision: 0.971044, train loss: 13.556245, valid precision: 0.821400, valid loss: 96.921496
epoch: 93, train precision: 0.967067, train loss: 14.836468, valid precision: 0.828000, valid loss: 96.382366
epoch: 94, train precision: 0.968711, train loss: 14.211231, valid precision: 0.837400, valid loss: 93.759077
epoch: 95, train precision: 0.972200, train loss: 13.230275, valid precision: 0.835800, valid loss: 88.433195
epoch: 96, train precision: 0.973044, train loss: 12.704612, valid precision: 0.829800, valid loss: 100.395762
epoch: 97, train precision: 0.975111, train loss: 12.231771, valid precision: 0.837200, valid loss: 93.834029
epoch: 98, train precision: 0.972422, train loss: 12.875387, valid precision: 0.838000, valid loss: 93.344525
epoch: 99, train precision: 0.971333, train loss: 13.298626, valid precision: 0.835200, valid loss: 94.412130
epoch: 100, train precision: 0.971089, train loss: 13.486735, valid precision: 0.837000, valid loss: 94.380903
epoch: 101, train precision: 0.971689, train loss: 13.161487, valid precision: 0.834600, valid loss: 94.652776
epoch: 102, train precision: 0.974133, train loss: 12.939164, valid precision: 0.832200, valid loss: 93.357298
epoch: 103, train precision: 0.979556, train loss: 10.922360, valid precision: 0.839200, valid loss: 90.071391
epoch: 104, train precision: 0.969356, train loss: 13.795834, valid precision: 0.831800, valid loss: 99.361304
epoch: 105, train precision: 0.975356, train loss: 11.943011, valid precision: 0.838600, valid loss: 97.317887
epoch: 106, train precision: 0.977200, train loss: 11.278765, valid precision: 0.836600, valid loss: 94.036349
epoch: 107, train precision: 0.976867, train loss: 11.880934, valid precision: 0.827600, valid loss: 96.382655
epoch: 108, train precision: 0.971800, train loss: 13.471866, valid precision: 0.834600, valid loss: 93.850527
epoch: 109, train precision: 0.977356, train loss: 11.394640, valid precision: 0.833000, valid loss: 95.646750
epoch: 110, train precision: 0.972556, train loss: 13.110466, valid precision: 0.827400, valid loss: 101.367889
epoch: 111, train precision: 0.973467, train loss: 12.880226, valid precision: 0.828000, valid loss: 101.384318
epoch: 112, train precision: 0.975533, train loss: 12.494462, valid precision: 0.833400, valid loss: 98.506697
epoch: 113, train precision: 0.969556, train loss: 14.113723, valid precision: 0.826000, valid loss: 103.039191
epoch: 114, train precision: 0.977044, train loss: 11.568326, valid precision: 0.833000, valid loss: 101.565194
epoch: 115, train precision: 0.979222, train loss: 11.010720, valid precision: 0.837800, valid loss: 96.208080
epoch: 116, train precision: 0.975289, train loss: 12.333885, valid precision: 0.837200, valid loss: 96.580101
epoch: 117, train precision: 0.974889, train loss: 12.570443, valid precision: 0.828600, valid loss: 96.366182
epoch: 118, train precision: 0.979222, train loss: 11.091472, valid precision: 0.839400, valid loss: 95.828346
epoch: 119, train precision: 0.976311, train loss: 12.146133, valid precision: 0.835200, valid loss: 97.100865
epoch: 120, train precision: 0.976133, train loss: 12.127272, valid precision: 0.830200, valid loss: 98.068636
epoch: 121, train precision: 0.979622, train loss: 10.764225, valid precision: 0.837800, valid loss: 94.917051
epoch: 122, train precision: 0.975911, train loss: 11.914041, valid precision: 0.835800, valid loss: 101.361648
epoch: 123, train precision: 0.980911, train loss: 10.559200, valid precision: 0.843000, valid loss: 95.279856
epoch: 124, train precision: 0.971644, train loss: 13.518819, valid precision: 0.829000, valid loss: 104.203376
epoch: 125, train precision: 0.978289, train loss: 11.394061, valid precision: 0.837800, valid loss: 96.970412
epoch: 126, train precision: 0.976067, train loss: 12.112238, valid precision: 0.832200, valid loss: 103.388880
epoch: 127, train precision: 0.974222, train loss: 12.562116, valid precision: 0.837800, valid loss: 101.864292
epoch: 128, train precision: 0.978711, train loss: 11.026998, valid precision: 0.837600, valid loss: 98.138445
epoch: 129, train precision: 0.973000, train loss: 13.319651, valid precision: 0.840400, valid loss: 100.103934
epoch: 130, train precision: 0.970822, train loss: 14.004007, valid precision: 0.827800, valid loss: 106.467082
epoch: 131, train precision: 0.978022, train loss: 11.578222, valid precision: 0.836400, valid loss: 103.867133
epoch: 132, train precision: 0.978600, train loss: 11.325896, valid precision: 0.837600, valid loss: 97.634464
epoch: 133, train precision: 0.975400, train loss: 11.911371, valid precision: 0.836000, valid loss: 103.913734
epoch: 134, train precision: 0.978422, train loss: 11.464483, valid precision: 0.835800, valid loss: 100.153285
epoch: 135, train precision: 0.976600, train loss: 12.178188, valid precision: 0.838800, valid loss: 99.523572
epoch: 136, train precision: 0.974600, train loss: 13.089093, valid precision: 0.833200, valid loss: 102.505274
epoch: 137, train precision: 0.970667, train loss: 14.161318, valid precision: 0.824200, valid loss: 106.338293
epoch: 138, train precision: 0.979533, train loss: 11.161485, valid precision: 0.832600, valid loss: 102.866989
epoch: 139, train precision: 0.977133, train loss: 12.241326, valid precision: 0.831600, valid loss: 98.990994
epoch: 140, train precision: 0.979156, train loss: 11.259482, valid precision: 0.838000, valid loss: 103.675960
epoch: 141, train precision: 0.977800, train loss: 12.002123, valid precision: 0.839600, valid loss: 101.830851
epoch: 142, train precision: 0.976556, train loss: 12.299420, valid precision: 0.834200, valid loss: 98.589091
epoch: 143, train precision: 0.968489, train loss: 15.180621, valid precision: 0.830200, valid loss: 107.613239
epoch: 144, train precision: 0.976911, train loss: 12.162049, valid precision: 0.833800, valid loss: 104.052510
epoch: 145, train precision: 0.975000, train loss: 12.732669, valid precision: 0.831000, valid loss: 106.627296
epoch: 146, train precision: 0.979400, train loss: 11.093373, valid precision: 0.834000, valid loss: 103.279804
epoch: 147, train precision: 0.975978, train loss: 12.514271, valid precision: 0.837200, valid loss: 103.519612
epoch: 148, train precision: 0.979533, train loss: 11.307402, valid precision: 0.838200, valid loss: 100.188718
epoch: 149, train precision: 0.981867, train loss: 10.345773, valid precision: 0.839200, valid loss: 104.359573
epoch: 150, train precision: 0.970489, train loss: 14.330817, valid precision: 0.827800, valid loss: 115.973200
epoch: 151, train precision: 0.978622, train loss: 11.547637, valid precision: 0.831000, valid loss: 103.868557
epoch: 152, train precision: 0.975444, train loss: 12.782206, valid precision: 0.828400, valid loss: 103.796776
epoch: 153, train precision: 0.977089, train loss: 11.977991, valid precision: 0.836800, valid loss: 103.236845
epoch: 154, train precision: 0.977267, train loss: 12.061432, valid precision: 0.829800, valid loss: 107.394764
epoch: 155, train precision: 0.979400, train loss: 11.265890, valid precision: 0.833000, valid loss: 106.782886
epoch: 156, train precision: 0.979267, train loss: 11.797022, valid precision: 0.831000, valid loss: 104.480688
epoch: 157, train precision: 0.976778, train loss: 12.653679, valid precision: 0.827800, valid loss: 104.362445
epoch: 158, train precision: 0.976378, train loss: 12.318363, valid precision: 0.832400, valid loss: 105.996859
epoch: 159, train precision: 0.973511, train loss: 13.405233, valid precision: 0.833000, valid loss: 108.266337
epoch: 160, train precision: 0.979178, train loss: 11.517343, valid precision: 0.843200, valid loss: 104.729546
epoch: 161, train precision: 0.978200, train loss: 11.759354, valid precision: 0.834000, valid loss: 108.080968
epoch: 162, train precision: 0.975044, train loss: 13.125916, valid precision: 0.835000, valid loss: 104.210962
epoch: 163, train precision: 0.980600, train loss: 11.260778, valid precision: 0.834600, valid loss: 108.402127
epoch: 164, train precision: 0.981600, train loss: 10.757654, valid precision: 0.840000, valid loss: 105.175489
epoch: 165, train precision: 0.974111, train loss: 13.530566, valid precision: 0.827000, valid loss: 111.977457
epoch: 166, train precision: 0.978400, train loss: 11.892540, valid precision: 0.834800, valid loss: 108.530857
epoch: 167, train precision: 0.981200, train loss: 10.843792, valid precision: 0.841000, valid loss: 102.998103
epoch: 168, train precision: 0.983333, train loss: 10.134286, valid precision: 0.842600, valid loss: 105.163065
epoch: 169, train precision: 0.965089, train loss: 17.299449, valid precision: 0.829200, valid loss: 110.219522
epoch: 170, train precision: 0.983489, train loss: 10.413521, valid precision: 0.842000, valid loss: 103.978444
epoch: 171, train precision: 0.978000, train loss: 12.057718, valid precision: 0.836200, valid loss: 109.449304
epoch: 172, train precision: 0.982067, train loss: 10.598824, valid precision: 0.842600, valid loss: 104.926063
epoch: 173, train precision: 0.975311, train loss: 13.360658, valid precision: 0.833400, valid loss: 108.684608
epoch: 174, train precision: 0.978400, train loss: 11.880688, valid precision: 0.835200, valid loss: 104.407237
epoch: 175, train precision: 0.983667, train loss: 10.084435, valid precision: 0.841400, valid loss: 109.545572
epoch: 176, train precision: 0.980311, train loss: 11.491682, valid precision: 0.834800, valid loss: 109.582958
epoch: 177, train precision: 0.980422, train loss: 11.318148, valid precision: 0.834600, valid loss: 108.476192
epoch: 178, train precision: 0.974778, train loss: 13.330533, valid precision: 0.837600, valid loss: 119.683354
epoch: 179, train precision: 0.977778, train loss: 12.381948, valid precision: 0.833000, valid loss: 107.484578
epoch: 180, train precision: 0.979800, train loss: 11.570585, valid precision: 0.835200, valid loss: 105.864321
epoch: 181, train precision: 0.982844, train loss: 10.448909, valid precision: 0.835800, valid loss: 116.295897
epoch: 182, train precision: 0.984400, train loss: 9.967640, valid precision: 0.838000, valid loss: 106.050653
epoch: 183, train precision: 0.976133, train loss: 12.907844, valid precision: 0.838600, valid loss: 114.411788
epoch: 184, train precision: 0.982489, train loss: 10.637784, valid precision: 0.836600, valid loss: 110.495983
epoch: 185, train precision: 0.978822, train loss: 11.843759, valid precision: 0.840200, valid loss: 112.232255
epoch: 186, train precision: 0.978489, train loss: 12.008185, valid precision: 0.841200, valid loss: 112.643741
epoch: 187, train precision: 0.979822, train loss: 11.577397, valid precision: 0.836000, valid loss: 110.820908
epoch: 188, train precision: 0.974089, train loss: 13.642217, valid precision: 0.832000, valid loss: 117.497347
epoch: 189, train precision: 0.979178, train loss: 11.958624, valid precision: 0.838600, valid loss: 111.472374
epoch: 190, train precision: 0.976822, train loss: 12.769804, valid precision: 0.839000, valid loss: 112.761404
epoch: 191, train precision: 0.979178, train loss: 11.818243, valid precision: 0.836600, valid loss: 114.255816
epoch: 192, train precision: 0.979444, train loss: 11.826511, valid precision: 0.831600, valid loss: 109.534752
epoch: 193, train precision: 0.973533, train loss: 14.506534, valid precision: 0.827800, valid loss: 116.341952
epoch: 194, train precision: 0.972222, train loss: 14.376668, valid precision: 0.832800, valid loss: 118.329975
epoch: 195, train precision: 0.976067, train loss: 13.130226, valid precision: 0.832000, valid loss: 111.475716
epoch: 196, train precision: 0.977067, train loss: 12.562522, valid precision: 0.840600, valid loss: 109.981159
epoch: 197, train precision: 0.978067, train loss: 12.147210, valid precision: 0.833000, valid loss: 113.315547
epoch: 198, train precision: 0.982467, train loss: 11.166815, valid precision: 0.834600, valid loss: 115.331044
epoch: 199, train precision: 0.977133, train loss: 12.976800, valid precision: 0.829600, valid loss: 116.156879
epoch: 200, train precision: 0.972422, train loss: 14.705482, valid precision: 0.832600, valid loss: 121.030970
epoch: 201, train precision: 0.983289, train loss: 10.476680, valid precision: 0.835800, valid loss: 114.351378
epoch: 202, train precision: 0.980733, train loss: 11.229181, valid precision: 0.833200, valid loss: 112.616336
epoch: 203, train precision: 0.981044, train loss: 11.482468, valid precision: 0.836000, valid loss: 113.190183
epoch: 204, train precision: 0.981533, train loss: 11.251119, valid precision: 0.831600, valid loss: 117.387154
epoch: 205, train precision: 0.976067, train loss: 13.303839, valid precision: 0.829600, valid loss: 118.780291
epoch: 206, train precision: 0.979956, train loss: 12.125515, valid precision: 0.834800, valid loss: 110.859046
epoch: 207, train precision: 0.977978, train loss: 12.668797, valid precision: 0.835600, valid loss: 121.023356
epoch: 208, train precision: 0.984178, train loss: 10.421364, valid precision: 0.839000, valid loss: 106.892510
epoch: 209, train precision: 0.980956, train loss: 11.563147, valid precision: 0.833400, valid loss: 118.079048
epoch: 210, train precision: 0.979644, train loss: 11.814775, valid precision: 0.840400, valid loss: 112.338325
epoch: 211, train precision: 0.981467, train loss: 11.253186, valid precision: 0.843800, valid loss: 111.874855
epoch: 212, train precision: 0.982800, train loss: 10.758593, valid precision: 0.840600, valid loss: 112.016814
epoch: 213, train precision: 0.979289, train loss: 12.065985, valid precision: 0.841200, valid loss: 109.180909
epoch: 214, train precision: 0.984444, train loss: 10.366117, valid precision: 0.834800, valid loss: 111.847937
epoch: 215, train precision: 0.983200, train loss: 10.937505, valid precision: 0.834800, valid loss: 111.914133
epoch: 216, train precision: 0.984800, train loss: 10.295404, valid precision: 0.840600, valid loss: 112.577985
epoch: 217, train precision: 0.981756, train loss: 11.672567, valid precision: 0.842800, valid loss: 110.598580
epoch: 218, train precision: 0.983067, train loss: 11.013735, valid precision: 0.839200, valid loss: 113.953371
epoch: 219, train precision: 0.982756, train loss: 10.849568, valid precision: 0.837200, valid loss: 114.474835
epoch: 220, train precision: 0.977533, train loss: 12.772026, valid precision: 0.830800, valid loss: 122.422102
epoch: 221, train precision: 0.981689, train loss: 11.234208, valid precision: 0.832800, valid loss: 122.810947
epoch: 222, train precision: 0.980911, train loss: 11.579358, valid precision: 0.837000, valid loss: 122.908623
epoch: 223, train precision: 0.978244, train loss: 12.794161, valid precision: 0.829000, valid loss: 122.260867
epoch: 224, train precision: 0.980222, train loss: 12.004297, valid precision: 0.830000, valid loss: 121.470951
epoch: 225, train precision: 0.983733, train loss: 10.819518, valid precision: 0.841000, valid loss: 113.375116
epoch: 226, train precision: 0.982556, train loss: 11.100551, valid precision: 0.840800, valid loss: 119.496546
epoch: 227, train precision: 0.981378, train loss: 11.772169, valid precision: 0.824200, valid loss: 119.517953
epoch: 228, train precision: 0.982600, train loss: 11.351738, valid precision: 0.833800, valid loss: 120.323513
epoch: 229, train precision: 0.983400, train loss: 11.112551, valid precision: 0.830800, valid loss: 119.979791
epoch: 230, train precision: 0.983333, train loss: 10.678499, valid precision: 0.834800, valid loss: 121.511863
epoch: 231, train precision: 0.976311, train loss: 14.204949, valid precision: 0.828000, valid loss: 127.881567
epoch: 232, train precision: 0.982889, train loss: 11.003120, valid precision: 0.831600, valid loss: 117.783019
epoch: 233, train precision: 0.979867, train loss: 12.068637, valid precision: 0.834000, valid loss: 119.354234
epoch: 234, train precision: 0.981244, train loss: 11.712338, valid precision: 0.838600, valid loss: 117.975640
epoch: 235, train precision: 0.982089, train loss: 11.406168, valid precision: 0.836800, valid loss: 121.965616
epoch: 236, train precision: 0.974844, train loss: 14.417615, valid precision: 0.826400, valid loss: 123.945740
epoch: 237, train precision: 0.976533, train loss: 13.563634, valid precision: 0.834800, valid loss: 122.239362
epoch: 238, train precision: 0.980844, train loss: 12.159533, valid precision: 0.838000, valid loss: 119.667042
epoch: 239, train precision: 0.981044, train loss: 11.900771, valid precision: 0.835200, valid loss: 121.288884
epoch: 240, train precision: 0.977867, train loss: 12.953707, valid precision: 0.833400, valid loss: 124.605766
epoch: 241, train precision: 0.976244, train loss: 14.085382, valid precision: 0.829400, valid loss: 130.612348
epoch: 242, train precision: 0.982511, train loss: 11.529548, valid precision: 0.836800, valid loss: 121.666361
epoch: 243, train precision: 0.983778, train loss: 11.182687, valid precision: 0.840000, valid loss: 121.957119
epoch: 244, train precision: 0.981044, train loss: 12.083081, valid precision: 0.834200, valid loss: 122.024469
epoch: 245, train precision: 0.976267, train loss: 13.769000, valid precision: 0.831800, valid loss: 124.224333
epoch: 246, train precision: 0.978956, train loss: 12.968728, valid precision: 0.837000, valid loss: 123.745652
epoch: 247, train precision: 0.976956, train loss: 13.352248, valid precision: 0.831400, valid loss: 125.019155
epoch: 248, train precision: 0.982933, train loss: 11.424988, valid precision: 0.839000, valid loss: 119.228716
epoch: 249, train precision: 0.980333, train loss: 12.295633, valid precision: 0.833800, valid loss: 126.768577
epoch: 250, train precision: 0.981289, train loss: 12.078379, valid precision: 0.841600, valid loss: 127.135084
epoch: 251, train precision: 0.983311, train loss: 11.211299, valid precision: 0.837800, valid loss: 119.295185
epoch: 252, train precision: 0.981933, train loss: 11.804206, valid precision: 0.837800, valid loss: 119.772755
epoch: 253, train precision: 0.979800, train loss: 12.519394, valid precision: 0.836200, valid loss: 121.634229
epoch: 254, train precision: 0.982756, train loss: 11.498781, valid precision: 0.836800, valid loss: 121.144477
epoch: 255, train precision: 0.981022, train loss: 12.083225, valid precision: 0.834800, valid loss: 119.301117
epoch: 256, train precision: 0.978644, train loss: 13.156900, valid precision: 0.835400, valid loss: 119.453560
epoch: 257, train precision: 0.975911, train loss: 14.058990, valid precision: 0.837000, valid loss: 115.904627
epoch: 258, train precision: 0.980333, train loss: 12.625108, valid precision: 0.836000, valid loss: 117.515498
epoch: 259, train precision: 0.981333, train loss: 12.168769, valid precision: 0.838000, valid loss: 126.984859
epoch: 260, train precision: 0.984022, train loss: 11.068792, valid precision: 0.836600, valid loss: 119.443014
epoch: 261, train precision: 0.984467, train loss: 11.188786, valid precision: 0.842800, valid loss: 119.324895
epoch: 262, train precision: 0.981378, train loss: 12.111781, valid precision: 0.834800, valid loss: 123.427593
epoch: 263, train precision: 0.983644, train loss: 11.181130, valid precision: 0.839400, valid loss: 119.682268
epoch: 264, train precision: 0.979200, train loss: 12.950566, valid precision: 0.836800, valid loss: 121.120742
epoch: 265, train precision: 0.984533, train loss: 11.041303, valid precision: 0.844400, valid loss: 114.641667
epoch: 266, train precision: 0.983422, train loss: 11.241930, valid precision: 0.844600, valid loss: 119.523894
epoch: 267, train precision: 0.983622, train loss: 11.368543, valid precision: 0.839000, valid loss: 115.151581
epoch: 268, train precision: 0.986778, train loss: 10.072037, valid precision: 0.839200, valid loss: 122.175856
epoch: 269, train precision: 0.980289, train loss: 12.600376, valid precision: 0.835600, valid loss: 125.279597
epoch: 270, train precision: 0.984311, train loss: 11.067314, valid precision: 0.837600, valid loss: 121.312247
epoch: 271, train precision: 0.984333, train loss: 11.202235, valid precision: 0.833000, valid loss: 124.276876
epoch: 272, train precision: 0.977600, train loss: 13.782212, valid precision: 0.833600, valid loss: 126.277381
epoch: 273, train precision: 0.983733, train loss: 11.262357, valid precision: 0.842000, valid loss: 123.167852
epoch: 274, train precision: 0.982044, train loss: 11.955359, valid precision: 0.838400, valid loss: 123.018748
epoch: 275, train precision: 0.984222, train loss: 11.071522, valid precision: 0.845000, valid loss: 118.780979
epoch: 276, train precision: 0.984511, train loss: 10.952675, valid precision: 0.843800, valid loss: 123.458465
epoch: 277, train precision: 0.981044, train loss: 12.381757, valid precision: 0.840000, valid loss: 123.829383
epoch: 278, train precision: 0.981733, train loss: 12.268361, valid precision: 0.844400, valid loss: 121.508318
epoch: 279, train precision: 0.980911, train loss: 12.679100, valid precision: 0.839600, valid loss: 129.354016
epoch: 280, train precision: 0.985556, train loss: 10.657102, valid precision: 0.842000, valid loss: 118.103738
epoch: 281, train precision: 0.983133, train loss: 11.474769, valid precision: 0.839800, valid loss: 128.536325
epoch: 282, train precision: 0.980956, train loss: 12.486536, valid precision: 0.839200, valid loss: 120.808987
epoch: 283, train precision: 0.985644, train loss: 11.005375, valid precision: 0.843200, valid loss: 122.213784
epoch: 284, train precision: 0.983133, train loss: 11.725805, valid precision: 0.836800, valid loss: 127.463224
epoch: 285, train precision: 0.987089, train loss: 10.334044, valid precision: 0.843400, valid loss: 117.309122
epoch: 286, train precision: 0.983178, train loss: 12.095079, valid precision: 0.842600, valid loss: 120.495260
epoch: 287, train precision: 0.982444, train loss: 12.343572, valid precision: 0.837600, valid loss: 126.502949
epoch: 288, train precision: 0.981822, train loss: 12.235416, valid precision: 0.839200, valid loss: 118.313427
epoch: 289, train precision: 0.983378, train loss: 11.469613, valid precision: 0.839800, valid loss: 124.745915
epoch: 290, train precision: 0.985156, train loss: 10.890154, valid precision: 0.839200, valid loss: 123.355711
epoch: 291, train precision: 0.981533, train loss: 12.591557, valid precision: 0.837400, valid loss: 126.533737
epoch: 292, train precision: 0.984444, train loss: 11.304410, valid precision: 0.837000, valid loss: 123.443059
epoch: 293, train precision: 0.981422, train loss: 12.619920, valid precision: 0.835800, valid loss: 127.437064
epoch: 294, train precision: 0.980022, train loss: 12.731292, valid precision: 0.837200, valid loss: 129.783079
epoch: 295, train precision: 0.983022, train loss: 11.822766, valid precision: 0.839200, valid loss: 128.884301
epoch: 296, train precision: 0.975156, train loss: 14.928876, valid precision: 0.834400, valid loss: 125.498139
epoch: 297, train precision: 0.984267, train loss: 11.449525, valid precision: 0.839600, valid loss: 127.573359
epoch: 298, train precision: 0.985978, train loss: 10.651656, valid precision: 0.836400, valid loss: 129.642096
epoch: 299, train precision: 0.978578, train loss: 13.735018, valid precision: 0.832800, valid loss: 127.806839
epoch: 300, train precision: 0.983178, train loss: 11.923138, valid precision: 0.836600, valid loss: 128.210268
epoch: 301, train precision: 0.980956, train loss: 12.775329, valid precision: 0.833600, valid loss: 127.005270
epoch: 302, train precision: 0.986311, train loss: 10.810209, valid precision: 0.839200, valid loss: 129.317705
epoch: 303, train precision: 0.969911, train loss: 17.163559, valid precision: 0.825600, valid loss: 130.519724
epoch: 304, train precision: 0.982867, train loss: 11.987998, valid precision: 0.843400, valid loss: 124.444369
epoch: 305, train precision: 0.982178, train loss: 12.127860, valid precision: 0.835800, valid loss: 126.193468
epoch: 306, train precision: 0.981244, train loss: 12.345074, valid precision: 0.846400, valid loss: 121.628420
epoch: 307, train precision: 0.982644, train loss: 12.107242, valid precision: 0.840800, valid loss: 124.143479
epoch: 308, train precision: 0.981622, train loss: 12.387664, valid precision: 0.837600, valid loss: 118.699780
epoch: 309, train precision: 0.982867, train loss: 12.187845, valid precision: 0.840800, valid loss: 128.679959
epoch: 310, train precision: 0.981000, train loss: 12.776779, valid precision: 0.838200, valid loss: 128.954650
epoch: 311, train precision: 0.980778, train loss: 12.819356, valid precision: 0.835800, valid loss: 129.491179
epoch: 312, train precision: 0.984200, train loss: 11.617010, valid precision: 0.837200, valid loss: 122.204226
epoch: 313, train precision: 0.980956, train loss: 12.527843, valid precision: 0.835200, valid loss: 121.443860
epoch: 314, train precision: 0.983400, train loss: 11.729901, valid precision: 0.838800, valid loss: 126.683463
epoch: 315, train precision: 0.978489, train loss: 13.810457, valid precision: 0.836600, valid loss: 129.467020
epoch: 316, train precision: 0.978911, train loss: 13.577954, valid precision: 0.832200, valid loss: 129.086813
epoch: 317, train precision: 0.982711, train loss: 12.075329, valid precision: 0.840000, valid loss: 134.514814
epoch: 318, train precision: 0.985200, train loss: 11.427770, valid precision: 0.841800, valid loss: 125.920890
epoch: 319, train precision: 0.985556, train loss: 11.206254, valid precision: 0.843600, valid loss: 132.672258
epoch: 320, train precision: 0.982000, train loss: 12.512476, valid precision: 0.838400, valid loss: 136.099588
epoch: 321, train precision: 0.983800, train loss: 11.855472, valid precision: 0.839600, valid loss: 126.348456
epoch: 322, train precision: 0.983133, train loss: 12.045587, valid precision: 0.835000, valid loss: 131.505314
epoch: 323, train precision: 0.981711, train loss: 12.580722, valid precision: 0.835200, valid loss: 127.204805
epoch: 324, train precision: 0.984533, train loss: 11.781796, valid precision: 0.842000, valid loss: 135.171556
epoch: 325, train precision: 0.974311, train loss: 15.171736, valid precision: 0.832000, valid loss: 127.833076
epoch: 326, train precision: 0.982333, train loss: 12.707146, valid precision: 0.837800, valid loss: 132.064004
epoch: 327, train precision: 0.982356, train loss: 12.426510, valid precision: 0.833000, valid loss: 124.258044
epoch: 328, train precision: 0.982756, train loss: 12.320972, valid precision: 0.834600, valid loss: 133.234634
epoch: 329, train precision: 0.987578, train loss: 10.473964, valid precision: 0.844200, valid loss: 124.438686
epoch: 330, train precision: 0.986756, train loss: 10.950215, valid precision: 0.839800, valid loss: 127.500853
epoch: 331, train precision: 0.981844, train loss: 12.732308, valid precision: 0.836400, valid loss: 125.904526
epoch: 332, train precision: 0.983422, train loss: 12.162339, valid precision: 0.839400, valid loss: 132.667674
epoch: 333, train precision: 0.985733, train loss: 11.287511, valid precision: 0.839000, valid loss: 129.680819
epoch: 334, train precision: 0.986222, train loss: 11.236913, valid precision: 0.832200, valid loss: 136.786416
epoch: 335, train precision: 0.985644, train loss: 11.204223, valid precision: 0.839600, valid loss: 135.718011
epoch: 336, train precision: 0.982778, train loss: 12.372956, valid precision: 0.836000, valid loss: 132.864241
epoch: 337, train precision: 0.982267, train loss: 12.908758, valid precision: 0.833400, valid loss: 140.138370
epoch: 338, train precision: 0.975311, train loss: 15.019475, valid precision: 0.827800, valid loss: 140.329658
epoch: 339, train precision: 0.985400, train loss: 11.355729, valid precision: 0.837400, valid loss: 139.095340
epoch: 340, train precision: 0.986822, train loss: 10.829170, valid precision: 0.836200, valid loss: 139.530369
epoch: 341, train precision: 0.983978, train loss: 12.153374, valid precision: 0.832800, valid loss: 137.367109
epoch: 342, train precision: 0.982400, train loss: 12.722636, valid precision: 0.832000, valid loss: 132.618229
epoch: 343, train precision: 0.986022, train loss: 11.136110, valid precision: 0.831800, valid loss: 137.257296
epoch: 344, train precision: 0.984333, train loss: 11.958789, valid precision: 0.836200, valid loss: 136.842458
epoch: 345, train precision: 0.982489, train loss: 12.393937, valid precision: 0.836400, valid loss: 127.087673
epoch: 346, train precision: 0.984067, train loss: 11.878139, valid precision: 0.839600, valid loss: 135.359462
epoch: 347, train precision: 0.980956, train loss: 13.248593, valid precision: 0.835800, valid loss: 139.200150
epoch: 348, train precision: 0.985356, train loss: 11.737702, valid precision: 0.835400, valid loss: 140.449427
epoch: 349, train precision: 0.985089, train loss: 11.458264, valid precision: 0.833000, valid loss: 139.097492
epoch: 350, train precision: 0.978867, train loss: 14.176423, valid precision: 0.829000, valid loss: 143.519291
epoch: 351, train precision: 0.984889, train loss: 11.803866, valid precision: 0.839200, valid loss: 136.073415
epoch: 352, train precision: 0.977422, train loss: 14.642824, valid precision: 0.829000, valid loss: 141.823588
epoch: 353, train precision: 0.987000, train loss: 10.845342, valid precision: 0.839000, valid loss: 136.584408
epoch: 354, train precision: 0.985667, train loss: 11.508143, valid precision: 0.836800, valid loss: 135.138657
epoch: 355, train precision: 0.981178, train loss: 13.305275, valid precision: 0.829600, valid loss: 137.550527
epoch: 356, train precision: 0.985244, train loss: 11.566686, valid precision: 0.838000, valid loss: 131.599014
epoch: 357, train precision: 0.984844, train loss: 11.953245, valid precision: 0.837200, valid loss: 131.851621
epoch: 358, train precision: 0.981244, train loss: 13.221562, valid precision: 0.830800, valid loss: 139.104323
epoch: 359, train precision: 0.985644, train loss: 11.395014, valid precision: 0.840200, valid loss: 131.832377
epoch: 360, train precision: 0.982733, train loss: 12.823586, valid precision: 0.835000, valid loss: 134.860991
epoch: 361, train precision: 0.985089, train loss: 11.770672, valid precision: 0.838000, valid loss: 133.941562
epoch: 362, train precision: 0.983533, train loss: 12.287606, valid precision: 0.833600, valid loss: 134.428452
epoch: 363, train precision: 0.983867, train loss: 12.335562, valid precision: 0.835200, valid loss: 133.786831
epoch: 364, train precision: 0.985200, train loss: 12.002722, valid precision: 0.839200, valid loss: 134.188567
epoch: 365, train precision: 0.983956, train loss: 12.330546, valid precision: 0.837400, valid loss: 131.604721
epoch: 366, train precision: 0.983733, train loss: 12.208694, valid precision: 0.832600, valid loss: 136.578516
epoch: 367, train precision: 0.985400, train loss: 11.710272, valid precision: 0.834600, valid loss: 136.000015
epoch: 368, train precision: 0.982222, train loss: 12.711239, valid precision: 0.840600, valid loss: 133.367851
epoch: 369, train precision: 0.983378, train loss: 12.553574, valid precision: 0.835800, valid loss: 133.065783
epoch: 370, train precision: 0.985067, train loss: 11.873929, valid precision: 0.833600, valid loss: 138.125559
epoch: 371, train precision: 0.980467, train loss: 13.533700, valid precision: 0.829200, valid loss: 134.724367
epoch: 372, train precision: 0.984400, train loss: 12.587381, valid precision: 0.840400, valid loss: 138.905626
epoch: 373, train precision: 0.983533, train loss: 12.508799, valid precision: 0.832800, valid loss: 141.197624
epoch: 374, train precision: 0.982156, train loss: 13.133795, valid precision: 0.835800, valid loss: 135.974535
epoch: 375, train precision: 0.982222, train loss: 13.083336, valid precision: 0.836600, valid loss: 132.879437
epoch: 376, train precision: 0.984333, train loss: 12.241395, valid precision: 0.836600, valid loss: 128.238921
epoch: 377, train precision: 0.983778, train loss: 12.454459, valid precision: 0.833200, valid loss: 134.182772
epoch: 378, train precision: 0.985422, train loss: 11.819086, valid precision: 0.828200, valid loss: 133.342528
epoch: 379, train precision: 0.982667, train loss: 12.841050, valid precision: 0.831400, valid loss: 138.976058
epoch: 380, train precision: 0.983689, train loss: 12.549780, valid precision: 0.839600, valid loss: 131.021707
epoch: 381, train precision: 0.984978, train loss: 11.995409, valid precision: 0.842600, valid loss: 133.557918
epoch: 382, train precision: 0.978133, train loss: 14.348998, valid precision: 0.837600, valid loss: 132.170505
epoch: 383, train precision: 0.976822, train loss: 15.423231, valid precision: 0.829800, valid loss: 142.789324
epoch: 384, train precision: 0.980800, train loss: 13.939126, valid precision: 0.836800, valid loss: 139.421690
epoch: 385, train precision: 0.982800, train loss: 12.995446, valid precision: 0.839400, valid loss: 128.492441
epoch: 386, train precision: 0.980711, train loss: 13.684354, valid precision: 0.833800, valid loss: 142.587348
epoch: 387, train precision: 0.979689, train loss: 14.329069, valid precision: 0.838200, valid loss: 135.088049
epoch: 388, train precision: 0.985022, train loss: 11.888911, valid precision: 0.840800, valid loss: 141.566961
epoch: 389, train precision: 0.984800, train loss: 12.385867, valid precision: 0.837600, valid loss: 143.692975
epoch: 390, train precision: 0.985333, train loss: 12.277866, valid precision: 0.839600, valid loss: 139.089729
epoch: 391, train precision: 0.985511, train loss: 11.853750, valid precision: 0.837000, valid loss: 139.329910
epoch: 392, train precision: 0.988067, train loss: 10.861009, valid precision: 0.846800, valid loss: 133.994979
epoch: 393, train precision: 0.982600, train loss: 12.987247, valid precision: 0.835200, valid loss: 140.208012
epoch: 394, train precision: 0.982800, train loss: 13.036956, valid precision: 0.841600, valid loss: 131.482233
epoch: 395, train precision: 0.984711, train loss: 12.019468, valid precision: 0.836000, valid loss: 138.745551
epoch: 396, train precision: 0.984267, train loss: 12.526167, valid precision: 0.837800, valid loss: 140.169382
epoch: 397, train precision: 0.987511, train loss: 11.321100, valid precision: 0.838600, valid loss: 139.580225
epoch: 398, train precision: 0.978156, train loss: 14.510458, valid precision: 0.836000, valid loss: 137.820805
epoch: 399, train precision: 0.982733, train loss: 13.348315, valid precision: 0.832800, valid loss: 141.160914
epoch: 400, train precision: 0.979356, train loss: 14.391828, valid precision: 0.832800, valid loss: 147.542603
epoch: 401, train precision: 0.983089, train loss: 12.926974, valid precision: 0.831400, valid loss: 141.992226
epoch: 402, train precision: 0.976733, train loss: 15.623310, valid precision: 0.833000, valid loss: 148.461384
epoch: 403, train precision: 0.984000, train loss: 12.559861, valid precision: 0.832800, valid loss: 137.011181
epoch: 404, train precision: 0.986689, train loss: 11.652713, valid precision: 0.835600, valid loss: 136.768516
epoch: 405, train precision: 0.985800, train loss: 11.780142, valid precision: 0.836600, valid loss: 131.192724
epoch: 406, train precision: 0.983778, train loss: 12.896245, valid precision: 0.832600, valid loss: 144.567530
epoch: 407, train precision: 0.986711, train loss: 11.541560, valid precision: 0.838200, valid loss: 138.355353
epoch: 408, train precision: 0.983067, train loss: 13.061244, valid precision: 0.833000, valid loss: 139.187782
epoch: 409, train precision: 0.983044, train loss: 12.856013, valid precision: 0.838400, valid loss: 137.173663
epoch: 410, train precision: 0.980133, train loss: 14.296447, valid precision: 0.833800, valid loss: 147.908565
epoch: 411, train precision: 0.982489, train loss: 13.534147, valid precision: 0.834400, valid loss: 146.504822
epoch: 412, train precision: 0.985622, train loss: 11.943990, valid precision: 0.834600, valid loss: 148.863755
epoch: 413, train precision: 0.982889, train loss: 13.228626, valid precision: 0.840200, valid loss: 139.366492
epoch: 414, train precision: 0.980422, train loss: 14.549921, valid precision: 0.832800, valid loss: 153.609024
epoch: 415, train precision: 0.984911, train loss: 12.560413, valid precision: 0.828600, valid loss: 142.062611
epoch: 416, train precision: 0.986711, train loss: 11.646069, valid precision: 0.835200, valid loss: 148.543069
epoch: 417, train precision: 0.980378, train loss: 14.382602, valid precision: 0.829000, valid loss: 154.954652
epoch: 418, train precision: 0.982000, train loss: 13.607420, valid precision: 0.828200, valid loss: 151.578556
epoch: 419, train precision: 0.984311, train loss: 12.599310, valid precision: 0.832000, valid loss: 153.036098
epoch: 420, train precision: 0.986400, train loss: 11.571843, valid precision: 0.832200, valid loss: 137.256693
epoch: 421, train precision: 0.977800, train loss: 15.199992, valid precision: 0.829800, valid loss: 150.931209
epoch: 422, train precision: 0.980800, train loss: 13.914270, valid precision: 0.833000, valid loss: 140.664860
epoch: 423, train precision: 0.987467, train loss: 11.329865, valid precision: 0.836000, valid loss: 134.359027
epoch: 424, train precision: 0.983400, train loss: 12.856298, valid precision: 0.841000, valid loss: 147.700224
epoch: 425, train precision: 0.984289, train loss: 13.044273, valid precision: 0.830000, valid loss: 146.874338
epoch: 426, train precision: 0.985067, train loss: 12.113079, valid precision: 0.831600, valid loss: 151.271681
epoch: 427, train precision: 0.985489, train loss: 12.012779, valid precision: 0.831400, valid loss: 146.984557
epoch: 428, train precision: 0.977956, train loss: 15.417403, valid precision: 0.834400, valid loss: 147.836998
epoch: 429, train precision: 0.986800, train loss: 11.665435, valid precision: 0.830400, valid loss: 148.085965
epoch: 430, train precision: 0.980067, train loss: 14.611251, valid precision: 0.825800, valid loss: 152.430375
epoch: 431, train precision: 0.986844, train loss: 11.508457, valid precision: 0.838200, valid loss: 143.806327
epoch: 432, train precision: 0.985756, train loss: 12.141712, valid precision: 0.830800, valid loss: 151.471693
epoch: 433, train precision: 0.988022, train loss: 11.429871, valid precision: 0.835800, valid loss: 140.059114
epoch: 434, train precision: 0.983311, train loss: 13.141650, valid precision: 0.838200, valid loss: 139.813079
epoch: 435, train precision: 0.983022, train loss: 13.536526, valid precision: 0.836200, valid loss: 148.824159
epoch: 436, train precision: 0.982956, train loss: 13.389816, valid precision: 0.832000, valid loss: 149.525626
epoch: 437, train precision: 0.984178, train loss: 12.716108, valid precision: 0.838800, valid loss: 146.157436
epoch: 438, train precision: 0.980333, train loss: 14.405734, valid precision: 0.830000, valid loss: 137.549568
epoch: 439, train precision: 0.974889, train loss: 16.698100, valid precision: 0.827600, valid loss: 150.661522
epoch: 440, train precision: 0.980667, train loss: 14.216580, valid precision: 0.827200, valid loss: 148.654601
epoch: 441, train precision: 0.986956, train loss: 11.759589, valid precision: 0.834800, valid loss: 143.387307
epoch: 442, train precision: 0.984089, train loss: 12.981160, valid precision: 0.831400, valid loss: 142.679838
epoch: 443, train precision: 0.982111, train loss: 13.674833, valid precision: 0.828000, valid loss: 146.039740
epoch: 444, train precision: 0.984733, train loss: 12.725945, valid precision: 0.831800, valid loss: 141.936848
epoch: 445, train precision: 0.985089, train loss: 12.522713, valid precision: 0.836200, valid loss: 148.097292
epoch: 446, train precision: 0.983467, train loss: 13.086091, valid precision: 0.836800, valid loss: 151.159544
epoch: 447, train precision: 0.983222, train loss: 13.336128, valid precision: 0.831000, valid loss: 147.413914
epoch: 448, train precision: 0.982622, train loss: 13.707765, valid precision: 0.836200, valid loss: 153.097178
epoch: 449, train precision: 0.984489, train loss: 12.846188, valid precision: 0.830800, valid loss: 153.052361
epoch: 450, train precision: 0.981978, train loss: 13.579944, valid precision: 0.836800, valid loss: 144.333191
epoch: 451, train precision: 0.985489, train loss: 12.461690, valid precision: 0.835200, valid loss: 140.914580
epoch: 452, train precision: 0.985022, train loss: 12.926905, valid precision: 0.838800, valid loss: 147.312023
epoch: 453, train precision: 0.984778, train loss: 12.956563, valid precision: 0.834800, valid loss: 150.729234
epoch: 454, train precision: 0.984422, train loss: 12.936952, valid precision: 0.837200, valid loss: 147.381194
epoch: 455, train precision: 0.985933, train loss: 12.454930, valid precision: 0.837400, valid loss: 156.397685
epoch: 456, train precision: 0.983689, train loss: 13.195395, valid precision: 0.832400, valid loss: 148.554225
epoch: 457, train precision: 0.986267, train loss: 12.164846, valid precision: 0.837800, valid loss: 150.393070
epoch: 458, train precision: 0.985444, train loss: 12.254075, valid precision: 0.837000, valid loss: 152.956331
epoch: 459, train precision: 0.984000, train loss: 12.919842, valid precision: 0.838400, valid loss: 144.127418
epoch: 460, train precision: 0.986000, train loss: 12.260549, valid precision: 0.842400, valid loss: 144.147061
epoch: 461, train precision: 0.984889, train loss: 12.582007, valid precision: 0.837600, valid loss: 137.900002
epoch: 462, train precision: 0.981622, train loss: 13.928469, valid precision: 0.839200, valid loss: 141.537698
epoch: 463, train precision: 0.984911, train loss: 12.666501, valid precision: 0.839600, valid loss: 147.502704
epoch: 464, train precision: 0.978556, train loss: 15.533744, valid precision: 0.831800, valid loss: 156.508005
epoch: 465, train precision: 0.984311, train loss: 13.019166, valid precision: 0.836400, valid loss: 152.059634
epoch: 466, train precision: 0.985400, train loss: 12.458764, valid precision: 0.834600, valid loss: 143.123515
epoch: 467, train precision: 0.985933, train loss: 12.267686, valid precision: 0.834200, valid loss: 154.461272
epoch: 468, train precision: 0.983711, train loss: 13.255066, valid precision: 0.837800, valid loss: 155.770368
epoch: 469, train precision: 0.983822, train loss: 13.240165, valid precision: 0.831000, valid loss: 146.209539
epoch: 470, train precision: 0.980400, train loss: 14.439429, valid precision: 0.836000, valid loss: 140.657068
epoch: 471, train precision: 0.985378, train loss: 12.793280, valid precision: 0.832400, valid loss: 147.881474
epoch: 472, train precision: 0.982756, train loss: 13.803797, valid precision: 0.832800, valid loss: 152.264891
epoch: 473, train precision: 0.986689, train loss: 12.299297, valid precision: 0.836800, valid loss: 137.654895
epoch: 474, train precision: 0.984533, train loss: 13.070695, valid precision: 0.838400, valid loss: 141.296451
epoch: 475, train precision: 0.982667, train loss: 13.358769, valid precision: 0.840200, valid loss: 146.331170
epoch: 476, train precision: 0.983667, train loss: 13.416308, valid precision: 0.840000, valid loss: 148.963693
epoch: 477, train precision: 0.983244, train loss: 13.520810, valid precision: 0.835400, valid loss: 149.440721
epoch: 478, train precision: 0.986067, train loss: 12.528963, valid precision: 0.838600, valid loss: 151.602777
epoch: 479, train precision: 0.982378, train loss: 14.322075, valid precision: 0.838400, valid loss: 155.070981
epoch: 480, train precision: 0.982800, train loss: 13.376273, valid precision: 0.837600, valid loss: 146.921053
epoch: 481, train precision: 0.985978, train loss: 12.189159, valid precision: 0.838200, valid loss: 145.253978
epoch: 482, train precision: 0.982778, train loss: 13.773902, valid precision: 0.836800, valid loss: 145.326769
epoch: 483, train precision: 0.983733, train loss: 13.057170, valid precision: 0.839200, valid loss: 150.693642
epoch: 484, train precision: 0.986778, train loss: 12.283084, valid precision: 0.837600, valid loss: 148.833952
epoch: 485, train precision: 0.979378, train loss: 15.424114, valid precision: 0.837600, valid loss: 154.569729
epoch: 486, train precision: 0.980467, train loss: 14.897691, valid precision: 0.834400, valid loss: 158.052475
epoch: 487, train precision: 0.983467, train loss: 13.492355, valid precision: 0.838000, valid loss: 145.397669
epoch: 488, train precision: 0.981467, train loss: 13.811800, valid precision: 0.840400, valid loss: 145.124891
epoch: 489, train precision: 0.987511, train loss: 11.810341, valid precision: 0.841200, valid loss: 146.716940
epoch: 490, train precision: 0.987711, train loss: 12.100047, valid precision: 0.842600, valid loss: 148.050919
epoch: 491, train precision: 0.985133, train loss: 12.757227, valid precision: 0.836400, valid loss: 149.451876
epoch: 492, train precision: 0.984222, train loss: 13.115536, valid precision: 0.834200, valid loss: 155.417758
epoch: 493, train precision: 0.982467, train loss: 13.786178, valid precision: 0.837400, valid loss: 147.555683
epoch: 494, train precision: 0.984822, train loss: 12.910613, valid precision: 0.832600, valid loss: 147.116803
epoch: 495, train precision: 0.985111, train loss: 12.664214, valid precision: 0.836400, valid loss: 148.423352
epoch: 496, train precision: 0.984000, train loss: 13.282209, valid precision: 0.839200, valid loss: 150.145380
epoch: 497, train precision: 0.986200, train loss: 12.573955, valid precision: 0.839600, valid loss: 149.048656
epoch: 498, train precision: 0.986644, train loss: 12.551299, valid precision: 0.839200, valid loss: 142.967623
epoch: 499, train precision: 0.985222, train loss: 12.720618, valid precision: 0.838400, valid loss: 146.073437
epoch: 500, train precision: 0.982756, train loss: 13.851676, valid precision: 0.832800, valid loss: 148.899103
epoch: 501, train precision: 0.984733, train loss: 13.055804, valid precision: 0.838000, valid loss: 144.502714
epoch: 502, train precision: 0.982600, train loss: 13.934930, valid precision: 0.841600, valid loss: 146.611776
epoch: 503, train precision: 0.985533, train loss: 12.965953, valid precision: 0.834800, valid loss: 142.164145
epoch: 504, train precision: 0.984978, train loss: 13.027438, valid precision: 0.834200, valid loss: 150.470264
epoch: 505, train precision: 0.985400, train loss: 12.764637, valid precision: 0.833600, valid loss: 149.718018
epoch: 506, train precision: 0.985600, train loss: 12.804826, valid precision: 0.834400, valid loss: 153.955879
epoch: 507, train precision: 0.984489, train loss: 13.087348, valid precision: 0.838600, valid loss: 148.644110
epoch: 508, train precision: 0.987333, train loss: 12.200390, valid precision: 0.836600, valid loss: 147.287601
epoch: 509, train precision: 0.983822, train loss: 13.366526, valid precision: 0.834200, valid loss: 147.497977
epoch: 510, train precision: 0.983444, train loss: 13.855559, valid precision: 0.832800, valid loss: 145.646271
epoch: 511, train precision: 0.980956, train loss: 14.878294, valid precision: 0.828400, valid loss: 155.949928
epoch: 512, train precision: 0.983844, train loss: 13.859933, valid precision: 0.833000, valid loss: 155.516923
epoch: 513, train precision: 0.985644, train loss: 12.983669, valid precision: 0.836600, valid loss: 150.088935
epoch: 514, train precision: 0.985067, train loss: 13.300355, valid precision: 0.838800, valid loss: 143.613862
epoch: 515, train precision: 0.979222, train loss: 15.382751, valid precision: 0.822000, valid loss: 145.543200
epoch: 516, train precision: 0.982533, train loss: 13.726207, valid precision: 0.836800, valid loss: 135.891094
epoch: 517, train precision: 0.984622, train loss: 13.263188, valid precision: 0.825400, valid loss: 154.828754
epoch: 518, train precision: 0.985400, train loss: 12.867208, valid precision: 0.835200, valid loss: 149.003799
epoch: 519, train precision: 0.982600, train loss: 14.074539, valid precision: 0.832400, valid loss: 152.402035
epoch: 520, train precision: 0.983067, train loss: 13.460867, valid precision: 0.838200, valid loss: 141.582914
epoch: 521, train precision: 0.982556, train loss: 14.133840, valid precision: 0.834600, valid loss: 151.043352
epoch: 522, train precision: 0.983089, train loss: 13.902192, valid precision: 0.835000, valid loss: 149.153902
epoch: 523, train precision: 0.983844, train loss: 13.535470, valid precision: 0.834000, valid loss: 143.190237
epoch: 524, train precision: 0.985644, train loss: 12.865846, valid precision: 0.836600, valid loss: 153.352992
epoch: 525, train precision: 0.986778, train loss: 12.390572, valid precision: 0.841600, valid loss: 146.312475
epoch: 526, train precision: 0.981178, train loss: 14.550206, valid precision: 0.835200, valid loss: 139.576498
epoch: 527, train precision: 0.986156, train loss: 12.752240, valid precision: 0.837600, valid loss: 142.536368
epoch: 528, train precision: 0.983511, train loss: 13.647730, valid precision: 0.837000, valid loss: 145.987441
epoch: 529, train precision: 0.983889, train loss: 13.704585, valid precision: 0.838600, valid loss: 144.551877
epoch: 530, train precision: 0.984600, train loss: 13.373519, valid precision: 0.835600, valid loss: 149.780181
epoch: 531, train precision: 0.982333, train loss: 14.105019, valid precision: 0.834600, valid loss: 141.538369
epoch: 532, train precision: 0.988089, train loss: 12.080460, valid precision: 0.835200, valid loss: 150.496122
epoch: 533, train precision: 0.987000, train loss: 12.435662, valid precision: 0.841800, valid loss: 144.661413
epoch: 534, train precision: 0.987489, train loss: 12.216369, valid precision: 0.840800, valid loss: 147.095613
epoch: 535, train precision: 0.982533, train loss: 14.612898, valid precision: 0.834200, valid loss: 142.811358
epoch: 536, train precision: 0.983267, train loss: 14.354246, valid precision: 0.834200, valid loss: 142.710329
epoch: 537, train precision: 0.982756, train loss: 14.208929, valid precision: 0.835800, valid loss: 155.246513
epoch: 538, train precision: 0.983844, train loss: 13.630943, valid precision: 0.837400, valid loss: 144.907574
epoch: 539, train precision: 0.983089, train loss: 14.060547, valid precision: 0.837600, valid loss: 145.927659
epoch: 540, train precision: 0.980333, train loss: 15.359247, valid precision: 0.834800, valid loss: 155.346415
epoch: 541, train precision: 0.985378, train loss: 12.997810, valid precision: 0.836400, valid loss: 150.138863
epoch: 542, train precision: 0.983844, train loss: 13.552653, valid precision: 0.834200, valid loss: 144.522909
epoch: 543, train precision: 0.984044, train loss: 13.903144, valid precision: 0.836400, valid loss: 149.614974
epoch: 544, train precision: 0.983244, train loss: 14.023610, valid precision: 0.841000, valid loss: 160.444697
epoch: 545, train precision: 0.987667, train loss: 12.102497, valid precision: 0.839200, valid loss: 154.032233
epoch: 546, train precision: 0.981711, train loss: 14.698281, valid precision: 0.832600, valid loss: 151.054520
epoch: 547, train precision: 0.986133, train loss: 12.879970, valid precision: 0.839600, valid loss: 145.540303
epoch: 548, train precision: 0.988822, train loss: 11.809608, valid precision: 0.845000, valid loss: 140.663406
epoch: 549, train precision: 0.985200, train loss: 12.989878, valid precision: 0.837800, valid loss: 144.493318
epoch: 550, train precision: 0.982556, train loss: 14.434844, valid precision: 0.842200, valid loss: 150.098155
epoch: 551, train precision: 0.984911, train loss: 12.930797, valid precision: 0.836800, valid loss: 149.924039
epoch: 552, train precision: 0.986200, train loss: 12.791971, valid precision: 0.832800, valid loss: 147.363930
epoch: 553, train precision: 0.983111, train loss: 13.967023, valid precision: 0.843600, valid loss: 152.600748
epoch: 554, train precision: 0.984489, train loss: 13.598328, valid precision: 0.843600, valid loss: 151.047703
epoch: 555, train precision: 0.979467, train loss: 15.663222, valid precision: 0.835400, valid loss: 155.675108
epoch: 556, train precision: 0.987267, train loss: 12.533999, valid precision: 0.843800, valid loss: 150.622781
epoch: 557, train precision: 0.986711, train loss: 12.773034, valid precision: 0.835000, valid loss: 155.464239
epoch: 558, train precision: 0.984644, train loss: 13.298210, valid precision: 0.833600, valid loss: 152.898770
epoch: 559, train precision: 0.986800, train loss: 12.368276, valid precision: 0.845800, valid loss: 142.976586
epoch: 560, train precision: 0.982622, train loss: 14.631379, valid precision: 0.840600, valid loss: 150.587262
epoch: 561, train precision: 0.987556, train loss: 12.416295, valid precision: 0.842600, valid loss: 149.607679
epoch: 562, train precision: 0.981889, train loss: 14.624940, valid precision: 0.836600, valid loss: 147.506007
epoch: 563, train precision: 0.986267, train loss: 13.099033, valid precision: 0.841200, valid loss: 147.597802
epoch: 564, train precision: 0.987356, train loss: 12.417620, valid precision: 0.837400, valid loss: 154.507507
epoch: 565, train precision: 0.986889, train loss: 12.336246, valid precision: 0.840600, valid loss: 137.931340
epoch: 566, train precision: 0.986844, train loss: 12.362824, valid precision: 0.833000, valid loss: 151.679669
epoch: 567, train precision: 0.985889, train loss: 13.095245, valid precision: 0.839200, valid loss: 150.091865
epoch: 568, train precision: 0.984644, train loss: 13.337689, valid precision: 0.836200, valid loss: 140.723545
epoch: 569, train precision: 0.984533, train loss: 13.754683, valid precision: 0.833200, valid loss: 151.612840
epoch: 570, train precision: 0.981000, train loss: 15.368342, valid precision: 0.834200, valid loss: 150.453870
epoch: 571, train precision: 0.984556, train loss: 13.549098, valid precision: 0.837600, valid loss: 154.267286
epoch: 572, train precision: 0.986622, train loss: 12.854620, valid precision: 0.840800, valid loss: 141.464675
epoch: 573, train precision: 0.987911, train loss: 12.395965, valid precision: 0.837400, valid loss: 149.691706
epoch: 574, train precision: 0.986244, train loss: 12.964030, valid precision: 0.842200, valid loss: 143.783804
epoch: 575, train precision: 0.984289, train loss: 13.276494, valid precision: 0.846800, valid loss: 137.562365
epoch: 576, train precision: 0.988844, train loss: 11.835725, valid precision: 0.839600, valid loss: 144.983762
epoch: 577, train precision: 0.984356, train loss: 13.909365, valid precision: 0.836400, valid loss: 146.256610
epoch: 578, train precision: 0.986289, train loss: 12.942326, valid precision: 0.834800, valid loss: 146.702454
epoch: 579, train precision: 0.980600, train loss: 15.048231, valid precision: 0.837800, valid loss: 151.928499
epoch: 580, train precision: 0.979289, train loss: 16.338423, valid precision: 0.831800, valid loss: 157.500184
epoch: 581, train precision: 0.986111, train loss: 12.893893, valid precision: 0.842400, valid loss: 140.923503
epoch: 582, train precision: 0.983756, train loss: 14.070307, valid precision: 0.836400, valid loss: 154.265534
epoch: 583, train precision: 0.982622, train loss: 14.370648, valid precision: 0.837800, valid loss: 146.343121
epoch: 584, train precision: 0.986778, train loss: 12.698874, valid precision: 0.837400, valid loss: 151.106459
epoch: 585, train precision: 0.983667, train loss: 14.503340, valid precision: 0.834800, valid loss: 155.020727
epoch: 586, train precision: 0.988933, train loss: 11.858669, valid precision: 0.845600, valid loss: 149.194748
epoch: 587, train precision: 0.986644, train loss: 12.902842, valid precision: 0.838600, valid loss: 150.993431
epoch: 588, train precision: 0.984600, train loss: 13.570644, valid precision: 0.833400, valid loss: 150.180600
epoch: 589, train precision: 0.987400, train loss: 12.603383, valid precision: 0.842600, valid loss: 143.248105
epoch: 590, train precision: 0.980178, train loss: 15.733018, valid precision: 0.830600, valid loss: 157.749648
epoch: 591, train precision: 0.983689, train loss: 13.991804, valid precision: 0.837600, valid loss: 149.138266
epoch: 592, train precision: 0.980911, train loss: 15.309572, valid precision: 0.832600, valid loss: 155.339901
epoch: 593, train precision: 0.988911, train loss: 11.905354, valid precision: 0.848800, valid loss: 147.879000
epoch: 594, train precision: 0.983933, train loss: 13.818436, valid precision: 0.837000, valid loss: 148.671849
epoch: 595, train precision: 0.986489, train loss: 12.837472, valid precision: 0.839800, valid loss: 147.143364
epoch: 596, train precision: 0.988556, train loss: 12.049077, valid precision: 0.838600, valid loss: 143.927921
epoch: 597, train precision: 0.982022, train loss: 14.572203, valid precision: 0.840200, valid loss: 145.232791
epoch: 598, train precision: 0.980444, train loss: 15.344541, valid precision: 0.835000, valid loss: 154.676403
epoch: 599, train precision: 0.986444, train loss: 13.264854, valid precision: 0.836600, valid loss: 162.213374
epoch: 600, train precision: 0.985111, train loss: 13.395516, valid precision: 0.840400, valid loss: 152.430834
epoch: 601, train precision: 0.983733, train loss: 13.874743, valid precision: 0.837600, valid loss: 155.794621
epoch: 602, train precision: 0.986867, train loss: 13.215052, valid precision: 0.839800, valid loss: 156.659088
epoch: 603, train precision: 0.983533, train loss: 13.831554, valid precision: 0.839400, valid loss: 148.607746
epoch: 604, train precision: 0.986000, train loss: 12.946005, valid precision: 0.839600, valid loss: 154.080092
epoch: 605, train precision: 0.985311, train loss: 13.543051, valid precision: 0.836200, valid loss: 150.922142
epoch: 606, train precision: 0.983400, train loss: 14.073790, valid precision: 0.834600, valid loss: 149.492823
epoch: 607, train precision: 0.985444, train loss: 13.246414, valid precision: 0.838400, valid loss: 160.612146
epoch: 608, train precision: 0.986644, train loss: 13.150101, valid precision: 0.839200, valid loss: 150.823270
epoch: 609, train precision: 0.986444, train loss: 12.812173, valid precision: 0.832000, valid loss: 148.654167
epoch: 610, train precision: 0.978978, train loss: 16.483406, valid precision: 0.829400, valid loss: 164.908267
epoch: 611, train precision: 0.983844, train loss: 14.402597, valid precision: 0.837200, valid loss: 159.765626
epoch: 612, train precision: 0.983267, train loss: 14.266274, valid precision: 0.830600, valid loss: 162.489312
epoch: 613, train precision: 0.982533, train loss: 14.760127, valid precision: 0.835800, valid loss: 160.874632
epoch: 614, train precision: 0.986244, train loss: 13.495365, valid precision: 0.835200, valid loss: 149.747549
epoch: 615, train precision: 0.987978, train loss: 12.440236, valid precision: 0.839000, valid loss: 151.454336
epoch: 616, train precision: 0.986622, train loss: 12.970957, valid precision: 0.831600, valid loss: 153.789584
epoch: 617, train precision: 0.987733, train loss: 12.547789, valid precision: 0.839200, valid loss: 150.664912
epoch: 618, train precision: 0.987378, train loss: 12.719572, valid precision: 0.835400, valid loss: 150.318907
epoch: 619, train precision: 0.983622, train loss: 14.626060, valid precision: 0.828800, valid loss: 169.253143
epoch: 620, train precision: 0.983733, train loss: 14.194221, valid precision: 0.828800, valid loss: 157.556762
epoch: 621, train precision: 0.985956, train loss: 13.167038, valid precision: 0.834000, valid loss: 155.811088
epoch: 622, train precision: 0.986244, train loss: 13.198274, valid precision: 0.839600, valid loss: 152.045986
epoch: 623, train precision: 0.989378, train loss: 11.948103, valid precision: 0.837200, valid loss: 149.728392
epoch: 624, train precision: 0.979711, train loss: 16.450205, valid precision: 0.827400, valid loss: 173.070399
epoch: 625, train precision: 0.985667, train loss: 13.363518, valid precision: 0.838800, valid loss: 158.243296
epoch: 626, train precision: 0.982311, train loss: 14.860042, valid precision: 0.830400, valid loss: 154.511840
epoch: 627, train precision: 0.981467, train loss: 15.404720, valid precision: 0.834400, valid loss: 157.109397
epoch: 628, train precision: 0.986489, train loss: 12.982523, valid precision: 0.841000, valid loss: 151.267046
epoch: 629, train precision: 0.988356, train loss: 12.558116, valid precision: 0.841800, valid loss: 143.376290
epoch: 630, train precision: 0.986622, train loss: 13.344067, valid precision: 0.830000, valid loss: 155.895310
epoch: 631, train precision: 0.980667, train loss: 15.545674, valid precision: 0.829400, valid loss: 165.213474
epoch: 632, train precision: 0.983978, train loss: 14.284731, valid precision: 0.843800, valid loss: 152.279012
epoch: 633, train precision: 0.988711, train loss: 12.398609, valid precision: 0.840400, valid loss: 154.872081
epoch: 634, train precision: 0.986600, train loss: 13.016650, valid precision: 0.840200, valid loss: 158.011672
epoch: 635, train precision: 0.986222, train loss: 13.639726, valid precision: 0.837200, valid loss: 155.739392
epoch: 636, train precision: 0.985200, train loss: 13.793577, valid precision: 0.835600, valid loss: 156.804888
epoch: 637, train precision: 0.984689, train loss: 14.187170, valid precision: 0.839000, valid loss: 157.739540
epoch: 638, train precision: 0.987622, train loss: 12.608288, valid precision: 0.841400, valid loss: 149.388645
epoch: 639, train precision: 0.984022, train loss: 14.298705, valid precision: 0.838600, valid loss: 148.788553
epoch: 640, train precision: 0.986022, train loss: 13.327332, valid precision: 0.836800, valid loss: 152.073811
epoch: 641, train precision: 0.987422, train loss: 12.916349, valid precision: 0.842800, valid loss: 159.110729
epoch: 642, train precision: 0.987244, train loss: 13.192071, valid precision: 0.843400, valid loss: 154.399176
epoch: 643, train precision: 0.983644, train loss: 14.196106, valid precision: 0.835200, valid loss: 161.511413
epoch: 644, train precision: 0.982156, train loss: 15.186634, valid precision: 0.842000, valid loss: 167.593588
epoch: 645, train precision: 0.986111, train loss: 13.355507, valid precision: 0.845600, valid loss: 145.195774
epoch: 646, train precision: 0.984822, train loss: 13.864628, valid precision: 0.835400, valid loss: 150.283922
epoch: 647, train precision: 0.980533, train loss: 15.842474, valid precision: 0.842200, valid loss: 158.366158
epoch: 648, train precision: 0.986933, train loss: 13.147119, valid precision: 0.841800, valid loss: 156.254343
epoch: 649, train precision: 0.985222, train loss: 13.788442, valid precision: 0.837600, valid loss: 148.799417
epoch: 650, train precision: 0.988511, train loss: 12.555281, valid precision: 0.840200, valid loss: 159.574997
epoch: 651, train precision: 0.982022, train loss: 15.114520, valid precision: 0.842600, valid loss: 144.811867
epoch: 652, train precision: 0.985222, train loss: 13.846411, valid precision: 0.834800, valid loss: 154.064634
epoch: 653, train precision: 0.985289, train loss: 13.713069, valid precision: 0.838400, valid loss: 151.447908
epoch: 654, train precision: 0.979533, train loss: 16.560128, valid precision: 0.833800, valid loss: 161.784664
epoch: 655, train precision: 0.988467, train loss: 12.572088, valid precision: 0.841200, valid loss: 148.969847
epoch: 656, train precision: 0.984867, train loss: 13.540079, valid precision: 0.839200, valid loss: 153.966930
epoch: 657, train precision: 0.984156, train loss: 14.433956, valid precision: 0.834400, valid loss: 159.079459
epoch: 658, train precision: 0.983644, train loss: 14.606931, valid precision: 0.833400, valid loss: 154.390391
epoch: 659, train precision: 0.985933, train loss: 13.339904, valid precision: 0.830800, valid loss: 156.645866
epoch: 660, train precision: 0.985333, train loss: 13.828885, valid precision: 0.838000, valid loss: 152.201651
epoch: 661, train precision: 0.986000, train loss: 13.578655, valid precision: 0.839200, valid loss: 165.294470
epoch: 662, train precision: 0.988689, train loss: 12.242393, valid precision: 0.838200, valid loss: 155.264766
epoch: 663, train precision: 0.985222, train loss: 13.760016, valid precision: 0.833000, valid loss: 157.799731
epoch: 664, train precision: 0.987822, train loss: 12.571317, valid precision: 0.835800, valid loss: 158.869772
epoch: 665, train precision: 0.986067, train loss: 13.510201, valid precision: 0.838000, valid loss: 159.096483
epoch: 666, train precision: 0.982911, train loss: 14.818990, valid precision: 0.830400, valid loss: 157.308763
epoch: 667, train precision: 0.984067, train loss: 14.285033, valid precision: 0.837400, valid loss: 161.157895
epoch: 668, train precision: 0.983889, train loss: 14.297482, valid precision: 0.835200, valid loss: 161.172433
epoch: 669, train precision: 0.984733, train loss: 14.198706, valid precision: 0.836000, valid loss: 150.239683
epoch: 670, train precision: 0.982244, train loss: 15.051261, valid precision: 0.832400, valid loss: 155.674309
epoch: 671, train precision: 0.983889, train loss: 14.220648, valid precision: 0.837800, valid loss: 155.766349
epoch: 672, train precision: 0.983467, train loss: 14.784852, valid precision: 0.832400, valid loss: 156.568110
epoch: 673, train precision: 0.985911, train loss: 13.406072, valid precision: 0.838400, valid loss: 156.638040
epoch: 674, train precision: 0.983578, train loss: 14.550968, valid precision: 0.838600, valid loss: 163.388663
epoch: 675, train precision: 0.987911, train loss: 12.909313, valid precision: 0.834800, valid loss: 160.145627
epoch: 676, train precision: 0.987600, train loss: 12.983619, valid precision: 0.838000, valid loss: 163.625166
epoch: 677, train precision: 0.985867, train loss: 13.807232, valid precision: 0.839800, valid loss: 165.899910
epoch: 678, train precision: 0.986311, train loss: 13.874694, valid precision: 0.842000, valid loss: 157.002361
epoch: 679, train precision: 0.983556, train loss: 14.806216, valid precision: 0.832600, valid loss: 151.402471
epoch: 680, train precision: 0.984400, train loss: 14.114229, valid precision: 0.840000, valid loss: 156.286695
epoch: 681, train precision: 0.981933, train loss: 15.685675, valid precision: 0.832200, valid loss: 160.650924
epoch: 682, train precision: 0.987644, train loss: 12.900707, valid precision: 0.839600, valid loss: 153.619878
epoch: 683, train precision: 0.984733, train loss: 14.134429, valid precision: 0.832800, valid loss: 163.358204
epoch: 684, train precision: 0.985756, train loss: 13.657326, valid precision: 0.836400, valid loss: 151.898554
epoch: 685, train precision: 0.985333, train loss: 13.857833, valid precision: 0.836800, valid loss: 155.706398
epoch: 686, train precision: 0.984067, train loss: 14.695525, valid precision: 0.837200, valid loss: 164.917171
epoch: 687, train precision: 0.984711, train loss: 13.940244, valid precision: 0.843000, valid loss: 155.975338
epoch: 688, train precision: 0.985022, train loss: 14.330087, valid precision: 0.838000, valid loss: 161.534851
epoch: 689, train precision: 0.984200, train loss: 14.700687, valid precision: 0.835400, valid loss: 158.427624
epoch: 690, train precision: 0.982556, train loss: 14.829739, valid precision: 0.830600, valid loss: 161.541237
epoch: 691, train precision: 0.980844, train loss: 15.517494, valid precision: 0.831800, valid loss: 157.400464
epoch: 692, train precision: 0.984756, train loss: 13.966068, valid precision: 0.837400, valid loss: 155.229419
epoch: 693, train precision: 0.987956, train loss: 12.789952, valid precision: 0.842000, valid loss: 155.761596
epoch: 694, train precision: 0.984911, train loss: 14.102748, valid precision: 0.830400, valid loss: 158.636814
epoch: 695, train precision: 0.984711, train loss: 14.219765, valid precision: 0.835800, valid loss: 158.652211
epoch: 696, train precision: 0.984689, train loss: 14.112002, valid precision: 0.836800, valid loss: 160.725176
epoch: 697, train precision: 0.986422, train loss: 13.404770, valid precision: 0.837800, valid loss: 163.736006
epoch: 698, train precision: 0.988333, train loss: 12.704376, valid precision: 0.841400, valid loss: 163.538658
epoch: 699, train precision: 0.983422, train loss: 14.713166, valid precision: 0.839400, valid loss: 162.442809
epoch: 700, train precision: 0.986400, train loss: 13.339647, valid precision: 0.839800, valid loss: 153.293880
epoch: 701, train precision: 0.986378, train loss: 13.371302, valid precision: 0.840600, valid loss: 155.634895
epoch: 702, train precision: 0.989000, train loss: 12.342467, valid precision: 0.840600, valid loss: 155.040500
epoch: 703, train precision: 0.984644, train loss: 14.370514, valid precision: 0.835600, valid loss: 156.002518
epoch: 704, train precision: 0.985356, train loss: 13.857984, valid precision: 0.834600, valid loss: 160.849674
epoch: 705, train precision: 0.985311, train loss: 13.982791, valid precision: 0.834000, valid loss: 149.826482
epoch: 706, train precision: 0.977067, train loss: 17.700450, valid precision: 0.830400, valid loss: 170.827563
epoch: 707, train precision: 0.986556, train loss: 13.373327, valid precision: 0.842600, valid loss: 153.244298
epoch: 708, train precision: 0.988178, train loss: 12.941006, valid precision: 0.841800, valid loss: 151.249083
epoch: 709, train precision: 0.985333, train loss: 13.921855, valid precision: 0.832600, valid loss: 163.170675
epoch: 710, train precision: 0.983311, train loss: 15.012036, valid precision: 0.838200, valid loss: 156.517098
epoch: 711, train precision: 0.983689, train loss: 14.729132, valid precision: 0.835000, valid loss: 165.402927
epoch: 712, train precision: 0.982733, train loss: 15.047637, valid precision: 0.829800, valid loss: 158.330055
epoch: 713, train precision: 0.987778, train loss: 12.928971, valid precision: 0.833600, valid loss: 153.629582
epoch: 714, train precision: 0.984533, train loss: 14.661891, valid precision: 0.831400, valid loss: 163.288195
epoch: 715, train precision: 0.984444, train loss: 14.623329, valid precision: 0.830600, valid loss: 177.346255
epoch: 716, train precision: 0.987867, train loss: 12.818251, valid precision: 0.836000, valid loss: 161.149538
epoch: 717, train precision: 0.984289, train loss: 14.453354, valid precision: 0.836200, valid loss: 164.402773
epoch: 718, train precision: 0.983600, train loss: 14.802084, valid precision: 0.831200, valid loss: 161.038709
epoch: 719, train precision: 0.986289, train loss: 13.564925, valid precision: 0.839600, valid loss: 153.217826
epoch: 720, train precision: 0.989733, train loss: 12.231814, valid precision: 0.841200, valid loss: 155.626509
epoch: 721, train precision: 0.987333, train loss: 13.304542, valid precision: 0.843200, valid loss: 159.525813
epoch: 722, train precision: 0.987089, train loss: 13.594408, valid precision: 0.835000, valid loss: 154.073708
epoch: 723, train precision: 0.986444, train loss: 13.532535, valid precision: 0.838400, valid loss: 152.903528
epoch: 724, train precision: 0.984244, train loss: 14.935905, valid precision: 0.834400, valid loss: 166.078084
epoch: 725, train precision: 0.986600, train loss: 13.449275, valid precision: 0.837400, valid loss: 161.238359
epoch: 726, train precision: 0.985289, train loss: 14.216461, valid precision: 0.838400, valid loss: 164.046988
epoch: 727, train precision: 0.986444, train loss: 14.023600, valid precision: 0.839200, valid loss: 162.891752
epoch: 728, train precision: 0.984022, train loss: 14.606327, valid precision: 0.833000, valid loss: 153.283677
epoch: 729, train precision: 0.986244, train loss: 14.061410, valid precision: 0.843600, valid loss: 161.773773
epoch: 730, train precision: 0.987000, train loss: 13.502935, valid precision: 0.834000, valid loss: 158.891859
epoch: 731, train precision: 0.986311, train loss: 14.154974, valid precision: 0.836200, valid loss: 161.509262
epoch: 732, train precision: 0.985822, train loss: 14.043056, valid precision: 0.835800, valid loss: 163.202086
epoch: 733, train precision: 0.986467, train loss: 13.584093, valid precision: 0.838400, valid loss: 170.278102
epoch: 734, train precision: 0.985378, train loss: 14.000236, valid precision: 0.837800, valid loss: 166.782831
epoch: 735, train precision: 0.975733, train loss: 18.122184, valid precision: 0.832600, valid loss: 166.736934
epoch: 736, train precision: 0.985956, train loss: 13.772126, valid precision: 0.845200, valid loss: 155.814445
epoch: 737, train precision: 0.981978, train loss: 15.514811, valid precision: 0.835600, valid loss: 161.879457
epoch: 738, train precision: 0.981022, train loss: 16.014476, valid precision: 0.833600, valid loss: 170.534318
epoch: 739, train precision: 0.984022, train loss: 15.119247, valid precision: 0.833800, valid loss: 176.149080
epoch: 740, train precision: 0.987933, train loss: 13.209146, valid precision: 0.839000, valid loss: 173.135906
epoch: 741, train precision: 0.987156, train loss: 13.469202, valid precision: 0.841800, valid loss: 148.752215
epoch: 742, train precision: 0.985800, train loss: 13.779369, valid precision: 0.841800, valid loss: 164.006954
epoch: 743, train precision: 0.984844, train loss: 14.008896, valid precision: 0.834000, valid loss: 159.639881
epoch: 744, train precision: 0.988867, train loss: 12.565044, valid precision: 0.839000, valid loss: 166.724997
epoch: 745, train precision: 0.986933, train loss: 13.463871, valid precision: 0.836000, valid loss: 168.196005
epoch: 746, train precision: 0.987556, train loss: 13.152302, valid precision: 0.840600, valid loss: 161.007303
epoch: 747, train precision: 0.987378, train loss: 13.609134, valid precision: 0.838800, valid loss: 153.680130
epoch: 748, train precision: 0.980822, train loss: 16.024097, valid precision: 0.832200, valid loss: 162.882208
epoch: 749, train precision: 0.986289, train loss: 13.844458, valid precision: 0.830800, valid loss: 163.518926
epoch: 750, train precision: 0.987400, train loss: 13.441334, valid precision: 0.837600, valid loss: 159.374112
epoch: 751, train precision: 0.984200, train loss: 15.010832, valid precision: 0.837800, valid loss: 169.727888
epoch: 752, train precision: 0.983022, train loss: 15.671620, valid precision: 0.833400, valid loss: 174.557764
epoch: 753, train precision: 0.980978, train loss: 16.087905, valid precision: 0.828800, valid loss: 179.530113
epoch: 754, train precision: 0.985511, train loss: 14.163283, valid precision: 0.834600, valid loss: 166.898721
epoch: 755, train precision: 0.985800, train loss: 14.033140, valid precision: 0.831400, valid loss: 173.182257
epoch: 756, train precision: 0.986733, train loss: 13.861640, valid precision: 0.833200, valid loss: 160.185041
epoch: 757, train precision: 0.989200, train loss: 12.681983, valid precision: 0.841800, valid loss: 155.878080
epoch: 758, train precision: 0.981600, train loss: 16.266007, valid precision: 0.835000, valid loss: 172.749835
epoch: 759, train precision: 0.982933, train loss: 15.069223, valid precision: 0.835400, valid loss: 167.561655
epoch: 760, train precision: 0.986644, train loss: 13.853446, valid precision: 0.834600, valid loss: 170.488197
epoch: 761, train precision: 0.984556, train loss: 14.411092, valid precision: 0.824800, valid loss: 167.436212
epoch: 762, train precision: 0.986756, train loss: 13.531682, valid precision: 0.833000, valid loss: 160.165866
epoch: 763, train precision: 0.988511, train loss: 13.009283, valid precision: 0.833600, valid loss: 158.617796
epoch: 764, train precision: 0.987556, train loss: 13.160024, valid precision: 0.835200, valid loss: 168.779538
epoch: 765, train precision: 0.984333, train loss: 14.806975, valid precision: 0.840000, valid loss: 172.116429
epoch: 766, train precision: 0.985289, train loss: 14.570446, valid precision: 0.839600, valid loss: 157.954924
epoch: 767, train precision: 0.982356, train loss: 15.571790, valid precision: 0.832800, valid loss: 159.249792
epoch: 768, train precision: 0.984289, train loss: 14.358193, valid precision: 0.831200, valid loss: 157.228880
epoch: 769, train precision: 0.988578, train loss: 12.763948, valid precision: 0.835400, valid loss: 155.642252
epoch: 770, train precision: 0.986667, train loss: 13.746510, valid precision: 0.841200, valid loss: 161.066898
epoch: 771, train precision: 0.985467, train loss: 14.400192, valid precision: 0.838000, valid loss: 159.448451
epoch: 772, train precision: 0.979756, train loss: 16.741679, valid precision: 0.831800, valid loss: 168.858802
epoch: 773, train precision: 0.987644, train loss: 13.204386, valid precision: 0.834600, valid loss: 166.653516
epoch: 774, train precision: 0.983222, train loss: 15.607571, valid precision: 0.835800, valid loss: 166.359519
epoch: 775, train precision: 0.987800, train loss: 13.188285, valid precision: 0.842200, valid loss: 158.955632
epoch: 776, train precision: 0.984311, train loss: 15.275193, valid precision: 0.838400, valid loss: 164.987004
epoch: 777, train precision: 0.987511, train loss: 13.567225, valid precision: 0.838600, valid loss: 153.835012
epoch: 778, train precision: 0.983000, train loss: 15.294923, valid precision: 0.832200, valid loss: 161.285947
epoch: 779, train precision: 0.987489, train loss: 13.440714, valid precision: 0.837800, valid loss: 150.955101
epoch: 780, train precision: 0.986889, train loss: 13.652070, valid precision: 0.839600, valid loss: 154.075599
epoch: 781, train precision: 0.981022, train loss: 16.393473, valid precision: 0.831600, valid loss: 160.859892
epoch: 782, train precision: 0.984267, train loss: 14.635630, valid precision: 0.834200, valid loss: 162.712398
epoch: 783, train precision: 0.982933, train loss: 15.139897, valid precision: 0.831800, valid loss: 156.854880
epoch: 784, train precision: 0.987933, train loss: 13.232311, valid precision: 0.835600, valid loss: 156.964221
epoch: 785, train precision: 0.988378, train loss: 13.161929, valid precision: 0.834200, valid loss: 160.915831
epoch: 786, train precision: 0.984133, train loss: 14.866336, valid precision: 0.836000, valid loss: 161.408486
epoch: 787, train precision: 0.984956, train loss: 14.175196, valid precision: 0.839400, valid loss: 152.622167
epoch: 788, train precision: 0.981978, train loss: 15.948890, valid precision: 0.837000, valid loss: 152.719336
epoch: 789, train precision: 0.987244, train loss: 13.344965, valid precision: 0.834800, valid loss: 159.054435
epoch: 790, train precision: 0.987244, train loss: 13.556391, valid precision: 0.842600, valid loss: 157.664584
epoch: 791, train precision: 0.986333, train loss: 14.213882, valid precision: 0.842800, valid loss: 171.708540
epoch: 792, train precision: 0.984756, train loss: 14.608392, valid precision: 0.840600, valid loss: 153.096862
epoch: 793, train precision: 0.986378, train loss: 13.699936, valid precision: 0.844400, valid loss: 154.867491
epoch: 794, train precision: 0.987889, train loss: 13.097999, valid precision: 0.839200, valid loss: 155.111295
epoch: 795, train precision: 0.984400, train loss: 15.579120, valid precision: 0.839200, valid loss: 162.437265
epoch: 796, train precision: 0.988222, train loss: 13.077704, valid precision: 0.849000, valid loss: 147.992098
epoch: 797, train precision: 0.984733, train loss: 14.518691, valid precision: 0.843600, valid loss: 162.118145
epoch: 798, train precision: 0.989089, train loss: 12.823655, valid precision: 0.841600, valid loss: 158.799678
epoch: 799, train precision: 0.987556, train loss: 13.805182, valid precision: 0.843000, valid loss: 157.512322
epoch: 800, train precision: 0.985667, train loss: 14.140770, valid precision: 0.838400, valid loss: 152.076276
epoch: 801, train precision: 0.988378, train loss: 13.248179, valid precision: 0.840600, valid loss: 156.178770
epoch: 802, train precision: 0.985422, train loss: 14.253210, valid precision: 0.841400, valid loss: 156.634040
epoch: 803, train precision: 0.985178, train loss: 14.595144, valid precision: 0.839800, valid loss: 155.893083
epoch: 804, train precision: 0.983578, train loss: 15.151225, valid precision: 0.833400, valid loss: 159.442527
epoch: 805, train precision: 0.981867, train loss: 15.965625, valid precision: 0.832000, valid loss: 159.561408
epoch: 806, train precision: 0.984889, train loss: 14.619863, valid precision: 0.831800, valid loss: 167.908398
epoch: 807, train precision: 0.987978, train loss: 13.296147, valid precision: 0.839200, valid loss: 162.497501
epoch: 808, train precision: 0.983378, train loss: 15.271406, valid precision: 0.832800, valid loss: 160.696743
epoch: 809, train precision: 0.984467, train loss: 14.886832, valid precision: 0.836800, valid loss: 158.739661
epoch: 810, train precision: 0.986978, train loss: 13.485973, valid precision: 0.841400, valid loss: 155.906188
epoch: 811, train precision: 0.987711, train loss: 13.470949, valid precision: 0.837200, valid loss: 163.745471
epoch: 812, train precision: 0.985022, train loss: 14.782505, valid precision: 0.839400, valid loss: 163.508847
epoch: 813, train precision: 0.983800, train loss: 15.298956, valid precision: 0.838200, valid loss: 166.703401
epoch: 814, train precision: 0.982089, train loss: 15.664153, valid precision: 0.833600, valid loss: 155.562304
epoch: 815, train precision: 0.985111, train loss: 14.707190, valid precision: 0.842000, valid loss: 166.312853
epoch: 816, train precision: 0.985889, train loss: 13.845103, valid precision: 0.841600, valid loss: 151.427268
epoch: 817, train precision: 0.985733, train loss: 14.273301, valid precision: 0.831400, valid loss: 163.621889
epoch: 818, train precision: 0.988356, train loss: 13.314234, valid precision: 0.840200, valid loss: 153.280279
epoch: 819, train precision: 0.982511, train loss: 15.921354, valid precision: 0.830600, valid loss: 168.639729
epoch: 820, train precision: 0.986889, train loss: 13.545686, valid precision: 0.838400, valid loss: 158.442054
epoch: 821, train precision: 0.987400, train loss: 13.244331, valid precision: 0.829600, valid loss: 157.748833
epoch: 822, train precision: 0.986267, train loss: 13.956712, valid precision: 0.837200, valid loss: 155.883588
epoch: 823, train precision: 0.985267, train loss: 14.543245, valid precision: 0.835200, valid loss: 166.555842
epoch: 824, train precision: 0.987511, train loss: 13.184149, valid precision: 0.841600, valid loss: 152.603510
epoch: 825, train precision: 0.986644, train loss: 13.980017, valid precision: 0.834600, valid loss: 156.660677
epoch: 826, train precision: 0.985467, train loss: 14.636211, valid precision: 0.832000, valid loss: 160.355707
epoch: 827, train precision: 0.986067, train loss: 14.162595, valid precision: 0.839000, valid loss: 157.621980
epoch: 828, train precision: 0.974311, train loss: 19.906631, valid precision: 0.826800, valid loss: 169.751751
epoch: 829, train precision: 0.989378, train loss: 12.728351, valid precision: 0.842400, valid loss: 150.411766
epoch: 830, train precision: 0.986178, train loss: 14.201409, valid precision: 0.833600, valid loss: 162.876169
epoch: 831, train precision: 0.984667, train loss: 15.430673, valid precision: 0.840200, valid loss: 166.973938
epoch: 832, train precision: 0.984822, train loss: 14.759446, valid precision: 0.832600, valid loss: 171.685240
epoch: 833, train precision: 0.988667, train loss: 13.277428, valid precision: 0.836200, valid loss: 162.849118
epoch: 834, train precision: 0.983467, train loss: 15.294242, valid precision: 0.837200, valid loss: 162.284874
epoch: 835, train precision: 0.981356, train loss: 16.253650, valid precision: 0.836800, valid loss: 167.126975
epoch: 836, train precision: 0.984289, train loss: 15.074767, valid precision: 0.841400, valid loss: 161.319103
epoch: 837, train precision: 0.985733, train loss: 14.480650, valid precision: 0.836000, valid loss: 160.361511
epoch: 838, train precision: 0.987867, train loss: 13.541967, valid precision: 0.837000, valid loss: 169.948099
epoch: 839, train precision: 0.987178, train loss: 13.567357, valid precision: 0.835800, valid loss: 163.513595
epoch: 840, train precision: 0.982556, train loss: 15.375050, valid precision: 0.833800, valid loss: 175.941451
epoch: 841, train precision: 0.985089, train loss: 14.676436, valid precision: 0.833200, valid loss: 167.382254
epoch: 842, train precision: 0.984556, train loss: 15.288693, valid precision: 0.833400, valid loss: 175.864533
epoch: 843, train precision: 0.985933, train loss: 14.250218, valid precision: 0.834800, valid loss: 167.080712
epoch: 844, train precision: 0.986911, train loss: 14.213258, valid precision: 0.839200, valid loss: 165.803356
epoch: 845, train precision: 0.986311, train loss: 14.002095, valid precision: 0.843800, valid loss: 161.972584
epoch: 846, train precision: 0.987622, train loss: 13.615414, valid precision: 0.840000, valid loss: 168.242509
epoch: 847, train precision: 0.986333, train loss: 14.441732, valid precision: 0.830200, valid loss: 174.052170
epoch: 848, train precision: 0.987867, train loss: 13.594305, valid precision: 0.838400, valid loss: 162.527550
epoch: 849, train precision: 0.989622, train loss: 12.560477, valid precision: 0.842600, valid loss: 158.966009
epoch: 850, train precision: 0.987022, train loss: 13.762930, valid precision: 0.833600, valid loss: 166.873706
epoch: 851, train precision: 0.983311, train loss: 15.757653, valid precision: 0.830600, valid loss: 166.558706
epoch: 852, train precision: 0.986733, train loss: 13.978228, valid precision: 0.833400, valid loss: 167.135727
epoch: 853, train precision: 0.986711, train loss: 13.893031, valid precision: 0.839000, valid loss: 164.277364
epoch: 854, train precision: 0.982867, train loss: 15.810065, valid precision: 0.833800, valid loss: 165.268246
epoch: 855, train precision: 0.990244, train loss: 12.671563, valid precision: 0.841600, valid loss: 164.544686
epoch: 856, train precision: 0.986933, train loss: 13.810013, valid precision: 0.840600, valid loss: 151.593609
epoch: 857, train precision: 0.987200, train loss: 13.425034, valid precision: 0.838800, valid loss: 161.369693
epoch: 858, train precision: 0.985956, train loss: 14.205460, valid precision: 0.840600, valid loss: 157.808218
epoch: 859, train precision: 0.987600, train loss: 14.053691, valid precision: 0.835600, valid loss: 179.001368
epoch: 860, train precision: 0.986467, train loss: 14.162760, valid precision: 0.833800, valid loss: 163.858961
epoch: 861, train precision: 0.984889, train loss: 14.901782, valid precision: 0.838400, valid loss: 161.589855
epoch: 862, train precision: 0.984511, train loss: 15.027657, valid precision: 0.836200, valid loss: 164.189693
epoch: 863, train precision: 0.986444, train loss: 14.211629, valid precision: 0.835200, valid loss: 167.105200
epoch: 864, train precision: 0.989511, train loss: 13.001394, valid precision: 0.846400, valid loss: 174.189040
epoch: 865, train precision: 0.987178, train loss: 14.110921, valid precision: 0.843200, valid loss: 183.952031
epoch: 866, train precision: 0.987867, train loss: 13.555610, valid precision: 0.835800, valid loss: 171.190868
epoch: 867, train precision: 0.988000, train loss: 13.477818, valid precision: 0.839000, valid loss: 162.019773
epoch: 868, train precision: 0.985578, train loss: 14.376164, valid precision: 0.831800, valid loss: 171.913181
epoch: 869, train precision: 0.988956, train loss: 13.041005, valid precision: 0.839000, valid loss: 163.269529
epoch: 870, train precision: 0.989467, train loss: 12.775927, valid precision: 0.840200, valid loss: 166.987719
epoch: 871, train precision: 0.986156, train loss: 13.875267, valid precision: 0.837600, valid loss: 163.541726
epoch: 872, train precision: 0.983022, train loss: 15.610930, valid precision: 0.833200, valid loss: 171.758637
epoch: 873, train precision: 0.982689, train loss: 15.654679, valid precision: 0.828000, valid loss: 168.926008
epoch: 874, train precision: 0.980533, train loss: 16.562161, valid precision: 0.830400, valid loss: 183.150709
epoch: 875, train precision: 0.980133, train loss: 16.715682, valid precision: 0.838800, valid loss: 161.891283
epoch: 876, train precision: 0.981111, train loss: 16.216550, valid precision: 0.830000, valid loss: 171.909492
epoch: 877, train precision: 0.987800, train loss: 13.514574, valid precision: 0.836600, valid loss: 164.613293
epoch: 878, train precision: 0.987933, train loss: 13.513026, valid precision: 0.844000, valid loss: 157.812405
epoch: 879, train precision: 0.983978, train loss: 15.036136, valid precision: 0.836400, valid loss: 149.808174
epoch: 880, train precision: 0.986422, train loss: 14.248435, valid precision: 0.841000, valid loss: 163.433512
epoch: 881, train precision: 0.987000, train loss: 13.988099, valid precision: 0.835200, valid loss: 177.423367
epoch: 882, train precision: 0.988333, train loss: 13.437809, valid precision: 0.833800, valid loss: 163.992294
epoch: 883, train precision: 0.989289, train loss: 12.804605, valid precision: 0.833400, valid loss: 163.827440
epoch: 884, train precision: 0.983667, train loss: 15.690340, valid precision: 0.829400, valid loss: 179.398792
epoch: 885, train precision: 0.982089, train loss: 16.026273, valid precision: 0.837400, valid loss: 158.417733
epoch: 886, train precision: 0.989022, train loss: 13.038841, valid precision: 0.838600, valid loss: 159.603210
epoch: 887, train precision: 0.983911, train loss: 15.392262, valid precision: 0.836600, valid loss: 167.651471
epoch: 888, train precision: 0.982400, train loss: 16.058589, valid precision: 0.833000, valid loss: 166.314341
epoch: 889, train precision: 0.989089, train loss: 13.244191, valid precision: 0.837000, valid loss: 156.133156
epoch: 890, train precision: 0.984489, train loss: 15.171703, valid precision: 0.835200, valid loss: 167.534515
epoch: 891, train precision: 0.988600, train loss: 13.470514, valid precision: 0.834000, valid loss: 165.515544
epoch: 892, train precision: 0.986933, train loss: 13.897121, valid precision: 0.834000, valid loss: 172.024392
epoch: 893, train precision: 0.988622, train loss: 13.578149, valid precision: 0.836000, valid loss: 163.050689
epoch: 894, train precision: 0.986733, train loss: 14.314121, valid precision: 0.834200, valid loss: 177.197536
epoch: 895, train precision: 0.984733, train loss: 14.909985, valid precision: 0.832000, valid loss: 174.302752
epoch: 896, train precision: 0.983422, train loss: 15.316619, valid precision: 0.833000, valid loss: 166.028012
epoch: 897, train precision: 0.987156, train loss: 13.949477, valid precision: 0.829600, valid loss: 169.465027
epoch: 898, train precision: 0.988400, train loss: 13.582878, valid precision: 0.836800, valid loss: 165.225832
epoch: 899, train precision: 0.985800, train loss: 14.301092, valid precision: 0.843400, valid loss: 160.314292
epoch: 900, train precision: 0.984422, train loss: 15.240480, valid precision: 0.839000, valid loss: 171.919671
epoch: 901, train precision: 0.982800, train loss: 15.841506, valid precision: 0.834400, valid loss: 171.729204
epoch: 902, train precision: 0.980556, train loss: 17.173252, valid precision: 0.827400, valid loss: 179.430515
epoch: 903, train precision: 0.984622, train loss: 14.929650, valid precision: 0.830800, valid loss: 170.882472
epoch: 904, train precision: 0.983756, train loss: 15.424782, valid precision: 0.835800, valid loss: 177.337239
epoch: 905, train precision: 0.985178, train loss: 14.814173, valid precision: 0.836400, valid loss: 163.116313
epoch: 906, train precision: 0.988067, train loss: 13.539359, valid precision: 0.835800, valid loss: 166.071797
epoch: 907, train precision: 0.988133, train loss: 13.831636, valid precision: 0.835200, valid loss: 167.715405
epoch: 908, train precision: 0.987089, train loss: 14.011011, valid precision: 0.836000, valid loss: 162.972208
epoch: 909, train precision: 0.986267, train loss: 14.309218, valid precision: 0.838200, valid loss: 169.196958
epoch: 910, train precision: 0.989578, train loss: 13.085762, valid precision: 0.838600, valid loss: 161.960750
epoch: 911, train precision: 0.986889, train loss: 14.215121, valid precision: 0.836400, valid loss: 164.079719
epoch: 912, train precision: 0.986911, train loss: 14.070373, valid precision: 0.837200, valid loss: 168.852640
epoch: 913, train precision: 0.986222, train loss: 14.559991, valid precision: 0.841400, valid loss: 167.152641
epoch: 914, train precision: 0.982067, train loss: 16.381995, valid precision: 0.830400, valid loss: 173.515141
epoch: 915, train precision: 0.986200, train loss: 14.331925, valid precision: 0.836000, valid loss: 171.843297
epoch: 916, train precision: 0.991467, train loss: 12.082804, valid precision: 0.837200, valid loss: 173.816563
epoch: 917, train precision: 0.982133, train loss: 16.434029, valid precision: 0.826800, valid loss: 174.556208
epoch: 918, train precision: 0.985578, train loss: 14.720959, valid precision: 0.837600, valid loss: 171.712402
epoch: 919, train precision: 0.986911, train loss: 14.129952, valid precision: 0.839200, valid loss: 170.107468
epoch: 920, train precision: 0.984911, train loss: 14.970445, valid precision: 0.840000, valid loss: 162.339698
epoch: 921, train precision: 0.989089, train loss: 13.438400, valid precision: 0.837400, valid loss: 168.767123
epoch: 922, train precision: 0.987622, train loss: 14.011120, valid precision: 0.837800, valid loss: 178.377039
epoch: 923, train precision: 0.986156, train loss: 14.275681, valid precision: 0.834800, valid loss: 166.673888
epoch: 924, train precision: 0.984844, train loss: 15.136926, valid precision: 0.833200, valid loss: 169.806762
epoch: 925, train precision: 0.984956, train loss: 14.907582, valid precision: 0.832000, valid loss: 184.945781
epoch: 926, train precision: 0.985844, train loss: 14.562570, valid precision: 0.834000, valid loss: 166.414299
epoch: 927, train precision: 0.986400, train loss: 14.369234, valid precision: 0.842000, valid loss: 165.382289
epoch: 928, train precision: 0.987556, train loss: 13.959602, valid precision: 0.835400, valid loss: 178.260533
epoch: 929, train precision: 0.986000, train loss: 14.289847, valid precision: 0.837000, valid loss: 175.327370
epoch: 930, train precision: 0.983111, train loss: 15.347699, valid precision: 0.833400, valid loss: 167.403229
epoch: 931, train precision: 0.976222, train loss: 19.065079, valid precision: 0.827200, valid loss: 174.941475
epoch: 932, train precision: 0.986222, train loss: 14.166232, valid precision: 0.838200, valid loss: 170.531486
epoch: 933, train precision: 0.984378, train loss: 15.340326, valid precision: 0.842600, valid loss: 175.659296
epoch: 934, train precision: 0.987289, train loss: 13.857955, valid precision: 0.835600, valid loss: 175.030940
epoch: 935, train precision: 0.983556, train loss: 15.690851, valid precision: 0.839600, valid loss: 172.799040
epoch: 936, train precision: 0.988400, train loss: 13.317766, valid precision: 0.836800, valid loss: 178.069873
epoch: 937, train precision: 0.986733, train loss: 14.127304, valid precision: 0.843800, valid loss: 167.040300
epoch: 938, train precision: 0.989089, train loss: 13.254245, valid precision: 0.841800, valid loss: 171.183099
epoch: 939, train precision: 0.986889, train loss: 13.990695, valid precision: 0.845200, valid loss: 162.582658
epoch: 940, train precision: 0.986267, train loss: 14.528190, valid precision: 0.836600, valid loss: 166.085585
epoch: 941, train precision: 0.987400, train loss: 14.163287, valid precision: 0.836400, valid loss: 165.601142
epoch: 942, train precision: 0.980844, train loss: 16.527506, valid precision: 0.830800, valid loss: 170.142212
epoch: 943, train precision: 0.987933, train loss: 13.731588, valid precision: 0.839200, valid loss: 172.025602
epoch: 944, train precision: 0.987044, train loss: 14.233403, valid precision: 0.840000, valid loss: 177.138696
epoch: 945, train precision: 0.986778, train loss: 13.999094, valid precision: 0.841000, valid loss: 164.487011
epoch: 946, train precision: 0.984778, train loss: 14.996782, valid precision: 0.829000, valid loss: 163.362516
epoch: 947, train precision: 0.981800, train loss: 16.690966, valid precision: 0.833800, valid loss: 174.046473
epoch: 948, train precision: 0.984978, train loss: 15.276091, valid precision: 0.839600, valid loss: 167.591771
epoch: 949, train precision: 0.988267, train loss: 13.633213, valid precision: 0.836400, valid loss: 168.581937
epoch: 950, train precision: 0.982267, train loss: 16.543371, valid precision: 0.835600, valid loss: 170.953833
epoch: 951, train precision: 0.986533, train loss: 14.355937, valid precision: 0.840800, valid loss: 161.265624
epoch: 952, train precision: 0.988156, train loss: 13.461520, valid precision: 0.839000, valid loss: 175.629753
epoch: 953, train precision: 0.982067, train loss: 16.208562, valid precision: 0.832200, valid loss: 169.631277
epoch: 954, train precision: 0.988889, train loss: 13.596856, valid precision: 0.844400, valid loss: 176.113243
epoch: 955, train precision: 0.987400, train loss: 14.103674, valid precision: 0.839400, valid loss: 179.045728
epoch: 956, train precision: 0.988578, train loss: 13.779798, valid precision: 0.837600, valid loss: 175.267605
epoch: 957, train precision: 0.984533, train loss: 15.330616, valid precision: 0.839600, valid loss: 172.060586
epoch: 958, train precision: 0.985133, train loss: 15.224106, valid precision: 0.829200, valid loss: 191.789638
epoch: 959, train precision: 0.986822, train loss: 14.304480, valid precision: 0.839400, valid loss: 168.432038
epoch: 960, train precision: 0.987133, train loss: 14.068661, valid precision: 0.845400, valid loss: 168.162747
epoch: 961, train precision: 0.988222, train loss: 13.708622, valid precision: 0.841000, valid loss: 169.047215
epoch: 962, train precision: 0.988444, train loss: 13.574816, valid precision: 0.840600, valid loss: 169.037201
epoch: 963, train precision: 0.985756, train loss: 15.074714, valid precision: 0.835400, valid loss: 179.912857
epoch: 964, train precision: 0.985244, train loss: 14.704116, valid precision: 0.834800, valid loss: 166.104908
epoch: 965, train precision: 0.987756, train loss: 13.865643, valid precision: 0.835800, valid loss: 165.468544
epoch: 966, train precision: 0.986244, train loss: 14.430242, valid precision: 0.834000, valid loss: 163.487517
epoch: 967, train precision: 0.985533, train loss: 14.752358, valid precision: 0.835800, valid loss: 164.956395
epoch: 968, train precision: 0.983067, train loss: 16.548969, valid precision: 0.831800, valid loss: 182.706317
epoch: 969, train precision: 0.984289, train loss: 15.647801, valid precision: 0.832200, valid loss: 169.954621
epoch: 970, train precision: 0.986289, train loss: 14.733170, valid precision: 0.836200, valid loss: 172.823187
epoch: 971, train precision: 0.985044, train loss: 14.975173, valid precision: 0.837200, valid loss: 169.024240
epoch: 972, train precision: 0.981289, train loss: 16.727157, valid precision: 0.825600, valid loss: 181.982967
epoch: 973, train precision: 0.986333, train loss: 14.680620, valid precision: 0.831800, valid loss: 175.532460
epoch: 974, train precision: 0.985178, train loss: 15.108445, valid precision: 0.828800, valid loss: 164.918537
epoch: 975, train precision: 0.982200, train loss: 16.453751, valid precision: 0.829800, valid loss: 170.375943
epoch: 976, train precision: 0.986689, train loss: 14.320329, valid precision: 0.836600, valid loss: 166.389741
epoch: 977, train precision: 0.982311, train loss: 16.391086, valid precision: 0.828000, valid loss: 166.187000
epoch: 978, train precision: 0.983200, train loss: 15.888499, valid precision: 0.830800, valid loss: 172.146242
epoch: 979, train precision: 0.987711, train loss: 13.887273, valid precision: 0.838800, valid loss: 171.469844
epoch: 980, train precision: 0.985956, train loss: 14.259906, valid precision: 0.833800, valid loss: 163.380789
epoch: 981, train precision: 0.983333, train loss: 15.986860, valid precision: 0.827400, valid loss: 168.212900
epoch: 982, train precision: 0.985289, train loss: 14.848676, valid precision: 0.836200, valid loss: 164.117167
epoch: 983, train precision: 0.987044, train loss: 14.759363, valid precision: 0.831400, valid loss: 177.133755
epoch: 984, train precision: 0.987022, train loss: 14.832059, valid precision: 0.835800, valid loss: 183.864097
epoch: 985, train precision: 0.984600, train loss: 15.370355, valid precision: 0.837600, valid loss: 175.158972
epoch: 986, train precision: 0.986911, train loss: 14.226367, valid precision: 0.833000, valid loss: 182.640000
epoch: 987, train precision: 0.986400, train loss: 14.383587, valid precision: 0.837400, valid loss: 185.671660
epoch: 988, train precision: 0.984933, train loss: 15.631033, valid precision: 0.840200, valid loss: 177.763760
epoch: 989, train precision: 0.984667, train loss: 15.285572, valid precision: 0.835400, valid loss: 164.939296
epoch: 990, train precision: 0.987311, train loss: 14.147534, valid precision: 0.833400, valid loss: 184.476741
epoch: 991, train precision: 0.986244, train loss: 14.570875, valid precision: 0.833600, valid loss: 172.738459
epoch: 992, train precision: 0.985978, train loss: 14.737472, valid precision: 0.835000, valid loss: 174.368386
epoch: 993, train precision: 0.985200, train loss: 15.298088, valid precision: 0.836400, valid loss: 181.608610
epoch: 994, train precision: 0.989067, train loss: 13.081444, valid precision: 0.835200, valid loss: 166.664090
epoch: 995, train precision: 0.981689, train loss: 17.125900, valid precision: 0.830200, valid loss: 174.962779
epoch: 996, train precision: 0.985911, train loss: 15.051343, valid precision: 0.834200, valid loss: 167.440075
epoch: 997, train precision: 0.986378, train loss: 14.469689, valid precision: 0.833600, valid loss: 167.751573
epoch: 998, train precision: 0.986911, train loss: 14.493938, valid precision: 0.836800, valid loss: 169.468812
epoch: 999, train precision: 0.982933, train loss: 16.324640, valid precision: 0.829000, valid loss: 171.743837
epoch: 1000, train precision: 0.988489, train loss: 13.829198, valid precision: 0.837800, valid loss: 178.275194
epoch: 1001, train precision: 0.987000, train loss: 14.293947, valid precision: 0.833400, valid loss: 172.535717
epoch: 1002, train precision: 0.985756, train loss: 14.984960, valid precision: 0.833200, valid loss: 174.515512
epoch: 1003, train precision: 0.985156, train loss: 15.060570, valid precision: 0.834400, valid loss: 171.252393
epoch: 1004, train precision: 0.984000, train loss: 15.525639, valid precision: 0.831000, valid loss: 174.659540
epoch: 1005, train precision: 0.986733, train loss: 14.768195, valid precision: 0.837000, valid loss: 178.192070
epoch: 1006, train precision: 0.985444, train loss: 15.303387, valid precision: 0.831600, valid loss: 172.021175
epoch: 1007, train precision: 0.986511, train loss: 14.652739, valid precision: 0.832400, valid loss: 168.246872
epoch: 1008, train precision: 0.989556, train loss: 13.156123, valid precision: 0.834000, valid loss: 179.762008
epoch: 1009, train precision: 0.987467, train loss: 14.054949, valid precision: 0.835600, valid loss: 177.630516
epoch: 1010, train precision: 0.985689, train loss: 15.075034, valid precision: 0.832400, valid loss: 166.409175
epoch: 1011, train precision: 0.987111, train loss: 14.343993, valid precision: 0.829400, valid loss: 174.927703
epoch: 1012, train precision: 0.986378, train loss: 14.578582, valid precision: 0.838800, valid loss: 162.517400
epoch: 1013, train precision: 0.979689, train loss: 17.400023, valid precision: 0.833400, valid loss: 173.496457
epoch: 1014, train precision: 0.986267, train loss: 14.643114, valid precision: 0.840600, valid loss: 175.394855
epoch: 1015, train precision: 0.985778, train loss: 14.557025, valid precision: 0.834000, valid loss: 166.540836
epoch: 1016, train precision: 0.984089, train loss: 15.515487, valid precision: 0.834000, valid loss: 177.793378
epoch: 1017, train precision: 0.987000, train loss: 14.506800, valid precision: 0.829800, valid loss: 169.249203
epoch: 1018, train precision: 0.986111, train loss: 14.639603, valid precision: 0.833800, valid loss: 167.914321
epoch: 1019, train precision: 0.986933, train loss: 14.763826, valid precision: 0.833200, valid loss: 183.124765
epoch: 1020, train precision: 0.987756, train loss: 13.780165, valid precision: 0.834400, valid loss: 169.575493
epoch: 1021, train precision: 0.981711, train loss: 16.706564, valid precision: 0.832200, valid loss: 170.780524
epoch: 1022, train precision: 0.985911, train loss: 14.844676, valid precision: 0.827200, valid loss: 178.888199
epoch: 1023, train precision: 0.986778, train loss: 14.351480, valid precision: 0.833200, valid loss: 167.267028
epoch: 1024, train precision: 0.985222, train loss: 15.256656, valid precision: 0.836800, valid loss: 171.970930
epoch: 1025, train precision: 0.984333, train loss: 15.555832, valid precision: 0.834800, valid loss: 172.077744
epoch: 1026, train precision: 0.986044, train loss: 15.039256, valid precision: 0.832800, valid loss: 168.898177
epoch: 1027, train precision: 0.984156, train loss: 15.979084, valid precision: 0.831400, valid loss: 169.520203
epoch: 1028, train precision: 0.987156, train loss: 14.097293, valid precision: 0.832400, valid loss: 163.073018
epoch: 1029, train precision: 0.987711, train loss: 13.861193, valid precision: 0.829400, valid loss: 171.990325
epoch: 1030, train precision: 0.987778, train loss: 14.261236, valid precision: 0.833400, valid loss: 187.437912
epoch: 1031, train precision: 0.980667, train loss: 16.788715, valid precision: 0.823600, valid loss: 179.814914
epoch: 1032, train precision: 0.988244, train loss: 13.819800, valid precision: 0.829200, valid loss: 171.513676
epoch: 1033, train precision: 0.986200, train loss: 14.589659, valid precision: 0.831600, valid loss: 164.849786
epoch: 1034, train precision: 0.986644, train loss: 14.740242, valid precision: 0.837200, valid loss: 168.589809
epoch: 1035, train precision: 0.988578, train loss: 13.739349, valid precision: 0.837200, valid loss: 171.913456
epoch: 1036, train precision: 0.985800, train loss: 15.306929, valid precision: 0.832200, valid loss: 175.341488
epoch: 1037, train precision: 0.988356, train loss: 13.908385, valid precision: 0.832200, valid loss: 173.156578
epoch: 1038, train precision: 0.987956, train loss: 14.217328, valid precision: 0.838800, valid loss: 171.709770
epoch: 1039, train precision: 0.986222, train loss: 14.587249, valid precision: 0.838400, valid loss: 167.138796
epoch: 1040, train precision: 0.989267, train loss: 13.837113, valid precision: 0.843200, valid loss: 162.714160
epoch: 1041, train precision: 0.983778, train loss: 15.576275, valid precision: 0.836400, valid loss: 172.241137
epoch: 1042, train precision: 0.983222, train loss: 16.449005, valid precision: 0.836800, valid loss: 179.751449
epoch: 1043, train precision: 0.986644, train loss: 14.421224, valid precision: 0.835400, valid loss: 168.313961
epoch: 1044, train precision: 0.989267, train loss: 13.574656, valid precision: 0.839200, valid loss: 169.108662
epoch: 1045, train precision: 0.984156, train loss: 15.682109, valid precision: 0.835400, valid loss: 170.080041
epoch: 1046, train precision: 0.988644, train loss: 13.673268, valid precision: 0.838200, valid loss: 168.676484
epoch: 1047, train precision: 0.984889, train loss: 15.133711, valid precision: 0.830600, valid loss: 168.946505
epoch: 1048, train precision: 0.988622, train loss: 13.686338, valid precision: 0.837800, valid loss: 168.644213
epoch: 1049, train precision: 0.987244, train loss: 14.506304, valid precision: 0.831400, valid loss: 181.086248
epoch: 1050, train precision: 0.984067, train loss: 15.621218, valid precision: 0.831600, valid loss: 176.611410
epoch: 1051, train precision: 0.985022, train loss: 15.247083, valid precision: 0.832200, valid loss: 182.939918
epoch: 1052, train precision: 0.986889, train loss: 14.355034, valid precision: 0.833000, valid loss: 166.415076
epoch: 1053, train precision: 0.985689, train loss: 14.644504, valid precision: 0.835200, valid loss: 175.511423
epoch: 1054, train precision: 0.985600, train loss: 15.019564, valid precision: 0.835000, valid loss: 183.091932
epoch: 1055, train precision: 0.986289, train loss: 14.836978, valid precision: 0.833800, valid loss: 185.478843
epoch: 1056, train precision: 0.983311, train loss: 15.958844, valid precision: 0.834600, valid loss: 176.665855
epoch: 1057, train precision: 0.984067, train loss: 15.860788, valid precision: 0.830600, valid loss: 172.826465
epoch: 1058, train precision: 0.986089, train loss: 14.973445, valid precision: 0.835800, valid loss: 165.990344
epoch: 1059, train precision: 0.986044, train loss: 15.012754, valid precision: 0.838000, valid loss: 170.506749
epoch: 1060, train precision: 0.989844, train loss: 13.448623, valid precision: 0.839400, valid loss: 165.413928
epoch: 1061, train precision: 0.985467, train loss: 14.788628, valid precision: 0.837600, valid loss: 168.178310
epoch: 1062, train precision: 0.984444, train loss: 15.408704, valid precision: 0.836400, valid loss: 160.097488
epoch: 1063, train precision: 0.988089, train loss: 13.822535, valid precision: 0.838400, valid loss: 184.010120
epoch: 1064, train precision: 0.987444, train loss: 14.174666, valid precision: 0.838400, valid loss: 167.995272
epoch: 1065, train precision: 0.986800, train loss: 14.544835, valid precision: 0.838000, valid loss: 172.724592
epoch: 1066, train precision: 0.987311, train loss: 14.278655, valid precision: 0.838400, valid loss: 176.020998
epoch: 1067, train precision: 0.987667, train loss: 14.110850, valid precision: 0.843400, valid loss: 172.075228
epoch: 1068, train precision: 0.987689, train loss: 13.980427, valid precision: 0.829800, valid loss: 169.887096
epoch: 1069, train precision: 0.988378, train loss: 13.762062, valid precision: 0.837000, valid loss: 175.524948
epoch: 1070, train precision: 0.988533, train loss: 13.668760, valid precision: 0.840800, valid loss: 173.797313
epoch: 1071, train precision: 0.986111, train loss: 14.868291, valid precision: 0.836200, valid loss: 163.967165
epoch: 1072, train precision: 0.986133, train loss: 14.541897, valid precision: 0.834600, valid loss: 172.928636
epoch: 1073, train precision: 0.988000, train loss: 14.188565, valid precision: 0.836400, valid loss: 171.786846
epoch: 1074, train precision: 0.981778, train loss: 17.006674, valid precision: 0.832800, valid loss: 177.721374
epoch: 1075, train precision: 0.986956, train loss: 14.731973, valid precision: 0.836200, valid loss: 165.689817
epoch: 1076, train precision: 0.987467, train loss: 14.535315, valid precision: 0.838200, valid loss: 171.668657
epoch: 1077, train precision: 0.988267, train loss: 13.837257, valid precision: 0.842000, valid loss: 176.958380
epoch: 1078, train precision: 0.983978, train loss: 15.740702, valid precision: 0.832400, valid loss: 169.208630
epoch: 1079, train precision: 0.985289, train loss: 15.390268, valid precision: 0.832200, valid loss: 173.111447
epoch: 1080, train precision: 0.987356, train loss: 14.460451, valid precision: 0.829000, valid loss: 179.351129
epoch: 1081, train precision: 0.984689, train loss: 15.498457, valid precision: 0.834000, valid loss: 168.243831
epoch: 1082, train precision: 0.985467, train loss: 15.269804, valid precision: 0.830600, valid loss: 179.723796
epoch: 1083, train precision: 0.988822, train loss: 13.596733, valid precision: 0.835400, valid loss: 171.878485
epoch: 1084, train precision: 0.988533, train loss: 13.773214, valid precision: 0.836800, valid loss: 175.592195
epoch: 1085, train precision: 0.986133, train loss: 14.860225, valid precision: 0.837600, valid loss: 175.716798
epoch: 1086, train precision: 0.987444, train loss: 14.013134, valid precision: 0.835000, valid loss: 173.559800
epoch: 1087, train precision: 0.985756, train loss: 14.949473, valid precision: 0.835000, valid loss: 183.196150
epoch: 1088, train precision: 0.985644, train loss: 15.301752, valid precision: 0.834400, valid loss: 171.776147
epoch: 1089, train precision: 0.988689, train loss: 14.028646, valid precision: 0.831200, valid loss: 164.368314
epoch: 1090, train precision: 0.986911, train loss: 14.391748, valid precision: 0.833800, valid loss: 174.161522
epoch: 1091, train precision: 0.986511, train loss: 14.795220, valid precision: 0.829400, valid loss: 177.314822
epoch: 1092, train precision: 0.986911, train loss: 14.661465, valid precision: 0.837000, valid loss: 173.906251
epoch: 1093, train precision: 0.984667, train loss: 15.190838, valid precision: 0.832000, valid loss: 169.568459
epoch: 1094, train precision: 0.986667, train loss: 14.714768, valid precision: 0.833800, valid loss: 182.241561
epoch: 1095, train precision: 0.986289, train loss: 14.970936, valid precision: 0.836000, valid loss: 177.872479
epoch: 1096, train precision: 0.980622, train loss: 17.217435, valid precision: 0.826200, valid loss: 172.764148
epoch: 1097, train precision: 0.983444, train loss: 16.147344, valid precision: 0.829800, valid loss: 172.718530
epoch: 1098, train precision: 0.986400, train loss: 14.764836, valid precision: 0.830000, valid loss: 175.246266
epoch: 1099, train precision: 0.984844, train loss: 15.371883, valid precision: 0.832200, valid loss: 167.345370
epoch: 1100, train precision: 0.984756, train loss: 15.309203, valid precision: 0.829000, valid loss: 173.916358
epoch: 1101, train precision: 0.988533, train loss: 14.234050, valid precision: 0.837400, valid loss: 174.733091
epoch: 1102, train precision: 0.987578, train loss: 14.181593, valid precision: 0.841200, valid loss: 156.919688
epoch: 1103, train precision: 0.988778, train loss: 13.779084, valid precision: 0.844000, valid loss: 169.019538
epoch: 1104, train precision: 0.987067, train loss: 14.277780, valid precision: 0.840000, valid loss: 165.052384
epoch: 1105, train precision: 0.987467, train loss: 14.218515, valid precision: 0.835800, valid loss: 173.818889
epoch: 1106, train precision: 0.983333, train loss: 16.114057, valid precision: 0.833400, valid loss: 175.544610
epoch: 1107, train precision: 0.985733, train loss: 14.784896, valid precision: 0.837800, valid loss: 172.943411
epoch: 1108, train precision: 0.983022, train loss: 16.300736, valid precision: 0.834000, valid loss: 172.824581
epoch: 1109, train precision: 0.987778, train loss: 14.534028, valid precision: 0.837200, valid loss: 172.215086
epoch: 1110, train precision: 0.987178, train loss: 14.428664, valid precision: 0.837600, valid loss: 179.448149
epoch: 1111, train precision: 0.988422, train loss: 14.064397, valid precision: 0.836200, valid loss: 178.415572
epoch: 1112, train precision: 0.984422, train loss: 15.571434, valid precision: 0.834000, valid loss: 178.924918
epoch: 1113, train precision: 0.986756, train loss: 14.592687, valid precision: 0.840000, valid loss: 178.414354
epoch: 1114, train precision: 0.983178, train loss: 16.135556, valid precision: 0.832800, valid loss: 181.537858
epoch: 1115, train precision: 0.986956, train loss: 14.335698, valid precision: 0.836800, valid loss: 170.653457
epoch: 1116, train precision: 0.989267, train loss: 13.597233, valid precision: 0.837600, valid loss: 164.081813
epoch: 1117, train precision: 0.990289, train loss: 13.071897, valid precision: 0.839400, valid loss: 172.701854
epoch: 1118, train precision: 0.985111, train loss: 15.362981, valid precision: 0.832000, valid loss: 180.222948
epoch: 1119, train precision: 0.987844, train loss: 14.233068, valid precision: 0.834400, valid loss: 178.190500
epoch: 1120, train precision: 0.986556, train loss: 14.536510, valid precision: 0.824000, valid loss: 180.226154
epoch: 1121, train precision: 0.988689, train loss: 13.518492, valid precision: 0.834000, valid loss: 183.352180
epoch: 1122, train precision: 0.984489, train loss: 15.909068, valid precision: 0.839400, valid loss: 186.590498
epoch: 1123, train precision: 0.986067, train loss: 15.074567, valid precision: 0.829800, valid loss: 174.291996
epoch: 1124, train precision: 0.986333, train loss: 14.442875, valid precision: 0.838600, valid loss: 173.535252
epoch: 1125, train precision: 0.987378, train loss: 14.126732, valid precision: 0.830200, valid loss: 161.009855
epoch: 1126, train precision: 0.986467, train loss: 14.546485, valid precision: 0.831400, valid loss: 178.399969
epoch: 1127, train precision: 0.985511, train loss: 15.268619, valid precision: 0.828400, valid loss: 191.861567
epoch: 1128, train precision: 0.988000, train loss: 14.439933, valid precision: 0.837000, valid loss: 187.147219
epoch: 1129, train precision: 0.983222, train loss: 16.938976, valid precision: 0.822800, valid loss: 186.207788
epoch: 1130, train precision: 0.982467, train loss: 16.683323, valid precision: 0.832600, valid loss: 175.168061
epoch: 1131, train precision: 0.987556, train loss: 14.617665, valid precision: 0.834400, valid loss: 178.410015
epoch: 1132, train precision: 0.984956, train loss: 15.728821, valid precision: 0.827600, valid loss: 183.205724
epoch: 1133, train precision: 0.985200, train loss: 15.807971, valid precision: 0.833000, valid loss: 178.180231
epoch: 1134, train precision: 0.985556, train loss: 15.543754, valid precision: 0.833600, valid loss: 172.791974
epoch: 1135, train precision: 0.986822, train loss: 14.609220, valid precision: 0.833600, valid loss: 178.201514
epoch: 1136, train precision: 0.988444, train loss: 14.215761, valid precision: 0.833600, valid loss: 178.656240
epoch: 1137, train precision: 0.989178, train loss: 13.665347, valid precision: 0.833600, valid loss: 177.841619
epoch: 1138, train precision: 0.982556, train loss: 16.705385, valid precision: 0.835200, valid loss: 185.838858
epoch: 1139, train precision: 0.985000, train loss: 15.719651, valid precision: 0.833200, valid loss: 179.083544
epoch: 1140, train precision: 0.987467, train loss: 14.426285, valid precision: 0.829400, valid loss: 177.788850
epoch: 1141, train precision: 0.989822, train loss: 13.551054, valid precision: 0.840600, valid loss: 164.594816
epoch: 1142, train precision: 0.985378, train loss: 15.101462, valid precision: 0.833800, valid loss: 168.666604
epoch: 1143, train precision: 0.988022, train loss: 14.430680, valid precision: 0.840000, valid loss: 175.106699
epoch: 1144, train precision: 0.990222, train loss: 13.215571, valid precision: 0.837600, valid loss: 170.458058
epoch: 1145, train precision: 0.984022, train loss: 16.131572, valid precision: 0.833600, valid loss: 175.595332
epoch: 1146, train precision: 0.984111, train loss: 16.238016, valid precision: 0.826800, valid loss: 173.028336
epoch: 1147, train precision: 0.987533, train loss: 14.327691, valid precision: 0.833800, valid loss: 179.076223
epoch: 1148, train precision: 0.987556, train loss: 14.175338, valid precision: 0.835000, valid loss: 179.246026
epoch: 1149, train precision: 0.987422, train loss: 14.790303, valid precision: 0.837400, valid loss: 172.589059
epoch: 1150, train precision: 0.985756, train loss: 15.088869, valid precision: 0.836400, valid loss: 171.211672
epoch: 1151, train precision: 0.987311, train loss: 14.323526, valid precision: 0.834800, valid loss: 173.588698
epoch: 1152, train precision: 0.985867, train loss: 15.439039, valid precision: 0.832200, valid loss: 163.335349
epoch: 1153, train precision: 0.987667, train loss: 14.440626, valid precision: 0.837600, valid loss: 170.815805
epoch: 1154, train precision: 0.985400, train loss: 15.326563, valid precision: 0.836000, valid loss: 182.669686
epoch: 1155, train precision: 0.986422, train loss: 14.858102, valid precision: 0.832800, valid loss: 169.419011
epoch: 1156, train precision: 0.988067, train loss: 14.343053, valid precision: 0.835800, valid loss: 180.646606
epoch: 1157, train precision: 0.985156, train loss: 15.194257, valid precision: 0.831000, valid loss: 181.059065
epoch: 1158, train precision: 0.985933, train loss: 15.146818, valid precision: 0.834800, valid loss: 165.413220
epoch: 1159, train precision: 0.986311, train loss: 15.199788, valid precision: 0.836000, valid loss: 175.282045
epoch: 1160, train precision: 0.985022, train loss: 15.599703, valid precision: 0.836000, valid loss: 177.729855
epoch: 1161, train precision: 0.984622, train loss: 15.538064, valid precision: 0.833400, valid loss: 171.794826
epoch: 1162, train precision: 0.985511, train loss: 15.353077, valid precision: 0.839400, valid loss: 169.356436
epoch: 1163, train precision: 0.987556, train loss: 14.289505, valid precision: 0.838200, valid loss: 161.694136
epoch: 1164, train precision: 0.986800, train loss: 14.775336, valid precision: 0.838000, valid loss: 181.051856
epoch: 1165, train precision: 0.988067, train loss: 13.869225, valid precision: 0.834600, valid loss: 174.040731
epoch: 1166, train precision: 0.984800, train loss: 15.668373, valid precision: 0.836000, valid loss: 179.924576
epoch: 1167, train precision: 0.985711, train loss: 15.170339, valid precision: 0.837600, valid loss: 172.898750
epoch: 1168, train precision: 0.987133, train loss: 14.619589, valid precision: 0.833200, valid loss: 174.824088
epoch: 1169, train precision: 0.984822, train loss: 15.556676, valid precision: 0.835400, valid loss: 172.324517
epoch: 1170, train precision: 0.983733, train loss: 15.702871, valid precision: 0.833400, valid loss: 173.926961
epoch: 1171, train precision: 0.987822, train loss: 14.037099, valid precision: 0.834800, valid loss: 163.164706
epoch: 1172, train precision: 0.985578, train loss: 14.948101, valid precision: 0.835200, valid loss: 171.335465
epoch: 1173, train precision: 0.986022, train loss: 14.999649, valid precision: 0.830400, valid loss: 177.301751
epoch: 1174, train precision: 0.986822, train loss: 14.729848, valid precision: 0.835400, valid loss: 176.212170
epoch: 1175, train precision: 0.984000, train loss: 15.775864, valid precision: 0.831800, valid loss: 176.105632
epoch: 1176, train precision: 0.986689, train loss: 14.973295, valid precision: 0.833000, valid loss: 180.338421
epoch: 1177, train precision: 0.989556, train loss: 13.692232, valid precision: 0.830800, valid loss: 179.695885
epoch: 1178, train precision: 0.988778, train loss: 13.891285, valid precision: 0.836800, valid loss: 179.715898
epoch: 1179, train precision: 0.983333, train loss: 16.476925, valid precision: 0.832200, valid loss: 184.162450
epoch: 1180, train precision: 0.988222, train loss: 14.254596, valid precision: 0.834600, valid loss: 174.630268
epoch: 1181, train precision: 0.986422, train loss: 14.826401, valid precision: 0.840200, valid loss: 174.094282
epoch: 1182, train precision: 0.986356, train loss: 15.055900, valid precision: 0.832200, valid loss: 174.650295
epoch: 1183, train precision: 0.987644, train loss: 14.357640, valid precision: 0.832600, valid loss: 182.996199
epoch: 1184, train precision: 0.984689, train loss: 15.610034, valid precision: 0.831600, valid loss: 182.983519
epoch: 1185, train precision: 0.986911, train loss: 14.725576, valid precision: 0.834400, valid loss: 169.976837
epoch: 1186, train precision: 0.987956, train loss: 13.960834, valid precision: 0.837600, valid loss: 178.970986
epoch: 1187, train precision: 0.986511, train loss: 14.926974, valid precision: 0.839400, valid loss: 169.222898
epoch: 1188, train precision: 0.983067, train loss: 16.552072, valid precision: 0.833000, valid loss: 190.032345
epoch: 1189, train precision: 0.987333, train loss: 14.555523, valid precision: 0.833200, valid loss: 185.833415
epoch: 1190, train precision: 0.984356, train loss: 16.321188, valid precision: 0.832000, valid loss: 192.550645
epoch: 1191, train precision: 0.987356, train loss: 14.358964, valid precision: 0.834000, valid loss: 186.303487
epoch: 1192, train precision: 0.985444, train loss: 15.562047, valid precision: 0.829800, valid loss: 180.869361
epoch: 1193, train precision: 0.988644, train loss: 14.282398, valid precision: 0.839200, valid loss: 178.931007
epoch: 1194, train precision: 0.989378, train loss: 13.466826, valid precision: 0.838800, valid loss: 171.318889
epoch: 1195, train precision: 0.989844, train loss: 13.438674, valid precision: 0.842600, valid loss: 181.030999
epoch: 1196, train precision: 0.987089, train loss: 14.499793, valid precision: 0.836400, valid loss: 176.394863
epoch: 1197, train precision: 0.986311, train loss: 15.096051, valid precision: 0.837400, valid loss: 170.359682
epoch: 1198, train precision: 0.988933, train loss: 14.049434, valid precision: 0.840400, valid loss: 173.324038
epoch: 1199, train precision: 0.989778, train loss: 13.538107, valid precision: 0.836400, valid loss: 168.909346
epoch: 1200, train precision: 0.985444, train loss: 15.869654, valid precision: 0.833200, valid loss: 178.223499
epoch: 1201, train precision: 0.987467, train loss: 14.058459, valid precision: 0.829600, valid loss: 166.792131
epoch: 1202, train precision: 0.986533, train loss: 14.833221, valid precision: 0.835200, valid loss: 176.414014
epoch: 1203, train precision: 0.986800, train loss: 14.989934, valid precision: 0.833800, valid loss: 173.386553
epoch: 1204, train precision: 0.989022, train loss: 13.755412, valid precision: 0.828000, valid loss: 177.595373
epoch: 1205, train precision: 0.986822, train loss: 15.001670, valid precision: 0.837400, valid loss: 180.556396
epoch: 1206, train precision: 0.989733, train loss: 13.569816, valid precision: 0.841400, valid loss: 179.058667
epoch: 1207, train precision: 0.980222, train loss: 18.204520, valid precision: 0.833600, valid loss: 189.045747
epoch: 1208, train precision: 0.985200, train loss: 15.747985, valid precision: 0.834000, valid loss: 177.647006
epoch: 1209, train precision: 0.988800, train loss: 14.120514, valid precision: 0.833200, valid loss: 174.306686
epoch: 1210, train precision: 0.986778, train loss: 14.595944, valid precision: 0.836600, valid loss: 184.065113
epoch: 1211, train precision: 0.983933, train loss: 16.306888, valid precision: 0.834400, valid loss: 175.055075
epoch: 1212, train precision: 0.985689, train loss: 15.544920, valid precision: 0.830200, valid loss: 184.778010
epoch: 1213, train precision: 0.989067, train loss: 13.804803, valid precision: 0.841600, valid loss: 171.409386
epoch: 1214, train precision: 0.983756, train loss: 16.253331, valid precision: 0.826800, valid loss: 184.882748
epoch: 1215, train precision: 0.988444, train loss: 14.198069, valid precision: 0.838000, valid loss: 184.756320
epoch: 1216, train precision: 0.986133, train loss: 15.067817, valid precision: 0.838200, valid loss: 181.048540
epoch: 1217, train precision: 0.987089, train loss: 14.544093, valid precision: 0.834200, valid loss: 168.735019
epoch: 1218, train precision: 0.984756, train loss: 15.761558, valid precision: 0.833200, valid loss: 187.109776
epoch: 1219, train precision: 0.986222, train loss: 14.999325, valid precision: 0.829400, valid loss: 187.868013
epoch: 1220, train precision: 0.983000, train loss: 16.704233, valid precision: 0.829600, valid loss: 183.607539
epoch: 1221, train precision: 0.986378, train loss: 15.074664, valid precision: 0.827800, valid loss: 180.239798
epoch: 1222, train precision: 0.985911, train loss: 15.504296, valid precision: 0.829600, valid loss: 188.169673
epoch: 1223, train precision: 0.987511, train loss: 14.251271, valid precision: 0.828800, valid loss: 187.253934
epoch: 1224, train precision: 0.989756, train loss: 13.591782, valid precision: 0.830400, valid loss: 192.887469
epoch: 1225, train precision: 0.985289, train loss: 15.646427, valid precision: 0.831000, valid loss: 188.455974
epoch: 1226, train precision: 0.984556, train loss: 16.153667, valid precision: 0.834800, valid loss: 187.901793
epoch: 1227, train precision: 0.988844, train loss: 14.089659, valid precision: 0.831000, valid loss: 191.999726
epoch: 1228, train precision: 0.985356, train loss: 15.804022, valid precision: 0.828200, valid loss: 198.969941
epoch: 1229, train precision: 0.984467, train loss: 15.811687, valid precision: 0.834800, valid loss: 177.483451
epoch: 1230, train precision: 0.986022, train loss: 15.077876, valid precision: 0.833400, valid loss: 173.207497
epoch: 1231, train precision: 0.984311, train loss: 15.848826, valid precision: 0.834600, valid loss: 180.486789
epoch: 1232, train precision: 0.988667, train loss: 13.732515, valid precision: 0.833600, valid loss: 174.204141
epoch: 1233, train precision: 0.987444, train loss: 14.522453, valid precision: 0.831000, valid loss: 175.087665
epoch: 1234, train precision: 0.986067, train loss: 15.402853, valid precision: 0.834000, valid loss: 188.179277
epoch: 1235, train precision: 0.987489, train loss: 14.523150, valid precision: 0.835000, valid loss: 180.504746
epoch: 1236, train precision: 0.983378, train loss: 16.601117, valid precision: 0.829400, valid loss: 178.218765
epoch: 1237, train precision: 0.985911, train loss: 15.296399, valid precision: 0.834000, valid loss: 186.361788
epoch: 1238, train precision: 0.988667, train loss: 13.960710, valid precision: 0.836400, valid loss: 172.093864
epoch: 1239, train precision: 0.985067, train loss: 15.598798, valid precision: 0.832200, valid loss: 184.643926
epoch: 1240, train precision: 0.988778, train loss: 13.921474, valid precision: 0.834800, valid loss: 179.856020
epoch: 1241, train precision: 0.984933, train loss: 15.655539, valid precision: 0.831000, valid loss: 182.567938
epoch: 1242, train precision: 0.986822, train loss: 14.878029, valid precision: 0.835000, valid loss: 182.725209
epoch: 1243, train precision: 0.987578, train loss: 14.388998, valid precision: 0.832600, valid loss: 191.313479
epoch: 1244, train precision: 0.986533, train loss: 14.941900, valid precision: 0.831600, valid loss: 186.048384
epoch: 1245, train precision: 0.986644, train loss: 14.955510, valid precision: 0.835600, valid loss: 182.430951
epoch: 1246, train precision: 0.988111, train loss: 14.178966, valid precision: 0.832200, valid loss: 181.620404
epoch: 1247, train precision: 0.986822, train loss: 14.761834, valid precision: 0.838000, valid loss: 179.083728
epoch: 1248, train precision: 0.986889, train loss: 14.794098, valid precision: 0.833600, valid loss: 185.675508
epoch: 1249, train precision: 0.988200, train loss: 14.284776, valid precision: 0.835000, valid loss: 191.689547
epoch: 1250, train precision: 0.986622, train loss: 14.940259, valid precision: 0.837200, valid loss: 196.696843
epoch: 1251, train precision: 0.987578, train loss: 14.841050, valid precision: 0.836000, valid loss: 182.214744
epoch: 1252, train precision: 0.987000, train loss: 15.248909, valid precision: 0.836200, valid loss: 192.285172
epoch: 1253, train precision: 0.986622, train loss: 15.029725, valid precision: 0.833600, valid loss: 175.906106
epoch: 1254, train precision: 0.987422, train loss: 14.499951, valid precision: 0.832400, valid loss: 167.862693
epoch: 1255, train precision: 0.985067, train loss: 15.529651, valid precision: 0.837200, valid loss: 164.533109
epoch: 1256, train precision: 0.983067, train loss: 16.291691, valid precision: 0.835400, valid loss: 184.227446
epoch: 1257, train precision: 0.983022, train loss: 16.520509, valid precision: 0.834200, valid loss: 180.761679
epoch: 1258, train precision: 0.985822, train loss: 15.165546, valid precision: 0.829200, valid loss: 176.668967
epoch: 1259, train precision: 0.985889, train loss: 15.625527, valid precision: 0.835400, valid loss: 192.167151
epoch: 1260, train precision: 0.986978, train loss: 14.488033, valid precision: 0.834800, valid loss: 172.383450
epoch: 1261, train precision: 0.988711, train loss: 14.062755, valid precision: 0.835400, valid loss: 188.341988
epoch: 1262, train precision: 0.983933, train loss: 16.519530, valid precision: 0.829400, valid loss: 186.840381
epoch: 1263, train precision: 0.987956, train loss: 14.468181, valid precision: 0.836000, valid loss: 178.684886
epoch: 1264, train precision: 0.984711, train loss: 15.752114, valid precision: 0.832800, valid loss: 194.019562
epoch: 1265, train precision: 0.986667, train loss: 14.937963, valid precision: 0.830600, valid loss: 184.713892
epoch: 1266, train precision: 0.985400, train loss: 15.376422, valid precision: 0.833200, valid loss: 178.359174
epoch: 1267, train precision: 0.986311, train loss: 15.266801, valid precision: 0.827000, valid loss: 186.462332
epoch: 1268, train precision: 0.988489, train loss: 14.280195, valid precision: 0.831000, valid loss: 190.660762
epoch: 1269, train precision: 0.985733, train loss: 15.403300, valid precision: 0.825600, valid loss: 189.467930
epoch: 1270, train precision: 0.984089, train loss: 15.875816, valid precision: 0.827600, valid loss: 183.455091
epoch: 1271, train precision: 0.985267, train loss: 15.699918, valid precision: 0.830400, valid loss: 186.219188
epoch: 1272, train precision: 0.984756, train loss: 15.633570, valid precision: 0.829800, valid loss: 176.269012
epoch: 1273, train precision: 0.986000, train loss: 15.312290, valid precision: 0.829600, valid loss: 179.780119
epoch: 1274, train precision: 0.985711, train loss: 15.402921, valid precision: 0.826400, valid loss: 193.521052
epoch: 1275, train precision: 0.985422, train loss: 15.782697, valid precision: 0.833000, valid loss: 189.479300
epoch: 1276, train precision: 0.985467, train loss: 15.652341, valid precision: 0.834200, valid loss: 179.471909
epoch: 1277, train precision: 0.985978, train loss: 15.043729, valid precision: 0.838600, valid loss: 174.516257
epoch: 1278, train precision: 0.990133, train loss: 13.389127, valid precision: 0.840000, valid loss: 185.496005
epoch: 1279, train precision: 0.988533, train loss: 13.985874, valid precision: 0.835800, valid loss: 185.087205
epoch: 1280, train precision: 0.987156, train loss: 14.691163, valid precision: 0.832400, valid loss: 180.644969
epoch: 1281, train precision: 0.986156, train loss: 15.144412, valid precision: 0.832000, valid loss: 181.871128
epoch: 1282, train precision: 0.985889, train loss: 15.541701, valid precision: 0.839000, valid loss: 183.926864
epoch: 1283, train precision: 0.985444, train loss: 15.389144, valid precision: 0.834800, valid loss: 178.792875
epoch: 1284, train precision: 0.985489, train loss: 15.986663, valid precision: 0.831200, valid loss: 179.515085
epoch: 1285, train precision: 0.990244, train loss: 13.374453, valid precision: 0.833600, valid loss: 177.942919
epoch: 1286, train precision: 0.989089, train loss: 13.924234, valid precision: 0.834400, valid loss: 175.674995
epoch: 1287, train precision: 0.983400, train loss: 16.551750, valid precision: 0.836600, valid loss: 176.869272
epoch: 1288, train precision: 0.984689, train loss: 15.938293, valid precision: 0.831400, valid loss: 177.947510
epoch: 1289, train precision: 0.985244, train loss: 15.533492, valid precision: 0.835800, valid loss: 179.817484
epoch: 1290, train precision: 0.989067, train loss: 14.496266, valid precision: 0.835200, valid loss: 190.959269
epoch: 1291, train precision: 0.985356, train loss: 15.763137, valid precision: 0.839000, valid loss: 176.363279
epoch: 1292, train precision: 0.989089, train loss: 13.929697, valid precision: 0.834800, valid loss: 180.228995
epoch: 1293, train precision: 0.986711, train loss: 14.758851, valid precision: 0.836200, valid loss: 182.228960
epoch: 1294, train precision: 0.982200, train loss: 17.105406, valid precision: 0.830200, valid loss: 185.480810
epoch: 1295, train precision: 0.983178, train loss: 15.753685, valid precision: 0.831800, valid loss: 174.218579
epoch: 1296, train precision: 0.988244, train loss: 14.300994, valid precision: 0.830600, valid loss: 181.807019
epoch: 1297, train precision: 0.990133, train loss: 13.601399, valid precision: 0.841000, valid loss: 181.927601
epoch: 1298, train precision: 0.988467, train loss: 14.120231, valid precision: 0.840400, valid loss: 163.295158
epoch: 1299, train precision: 0.987133, train loss: 14.821605, valid precision: 0.831600, valid loss: 174.358729
epoch: 1300, train precision: 0.984067, train loss: 16.760225, valid precision: 0.832400, valid loss: 198.778624
epoch: 1301, train precision: 0.985044, train loss: 16.065073, valid precision: 0.837000, valid loss: 173.245974
epoch: 1302, train precision: 0.988889, train loss: 13.840549, valid precision: 0.828800, valid loss: 180.328103
epoch: 1303, train precision: 0.989556, train loss: 13.999758, valid precision: 0.838200, valid loss: 184.597225
epoch: 1304, train precision: 0.987067, train loss: 14.832408, valid precision: 0.832400, valid loss: 178.343937
epoch: 1305, train precision: 0.990422, train loss: 13.376913, valid precision: 0.836400, valid loss: 181.224512
epoch: 1306, train precision: 0.986044, train loss: 15.018091, valid precision: 0.835800, valid loss: 182.049358
epoch: 1307, train precision: 0.981911, train loss: 17.034793, valid precision: 0.833600, valid loss: 195.925557
epoch: 1308, train precision: 0.985933, train loss: 15.264155, valid precision: 0.835600, valid loss: 187.390103
epoch: 1309, train precision: 0.985089, train loss: 15.830715, valid precision: 0.830400, valid loss: 194.056809
epoch: 1310, train precision: 0.990067, train loss: 13.621010, valid precision: 0.836000, valid loss: 196.510699
epoch: 1311, train precision: 0.986822, train loss: 15.246128, valid precision: 0.833600, valid loss: 193.536492
epoch: 1312, train precision: 0.988133, train loss: 14.314028, valid precision: 0.829800, valid loss: 173.232965
epoch: 1313, train precision: 0.989000, train loss: 14.004138, valid precision: 0.839400, valid loss: 175.372134
epoch: 1314, train precision: 0.986756, train loss: 14.866018, valid precision: 0.839600, valid loss: 184.175609
epoch: 1315, train precision: 0.984711, train loss: 16.151161, valid precision: 0.837600, valid loss: 184.901875
epoch: 1316, train precision: 0.987178, train loss: 14.663944, valid precision: 0.832600, valid loss: 189.385700
epoch: 1317, train precision: 0.986356, train loss: 14.877352, valid precision: 0.833000, valid loss: 169.607552
epoch: 1318, train precision: 0.988333, train loss: 14.313670, valid precision: 0.838600, valid loss: 175.888897
epoch: 1319, train precision: 0.987400, train loss: 14.671707, valid precision: 0.836800, valid loss: 179.520354
epoch: 1320, train precision: 0.986089, train loss: 15.241536, valid precision: 0.828000, valid loss: 178.782969
epoch: 1321, train precision: 0.987444, train loss: 14.871363, valid precision: 0.830000, valid loss: 185.001588
epoch: 1322, train precision: 0.988178, train loss: 14.548161, valid precision: 0.835600, valid loss: 181.252299
epoch: 1323, train precision: 0.983667, train loss: 16.471668, valid precision: 0.832000, valid loss: 185.658385
epoch: 1324, train precision: 0.986333, train loss: 15.210478, valid precision: 0.830400, valid loss: 175.031211
epoch: 1325, train precision: 0.988000, train loss: 14.347624, valid precision: 0.835800, valid loss: 188.322142
epoch: 1326, train precision: 0.986156, train loss: 15.678297, valid precision: 0.827800, valid loss: 193.766396
epoch: 1327, train precision: 0.986444, train loss: 15.031822, valid precision: 0.829600, valid loss: 171.288833
epoch: 1328, train precision: 0.987044, train loss: 14.782161, valid precision: 0.832000, valid loss: 190.345571
epoch: 1329, train precision: 0.984533, train loss: 16.132392, valid precision: 0.825000, valid loss: 181.527850
epoch: 1330, train precision: 0.987600, train loss: 14.604104, valid precision: 0.832200, valid loss: 187.879470
epoch: 1331, train precision: 0.986644, train loss: 14.809964, valid precision: 0.832200, valid loss: 192.296943
epoch: 1332, train precision: 0.985867, train loss: 15.260579, valid precision: 0.832400, valid loss: 184.587827
epoch: 1333, train precision: 0.986311, train loss: 15.110938, valid precision: 0.827800, valid loss: 185.219001
epoch: 1334, train precision: 0.984289, train loss: 16.176561, valid precision: 0.835200, valid loss: 194.732549
epoch: 1335, train precision: 0.988911, train loss: 13.901119, valid precision: 0.837000, valid loss: 178.353584
epoch: 1336, train precision: 0.987022, train loss: 14.880370, valid precision: 0.827400, valid loss: 188.572698
epoch: 1337, train precision: 0.986867, train loss: 14.829204, valid precision: 0.834000, valid loss: 176.251540
epoch: 1338, train precision: 0.988467, train loss: 14.407016, valid precision: 0.831200, valid loss: 178.569210
epoch: 1339, train precision: 0.988044, train loss: 14.962638, valid precision: 0.837000, valid loss: 201.091876
epoch: 1340, train precision: 0.983111, train loss: 16.464764, valid precision: 0.832400, valid loss: 172.206931
epoch: 1341, train precision: 0.986511, train loss: 15.053182, valid precision: 0.831400, valid loss: 194.570295
epoch: 1342, train precision: 0.985822, train loss: 15.343833, valid precision: 0.832400, valid loss: 190.117999
epoch: 1343, train precision: 0.987578, train loss: 14.587981, valid precision: 0.836600, valid loss: 182.540663
epoch: 1344, train precision: 0.983111, train loss: 16.592271, valid precision: 0.827600, valid loss: 188.736211
epoch: 1345, train precision: 0.987800, train loss: 15.032863, valid precision: 0.833800, valid loss: 194.973262
epoch: 1346, train precision: 0.985289, train loss: 16.076825, valid precision: 0.831200, valid loss: 192.923096
epoch: 1347, train precision: 0.985578, train loss: 15.568608, valid precision: 0.834000, valid loss: 182.666240
epoch: 1348, train precision: 0.987022, train loss: 14.918070, valid precision: 0.830000, valid loss: 183.947999
epoch: 1349, train precision: 0.987289, train loss: 15.179305, valid precision: 0.840000, valid loss: 185.021103
epoch: 1350, train precision: 0.985756, train loss: 15.532498, valid precision: 0.835400, valid loss: 177.371644
epoch: 1351, train precision: 0.986978, train loss: 14.862128, valid precision: 0.830800, valid loss: 193.762094
epoch: 1352, train precision: 0.986978, train loss: 15.125446, valid precision: 0.831800, valid loss: 176.064164
epoch: 1353, train precision: 0.988978, train loss: 13.980110, valid precision: 0.836000, valid loss: 188.946306
epoch: 1354, train precision: 0.988400, train loss: 14.547316, valid precision: 0.833600, valid loss: 192.064501
epoch: 1355, train precision: 0.985756, train loss: 15.655359, valid precision: 0.839200, valid loss: 190.567352
epoch: 1356, train precision: 0.987622, train loss: 14.661730, valid precision: 0.832200, valid loss: 182.116263
epoch: 1357, train precision: 0.987022, train loss: 15.195498, valid precision: 0.838000, valid loss: 174.942569
epoch: 1358, train precision: 0.983978, train loss: 16.168586, valid precision: 0.828800, valid loss: 179.352894
epoch: 1359, train precision: 0.987600, train loss: 14.859911, valid precision: 0.837000, valid loss: 177.851649
epoch: 1360, train precision: 0.989689, train loss: 13.608259, valid precision: 0.839200, valid loss: 184.120866
epoch: 1361, train precision: 0.985778, train loss: 15.788896, valid precision: 0.830400, valid loss: 190.136388
epoch: 1362, train precision: 0.988311, train loss: 14.429713, valid precision: 0.834800, valid loss: 187.715839
epoch: 1363, train precision: 0.987800, train loss: 14.873051, valid precision: 0.832200, valid loss: 196.989456
epoch: 1364, train precision: 0.987422, train loss: 14.985027, valid precision: 0.831000, valid loss: 190.681372
epoch: 1365, train precision: 0.987178, train loss: 14.760566, valid precision: 0.831400, valid loss: 187.533016
epoch: 1366, train precision: 0.978378, train loss: 19.000897, valid precision: 0.827000, valid loss: 186.112413
epoch: 1367, train precision: 0.985000, train loss: 16.403815, valid precision: 0.836800, valid loss: 197.296981
epoch: 1368, train precision: 0.986933, train loss: 14.836079, valid precision: 0.833200, valid loss: 182.613758
epoch: 1369, train precision: 0.986756, train loss: 15.204405, valid precision: 0.836000, valid loss: 189.355562
epoch: 1370, train precision: 0.989022, train loss: 14.194530, valid precision: 0.839000, valid loss: 187.885025
epoch: 1371, train precision: 0.981044, train loss: 18.404077, valid precision: 0.831000, valid loss: 193.556847
epoch: 1372, train precision: 0.985133, train loss: 15.860021, valid precision: 0.835600, valid loss: 191.677758
epoch: 1373, train precision: 0.989956, train loss: 13.821069, valid precision: 0.833600, valid loss: 190.281797
epoch: 1374, train precision: 0.988289, train loss: 14.284914, valid precision: 0.829000, valid loss: 184.007909
epoch: 1375, train precision: 0.986978, train loss: 15.275936, valid precision: 0.834200, valid loss: 184.612409
epoch: 1376, train precision: 0.986444, train loss: 15.408316, valid precision: 0.836200, valid loss: 182.993287
epoch: 1377, train precision: 0.985689, train loss: 15.369663, valid precision: 0.828400, valid loss: 178.418208
epoch: 1378, train precision: 0.985800, train loss: 15.505949, valid precision: 0.839400, valid loss: 180.012178
epoch: 1379, train precision: 0.986578, train loss: 15.065018, valid precision: 0.831000, valid loss: 185.351881
epoch: 1380, train precision: 0.986156, train loss: 15.380959, valid precision: 0.832600, valid loss: 182.528030
epoch: 1381, train precision: 0.982822, train loss: 16.988723, valid precision: 0.832000, valid loss: 193.660723
epoch: 1382, train precision: 0.986778, train loss: 15.184061, valid precision: 0.835000, valid loss: 203.473002
epoch: 1383, train precision: 0.986689, train loss: 15.238847, valid precision: 0.834600, valid loss: 188.873916
epoch: 1384, train precision: 0.986978, train loss: 15.207045, valid precision: 0.840200, valid loss: 194.361838
epoch: 1385, train precision: 0.986711, train loss: 15.257795, valid precision: 0.833600, valid loss: 183.017449
epoch: 1386, train precision: 0.988222, train loss: 14.313036, valid precision: 0.840400, valid loss: 169.674463
epoch: 1387, train precision: 0.986956, train loss: 14.793941, valid precision: 0.833000, valid loss: 177.336036
epoch: 1388, train precision: 0.987489, train loss: 14.800034, valid precision: 0.840400, valid loss: 190.617207
epoch: 1389, train precision: 0.986956, train loss: 14.644603, valid precision: 0.831400, valid loss: 175.083880
epoch: 1390, train precision: 0.985622, train loss: 15.370072, valid precision: 0.834000, valid loss: 188.329614
epoch: 1391, train precision: 0.985444, train loss: 15.749396, valid precision: 0.827600, valid loss: 197.854001
epoch: 1392, train precision: 0.984778, train loss: 16.007994, valid precision: 0.833800, valid loss: 173.592484
epoch: 1393, train precision: 0.986622, train loss: 14.971457, valid precision: 0.839400, valid loss: 177.513704
epoch: 1394, train precision: 0.986000, train loss: 15.674017, valid precision: 0.834600, valid loss: 187.128250
epoch: 1395, train precision: 0.989400, train loss: 13.992182, valid precision: 0.833600, valid loss: 184.955762
epoch: 1396, train precision: 0.984756, train loss: 16.152995, valid precision: 0.832000, valid loss: 185.602098
epoch: 1397, train precision: 0.986111, train loss: 15.088390, valid precision: 0.832400, valid loss: 191.237265
epoch: 1398, train precision: 0.983400, train loss: 16.815294, valid precision: 0.825600, valid loss: 192.824649
epoch: 1399, train precision: 0.986733, train loss: 14.934166, valid precision: 0.833800, valid loss: 193.078054
epoch: 1400, train precision: 0.989333, train loss: 14.141531, valid precision: 0.836200, valid loss: 189.723476
epoch: 1401, train precision: 0.981311, train loss: 17.551626, valid precision: 0.829800, valid loss: 183.316060
epoch: 1402, train precision: 0.986889, train loss: 15.168230, valid precision: 0.837000, valid loss: 191.287162
epoch: 1403, train precision: 0.985689, train loss: 15.719537, valid precision: 0.834800, valid loss: 178.474017
epoch: 1404, train precision: 0.986600, train loss: 15.434456, valid precision: 0.833600, valid loss: 184.445565
epoch: 1405, train precision: 0.983467, train loss: 17.210783, valid precision: 0.830600, valid loss: 192.442311
epoch: 1406, train precision: 0.987956, train loss: 14.802781, valid precision: 0.837200, valid loss: 180.541988
epoch: 1407, train precision: 0.983933, train loss: 16.183872, valid precision: 0.834400, valid loss: 178.436812
epoch: 1408, train precision: 0.989689, train loss: 13.780590, valid precision: 0.844800, valid loss: 189.040985
epoch: 1409, train precision: 0.989244, train loss: 13.946381, valid precision: 0.835800, valid loss: 184.204059
epoch: 1410, train precision: 0.983756, train loss: 16.389442, valid precision: 0.834400, valid loss: 186.143608
epoch: 1411, train precision: 0.987089, train loss: 15.236243, valid precision: 0.835400, valid loss: 182.449712
epoch: 1412, train precision: 0.986333, train loss: 15.347485, valid precision: 0.835400, valid loss: 181.057981
epoch: 1413, train precision: 0.986911, train loss: 15.105532, valid precision: 0.834800, valid loss: 183.916594
epoch: 1414, train precision: 0.989378, train loss: 14.177998, valid precision: 0.833000, valid loss: 184.647456
epoch: 1415, train precision: 0.983822, train loss: 16.362729, valid precision: 0.831400, valid loss: 186.340756
epoch: 1416, train precision: 0.988667, train loss: 14.563842, valid precision: 0.833200, valid loss: 189.908080
epoch: 1417, train precision: 0.984800, train loss: 16.276634, valid precision: 0.830800, valid loss: 189.713973
epoch: 1418, train precision: 0.986800, train loss: 15.210930, valid precision: 0.835200, valid loss: 185.973640
epoch: 1419, train precision: 0.984689, train loss: 16.096492, valid precision: 0.830600, valid loss: 191.703659
epoch: 1420, train precision: 0.987756, train loss: 14.550107, valid precision: 0.839000, valid loss: 175.416761
epoch: 1421, train precision: 0.986067, train loss: 15.515747, valid precision: 0.835400, valid loss: 189.687782
epoch: 1422, train precision: 0.987733, train loss: 14.902189, valid precision: 0.835200, valid loss: 200.986215
epoch: 1423, train precision: 0.987022, train loss: 15.621326, valid precision: 0.834800, valid loss: 199.460301
epoch: 1424, train precision: 0.987733, train loss: 14.735262, valid precision: 0.833000, valid loss: 187.252021
epoch: 1425, train precision: 0.986133, train loss: 14.985473, valid precision: 0.836200, valid loss: 182.620232
epoch: 1426, train precision: 0.984844, train loss: 15.622413, valid precision: 0.833000, valid loss: 188.658188
epoch: 1427, train precision: 0.986111, train loss: 15.149070, valid precision: 0.840800, valid loss: 178.412357
epoch: 1428, train precision: 0.986489, train loss: 15.472634, valid precision: 0.829400, valid loss: 180.424942
epoch: 1429, train precision: 0.987511, train loss: 14.570119, valid precision: 0.833800, valid loss: 183.481781
epoch: 1430, train precision: 0.987289, train loss: 15.186310, valid precision: 0.835800, valid loss: 184.444916
epoch: 1431, train precision: 0.989022, train loss: 14.421554, valid precision: 0.840000, valid loss: 182.233116
epoch: 1432, train precision: 0.987756, train loss: 14.892238, valid precision: 0.836200, valid loss: 182.480152
epoch: 1433, train precision: 0.988422, train loss: 14.535307, valid precision: 0.838400, valid loss: 182.161320
epoch: 1434, train precision: 0.985467, train loss: 15.612873, valid precision: 0.837000, valid loss: 175.656222
epoch: 1435, train precision: 0.989111, train loss: 14.031135, valid precision: 0.834400, valid loss: 178.238554
epoch: 1436, train precision: 0.988311, train loss: 14.470418, valid precision: 0.841600, valid loss: 185.923652
epoch: 1437, train precision: 0.986044, train loss: 15.429375, valid precision: 0.836600, valid loss: 187.640316
epoch: 1438, train precision: 0.986978, train loss: 14.746340, valid precision: 0.833400, valid loss: 180.781371
epoch: 1439, train precision: 0.982333, train loss: 17.012812, valid precision: 0.834200, valid loss: 187.869668
epoch: 1440, train precision: 0.986044, train loss: 15.436710, valid precision: 0.834800, valid loss: 176.702119
epoch: 1441, train precision: 0.982644, train loss: 17.274275, valid precision: 0.837800, valid loss: 184.380560
epoch: 1442, train precision: 0.983600, train loss: 16.462453, valid precision: 0.838200, valid loss: 172.757349
epoch: 1443, train precision: 0.981289, train loss: 17.889357, valid precision: 0.839600, valid loss: 185.254322
epoch: 1444, train precision: 0.989022, train loss: 14.353981, valid precision: 0.842600, valid loss: 196.428224
epoch: 1445, train precision: 0.985622, train loss: 15.665332, valid precision: 0.835400, valid loss: 183.445215
epoch: 1446, train precision: 0.989733, train loss: 13.725608, valid precision: 0.833400, valid loss: 183.463737
epoch: 1447, train precision: 0.987200, train loss: 14.799626, valid precision: 0.833600, valid loss: 176.614652
epoch: 1448, train precision: 0.986800, train loss: 15.026423, valid precision: 0.840200, valid loss: 174.975016
epoch: 1449, train precision: 0.985333, train loss: 16.318956, valid precision: 0.837800, valid loss: 184.233195
epoch: 1450, train precision: 0.985444, train loss: 15.850686, valid precision: 0.833400, valid loss: 182.048971
epoch: 1451, train precision: 0.984644, train loss: 15.751309, valid precision: 0.834000, valid loss: 182.294984
epoch: 1452, train precision: 0.985489, train loss: 15.914299, valid precision: 0.831200, valid loss: 185.082601
epoch: 1453, train precision: 0.987844, train loss: 14.448195, valid precision: 0.837800, valid loss: 185.117079
epoch: 1454, train precision: 0.989533, train loss: 13.995819, valid precision: 0.836400, valid loss: 188.854684
epoch: 1455, train precision: 0.980800, train loss: 18.084746, valid precision: 0.828400, valid loss: 186.459407
epoch: 1456, train precision: 0.988311, train loss: 14.840299, valid precision: 0.837000, valid loss: 183.282548
epoch: 1457, train precision: 0.982978, train loss: 17.244099, valid precision: 0.838000, valid loss: 185.301311
epoch: 1458, train precision: 0.984400, train loss: 16.228614, valid precision: 0.832200, valid loss: 186.950797
epoch: 1459, train precision: 0.988400, train loss: 14.427677, valid precision: 0.843200, valid loss: 191.078859
epoch: 1460, train precision: 0.985444, train loss: 15.845030, valid precision: 0.837000, valid loss: 187.594199
epoch: 1461, train precision: 0.987200, train loss: 14.694091, valid precision: 0.835800, valid loss: 174.877489
epoch: 1462, train precision: 0.987000, train loss: 15.159998, valid precision: 0.832800, valid loss: 189.090447
epoch: 1463, train precision: 0.983200, train loss: 17.312397, valid precision: 0.837600, valid loss: 201.425955
epoch: 1464, train precision: 0.989333, train loss: 13.761269, valid precision: 0.838800, valid loss: 173.303779
epoch: 1465, train precision: 0.986422, train loss: 15.644349, valid precision: 0.837800, valid loss: 191.301454
epoch: 1466, train precision: 0.986444, train loss: 15.090814, valid precision: 0.833800, valid loss: 194.635393
epoch: 1467, train precision: 0.984822, train loss: 16.338181, valid precision: 0.838200, valid loss: 191.868143
epoch: 1468, train precision: 0.990689, train loss: 13.305178, valid precision: 0.836200, valid loss: 172.756643
epoch: 1469, train precision: 0.985267, train loss: 15.962931, valid precision: 0.837800, valid loss: 177.959105
epoch: 1470, train precision: 0.987067, train loss: 15.092611, valid precision: 0.834600, valid loss: 179.915581
epoch: 1471, train precision: 0.988644, train loss: 14.273383, valid precision: 0.837800, valid loss: 193.205222
epoch: 1472, train precision: 0.988244, train loss: 14.715836, valid precision: 0.836400, valid loss: 197.703283
epoch: 1473, train precision: 0.987333, train loss: 14.804749, valid precision: 0.840200, valid loss: 176.167169
epoch: 1474, train precision: 0.984667, train loss: 16.772061, valid precision: 0.837400, valid loss: 197.151581
epoch: 1475, train precision: 0.987422, train loss: 14.925688, valid precision: 0.840000, valid loss: 175.775079
epoch: 1476, train precision: 0.986556, train loss: 15.161976, valid precision: 0.835400, valid loss: 179.460573
epoch: 1477, train precision: 0.989600, train loss: 14.012679, valid precision: 0.844800, valid loss: 187.218046
epoch: 1478, train precision: 0.987333, train loss: 15.311381, valid precision: 0.837800, valid loss: 199.326256
epoch: 1479, train precision: 0.986222, train loss: 15.664237, valid precision: 0.830800, valid loss: 185.108488
epoch: 1480, train precision: 0.986156, train loss: 15.527805, valid precision: 0.840800, valid loss: 189.786432
epoch: 1481, train precision: 0.986644, train loss: 15.316278, valid precision: 0.836000, valid loss: 190.295181
epoch: 1482, train precision: 0.986178, train loss: 15.687513, valid precision: 0.837000, valid loss: 191.792046
epoch: 1483, train precision: 0.987844, train loss: 14.794526, valid precision: 0.836800, valid loss: 178.883409
epoch: 1484, train precision: 0.987911, train loss: 14.750923, valid precision: 0.830400, valid loss: 191.737634
epoch: 1485, train precision: 0.989844, train loss: 13.670922, valid precision: 0.839400, valid loss: 176.190596
epoch: 1486, train precision: 0.987800, train loss: 15.028242, valid precision: 0.832800, valid loss: 195.115208
epoch: 1487, train precision: 0.991200, train loss: 13.522122, valid precision: 0.833000, valid loss: 189.573276
epoch: 1488, train precision: 0.985489, train loss: 15.897740, valid precision: 0.827600, valid loss: 190.945109
epoch: 1489, train precision: 0.985867, train loss: 15.768073, valid precision: 0.832800, valid loss: 175.076704
epoch: 1490, train precision: 0.981533, train loss: 17.333868, valid precision: 0.829200, valid loss: 184.024422
epoch: 1491, train precision: 0.986533, train loss: 15.230022, valid precision: 0.832800, valid loss: 195.401618
epoch: 1492, train precision: 0.982000, train loss: 17.821257, valid precision: 0.830800, valid loss: 196.609351
epoch: 1493, train precision: 0.984933, train loss: 16.389912, valid precision: 0.830000, valid loss: 194.279219
epoch: 1494, train precision: 0.986489, train loss: 15.523770, valid precision: 0.829800, valid loss: 203.908303
epoch: 1495, train precision: 0.983956, train loss: 16.836736, valid precision: 0.832200, valid loss: 197.688947
epoch: 1496, train precision: 0.986578, train loss: 14.958783, valid precision: 0.832400, valid loss: 190.248438
epoch: 1497, train precision: 0.987044, train loss: 15.480210, valid precision: 0.826600, valid loss: 191.076994
epoch: 1498, train precision: 0.986222, train loss: 15.286327, valid precision: 0.830600, valid loss: 198.501844
epoch: 1499, train precision: 0.989933, train loss: 14.050780, valid precision: 0.839800, valid loss: 202.431992
epoch: 1500, train precision: 0.987222, train loss: 14.884934, valid precision: 0.836600, valid loss: 189.243867
epoch: 1501, train precision: 0.987956, train loss: 14.426930, valid precision: 0.835200, valid loss: 185.944997
epoch: 1502, train precision: 0.988444, train loss: 14.801216, valid precision: 0.836400, valid loss: 196.712126
epoch: 1503, train precision: 0.988422, train loss: 14.891600, valid precision: 0.835600, valid loss: 188.621817
epoch: 1504, train precision: 0.984956, train loss: 16.273457, valid precision: 0.834600, valid loss: 188.007227
epoch: 1505, train precision: 0.989156, train loss: 14.459465, valid precision: 0.835000, valid loss: 198.129353
epoch: 1506, train precision: 0.984867, train loss: 16.158499, valid precision: 0.829800, valid loss: 196.815123
epoch: 1507, train precision: 0.986378, train loss: 15.475565, valid precision: 0.839000, valid loss: 188.144447
epoch: 1508, train precision: 0.989311, train loss: 14.119268, valid precision: 0.833600, valid loss: 195.430874
epoch: 1509, train precision: 0.986622, train loss: 15.206076, valid precision: 0.832600, valid loss: 187.184685
epoch: 1510, train precision: 0.984711, train loss: 16.503587, valid precision: 0.831600, valid loss: 196.732896
epoch: 1511, train precision: 0.987889, train loss: 14.583632, valid precision: 0.830600, valid loss: 173.550629
epoch: 1512, train precision: 0.988000, train loss: 14.984248, valid precision: 0.833400, valid loss: 199.354097
epoch: 1513, train precision: 0.988289, train loss: 14.473184, valid precision: 0.834800, valid loss: 183.158319
epoch: 1514, train precision: 0.986778, train loss: 15.215480, valid precision: 0.835200, valid loss: 189.391948
epoch: 1515, train precision: 0.986956, train loss: 15.020385, valid precision: 0.828200, valid loss: 166.336018
epoch: 1516, train precision: 0.987978, train loss: 14.613075, valid precision: 0.837200, valid loss: 193.655802
epoch: 1517, train precision: 0.985778, train loss: 15.639523, valid precision: 0.830800, valid loss: 182.415027
epoch: 1518, train precision: 0.986289, train loss: 15.587003, valid precision: 0.828800, valid loss: 186.901076
epoch: 1519, train precision: 0.987333, train loss: 15.358113, valid precision: 0.833600, valid loss: 192.671391
epoch: 1520, train precision: 0.985933, train loss: 16.008330, valid precision: 0.829400, valid loss: 187.673696
epoch: 1521, train precision: 0.987533, train loss: 15.520817, valid precision: 0.825000, valid loss: 193.068231
epoch: 1522, train precision: 0.988844, train loss: 14.278595, valid precision: 0.835200, valid loss: 185.385334
epoch: 1523, train precision: 0.990333, train loss: 13.608365, valid precision: 0.839600, valid loss: 183.996145
epoch: 1524, train precision: 0.987422, train loss: 15.377277, valid precision: 0.841400, valid loss: 198.300834
epoch: 1525, train precision: 0.982689, train loss: 17.126039, valid precision: 0.825600, valid loss: 192.022951
epoch: 1526, train precision: 0.988378, train loss: 14.746260, valid precision: 0.835400, valid loss: 190.147461
epoch: 1527, train precision: 0.986956, train loss: 15.317655, valid precision: 0.831000, valid loss: 190.294816
epoch: 1528, train precision: 0.988756, train loss: 14.978831, valid precision: 0.829600, valid loss: 195.775170
epoch: 1529, train precision: 0.986444, train loss: 15.558574, valid precision: 0.832200, valid loss: 196.493671
epoch: 1530, train precision: 0.987578, train loss: 14.768686, valid precision: 0.835200, valid loss: 198.363417
epoch: 1531, train precision: 0.987511, train loss: 14.779417, valid precision: 0.839600, valid loss: 187.245060
epoch: 1532, train precision: 0.987022, train loss: 15.220262, valid precision: 0.833400, valid loss: 195.695358
epoch: 1533, train precision: 0.987311, train loss: 15.200475, valid precision: 0.832200, valid loss: 197.881918
epoch: 1534, train precision: 0.985889, train loss: 15.641845, valid precision: 0.833400, valid loss: 197.994115
epoch: 1535, train precision: 0.987867, train loss: 15.202082, valid precision: 0.833800, valid loss: 203.242536
epoch: 1536, train precision: 0.986867, train loss: 15.185340, valid precision: 0.834600, valid loss: 186.931030
epoch: 1537, train precision: 0.989911, train loss: 13.952464, valid precision: 0.838400, valid loss: 178.295252
epoch: 1538, train precision: 0.983844, train loss: 16.282006, valid precision: 0.827800, valid loss: 197.978410
epoch: 1539, train precision: 0.988556, train loss: 14.491859, valid precision: 0.833000, valid loss: 181.516433
epoch: 1540, train precision: 0.986667, train loss: 15.561745, valid precision: 0.829600, valid loss: 188.027244
epoch: 1541, train precision: 0.985978, train loss: 15.495753, valid precision: 0.835600, valid loss: 207.535124
epoch: 1542, train precision: 0.983778, train loss: 16.366672, valid precision: 0.831200, valid loss: 185.938778
epoch: 1543, train precision: 0.988378, train loss: 14.528017, valid precision: 0.829000, valid loss: 190.209116
epoch: 1544, train precision: 0.986289, train loss: 15.732302, valid precision: 0.837000, valid loss: 198.504965
epoch: 1545, train precision: 0.982889, train loss: 16.966443, valid precision: 0.825400, valid loss: 201.850068
epoch: 1546, train precision: 0.983467, train loss: 17.021314, valid precision: 0.826200, valid loss: 195.845993
epoch: 1547, train precision: 0.990711, train loss: 13.469694, valid precision: 0.835800, valid loss: 184.822708
epoch: 1548, train precision: 0.990422, train loss: 13.922569, valid precision: 0.830200, valid loss: 193.593118
epoch: 1549, train precision: 0.988111, train loss: 14.876824, valid precision: 0.828800, valid loss: 189.092376
epoch: 1550, train precision: 0.988222, train loss: 14.743554, valid precision: 0.833800, valid loss: 196.862785
epoch: 1551, train precision: 0.987111, train loss: 15.128459, valid precision: 0.832400, valid loss: 191.307020
epoch: 1552, train precision: 0.984267, train loss: 16.569459, valid precision: 0.826400, valid loss: 205.723529
epoch: 1553, train precision: 0.985978, train loss: 15.741927, valid precision: 0.829000, valid loss: 195.582657
epoch: 1554, train precision: 0.988444, train loss: 14.780380, valid precision: 0.832600, valid loss: 195.171066
epoch: 1555, train precision: 0.985422, train loss: 16.521715, valid precision: 0.830000, valid loss: 201.760038
epoch: 1556, train precision: 0.989556, train loss: 14.028695, valid precision: 0.832200, valid loss: 194.651972
epoch: 1557, train precision: 0.987644, train loss: 15.080561, valid precision: 0.831400, valid loss: 194.539404
epoch: 1558, train precision: 0.989867, train loss: 14.013133, valid precision: 0.831400, valid loss: 193.356319
epoch: 1559, train precision: 0.988467, train loss: 14.632704, valid precision: 0.830600, valid loss: 191.742853
epoch: 1560, train precision: 0.983711, train loss: 17.227198, valid precision: 0.824600, valid loss: 215.823651
epoch: 1561, train precision: 0.989133, train loss: 14.162031, valid precision: 0.835600, valid loss: 191.193290
epoch: 1562, train precision: 0.987000, train loss: 15.079671, valid precision: 0.831400, valid loss: 185.333082
epoch: 1563, train precision: 0.977911, train loss: 20.268164, valid precision: 0.818400, valid loss: 216.025801
epoch: 1564, train precision: 0.984578, train loss: 16.125925, valid precision: 0.828800, valid loss: 190.948493
epoch: 1565, train precision: 0.990244, train loss: 13.863653, valid precision: 0.837400, valid loss: 206.717961
epoch: 1566, train precision: 0.986000, train loss: 15.958164, valid precision: 0.829000, valid loss: 211.370174
epoch: 1567, train precision: 0.988822, train loss: 14.463615, valid precision: 0.834200, valid loss: 189.934799
epoch: 1568, train precision: 0.983822, train loss: 16.526211, valid precision: 0.832200, valid loss: 188.101695
epoch: 1569, train precision: 0.987956, train loss: 15.281144, valid precision: 0.832800, valid loss: 198.383001
epoch: 1570, train precision: 0.987244, train loss: 15.733031, valid precision: 0.831800, valid loss: 193.110671
epoch: 1571, train precision: 0.985667, train loss: 15.822754, valid precision: 0.832600, valid loss: 197.997286
epoch: 1572, train precision: 0.988867, train loss: 14.434523, valid precision: 0.835000, valid loss: 181.229555
epoch: 1573, train precision: 0.984844, train loss: 16.409469, valid precision: 0.835000, valid loss: 202.376260
epoch: 1574, train precision: 0.986667, train loss: 15.250156, valid precision: 0.834800, valid loss: 194.134787
epoch: 1575, train precision: 0.986444, train loss: 15.521851, valid precision: 0.822400, valid loss: 196.287766
epoch: 1576, train precision: 0.984711, train loss: 16.309735, valid precision: 0.827200, valid loss: 204.588605
epoch: 1577, train precision: 0.988733, train loss: 14.255479, valid precision: 0.831200, valid loss: 202.192254
epoch: 1578, train precision: 0.986956, train loss: 15.125347, valid precision: 0.828800, valid loss: 187.617936
epoch: 1579, train precision: 0.988178, train loss: 14.706058, valid precision: 0.836600, valid loss: 195.438949
epoch: 1580, train precision: 0.985822, train loss: 15.933231, valid precision: 0.833000, valid loss: 188.080747
epoch: 1581, train precision: 0.985067, train loss: 15.896075, valid precision: 0.830000, valid loss: 194.093202
epoch: 1582, train precision: 0.986533, train loss: 15.896885, valid precision: 0.830600, valid loss: 202.824996
epoch: 1583, train precision: 0.984467, train loss: 16.722117, valid precision: 0.839600, valid loss: 201.943494
epoch: 1584, train precision: 0.988089, train loss: 14.752572, valid precision: 0.831600, valid loss: 205.274293
epoch: 1585, train precision: 0.985444, train loss: 15.791321, valid precision: 0.830800, valid loss: 188.990261
epoch: 1586, train precision: 0.984156, train loss: 16.538360, valid precision: 0.831800, valid loss: 185.081751
epoch: 1587, train precision: 0.987556, train loss: 15.080404, valid precision: 0.832800, valid loss: 185.632396
epoch: 1588, train precision: 0.988111, train loss: 14.330908, valid precision: 0.829600, valid loss: 174.845976
epoch: 1589, train precision: 0.987644, train loss: 15.317593, valid precision: 0.831400, valid loss: 211.932833
epoch: 1590, train precision: 0.985422, train loss: 15.947869, valid precision: 0.829000, valid loss: 196.510174
epoch: 1591, train precision: 0.985711, train loss: 15.898634, valid precision: 0.833800, valid loss: 188.126738
epoch: 1592, train precision: 0.989800, train loss: 14.245798, valid precision: 0.838600, valid loss: 191.612358
epoch: 1593, train precision: 0.984733, train loss: 16.309830, valid precision: 0.832400, valid loss: 197.682458
epoch: 1594, train precision: 0.983556, train loss: 16.720764, valid precision: 0.834200, valid loss: 192.251723
epoch: 1595, train precision: 0.987089, train loss: 15.006593, valid precision: 0.826800, valid loss: 202.296229
epoch: 1596, train precision: 0.988667, train loss: 14.139877, valid precision: 0.833200, valid loss: 197.923086
epoch: 1597, train precision: 0.987800, train loss: 14.655367, valid precision: 0.830400, valid loss: 192.755064
epoch: 1598, train precision: 0.989711, train loss: 14.240929, valid precision: 0.834000, valid loss: 193.104876
epoch: 1599, train precision: 0.986489, train loss: 15.503365, valid precision: 0.830800, valid loss: 193.220367
epoch: 1600, train precision: 0.985511, train loss: 15.540797, valid precision: 0.830600, valid loss: 190.452894
epoch: 1601, train precision: 0.985600, train loss: 16.019945, valid precision: 0.829400, valid loss: 206.518550
epoch: 1602, train precision: 0.986711, train loss: 16.191792, valid precision: 0.829200, valid loss: 218.181566
epoch: 1603, train precision: 0.988778, train loss: 14.611551, valid precision: 0.832000, valid loss: 209.629879
epoch: 1604, train precision: 0.989156, train loss: 14.293890, valid precision: 0.835000, valid loss: 188.069462
epoch: 1605, train precision: 0.987911, train loss: 14.878872, valid precision: 0.836400, valid loss: 182.706259
epoch: 1606, train precision: 0.987911, train loss: 14.430731, valid precision: 0.829400, valid loss: 193.255953
epoch: 1607, train precision: 0.984089, train loss: 16.526813, valid precision: 0.826600, valid loss: 202.098746
epoch: 1608, train precision: 0.986400, train loss: 15.894837, valid precision: 0.832000, valid loss: 201.741861
epoch: 1609, train precision: 0.988533, train loss: 14.569596, valid precision: 0.836200, valid loss: 180.710319
epoch: 1610, train precision: 0.986800, train loss: 14.917731, valid precision: 0.828600, valid loss: 188.811999
epoch: 1611, train precision: 0.988444, train loss: 14.561871, valid precision: 0.829800, valid loss: 198.412415
epoch: 1612, train precision: 0.988956, train loss: 14.664042, valid precision: 0.834800, valid loss: 202.239321
epoch: 1613, train precision: 0.983133, train loss: 17.085394, valid precision: 0.826400, valid loss: 184.726397
epoch: 1614, train precision: 0.989089, train loss: 14.387479, valid precision: 0.831800, valid loss: 191.327115
epoch: 1615, train precision: 0.981778, train loss: 17.759189, valid precision: 0.820000, valid loss: 200.588629
epoch: 1616, train precision: 0.985844, train loss: 16.167504, valid precision: 0.829400, valid loss: 208.324667
epoch: 1617, train precision: 0.981689, train loss: 17.440375, valid precision: 0.821800, valid loss: 203.282848
epoch: 1618, train precision: 0.985844, train loss: 15.661975, valid precision: 0.833600, valid loss: 202.582065
epoch: 1619, train precision: 0.988778, train loss: 14.516700, valid precision: 0.834000, valid loss: 197.919114
epoch: 1620, train precision: 0.986822, train loss: 15.541596, valid precision: 0.828400, valid loss: 195.930384
epoch: 1621, train precision: 0.987267, train loss: 15.099665, valid precision: 0.830800, valid loss: 197.828052
epoch: 1622, train precision: 0.988578, train loss: 14.774269, valid precision: 0.837600, valid loss: 206.717711
epoch: 1623, train precision: 0.984111, train loss: 16.367772, valid precision: 0.834600, valid loss: 181.142476
epoch: 1624, train precision: 0.986044, train loss: 15.910075, valid precision: 0.833800, valid loss: 204.998586
epoch: 1625, train precision: 0.985533, train loss: 16.145932, valid precision: 0.837400, valid loss: 183.809363
epoch: 1626, train precision: 0.981533, train loss: 18.331631, valid precision: 0.828800, valid loss: 185.736950
epoch: 1627, train precision: 0.983089, train loss: 16.912967, valid precision: 0.830800, valid loss: 189.770337
epoch: 1628, train precision: 0.987822, train loss: 14.898279, valid precision: 0.832600, valid loss: 197.157079
epoch: 1629, train precision: 0.986911, train loss: 15.340433, valid precision: 0.834000, valid loss: 195.093598
epoch: 1630, train precision: 0.986200, train loss: 15.687570, valid precision: 0.829600, valid loss: 188.257355
epoch: 1631, train precision: 0.986333, train loss: 15.365349, valid precision: 0.836000, valid loss: 198.732599
epoch: 1632, train precision: 0.986444, train loss: 15.916720, valid precision: 0.836200, valid loss: 192.630293
epoch: 1633, train precision: 0.985889, train loss: 16.102841, valid precision: 0.837400, valid loss: 183.222161
epoch: 1634, train precision: 0.987178, train loss: 15.055187, valid precision: 0.833600, valid loss: 183.297593
epoch: 1635, train precision: 0.985800, train loss: 15.666122, valid precision: 0.830000, valid loss: 177.967298
epoch: 1636, train precision: 0.984711, train loss: 16.283581, valid precision: 0.831800, valid loss: 184.765237
epoch: 1637, train precision: 0.984244, train loss: 16.399845, valid precision: 0.833800, valid loss: 196.649493
epoch: 1638, train precision: 0.986889, train loss: 15.835234, valid precision: 0.834000, valid loss: 200.944803
epoch: 1639, train precision: 0.986933, train loss: 15.239329, valid precision: 0.836400, valid loss: 198.077587
epoch: 1640, train precision: 0.987511, train loss: 15.140491, valid precision: 0.839000, valid loss: 189.160983
epoch: 1641, train precision: 0.986222, train loss: 15.719993, valid precision: 0.836400, valid loss: 181.766525
epoch: 1642, train precision: 0.989222, train loss: 14.712880, valid precision: 0.839400, valid loss: 193.080792
epoch: 1643, train precision: 0.983356, train loss: 17.267703, valid precision: 0.832600, valid loss: 202.010910
epoch: 1644, train precision: 0.987733, train loss: 15.200341, valid precision: 0.838000, valid loss: 200.127245
epoch: 1645, train precision: 0.985289, train loss: 15.765659, valid precision: 0.837200, valid loss: 184.523631
epoch: 1646, train precision: 0.987400, train loss: 15.063227, valid precision: 0.827000, valid loss: 197.866709
epoch: 1647, train precision: 0.988200, train loss: 14.505672, valid precision: 0.835200, valid loss: 184.460928
epoch: 1648, train precision: 0.985222, train loss: 16.221975, valid precision: 0.829200, valid loss: 198.703160
epoch: 1649, train precision: 0.985200, train loss: 15.828271, valid precision: 0.831600, valid loss: 182.420268
epoch: 1650, train precision: 0.988711, train loss: 14.708103, valid precision: 0.832400, valid loss: 197.837957
epoch: 1651, train precision: 0.987644, train loss: 14.909197, valid precision: 0.839200, valid loss: 181.327390
epoch: 1652, train precision: 0.990067, train loss: 14.356184, valid precision: 0.835600, valid loss: 209.738088
epoch: 1653, train precision: 0.982178, train loss: 17.551735, valid precision: 0.830800, valid loss: 204.985572
epoch: 1654, train precision: 0.985378, train loss: 16.262288, valid precision: 0.827400, valid loss: 204.457616
epoch: 1655, train precision: 0.990400, train loss: 13.832684, valid precision: 0.841200, valid loss: 203.396617
epoch: 1656, train precision: 0.983978, train loss: 16.618729, valid precision: 0.834600, valid loss: 180.014966
epoch: 1657, train precision: 0.989067, train loss: 14.438430, valid precision: 0.835000, valid loss: 180.929616
epoch: 1658, train precision: 0.989422, train loss: 14.243401, valid precision: 0.833200, valid loss: 187.068505
epoch: 1659, train precision: 0.987222, train loss: 15.770679, valid precision: 0.837000, valid loss: 198.088077
epoch: 1660, train precision: 0.986289, train loss: 16.006325, valid precision: 0.835000, valid loss: 200.931260
epoch: 1661, train precision: 0.981778, train loss: 17.881564, valid precision: 0.827600, valid loss: 197.513765
epoch: 1662, train precision: 0.988578, train loss: 14.812350, valid precision: 0.837800, valid loss: 193.115966
epoch: 1663, train precision: 0.989844, train loss: 14.346166, valid precision: 0.838000, valid loss: 199.404784
epoch: 1664, train precision: 0.981400, train loss: 18.441348, valid precision: 0.834000, valid loss: 195.329030
epoch: 1665, train precision: 0.980533, train loss: 18.057073, valid precision: 0.833400, valid loss: 180.665949
epoch: 1666, train precision: 0.988111, train loss: 14.946911, valid precision: 0.835600, valid loss: 188.168459
epoch: 1667, train precision: 0.986111, train loss: 15.627241, valid precision: 0.834000, valid loss: 183.225276
epoch: 1668, train precision: 0.984089, train loss: 16.571026, valid precision: 0.834600, valid loss: 196.787878
epoch: 1669, train precision: 0.987400, train loss: 15.227261, valid precision: 0.837000, valid loss: 179.296521
epoch: 1670, train precision: 0.982444, train loss: 17.687063, valid precision: 0.833400, valid loss: 179.925823
epoch: 1671, train precision: 0.990933, train loss: 13.726038, valid precision: 0.845200, valid loss: 193.839984
epoch: 1672, train precision: 0.984311, train loss: 16.687554, valid precision: 0.830600, valid loss: 187.884618
epoch: 1673, train precision: 0.982311, train loss: 17.602971, valid precision: 0.828600, valid loss: 175.644535
epoch: 1674, train precision: 0.988711, train loss: 14.550422, valid precision: 0.834800, valid loss: 178.345402
epoch: 1675, train precision: 0.990000, train loss: 13.872061, valid precision: 0.828200, valid loss: 202.484589
epoch: 1676, train precision: 0.988822, train loss: 14.830808, valid precision: 0.829200, valid loss: 182.154282
epoch: 1677, train precision: 0.982844, train loss: 17.075908, valid precision: 0.822200, valid loss: 187.741287
epoch: 1678, train precision: 0.985511, train loss: 15.967794, valid precision: 0.828400, valid loss: 188.109954
epoch: 1679, train precision: 0.983578, train loss: 17.697446, valid precision: 0.830400, valid loss: 202.187464
epoch: 1680, train precision: 0.988489, train loss: 14.731268, valid precision: 0.837600, valid loss: 188.050444
epoch: 1681, train precision: 0.987667, train loss: 14.748776, valid precision: 0.834200, valid loss: 177.954445
epoch: 1682, train precision: 0.988178, train loss: 14.970979, valid precision: 0.834800, valid loss: 172.856180
epoch: 1683, train precision: 0.986911, train loss: 15.583905, valid precision: 0.827400, valid loss: 187.884889
epoch: 1684, train precision: 0.985489, train loss: 16.159386, valid precision: 0.834000, valid loss: 191.466210
epoch: 1685, train precision: 0.990044, train loss: 14.163972, valid precision: 0.834800, valid loss: 195.761948
epoch: 1686, train precision: 0.986644, train loss: 15.435946, valid precision: 0.828000, valid loss: 185.044173
epoch: 1687, train precision: 0.987400, train loss: 15.482582, valid precision: 0.837000, valid loss: 197.659918
epoch: 1688, train precision: 0.987178, train loss: 15.083410, valid precision: 0.837600, valid loss: 188.648385
epoch: 1689, train precision: 0.983133, train loss: 17.525148, valid precision: 0.834400, valid loss: 212.078958
epoch: 1690, train precision: 0.982644, train loss: 18.159020, valid precision: 0.825000, valid loss: 203.409232
epoch: 1691, train precision: 0.986556, train loss: 15.806712, valid precision: 0.831600, valid loss: 207.173146
epoch: 1692, train precision: 0.986133, train loss: 16.092653, valid precision: 0.833000, valid loss: 203.739758
epoch: 1693, train precision: 0.985667, train loss: 16.742119, valid precision: 0.830800, valid loss: 200.714112
epoch: 1694, train precision: 0.985756, train loss: 15.813617, valid precision: 0.832600, valid loss: 204.253484
epoch: 1695, train precision: 0.982733, train loss: 17.504859, valid precision: 0.832800, valid loss: 189.390580
epoch: 1696, train precision: 0.986756, train loss: 15.161970, valid precision: 0.833200, valid loss: 191.911045
epoch: 1697, train precision: 0.986289, train loss: 15.989919, valid precision: 0.836400, valid loss: 191.327290
epoch: 1698, train precision: 0.984267, train loss: 16.971528, valid precision: 0.840200, valid loss: 207.125314
epoch: 1699, train precision: 0.984156, train loss: 16.726191, valid precision: 0.830600, valid loss: 191.079500
epoch: 1700, train precision: 0.990067, train loss: 14.051970, valid precision: 0.835000, valid loss: 176.468299
epoch: 1701, train precision: 0.987311, train loss: 15.064404, valid precision: 0.837200, valid loss: 182.862261
epoch: 1702, train precision: 0.985600, train loss: 15.805756, valid precision: 0.837000, valid loss: 194.784985
epoch: 1703, train precision: 0.988044, train loss: 14.996179, valid precision: 0.840800, valid loss: 194.471563
epoch: 1704, train precision: 0.984378, train loss: 16.486658, valid precision: 0.830400, valid loss: 184.113657
epoch: 1705, train precision: 0.986622, train loss: 15.423855, valid precision: 0.835400, valid loss: 197.634647
epoch: 1706, train precision: 0.987467, train loss: 14.918441, valid precision: 0.831800, valid loss: 196.572327
epoch: 1707, train precision: 0.984244, train loss: 16.329497, valid precision: 0.829000, valid loss: 178.029658
epoch: 1708, train precision: 0.982089, train loss: 17.801890, valid precision: 0.826800, valid loss: 189.305860
epoch: 1709, train precision: 0.986200, train loss: 15.794818, valid precision: 0.837600, valid loss: 183.568838
epoch: 1710, train precision: 0.984978, train loss: 16.003542, valid precision: 0.828400, valid loss: 173.135447
epoch: 1711, train precision: 0.986222, train loss: 15.856758, valid precision: 0.834600, valid loss: 173.323046
epoch: 1712, train precision: 0.981578, train loss: 18.167356, valid precision: 0.824000, valid loss: 180.012529
epoch: 1713, train precision: 0.989400, train loss: 14.379252, valid precision: 0.829800, valid loss: 181.093704
epoch: 1714, train precision: 0.986578, train loss: 15.396320, valid precision: 0.834600, valid loss: 187.755574
epoch: 1715, train precision: 0.985733, train loss: 16.200117, valid precision: 0.825200, valid loss: 196.824891
epoch: 1716, train precision: 0.989178, train loss: 14.561504, valid precision: 0.833800, valid loss: 196.500145
epoch: 1717, train precision: 0.983444, train loss: 17.756394, valid precision: 0.830600, valid loss: 201.379528
epoch: 1718, train precision: 0.988667, train loss: 14.824656, valid precision: 0.834400, valid loss: 196.750774
epoch: 1719, train precision: 0.986644, train loss: 15.533342, valid precision: 0.833000, valid loss: 184.512351
epoch: 1720, train precision: 0.985933, train loss: 16.175914, valid precision: 0.831400, valid loss: 205.386179
epoch: 1721, train precision: 0.986000, train loss: 15.835689, valid precision: 0.834000, valid loss: 200.245361
epoch: 1722, train precision: 0.989511, train loss: 14.350640, valid precision: 0.834000, valid loss: 202.769478
epoch: 1723, train precision: 0.988978, train loss: 14.524329, valid precision: 0.834600, valid loss: 195.916442
epoch: 1724, train precision: 0.984467, train loss: 16.490161, valid precision: 0.828600, valid loss: 196.406000
epoch: 1725, train precision: 0.989422, train loss: 14.294222, valid precision: 0.840400, valid loss: 195.788782
epoch: 1726, train precision: 0.983333, train loss: 16.750925, valid precision: 0.824200, valid loss: 196.264973
epoch: 1727, train precision: 0.988778, train loss: 14.588327, valid precision: 0.836600, valid loss: 196.193380
epoch: 1728, train precision: 0.984533, train loss: 16.637101, valid precision: 0.834000, valid loss: 189.473986
epoch: 1729, train precision: 0.986422, train loss: 15.806532, valid precision: 0.825800, valid loss: 215.430710
epoch: 1730, train precision: 0.987267, train loss: 15.157627, valid precision: 0.827600, valid loss: 195.648465
epoch: 1731, train precision: 0.989200, train loss: 14.352843, valid precision: 0.835600, valid loss: 191.043587
epoch: 1732, train precision: 0.985844, train loss: 15.939722, valid precision: 0.828400, valid loss: 177.848384
epoch: 1733, train precision: 0.986511, train loss: 15.718535, valid precision: 0.828800, valid loss: 205.931847
epoch: 1734, train precision: 0.988600, train loss: 14.902970, valid precision: 0.835000, valid loss: 186.186062
epoch: 1735, train precision: 0.986533, train loss: 15.944648, valid precision: 0.833400, valid loss: 201.198737
epoch: 1736, train precision: 0.986756, train loss: 15.654127, valid precision: 0.830200, valid loss: 187.606225
epoch: 1737, train precision: 0.988578, train loss: 14.744936, valid precision: 0.829600, valid loss: 199.605865
epoch: 1738, train precision: 0.983578, train loss: 17.388822, valid precision: 0.823400, valid loss: 197.533965
epoch: 1739, train precision: 0.989178, train loss: 14.409000, valid precision: 0.829800, valid loss: 190.470469
epoch: 1740, train precision: 0.987511, train loss: 14.854518, valid precision: 0.827200, valid loss: 204.765682
epoch: 1741, train precision: 0.986267, train loss: 15.810105, valid precision: 0.826400, valid loss: 187.729059
epoch: 1742, train precision: 0.985578, train loss: 15.872824, valid precision: 0.834000, valid loss: 189.294826
epoch: 1743, train precision: 0.982911, train loss: 17.733592, valid precision: 0.823200, valid loss: 198.348461
epoch: 1744, train precision: 0.982889, train loss: 17.635319, valid precision: 0.824600, valid loss: 192.683982
epoch: 1745, train precision: 0.988822, train loss: 14.885269, valid precision: 0.836000, valid loss: 195.603835
epoch: 1746, train precision: 0.985867, train loss: 16.035516, valid precision: 0.834400, valid loss: 190.962015
epoch: 1747, train precision: 0.988200, train loss: 14.862623, valid precision: 0.833400, valid loss: 186.488019
epoch: 1748, train precision: 0.989244, train loss: 14.471509, valid precision: 0.834200, valid loss: 188.253298
epoch: 1749, train precision: 0.986444, train loss: 15.125689, valid precision: 0.835600, valid loss: 187.048299
epoch: 1750, train precision: 0.984378, train loss: 17.063024, valid precision: 0.827000, valid loss: 193.677526
epoch: 1751, train precision: 0.988156, train loss: 15.038259, valid precision: 0.835400, valid loss: 199.428686
epoch: 1752, train precision: 0.986622, train loss: 15.792858, valid precision: 0.833000, valid loss: 203.286553
epoch: 1753, train precision: 0.987556, train loss: 14.790056, valid precision: 0.835400, valid loss: 184.475555
epoch: 1754, train precision: 0.985556, train loss: 16.191334, valid precision: 0.833400, valid loss: 198.642162
epoch: 1755, train precision: 0.983600, train loss: 16.958445, valid precision: 0.828600, valid loss: 192.745074
epoch: 1756, train precision: 0.988156, train loss: 14.876586, valid precision: 0.838000, valid loss: 190.712760
epoch: 1757, train precision: 0.986578, train loss: 15.870539, valid precision: 0.833400, valid loss: 193.882144
epoch: 1758, train precision: 0.986533, train loss: 15.835951, valid precision: 0.831000, valid loss: 185.066312
epoch: 1759, train precision: 0.987956, train loss: 14.896965, valid precision: 0.833400, valid loss: 198.854984
epoch: 1760, train precision: 0.984067, train loss: 16.487803, valid precision: 0.833000, valid loss: 202.429940
epoch: 1761, train precision: 0.987111, train loss: 15.378213, valid precision: 0.829200, valid loss: 189.173308
epoch: 1762, train precision: 0.985889, train loss: 16.191285, valid precision: 0.827400, valid loss: 198.211217
epoch: 1763, train precision: 0.986133, train loss: 15.857707, valid precision: 0.831400, valid loss: 176.681849
epoch: 1764, train precision: 0.990422, train loss: 13.822413, valid precision: 0.842600, valid loss: 192.710005
epoch: 1765, train precision: 0.985956, train loss: 16.014546, valid precision: 0.834600, valid loss: 201.214560
epoch: 1766, train precision: 0.988956, train loss: 14.361723, valid precision: 0.832800, valid loss: 196.040136
epoch: 1767, train precision: 0.989111, train loss: 14.714216, valid precision: 0.834200, valid loss: 209.342442
epoch: 1768, train precision: 0.984533, train loss: 16.201761, valid precision: 0.827600, valid loss: 181.246223
epoch: 1769, train precision: 0.988200, train loss: 14.856325, valid precision: 0.839600, valid loss: 194.133112
epoch: 1770, train precision: 0.985822, train loss: 16.233029, valid precision: 0.835200, valid loss: 191.708890
epoch: 1771, train precision: 0.986467, train loss: 15.612307, valid precision: 0.836600, valid loss: 182.309996
epoch: 1772, train precision: 0.985511, train loss: 16.252972, valid precision: 0.837600, valid loss: 195.261154
epoch: 1773, train precision: 0.987511, train loss: 15.443172, valid precision: 0.832400, valid loss: 201.182101
epoch: 1774, train precision: 0.979289, train loss: 19.216907, valid precision: 0.828800, valid loss: 194.855354
epoch: 1775, train precision: 0.987022, train loss: 15.804009, valid precision: 0.840200, valid loss: 203.296411
epoch: 1776, train precision: 0.982756, train loss: 17.308046, valid precision: 0.828200, valid loss: 185.709237
epoch: 1777, train precision: 0.984511, train loss: 16.889956, valid precision: 0.831600, valid loss: 206.099446
epoch: 1778, train precision: 0.988111, train loss: 14.539516, valid precision: 0.838800, valid loss: 197.658414
epoch: 1779, train precision: 0.983511, train loss: 17.143298, valid precision: 0.827000, valid loss: 203.757922
epoch: 1780, train precision: 0.986667, train loss: 15.561930, valid precision: 0.833000, valid loss: 205.023864
epoch: 1781, train precision: 0.987578, train loss: 15.311605, valid precision: 0.832200, valid loss: 201.103282
epoch: 1782, train precision: 0.988556, train loss: 14.748558, valid precision: 0.836000, valid loss: 192.040823
epoch: 1783, train precision: 0.986022, train loss: 15.789982, valid precision: 0.834800, valid loss: 185.336012
epoch: 1784, train precision: 0.989867, train loss: 14.048089, valid precision: 0.836000, valid loss: 192.706659
epoch: 1785, train precision: 0.984800, train loss: 16.597482, valid precision: 0.828200, valid loss: 199.695512
epoch: 1786, train precision: 0.985978, train loss: 16.660199, valid precision: 0.834800, valid loss: 190.050777
epoch: 1787, train precision: 0.988200, train loss: 14.823008, valid precision: 0.837600, valid loss: 199.383196
epoch: 1788, train precision: 0.987667, train loss: 15.352323, valid precision: 0.834600, valid loss: 192.965698
epoch: 1789, train precision: 0.986356, train loss: 15.443973, valid precision: 0.832000, valid loss: 189.466830
epoch: 1790, train precision: 0.987800, train loss: 15.486540, valid precision: 0.833600, valid loss: 201.881741
epoch: 1791, train precision: 0.987978, train loss: 15.285325, valid precision: 0.833200, valid loss: 211.457782
epoch: 1792, train precision: 0.985533, train loss: 16.160177, valid precision: 0.830000, valid loss: 194.213870
epoch: 1793, train precision: 0.984000, train loss: 17.038147, valid precision: 0.828000, valid loss: 205.820430
epoch: 1794, train precision: 0.986044, train loss: 16.183853, valid precision: 0.834400, valid loss: 182.746806
epoch: 1795, train precision: 0.988978, train loss: 14.984437, valid precision: 0.842400, valid loss: 196.558288
epoch: 1796, train precision: 0.987356, train loss: 15.399453, valid precision: 0.832200, valid loss: 198.372543
epoch: 1797, train precision: 0.990978, train loss: 14.102081, valid precision: 0.838600, valid loss: 204.883694
epoch: 1798, train precision: 0.988222, train loss: 15.260819, valid precision: 0.834800, valid loss: 202.083067
epoch: 1799, train precision: 0.981644, train loss: 17.970909, valid precision: 0.827400, valid loss: 191.960107
epoch: 1800, train precision: 0.982644, train loss: 17.624042, valid precision: 0.834400, valid loss: 194.722071
epoch: 1801, train precision: 0.987911, train loss: 15.143460, valid precision: 0.832800, valid loss: 210.484828
epoch: 1802, train precision: 0.987533, train loss: 15.705230, valid precision: 0.838400, valid loss: 220.543686
epoch: 1803, train precision: 0.985733, train loss: 15.867330, valid precision: 0.831200, valid loss: 205.758753
epoch: 1804, train precision: 0.985956, train loss: 16.173678, valid precision: 0.830800, valid loss: 201.269787
epoch: 1805, train precision: 0.987467, train loss: 15.361987, valid precision: 0.838200, valid loss: 195.664521
epoch: 1806, train precision: 0.989800, train loss: 14.493389, valid precision: 0.833600, valid loss: 189.666592
epoch: 1807, train precision: 0.987556, train loss: 15.284169, valid precision: 0.830600, valid loss: 201.306122
epoch: 1808, train precision: 0.988400, train loss: 14.890472, valid precision: 0.833600, valid loss: 196.102744
epoch: 1809, train precision: 0.987111, train loss: 15.524444, valid precision: 0.833200, valid loss: 197.286054
epoch: 1810, train precision: 0.988244, train loss: 15.104504, valid precision: 0.840600, valid loss: 191.472441
epoch: 1811, train precision: 0.982778, train loss: 17.050554, valid precision: 0.829000, valid loss: 189.447863
epoch: 1812, train precision: 0.986778, train loss: 15.904283, valid precision: 0.836800, valid loss: 194.683473
epoch: 1813, train precision: 0.988244, train loss: 15.022895, valid precision: 0.830000, valid loss: 199.793801
epoch: 1814, train precision: 0.986622, train loss: 15.838182, valid precision: 0.834600, valid loss: 196.502225
epoch: 1815, train precision: 0.986267, train loss: 15.918776, valid precision: 0.833600, valid loss: 203.937912
epoch: 1816, train precision: 0.985222, train loss: 16.364216, valid precision: 0.835200, valid loss: 195.525790
epoch: 1817, train precision: 0.986889, train loss: 15.793919, valid precision: 0.840400, valid loss: 195.366998
epoch: 1818, train precision: 0.988178, train loss: 14.769776, valid precision: 0.835000, valid loss: 195.198539
epoch: 1819, train precision: 0.988822, train loss: 15.038307, valid precision: 0.828600, valid loss: 187.693965
epoch: 1820, train precision: 0.989178, train loss: 14.658564, valid precision: 0.832400, valid loss: 207.761154
epoch: 1821, train precision: 0.986000, train loss: 15.937345, valid precision: 0.828800, valid loss: 184.422626
epoch: 1822, train precision: 0.985956, train loss: 15.956886, valid precision: 0.830400, valid loss: 192.109297
epoch: 1823, train precision: 0.986022, train loss: 16.125071, valid precision: 0.834200, valid loss: 195.238674
epoch: 1824, train precision: 0.990356, train loss: 13.903513, valid precision: 0.830200, valid loss: 201.557249
epoch: 1825, train precision: 0.988378, train loss: 14.785916, valid precision: 0.833600, valid loss: 190.434403
epoch: 1826, train precision: 0.981244, train loss: 18.658341, valid precision: 0.829800, valid loss: 210.526019
epoch: 1827, train precision: 0.984444, train loss: 16.832029, valid precision: 0.829000, valid loss: 201.311085
epoch: 1828, train precision: 0.988133, train loss: 15.120872, valid precision: 0.827600, valid loss: 212.173417
epoch: 1829, train precision: 0.986267, train loss: 16.412148, valid precision: 0.830200, valid loss: 223.638172
epoch: 1830, train precision: 0.987911, train loss: 14.819521, valid precision: 0.825200, valid loss: 191.437444
epoch: 1831, train precision: 0.988178, train loss: 15.073997, valid precision: 0.833200, valid loss: 202.126519
epoch: 1832, train precision: 0.989044, train loss: 14.697245, valid precision: 0.830200, valid loss: 197.226109
epoch: 1833, train precision: 0.986556, train loss: 15.799511, valid precision: 0.833600, valid loss: 204.131226
epoch: 1834, train precision: 0.987622, train loss: 15.395570, valid precision: 0.836600, valid loss: 210.289916
epoch: 1835, train precision: 0.983556, train loss: 16.937499, valid precision: 0.829400, valid loss: 179.945949
epoch: 1836, train precision: 0.987533, train loss: 15.475746, valid precision: 0.837000, valid loss: 210.392387
epoch: 1837, train precision: 0.987644, train loss: 15.252009, valid precision: 0.830800, valid loss: 187.909534
epoch: 1838, train precision: 0.986400, train loss: 15.233386, valid precision: 0.834800, valid loss: 194.247506
epoch: 1839, train precision: 0.983267, train loss: 17.449852, valid precision: 0.831800, valid loss: 200.585646
epoch: 1840, train precision: 0.987889, train loss: 15.324655, valid precision: 0.837600, valid loss: 195.028015
epoch: 1841, train precision: 0.983156, train loss: 16.893599, valid precision: 0.832400, valid loss: 195.488625
epoch: 1842, train precision: 0.986267, train loss: 15.772318, valid precision: 0.835400, valid loss: 184.382510
epoch: 1843, train precision: 0.984467, train loss: 16.827920, valid precision: 0.837000, valid loss: 179.660539
epoch: 1844, train precision: 0.983778, train loss: 17.328407, valid precision: 0.835600, valid loss: 207.008888
epoch: 1845, train precision: 0.985022, train loss: 16.578699, valid precision: 0.832000, valid loss: 192.337899
epoch: 1846, train precision: 0.985733, train loss: 16.351095, valid precision: 0.828800, valid loss: 187.005719
epoch: 1847, train precision: 0.985289, train loss: 16.152311, valid precision: 0.829600, valid loss: 182.364015
epoch: 1848, train precision: 0.984844, train loss: 16.922244, valid precision: 0.830400, valid loss: 189.375929
epoch: 1849, train precision: 0.987867, train loss: 15.305216, valid precision: 0.835400, valid loss: 208.132181
epoch: 1850, train precision: 0.987400, train loss: 15.250799, valid precision: 0.831800, valid loss: 208.769097
epoch: 1851, train precision: 0.989800, train loss: 14.361185, valid precision: 0.833600, valid loss: 191.260117
epoch: 1852, train precision: 0.988111, train loss: 15.125872, valid precision: 0.834800, valid loss: 197.675850
epoch: 1853, train precision: 0.988489, train loss: 14.727512, valid precision: 0.833800, valid loss: 207.885205
epoch: 1854, train precision: 0.986467, train loss: 15.595893, valid precision: 0.834000, valid loss: 181.088801
epoch: 1855, train precision: 0.987978, train loss: 15.497183, valid precision: 0.833200, valid loss: 202.956804
epoch: 1856, train precision: 0.988911, train loss: 14.690411, valid precision: 0.835800, valid loss: 185.104702
epoch: 1857, train precision: 0.987756, train loss: 15.185167, valid precision: 0.833800, valid loss: 198.438459
epoch: 1858, train precision: 0.984089, train loss: 16.687361, valid precision: 0.831000, valid loss: 183.550781
epoch: 1859, train precision: 0.987511, train loss: 15.506513, valid precision: 0.829000, valid loss: 195.446025
epoch: 1860, train precision: 0.987067, train loss: 15.566423, valid precision: 0.834800, valid loss: 190.767213
epoch: 1861, train precision: 0.986800, train loss: 15.798131, valid precision: 0.834800, valid loss: 196.244544
epoch: 1862, train precision: 0.987178, train loss: 15.573502, valid precision: 0.838600, valid loss: 189.228376
epoch: 1863, train precision: 0.986956, train loss: 15.614352, valid precision: 0.834200, valid loss: 197.964475
epoch: 1864, train precision: 0.988000, train loss: 14.773077, valid precision: 0.831000, valid loss: 191.826936
epoch: 1865, train precision: 0.983444, train loss: 17.300777, valid precision: 0.824000, valid loss: 202.834065
epoch: 1866, train precision: 0.989000, train loss: 14.320789, valid precision: 0.828800, valid loss: 188.588638
epoch: 1867, train precision: 0.988244, train loss: 15.211377, valid precision: 0.832200, valid loss: 192.137693
epoch: 1868, train precision: 0.986267, train loss: 16.284471, valid precision: 0.830200, valid loss: 208.072101
epoch: 1869, train precision: 0.988422, train loss: 15.293680, valid precision: 0.837800, valid loss: 196.436431
epoch: 1870, train precision: 0.982467, train loss: 17.466935, valid precision: 0.828400, valid loss: 182.468357
epoch: 1871, train precision: 0.987156, train loss: 15.640844, valid precision: 0.833800, valid loss: 201.959402
epoch: 1872, train precision: 0.986178, train loss: 16.534327, valid precision: 0.839000, valid loss: 220.298939
epoch: 1873, train precision: 0.983089, train loss: 17.367359, valid precision: 0.825200, valid loss: 194.112481
epoch: 1874, train precision: 0.981111, train loss: 18.395023, valid precision: 0.829600, valid loss: 189.114690
epoch: 1875, train precision: 0.988556, train loss: 15.035927, valid precision: 0.833200, valid loss: 193.916355
epoch: 1876, train precision: 0.988356, train loss: 14.953013, valid precision: 0.837400, valid loss: 194.061576
epoch: 1877, train precision: 0.989422, train loss: 14.496789, valid precision: 0.835200, valid loss: 186.892931
epoch: 1878, train precision: 0.988178, train loss: 15.021145, valid precision: 0.833400, valid loss: 198.638127
epoch: 1879, train precision: 0.988333, train loss: 14.732256, valid precision: 0.832400, valid loss: 200.676158
epoch: 1880, train precision: 0.986800, train loss: 15.826931, valid precision: 0.830400, valid loss: 198.843896
epoch: 1881, train precision: 0.989289, train loss: 14.378062, valid precision: 0.839600, valid loss: 177.879694
epoch: 1882, train precision: 0.987111, train loss: 15.854047, valid precision: 0.837000, valid loss: 195.078440
epoch: 1883, train precision: 0.985089, train loss: 15.962220, valid precision: 0.826200, valid loss: 183.761418
epoch: 1884, train precision: 0.988333, train loss: 14.765216, valid precision: 0.831800, valid loss: 192.007529
epoch: 1885, train precision: 0.984289, train loss: 16.605648, valid precision: 0.831600, valid loss: 190.002790
epoch: 1886, train precision: 0.985111, train loss: 16.793145, valid precision: 0.830200, valid loss: 205.511354
epoch: 1887, train precision: 0.987911, train loss: 15.081065, valid precision: 0.834600, valid loss: 204.301605
epoch: 1888, train precision: 0.985422, train loss: 16.198186, valid precision: 0.832000, valid loss: 191.772986
epoch: 1889, train precision: 0.986711, train loss: 15.441610, valid precision: 0.831400, valid loss: 178.392295
epoch: 1890, train precision: 0.985533, train loss: 16.506521, valid precision: 0.839600, valid loss: 191.451800
epoch: 1891, train precision: 0.984844, train loss: 16.209799, valid precision: 0.834600, valid loss: 200.134832
epoch: 1892, train precision: 0.986311, train loss: 16.378355, valid precision: 0.835200, valid loss: 203.307671
epoch: 1893, train precision: 0.986911, train loss: 15.949605, valid precision: 0.837400, valid loss: 202.676159
epoch: 1894, train precision: 0.988889, train loss: 14.707853, valid precision: 0.832600, valid loss: 192.517349
epoch: 1895, train precision: 0.986267, train loss: 16.457647, valid precision: 0.834000, valid loss: 192.748300
epoch: 1896, train precision: 0.988933, train loss: 14.819966, valid precision: 0.839600, valid loss: 188.608999
epoch: 1897, train precision: 0.988956, train loss: 14.551283, valid precision: 0.829400, valid loss: 183.458048
epoch: 1898, train precision: 0.984533, train loss: 16.918686, valid precision: 0.831600, valid loss: 199.910505
epoch: 1899, train precision: 0.989244, train loss: 14.768692, valid precision: 0.842800, valid loss: 191.911210
epoch: 1900, train precision: 0.985556, train loss: 16.641682, valid precision: 0.827400, valid loss: 195.013083
epoch: 1901, train precision: 0.987711, train loss: 15.387292, valid precision: 0.828800, valid loss: 201.633969
epoch: 1902, train precision: 0.985333, train loss: 16.333323, valid precision: 0.830400, valid loss: 195.504092
epoch: 1903, train precision: 0.984489, train loss: 16.494063, valid precision: 0.827400, valid loss: 193.203920
epoch: 1904, train precision: 0.986111, train loss: 16.353359, valid precision: 0.830400, valid loss: 211.763276
epoch: 1905, train precision: 0.987511, train loss: 15.553170, valid precision: 0.837000, valid loss: 190.042202
epoch: 1906, train precision: 0.980578, train loss: 19.482662, valid precision: 0.825800, valid loss: 194.040682
epoch: 1907, train precision: 0.984756, train loss: 16.427948, valid precision: 0.828600, valid loss: 165.918510
epoch: 1908, train precision: 0.986733, train loss: 15.889516, valid precision: 0.839400, valid loss: 180.993372
epoch: 1909, train precision: 0.986911, train loss: 15.375931, valid precision: 0.835200, valid loss: 187.873098
epoch: 1910, train precision: 0.984667, train loss: 16.431613, valid precision: 0.832000, valid loss: 194.256504
epoch: 1911, train precision: 0.983867, train loss: 16.833783, valid precision: 0.835400, valid loss: 186.570027
epoch: 1912, train precision: 0.987111, train loss: 15.587413, valid precision: 0.830600, valid loss: 191.020193
epoch: 1913, train precision: 0.987644, train loss: 15.355135, valid precision: 0.829200, valid loss: 193.821006
epoch: 1914, train precision: 0.985089, train loss: 16.268266, valid precision: 0.834000, valid loss: 205.484806
epoch: 1915, train precision: 0.989400, train loss: 14.599509, valid precision: 0.833000, valid loss: 205.904656
epoch: 1916, train precision: 0.989689, train loss: 14.673448, valid precision: 0.830000, valid loss: 198.451961
epoch: 1917, train precision: 0.989978, train loss: 14.336919, valid precision: 0.837400, valid loss: 199.800861
epoch: 1918, train precision: 0.987289, train loss: 15.556746, valid precision: 0.832600, valid loss: 201.624624
epoch: 1919, train precision: 0.987467, train loss: 15.769070, valid precision: 0.831600, valid loss: 201.454537
epoch: 1920, train precision: 0.987222, train loss: 16.024929, valid precision: 0.829800, valid loss: 207.171276
epoch: 1921, train precision: 0.983000, train loss: 17.289277, valid precision: 0.834800, valid loss: 186.845316
epoch: 1922, train precision: 0.986778, train loss: 16.172657, valid precision: 0.832800, valid loss: 196.864983
epoch: 1923, train precision: 0.984533, train loss: 16.934547, valid precision: 0.828000, valid loss: 184.680901
epoch: 1924, train precision: 0.985867, train loss: 16.265716, valid precision: 0.831000, valid loss: 197.478114
epoch: 1925, train precision: 0.986556, train loss: 16.207011, valid precision: 0.830000, valid loss: 215.371968
epoch: 1926, train precision: 0.983644, train loss: 17.354440, valid precision: 0.827200, valid loss: 213.239789
epoch: 1927, train precision: 0.987689, train loss: 15.401349, valid precision: 0.832000, valid loss: 194.574568
epoch: 1928, train precision: 0.987689, train loss: 15.320637, valid precision: 0.832400, valid loss: 190.465815
epoch: 1929, train precision: 0.988133, train loss: 15.143794, valid precision: 0.834400, valid loss: 187.113779
epoch: 1930, train precision: 0.982200, train loss: 18.216370, valid precision: 0.821800, valid loss: 204.159317
epoch: 1931, train precision: 0.986733, train loss: 15.871153, valid precision: 0.828000, valid loss: 201.053562
epoch: 1932, train precision: 0.985156, train loss: 16.638995, valid precision: 0.830800, valid loss: 210.459716
epoch: 1933, train precision: 0.983222, train loss: 17.973592, valid precision: 0.824200, valid loss: 207.589192
epoch: 1934, train precision: 0.983978, train loss: 17.045571, valid precision: 0.829600, valid loss: 194.149896
epoch: 1935, train precision: 0.988289, train loss: 15.124626, valid precision: 0.832200, valid loss: 195.941478
epoch: 1936, train precision: 0.987289, train loss: 15.842079, valid precision: 0.828800, valid loss: 208.519662
epoch: 1937, train precision: 0.987622, train loss: 15.387333, valid precision: 0.833600, valid loss: 192.361280
epoch: 1938, train precision: 0.987111, train loss: 15.659476, valid precision: 0.831200, valid loss: 202.812796
epoch: 1939, train precision: 0.986511, train loss: 16.061239, valid precision: 0.833800, valid loss: 193.919394
epoch: 1940, train precision: 0.987200, train loss: 15.742390, valid precision: 0.834600, valid loss: 197.905355
epoch: 1941, train precision: 0.984578, train loss: 17.052916, valid precision: 0.836600, valid loss: 195.633698
epoch: 1942, train precision: 0.981844, train loss: 18.143535, valid precision: 0.830000, valid loss: 202.559542
epoch: 1943, train precision: 0.988089, train loss: 15.663092, valid precision: 0.832400, valid loss: 202.739959
epoch: 1944, train precision: 0.984044, train loss: 17.256648, valid precision: 0.833000, valid loss: 200.106117
epoch: 1945, train precision: 0.985378, train loss: 16.517815, valid precision: 0.833800, valid loss: 191.985747
epoch: 1946, train precision: 0.987267, train loss: 15.763079, valid precision: 0.832000, valid loss: 190.417709
epoch: 1947, train precision: 0.984889, train loss: 16.629170, valid precision: 0.832200, valid loss: 193.529453
epoch: 1948, train precision: 0.989089, train loss: 14.624118, valid precision: 0.831600, valid loss: 194.062912
epoch: 1949, train precision: 0.986333, train loss: 15.841293, valid precision: 0.832400, valid loss: 188.247043
epoch: 1950, train precision: 0.986533, train loss: 16.078772, valid precision: 0.832600, valid loss: 189.775732
epoch: 1951, train precision: 0.988489, train loss: 14.941338, valid precision: 0.836200, valid loss: 189.043291
epoch: 1952, train precision: 0.987867, train loss: 15.198894, valid precision: 0.832600, valid loss: 191.346580
epoch: 1953, train precision: 0.986711, train loss: 15.631439, valid precision: 0.831200, valid loss: 178.274585
epoch: 1954, train precision: 0.986956, train loss: 15.757057, valid precision: 0.835200, valid loss: 192.538344
epoch: 1955, train precision: 0.986133, train loss: 16.389649, valid precision: 0.834600, valid loss: 205.085898
epoch: 1956, train precision: 0.984733, train loss: 16.985838, valid precision: 0.836400, valid loss: 208.611595
epoch: 1957, train precision: 0.986400, train loss: 16.085086, valid precision: 0.833800, valid loss: 184.222995
epoch: 1958, train precision: 0.985311, train loss: 16.753112, valid precision: 0.832600, valid loss: 188.474076
epoch: 1959, train precision: 0.989022, train loss: 14.672196, valid precision: 0.833800, valid loss: 200.886241
epoch: 1960, train precision: 0.984711, train loss: 16.837908, valid precision: 0.828600, valid loss: 207.936401
epoch: 1961, train precision: 0.987733, train loss: 15.331131, valid precision: 0.828800, valid loss: 188.108499
epoch: 1962, train precision: 0.984711, train loss: 16.667245, valid precision: 0.835800, valid loss: 181.900395
epoch: 1963, train precision: 0.987156, train loss: 15.879852, valid precision: 0.833000, valid loss: 199.728512
epoch: 1964, train precision: 0.985422, train loss: 16.508258, valid precision: 0.829600, valid loss: 197.514105
epoch: 1965, train precision: 0.988467, train loss: 14.913703, valid precision: 0.833000, valid loss: 198.282970
epoch: 1966, train precision: 0.990467, train loss: 14.189710, valid precision: 0.832800, valid loss: 194.442588
epoch: 1967, train precision: 0.986533, train loss: 16.295866, valid precision: 0.828000, valid loss: 184.603363
epoch: 1968, train precision: 0.986156, train loss: 15.723412, valid precision: 0.833400, valid loss: 188.722516
epoch: 1969, train precision: 0.984689, train loss: 17.049474, valid precision: 0.829800, valid loss: 208.925078
epoch: 1970, train precision: 0.988933, train loss: 14.897814, valid precision: 0.829800, valid loss: 193.473024
epoch: 1971, train precision: 0.985956, train loss: 17.190542, valid precision: 0.829400, valid loss: 215.234060
epoch: 1972, train precision: 0.986978, train loss: 16.391178, valid precision: 0.830200, valid loss: 216.271884
epoch: 1973, train precision: 0.986044, train loss: 16.240427, valid precision: 0.833200, valid loss: 202.706087
epoch: 1974, train precision: 0.985978, train loss: 16.600629, valid precision: 0.835400, valid loss: 201.251817
epoch: 1975, train precision: 0.986133, train loss: 16.110007, valid precision: 0.836600, valid loss: 186.884131
epoch: 1976, train precision: 0.984200, train loss: 16.990821, valid precision: 0.826200, valid loss: 194.055264
epoch: 1977, train precision: 0.985289, train loss: 16.528704, valid precision: 0.826400, valid loss: 196.901544
epoch: 1978, train precision: 0.988933, train loss: 15.379229, valid precision: 0.834600, valid loss: 214.728727
epoch: 1979, train precision: 0.985978, train loss: 16.398085, valid precision: 0.836600, valid loss: 200.821039
epoch: 1980, train precision: 0.985533, train loss: 16.455772, valid precision: 0.832600, valid loss: 190.046434
epoch: 1981, train precision: 0.978511, train loss: 19.721385, valid precision: 0.827800, valid loss: 195.540372
epoch: 1982, train precision: 0.987422, train loss: 15.838310, valid precision: 0.830400, valid loss: 211.527397
epoch: 1983, train precision: 0.986800, train loss: 15.965817, valid precision: 0.832600, valid loss: 210.408989
epoch: 1984, train precision: 0.988400, train loss: 15.055314, valid precision: 0.830000, valid loss: 187.643329
epoch: 1985, train precision: 0.986422, train loss: 16.230827, valid precision: 0.833600, valid loss: 198.629866
epoch: 1986, train precision: 0.987444, train loss: 16.134297, valid precision: 0.828400, valid loss: 211.772867
epoch: 1987, train precision: 0.983089, train loss: 17.522738, valid precision: 0.832200, valid loss: 192.193673
epoch: 1988, train precision: 0.981044, train loss: 18.512319, valid precision: 0.827200, valid loss: 185.303622
epoch: 1989, train precision: 0.982711, train loss: 17.542586, valid precision: 0.827200, valid loss: 188.965275
epoch: 1990, train precision: 0.984400, train loss: 17.047763, valid precision: 0.836400, valid loss: 205.588589
epoch: 1991, train precision: 0.987000, train loss: 15.647679, valid precision: 0.835200, valid loss: 196.907179
epoch: 1992, train precision: 0.988956, train loss: 14.886196, valid precision: 0.833400, valid loss: 186.367996
epoch: 1993, train precision: 0.985844, train loss: 16.150739, valid precision: 0.828800, valid loss: 178.452546
epoch: 1994, train precision: 0.986533, train loss: 16.394824, valid precision: 0.834800, valid loss: 212.332508
epoch: 1995, train precision: 0.985600, train loss: 16.539246, valid precision: 0.829000, valid loss: 206.933988
epoch: 1996, train precision: 0.988489, train loss: 15.306179, valid precision: 0.836200, valid loss: 201.817447
epoch: 1997, train precision: 0.987356, train loss: 15.588907, valid precision: 0.831200, valid loss: 196.169463
epoch: 1998, train precision: 0.987733, train loss: 15.305955, valid precision: 0.837800, valid loss: 198.045593
epoch: 1999, train precision: 0.987622, train loss: 15.469453, valid precision: 0.832000, valid loss: 197.353761
epoch: 2000, train precision: 0.983422, train loss: 18.192548, valid precision: 0.832200, valid loss: 209.373108
epoch: 2001, train precision: 0.983133, train loss: 17.408607, valid precision: 0.825800, valid loss: 180.570599
epoch: 2002, train precision: 0.989911, train loss: 14.651338, valid precision: 0.829000, valid loss: 186.597607
epoch: 2003, train precision: 0.987867, train loss: 15.547950, valid precision: 0.833800, valid loss: 187.247652
epoch: 2004, train precision: 0.981422, train loss: 19.039541, valid precision: 0.827400, valid loss: 217.195705
epoch: 2005, train precision: 0.987200, train loss: 16.052996, valid precision: 0.841600, valid loss: 208.585681
epoch: 2006, train precision: 0.984244, train loss: 16.923657, valid precision: 0.830800, valid loss: 176.969472
epoch: 2007, train precision: 0.982956, train loss: 17.954935, valid precision: 0.831800, valid loss: 200.167491
epoch: 2008, train precision: 0.984044, train loss: 17.199217, valid precision: 0.834800, valid loss: 190.991198
epoch: 2009, train precision: 0.984911, train loss: 16.829569, valid precision: 0.832600, valid loss: 203.924182
epoch: 2010, train precision: 0.986044, train loss: 16.500848, valid precision: 0.830400, valid loss: 197.135391
epoch: 2011, train precision: 0.986689, train loss: 16.176041, valid precision: 0.838200, valid loss: 196.910336
epoch: 2012, train precision: 0.986978, train loss: 15.626069, valid precision: 0.833600, valid loss: 192.025627
epoch: 2013, train precision: 0.986089, train loss: 16.263518, valid precision: 0.833800, valid loss: 193.876480
epoch: 2014, train precision: 0.987489, train loss: 15.303353, valid precision: 0.826200, valid loss: 181.173838
epoch: 2015, train precision: 0.987467, train loss: 16.228589, valid precision: 0.830800, valid loss: 205.363405
epoch: 2016, train precision: 0.987600, train loss: 15.282402, valid precision: 0.831000, valid loss: 205.885468
epoch: 2017, train precision: 0.983022, train loss: 18.185366, valid precision: 0.830400, valid loss: 196.450711
epoch: 2018, train precision: 0.985689, train loss: 16.025889, valid precision: 0.832800, valid loss: 193.891462
epoch: 2019, train precision: 0.988378, train loss: 15.392580, valid precision: 0.834000, valid loss: 188.855335
epoch: 2020, train precision: 0.987667, train loss: 15.725760, valid precision: 0.835400, valid loss: 197.047478
epoch: 2021, train precision: 0.979711, train loss: 19.036999, valid precision: 0.829000, valid loss: 191.890346
epoch: 2022, train precision: 0.987933, train loss: 15.756195, valid precision: 0.834400, valid loss: 193.314184
epoch: 2023, train precision: 0.987644, train loss: 15.756410, valid precision: 0.831800, valid loss: 196.103185
epoch: 2024, train precision: 0.981333, train loss: 18.246741, valid precision: 0.819200, valid loss: 194.127708
epoch: 2025, train precision: 0.989444, train loss: 14.791071, valid precision: 0.829800, valid loss: 210.664749
epoch: 2026, train precision: 0.986689, train loss: 16.204873, valid precision: 0.832800, valid loss: 202.855675
epoch: 2027, train precision: 0.987311, train loss: 15.854719, valid precision: 0.835200, valid loss: 188.680082
epoch: 2028, train precision: 0.989133, train loss: 15.298347, valid precision: 0.832800, valid loss: 203.716294
epoch: 2029, train precision: 0.986800, train loss: 15.782264, valid precision: 0.830400, valid loss: 201.556831
epoch: 2030, train precision: 0.986644, train loss: 15.631966, valid precision: 0.827200, valid loss: 198.891851
epoch: 2031, train precision: 0.986689, train loss: 15.899771, valid precision: 0.831000, valid loss: 203.482646
epoch: 2032, train precision: 0.984022, train loss: 16.874437, valid precision: 0.836400, valid loss: 198.396578
epoch: 2033, train precision: 0.986733, train loss: 15.603843, valid precision: 0.828000, valid loss: 189.613922
epoch: 2034, train precision: 0.986467, train loss: 15.776927, valid precision: 0.825600, valid loss: 195.506699
epoch: 2035, train precision: 0.986444, train loss: 16.565355, valid precision: 0.825600, valid loss: 213.184966
epoch: 2036, train precision: 0.988956, train loss: 14.930000, valid precision: 0.834000, valid loss: 196.289915
epoch: 2037, train precision: 0.985200, train loss: 16.590115, valid precision: 0.832400, valid loss: 182.574647
epoch: 2038, train precision: 0.985089, train loss: 16.758653, valid precision: 0.824800, valid loss: 186.484229
epoch: 2039, train precision: 0.986356, train loss: 16.182133, valid precision: 0.831400, valid loss: 214.571980
epoch: 2040, train precision: 0.988556, train loss: 15.057551, valid precision: 0.830400, valid loss: 202.258366
epoch: 2041, train precision: 0.984556, train loss: 16.988089, valid precision: 0.830800, valid loss: 187.033614
epoch: 2042, train precision: 0.987844, train loss: 15.824437, valid precision: 0.839600, valid loss: 207.000306
epoch: 2043, train precision: 0.980178, train loss: 20.019458, valid precision: 0.820000, valid loss: 211.885524
epoch: 2044, train precision: 0.989289, train loss: 14.918835, valid precision: 0.828800, valid loss: 206.700854
epoch: 2045, train precision: 0.983956, train loss: 17.489835, valid precision: 0.829800, valid loss: 216.272929
epoch: 2046, train precision: 0.987133, train loss: 15.395194, valid precision: 0.828800, valid loss: 193.679400
epoch: 2047, train precision: 0.980511, train loss: 19.195660, valid precision: 0.826200, valid loss: 193.613548
epoch: 2048, train precision: 0.985667, train loss: 16.534011, valid precision: 0.823600, valid loss: 180.104302
epoch: 2049, train precision: 0.982933, train loss: 18.095024, valid precision: 0.824800, valid loss: 199.733647
epoch: 2050, train precision: 0.989200, train loss: 14.797084, valid precision: 0.828400, valid loss: 195.936545
epoch: 2051, train precision: 0.984444, train loss: 17.339580, valid precision: 0.824000, valid loss: 200.137571
epoch: 2052, train precision: 0.983667, train loss: 16.987833, valid precision: 0.828000, valid loss: 187.221736
epoch: 2053, train precision: 0.984067, train loss: 16.914801, valid precision: 0.827600, valid loss: 195.785665
epoch: 2054, train precision: 0.978800, train loss: 19.857459, valid precision: 0.822400, valid loss: 180.223318
epoch: 2055, train precision: 0.985933, train loss: 16.870485, valid precision: 0.826200, valid loss: 217.776680
epoch: 2056, train precision: 0.984800, train loss: 16.609172, valid precision: 0.830000, valid loss: 197.807465
epoch: 2057, train precision: 0.980111, train loss: 18.837136, valid precision: 0.829200, valid loss: 210.151596
epoch: 2058, train precision: 0.989733, train loss: 14.774232, valid precision: 0.829600, valid loss: 203.309471
epoch: 2059, train precision: 0.986378, train loss: 15.907318, valid precision: 0.828600, valid loss: 194.888360
epoch: 2060, train precision: 0.988067, train loss: 15.274352, valid precision: 0.833600, valid loss: 197.587786
epoch: 2061, train precision: 0.984467, train loss: 17.545544, valid precision: 0.826600, valid loss: 229.274769
epoch: 2062, train precision: 0.987267, train loss: 15.769006, valid precision: 0.832000, valid loss: 200.571405
epoch: 2063, train precision: 0.988644, train loss: 15.132530, valid precision: 0.833000, valid loss: 203.418404
epoch: 2064, train precision: 0.986311, train loss: 16.265959, valid precision: 0.829200, valid loss: 218.823302
epoch: 2065, train precision: 0.985089, train loss: 16.917733, valid precision: 0.827600, valid loss: 193.574895
epoch: 2066, train precision: 0.982911, train loss: 17.334068, valid precision: 0.826800, valid loss: 190.721098
epoch: 2067, train precision: 0.990222, train loss: 14.284731, valid precision: 0.832200, valid loss: 199.551905
epoch: 2068, train precision: 0.988533, train loss: 15.051443, valid precision: 0.832000, valid loss: 209.121527
epoch: 2069, train precision: 0.987311, train loss: 15.739125, valid precision: 0.832800, valid loss: 206.709641
epoch: 2070, train precision: 0.988578, train loss: 15.329466, valid precision: 0.831200, valid loss: 203.220933
epoch: 2071, train precision: 0.986622, train loss: 16.259718, valid precision: 0.833200, valid loss: 210.706526
epoch: 2072, train precision: 0.983533, train loss: 17.539973, valid precision: 0.827800, valid loss: 204.354395
epoch: 2073, train precision: 0.989800, train loss: 14.671045, valid precision: 0.834400, valid loss: 203.934298
epoch: 2074, train precision: 0.985911, train loss: 16.517762, valid precision: 0.835600, valid loss: 182.014055
epoch: 2075, train precision: 0.983311, train loss: 18.122968, valid precision: 0.830200, valid loss: 196.200138
epoch: 2076, train precision: 0.984889, train loss: 16.593761, valid precision: 0.832200, valid loss: 201.279139
epoch: 2077, train precision: 0.986356, train loss: 16.331923, valid precision: 0.829400, valid loss: 202.370514
epoch: 2078, train precision: 0.986067, train loss: 16.175737, valid precision: 0.835400, valid loss: 200.714808
epoch: 2079, train precision: 0.979333, train loss: 19.607061, valid precision: 0.820600, valid loss: 189.588993
epoch: 2080, train precision: 0.987467, train loss: 15.727198, valid precision: 0.833200, valid loss: 221.019484
epoch: 2081, train precision: 0.989333, train loss: 14.952376, valid precision: 0.836000, valid loss: 215.703351
epoch: 2082, train precision: 0.985267, train loss: 16.821694, valid precision: 0.837400, valid loss: 211.575121
epoch: 2083, train precision: 0.987644, train loss: 15.802290, valid precision: 0.834200, valid loss: 198.887673
epoch: 2084, train precision: 0.988311, train loss: 15.596337, valid precision: 0.837600, valid loss: 212.013475
epoch: 2085, train precision: 0.987822, train loss: 15.344794, valid precision: 0.837200, valid loss: 207.923395
epoch: 2086, train precision: 0.987889, train loss: 15.777193, valid precision: 0.836600, valid loss: 208.060568
epoch: 2087, train precision: 0.985311, train loss: 16.316449, valid precision: 0.834600, valid loss: 191.589417
epoch: 2088, train precision: 0.987289, train loss: 15.793026, valid precision: 0.836200, valid loss: 185.568467
epoch: 2089, train precision: 0.981289, train loss: 18.664949, valid precision: 0.827400, valid loss: 183.148655
epoch: 2090, train precision: 0.986089, train loss: 16.689247, valid precision: 0.837800, valid loss: 205.289518
epoch: 2091, train precision: 0.983956, train loss: 18.063482, valid precision: 0.835000, valid loss: 206.820221
epoch: 2092, train precision: 0.988956, train loss: 15.036977, valid precision: 0.837000, valid loss: 197.040948
epoch: 2093, train precision: 0.986089, train loss: 16.584116, valid precision: 0.835000, valid loss: 192.468910
epoch: 2094, train precision: 0.985111, train loss: 17.143091, valid precision: 0.825800, valid loss: 184.830887
epoch: 2095, train precision: 0.986311, train loss: 16.004992, valid precision: 0.834400, valid loss: 199.165698
epoch: 2096, train precision: 0.985556, train loss: 16.806793, valid precision: 0.838600, valid loss: 212.074176
epoch: 2097, train precision: 0.986267, train loss: 16.181338, valid precision: 0.835200, valid loss: 190.446361
epoch: 2098, train precision: 0.989111, train loss: 15.181293, valid precision: 0.833200, valid loss: 198.650773
epoch: 2099, train precision: 0.985733, train loss: 16.471173, valid precision: 0.832400, valid loss: 199.564219
epoch: 2100, train precision: 0.985111, train loss: 16.632679, valid precision: 0.830600, valid loss: 183.488998
epoch: 2101, train precision: 0.983800, train loss: 18.596543, valid precision: 0.833000, valid loss: 224.842820
epoch: 2102, train precision: 0.984533, train loss: 16.967727, valid precision: 0.832000, valid loss: 186.312190
epoch: 2103, train precision: 0.987400, train loss: 15.922685, valid precision: 0.837800, valid loss: 188.149034
epoch: 2104, train precision: 0.988044, train loss: 15.124418, valid precision: 0.829600, valid loss: 192.894149
epoch: 2105, train precision: 0.987444, train loss: 15.665128, valid precision: 0.836800, valid loss: 186.201970
epoch: 2106, train precision: 0.986689, train loss: 15.990875, valid precision: 0.838000, valid loss: 203.303627
epoch: 2107, train precision: 0.983267, train loss: 17.919240, valid precision: 0.826200, valid loss: 195.028248
epoch: 2108, train precision: 0.986622, train loss: 16.437187, valid precision: 0.831400, valid loss: 197.871652
epoch: 2109, train precision: 0.989556, train loss: 14.897914, valid precision: 0.832000, valid loss: 201.030394
epoch: 2110, train precision: 0.988778, train loss: 15.492847, valid precision: 0.830800, valid loss: 211.343889
epoch: 2111, train precision: 0.987133, train loss: 16.113159, valid precision: 0.834400, valid loss: 210.206016
epoch: 2112, train precision: 0.983533, train loss: 17.067202, valid precision: 0.829400, valid loss: 192.344493
epoch: 2113, train precision: 0.986600, train loss: 16.175233, valid precision: 0.832000, valid loss: 211.852741
epoch: 2114, train precision: 0.990089, train loss: 14.752820, valid precision: 0.838000, valid loss: 213.991688
epoch: 2115, train precision: 0.982867, train loss: 18.317211, valid precision: 0.829800, valid loss: 214.545270
epoch: 2116, train precision: 0.987933, train loss: 15.857766, valid precision: 0.830200, valid loss: 200.923495
epoch: 2117, train precision: 0.989489, train loss: 14.593305, valid precision: 0.833200, valid loss: 218.243877
epoch: 2118, train precision: 0.984756, train loss: 17.237077, valid precision: 0.835600, valid loss: 215.438411
epoch: 2119, train precision: 0.987267, train loss: 15.396002, valid precision: 0.829600, valid loss: 189.077259
epoch: 2120, train precision: 0.986200, train loss: 16.119292, valid precision: 0.838600, valid loss: 180.637865
epoch: 2121, train precision: 0.985533, train loss: 17.469505, valid precision: 0.833000, valid loss: 209.968836
epoch: 2122, train precision: 0.986711, train loss: 16.204917, valid precision: 0.835400, valid loss: 208.643481
epoch: 2123, train precision: 0.989911, train loss: 14.606700, valid precision: 0.836400, valid loss: 208.592802
epoch: 2124, train precision: 0.987244, train loss: 15.815573, valid precision: 0.837600, valid loss: 214.229725
epoch: 2125, train precision: 0.986867, train loss: 15.918300, valid precision: 0.833400, valid loss: 206.148072
epoch: 2126, train precision: 0.979844, train loss: 19.995571, valid precision: 0.830800, valid loss: 210.384413
epoch: 2127, train precision: 0.988622, train loss: 15.259064, valid precision: 0.841000, valid loss: 194.515457
epoch: 2128, train precision: 0.986044, train loss: 16.641018, valid precision: 0.833000, valid loss: 187.226678
epoch: 2129, train precision: 0.985911, train loss: 16.642105, valid precision: 0.832200, valid loss: 197.861936
epoch: 2130, train precision: 0.987689, train loss: 16.337440, valid precision: 0.839400, valid loss: 217.191079
epoch: 2131, train precision: 0.986267, train loss: 16.623777, valid precision: 0.830200, valid loss: 215.774921
epoch: 2132, train precision: 0.985444, train loss: 17.120741, valid precision: 0.832000, valid loss: 215.243520
epoch: 2133, train precision: 0.987489, train loss: 15.850869, valid precision: 0.826400, valid loss: 198.584151
epoch: 2134, train precision: 0.981178, train loss: 18.988214, valid precision: 0.828400, valid loss: 208.649337
epoch: 2135, train precision: 0.986933, train loss: 16.074401, valid precision: 0.833000, valid loss: 212.882595
epoch: 2136, train precision: 0.987422, train loss: 15.798660, valid precision: 0.830000, valid loss: 193.371059
epoch: 2137, train precision: 0.985600, train loss: 16.409042, valid precision: 0.828800, valid loss: 195.901006
epoch: 2138, train precision: 0.984311, train loss: 17.456737, valid precision: 0.831200, valid loss: 217.127683
epoch: 2139, train precision: 0.985289, train loss: 16.655367, valid precision: 0.831400, valid loss: 189.295841
epoch: 2140, train precision: 0.983444, train loss: 17.573892, valid precision: 0.830800, valid loss: 181.893626
epoch: 2141, train precision: 0.986644, train loss: 16.267847, valid precision: 0.831400, valid loss: 199.539927
epoch: 2142, train precision: 0.986800, train loss: 16.270906, valid precision: 0.832800, valid loss: 206.914689
epoch: 2143, train precision: 0.983600, train loss: 17.644641, valid precision: 0.830200, valid loss: 205.313485
epoch: 2144, train precision: 0.989267, train loss: 15.373533, valid precision: 0.833400, valid loss: 219.783110
epoch: 2145, train precision: 0.989111, train loss: 14.573362, valid precision: 0.834800, valid loss: 195.961413
epoch: 2146, train precision: 0.984889, train loss: 16.964208, valid precision: 0.828200, valid loss: 214.637004
epoch: 2147, train precision: 0.987156, train loss: 15.536777, valid precision: 0.836200, valid loss: 202.366908
epoch: 2148, train precision: 0.986711, train loss: 16.456758, valid precision: 0.831800, valid loss: 199.947634
epoch: 2149, train precision: 0.984911, train loss: 16.751311, valid precision: 0.833200, valid loss: 199.803575
epoch: 2150, train precision: 0.982356, train loss: 18.058899, valid precision: 0.833200, valid loss: 205.476921
epoch: 2151, train precision: 0.984244, train loss: 16.901378, valid precision: 0.830800, valid loss: 183.768525
epoch: 2152, train precision: 0.988289, train loss: 15.198694, valid precision: 0.839600, valid loss: 191.140000
epoch: 2153, train precision: 0.989244, train loss: 14.863186, valid precision: 0.833200, valid loss: 210.979639
epoch: 2154, train precision: 0.987000, train loss: 16.041637, valid precision: 0.836400, valid loss: 209.952566
epoch: 2155, train precision: 0.985356, train loss: 16.800276, valid precision: 0.831200, valid loss: 199.453842
epoch: 2156, train precision: 0.987733, train loss: 16.063654, valid precision: 0.834200, valid loss: 200.368282
epoch: 2157, train precision: 0.990089, train loss: 14.785021, valid precision: 0.829800, valid loss: 206.695478
epoch: 2158, train precision: 0.988044, train loss: 15.783031, valid precision: 0.828200, valid loss: 223.017847
epoch: 2159, train precision: 0.988356, train loss: 15.491593, valid precision: 0.830400, valid loss: 206.242253
epoch: 2160, train precision: 0.986622, train loss: 16.154156, valid precision: 0.829600, valid loss: 214.085954
epoch: 2161, train precision: 0.984089, train loss: 17.319357, valid precision: 0.827800, valid loss: 205.984676
epoch: 2162, train precision: 0.984178, train loss: 17.075716, valid precision: 0.827400, valid loss: 198.438762
epoch: 2163, train precision: 0.983889, train loss: 17.670684, valid precision: 0.830200, valid loss: 206.902848
epoch: 2164, train precision: 0.986600, train loss: 15.995735, valid precision: 0.831200, valid loss: 188.899374
epoch: 2165, train precision: 0.981600, train loss: 19.193496, valid precision: 0.831400, valid loss: 221.552950
epoch: 2166, train precision: 0.985444, train loss: 17.189299, valid precision: 0.832600, valid loss: 200.142733
epoch: 2167, train precision: 0.986556, train loss: 16.028617, valid precision: 0.834400, valid loss: 181.964202
epoch: 2168, train precision: 0.984911, train loss: 16.736256, valid precision: 0.829000, valid loss: 189.469956
epoch: 2169, train precision: 0.985622, train loss: 16.651482, valid precision: 0.827200, valid loss: 204.054177
epoch: 2170, train precision: 0.983444, train loss: 18.837158, valid precision: 0.828400, valid loss: 244.171595
epoch: 2171, train precision: 0.988600, train loss: 15.088159, valid precision: 0.833000, valid loss: 206.822841
epoch: 2172, train precision: 0.986578, train loss: 16.069406, valid precision: 0.828400, valid loss: 186.074572
epoch: 2173, train precision: 0.982800, train loss: 18.096858, valid precision: 0.830600, valid loss: 205.289751
epoch: 2174, train precision: 0.983511, train loss: 18.238989, valid precision: 0.832200, valid loss: 233.810959
epoch: 2175, train precision: 0.986044, train loss: 16.672284, valid precision: 0.831800, valid loss: 208.336077
epoch: 2176, train precision: 0.986133, train loss: 16.743679, valid precision: 0.832800, valid loss: 203.038029
epoch: 2177, train precision: 0.984044, train loss: 17.278178, valid precision: 0.826800, valid loss: 179.584081
epoch: 2178, train precision: 0.988000, train loss: 15.241576, valid precision: 0.832800, valid loss: 200.079353
epoch: 2179, train precision: 0.987511, train loss: 16.091334, valid precision: 0.835400, valid loss: 227.763676
epoch: 2180, train precision: 0.989356, train loss: 14.683413, valid precision: 0.833600, valid loss: 196.388271
epoch: 2181, train precision: 0.984000, train loss: 17.695500, valid precision: 0.824200, valid loss: 195.391426
epoch: 2182, train precision: 0.984133, train loss: 17.157532, valid precision: 0.827200, valid loss: 198.086399
epoch: 2183, train precision: 0.987200, train loss: 16.034025, valid precision: 0.837000, valid loss: 206.924661
epoch: 2184, train precision: 0.985822, train loss: 16.295392, valid precision: 0.827800, valid loss: 192.900932
epoch: 2185, train precision: 0.988400, train loss: 15.551607, valid precision: 0.832000, valid loss: 195.551066
epoch: 2186, train precision: 0.987533, train loss: 15.799861, valid precision: 0.832200, valid loss: 212.035764
epoch: 2187, train precision: 0.985200, train loss: 17.083851, valid precision: 0.828400, valid loss: 213.825954
epoch: 2188, train precision: 0.984333, train loss: 17.566433, valid precision: 0.823200, valid loss: 209.012745
epoch: 2189, train precision: 0.988711, train loss: 15.452187, valid precision: 0.829600, valid loss: 205.468700
epoch: 2190, train precision: 0.988444, train loss: 15.469771, valid precision: 0.832200, valid loss: 208.509737
epoch: 2191, train precision: 0.983089, train loss: 17.703706, valid precision: 0.829000, valid loss: 197.641778
epoch: 2192, train precision: 0.988111, train loss: 15.850459, valid precision: 0.835600, valid loss: 214.965202
epoch: 2193, train precision: 0.990400, train loss: 14.401485, valid precision: 0.837200, valid loss: 219.074442
epoch: 2194, train precision: 0.989356, train loss: 15.054572, valid precision: 0.831000, valid loss: 204.631934
epoch: 2195, train precision: 0.987400, train loss: 16.285429, valid precision: 0.833000, valid loss: 208.988278
epoch: 2196, train precision: 0.983600, train loss: 17.621784, valid precision: 0.827000, valid loss: 202.570878
epoch: 2197, train precision: 0.983244, train loss: 17.988882, valid precision: 0.832000, valid loss: 207.237251
epoch: 2198, train precision: 0.981867, train loss: 18.885078, valid precision: 0.831200, valid loss: 209.282040
epoch: 2199, train precision: 0.988067, train loss: 15.582333, valid precision: 0.835200, valid loss: 203.605357
epoch: 2200, train precision: 0.988644, train loss: 15.567625, valid precision: 0.834600, valid loss: 204.073717
epoch: 2201, train precision: 0.989156, train loss: 14.880104, valid precision: 0.830000, valid loss: 198.017320
epoch: 2202, train precision: 0.984667, train loss: 17.272358, valid precision: 0.826800, valid loss: 198.746321
epoch: 2203, train precision: 0.985333, train loss: 16.817770, valid precision: 0.831400, valid loss: 195.732801
epoch: 2204, train precision: 0.985956, train loss: 16.794261, valid precision: 0.834000, valid loss: 204.948328
epoch: 2205, train precision: 0.983111, train loss: 18.059583, valid precision: 0.822200, valid loss: 199.340504
epoch: 2206, train precision: 0.987200, train loss: 16.260805, valid precision: 0.827000, valid loss: 205.058260
epoch: 2207, train precision: 0.987467, train loss: 16.005920, valid precision: 0.831200, valid loss: 188.516839
epoch: 2208, train precision: 0.982444, train loss: 18.615082, valid precision: 0.832400, valid loss: 187.841004
epoch: 2209, train precision: 0.984756, train loss: 17.969638, valid precision: 0.830600, valid loss: 214.865216
epoch: 2210, train precision: 0.985644, train loss: 16.873413, valid precision: 0.831800, valid loss: 215.191700
epoch: 2211, train precision: 0.986089, train loss: 16.430250, valid precision: 0.834400, valid loss: 196.679891
epoch: 2212, train precision: 0.984244, train loss: 17.485237, valid precision: 0.832400, valid loss: 188.377890
epoch: 2213, train precision: 0.985000, train loss: 17.252734, valid precision: 0.835400, valid loss: 204.849612
epoch: 2214, train precision: 0.980667, train loss: 19.540003, valid precision: 0.825800, valid loss: 210.785504
epoch: 2215, train precision: 0.981489, train loss: 18.909398, valid precision: 0.834800, valid loss: 196.556583
epoch: 2216, train precision: 0.988867, train loss: 15.165846, valid precision: 0.840200, valid loss: 189.695358
epoch: 2217, train precision: 0.985133, train loss: 17.183875, valid precision: 0.833000, valid loss: 200.797392
epoch: 2218, train precision: 0.986756, train loss: 16.248418, valid precision: 0.833800, valid loss: 213.138938
epoch: 2219, train precision: 0.986222, train loss: 16.575835, valid precision: 0.837000, valid loss: 210.127544
epoch: 2220, train precision: 0.980578, train loss: 19.618364, valid precision: 0.828200, valid loss: 201.798901
epoch: 2221, train precision: 0.983156, train loss: 17.642988, valid precision: 0.832200, valid loss: 203.159832
epoch: 2222, train precision: 0.987689, train loss: 16.115695, valid precision: 0.835800, valid loss: 200.346077
epoch: 2223, train precision: 0.986200, train loss: 16.373123, valid precision: 0.833600, valid loss: 203.767753
epoch: 2224, train precision: 0.987222, train loss: 15.811465, valid precision: 0.836800, valid loss: 205.800863
epoch: 2225, train precision: 0.989089, train loss: 15.251969, valid precision: 0.836600, valid loss: 221.023343
epoch: 2226, train precision: 0.984533, train loss: 17.204318, valid precision: 0.831800, valid loss: 212.586352
epoch: 2227, train precision: 0.987156, train loss: 15.896355, valid precision: 0.833600, valid loss: 214.056002
epoch: 2228, train precision: 0.987178, train loss: 16.231520, valid precision: 0.830000, valid loss: 224.172323
epoch: 2229, train precision: 0.987156, train loss: 16.032449, valid precision: 0.831600, valid loss: 195.832161
epoch: 2230, train precision: 0.986711, train loss: 16.240856, valid precision: 0.833600, valid loss: 205.061104
epoch: 2231, train precision: 0.984689, train loss: 17.238285, valid precision: 0.831000, valid loss: 211.767274
epoch: 2232, train precision: 0.987333, train loss: 16.340824, valid precision: 0.831000, valid loss: 208.294417
epoch: 2233, train precision: 0.987622, train loss: 15.664092, valid precision: 0.829200, valid loss: 194.386925
epoch: 2234, train precision: 0.988889, train loss: 15.270271, valid precision: 0.839200, valid loss: 219.560674
epoch: 2235, train precision: 0.986667, train loss: 15.946237, valid precision: 0.831400, valid loss: 207.231362
epoch: 2236, train precision: 0.986689, train loss: 15.994250, valid precision: 0.837000, valid loss: 209.289205
epoch: 2237, train precision: 0.985711, train loss: 16.790508, valid precision: 0.828400, valid loss: 197.378655
epoch: 2238, train precision: 0.984489, train loss: 17.454571, valid precision: 0.827000, valid loss: 214.946109
epoch: 2239, train precision: 0.985622, train loss: 17.027945, valid precision: 0.823200, valid loss: 211.977657
epoch: 2240, train precision: 0.981444, train loss: 18.051643, valid precision: 0.826000, valid loss: 193.550737
epoch: 2241, train precision: 0.987600, train loss: 15.803245, valid precision: 0.829800, valid loss: 220.758278
epoch: 2242, train precision: 0.987244, train loss: 16.160741, valid precision: 0.831400, valid loss: 218.844741
epoch: 2243, train precision: 0.988222, train loss: 15.502070, valid precision: 0.831600, valid loss: 202.970233
epoch: 2244, train precision: 0.988200, train loss: 15.619453, valid precision: 0.835200, valid loss: 204.251094
epoch: 2245, train precision: 0.987289, train loss: 16.044498, valid precision: 0.831000, valid loss: 218.120680
epoch: 2246, train precision: 0.985889, train loss: 16.662289, valid precision: 0.829000, valid loss: 179.801828
epoch: 2247, train precision: 0.987600, train loss: 15.603796, valid precision: 0.832400, valid loss: 201.185905
epoch: 2248, train precision: 0.985733, train loss: 16.995684, valid precision: 0.831000, valid loss: 231.497925
epoch: 2249, train precision: 0.983022, train loss: 18.344181, valid precision: 0.832000, valid loss: 215.625764
epoch: 2250, train precision: 0.986756, train loss: 15.849746, valid precision: 0.832800, valid loss: 195.542698
epoch: 2251, train precision: 0.987156, train loss: 15.682124, valid precision: 0.830000, valid loss: 187.763308
epoch: 2252, train precision: 0.983533, train loss: 17.077717, valid precision: 0.827800, valid loss: 183.585180
epoch: 2253, train precision: 0.985600, train loss: 17.299813, valid precision: 0.827000, valid loss: 221.267037
epoch: 2254, train precision: 0.981044, train loss: 19.721450, valid precision: 0.823000, valid loss: 218.393543
epoch: 2255, train precision: 0.980733, train loss: 19.273969, valid precision: 0.828200, valid loss: 204.211995
epoch: 2256, train precision: 0.987244, train loss: 15.624003, valid precision: 0.838200, valid loss: 191.637248
epoch: 2257, train precision: 0.985756, train loss: 17.277969, valid precision: 0.832000, valid loss: 214.451371
epoch: 2258, train precision: 0.988000, train loss: 15.216085, valid precision: 0.828600, valid loss: 186.309041
epoch: 2259, train precision: 0.988511, train loss: 15.417710, valid precision: 0.830400, valid loss: 210.082529
epoch: 2260, train precision: 0.987044, train loss: 16.250235, valid precision: 0.835000, valid loss: 205.309750
epoch: 2261, train precision: 0.987333, train loss: 16.202555, valid precision: 0.828200, valid loss: 201.407907
epoch: 2262, train precision: 0.984644, train loss: 17.177649, valid precision: 0.829400, valid loss: 200.878930
epoch: 2263, train precision: 0.982378, train loss: 17.822193, valid precision: 0.823600, valid loss: 188.933378
epoch: 2264, train precision: 0.986956, train loss: 16.203670, valid precision: 0.833400, valid loss: 222.413252
epoch: 2265, train precision: 0.988378, train loss: 14.919584, valid precision: 0.840600, valid loss: 196.613218
epoch: 2266, train precision: 0.986956, train loss: 16.213947, valid precision: 0.831200, valid loss: 195.082666
epoch: 2267, train precision: 0.986378, train loss: 16.574791, valid precision: 0.827200, valid loss: 209.542984
epoch: 2268, train precision: 0.986200, train loss: 16.380949, valid precision: 0.831400, valid loss: 212.698623
epoch: 2269, train precision: 0.985444, train loss: 16.810759, valid precision: 0.838200, valid loss: 199.321185
epoch: 2270, train precision: 0.986644, train loss: 16.612702, valid precision: 0.834000, valid loss: 213.579979
epoch: 2271, train precision: 0.984311, train loss: 17.265618, valid precision: 0.835400, valid loss: 192.088303
epoch: 2272, train precision: 0.986778, train loss: 16.335427, valid precision: 0.831000, valid loss: 195.403294
epoch: 2273, train precision: 0.987533, train loss: 16.018744, valid precision: 0.837800, valid loss: 219.440962
epoch: 2274, train precision: 0.988644, train loss: 15.257273, valid precision: 0.841200, valid loss: 186.701347
epoch: 2275, train precision: 0.988644, train loss: 15.704514, valid precision: 0.840200, valid loss: 209.474474
epoch: 2276, train precision: 0.986533, train loss: 16.146480, valid precision: 0.835000, valid loss: 195.642055
epoch: 2277, train precision: 0.989267, train loss: 15.344180, valid precision: 0.831400, valid loss: 223.895743
epoch: 2278, train precision: 0.984711, train loss: 17.140365, valid precision: 0.833000, valid loss: 207.956332
epoch: 2279, train precision: 0.979000, train loss: 19.814349, valid precision: 0.826400, valid loss: 199.159539
epoch: 2280, train precision: 0.986467, train loss: 16.642519, valid precision: 0.835400, valid loss: 200.392544
epoch: 2281, train precision: 0.987244, train loss: 16.094083, valid precision: 0.831400, valid loss: 182.588428
epoch: 2282, train precision: 0.983133, train loss: 18.350440, valid precision: 0.838200, valid loss: 202.732510
epoch: 2283, train precision: 0.982000, train loss: 19.252444, valid precision: 0.826400, valid loss: 223.807284
epoch: 2284, train precision: 0.988089, train loss: 15.665152, valid precision: 0.834000, valid loss: 217.557415
epoch: 2285, train precision: 0.988556, train loss: 15.496533, valid precision: 0.832200, valid loss: 201.383111
epoch: 2286, train precision: 0.986000, train loss: 16.818856, valid precision: 0.831400, valid loss: 209.959919
epoch: 2287, train precision: 0.987022, train loss: 16.060154, valid precision: 0.833400, valid loss: 197.370627
epoch: 2288, train precision: 0.988956, train loss: 14.890031, valid precision: 0.837800, valid loss: 202.567712
epoch: 2289, train precision: 0.981378, train loss: 18.987049, valid precision: 0.829800, valid loss: 206.411890
epoch: 2290, train precision: 0.986756, train loss: 16.226546, valid precision: 0.826800, valid loss: 205.873158
epoch: 2291, train precision: 0.987822, train loss: 15.782980, valid precision: 0.833400, valid loss: 195.329805
epoch: 2292, train precision: 0.987222, train loss: 16.022963, valid precision: 0.833400, valid loss: 215.477215
epoch: 2293, train precision: 0.986356, train loss: 16.126721, valid precision: 0.826000, valid loss: 207.759643
epoch: 2294, train precision: 0.982267, train loss: 18.741593, valid precision: 0.828000, valid loss: 203.609769
epoch: 2295, train precision: 0.985867, train loss: 16.602686, valid precision: 0.828800, valid loss: 210.297929
epoch: 2296, train precision: 0.986044, train loss: 16.628111, valid precision: 0.829400, valid loss: 216.511239
epoch: 2297, train precision: 0.988733, train loss: 15.562235, valid precision: 0.833200, valid loss: 204.218137
epoch: 2298, train precision: 0.985156, train loss: 17.187521, valid precision: 0.827000, valid loss: 202.108254
epoch: 2299, train precision: 0.986400, train loss: 16.174313, valid precision: 0.828800, valid loss: 202.763708
epoch: 2300, train precision: 0.983200, train loss: 18.682811, valid precision: 0.822400, valid loss: 230.718573
epoch: 2301, train precision: 0.985978, train loss: 16.457785, valid precision: 0.833400, valid loss: 200.649896
epoch: 2302, train precision: 0.986289, train loss: 15.678861, valid precision: 0.835400, valid loss: 198.117785
epoch: 2303, train precision: 0.983267, train loss: 18.809768, valid precision: 0.828400, valid loss: 226.174822
epoch: 2304, train precision: 0.988489, train loss: 15.321623, valid precision: 0.830800, valid loss: 200.582445
epoch: 2305, train precision: 0.988178, train loss: 15.489686, valid precision: 0.832600, valid loss: 204.891634
epoch: 2306, train precision: 0.986622, train loss: 16.067994, valid precision: 0.827800, valid loss: 196.501630
epoch: 2307, train precision: 0.986378, train loss: 16.661811, valid precision: 0.827800, valid loss: 214.523856
epoch: 2308, train precision: 0.985133, train loss: 17.160786, valid precision: 0.828200, valid loss: 220.753708
epoch: 2309, train precision: 0.983400, train loss: 18.191023, valid precision: 0.833400, valid loss: 204.036832
epoch: 2310, train precision: 0.984733, train loss: 17.249358, valid precision: 0.831200, valid loss: 203.841322
epoch: 2311, train precision: 0.987311, train loss: 15.876496, valid precision: 0.840000, valid loss: 211.711429
epoch: 2312, train precision: 0.984178, train loss: 17.695862, valid precision: 0.832000, valid loss: 206.515876
epoch: 2313, train precision: 0.987889, train loss: 15.779741, valid precision: 0.828000, valid loss: 193.155984
epoch: 2314, train precision: 0.987044, train loss: 16.750495, valid precision: 0.828800, valid loss: 240.772354
epoch: 2315, train precision: 0.981667, train loss: 19.419341, valid precision: 0.825800, valid loss: 214.672934
epoch: 2316, train precision: 0.982533, train loss: 18.822287, valid precision: 0.820600, valid loss: 223.108635
epoch: 2317, train precision: 0.989800, train loss: 14.732817, valid precision: 0.832000, valid loss: 212.831706
epoch: 2318, train precision: 0.987956, train loss: 15.745750, valid precision: 0.831600, valid loss: 213.155294
epoch: 2319, train precision: 0.981867, train loss: 18.279029, valid precision: 0.822400, valid loss: 201.607408
epoch: 2320, train precision: 0.983556, train loss: 17.236138, valid precision: 0.825200, valid loss: 191.305472
epoch: 2321, train precision: 0.985244, train loss: 16.634283, valid precision: 0.825000, valid loss: 196.924059
epoch: 2322, train precision: 0.986489, train loss: 17.132731, valid precision: 0.834200, valid loss: 236.528417
epoch: 2323, train precision: 0.982978, train loss: 18.089079, valid precision: 0.822800, valid loss: 214.870453
epoch: 2324, train precision: 0.987244, train loss: 15.983167, valid precision: 0.829000, valid loss: 202.739606
epoch: 2325, train precision: 0.990867, train loss: 14.577280, valid precision: 0.834200, valid loss: 218.932101
epoch: 2326, train precision: 0.988467, train loss: 15.802139, valid precision: 0.833200, valid loss: 223.426330
epoch: 2327, train precision: 0.988356, train loss: 16.084130, valid precision: 0.832200, valid loss: 227.656541
epoch: 2328, train precision: 0.985667, train loss: 16.678284, valid precision: 0.832800, valid loss: 219.673317
epoch: 2329, train precision: 0.984644, train loss: 17.394639, valid precision: 0.826000, valid loss: 204.339723
epoch: 2330, train precision: 0.986756, train loss: 16.700220, valid precision: 0.830400, valid loss: 219.046539
epoch: 2331, train precision: 0.987356, train loss: 15.833504, valid precision: 0.831200, valid loss: 194.404663
epoch: 2332, train precision: 0.991133, train loss: 14.397930, valid precision: 0.834400, valid loss: 208.768834
epoch: 2333, train precision: 0.983511, train loss: 18.302606, valid precision: 0.829600, valid loss: 201.057953
epoch: 2334, train precision: 0.985400, train loss: 16.810879, valid precision: 0.831200, valid loss: 202.238470
epoch: 2335, train precision: 0.987400, train loss: 15.885680, valid precision: 0.835400, valid loss: 208.372898
epoch: 2336, train precision: 0.988600, train loss: 15.269614, valid precision: 0.830000, valid loss: 208.470635
epoch: 2337, train precision: 0.986333, train loss: 16.089760, valid precision: 0.835400, valid loss: 204.920202
epoch: 2338, train precision: 0.985333, train loss: 17.717174, valid precision: 0.841200, valid loss: 236.702346
epoch: 2339, train precision: 0.980844, train loss: 19.383789, valid precision: 0.831400, valid loss: 196.247456
epoch: 2340, train precision: 0.987867, train loss: 15.727433, valid precision: 0.831600, valid loss: 220.654170
epoch: 2341, train precision: 0.985622, train loss: 17.118179, valid precision: 0.829000, valid loss: 220.368263
epoch: 2342, train precision: 0.989156, train loss: 15.296883, valid precision: 0.838000, valid loss: 212.895989
epoch: 2343, train precision: 0.988844, train loss: 15.061607, valid precision: 0.835800, valid loss: 199.993279
epoch: 2344, train precision: 0.981222, train loss: 18.937948, valid precision: 0.834800, valid loss: 202.766291
epoch: 2345, train precision: 0.988422, train loss: 15.797772, valid precision: 0.837600, valid loss: 227.197450
epoch: 2346, train precision: 0.987778, train loss: 15.944499, valid precision: 0.838800, valid loss: 214.023214
epoch: 2347, train precision: 0.986400, train loss: 16.878830, valid precision: 0.836400, valid loss: 210.743216
epoch: 2348, train precision: 0.979556, train loss: 19.655870, valid precision: 0.828600, valid loss: 180.307395
epoch: 2349, train precision: 0.988956, train loss: 15.502606, valid precision: 0.836400, valid loss: 206.136595
epoch: 2350, train precision: 0.983933, train loss: 17.423386, valid precision: 0.825200, valid loss: 195.382341
epoch: 2351, train precision: 0.989200, train loss: 15.136915, valid precision: 0.833200, valid loss: 203.058508
epoch: 2352, train precision: 0.985800, train loss: 16.503704, valid precision: 0.831400, valid loss: 187.759448
epoch: 2353, train precision: 0.987978, train loss: 16.254159, valid precision: 0.830000, valid loss: 237.793737
epoch: 2354, train precision: 0.989200, train loss: 15.738326, valid precision: 0.830800, valid loss: 226.376887
epoch: 2355, train precision: 0.983044, train loss: 17.980745, valid precision: 0.827000, valid loss: 202.016776
epoch: 2356, train precision: 0.983444, train loss: 18.218626, valid precision: 0.831600, valid loss: 211.661150
epoch: 2357, train precision: 0.984600, train loss: 17.485163, valid precision: 0.830000, valid loss: 207.492369
epoch: 2358, train precision: 0.983356, train loss: 17.418958, valid precision: 0.821600, valid loss: 198.730708
epoch: 2359, train precision: 0.989422, train loss: 14.986055, valid precision: 0.832800, valid loss: 203.887646
epoch: 2360, train precision: 0.986356, train loss: 16.787365, valid precision: 0.828600, valid loss: 210.458657
epoch: 2361, train precision: 0.985222, train loss: 17.071823, valid precision: 0.833000, valid loss: 197.431504
epoch: 2362, train precision: 0.986178, train loss: 16.490820, valid precision: 0.829800, valid loss: 192.344170
epoch: 2363, train precision: 0.988978, train loss: 15.206488, valid precision: 0.834600, valid loss: 202.426118
epoch: 2364, train precision: 0.985467, train loss: 16.990772, valid precision: 0.831000, valid loss: 217.303536
epoch: 2365, train precision: 0.985933, train loss: 16.563140, valid precision: 0.830200, valid loss: 192.747892
epoch: 2366, train precision: 0.986289, train loss: 16.703587, valid precision: 0.832600, valid loss: 206.398539
epoch: 2367, train precision: 0.988600, train loss: 15.216029, valid precision: 0.834000, valid loss: 202.522645
epoch: 2368, train precision: 0.983311, train loss: 17.588916, valid precision: 0.831000, valid loss: 177.462842
epoch: 2369, train precision: 0.982867, train loss: 18.443140, valid precision: 0.832800, valid loss: 191.521560
epoch: 2370, train precision: 0.986911, train loss: 16.316313, valid precision: 0.836800, valid loss: 199.710912
epoch: 2371, train precision: 0.985222, train loss: 17.195522, valid precision: 0.830600, valid loss: 207.572588
epoch: 2372, train precision: 0.985778, train loss: 16.729283, valid precision: 0.835800, valid loss: 194.405275
epoch: 2373, train precision: 0.984356, train loss: 17.345867, valid precision: 0.834800, valid loss: 191.078844
epoch: 2374, train precision: 0.986600, train loss: 16.158727, valid precision: 0.831400, valid loss: 199.889044
epoch: 2375, train precision: 0.989556, train loss: 14.862070, valid precision: 0.831600, valid loss: 202.811063
epoch: 2376, train precision: 0.987800, train loss: 15.867373, valid precision: 0.828200, valid loss: 204.996028
epoch: 2377, train precision: 0.985133, train loss: 17.338572, valid precision: 0.834800, valid loss: 200.757956
epoch: 2378, train precision: 0.986444, train loss: 16.794811, valid precision: 0.837600, valid loss: 207.453890
epoch: 2379, train precision: 0.985022, train loss: 17.662398, valid precision: 0.834000, valid loss: 204.449388
epoch: 2380, train precision: 0.984600, train loss: 17.470580, valid precision: 0.832800, valid loss: 213.222895
epoch: 2381, train precision: 0.986933, train loss: 16.558326, valid precision: 0.835400, valid loss: 189.729552
epoch: 2382, train precision: 0.987867, train loss: 15.815775, valid precision: 0.832600, valid loss: 201.305939
epoch: 2383, train precision: 0.988178, train loss: 15.759513, valid precision: 0.839200, valid loss: 202.803588
epoch: 2384, train precision: 0.985311, train loss: 17.254743, valid precision: 0.836200, valid loss: 217.855379
epoch: 2385, train precision: 0.985400, train loss: 17.662052, valid precision: 0.835200, valid loss: 227.170849
epoch: 2386, train precision: 0.981867, train loss: 18.514705, valid precision: 0.835600, valid loss: 215.202431
epoch: 2387, train precision: 0.988111, train loss: 15.383679, valid precision: 0.832200, valid loss: 204.967365
epoch: 2388, train precision: 0.983978, train loss: 17.383672, valid precision: 0.831400, valid loss: 199.734017
epoch: 2389, train precision: 0.989400, train loss: 15.214823, valid precision: 0.838000, valid loss: 216.948173
epoch: 2390, train precision: 0.985822, train loss: 16.590784, valid precision: 0.831000, valid loss: 204.092268
epoch: 2391, train precision: 0.987756, train loss: 16.097589, valid precision: 0.834000, valid loss: 210.456531
epoch: 2392, train precision: 0.984711, train loss: 17.065046, valid precision: 0.832600, valid loss: 196.909810
epoch: 2393, train precision: 0.984400, train loss: 18.013950, valid precision: 0.828000, valid loss: 210.915751
epoch: 2394, train precision: 0.988600, train loss: 15.907195, valid precision: 0.837000, valid loss: 206.109351
epoch: 2395, train precision: 0.987911, train loss: 16.157809, valid precision: 0.833000, valid loss: 195.387216
epoch: 2396, train precision: 0.986000, train loss: 16.849453, valid precision: 0.830800, valid loss: 200.987277
epoch: 2397, train precision: 0.984733, train loss: 18.037948, valid precision: 0.829600, valid loss: 221.145895
epoch: 2398, train precision: 0.986356, train loss: 16.759577, valid precision: 0.832800, valid loss: 197.909591
epoch: 2399, train precision: 0.978800, train loss: 19.693418, valid precision: 0.826000, valid loss: 190.010914
epoch: 2400, train precision: 0.988356, train loss: 15.343646, valid precision: 0.830800, valid loss: 217.073270
epoch: 2401, train precision: 0.985578, train loss: 17.279195, valid precision: 0.828600, valid loss: 232.441974
epoch: 2402, train precision: 0.985311, train loss: 17.116550, valid precision: 0.826400, valid loss: 224.785094
epoch: 2403, train precision: 0.985400, train loss: 17.383832, valid precision: 0.829200, valid loss: 193.002577
epoch: 2404, train precision: 0.987156, train loss: 16.655196, valid precision: 0.832000, valid loss: 213.720472
epoch: 2405, train precision: 0.986822, train loss: 16.468781, valid precision: 0.835400, valid loss: 202.214160
epoch: 2406, train precision: 0.988778, train loss: 15.716023, valid precision: 0.836800, valid loss: 214.802169
epoch: 2407, train precision: 0.985400, train loss: 17.095886, valid precision: 0.835800, valid loss: 212.401320
epoch: 2408, train precision: 0.986333, train loss: 16.962524, valid precision: 0.833400, valid loss: 214.201815
epoch: 2409, train precision: 0.983756, train loss: 17.529318, valid precision: 0.825000, valid loss: 192.076782
epoch: 2410, train precision: 0.988333, train loss: 15.647996, valid precision: 0.832200, valid loss: 208.218510
epoch: 2411, train precision: 0.982111, train loss: 18.622546, valid precision: 0.826200, valid loss: 180.002594
epoch: 2412, train precision: 0.987089, train loss: 16.042263, valid precision: 0.828400, valid loss: 182.625824
epoch: 2413, train precision: 0.984622, train loss: 17.268970, valid precision: 0.835000, valid loss: 185.975591
epoch: 2414, train precision: 0.980756, train loss: 19.074651, valid precision: 0.823400, valid loss: 197.033067
epoch: 2415, train precision: 0.983978, train loss: 17.384626, valid precision: 0.829400, valid loss: 193.778756
epoch: 2416, train precision: 0.984222, train loss: 18.066673, valid precision: 0.836800, valid loss: 221.107387
epoch: 2417, train precision: 0.988133, train loss: 15.632741, valid precision: 0.828600, valid loss: 213.393787
epoch: 2418, train precision: 0.988556, train loss: 15.610278, valid precision: 0.831400, valid loss: 200.998703
epoch: 2419, train precision: 0.986467, train loss: 16.421312, valid precision: 0.830600, valid loss: 199.391591
epoch: 2420, train precision: 0.985578, train loss: 17.769149, valid precision: 0.825200, valid loss: 238.255115
epoch: 2421, train precision: 0.984622, train loss: 16.522309, valid precision: 0.828400, valid loss: 193.915277
epoch: 2422, train precision: 0.985333, train loss: 17.456617, valid precision: 0.829600, valid loss: 214.836401
epoch: 2423, train precision: 0.986444, train loss: 16.199735, valid precision: 0.827400, valid loss: 186.412072
epoch: 2424, train precision: 0.984622, train loss: 17.339635, valid precision: 0.830800, valid loss: 196.185117
epoch: 2425, train precision: 0.986578, train loss: 17.010745, valid precision: 0.833800, valid loss: 213.897329
epoch: 2426, train precision: 0.989800, train loss: 14.954118, valid precision: 0.836200, valid loss: 211.941975
epoch: 2427, train precision: 0.986178, train loss: 17.086352, valid precision: 0.838000, valid loss: 217.788406
epoch: 2428, train precision: 0.984378, train loss: 17.518317, valid precision: 0.830000, valid loss: 193.078866
epoch: 2429, train precision: 0.982378, train loss: 18.873996, valid precision: 0.828600, valid loss: 211.871764
epoch: 2430, train precision: 0.987800, train loss: 15.741793, valid precision: 0.832000, valid loss: 204.011360
epoch: 2431, train precision: 0.986022, train loss: 16.856859, valid precision: 0.827000, valid loss: 185.752831
epoch: 2432, train precision: 0.986156, train loss: 16.745493, valid precision: 0.827400, valid loss: 205.029020
epoch: 2433, train precision: 0.987844, train loss: 16.041034, valid precision: 0.833000, valid loss: 211.171745
epoch: 2434, train precision: 0.982889, train loss: 18.426466, valid precision: 0.830800, valid loss: 205.955292
epoch: 2435, train precision: 0.987422, train loss: 15.915496, valid precision: 0.831800, valid loss: 210.636240
epoch: 2436, train precision: 0.987822, train loss: 16.374285, valid precision: 0.835000, valid loss: 218.583301
epoch: 2437, train precision: 0.987756, train loss: 15.521310, valid precision: 0.829200, valid loss: 189.145926
epoch: 2438, train precision: 0.988089, train loss: 16.187485, valid precision: 0.831600, valid loss: 238.760373
epoch: 2439, train precision: 0.985200, train loss: 17.631650, valid precision: 0.828400, valid loss: 237.772756
epoch: 2440, train precision: 0.984378, train loss: 17.547594, valid precision: 0.823400, valid loss: 215.977515
epoch: 2441, train precision: 0.984200, train loss: 18.267748, valid precision: 0.827000, valid loss: 225.432962
epoch: 2442, train precision: 0.990578, train loss: 14.705634, valid precision: 0.837400, valid loss: 209.018857
epoch: 2443, train precision: 0.980778, train loss: 19.212205, valid precision: 0.827000, valid loss: 210.035415
epoch: 2444, train precision: 0.985156, train loss: 17.251904, valid precision: 0.831200, valid loss: 198.267551
epoch: 2445, train precision: 0.986022, train loss: 16.652970, valid precision: 0.831400, valid loss: 206.384035
epoch: 2446, train precision: 0.988000, train loss: 15.743623, valid precision: 0.831200, valid loss: 196.234844
epoch: 2447, train precision: 0.987356, train loss: 15.762757, valid precision: 0.831400, valid loss: 197.868155
epoch: 2448, train precision: 0.987467, train loss: 15.972438, valid precision: 0.831000, valid loss: 219.778675
epoch: 2449, train precision: 0.982333, train loss: 18.401515, valid precision: 0.830600, valid loss: 192.611865
epoch: 2450, train precision: 0.986356, train loss: 17.551254, valid precision: 0.829200, valid loss: 213.514767
epoch: 2451, train precision: 0.985444, train loss: 16.909489, valid precision: 0.835800, valid loss: 207.423973
epoch: 2452, train precision: 0.984111, train loss: 17.671354, valid precision: 0.829000, valid loss: 190.313611
epoch: 2453, train precision: 0.988622, train loss: 15.594398, valid precision: 0.834400, valid loss: 202.894264
epoch: 2454, train precision: 0.984267, train loss: 17.296900, valid precision: 0.830200, valid loss: 191.983979
epoch: 2455, train precision: 0.987733, train loss: 16.145545, valid precision: 0.832800, valid loss: 191.083799
epoch: 2456, train precision: 0.987556, train loss: 15.903736, valid precision: 0.833200, valid loss: 201.280642
epoch: 2457, train precision: 0.985356, train loss: 17.521683, valid precision: 0.826400, valid loss: 221.209139
epoch: 2458, train precision: 0.988022, train loss: 16.044231, valid precision: 0.833400, valid loss: 221.367465
epoch: 2459, train precision: 0.985511, train loss: 17.307620, valid precision: 0.833000, valid loss: 211.821041
epoch: 2460, train precision: 0.988711, train loss: 15.534809, valid precision: 0.832600, valid loss: 201.999063
epoch: 2461, train precision: 0.983844, train loss: 18.074580, valid precision: 0.826800, valid loss: 236.201469
epoch: 2462, train precision: 0.984667, train loss: 16.983912, valid precision: 0.825400, valid loss: 200.796223
epoch: 2463, train precision: 0.985289, train loss: 16.878870, valid precision: 0.831000, valid loss: 210.822912
epoch: 2464, train precision: 0.987533, train loss: 16.020775, valid precision: 0.832200, valid loss: 195.450911
epoch: 2465, train precision: 0.987867, train loss: 15.916456, valid precision: 0.833200, valid loss: 227.856882
epoch: 2466, train precision: 0.978644, train loss: 19.338486, valid precision: 0.825200, valid loss: 170.174370
epoch: 2467, train precision: 0.986644, train loss: 16.739296, valid precision: 0.830600, valid loss: 202.277562
epoch: 2468, train precision: 0.985733, train loss: 16.539988, valid precision: 0.833600, valid loss: 187.964834
epoch: 2469, train precision: 0.986178, train loss: 17.182056, valid precision: 0.834600, valid loss: 213.205859
epoch: 2470, train precision: 0.984422, train loss: 18.193772, valid precision: 0.830200, valid loss: 206.656211
epoch: 2471, train precision: 0.988489, train loss: 16.185578, valid precision: 0.835800, valid loss: 214.796608
epoch: 2472, train precision: 0.985467, train loss: 16.905083, valid precision: 0.835000, valid loss: 187.950354
epoch: 2473, train precision: 0.985267, train loss: 17.385910, valid precision: 0.832200, valid loss: 206.787654
epoch: 2474, train precision: 0.979067, train loss: 20.022515, valid precision: 0.826800, valid loss: 191.138996
epoch: 2475, train precision: 0.986622, train loss: 16.485840, valid precision: 0.835400, valid loss: 200.344418
epoch: 2476, train precision: 0.984844, train loss: 17.737432, valid precision: 0.825000, valid loss: 214.135308
epoch: 2477, train precision: 0.983244, train loss: 18.717286, valid precision: 0.828200, valid loss: 211.689651
epoch: 2478, train precision: 0.987356, train loss: 16.165875, valid precision: 0.825400, valid loss: 200.952473
epoch: 2479, train precision: 0.985111, train loss: 16.978900, valid precision: 0.826200, valid loss: 195.170590
epoch: 2480, train precision: 0.981733, train loss: 18.752980, valid precision: 0.827200, valid loss: 216.405455
epoch: 2481, train precision: 0.986956, train loss: 16.385187, valid precision: 0.837600, valid loss: 195.523278
epoch: 2482, train precision: 0.984667, train loss: 17.292610, valid precision: 0.835400, valid loss: 199.858911
epoch: 2483, train precision: 0.981556, train loss: 18.863169, valid precision: 0.834800, valid loss: 199.857424
epoch: 2484, train precision: 0.986200, train loss: 16.455382, valid precision: 0.832000, valid loss: 196.369130
epoch: 2485, train precision: 0.984467, train loss: 17.276357, valid precision: 0.832600, valid loss: 192.996469
epoch: 2486, train precision: 0.987022, train loss: 16.163640, valid precision: 0.834000, valid loss: 192.562631
epoch: 2487, train precision: 0.981978, train loss: 19.104247, valid precision: 0.831200, valid loss: 202.658332
epoch: 2488, train precision: 0.986644, train loss: 16.120383, valid precision: 0.832400, valid loss: 197.948597
epoch: 2489, train precision: 0.983244, train loss: 17.852760, valid precision: 0.826200, valid loss: 196.046544
epoch: 2490, train precision: 0.987911, train loss: 15.732978, valid precision: 0.833400, valid loss: 195.203164
epoch: 2491, train precision: 0.985311, train loss: 17.465234, valid precision: 0.829200, valid loss: 195.676580
epoch: 2492, train precision: 0.979956, train loss: 20.291707, valid precision: 0.831600, valid loss: 204.767245
epoch: 2493, train precision: 0.986800, train loss: 16.667333, valid precision: 0.834000, valid loss: 225.509902
epoch: 2494, train precision: 0.987600, train loss: 15.664520, valid precision: 0.835000, valid loss: 188.800851
epoch: 2495, train precision: 0.988311, train loss: 15.791691, valid precision: 0.839600, valid loss: 199.605094
epoch: 2496, train precision: 0.987489, train loss: 16.577221, valid precision: 0.833200, valid loss: 199.350057
epoch: 2497, train precision: 0.982244, train loss: 18.552122, valid precision: 0.828200, valid loss: 190.039072
epoch: 2498, train precision: 0.984356, train loss: 18.390767, valid precision: 0.836200, valid loss: 209.828984
epoch: 2499, train precision: 0.988467, train loss: 16.085816, valid precision: 0.839200, valid loss: 226.882484
epoch: 2500, train precision: 0.982711, train loss: 19.003827, valid precision: 0.830000, valid loss: 203.929395
epoch: 2501, train precision: 0.985622, train loss: 16.595978, valid precision: 0.827400, valid loss: 175.681581
epoch: 2502, train precision: 0.983800, train loss: 18.227292, valid precision: 0.831200, valid loss: 203.641206
epoch: 2503, train precision: 0.985733, train loss: 16.892413, valid precision: 0.830400, valid loss: 198.088545
epoch: 2504, train precision: 0.987222, train loss: 16.199626, valid precision: 0.832200, valid loss: 202.943874
epoch: 2505, train precision: 0.987844, train loss: 16.027595, valid precision: 0.832800, valid loss: 207.619716
epoch: 2506, train precision: 0.988289, train loss: 15.349988, valid precision: 0.831400, valid loss: 199.749115
epoch: 2507, train precision: 0.984778, train loss: 17.202750, valid precision: 0.834800, valid loss: 196.098055
epoch: 2508, train precision: 0.986889, train loss: 16.775179, valid precision: 0.831200, valid loss: 213.672728
epoch: 2509, train precision: 0.984644, train loss: 17.099549, valid precision: 0.832200, valid loss: 198.034865
epoch: 2510, train precision: 0.988356, train loss: 15.864254, valid precision: 0.832600, valid loss: 195.115783
epoch: 2511, train precision: 0.983933, train loss: 18.354204, valid precision: 0.834000, valid loss: 214.133998
epoch: 2512, train precision: 0.982289, train loss: 19.232535, valid precision: 0.837600, valid loss: 211.174752
epoch: 2513, train precision: 0.984600, train loss: 18.055153, valid precision: 0.829200, valid loss: 213.938848
epoch: 2514, train precision: 0.982956, train loss: 17.619259, valid precision: 0.828400, valid loss: 182.591290
epoch: 2515, train precision: 0.985711, train loss: 16.793529, valid precision: 0.842600, valid loss: 213.180828
epoch: 2516, train precision: 0.984644, train loss: 17.287534, valid precision: 0.837200, valid loss: 198.338360
epoch: 2517, train precision: 0.984622, train loss: 17.811231, valid precision: 0.836200, valid loss: 200.552863
epoch: 2518, train precision: 0.983133, train loss: 18.131351, valid precision: 0.836000, valid loss: 193.707951
epoch: 2519, train precision: 0.985444, train loss: 17.280186, valid precision: 0.832200, valid loss: 209.924676
epoch: 2520, train precision: 0.988067, train loss: 15.836634, valid precision: 0.834800, valid loss: 203.805902
epoch: 2521, train precision: 0.985156, train loss: 17.207685, valid precision: 0.835400, valid loss: 218.512786
epoch: 2522, train precision: 0.986111, train loss: 16.592219, valid precision: 0.832000, valid loss: 194.195371
epoch: 2523, train precision: 0.986511, train loss: 16.486428, valid precision: 0.831000, valid loss: 212.764911
epoch: 2524, train precision: 0.983156, train loss: 18.363009, valid precision: 0.831200, valid loss: 197.182410
epoch: 2525, train precision: 0.988867, train loss: 15.431366, valid precision: 0.836200, valid loss: 227.402651
epoch: 2526, train precision: 0.983333, train loss: 18.570851, valid precision: 0.832000, valid loss: 223.790615
epoch: 2527, train precision: 0.984511, train loss: 17.777544, valid precision: 0.832000, valid loss: 215.793877
epoch: 2528, train precision: 0.987356, train loss: 16.385837, valid precision: 0.833600, valid loss: 202.271340
epoch: 2529, train precision: 0.985889, train loss: 16.731550, valid precision: 0.833200, valid loss: 205.163208
epoch: 2530, train precision: 0.988889, train loss: 15.477715, valid precision: 0.830400, valid loss: 210.713896
epoch: 2531, train precision: 0.988067, train loss: 15.670070, valid precision: 0.831400, valid loss: 212.547740
epoch: 2532, train precision: 0.987089, train loss: 16.863540, valid precision: 0.841200, valid loss: 220.238107
epoch: 2533, train precision: 0.985467, train loss: 16.514784, valid precision: 0.832000, valid loss: 187.919950
epoch: 2534, train precision: 0.987600, train loss: 16.580665, valid precision: 0.830600, valid loss: 236.348144
epoch: 2535, train precision: 0.988067, train loss: 16.168217, valid precision: 0.835800, valid loss: 211.139013
epoch: 2536, train precision: 0.985200, train loss: 17.329958, valid precision: 0.829800, valid loss: 201.446820
epoch: 2537, train precision: 0.977333, train loss: 22.570891, valid precision: 0.831200, valid loss: 226.961916
epoch: 2538, train precision: 0.988689, train loss: 16.019932, valid precision: 0.841800, valid loss: 235.774953
epoch: 2539, train precision: 0.980844, train loss: 18.750525, valid precision: 0.829000, valid loss: 178.004295
epoch: 2540, train precision: 0.980311, train loss: 19.668447, valid precision: 0.833200, valid loss: 197.788868
epoch: 2541, train precision: 0.986289, train loss: 16.407152, valid precision: 0.835800, valid loss: 201.706859
epoch: 2542, train precision: 0.983044, train loss: 17.937762, valid precision: 0.833200, valid loss: 198.159418
epoch: 2543, train precision: 0.986822, train loss: 16.468350, valid precision: 0.827600, valid loss: 222.139558
epoch: 2544, train precision: 0.984356, train loss: 17.513355, valid precision: 0.831000, valid loss: 214.368492
epoch: 2545, train precision: 0.985289, train loss: 17.280267, valid precision: 0.828200, valid loss: 187.791998
epoch: 2546, train precision: 0.986622, train loss: 16.832619, valid precision: 0.834200, valid loss: 212.655854
epoch: 2547, train precision: 0.986644, train loss: 16.309671, valid precision: 0.837400, valid loss: 196.184054
epoch: 2548, train precision: 0.986244, train loss: 16.944394, valid precision: 0.835800, valid loss: 194.994771
epoch: 2549, train precision: 0.986600, train loss: 17.050390, valid precision: 0.834200, valid loss: 200.019713
epoch: 2550, train precision: 0.988089, train loss: 15.771431, valid precision: 0.835400, valid loss: 197.400396
epoch: 2551, train precision: 0.985044, train loss: 16.866598, valid precision: 0.834000, valid loss: 177.348917
epoch: 2552, train precision: 0.979867, train loss: 19.825221, valid precision: 0.830400, valid loss: 186.789025
epoch: 2553, train precision: 0.983467, train loss: 18.079571, valid precision: 0.827800, valid loss: 184.875863
epoch: 2554, train precision: 0.986511, train loss: 16.788028, valid precision: 0.839000, valid loss: 221.111576
epoch: 2555, train precision: 0.984644, train loss: 17.275597, valid precision: 0.831400, valid loss: 207.166083
epoch: 2556, train precision: 0.985600, train loss: 17.902083, valid precision: 0.837200, valid loss: 230.064163
epoch: 2557, train precision: 0.988556, train loss: 15.719114, valid precision: 0.841400, valid loss: 193.730584
epoch: 2558, train precision: 0.986622, train loss: 16.887373, valid precision: 0.833200, valid loss: 212.389839
epoch: 2559, train precision: 0.986778, train loss: 16.295118, valid precision: 0.827600, valid loss: 204.606053
epoch: 2560, train precision: 0.987178, train loss: 16.528626, valid precision: 0.831400, valid loss: 221.390943
epoch: 2561, train precision: 0.987000, train loss: 16.199839, valid precision: 0.828800, valid loss: 198.689809
epoch: 2562, train precision: 0.982089, train loss: 18.001623, valid precision: 0.828800, valid loss: 193.832685
epoch: 2563, train precision: 0.985711, train loss: 17.498765, valid precision: 0.830400, valid loss: 225.570697
epoch: 2564, train precision: 0.986356, train loss: 16.524836, valid precision: 0.831400, valid loss: 196.781011
epoch: 2565, train precision: 0.983444, train loss: 17.991980, valid precision: 0.833400, valid loss: 185.000029
epoch: 2566, train precision: 0.986956, train loss: 16.787986, valid precision: 0.831800, valid loss: 234.476711
epoch: 2567, train precision: 0.981533, train loss: 18.757804, valid precision: 0.831600, valid loss: 192.065024
epoch: 2568, train precision: 0.987756, train loss: 16.016184, valid precision: 0.834600, valid loss: 212.580836
epoch: 2569, train precision: 0.984133, train loss: 17.897205, valid precision: 0.827400, valid loss: 207.092737
epoch: 2570, train precision: 0.981067, train loss: 18.622209, valid precision: 0.830200, valid loss: 200.000133
epoch: 2571, train precision: 0.981400, train loss: 19.400755, valid precision: 0.832000, valid loss: 226.010725
epoch: 2572, train precision: 0.987333, train loss: 16.091590, valid precision: 0.837400, valid loss: 190.745339
epoch: 2573, train precision: 0.984600, train loss: 17.583688, valid precision: 0.832400, valid loss: 192.205330
epoch: 2574, train precision: 0.987133, train loss: 16.519710, valid precision: 0.836000, valid loss: 230.854430
epoch: 2575, train precision: 0.983556, train loss: 18.333745, valid precision: 0.830000, valid loss: 216.269283
epoch: 2576, train precision: 0.983600, train loss: 18.533838, valid precision: 0.829200, valid loss: 207.368586
epoch: 2577, train precision: 0.987533, train loss: 15.626515, valid precision: 0.836000, valid loss: 199.004432
epoch: 2578, train precision: 0.986689, train loss: 16.708241, valid precision: 0.836000, valid loss: 224.373322
epoch: 2579, train precision: 0.987178, train loss: 16.866392, valid precision: 0.835000, valid loss: 229.150619
epoch: 2580, train precision: 0.985156, train loss: 17.171952, valid precision: 0.827800, valid loss: 214.261661
epoch: 2581, train precision: 0.981178, train loss: 20.326265, valid precision: 0.830200, valid loss: 216.589569
epoch: 2582, train precision: 0.986533, train loss: 16.455856, valid precision: 0.830200, valid loss: 215.610357
epoch: 2583, train precision: 0.990644, train loss: 14.890438, valid precision: 0.837600, valid loss: 212.922146
epoch: 2584, train precision: 0.979422, train loss: 19.767609, valid precision: 0.823000, valid loss: 204.967145
epoch: 2585, train precision: 0.980444, train loss: 19.445671, valid precision: 0.827400, valid loss: 207.826644
epoch: 2586, train precision: 0.980800, train loss: 20.238372, valid precision: 0.832600, valid loss: 226.009042
epoch: 2587, train precision: 0.980333, train loss: 20.059107, valid precision: 0.834600, valid loss: 229.583138
epoch: 2588, train precision: 0.984756, train loss: 17.546675, valid precision: 0.832800, valid loss: 204.603831
epoch: 2589, train precision: 0.985956, train loss: 16.962325, valid precision: 0.834200, valid loss: 220.730419
epoch: 2590, train precision: 0.984133, train loss: 17.467908, valid precision: 0.825600, valid loss: 204.233845
epoch: 2591, train precision: 0.984756, train loss: 17.969240, valid precision: 0.830800, valid loss: 195.122386
epoch: 2592, train precision: 0.986267, train loss: 16.610808, valid precision: 0.834800, valid loss: 196.965456
epoch: 2593, train precision: 0.983644, train loss: 18.596093, valid precision: 0.830000, valid loss: 233.660155
epoch: 2594, train precision: 0.989600, train loss: 15.215794, valid precision: 0.840800, valid loss: 208.201477
epoch: 2595, train precision: 0.984178, train loss: 17.958830, valid precision: 0.832000, valid loss: 222.579395
epoch: 2596, train precision: 0.985889, train loss: 16.970840, valid precision: 0.832400, valid loss: 205.225513
epoch: 2597, train precision: 0.987000, train loss: 16.586176, valid precision: 0.839600, valid loss: 193.773340
epoch: 2598, train precision: 0.984133, train loss: 17.628756, valid precision: 0.829800, valid loss: 195.974879
epoch: 2599, train precision: 0.986044, train loss: 16.989270, valid precision: 0.832800, valid loss: 231.315840
epoch: 2600, train precision: 0.986222, train loss: 16.752105, valid precision: 0.835400, valid loss: 235.708954
epoch: 2601, train precision: 0.986000, train loss: 17.174763, valid precision: 0.831600, valid loss: 221.000349
epoch: 2602, train precision: 0.986467, train loss: 16.877887, valid precision: 0.834200, valid loss: 196.105713
epoch: 2603, train precision: 0.984689, train loss: 17.316990, valid precision: 0.832600, valid loss: 186.322760
epoch: 2604, train precision: 0.982044, train loss: 18.521940, valid precision: 0.831800, valid loss: 195.028494
epoch: 2605, train precision: 0.986333, train loss: 16.291933, valid precision: 0.834600, valid loss: 197.538283
epoch: 2606, train precision: 0.984844, train loss: 17.792600, valid precision: 0.835400, valid loss: 200.643134
epoch: 2607, train precision: 0.987889, train loss: 15.964481, valid precision: 0.833800, valid loss: 207.112918
epoch: 2608, train precision: 0.985867, train loss: 17.582523, valid precision: 0.838200, valid loss: 209.704713
epoch: 2609, train precision: 0.979422, train loss: 20.137189, valid precision: 0.837000, valid loss: 184.893173
epoch: 2610, train precision: 0.987800, train loss: 16.338524, valid precision: 0.842600, valid loss: 221.256370
epoch: 2611, train precision: 0.985156, train loss: 17.067108, valid precision: 0.839000, valid loss: 194.078901
epoch: 2612, train precision: 0.984467, train loss: 17.720362, valid precision: 0.831200, valid loss: 204.647322
epoch: 2613, train precision: 0.985956, train loss: 17.080955, valid precision: 0.832600, valid loss: 202.196234
epoch: 2614, train precision: 0.984422, train loss: 17.821601, valid precision: 0.835000, valid loss: 199.213845
epoch: 2615, train precision: 0.982200, train loss: 19.344154, valid precision: 0.838200, valid loss: 216.594282
epoch: 2616, train precision: 0.983178, train loss: 18.575263, valid precision: 0.832600, valid loss: 203.996048
epoch: 2617, train precision: 0.986489, train loss: 16.578564, valid precision: 0.835000, valid loss: 199.377460
epoch: 2618, train precision: 0.985644, train loss: 17.353564, valid precision: 0.840000, valid loss: 208.259686
epoch: 2619, train precision: 0.983200, train loss: 17.993444, valid precision: 0.832200, valid loss: 198.166591
epoch: 2620, train precision: 0.980911, train loss: 19.163607, valid precision: 0.829000, valid loss: 197.251930
epoch: 2621, train precision: 0.985778, train loss: 17.166291, valid precision: 0.835600, valid loss: 195.776238
epoch: 2622, train precision: 0.984356, train loss: 17.697648, valid precision: 0.831400, valid loss: 195.342016
epoch: 2623, train precision: 0.981000, train loss: 19.017491, valid precision: 0.830400, valid loss: 193.633650
epoch: 2624, train precision: 0.984844, train loss: 18.202055, valid precision: 0.835000, valid loss: 229.372885
epoch: 2625, train precision: 0.985244, train loss: 17.790501, valid precision: 0.831800, valid loss: 221.872726
epoch: 2626, train precision: 0.985600, train loss: 16.962915, valid precision: 0.836600, valid loss: 200.669629
epoch: 2627, train precision: 0.983933, train loss: 17.841736, valid precision: 0.840400, valid loss: 191.456806
epoch: 2628, train precision: 0.983822, train loss: 18.415155, valid precision: 0.830000, valid loss: 203.939005
epoch: 2629, train precision: 0.987467, train loss: 16.529144, valid precision: 0.840200, valid loss: 216.617574
epoch: 2630, train precision: 0.979956, train loss: 20.013105, valid precision: 0.828000, valid loss: 201.211595
epoch: 2631, train precision: 0.986400, train loss: 17.306500, valid precision: 0.834800, valid loss: 211.756155
epoch: 2632, train precision: 0.982400, train loss: 19.127200, valid precision: 0.826200, valid loss: 202.252120
epoch: 2633, train precision: 0.983467, train loss: 18.520169, valid precision: 0.829400, valid loss: 201.832222
epoch: 2634, train precision: 0.988267, train loss: 15.740140, valid precision: 0.835800, valid loss: 203.899619
epoch: 2635, train precision: 0.981844, train loss: 18.570726, valid precision: 0.826400, valid loss: 181.103235
epoch: 2636, train precision: 0.983444, train loss: 18.163024, valid precision: 0.832400, valid loss: 196.503472
epoch: 2637, train precision: 0.982178, train loss: 18.969857, valid precision: 0.832200, valid loss: 205.749603
epoch: 2638, train precision: 0.989644, train loss: 15.167506, valid precision: 0.841000, valid loss: 195.314291
epoch: 2639, train precision: 0.987533, train loss: 16.117060, valid precision: 0.843600, valid loss: 185.773051
epoch: 2640, train precision: 0.987733, train loss: 15.983686, valid precision: 0.841000, valid loss: 196.942793
epoch: 2641, train precision: 0.987178, train loss: 16.236752, valid precision: 0.839400, valid loss: 192.228988
epoch: 2642, train precision: 0.982156, train loss: 18.709657, valid precision: 0.832400, valid loss: 175.981378
epoch: 2643, train precision: 0.982133, train loss: 18.389766, valid precision: 0.829400, valid loss: 172.308098
epoch: 2644, train precision: 0.984489, train loss: 17.920976, valid precision: 0.833600, valid loss: 212.661064
epoch: 2645, train precision: 0.989333, train loss: 15.422891, valid precision: 0.838400, valid loss: 210.500707
epoch: 2646, train precision: 0.984289, train loss: 17.921892, valid precision: 0.837400, valid loss: 199.401521
epoch: 2647, train precision: 0.984133, train loss: 17.929670, valid precision: 0.835000, valid loss: 195.810884
epoch: 2648, train precision: 0.984511, train loss: 18.079364, valid precision: 0.841600, valid loss: 224.639228
epoch: 2649, train precision: 0.981444, train loss: 18.734092, valid precision: 0.828200, valid loss: 192.614896
epoch: 2650, train precision: 0.986178, train loss: 16.939505, valid precision: 0.837000, valid loss: 241.129852
epoch: 2651, train precision: 0.983489, train loss: 18.247353, valid precision: 0.829200, valid loss: 212.960778
epoch: 2652, train precision: 0.984600, train loss: 17.439540, valid precision: 0.832800, valid loss: 193.359355
epoch: 2653, train precision: 0.985889, train loss: 17.256824, valid precision: 0.833400, valid loss: 213.906554
epoch: 2654, train precision: 0.989244, train loss: 15.529833, valid precision: 0.842200, valid loss: 219.207701
epoch: 2655, train precision: 0.984844, train loss: 17.589982, valid precision: 0.831400, valid loss: 212.326674
epoch: 2656, train precision: 0.979556, train loss: 19.753924, valid precision: 0.825600, valid loss: 175.458617
epoch: 2657, train precision: 0.984311, train loss: 17.878984, valid precision: 0.835600, valid loss: 215.016127
epoch: 2658, train precision: 0.983889, train loss: 18.088085, valid precision: 0.831400, valid loss: 191.813706
epoch: 2659, train precision: 0.986756, train loss: 16.763536, valid precision: 0.830200, valid loss: 212.224108
epoch: 2660, train precision: 0.988444, train loss: 16.098779, valid precision: 0.830400, valid loss: 223.245081
epoch: 2661, train precision: 0.986156, train loss: 17.129077, valid precision: 0.832600, valid loss: 203.354546
epoch: 2662, train precision: 0.985889, train loss: 17.014082, valid precision: 0.829600, valid loss: 206.065070
epoch: 2663, train precision: 0.986933, train loss: 16.542786, valid precision: 0.835800, valid loss: 200.792936
epoch: 2664, train precision: 0.985867, train loss: 16.974797, valid precision: 0.829200, valid loss: 201.571890
epoch: 2665, train precision: 0.985778, train loss: 17.022772, valid precision: 0.839200, valid loss: 204.096790
epoch: 2666, train precision: 0.984867, train loss: 17.360942, valid precision: 0.836600, valid loss: 189.453846
epoch: 2667, train precision: 0.983356, train loss: 19.166522, valid precision: 0.827600, valid loss: 226.332119
epoch: 2668, train precision: 0.985889, train loss: 16.852661, valid precision: 0.837800, valid loss: 191.457263
epoch: 2669, train precision: 0.988822, train loss: 16.065108, valid precision: 0.836400, valid loss: 221.517367
epoch: 2670, train precision: 0.985622, train loss: 16.873916, valid precision: 0.835200, valid loss: 195.720821
epoch: 2671, train precision: 0.988244, train loss: 15.983539, valid precision: 0.834800, valid loss: 202.563621
epoch: 2672, train precision: 0.982778, train loss: 18.450516, valid precision: 0.830800, valid loss: 216.358003
epoch: 2673, train precision: 0.987778, train loss: 15.967472, valid precision: 0.835800, valid loss: 203.807956
epoch: 2674, train precision: 0.986556, train loss: 16.983359, valid precision: 0.836000, valid loss: 207.317001
epoch: 2675, train precision: 0.985311, train loss: 17.234776, valid precision: 0.827600, valid loss: 182.202374
epoch: 2676, train precision: 0.987267, train loss: 16.151246, valid precision: 0.833600, valid loss: 201.995937
epoch: 2677, train precision: 0.987378, train loss: 15.705929, valid precision: 0.832200, valid loss: 194.703555
epoch: 2678, train precision: 0.985889, train loss: 17.076885, valid precision: 0.834400, valid loss: 210.883467
epoch: 2679, train precision: 0.982244, train loss: 18.927275, valid precision: 0.828000, valid loss: 202.603307
epoch: 2680, train precision: 0.984889, train loss: 17.811806, valid precision: 0.837600, valid loss: 223.073745
epoch: 2681, train precision: 0.987444, train loss: 16.613379, valid precision: 0.832400, valid loss: 217.957878
epoch: 2682, train precision: 0.981756, train loss: 18.673414, valid precision: 0.834200, valid loss: 187.393634
epoch: 2683, train precision: 0.986644, train loss: 16.759961, valid precision: 0.835800, valid loss: 212.457821
epoch: 2684, train precision: 0.984111, train loss: 18.289642, valid precision: 0.830400, valid loss: 199.821633
epoch: 2685, train precision: 0.985956, train loss: 16.706239, valid precision: 0.831200, valid loss: 192.476933
epoch: 2686, train precision: 0.986156, train loss: 16.997742, valid precision: 0.831400, valid loss: 209.274814
epoch: 2687, train precision: 0.981822, train loss: 18.847936, valid precision: 0.829200, valid loss: 202.711456
epoch: 2688, train precision: 0.981000, train loss: 19.749496, valid precision: 0.833000, valid loss: 215.090073
epoch: 2689, train precision: 0.986422, train loss: 16.534367, valid precision: 0.832800, valid loss: 209.916591
epoch: 2690, train precision: 0.986511, train loss: 16.735763, valid precision: 0.836200, valid loss: 202.159202
epoch: 2691, train precision: 0.988089, train loss: 15.833762, valid precision: 0.832600, valid loss: 204.267500
epoch: 2692, train precision: 0.983711, train loss: 17.696649, valid precision: 0.835400, valid loss: 199.043968
epoch: 2693, train precision: 0.982867, train loss: 18.303310, valid precision: 0.832200, valid loss: 186.441546
epoch: 2694, train precision: 0.984222, train loss: 17.854438, valid precision: 0.833800, valid loss: 201.969891
epoch: 2695, train precision: 0.983067, train loss: 18.868299, valid precision: 0.829800, valid loss: 215.733662
epoch: 2696, train precision: 0.986733, train loss: 17.143829, valid precision: 0.842400, valid loss: 208.908877
epoch: 2697, train precision: 0.981022, train loss: 19.220344, valid precision: 0.831800, valid loss: 202.649291
epoch: 2698, train precision: 0.987578, train loss: 16.258181, valid precision: 0.836600, valid loss: 206.951026
epoch: 2699, train precision: 0.984689, train loss: 17.778732, valid precision: 0.829200, valid loss: 202.299538
epoch: 2700, train precision: 0.985311, train loss: 17.275782, valid precision: 0.836400, valid loss: 188.976107
epoch: 2701, train precision: 0.986733, train loss: 16.491613, valid precision: 0.828800, valid loss: 205.068609
epoch: 2702, train precision: 0.985022, train loss: 17.720915, valid precision: 0.833200, valid loss: 204.499736
epoch: 2703, train precision: 0.985133, train loss: 18.204116, valid precision: 0.833600, valid loss: 208.614018
epoch: 2704, train precision: 0.983822, train loss: 18.559540, valid precision: 0.838400, valid loss: 207.153081
epoch: 2705, train precision: 0.986578, train loss: 16.740656, valid precision: 0.830600, valid loss: 195.935708
epoch: 2706, train precision: 0.982156, train loss: 19.082365, valid precision: 0.829600, valid loss: 198.170984
epoch: 2707, train precision: 0.979911, train loss: 19.701477, valid precision: 0.826600, valid loss: 198.059509
epoch: 2708, train precision: 0.985600, train loss: 17.208906, valid precision: 0.833200, valid loss: 217.259758
epoch: 2709, train precision: 0.984244, train loss: 18.926255, valid precision: 0.833200, valid loss: 233.789237
epoch: 2710, train precision: 0.985467, train loss: 17.455810, valid precision: 0.831200, valid loss: 218.638814
epoch: 2711, train precision: 0.988822, train loss: 15.386093, valid precision: 0.835600, valid loss: 217.582298
epoch: 2712, train precision: 0.987333, train loss: 16.640959, valid precision: 0.831400, valid loss: 223.691873
epoch: 2713, train precision: 0.981933, train loss: 19.378743, valid precision: 0.831400, valid loss: 216.105635
epoch: 2714, train precision: 0.986022, train loss: 17.035724, valid precision: 0.835400, valid loss: 207.286582
epoch: 2715, train precision: 0.980911, train loss: 19.294997, valid precision: 0.831200, valid loss: 209.888238
epoch: 2716, train precision: 0.987956, train loss: 16.111932, valid precision: 0.838000, valid loss: 204.598245
epoch: 2717, train precision: 0.983133, train loss: 17.986661, valid precision: 0.832200, valid loss: 199.218665
epoch: 2718, train precision: 0.987600, train loss: 16.248134, valid precision: 0.837200, valid loss: 219.260776
epoch: 2719, train precision: 0.986822, train loss: 16.801287, valid precision: 0.830000, valid loss: 201.781220
epoch: 2720, train precision: 0.987800, train loss: 16.309091, valid precision: 0.835200, valid loss: 206.684456
epoch: 2721, train precision: 0.983044, train loss: 18.508139, valid precision: 0.829400, valid loss: 207.674348
epoch: 2722, train precision: 0.985311, train loss: 16.755901, valid precision: 0.831800, valid loss: 198.735275
epoch: 2723, train precision: 0.982089, train loss: 18.957345, valid precision: 0.827400, valid loss: 200.475838
epoch: 2724, train precision: 0.987511, train loss: 16.302687, valid precision: 0.830400, valid loss: 212.033130
epoch: 2725, train precision: 0.985822, train loss: 17.267306, valid precision: 0.827600, valid loss: 204.983614
epoch: 2726, train precision: 0.986889, train loss: 16.651535, valid precision: 0.835200, valid loss: 212.544303
epoch: 2727, train precision: 0.984333, train loss: 19.032810, valid precision: 0.833200, valid loss: 235.298933
epoch: 2728, train precision: 0.982822, train loss: 17.699663, valid precision: 0.825600, valid loss: 194.550313
epoch: 2729, train precision: 0.984289, train loss: 18.069544, valid precision: 0.827000, valid loss: 206.816384
epoch: 2730, train precision: 0.988133, train loss: 15.789926, valid precision: 0.834600, valid loss: 223.909637
epoch: 2731, train precision: 0.978644, train loss: 20.252909, valid precision: 0.824400, valid loss: 188.379697
epoch: 2732, train precision: 0.984533, train loss: 18.422685, valid precision: 0.836000, valid loss: 211.934257
epoch: 2733, train precision: 0.985244, train loss: 17.957315, valid precision: 0.830400, valid loss: 227.030769
epoch: 2734, train precision: 0.982089, train loss: 18.431698, valid precision: 0.833000, valid loss: 190.492824
epoch: 2735, train precision: 0.987133, train loss: 16.277084, valid precision: 0.834400, valid loss: 229.354510
epoch: 2736, train precision: 0.982200, train loss: 18.951625, valid precision: 0.837400, valid loss: 197.749587
epoch: 2737, train precision: 0.982378, train loss: 18.922051, valid precision: 0.828600, valid loss: 206.671165
epoch: 2738, train precision: 0.985800, train loss: 16.970931, valid precision: 0.835800, valid loss: 208.786519
epoch: 2739, train precision: 0.985178, train loss: 17.442680, valid precision: 0.832000, valid loss: 199.396831
epoch: 2740, train precision: 0.981133, train loss: 19.416933, valid precision: 0.829600, valid loss: 205.180738
epoch: 2741, train precision: 0.983889, train loss: 18.295868, valid precision: 0.827000, valid loss: 210.410836
epoch: 2742, train precision: 0.984111, train loss: 17.781785, valid precision: 0.836200, valid loss: 187.926794
epoch: 2743, train precision: 0.982867, train loss: 18.104204, valid precision: 0.833800, valid loss: 194.290651
epoch: 2744, train precision: 0.981622, train loss: 18.769475, valid precision: 0.827000, valid loss: 197.883729
epoch: 2745, train precision: 0.986400, train loss: 17.357940, valid precision: 0.833200, valid loss: 208.036531
epoch: 2746, train precision: 0.984178, train loss: 19.024772, valid precision: 0.836400, valid loss: 233.201812
epoch: 2747, train precision: 0.986511, train loss: 16.830842, valid precision: 0.830200, valid loss: 188.044677
epoch: 2748, train precision: 0.986311, train loss: 16.765715, valid precision: 0.837000, valid loss: 196.007574
epoch: 2749, train precision: 0.987111, train loss: 17.117767, valid precision: 0.840600, valid loss: 224.859853
epoch: 2750, train precision: 0.984178, train loss: 17.869017, valid precision: 0.832400, valid loss: 210.684253
epoch: 2751, train precision: 0.987711, train loss: 16.649532, valid precision: 0.840600, valid loss: 230.526481
epoch: 2752, train precision: 0.982000, train loss: 19.148662, valid precision: 0.830800, valid loss: 206.689479
epoch: 2753, train precision: 0.985311, train loss: 17.267508, valid precision: 0.834000, valid loss: 219.166034
epoch: 2754, train precision: 0.988511, train loss: 16.295233, valid precision: 0.839200, valid loss: 219.415557
epoch: 2755, train precision: 0.984089, train loss: 18.758086, valid precision: 0.834200, valid loss: 247.666549
epoch: 2756, train precision: 0.983511, train loss: 18.027208, valid precision: 0.828000, valid loss: 202.029389
epoch: 2757, train precision: 0.982000, train loss: 19.029597, valid precision: 0.829800, valid loss: 212.208043
epoch: 2758, train precision: 0.982578, train loss: 18.871553, valid precision: 0.833000, valid loss: 212.364339
epoch: 2759, train precision: 0.986044, train loss: 17.093920, valid precision: 0.831600, valid loss: 197.281602
epoch: 2760, train precision: 0.982156, train loss: 18.600513, valid precision: 0.835800, valid loss: 199.266381
epoch: 2761, train precision: 0.982333, train loss: 19.335275, valid precision: 0.827600, valid loss: 213.043155
epoch: 2762, train precision: 0.982711, train loss: 18.194482, valid precision: 0.832800, valid loss: 191.299291
epoch: 2763, train precision: 0.988244, train loss: 16.129569, valid precision: 0.839200, valid loss: 225.454725
epoch: 2764, train precision: 0.987044, train loss: 16.879367, valid precision: 0.839200, valid loss: 200.766017
epoch: 2765, train precision: 0.984600, train loss: 17.850694, valid precision: 0.837600, valid loss: 214.584368
epoch: 2766, train precision: 0.983600, train loss: 18.291427, valid precision: 0.830200, valid loss: 222.528544
epoch: 2767, train precision: 0.982111, train loss: 19.138258, valid precision: 0.826600, valid loss: 217.692708
epoch: 2768, train precision: 0.985467, train loss: 17.774385, valid precision: 0.841600, valid loss: 224.408084
epoch: 2769, train precision: 0.988756, train loss: 15.712952, valid precision: 0.837800, valid loss: 209.532427
epoch: 2770, train precision: 0.986800, train loss: 17.254323, valid precision: 0.838400, valid loss: 219.288385
epoch: 2771, train precision: 0.986378, train loss: 16.843603, valid precision: 0.834600, valid loss: 192.590898
epoch: 2772, train precision: 0.986933, train loss: 17.310190, valid precision: 0.836800, valid loss: 229.108586
epoch: 2773, train precision: 0.979200, train loss: 20.093047, valid precision: 0.825800, valid loss: 182.213924
epoch: 2774, train precision: 0.981422, train loss: 18.498675, valid precision: 0.831600, valid loss: 174.200158
epoch: 2775, train precision: 0.988533, train loss: 15.936216, valid precision: 0.836400, valid loss: 198.588744
epoch: 2776, train precision: 0.983556, train loss: 17.929110, valid precision: 0.828800, valid loss: 195.135209
epoch: 2777, train precision: 0.987733, train loss: 16.511456, valid precision: 0.834800, valid loss: 205.034370
epoch: 2778, train precision: 0.987067, train loss: 16.357482, valid precision: 0.840200, valid loss: 223.151218
epoch: 2779, train precision: 0.986578, train loss: 16.672927, valid precision: 0.831400, valid loss: 200.285571
epoch: 2780, train precision: 0.988067, train loss: 16.055915, valid precision: 0.837400, valid loss: 210.917906
epoch: 2781, train precision: 0.984378, train loss: 17.656235, valid precision: 0.838200, valid loss: 191.795827
epoch: 2782, train precision: 0.984222, train loss: 17.644817, valid precision: 0.836400, valid loss: 192.326769
epoch: 2783, train precision: 0.984556, train loss: 17.653529, valid precision: 0.837400, valid loss: 179.149295
epoch: 2784, train precision: 0.983289, train loss: 18.036366, valid precision: 0.834600, valid loss: 187.113651
epoch: 2785, train precision: 0.987244, train loss: 16.734104, valid precision: 0.831800, valid loss: 214.313561
epoch: 2786, train precision: 0.986800, train loss: 16.860393, valid precision: 0.837400, valid loss: 208.375696
epoch: 2787, train precision: 0.984822, train loss: 17.429233, valid precision: 0.837800, valid loss: 195.514488
epoch: 2788, train precision: 0.984733, train loss: 17.939662, valid precision: 0.832600, valid loss: 199.331388
epoch: 2789, train precision: 0.987644, train loss: 16.844155, valid precision: 0.841000, valid loss: 214.533584
epoch: 2790, train precision: 0.986422, train loss: 17.446961, valid precision: 0.841000, valid loss: 214.871058
epoch: 2791, train precision: 0.985578, train loss: 17.491813, valid precision: 0.823800, valid loss: 201.107054
epoch: 2792, train precision: 0.984800, train loss: 17.871382, valid precision: 0.839400, valid loss: 212.166090
epoch: 2793, train precision: 0.986422, train loss: 17.199854, valid precision: 0.833000, valid loss: 227.192736
epoch: 2794, train precision: 0.985578, train loss: 17.857010, valid precision: 0.835800, valid loss: 187.607303
epoch: 2795, train precision: 0.982644, train loss: 18.787639, valid precision: 0.834200, valid loss: 195.381117
epoch: 2796, train precision: 0.986800, train loss: 16.549881, valid precision: 0.833400, valid loss: 225.863982
epoch: 2797, train precision: 0.983622, train loss: 18.081503, valid precision: 0.835400, valid loss: 208.521792
epoch: 2798, train precision: 0.981356, train loss: 19.342200, valid precision: 0.829000, valid loss: 198.435398
epoch: 2799, train precision: 0.982622, train loss: 18.167768, valid precision: 0.832600, valid loss: 194.264561
epoch: 2800, train precision: 0.983156, train loss: 18.799478, valid precision: 0.828600, valid loss: 212.201633
epoch: 2801, train precision: 0.982578, train loss: 18.568181, valid precision: 0.830400, valid loss: 219.136976
epoch: 2802, train precision: 0.987556, train loss: 16.348441, valid precision: 0.839600, valid loss: 206.059033
epoch: 2803, train precision: 0.983156, train loss: 18.303750, valid precision: 0.832600, valid loss: 209.892250
epoch: 2804, train precision: 0.984356, train loss: 17.983539, valid precision: 0.836800, valid loss: 202.728985
epoch: 2805, train precision: 0.989378, train loss: 15.317291, valid precision: 0.835600, valid loss: 217.437477
epoch: 2806, train precision: 0.982156, train loss: 18.676015, valid precision: 0.834000, valid loss: 203.042278
epoch: 2807, train precision: 0.984178, train loss: 19.484406, valid precision: 0.832200, valid loss: 260.630886
epoch: 2808, train precision: 0.986578, train loss: 16.853220, valid precision: 0.835600, valid loss: 202.559877
epoch: 2809, train precision: 0.978244, train loss: 21.799995, valid precision: 0.831000, valid loss: 213.810589
epoch: 2810, train precision: 0.977400, train loss: 21.019721, valid precision: 0.825400, valid loss: 177.944406
epoch: 2811, train precision: 0.983867, train loss: 18.553874, valid precision: 0.835200, valid loss: 196.219416
epoch: 2812, train precision: 0.987978, train loss: 16.123264, valid precision: 0.838400, valid loss: 212.206929
epoch: 2813, train precision: 0.986156, train loss: 17.423914, valid precision: 0.842800, valid loss: 220.111675
epoch: 2814, train precision: 0.986356, train loss: 17.924824, valid precision: 0.838200, valid loss: 228.881747
epoch: 2815, train precision: 0.987133, train loss: 16.253287, valid precision: 0.832400, valid loss: 188.396497
epoch: 2816, train precision: 0.983111, train loss: 17.956219, valid precision: 0.833000, valid loss: 195.915425
epoch: 2817, train precision: 0.986800, train loss: 16.902788, valid precision: 0.835000, valid loss: 216.390952
epoch: 2818, train precision: 0.980511, train loss: 19.503318, valid precision: 0.826000, valid loss: 202.191645
epoch: 2819, train precision: 0.984733, train loss: 17.236719, valid precision: 0.831800, valid loss: 188.773841
epoch: 2820, train precision: 0.985956, train loss: 17.415030, valid precision: 0.831800, valid loss: 221.627839
epoch: 2821, train precision: 0.986356, train loss: 16.606584, valid precision: 0.833200, valid loss: 202.527590
epoch: 2822, train precision: 0.984133, train loss: 17.936506, valid precision: 0.827600, valid loss: 207.676587
epoch: 2823, train precision: 0.983200, train loss: 18.634964, valid precision: 0.834000, valid loss: 211.230307
epoch: 2824, train precision: 0.988467, train loss: 15.789816, valid precision: 0.838800, valid loss: 208.121147
epoch: 2825, train precision: 0.985422, train loss: 17.648711, valid precision: 0.833400, valid loss: 210.595409
epoch: 2826, train precision: 0.984244, train loss: 17.517450, valid precision: 0.834600, valid loss: 183.948436
epoch: 2827, train precision: 0.984400, train loss: 18.012292, valid precision: 0.833000, valid loss: 210.720276
epoch: 2828, train precision: 0.985956, train loss: 16.932035, valid precision: 0.842600, valid loss: 196.801773
epoch: 2829, train precision: 0.981956, train loss: 19.948444, valid precision: 0.832000, valid loss: 233.151328
epoch: 2830, train precision: 0.988733, train loss: 15.950418, valid precision: 0.840800, valid loss: 220.379401
epoch: 2831, train precision: 0.986844, train loss: 16.643944, valid precision: 0.840200, valid loss: 210.714484
epoch: 2832, train precision: 0.984244, train loss: 18.057859, valid precision: 0.829800, valid loss: 191.722185
epoch: 2833, train precision: 0.986600, train loss: 17.010080, valid precision: 0.840600, valid loss: 218.278335
epoch: 2834, train precision: 0.987889, train loss: 17.034542, valid precision: 0.837400, valid loss: 221.265962
epoch: 2835, train precision: 0.988667, train loss: 15.903626, valid precision: 0.837600, valid loss: 204.186144
epoch: 2836, train precision: 0.982667, train loss: 18.352553, valid precision: 0.828800, valid loss: 202.303869
epoch: 2837, train precision: 0.986933, train loss: 16.695517, valid precision: 0.837600, valid loss: 193.985127
epoch: 2838, train precision: 0.986156, train loss: 17.223877, valid precision: 0.835200, valid loss: 199.850619
epoch: 2839, train precision: 0.984311, train loss: 18.686661, valid precision: 0.830000, valid loss: 228.877304
epoch: 2840, train precision: 0.989133, train loss: 15.750955, valid precision: 0.836000, valid loss: 227.916508
epoch: 2841, train precision: 0.980867, train loss: 19.083812, valid precision: 0.828400, valid loss: 184.581593
epoch: 2842, train precision: 0.985556, train loss: 17.200930, valid precision: 0.834600, valid loss: 200.925923
epoch: 2843, train precision: 0.982178, train loss: 19.023771, valid precision: 0.832800, valid loss: 195.076422
epoch: 2844, train precision: 0.989467, train loss: 15.697368, valid precision: 0.834000, valid loss: 217.915282
epoch: 2845, train precision: 0.977378, train loss: 21.522665, valid precision: 0.833800, valid loss: 212.829562
epoch: 2846, train precision: 0.987333, train loss: 16.492124, valid precision: 0.835000, valid loss: 216.807238
epoch: 2847, train precision: 0.985222, train loss: 17.896699, valid precision: 0.837200, valid loss: 196.136808
epoch: 2848, train precision: 0.987267, train loss: 16.663006, valid precision: 0.839400, valid loss: 229.989582
epoch: 2849, train precision: 0.989111, train loss: 16.158733, valid precision: 0.842000, valid loss: 227.043315
epoch: 2850, train precision: 0.979489, train loss: 19.892046, valid precision: 0.826400, valid loss: 209.696028
epoch: 2851, train precision: 0.985600, train loss: 17.452072, valid precision: 0.839200, valid loss: 219.491662
epoch: 2852, train precision: 0.984822, train loss: 18.173150, valid precision: 0.844400, valid loss: 232.739800
epoch: 2853, train precision: 0.983933, train loss: 18.255327, valid precision: 0.837200, valid loss: 223.328645
epoch: 2854, train precision: 0.984644, train loss: 17.793083, valid precision: 0.833400, valid loss: 205.429596
epoch: 2855, train precision: 0.986400, train loss: 17.414611, valid precision: 0.829000, valid loss: 242.154682
epoch: 2856, train precision: 0.986289, train loss: 17.203487, valid precision: 0.836000, valid loss: 216.992668
epoch: 2857, train precision: 0.989244, train loss: 15.370173, valid precision: 0.835400, valid loss: 212.750179
epoch: 2858, train precision: 0.987889, train loss: 16.098407, valid precision: 0.834600, valid loss: 217.285032
epoch: 2859, train precision: 0.987178, train loss: 16.807853, valid precision: 0.835800, valid loss: 219.898557
epoch: 2860, train precision: 0.984578, train loss: 17.828039, valid precision: 0.830800, valid loss: 214.944047
epoch: 2861, train precision: 0.983600, train loss: 18.159021, valid precision: 0.830800, valid loss: 205.264734
epoch: 2862, train precision: 0.988600, train loss: 16.040816, valid precision: 0.839200, valid loss: 224.206440
epoch: 2863, train precision: 0.987622, train loss: 15.821998, valid precision: 0.829000, valid loss: 198.922652
epoch: 2864, train precision: 0.986000, train loss: 16.959782, valid precision: 0.840400, valid loss: 207.456797
epoch: 2865, train precision: 0.986356, train loss: 16.874205, valid precision: 0.832800, valid loss: 198.549980
epoch: 2866, train precision: 0.983467, train loss: 18.665348, valid precision: 0.834200, valid loss: 209.258121
epoch: 2867, train precision: 0.984200, train loss: 18.832561, valid precision: 0.833200, valid loss: 231.943535
epoch: 2868, train precision: 0.985667, train loss: 17.386334, valid precision: 0.833000, valid loss: 218.522745
epoch: 2869, train precision: 0.985578, train loss: 18.730405, valid precision: 0.844200, valid loss: 235.504780
epoch: 2870, train precision: 0.984556, train loss: 18.315314, valid precision: 0.835400, valid loss: 220.893363
epoch: 2871, train precision: 0.985800, train loss: 17.115431, valid precision: 0.840400, valid loss: 194.741485
epoch: 2872, train precision: 0.983867, train loss: 18.742542, valid precision: 0.840600, valid loss: 211.623664
epoch: 2873, train precision: 0.984889, train loss: 17.853063, valid precision: 0.843400, valid loss: 209.847467
epoch: 2874, train precision: 0.986244, train loss: 17.034365, valid precision: 0.830000, valid loss: 201.578343
epoch: 2875, train precision: 0.983311, train loss: 18.519921, valid precision: 0.830800, valid loss: 202.273652
epoch: 2876, train precision: 0.984156, train loss: 17.595674, valid precision: 0.836400, valid loss: 192.043931
epoch: 2877, train precision: 0.987200, train loss: 18.080387, valid precision: 0.843200, valid loss: 241.123064
epoch: 2878, train precision: 0.979089, train loss: 20.166828, valid precision: 0.829800, valid loss: 187.351918
epoch: 2879, train precision: 0.985667, train loss: 17.019217, valid precision: 0.834800, valid loss: 197.153215
epoch: 2880, train precision: 0.984556, train loss: 17.675878, valid precision: 0.836400, valid loss: 227.489458
epoch: 2881, train precision: 0.980778, train loss: 19.995433, valid precision: 0.828200, valid loss: 235.729865
epoch: 2882, train precision: 0.986667, train loss: 17.095513, valid precision: 0.837800, valid loss: 237.758576
epoch: 2883, train precision: 0.987133, train loss: 16.432986, valid precision: 0.836800, valid loss: 216.374206
epoch: 2884, train precision: 0.988356, train loss: 16.208068, valid precision: 0.839800, valid loss: 217.763316
epoch: 2885, train precision: 0.984978, train loss: 17.877294, valid precision: 0.834800, valid loss: 219.430329
epoch: 2886, train precision: 0.986600, train loss: 16.895757, valid precision: 0.836200, valid loss: 205.511715
epoch: 2887, train precision: 0.983022, train loss: 18.763292, valid precision: 0.831200, valid loss: 221.801722
epoch: 2888, train precision: 0.987378, train loss: 16.430389, valid precision: 0.835400, valid loss: 215.987528
epoch: 2889, train precision: 0.987911, train loss: 16.801506, valid precision: 0.838000, valid loss: 224.032136
epoch: 2890, train precision: 0.985778, train loss: 17.944227, valid precision: 0.837200, valid loss: 228.086524
epoch: 2891, train precision: 0.988444, train loss: 16.289101, valid precision: 0.838600, valid loss: 208.993014
epoch: 2892, train precision: 0.985644, train loss: 17.116454, valid precision: 0.834200, valid loss: 193.587434
epoch: 2893, train precision: 0.984244, train loss: 17.553047, valid precision: 0.832800, valid loss: 210.875572
epoch: 2894, train precision: 0.983756, train loss: 18.342344, valid precision: 0.838600, valid loss: 218.297472
epoch: 2895, train precision: 0.985511, train loss: 17.588965, valid precision: 0.838000, valid loss: 202.421837
epoch: 2896, train precision: 0.982089, train loss: 19.527133, valid precision: 0.838200, valid loss: 197.908078
epoch: 2897, train precision: 0.986778, train loss: 17.101653, valid precision: 0.837400, valid loss: 203.760056
epoch: 2898, train precision: 0.986489, train loss: 16.846407, valid precision: 0.837400, valid loss: 238.849393
epoch: 2899, train precision: 0.985756, train loss: 17.726343, valid precision: 0.834400, valid loss: 226.347487
epoch: 2900, train precision: 0.984089, train loss: 18.552261, valid precision: 0.833800, valid loss: 221.367815
epoch: 2901, train precision: 0.985356, train loss: 17.859638, valid precision: 0.835600, valid loss: 197.335594
epoch: 2902, train precision: 0.982444, train loss: 19.167278, valid precision: 0.837800, valid loss: 200.625279
epoch: 2903, train precision: 0.979267, train loss: 20.136981, valid precision: 0.831400, valid loss: 186.986072
epoch: 2904, train precision: 0.980756, train loss: 19.464532, valid precision: 0.834200, valid loss: 205.563824
epoch: 2905, train precision: 0.986200, train loss: 17.338572, valid precision: 0.837600, valid loss: 226.977686
epoch: 2906, train precision: 0.986489, train loss: 16.853372, valid precision: 0.842400, valid loss: 206.795075
epoch: 2907, train precision: 0.986756, train loss: 16.830762, valid precision: 0.835200, valid loss: 216.931292
epoch: 2908, train precision: 0.984000, train loss: 18.404479, valid precision: 0.832600, valid loss: 209.099207
epoch: 2909, train precision: 0.986067, train loss: 17.133503, valid precision: 0.833800, valid loss: 200.092883
epoch: 2910, train precision: 0.978089, train loss: 20.859894, valid precision: 0.827600, valid loss: 192.789667
epoch: 2911, train precision: 0.987822, train loss: 16.112898, valid precision: 0.840800, valid loss: 210.225262
epoch: 2912, train precision: 0.988089, train loss: 15.992603, valid precision: 0.839600, valid loss: 220.816895
epoch: 2913, train precision: 0.987067, train loss: 17.637591, valid precision: 0.834000, valid loss: 247.652522
epoch: 2914, train precision: 0.988578, train loss: 16.043680, valid precision: 0.837600, valid loss: 216.078432
epoch: 2915, train precision: 0.986378, train loss: 17.474555, valid precision: 0.839000, valid loss: 217.614522
epoch: 2916, train precision: 0.986822, train loss: 16.989269, valid precision: 0.835800, valid loss: 197.255424
epoch: 2917, train precision: 0.984267, train loss: 17.522834, valid precision: 0.834200, valid loss: 187.939534
epoch: 2918, train precision: 0.984578, train loss: 19.622550, valid precision: 0.833600, valid loss: 242.814568
epoch: 2919, train precision: 0.986644, train loss: 17.249176, valid precision: 0.833400, valid loss: 231.108918
epoch: 2920, train precision: 0.988156, train loss: 16.086370, valid precision: 0.839400, valid loss: 209.621481
epoch: 2921, train precision: 0.984244, train loss: 18.124833, valid precision: 0.836600, valid loss: 207.198252
epoch: 2922, train precision: 0.984378, train loss: 17.975104, valid precision: 0.836400, valid loss: 206.631276
epoch: 2923, train precision: 0.988756, train loss: 16.106558, valid precision: 0.836600, valid loss: 204.042265
epoch: 2924, train precision: 0.977089, train loss: 22.582080, valid precision: 0.829600, valid loss: 197.065084
epoch: 2925, train precision: 0.982222, train loss: 19.108731, valid precision: 0.828600, valid loss: 198.149724
epoch: 2926, train precision: 0.988733, train loss: 15.920185, valid precision: 0.836400, valid loss: 204.488542
epoch: 2927, train precision: 0.987956, train loss: 16.709914, valid precision: 0.837800, valid loss: 239.691895
epoch: 2928, train precision: 0.988378, train loss: 16.031991, valid precision: 0.832000, valid loss: 235.024889
epoch: 2929, train precision: 0.981889, train loss: 19.616282, valid precision: 0.829600, valid loss: 221.240123
epoch: 2930, train precision: 0.985489, train loss: 17.496154, valid precision: 0.838000, valid loss: 207.613989
epoch: 2931, train precision: 0.985467, train loss: 17.162534, valid precision: 0.830000, valid loss: 196.343481
epoch: 2932, train precision: 0.985778, train loss: 17.507658, valid precision: 0.837200, valid loss: 211.893524
epoch: 2933, train precision: 0.982244, train loss: 18.857602, valid precision: 0.830600, valid loss: 181.359481
epoch: 2934, train precision: 0.986778, train loss: 17.326901, valid precision: 0.838400, valid loss: 230.547498
epoch: 2935, train precision: 0.983844, train loss: 18.236311, valid precision: 0.834600, valid loss: 204.669409
epoch: 2936, train precision: 0.979556, train loss: 20.220526, valid precision: 0.831000, valid loss: 203.203074
epoch: 2937, train precision: 0.978756, train loss: 20.315894, valid precision: 0.833400, valid loss: 176.149514
epoch: 2938, train precision: 0.986022, train loss: 17.014229, valid precision: 0.837000, valid loss: 201.504222
epoch: 2939, train precision: 0.984289, train loss: 17.582594, valid precision: 0.831400, valid loss: 192.177637
epoch: 2940, train precision: 0.982978, train loss: 19.577352, valid precision: 0.834200, valid loss: 202.990023
epoch: 2941, train precision: 0.986333, train loss: 16.986572, valid precision: 0.836000, valid loss: 202.593876
epoch: 2942, train precision: 0.985689, train loss: 17.223076, valid precision: 0.836800, valid loss: 198.267328
epoch: 2943, train precision: 0.983200, train loss: 18.345221, valid precision: 0.832000, valid loss: 191.052892
epoch: 2944, train precision: 0.982956, train loss: 18.740251, valid precision: 0.837400, valid loss: 199.187143
epoch: 2945, train precision: 0.983444, train loss: 19.568294, valid precision: 0.836000, valid loss: 213.792672
epoch: 2946, train precision: 0.988333, train loss: 16.117370, valid precision: 0.837200, valid loss: 208.200185
epoch: 2947, train precision: 0.983911, train loss: 17.633752, valid precision: 0.826600, valid loss: 200.494231
epoch: 2948, train precision: 0.988400, train loss: 16.051973, valid precision: 0.839200, valid loss: 218.756287
epoch: 2949, train precision: 0.981867, train loss: 19.002273, valid precision: 0.829800, valid loss: 202.600555
epoch: 2950, train precision: 0.986533, train loss: 17.258607, valid precision: 0.841600, valid loss: 213.238685
epoch: 2951, train precision: 0.985356, train loss: 17.777825, valid precision: 0.834600, valid loss: 213.227542
epoch: 2952, train precision: 0.983022, train loss: 18.683837, valid precision: 0.831800, valid loss: 206.199541
epoch: 2953, train precision: 0.984511, train loss: 17.964612, valid precision: 0.837800, valid loss: 204.427464
epoch: 2954, train precision: 0.984711, train loss: 18.281786, valid precision: 0.839600, valid loss: 223.265527
epoch: 2955, train precision: 0.986511, train loss: 17.375243, valid precision: 0.838600, valid loss: 235.021837
epoch: 2956, train precision: 0.982822, train loss: 18.940710, valid precision: 0.831000, valid loss: 210.474426
epoch: 2957, train precision: 0.985933, train loss: 17.541233, valid precision: 0.838000, valid loss: 242.577541
epoch: 2958, train precision: 0.988378, train loss: 17.045720, valid precision: 0.838600, valid loss: 241.318663
epoch: 2959, train precision: 0.988511, train loss: 16.988448, valid precision: 0.838000, valid loss: 222.926421
epoch: 2960, train precision: 0.984400, train loss: 17.553291, valid precision: 0.831000, valid loss: 194.761621
epoch: 2961, train precision: 0.986667, train loss: 17.455923, valid precision: 0.835800, valid loss: 242.724957
epoch: 2962, train precision: 0.984689, train loss: 17.682050, valid precision: 0.834800, valid loss: 202.432219
epoch: 2963, train precision: 0.985889, train loss: 16.936463, valid precision: 0.827600, valid loss: 200.891495
epoch: 2964, train precision: 0.983489, train loss: 18.286153, valid precision: 0.833800, valid loss: 208.897857
epoch: 2965, train precision: 0.986022, train loss: 17.718640, valid precision: 0.835200, valid loss: 201.264609
epoch: 2966, train precision: 0.985089, train loss: 17.614593, valid precision: 0.830200, valid loss: 193.321306
epoch: 2967, train precision: 0.984733, train loss: 17.598058, valid precision: 0.836200, valid loss: 185.889396
epoch: 2968, train precision: 0.983489, train loss: 18.218858, valid precision: 0.826800, valid loss: 199.084403
epoch: 2969, train precision: 0.985444, train loss: 17.560115, valid precision: 0.830600, valid loss: 223.451444
epoch: 2970, train precision: 0.981956, train loss: 19.543567, valid precision: 0.835400, valid loss: 221.958953
epoch: 2971, train precision: 0.983911, train loss: 18.471075, valid precision: 0.829200, valid loss: 214.295025
epoch: 2972, train precision: 0.979956, train loss: 20.235792, valid precision: 0.827200, valid loss: 195.036771
epoch: 2973, train precision: 0.980178, train loss: 19.488335, valid precision: 0.826000, valid loss: 193.845079
epoch: 2974, train precision: 0.985689, train loss: 17.624662, valid precision: 0.831200, valid loss: 212.823201
epoch: 2975, train precision: 0.986911, train loss: 16.513309, valid precision: 0.828000, valid loss: 199.195634
epoch: 2976, train precision: 0.988378, train loss: 16.048672, valid precision: 0.837600, valid loss: 194.020093
epoch: 2977, train precision: 0.983000, train loss: 18.513646, valid precision: 0.829600, valid loss: 206.251262
epoch: 2978, train precision: 0.983200, train loss: 18.444191, valid precision: 0.831400, valid loss: 190.650301
epoch: 2979, train precision: 0.987844, train loss: 16.604198, valid precision: 0.835600, valid loss: 206.151890
epoch: 2980, train precision: 0.983622, train loss: 18.220511, valid precision: 0.834200, valid loss: 200.114173
epoch: 2981, train precision: 0.982022, train loss: 19.653563, valid precision: 0.832200, valid loss: 216.489555
epoch: 2982, train precision: 0.983778, train loss: 18.459436, valid precision: 0.832200, valid loss: 209.384522
epoch: 2983, train precision: 0.987867, train loss: 16.496807, valid precision: 0.840800, valid loss: 208.405723
epoch: 2984, train precision: 0.987111, train loss: 17.042505, valid precision: 0.838000, valid loss: 208.267700
epoch: 2985, train precision: 0.984933, train loss: 17.669474, valid precision: 0.836200, valid loss: 210.888193
epoch: 2986, train precision: 0.985289, train loss: 17.391768, valid precision: 0.837400, valid loss: 207.656045
epoch: 2987, train precision: 0.984333, train loss: 18.961544, valid precision: 0.832800, valid loss: 216.284611
epoch: 2988, train precision: 0.984289, train loss: 18.599765, valid precision: 0.837400, valid loss: 201.676788
epoch: 2989, train precision: 0.980333, train loss: 21.223643, valid precision: 0.835200, valid loss: 234.264286
epoch: 2990, train precision: 0.983044, train loss: 18.912882, valid precision: 0.830600, valid loss: 225.981899
epoch: 2991, train precision: 0.979422, train loss: 20.816880, valid precision: 0.823800, valid loss: 185.330202
epoch: 2992, train precision: 0.980489, train loss: 20.044858, valid precision: 0.828600, valid loss: 213.279123
epoch: 2993, train precision: 0.985756, train loss: 17.546850, valid precision: 0.838200, valid loss: 196.545142
epoch: 2994, train precision: 0.984089, train loss: 19.102593, valid precision: 0.830400, valid loss: 240.862464
epoch: 2995, train precision: 0.984467, train loss: 17.801672, valid precision: 0.834600, valid loss: 187.849672
epoch: 2996, train precision: 0.983089, train loss: 18.565935, valid precision: 0.831400, valid loss: 198.258019
epoch: 2997, train precision: 0.985556, train loss: 17.796769, valid precision: 0.842000, valid loss: 242.112616
epoch: 2998, train precision: 0.987467, train loss: 16.670367, valid precision: 0.838800, valid loss: 200.596736
epoch: 2999, train precision: 0.985000, train loss: 18.977180, valid precision: 0.832200, valid loss: 246.318705
epoch: 3000, train precision: 0.986422, train loss: 16.912987, valid precision: 0.830200, valid loss: 208.493890
epoch: 3001, train precision: 0.987333, train loss: 16.778212, valid precision: 0.836800, valid loss: 223.422738
epoch: 3002, train precision: 0.986622, train loss: 17.226133, valid precision: 0.838200, valid loss: 213.328876
epoch: 3003, train precision: 0.985533, train loss: 17.378766, valid precision: 0.834800, valid loss: 193.159862
epoch: 3004, train precision: 0.984111, train loss: 17.778562, valid precision: 0.837000, valid loss: 196.995309
epoch: 3005, train precision: 0.982622, train loss: 18.871123, valid precision: 0.833600, valid loss: 212.462270
epoch: 3006, train precision: 0.984644, train loss: 17.932482, valid precision: 0.830400, valid loss: 203.527186
epoch: 3007, train precision: 0.983156, train loss: 19.047210, valid precision: 0.836400, valid loss: 216.810052
epoch: 3008, train precision: 0.983489, train loss: 18.540380, valid precision: 0.831400, valid loss: 189.359190
epoch: 3009, train precision: 0.973356, train loss: 22.547723, valid precision: 0.824400, valid loss: 178.274804
epoch: 3010, train precision: 0.986489, train loss: 17.291767, valid precision: 0.835800, valid loss: 226.298634
epoch: 3011, train precision: 0.982444, train loss: 18.922831, valid precision: 0.837800, valid loss: 224.327249
epoch: 3012, train precision: 0.984333, train loss: 18.145058, valid precision: 0.834000, valid loss: 214.569706
epoch: 3013, train precision: 0.984133, train loss: 17.817661, valid precision: 0.831200, valid loss: 198.735851
epoch: 3014, train precision: 0.989267, train loss: 15.512472, valid precision: 0.840600, valid loss: 217.484122
epoch: 3015, train precision: 0.984400, train loss: 18.708463, valid precision: 0.835800, valid loss: 218.599611
epoch: 3016, train precision: 0.987133, train loss: 16.708909, valid precision: 0.835800, valid loss: 216.210427
epoch: 3017, train precision: 0.986711, train loss: 16.975268, valid precision: 0.839400, valid loss: 214.904082
epoch: 3018, train precision: 0.982867, train loss: 18.632804, valid precision: 0.833000, valid loss: 178.648394
epoch: 3019, train precision: 0.986289, train loss: 17.303963, valid precision: 0.833400, valid loss: 202.013518
epoch: 3020, train precision: 0.984756, train loss: 17.432919, valid precision: 0.841600, valid loss: 176.850525
epoch: 3021, train precision: 0.982600, train loss: 19.037774, valid precision: 0.831800, valid loss: 206.388232
epoch: 3022, train precision: 0.986356, train loss: 16.987919, valid precision: 0.833400, valid loss: 196.839414
epoch: 3023, train precision: 0.982800, train loss: 19.613870, valid precision: 0.834800, valid loss: 208.793181
epoch: 3024, train precision: 0.987000, train loss: 16.630447, valid precision: 0.835400, valid loss: 202.026156
epoch: 3025, train precision: 0.985378, train loss: 18.123005, valid precision: 0.837000, valid loss: 212.822888
epoch: 3026, train precision: 0.983644, train loss: 19.141979, valid precision: 0.839600, valid loss: 203.760352
epoch: 3027, train precision: 0.983467, train loss: 18.319389, valid precision: 0.837000, valid loss: 182.507719
epoch: 3028, train precision: 0.987933, train loss: 16.387705, valid precision: 0.836800, valid loss: 210.265561
epoch: 3029, train precision: 0.981600, train loss: 18.936658, valid precision: 0.829600, valid loss: 186.916497
epoch: 3030, train precision: 0.985956, train loss: 17.537341, valid precision: 0.839800, valid loss: 206.134877
epoch: 3031, train precision: 0.984467, train loss: 18.380227, valid precision: 0.837400, valid loss: 201.581011
epoch: 3032, train precision: 0.984111, train loss: 18.297507, valid precision: 0.836600, valid loss: 204.276065
epoch: 3033, train precision: 0.987356, train loss: 16.368921, valid precision: 0.841200, valid loss: 221.105283
epoch: 3034, train precision: 0.982333, train loss: 19.667782, valid precision: 0.835600, valid loss: 202.891966
epoch: 3035, train precision: 0.986511, train loss: 16.993176, valid precision: 0.832800, valid loss: 213.803362
epoch: 3036, train precision: 0.984889, train loss: 17.991728, valid precision: 0.830400, valid loss: 221.887200
epoch: 3037, train precision: 0.981311, train loss: 19.445904, valid precision: 0.831600, valid loss: 185.544167
epoch: 3038, train precision: 0.984022, train loss: 18.246912, valid precision: 0.831800, valid loss: 202.426189
epoch: 3039, train precision: 0.984844, train loss: 17.503163, valid precision: 0.831400, valid loss: 194.782483
epoch: 3040, train precision: 0.984267, train loss: 17.848100, valid precision: 0.828200, valid loss: 179.452370
epoch: 3041, train precision: 0.988156, train loss: 16.278713, valid precision: 0.838800, valid loss: 215.368763
epoch: 3042, train precision: 0.982844, train loss: 18.497647, valid precision: 0.834200, valid loss: 202.006565
epoch: 3043, train precision: 0.984200, train loss: 18.137325, valid precision: 0.835200, valid loss: 196.979418
epoch: 3044, train precision: 0.987289, train loss: 16.532027, valid precision: 0.833800, valid loss: 223.578445
epoch: 3045, train precision: 0.986756, train loss: 17.187504, valid precision: 0.838600, valid loss: 224.239679
epoch: 3046, train precision: 0.986956, train loss: 16.662102, valid precision: 0.835800, valid loss: 215.961547
epoch: 3047, train precision: 0.984556, train loss: 18.292759, valid precision: 0.831400, valid loss: 212.173956
epoch: 3048, train precision: 0.985178, train loss: 17.627196, valid precision: 0.835200, valid loss: 195.114279
epoch: 3049, train precision: 0.986800, train loss: 16.494427, valid precision: 0.837400, valid loss: 189.663204
epoch: 3050, train precision: 0.987022, train loss: 17.028401, valid precision: 0.836800, valid loss: 213.053022
epoch: 3051, train precision: 0.985889, train loss: 17.148338, valid precision: 0.836600, valid loss: 211.758165
epoch: 3052, train precision: 0.980267, train loss: 19.982737, valid precision: 0.834800, valid loss: 213.618013
epoch: 3053, train precision: 0.983289, train loss: 18.501420, valid precision: 0.829400, valid loss: 188.466543
epoch: 3054, train precision: 0.982756, train loss: 19.162577, valid precision: 0.834200, valid loss: 221.139518
epoch: 3055, train precision: 0.986778, train loss: 16.895526, valid precision: 0.836200, valid loss: 224.573918
epoch: 3056, train precision: 0.979467, train loss: 21.053543, valid precision: 0.830400, valid loss: 216.737258
epoch: 3057, train precision: 0.984844, train loss: 18.618579, valid precision: 0.835800, valid loss: 237.254324
epoch: 3058, train precision: 0.982000, train loss: 19.244124, valid precision: 0.835200, valid loss: 190.067712
epoch: 3059, train precision: 0.983800, train loss: 17.911724, valid precision: 0.832400, valid loss: 214.826809
epoch: 3060, train precision: 0.981956, train loss: 19.466093, valid precision: 0.828200, valid loss: 227.927568
epoch: 3061, train precision: 0.978844, train loss: 21.047228, valid precision: 0.830400, valid loss: 209.548877
epoch: 3062, train precision: 0.985511, train loss: 18.010546, valid precision: 0.839200, valid loss: 223.938910
epoch: 3063, train precision: 0.985200, train loss: 17.664331, valid precision: 0.838000, valid loss: 206.955201
epoch: 3064, train precision: 0.981822, train loss: 18.842668, valid precision: 0.833400, valid loss: 189.970526
epoch: 3065, train precision: 0.987489, train loss: 16.693381, valid precision: 0.837800, valid loss: 222.723964
epoch: 3066, train precision: 0.984156, train loss: 18.188911, valid precision: 0.827400, valid loss: 214.592607
epoch: 3067, train precision: 0.981244, train loss: 18.826329, valid precision: 0.830200, valid loss: 216.502752
epoch: 3068, train precision: 0.985267, train loss: 17.530676, valid precision: 0.833400, valid loss: 204.655981
epoch: 3069, train precision: 0.985889, train loss: 17.366856, valid precision: 0.837800, valid loss: 210.139492
epoch: 3070, train precision: 0.985933, train loss: 16.871265, valid precision: 0.836000, valid loss: 212.658420
epoch: 3071, train precision: 0.985289, train loss: 17.699496, valid precision: 0.833800, valid loss: 198.002041
epoch: 3072, train precision: 0.976844, train loss: 21.271327, valid precision: 0.829000, valid loss: 185.885591
epoch: 3073, train precision: 0.983956, train loss: 18.860523, valid precision: 0.830000, valid loss: 227.367679
epoch: 3074, train precision: 0.987222, train loss: 16.770006, valid precision: 0.836200, valid loss: 237.257078
epoch: 3075, train precision: 0.984244, train loss: 18.477063, valid precision: 0.835800, valid loss: 225.365487
epoch: 3076, train precision: 0.978000, train loss: 20.720596, valid precision: 0.833800, valid loss: 196.192209
epoch: 3077, train precision: 0.985533, train loss: 17.514630, valid precision: 0.833800, valid loss: 226.223120
epoch: 3078, train precision: 0.984333, train loss: 18.489544, valid precision: 0.832600, valid loss: 215.137328
epoch: 3079, train precision: 0.983489, train loss: 18.231536, valid precision: 0.825000, valid loss: 206.694875
epoch: 3080, train precision: 0.978711, train loss: 20.162838, valid precision: 0.825400, valid loss: 218.272000
epoch: 3081, train precision: 0.986467, train loss: 16.958634, valid precision: 0.835400, valid loss: 235.753906
epoch: 3082, train precision: 0.986489, train loss: 17.124796, valid precision: 0.830000, valid loss: 227.936796
epoch: 3083, train precision: 0.984244, train loss: 18.609559, valid precision: 0.829400, valid loss: 238.150689
epoch: 3084, train precision: 0.987733, train loss: 16.471097, valid precision: 0.833400, valid loss: 227.750881
epoch: 3085, train precision: 0.984756, train loss: 18.004094, valid precision: 0.829600, valid loss: 215.457976
epoch: 3086, train precision: 0.982222, train loss: 19.039875, valid precision: 0.833600, valid loss: 193.150552
epoch: 3087, train precision: 0.986822, train loss: 17.203392, valid precision: 0.838000, valid loss: 223.814343
epoch: 3088, train precision: 0.983689, train loss: 18.026733, valid precision: 0.830400, valid loss: 202.014630
epoch: 3089, train precision: 0.985689, train loss: 17.222800, valid precision: 0.832200, valid loss: 212.882076
epoch: 3090, train precision: 0.985578, train loss: 17.770279, valid precision: 0.834800, valid loss: 241.157113
epoch: 3091, train precision: 0.982889, train loss: 19.854224, valid precision: 0.830600, valid loss: 227.476081
epoch: 3092, train precision: 0.982267, train loss: 18.668465, valid precision: 0.831200, valid loss: 204.413709
epoch: 3093, train precision: 0.985000, train loss: 18.156660, valid precision: 0.831000, valid loss: 233.115830
epoch: 3094, train precision: 0.983067, train loss: 18.443205, valid precision: 0.827800, valid loss: 217.220685
epoch: 3095, train precision: 0.985267, train loss: 18.230445, valid precision: 0.834200, valid loss: 238.385421
epoch: 3096, train precision: 0.986889, train loss: 16.880099, valid precision: 0.828400, valid loss: 222.399424
epoch: 3097, train precision: 0.987422, train loss: 17.223109, valid precision: 0.828600, valid loss: 237.249408
epoch: 3098, train precision: 0.987956, train loss: 16.264716, valid precision: 0.828200, valid loss: 208.356994
epoch: 3099, train precision: 0.980933, train loss: 20.224797, valid precision: 0.827600, valid loss: 238.643186
epoch: 3100, train precision: 0.984489, train loss: 18.048570, valid precision: 0.828800, valid loss: 199.492470
epoch: 3101, train precision: 0.983311, train loss: 18.722132, valid precision: 0.834600, valid loss: 189.508602
epoch: 3102, train precision: 0.982956, train loss: 18.462484, valid precision: 0.840000, valid loss: 194.732502
epoch: 3103, train precision: 0.986844, train loss: 17.131224, valid precision: 0.838400, valid loss: 202.653557
epoch: 3104, train precision: 0.976911, train loss: 22.411648, valid precision: 0.832800, valid loss: 219.908093
epoch: 3105, train precision: 0.981756, train loss: 21.354948, valid precision: 0.829400, valid loss: 246.836424
epoch: 3106, train precision: 0.984244, train loss: 17.539833, valid precision: 0.836800, valid loss: 197.729225
epoch: 3107, train precision: 0.986622, train loss: 17.477304, valid precision: 0.835200, valid loss: 210.628025
epoch: 3108, train precision: 0.982156, train loss: 19.316366, valid precision: 0.825400, valid loss: 239.222843
epoch: 3109, train precision: 0.987156, train loss: 17.390298, valid precision: 0.834000, valid loss: 241.035658
epoch: 3110, train precision: 0.985156, train loss: 17.860690, valid precision: 0.833600, valid loss: 215.855120
epoch: 3111, train precision: 0.983467, train loss: 18.776968, valid precision: 0.832400, valid loss: 219.508298
epoch: 3112, train precision: 0.987156, train loss: 17.750000, valid precision: 0.838600, valid loss: 242.833504
epoch: 3113, train precision: 0.984622, train loss: 18.257338, valid precision: 0.831400, valid loss: 219.914395
epoch: 3114, train precision: 0.978911, train loss: 21.398700, valid precision: 0.831000, valid loss: 202.527318
epoch: 3115, train precision: 0.987933, train loss: 16.130523, valid precision: 0.835200, valid loss: 206.723838
epoch: 3116, train precision: 0.984022, train loss: 18.645876, valid precision: 0.838400, valid loss: 208.854585
epoch: 3117, train precision: 0.987244, train loss: 16.638431, valid precision: 0.835600, valid loss: 215.130684
epoch: 3118, train precision: 0.979044, train loss: 20.066214, valid precision: 0.828800, valid loss: 192.223304
epoch: 3119, train precision: 0.987267, train loss: 16.728969, valid precision: 0.834800, valid loss: 217.906941
epoch: 3120, train precision: 0.984667, train loss: 18.056872, valid precision: 0.838400, valid loss: 209.543232
epoch: 3121, train precision: 0.984689, train loss: 18.325885, valid precision: 0.830600, valid loss: 227.017063
epoch: 3122, train precision: 0.982867, train loss: 19.042285, valid precision: 0.831800, valid loss: 222.390862
epoch: 3123, train precision: 0.979333, train loss: 20.695693, valid precision: 0.829200, valid loss: 200.086583
epoch: 3124, train precision: 0.980044, train loss: 20.618746, valid precision: 0.826800, valid loss: 213.200921
epoch: 3125, train precision: 0.983733, train loss: 18.990043, valid precision: 0.834400, valid loss: 209.570509
epoch: 3126, train precision: 0.985378, train loss: 18.030528, valid precision: 0.833000, valid loss: 231.547330
epoch: 3127, train precision: 0.984556, train loss: 18.081014, valid precision: 0.835600, valid loss: 215.160425
epoch: 3128, train precision: 0.981844, train loss: 19.502749, valid precision: 0.837200, valid loss: 205.740910
epoch: 3129, train precision: 0.985867, train loss: 17.330978, valid precision: 0.834400, valid loss: 200.821545
epoch: 3130, train precision: 0.984644, train loss: 18.860850, valid precision: 0.836800, valid loss: 221.230436
epoch: 3131, train precision: 0.983533, train loss: 18.677690, valid precision: 0.838800, valid loss: 224.351441
epoch: 3132, train precision: 0.986600, train loss: 16.663381, valid precision: 0.838800, valid loss: 185.669027
epoch: 3133, train precision: 0.986444, train loss: 17.292647, valid precision: 0.838000, valid loss: 213.518593
epoch: 3134, train precision: 0.984356, train loss: 18.201758, valid precision: 0.835000, valid loss: 191.986253
epoch: 3135, train precision: 0.974289, train loss: 22.779273, valid precision: 0.827200, valid loss: 182.843450
epoch: 3136, train precision: 0.984022, train loss: 18.808088, valid precision: 0.840600, valid loss: 228.234147
epoch: 3137, train precision: 0.983444, train loss: 19.086296, valid precision: 0.836600, valid loss: 195.855185
epoch: 3138, train precision: 0.978000, train loss: 20.942020, valid precision: 0.829800, valid loss: 193.271658
epoch: 3139, train precision: 0.985378, train loss: 17.993185, valid precision: 0.834800, valid loss: 209.056030
epoch: 3140, train precision: 0.983022, train loss: 18.140097, valid precision: 0.835200, valid loss: 191.476957
epoch: 3141, train precision: 0.986222, train loss: 17.029847, valid precision: 0.838800, valid loss: 217.720827
epoch: 3142, train precision: 0.982289, train loss: 19.404015, valid precision: 0.836800, valid loss: 208.537131
epoch: 3143, train precision: 0.987022, train loss: 17.457246, valid precision: 0.838000, valid loss: 243.489540
epoch: 3144, train precision: 0.988933, train loss: 16.148728, valid precision: 0.838600, valid loss: 206.771322
epoch: 3145, train precision: 0.987578, train loss: 16.731370, valid precision: 0.832400, valid loss: 219.267599
epoch: 3146, train precision: 0.986356, train loss: 17.005100, valid precision: 0.835600, valid loss: 205.137676
epoch: 3147, train precision: 0.985556, train loss: 18.244113, valid precision: 0.840200, valid loss: 222.336033
epoch: 3148, train precision: 0.983244, train loss: 18.619611, valid precision: 0.833200, valid loss: 193.067800
epoch: 3149, train precision: 0.981978, train loss: 18.737899, valid precision: 0.833400, valid loss: 190.988360
epoch: 3150, train precision: 0.982244, train loss: 19.947792, valid precision: 0.832800, valid loss: 204.884871
epoch: 3151, train precision: 0.981422, train loss: 19.446626, valid precision: 0.834600, valid loss: 194.133486
epoch: 3152, train precision: 0.987022, train loss: 17.457687, valid precision: 0.836600, valid loss: 233.750229
epoch: 3153, train precision: 0.985289, train loss: 17.661083, valid precision: 0.831000, valid loss: 218.072599
epoch: 3154, train precision: 0.983222, train loss: 18.522041, valid precision: 0.835200, valid loss: 206.085239
epoch: 3155, train precision: 0.984511, train loss: 17.506584, valid precision: 0.832800, valid loss: 207.950707
epoch: 3156, train precision: 0.988467, train loss: 15.677987, valid precision: 0.837600, valid loss: 199.109406
epoch: 3157, train precision: 0.983400, train loss: 19.218891, valid precision: 0.834200, valid loss: 228.490190
epoch: 3158, train precision: 0.984756, train loss: 18.078440, valid precision: 0.835600, valid loss: 213.696360
epoch: 3159, train precision: 0.984756, train loss: 17.854823, valid precision: 0.835800, valid loss: 206.369072
epoch: 3160, train precision: 0.986422, train loss: 16.885778, valid precision: 0.836400, valid loss: 200.871841
epoch: 3161, train precision: 0.988956, train loss: 16.295046, valid precision: 0.838600, valid loss: 236.719245
epoch: 3162, train precision: 0.984822, train loss: 18.479952, valid precision: 0.832400, valid loss: 217.302932
epoch: 3163, train precision: 0.984444, train loss: 18.999930, valid precision: 0.827000, valid loss: 244.461698
epoch: 3164, train precision: 0.986644, train loss: 16.980092, valid precision: 0.836000, valid loss: 231.164929
epoch: 3165, train precision: 0.983222, train loss: 19.040713, valid precision: 0.842400, valid loss: 228.636682
epoch: 3166, train precision: 0.984556, train loss: 18.151497, valid precision: 0.836200, valid loss: 213.782862
epoch: 3167, train precision: 0.987178, train loss: 16.878725, valid precision: 0.834800, valid loss: 207.335628
epoch: 3168, train precision: 0.985867, train loss: 17.578662, valid precision: 0.834000, valid loss: 226.549666
epoch: 3169, train precision: 0.986533, train loss: 16.906118, valid precision: 0.836400, valid loss: 206.069712
epoch: 3170, train precision: 0.987244, train loss: 16.948982, valid precision: 0.838200, valid loss: 222.909146
epoch: 3171, train precision: 0.987467, train loss: 17.134082, valid precision: 0.836200, valid loss: 240.190472
epoch: 3172, train precision: 0.985067, train loss: 17.412830, valid precision: 0.832400, valid loss: 192.545078
epoch: 3173, train precision: 0.981711, train loss: 19.642323, valid precision: 0.826800, valid loss: 202.980353
epoch: 3174, train precision: 0.978244, train loss: 21.004151, valid precision: 0.826600, valid loss: 195.033293
epoch: 3175, train precision: 0.984667, train loss: 17.746606, valid precision: 0.836000, valid loss: 207.564267
epoch: 3176, train precision: 0.985822, train loss: 17.209510, valid precision: 0.834800, valid loss: 190.720398
epoch: 3177, train precision: 0.986111, train loss: 17.439752, valid precision: 0.832600, valid loss: 215.245665
epoch: 3178, train precision: 0.982800, train loss: 19.562520, valid precision: 0.837200, valid loss: 233.744807
epoch: 3179, train precision: 0.986533, train loss: 16.843106, valid precision: 0.839800, valid loss: 202.856385
epoch: 3180, train precision: 0.984711, train loss: 18.173351, valid precision: 0.833000, valid loss: 215.553864
epoch: 3181, train precision: 0.983000, train loss: 18.500604, valid precision: 0.832000, valid loss: 190.835140
epoch: 3182, train precision: 0.988289, train loss: 16.013788, valid precision: 0.839800, valid loss: 208.198520
epoch: 3183, train precision: 0.986089, train loss: 17.621365, valid precision: 0.839000, valid loss: 222.244554
epoch: 3184, train precision: 0.985933, train loss: 17.337046, valid precision: 0.829800, valid loss: 228.429533
epoch: 3185, train precision: 0.985622, train loss: 17.296072, valid precision: 0.838800, valid loss: 191.075833
epoch: 3186, train precision: 0.984489, train loss: 17.507057, valid precision: 0.834200, valid loss: 192.863156
epoch: 3187, train precision: 0.986822, train loss: 17.560354, valid precision: 0.838600, valid loss: 213.635756
epoch: 3188, train precision: 0.980733, train loss: 19.890216, valid precision: 0.840200, valid loss: 199.266300
epoch: 3189, train precision: 0.977911, train loss: 20.835119, valid precision: 0.832200, valid loss: 180.871286
epoch: 3190, train precision: 0.985400, train loss: 17.813956, valid precision: 0.841200, valid loss: 225.590607
epoch: 3191, train precision: 0.985289, train loss: 18.299081, valid precision: 0.838200, valid loss: 224.484414
epoch: 3192, train precision: 0.984756, train loss: 18.009202, valid precision: 0.840400, valid loss: 181.406432
epoch: 3193, train precision: 0.981867, train loss: 19.814178, valid precision: 0.834600, valid loss: 220.644515
epoch: 3194, train precision: 0.982689, train loss: 18.813315, valid precision: 0.841600, valid loss: 192.027150
epoch: 3195, train precision: 0.982822, train loss: 19.803437, valid precision: 0.840600, valid loss: 217.306956
epoch: 3196, train precision: 0.983756, train loss: 17.675038, valid precision: 0.836600, valid loss: 180.587826
epoch: 3197, train precision: 0.981533, train loss: 19.483820, valid precision: 0.837800, valid loss: 206.609259
epoch: 3198, train precision: 0.984311, train loss: 18.362812, valid precision: 0.836800, valid loss: 214.174728
epoch: 3199, train precision: 0.985978, train loss: 17.535486, valid precision: 0.836600, valid loss: 225.504246
epoch: 3200, train precision: 0.981356, train loss: 20.090414, valid precision: 0.836000, valid loss: 204.202177
epoch: 3201, train precision: 0.981644, train loss: 19.352371, valid precision: 0.837600, valid loss: 220.292278
epoch: 3202, train precision: 0.984822, train loss: 18.612766, valid precision: 0.833400, valid loss: 217.712208
epoch: 3203, train precision: 0.985689, train loss: 17.202830, valid precision: 0.833400, valid loss: 218.619156
epoch: 3204, train precision: 0.983978, train loss: 18.706333, valid precision: 0.832200, valid loss: 241.150998
epoch: 3205, train precision: 0.985578, train loss: 19.180595, valid precision: 0.838800, valid loss: 273.187503
epoch: 3206, train precision: 0.986644, train loss: 17.304581, valid precision: 0.837800, valid loss: 234.703052
epoch: 3207, train precision: 0.982378, train loss: 19.570347, valid precision: 0.837400, valid loss: 230.327962
epoch: 3208, train precision: 0.986578, train loss: 17.380023, valid precision: 0.839400, valid loss: 233.748091
epoch: 3209, train precision: 0.984822, train loss: 17.590997, valid precision: 0.835400, valid loss: 192.985669
epoch: 3210, train precision: 0.986911, train loss: 18.347244, valid precision: 0.843400, valid loss: 254.649619
epoch: 3211, train precision: 0.988000, train loss: 16.385526, valid precision: 0.836600, valid loss: 204.050015
epoch: 3212, train precision: 0.989111, train loss: 15.993615, valid precision: 0.834200, valid loss: 223.227645
epoch: 3213, train precision: 0.983178, train loss: 18.597200, valid precision: 0.836400, valid loss: 202.525671
epoch: 3214, train precision: 0.981822, train loss: 19.854228, valid precision: 0.833200, valid loss: 221.153490
epoch: 3215, train precision: 0.985711, train loss: 17.245475, valid precision: 0.837400, valid loss: 222.782114
epoch: 3216, train precision: 0.983111, train loss: 18.766687, valid precision: 0.835400, valid loss: 218.888206
epoch: 3217, train precision: 0.985000, train loss: 17.712758, valid precision: 0.837200, valid loss: 207.445163
epoch: 3218, train precision: 0.983444, train loss: 19.870877, valid precision: 0.828400, valid loss: 232.754586
epoch: 3219, train precision: 0.984556, train loss: 17.830790, valid precision: 0.830600, valid loss: 224.737426
epoch: 3220, train precision: 0.986333, train loss: 17.418716, valid precision: 0.831800, valid loss: 209.367734
epoch: 3221, train precision: 0.987089, train loss: 17.301480, valid precision: 0.837000, valid loss: 182.554709
epoch: 3222, train precision: 0.987956, train loss: 16.445477, valid precision: 0.837800, valid loss: 215.702651
epoch: 3223, train precision: 0.986244, train loss: 17.408880, valid precision: 0.834800, valid loss: 225.847117
epoch: 3224, train precision: 0.984867, train loss: 18.029464, valid precision: 0.837400, valid loss: 196.864092
epoch: 3225, train precision: 0.986844, train loss: 17.412100, valid precision: 0.834800, valid loss: 220.614871
epoch: 3226, train precision: 0.985689, train loss: 17.716812, valid precision: 0.834800, valid loss: 219.628593
epoch: 3227, train precision: 0.984489, train loss: 18.089935, valid precision: 0.835000, valid loss: 226.650369
epoch: 3228, train precision: 0.984844, train loss: 18.053117, valid precision: 0.837400, valid loss: 223.936323
epoch: 3229, train precision: 0.984622, train loss: 18.185072, valid precision: 0.838400, valid loss: 196.737727
epoch: 3230, train precision: 0.982800, train loss: 18.424667, valid precision: 0.835800, valid loss: 185.788787
epoch: 3231, train precision: 0.985511, train loss: 17.117446, valid precision: 0.838600, valid loss: 197.601065
epoch: 3232, train precision: 0.983089, train loss: 18.161519, valid precision: 0.837000, valid loss: 201.570651
epoch: 3233, train precision: 0.984178, train loss: 17.710405, valid precision: 0.832400, valid loss: 193.663930
epoch: 3234, train precision: 0.977578, train loss: 21.094758, valid precision: 0.825600, valid loss: 181.447056
epoch: 3235, train precision: 0.983844, train loss: 18.450263, valid precision: 0.834400, valid loss: 210.090323
epoch: 3236, train precision: 0.981000, train loss: 19.461597, valid precision: 0.831800, valid loss: 186.529104
epoch: 3237, train precision: 0.980556, train loss: 19.538292, valid precision: 0.833000, valid loss: 193.703686
epoch: 3238, train precision: 0.981511, train loss: 19.703049, valid precision: 0.831600, valid loss: 207.897689
epoch: 3239, train precision: 0.984756, train loss: 18.020863, valid precision: 0.832800, valid loss: 202.769390
epoch: 3240, train precision: 0.984022, train loss: 19.590391, valid precision: 0.829800, valid loss: 265.969360
epoch: 3241, train precision: 0.986844, train loss: 17.981742, valid precision: 0.837600, valid loss: 246.010133
epoch: 3242, train precision: 0.987178, train loss: 16.989880, valid precision: 0.835400, valid loss: 237.514737
epoch: 3243, train precision: 0.984622, train loss: 17.913174, valid precision: 0.834200, valid loss: 216.024713
epoch: 3244, train precision: 0.981867, train loss: 21.054202, valid precision: 0.835600, valid loss: 226.492631
epoch: 3245, train precision: 0.979444, train loss: 20.243079, valid precision: 0.828400, valid loss: 213.724656
epoch: 3246, train precision: 0.988044, train loss: 16.781313, valid precision: 0.840400, valid loss: 219.008127
epoch: 3247, train precision: 0.982733, train loss: 18.890256, valid precision: 0.840600, valid loss: 198.337779
epoch: 3248, train precision: 0.984200, train loss: 18.222477, valid precision: 0.835600, valid loss: 202.612202
epoch: 3249, train precision: 0.984667, train loss: 18.004112, valid precision: 0.840600, valid loss: 208.467246
epoch: 3250, train precision: 0.982467, train loss: 18.750241, valid precision: 0.833400, valid loss: 190.610992
epoch: 3251, train precision: 0.984556, train loss: 17.479644, valid precision: 0.830000, valid loss: 208.530763
epoch: 3252, train precision: 0.986378, train loss: 17.133711, valid precision: 0.831800, valid loss: 227.626607
epoch: 3253, train precision: 0.985622, train loss: 17.573724, valid precision: 0.832000, valid loss: 220.010613
epoch: 3254, train precision: 0.986400, train loss: 17.688400, valid precision: 0.834600, valid loss: 223.000239
epoch: 3255, train precision: 0.980911, train loss: 20.227861, valid precision: 0.830400, valid loss: 216.605346
epoch: 3256, train precision: 0.984422, train loss: 18.399016, valid precision: 0.839600, valid loss: 210.968258
epoch: 3257, train precision: 0.983244, train loss: 19.082866, valid precision: 0.833600, valid loss: 199.004562
epoch: 3258, train precision: 0.977311, train loss: 21.738146, valid precision: 0.829400, valid loss: 220.860798
epoch: 3259, train precision: 0.982289, train loss: 19.499284, valid precision: 0.832200, valid loss: 222.192681
epoch: 3260, train precision: 0.979956, train loss: 20.403436, valid precision: 0.837800, valid loss: 199.465018
epoch: 3261, train precision: 0.982578, train loss: 19.693313, valid precision: 0.837400, valid loss: 212.099626
epoch: 3262, train precision: 0.986444, train loss: 16.755534, valid precision: 0.834600, valid loss: 203.245908
epoch: 3263, train precision: 0.984956, train loss: 17.181546, valid precision: 0.834800, valid loss: 202.439647
epoch: 3264, train precision: 0.988378, train loss: 15.880901, valid precision: 0.841400, valid loss: 188.175504
epoch: 3265, train precision: 0.986244, train loss: 17.593050, valid precision: 0.840000, valid loss: 227.659138
epoch: 3266, train precision: 0.981244, train loss: 19.204392, valid precision: 0.837800, valid loss: 189.277018
epoch: 3267, train precision: 0.986267, train loss: 17.705586, valid precision: 0.839800, valid loss: 210.978358
epoch: 3268, train precision: 0.982978, train loss: 19.119520, valid precision: 0.834000, valid loss: 226.167728
epoch: 3269, train precision: 0.987578, train loss: 16.654729, valid precision: 0.843000, valid loss: 222.718516
epoch: 3270, train precision: 0.981956, train loss: 19.353098, valid precision: 0.832000, valid loss: 208.040795
epoch: 3271, train precision: 0.979467, train loss: 21.096900, valid precision: 0.839400, valid loss: 204.064894
epoch: 3272, train precision: 0.985289, train loss: 18.491900, valid precision: 0.839000, valid loss: 226.833710
epoch: 3273, train precision: 0.984756, train loss: 19.005783, valid precision: 0.841000, valid loss: 221.077360
epoch: 3274, train precision: 0.985689, train loss: 17.657819, valid precision: 0.835800, valid loss: 208.855208
epoch: 3275, train precision: 0.986067, train loss: 17.603055, valid precision: 0.837800, valid loss: 219.665136
epoch: 3276, train precision: 0.984778, train loss: 18.080189, valid precision: 0.836600, valid loss: 200.711670
epoch: 3277, train precision: 0.985489, train loss: 17.582068, valid precision: 0.838800, valid loss: 194.593813
epoch: 3278, train precision: 0.988267, train loss: 16.663122, valid precision: 0.835000, valid loss: 225.047256
epoch: 3279, train precision: 0.986178, train loss: 16.841283, valid precision: 0.842600, valid loss: 196.647277
epoch: 3280, train precision: 0.986067, train loss: 17.258150, valid precision: 0.839400, valid loss: 198.663175
epoch: 3281, train precision: 0.984244, train loss: 19.784884, valid precision: 0.837200, valid loss: 228.452496
epoch: 3282, train precision: 0.985778, train loss: 17.765431, valid precision: 0.836400, valid loss: 204.219995
epoch: 3283, train precision: 0.982911, train loss: 19.713482, valid precision: 0.840800, valid loss: 196.980217
epoch: 3284, train precision: 0.983800, train loss: 17.952910, valid precision: 0.831600, valid loss: 191.020829
epoch: 3285, train precision: 0.987089, train loss: 17.616245, valid precision: 0.843000, valid loss: 221.989247
epoch: 3286, train precision: 0.980667, train loss: 20.431721, valid precision: 0.833200, valid loss: 192.865355
epoch: 3287, train precision: 0.986400, train loss: 17.050610, valid precision: 0.836400, valid loss: 210.038266
epoch: 3288, train precision: 0.985289, train loss: 18.455379, valid precision: 0.841400, valid loss: 236.126950
epoch: 3289, train precision: 0.984467, train loss: 18.212433, valid precision: 0.838000, valid loss: 215.180307
epoch: 3290, train precision: 0.983111, train loss: 18.752838, valid precision: 0.832600, valid loss: 200.853120
epoch: 3291, train precision: 0.987067, train loss: 16.788013, valid precision: 0.836800, valid loss: 209.894914
epoch: 3292, train precision: 0.985600, train loss: 17.585394, valid precision: 0.834200, valid loss: 201.864395
epoch: 3293, train precision: 0.984511, train loss: 18.169265, valid precision: 0.837400, valid loss: 231.170632
epoch: 3294, train precision: 0.984156, train loss: 18.006850, valid precision: 0.837000, valid loss: 191.190464
epoch: 3295, train precision: 0.984800, train loss: 18.281306, valid precision: 0.842400, valid loss: 223.574419
epoch: 3296, train precision: 0.980978, train loss: 19.153794, valid precision: 0.832000, valid loss: 176.192969
epoch: 3297, train precision: 0.985911, train loss: 17.629700, valid precision: 0.837600, valid loss: 204.399807
epoch: 3298, train precision: 0.986422, train loss: 17.459468, valid precision: 0.832000, valid loss: 217.316541
epoch: 3299, train precision: 0.981756, train loss: 18.969840, valid precision: 0.830600, valid loss: 182.412371
epoch: 3300, train precision: 0.982422, train loss: 19.999702, valid precision: 0.829200, valid loss: 224.608251
epoch: 3301, train precision: 0.980644, train loss: 20.289894, valid precision: 0.830200, valid loss: 221.854066
epoch: 3302, train precision: 0.984489, train loss: 18.338700, valid precision: 0.831400, valid loss: 211.456623
epoch: 3303, train precision: 0.977689, train loss: 20.864942, valid precision: 0.826600, valid loss: 183.741826
epoch: 3304, train precision: 0.982533, train loss: 19.120333, valid precision: 0.833400, valid loss: 204.649045
epoch: 3305, train precision: 0.983111, train loss: 18.889224, valid precision: 0.832200, valid loss: 204.371660
epoch: 3306, train precision: 0.980911, train loss: 19.304148, valid precision: 0.829400, valid loss: 202.082240
epoch: 3307, train precision: 0.985933, train loss: 17.366197, valid precision: 0.836400, valid loss: 213.121387
epoch: 3308, train precision: 0.986844, train loss: 16.647925, valid precision: 0.838800, valid loss: 205.597824
epoch: 3309, train precision: 0.983444, train loss: 18.942215, valid precision: 0.827800, valid loss: 231.106824
epoch: 3310, train precision: 0.984333, train loss: 18.071050, valid precision: 0.838200, valid loss: 183.637922
epoch: 3311, train precision: 0.981511, train loss: 19.413099, valid precision: 0.838600, valid loss: 184.329482
epoch: 3312, train precision: 0.984333, train loss: 18.667698, valid precision: 0.837800, valid loss: 225.261642
epoch: 3313, train precision: 0.984356, train loss: 18.342957, valid precision: 0.836600, valid loss: 217.830861
epoch: 3314, train precision: 0.984044, train loss: 19.661579, valid precision: 0.833400, valid loss: 226.892842
epoch: 3315, train precision: 0.986844, train loss: 16.865853, valid precision: 0.836000, valid loss: 199.840924
epoch: 3316, train precision: 0.985533, train loss: 17.614504, valid precision: 0.833200, valid loss: 214.224736
epoch: 3317, train precision: 0.985022, train loss: 17.976236, valid precision: 0.841000, valid loss: 230.420490
epoch: 3318, train precision: 0.982378, train loss: 18.744745, valid precision: 0.833200, valid loss: 193.896504
epoch: 3319, train precision: 0.978178, train loss: 21.045004, valid precision: 0.834200, valid loss: 211.731769
epoch: 3320, train precision: 0.983267, train loss: 19.154961, valid precision: 0.837800, valid loss: 213.019055
epoch: 3321, train precision: 0.986844, train loss: 16.991728, valid precision: 0.837800, valid loss: 213.194282
epoch: 3322, train precision: 0.978400, train loss: 20.729824, valid precision: 0.832800, valid loss: 195.372941
epoch: 3323, train precision: 0.985822, train loss: 17.515870, valid precision: 0.839400, valid loss: 216.048739
epoch: 3324, train precision: 0.982933, train loss: 20.221505, valid precision: 0.835800, valid loss: 240.750504
epoch: 3325, train precision: 0.978956, train loss: 20.660782, valid precision: 0.836200, valid loss: 192.908258
epoch: 3326, train precision: 0.983089, train loss: 18.990184, valid precision: 0.837200, valid loss: 220.404701
epoch: 3327, train precision: 0.975689, train loss: 22.553030, valid precision: 0.834600, valid loss: 201.118136
epoch: 3328, train precision: 0.983400, train loss: 18.026678, valid precision: 0.833400, valid loss: 202.290905
epoch: 3329, train precision: 0.983667, train loss: 18.462773, valid precision: 0.833000, valid loss: 225.659712
epoch: 3330, train precision: 0.982800, train loss: 19.092591, valid precision: 0.833600, valid loss: 210.573940
epoch: 3331, train precision: 0.986400, train loss: 17.340392, valid precision: 0.837800, valid loss: 215.356362
epoch: 3332, train precision: 0.979711, train loss: 20.643216, valid precision: 0.833200, valid loss: 218.009818
epoch: 3333, train precision: 0.980133, train loss: 19.878360, valid precision: 0.839000, valid loss: 204.559157
epoch: 3334, train precision: 0.982133, train loss: 19.280892, valid precision: 0.833400, valid loss: 218.840144
epoch: 3335, train precision: 0.984111, train loss: 18.792237, valid precision: 0.835600, valid loss: 232.525459
epoch: 3336, train precision: 0.982044, train loss: 18.878939, valid precision: 0.833400, valid loss: 191.990097
epoch: 3337, train precision: 0.986089, train loss: 17.855258, valid precision: 0.835600, valid loss: 244.012258
epoch: 3338, train precision: 0.984756, train loss: 17.850620, valid precision: 0.837600, valid loss: 210.086682
epoch: 3339, train precision: 0.983000, train loss: 19.194213, valid precision: 0.832600, valid loss: 190.227933
epoch: 3340, train precision: 0.985044, train loss: 18.055457, valid precision: 0.834600, valid loss: 215.753241
epoch: 3341, train precision: 0.981356, train loss: 19.000995, valid precision: 0.838400, valid loss: 193.838252
epoch: 3342, train precision: 0.987022, train loss: 16.457422, valid precision: 0.845200, valid loss: 215.444029
epoch: 3343, train precision: 0.981756, train loss: 20.241238, valid precision: 0.832000, valid loss: 232.693777
epoch: 3344, train precision: 0.984000, train loss: 19.084477, valid precision: 0.833800, valid loss: 235.022005
epoch: 3345, train precision: 0.986133, train loss: 18.244287, valid precision: 0.840800, valid loss: 249.177866
epoch: 3346, train precision: 0.981578, train loss: 19.572513, valid precision: 0.831800, valid loss: 190.008301
epoch: 3347, train precision: 0.984644, train loss: 17.969953, valid precision: 0.843000, valid loss: 194.223895
epoch: 3348, train precision: 0.983622, train loss: 18.521297, valid precision: 0.840000, valid loss: 213.485052
epoch: 3349, train precision: 0.985644, train loss: 18.015428, valid precision: 0.840400, valid loss: 207.415743
epoch: 3350, train precision: 0.985822, train loss: 17.134479, valid precision: 0.837600, valid loss: 193.479330
epoch: 3351, train precision: 0.984778, train loss: 18.485043, valid precision: 0.836200, valid loss: 227.527354
epoch: 3352, train precision: 0.984089, train loss: 18.188775, valid precision: 0.833600, valid loss: 214.331098
epoch: 3353, train precision: 0.982333, train loss: 18.849734, valid precision: 0.834000, valid loss: 193.163495
epoch: 3354, train precision: 0.986444, train loss: 17.651152, valid precision: 0.836200, valid loss: 196.581485
epoch: 3355, train precision: 0.980911, train loss: 19.682372, valid precision: 0.834200, valid loss: 186.775211
epoch: 3356, train precision: 0.987800, train loss: 17.047212, valid precision: 0.839800, valid loss: 230.294224
epoch: 3357, train precision: 0.983822, train loss: 19.143186, valid precision: 0.833800, valid loss: 216.755957
epoch: 3358, train precision: 0.984378, train loss: 18.177565, valid precision: 0.834200, valid loss: 202.661342
epoch: 3359, train precision: 0.983711, train loss: 18.266819, valid precision: 0.839000, valid loss: 202.333976
epoch: 3360, train precision: 0.984733, train loss: 18.339664, valid precision: 0.838000, valid loss: 220.826742
epoch: 3361, train precision: 0.983911, train loss: 18.002928, valid precision: 0.833600, valid loss: 193.288534
epoch: 3362, train precision: 0.984800, train loss: 18.256374, valid precision: 0.835200, valid loss: 233.515789
epoch: 3363, train precision: 0.987244, train loss: 16.734391, valid precision: 0.836600, valid loss: 202.379434
epoch: 3364, train precision: 0.981444, train loss: 19.430768, valid precision: 0.832600, valid loss: 184.573461
epoch: 3365, train precision: 0.986000, train loss: 17.372029, valid precision: 0.835800, valid loss: 208.258370
epoch: 3366, train precision: 0.983978, train loss: 17.941525, valid precision: 0.838400, valid loss: 190.279030
epoch: 3367, train precision: 0.982711, train loss: 18.829582, valid precision: 0.831200, valid loss: 214.564647
epoch: 3368, train precision: 0.982756, train loss: 18.496836, valid precision: 0.831400, valid loss: 197.633937
epoch: 3369, train precision: 0.979533, train loss: 20.687450, valid precision: 0.828400, valid loss: 197.160076
epoch: 3370, train precision: 0.986311, train loss: 17.507746, valid precision: 0.838600, valid loss: 218.853454
epoch: 3371, train precision: 0.981622, train loss: 19.344707, valid precision: 0.828400, valid loss: 209.900872
epoch: 3372, train precision: 0.985800, train loss: 17.034842, valid precision: 0.835600, valid loss: 200.174649
epoch: 3373, train precision: 0.986400, train loss: 17.120098, valid precision: 0.838600, valid loss: 222.222954
epoch: 3374, train precision: 0.987933, train loss: 16.610694, valid precision: 0.837800, valid loss: 206.578212
epoch: 3375, train precision: 0.983844, train loss: 17.810985, valid precision: 0.836600, valid loss: 204.336276
epoch: 3376, train precision: 0.981444, train loss: 19.190003, valid precision: 0.833200, valid loss: 183.062519
epoch: 3377, train precision: 0.982889, train loss: 18.685507, valid precision: 0.834200, valid loss: 191.950194
epoch: 3378, train precision: 0.981822, train loss: 18.955119, valid precision: 0.834600, valid loss: 223.043261
epoch: 3379, train precision: 0.985800, train loss: 17.907427, valid precision: 0.834200, valid loss: 234.865118
epoch: 3380, train precision: 0.982711, train loss: 19.216173, valid precision: 0.828800, valid loss: 219.192140
epoch: 3381, train precision: 0.980222, train loss: 20.540780, valid precision: 0.834600, valid loss: 199.398917
epoch: 3382, train precision: 0.986933, train loss: 17.275749, valid precision: 0.838800, valid loss: 220.362452
epoch: 3383, train precision: 0.982556, train loss: 19.421063, valid precision: 0.830000, valid loss: 228.586117
epoch: 3384, train precision: 0.986533, train loss: 17.250824, valid precision: 0.837600, valid loss: 209.025428
epoch: 3385, train precision: 0.982667, train loss: 18.880127, valid precision: 0.834200, valid loss: 187.686037
epoch: 3386, train precision: 0.982600, train loss: 19.297447, valid precision: 0.834000, valid loss: 196.375140
epoch: 3387, train precision: 0.983289, train loss: 19.337772, valid precision: 0.836200, valid loss: 225.697182
epoch: 3388, train precision: 0.984044, train loss: 17.830247, valid precision: 0.834800, valid loss: 194.715703
epoch: 3389, train precision: 0.980000, train loss: 21.426026, valid precision: 0.832200, valid loss: 234.697077
epoch: 3390, train precision: 0.979622, train loss: 20.526018, valid precision: 0.826800, valid loss: 193.424488
epoch: 3391, train precision: 0.984267, train loss: 19.456677, valid precision: 0.832600, valid loss: 233.447719
epoch: 3392, train precision: 0.987756, train loss: 16.917111, valid precision: 0.838000, valid loss: 234.076225
epoch: 3393, train precision: 0.987156, train loss: 17.392120, valid precision: 0.829800, valid loss: 234.277705
epoch: 3394, train precision: 0.982378, train loss: 19.181658, valid precision: 0.833000, valid loss: 213.388336
epoch: 3395, train precision: 0.981756, train loss: 20.714180, valid precision: 0.831000, valid loss: 236.012406
epoch: 3396, train precision: 0.979756, train loss: 20.451984, valid precision: 0.827400, valid loss: 192.677922
epoch: 3397, train precision: 0.982733, train loss: 19.097372, valid precision: 0.833800, valid loss: 198.836292
epoch: 3398, train precision: 0.986222, train loss: 16.830184, valid precision: 0.835400, valid loss: 199.143523
epoch: 3399, train precision: 0.980844, train loss: 19.612254, valid precision: 0.832800, valid loss: 197.440326
epoch: 3400, train precision: 0.985733, train loss: 18.033307, valid precision: 0.836800, valid loss: 224.675304
epoch: 3401, train precision: 0.984467, train loss: 17.757027, valid precision: 0.836200, valid loss: 188.902523
epoch: 3402, train precision: 0.984578, train loss: 19.016392, valid precision: 0.837600, valid loss: 232.304422
epoch: 3403, train precision: 0.987178, train loss: 17.170929, valid precision: 0.835400, valid loss: 223.291811
epoch: 3404, train precision: 0.984689, train loss: 17.782146, valid precision: 0.841800, valid loss: 203.281847
epoch: 3405, train precision: 0.985044, train loss: 18.543812, valid precision: 0.840600, valid loss: 224.360699
epoch: 3406, train precision: 0.983156, train loss: 19.172801, valid precision: 0.843200, valid loss: 221.797607
epoch: 3407, train precision: 0.982533, train loss: 18.991841, valid precision: 0.831800, valid loss: 194.931302
epoch: 3408, train precision: 0.985067, train loss: 17.830750, valid precision: 0.836200, valid loss: 188.940349
epoch: 3409, train precision: 0.969867, train loss: 25.331088, valid precision: 0.827600, valid loss: 193.360387
epoch: 3410, train precision: 0.983778, train loss: 18.163532, valid precision: 0.835400, valid loss: 200.075475
epoch: 3411, train precision: 0.987667, train loss: 16.672082, valid precision: 0.837200, valid loss: 218.377780
epoch: 3412, train precision: 0.984844, train loss: 17.964751, valid precision: 0.835800, valid loss: 198.747514
epoch: 3413, train precision: 0.985244, train loss: 18.253430, valid precision: 0.833000, valid loss: 233.743100
epoch: 3414, train precision: 0.984022, train loss: 20.410656, valid precision: 0.840400, valid loss: 262.189246
epoch: 3415, train precision: 0.987000, train loss: 17.312968, valid precision: 0.841400, valid loss: 221.304611
epoch: 3416, train precision: 0.986867, train loss: 17.141887, valid precision: 0.843800, valid loss: 201.286108
epoch: 3417, train precision: 0.984667, train loss: 17.824480, valid precision: 0.834400, valid loss: 201.441089
epoch: 3418, train precision: 0.983444, train loss: 18.833935, valid precision: 0.825800, valid loss: 193.359180
epoch: 3419, train precision: 0.981533, train loss: 18.975404, valid precision: 0.830000, valid loss: 172.540664
epoch: 3420, train precision: 0.984444, train loss: 18.289094, valid precision: 0.837200, valid loss: 205.688435
epoch: 3421, train precision: 0.984178, train loss: 18.333196, valid precision: 0.838200, valid loss: 194.386922
epoch: 3422, train precision: 0.982311, train loss: 19.086984, valid precision: 0.829400, valid loss: 195.232330
epoch: 3423, train precision: 0.982378, train loss: 19.154855, valid precision: 0.836800, valid loss: 197.974667
epoch: 3424, train precision: 0.981444, train loss: 19.383341, valid precision: 0.834600, valid loss: 189.821726
epoch: 3425, train precision: 0.981467, train loss: 20.290566, valid precision: 0.838200, valid loss: 212.243251
epoch: 3426, train precision: 0.984956, train loss: 17.780023, valid precision: 0.839400, valid loss: 193.900652
epoch: 3427, train precision: 0.984422, train loss: 18.742097, valid precision: 0.833400, valid loss: 212.097737
epoch: 3428, train precision: 0.986489, train loss: 17.309201, valid precision: 0.830600, valid loss: 213.860656
epoch: 3429, train precision: 0.983911, train loss: 18.265901, valid precision: 0.835600, valid loss: 190.777579
epoch: 3430, train precision: 0.985933, train loss: 16.879893, valid precision: 0.840400, valid loss: 194.131843
epoch: 3431, train precision: 0.979600, train loss: 21.156306, valid precision: 0.835600, valid loss: 222.379291
epoch: 3432, train precision: 0.984778, train loss: 17.980040, valid precision: 0.841200, valid loss: 209.769157
epoch: 3433, train precision: 0.985044, train loss: 18.163561, valid precision: 0.838600, valid loss: 219.423645
epoch: 3434, train precision: 0.985311, train loss: 17.524664, valid precision: 0.839000, valid loss: 196.568601
epoch: 3435, train precision: 0.986622, train loss: 17.676868, valid precision: 0.835400, valid loss: 213.200151
epoch: 3436, train precision: 0.981378, train loss: 20.209961, valid precision: 0.837800, valid loss: 205.683580
epoch: 3437, train precision: 0.983089, train loss: 19.522180, valid precision: 0.839400, valid loss: 242.827779
epoch: 3438, train precision: 0.983911, train loss: 17.808081, valid precision: 0.835000, valid loss: 195.767584
epoch: 3439, train precision: 0.979356, train loss: 21.483543, valid precision: 0.832000, valid loss: 235.539707
epoch: 3440, train precision: 0.984067, train loss: 18.770128, valid precision: 0.833200, valid loss: 206.370348
epoch: 3441, train precision: 0.985267, train loss: 17.803619, valid precision: 0.837400, valid loss: 205.132784
epoch: 3442, train precision: 0.981778, train loss: 20.686031, valid precision: 0.841600, valid loss: 232.980601
epoch: 3443, train precision: 0.988044, train loss: 16.569425, valid precision: 0.836800, valid loss: 222.727337
epoch: 3444, train precision: 0.987000, train loss: 17.565657, valid precision: 0.837200, valid loss: 211.073622
epoch: 3445, train precision: 0.987067, train loss: 16.647731, valid precision: 0.835800, valid loss: 206.248041
epoch: 3446, train precision: 0.985511, train loss: 18.091090, valid precision: 0.837600, valid loss: 230.512147
epoch: 3447, train precision: 0.986044, train loss: 17.342873, valid precision: 0.839000, valid loss: 192.654679
epoch: 3448, train precision: 0.986511, train loss: 17.066021, valid precision: 0.843600, valid loss: 207.162997
epoch: 3449, train precision: 0.983356, train loss: 18.607330, valid precision: 0.840200, valid loss: 214.196916
epoch: 3450, train precision: 0.984867, train loss: 17.671608, valid precision: 0.838600, valid loss: 198.993977
epoch: 3451, train precision: 0.981600, train loss: 19.707135, valid precision: 0.837600, valid loss: 211.415959
epoch: 3452, train precision: 0.981933, train loss: 19.236733, valid precision: 0.834600, valid loss: 207.779007
epoch: 3453, train precision: 0.982489, train loss: 19.819300, valid precision: 0.838800, valid loss: 250.053950
epoch: 3454, train precision: 0.983733, train loss: 19.046958, valid precision: 0.834600, valid loss: 215.164486
epoch: 3455, train precision: 0.982822, train loss: 20.657962, valid precision: 0.835000, valid loss: 224.751572
epoch: 3456, train precision: 0.985244, train loss: 18.466724, valid precision: 0.836000, valid loss: 227.024335
epoch: 3457, train precision: 0.985444, train loss: 17.747273, valid precision: 0.840000, valid loss: 194.488486
epoch: 3458, train precision: 0.986200, train loss: 17.253160, valid precision: 0.838200, valid loss: 196.945571
epoch: 3459, train precision: 0.978156, train loss: 21.420913, valid precision: 0.832400, valid loss: 203.179568
epoch: 3460, train precision: 0.979933, train loss: 20.066317, valid precision: 0.831600, valid loss: 176.032890
epoch: 3461, train precision: 0.980422, train loss: 19.825233, valid precision: 0.834600, valid loss: 194.242011
epoch: 3462, train precision: 0.986844, train loss: 17.042072, valid precision: 0.838400, valid loss: 204.789785
epoch: 3463, train precision: 0.987556, train loss: 17.109808, valid precision: 0.837000, valid loss: 233.698610
epoch: 3464, train precision: 0.980867, train loss: 19.533484, valid precision: 0.834200, valid loss: 201.512282
epoch: 3465, train precision: 0.985400, train loss: 18.317701, valid precision: 0.834600, valid loss: 214.738972
epoch: 3466, train precision: 0.985711, train loss: 17.264781, valid precision: 0.837000, valid loss: 213.358574
epoch: 3467, train precision: 0.982822, train loss: 19.274028, valid precision: 0.838200, valid loss: 212.361792
epoch: 3468, train precision: 0.983844, train loss: 18.242143, valid precision: 0.832400, valid loss: 210.877962
epoch: 3469, train precision: 0.979956, train loss: 20.871567, valid precision: 0.832400, valid loss: 209.672819
epoch: 3470, train precision: 0.986400, train loss: 17.212595, valid precision: 0.839600, valid loss: 214.401083
epoch: 3471, train precision: 0.986978, train loss: 17.247756, valid precision: 0.842400, valid loss: 229.412095
epoch: 3472, train precision: 0.978222, train loss: 20.836960, valid precision: 0.833800, valid loss: 201.556743
epoch: 3473, train precision: 0.986600, train loss: 17.216685, valid precision: 0.840000, valid loss: 219.246631
epoch: 3474, train precision: 0.983756, train loss: 18.471421, valid precision: 0.828600, valid loss: 212.969799
epoch: 3475, train precision: 0.981844, train loss: 19.291974, valid precision: 0.832000, valid loss: 220.277250
epoch: 3476, train precision: 0.976422, train loss: 22.903439, valid precision: 0.827600, valid loss: 218.461675
epoch: 3477, train precision: 0.987467, train loss: 17.203637, valid precision: 0.839400, valid loss: 218.411835
epoch: 3478, train precision: 0.978778, train loss: 20.825254, valid precision: 0.834600, valid loss: 188.719790
epoch: 3479, train precision: 0.985556, train loss: 17.953608, valid precision: 0.837000, valid loss: 226.274803
epoch: 3480, train precision: 0.985156, train loss: 18.301221, valid precision: 0.838200, valid loss: 208.526235
epoch: 3481, train precision: 0.982333, train loss: 19.088501, valid precision: 0.836400, valid loss: 192.682283
epoch: 3482, train precision: 0.981067, train loss: 19.911734, valid precision: 0.831000, valid loss: 193.709971
epoch: 3483, train precision: 0.983556, train loss: 19.487287, valid precision: 0.835600, valid loss: 216.308601
epoch: 3484, train precision: 0.980289, train loss: 22.274158, valid precision: 0.831800, valid loss: 241.216085
epoch: 3485, train precision: 0.986533, train loss: 17.615535, valid precision: 0.837600, valid loss: 225.853356
epoch: 3486, train precision: 0.986156, train loss: 17.424279, valid precision: 0.834800, valid loss: 208.473025
epoch: 3487, train precision: 0.986333, train loss: 17.850779, valid precision: 0.835200, valid loss: 218.078021
epoch: 3488, train precision: 0.980022, train loss: 20.661352, valid precision: 0.832400, valid loss: 207.045798
epoch: 3489, train precision: 0.980267, train loss: 19.659402, valid precision: 0.827200, valid loss: 196.825000
epoch: 3490, train precision: 0.983333, train loss: 19.623622, valid precision: 0.835600, valid loss: 219.635352
epoch: 3491, train precision: 0.980556, train loss: 21.379349, valid precision: 0.833800, valid loss: 226.489900
epoch: 3492, train precision: 0.983978, train loss: 18.552213, valid precision: 0.836600, valid loss: 198.525386
epoch: 3493, train precision: 0.984178, train loss: 18.285677, valid precision: 0.832800, valid loss: 196.149201
epoch: 3494, train precision: 0.986222, train loss: 17.565865, valid precision: 0.835400, valid loss: 222.036460
epoch: 3495, train precision: 0.982044, train loss: 19.412181, valid precision: 0.833000, valid loss: 221.338555
epoch: 3496, train precision: 0.986422, train loss: 17.203693, valid precision: 0.839000, valid loss: 206.700389
epoch: 3497, train precision: 0.982089, train loss: 19.225591, valid precision: 0.839400, valid loss: 199.745953
epoch: 3498, train precision: 0.983511, train loss: 18.370307, valid precision: 0.829400, valid loss: 196.523870
epoch: 3499, train precision: 0.983289, train loss: 18.360851, valid precision: 0.831400, valid loss: 197.486303
epoch: 3500, train precision: 0.985244, train loss: 18.320487, valid precision: 0.840000, valid loss: 218.055910
epoch: 3501, train precision: 0.983200, train loss: 18.831716, valid precision: 0.830000, valid loss: 198.369084
epoch: 3502, train precision: 0.985511, train loss: 18.085653, valid precision: 0.836400, valid loss: 223.180610
epoch: 3503, train precision: 0.985356, train loss: 17.727878, valid precision: 0.839800, valid loss: 194.217310
epoch: 3504, train precision: 0.987111, train loss: 16.762046, valid precision: 0.834800, valid loss: 197.133959
epoch: 3505, train precision: 0.983733, train loss: 18.389433, valid precision: 0.832400, valid loss: 199.856435
epoch: 3506, train precision: 0.988222, train loss: 16.631523, valid precision: 0.838800, valid loss: 232.494636
epoch: 3507, train precision: 0.981889, train loss: 18.775076, valid precision: 0.831800, valid loss: 204.171950
epoch: 3508, train precision: 0.983067, train loss: 20.910593, valid precision: 0.840200, valid loss: 267.318993
epoch: 3509, train precision: 0.985289, train loss: 18.742720, valid precision: 0.838600, valid loss: 214.103578
epoch: 3510, train precision: 0.988644, train loss: 16.532763, valid precision: 0.843000, valid loss: 222.979710
epoch: 3511, train precision: 0.980044, train loss: 19.833771, valid precision: 0.834400, valid loss: 191.438456
epoch: 3512, train precision: 0.978511, train loss: 21.227452, valid precision: 0.835400, valid loss: 186.887450
epoch: 3513, train precision: 0.979333, train loss: 20.237302, valid precision: 0.839200, valid loss: 196.270238
epoch: 3514, train precision: 0.987178, train loss: 16.469012, valid precision: 0.837600, valid loss: 201.274888
epoch: 3515, train precision: 0.984667, train loss: 18.245032, valid precision: 0.835600, valid loss: 210.068719
epoch: 3516, train precision: 0.986356, train loss: 17.636644, valid precision: 0.845600, valid loss: 223.867491
epoch: 3517, train precision: 0.979844, train loss: 20.479075, valid precision: 0.833400, valid loss: 182.743115
epoch: 3518, train precision: 0.982356, train loss: 18.856515, valid precision: 0.828800, valid loss: 196.280597
epoch: 3519, train precision: 0.983089, train loss: 18.807501, valid precision: 0.833800, valid loss: 208.062295
epoch: 3520, train precision: 0.987667, train loss: 16.656803, valid precision: 0.837400, valid loss: 227.675366
epoch: 3521, train precision: 0.987022, train loss: 17.013673, valid precision: 0.842000, valid loss: 205.783590
epoch: 3522, train precision: 0.987044, train loss: 16.637379, valid precision: 0.837000, valid loss: 210.867395
epoch: 3523, train precision: 0.984867, train loss: 18.250712, valid precision: 0.832400, valid loss: 201.247582
epoch: 3524, train precision: 0.984911, train loss: 18.196720, valid precision: 0.834200, valid loss: 219.374216
epoch: 3525, train precision: 0.988556, train loss: 15.895305, valid precision: 0.843200, valid loss: 211.759745
epoch: 3526, train precision: 0.984289, train loss: 18.087068, valid precision: 0.831600, valid loss: 204.642471
epoch: 3527, train precision: 0.978822, train loss: 21.235601, valid precision: 0.833200, valid loss: 206.887187
epoch: 3528, train precision: 0.984556, train loss: 18.840524, valid precision: 0.829400, valid loss: 210.601100
epoch: 3529, train precision: 0.983467, train loss: 18.902965, valid precision: 0.833600, valid loss: 210.139221
epoch: 3530, train precision: 0.981644, train loss: 20.122483, valid precision: 0.832000, valid loss: 210.525939
epoch: 3531, train precision: 0.981511, train loss: 19.938350, valid precision: 0.830600, valid loss: 210.836436
epoch: 3532, train precision: 0.987822, train loss: 16.552517, valid precision: 0.837200, valid loss: 205.475977
epoch: 3533, train precision: 0.981467, train loss: 18.893717, valid precision: 0.828000, valid loss: 186.130075
epoch: 3534, train precision: 0.984867, train loss: 18.067565, valid precision: 0.833600, valid loss: 183.895206
epoch: 3535, train precision: 0.982022, train loss: 19.030925, valid precision: 0.834000, valid loss: 173.409084
epoch: 3536, train precision: 0.988778, train loss: 16.285686, valid precision: 0.834400, valid loss: 215.254755
epoch: 3537, train precision: 0.984089, train loss: 19.044640, valid precision: 0.839200, valid loss: 231.936583
epoch: 3538, train precision: 0.985978, train loss: 17.492121, valid precision: 0.837200, valid loss: 209.082799
epoch: 3539, train precision: 0.985889, train loss: 17.885827, valid precision: 0.836000, valid loss: 212.070781
epoch: 3540, train precision: 0.981267, train loss: 19.292784, valid precision: 0.835600, valid loss: 185.246717
epoch: 3541, train precision: 0.984000, train loss: 18.833543, valid precision: 0.836400, valid loss: 203.377277
epoch: 3542, train precision: 0.986733, train loss: 17.135503, valid precision: 0.836200, valid loss: 192.941109
epoch: 3543, train precision: 0.981733, train loss: 19.290390, valid precision: 0.832000, valid loss: 191.777309
epoch: 3544, train precision: 0.985356, train loss: 17.941894, valid precision: 0.834600, valid loss: 211.858732
epoch: 3545, train precision: 0.983378, train loss: 19.167205, valid precision: 0.829600, valid loss: 215.682096
epoch: 3546, train precision: 0.983311, train loss: 19.564733, valid precision: 0.837400, valid loss: 229.882502
epoch: 3547, train precision: 0.986778, train loss: 17.547018, valid precision: 0.838400, valid loss: 229.513944
epoch: 3548, train precision: 0.979889, train loss: 19.754602, valid precision: 0.828400, valid loss: 166.747890
epoch: 3549, train precision: 0.981200, train loss: 20.334147, valid precision: 0.842400, valid loss: 218.521977
epoch: 3550, train precision: 0.986600, train loss: 17.996646, valid precision: 0.834600, valid loss: 239.731094
epoch: 3551, train precision: 0.983644, train loss: 18.770423, valid precision: 0.839000, valid loss: 202.669569
epoch: 3552, train precision: 0.984000, train loss: 18.941698, valid precision: 0.834600, valid loss: 219.447907
epoch: 3553, train precision: 0.977311, train loss: 20.679297, valid precision: 0.831200, valid loss: 181.074050
epoch: 3554, train precision: 0.987800, train loss: 17.386968, valid precision: 0.838800, valid loss: 241.158080
epoch: 3555, train precision: 0.977156, train loss: 21.547833, valid precision: 0.834000, valid loss: 175.624800
epoch: 3556, train precision: 0.985822, train loss: 17.176650, valid precision: 0.846600, valid loss: 195.124115
epoch: 3557, train precision: 0.983089, train loss: 20.339988, valid precision: 0.837400, valid loss: 252.385601
epoch: 3558, train precision: 0.979133, train loss: 21.320354, valid precision: 0.836600, valid loss: 229.907636
epoch: 3559, train precision: 0.984000, train loss: 18.631342, valid precision: 0.836600, valid loss: 199.930651
epoch: 3560, train precision: 0.987667, train loss: 16.689991, valid precision: 0.843000, valid loss: 200.103030
epoch: 3561, train precision: 0.986911, train loss: 17.105721, valid precision: 0.842200, valid loss: 200.818441
epoch: 3562, train precision: 0.985400, train loss: 18.815390, valid precision: 0.842200, valid loss: 233.611416
epoch: 3563, train precision: 0.982356, train loss: 18.810415, valid precision: 0.829800, valid loss: 192.191233
epoch: 3564, train precision: 0.976222, train loss: 23.637207, valid precision: 0.834400, valid loss: 214.611696
epoch: 3565, train precision: 0.980756, train loss: 20.003616, valid precision: 0.827400, valid loss: 200.391415
epoch: 3566, train precision: 0.983178, train loss: 18.475332, valid precision: 0.833400, valid loss: 189.158620
epoch: 3567, train precision: 0.987800, train loss: 16.438385, valid precision: 0.832800, valid loss: 217.365704
epoch: 3568, train precision: 0.982489, train loss: 19.424747, valid precision: 0.839000, valid loss: 204.731363
epoch: 3569, train precision: 0.984178, train loss: 18.172958, valid precision: 0.834800, valid loss: 199.935042
epoch: 3570, train precision: 0.981756, train loss: 19.498430, valid precision: 0.825400, valid loss: 225.034345
epoch: 3571, train precision: 0.975600, train loss: 21.830588, valid precision: 0.827000, valid loss: 180.438290
epoch: 3572, train precision: 0.986022, train loss: 17.575676, valid precision: 0.837600, valid loss: 218.754905
epoch: 3573, train precision: 0.983533, train loss: 18.420373, valid precision: 0.832800, valid loss: 210.893937
epoch: 3574, train precision: 0.985133, train loss: 19.080437, valid precision: 0.838200, valid loss: 209.290297
epoch: 3575, train precision: 0.984356, train loss: 18.365487, valid precision: 0.828200, valid loss: 216.150567
epoch: 3576, train precision: 0.985022, train loss: 18.764818, valid precision: 0.835400, valid loss: 230.537003
epoch: 3577, train precision: 0.986889, train loss: 16.930166, valid precision: 0.833800, valid loss: 208.585938
epoch: 3578, train precision: 0.984156, train loss: 19.016024, valid precision: 0.832800, valid loss: 231.702160
epoch: 3579, train precision: 0.983156, train loss: 18.342037, valid precision: 0.828400, valid loss: 201.809761
epoch: 3580, train precision: 0.983622, train loss: 19.088360, valid precision: 0.839000, valid loss: 236.463324
epoch: 3581, train precision: 0.983356, train loss: 18.655642, valid precision: 0.833400, valid loss: 205.981516
epoch: 3582, train precision: 0.986689, train loss: 16.948111, valid precision: 0.838800, valid loss: 191.991898
epoch: 3583, train precision: 0.979778, train loss: 20.752983, valid precision: 0.829000, valid loss: 218.693606
epoch: 3584, train precision: 0.979689, train loss: 21.793273, valid precision: 0.836400, valid loss: 221.756298
epoch: 3585, train precision: 0.987511, train loss: 17.086807, valid precision: 0.838600, valid loss: 219.206787
epoch: 3586, train precision: 0.984222, train loss: 18.194755, valid precision: 0.836400, valid loss: 206.006287
epoch: 3587, train precision: 0.984844, train loss: 18.145349, valid precision: 0.838200, valid loss: 200.358457
epoch: 3588, train precision: 0.985711, train loss: 18.016018, valid precision: 0.833800, valid loss: 225.214277
epoch: 3589, train precision: 0.985533, train loss: 18.572399, valid precision: 0.836600, valid loss: 245.390497
epoch: 3590, train precision: 0.986000, train loss: 17.316228, valid precision: 0.836800, valid loss: 205.818285
epoch: 3591, train precision: 0.987689, train loss: 17.079982, valid precision: 0.839800, valid loss: 227.246372
epoch: 3592, train precision: 0.981511, train loss: 19.131697, valid precision: 0.832800, valid loss: 184.329264
epoch: 3593, train precision: 0.984644, train loss: 18.514466, valid precision: 0.836400, valid loss: 209.345343
epoch: 3594, train precision: 0.981667, train loss: 20.031774, valid precision: 0.825000, valid loss: 208.731903
epoch: 3595, train precision: 0.984956, train loss: 17.842437, valid precision: 0.839000, valid loss: 198.017208
epoch: 3596, train precision: 0.985822, train loss: 17.532377, valid precision: 0.837000, valid loss: 200.491470
epoch: 3597, train precision: 0.985511, train loss: 17.756833, valid precision: 0.831600, valid loss: 199.538634
epoch: 3598, train precision: 0.986156, train loss: 17.202872, valid precision: 0.834000, valid loss: 214.871256
epoch: 3599, train precision: 0.982711, train loss: 18.954280, valid precision: 0.832800, valid loss: 206.489980
epoch: 3600, train precision: 0.982844, train loss: 18.446224, valid precision: 0.830000, valid loss: 189.378500
epoch: 3601, train precision: 0.985667, train loss: 17.654562, valid precision: 0.837600, valid loss: 201.972085
epoch: 3602, train precision: 0.980156, train loss: 20.304723, valid precision: 0.828200, valid loss: 204.709054
epoch: 3603, train precision: 0.982000, train loss: 20.096111, valid precision: 0.835800, valid loss: 222.537873
epoch: 3604, train precision: 0.984000, train loss: 18.086825, valid precision: 0.827800, valid loss: 199.044350
epoch: 3605, train precision: 0.982622, train loss: 19.581574, valid precision: 0.831600, valid loss: 232.784586
epoch: 3606, train precision: 0.983667, train loss: 19.137694, valid precision: 0.833600, valid loss: 211.088336
epoch: 3607, train precision: 0.983333, train loss: 18.539423, valid precision: 0.834800, valid loss: 199.544511
epoch: 3608, train precision: 0.985533, train loss: 18.121345, valid precision: 0.843000, valid loss: 246.776263
epoch: 3609, train precision: 0.980222, train loss: 21.157587, valid precision: 0.832800, valid loss: 238.638518
epoch: 3610, train precision: 0.982222, train loss: 19.782791, valid precision: 0.838800, valid loss: 208.525163
epoch: 3611, train precision: 0.979733, train loss: 20.616050, valid precision: 0.833800, valid loss: 204.661886
epoch: 3612, train precision: 0.983600, train loss: 18.855329, valid precision: 0.831400, valid loss: 199.107327
epoch: 3613, train precision: 0.984844, train loss: 17.954005, valid precision: 0.840000, valid loss: 211.524164
epoch: 3614, train precision: 0.985578, train loss: 17.973687, valid precision: 0.836000, valid loss: 223.268863
epoch: 3615, train precision: 0.986844, train loss: 16.936584, valid precision: 0.838400, valid loss: 223.735556
epoch: 3616, train precision: 0.983711, train loss: 18.522041, valid precision: 0.833400, valid loss: 198.158696
epoch: 3617, train precision: 0.984956, train loss: 18.559226, valid precision: 0.832400, valid loss: 232.768407
epoch: 3618, train precision: 0.983044, train loss: 19.051632, valid precision: 0.832200, valid loss: 216.903983
epoch: 3619, train precision: 0.979444, train loss: 21.141128, valid precision: 0.835000, valid loss: 206.153044
epoch: 3620, train precision: 0.983111, train loss: 19.030277, valid precision: 0.838200, valid loss: 233.182844
epoch: 3621, train precision: 0.986200, train loss: 18.046929, valid precision: 0.837000, valid loss: 240.470093
epoch: 3622, train precision: 0.983756, train loss: 18.006797, valid precision: 0.834600, valid loss: 192.847524
epoch: 3623, train precision: 0.979822, train loss: 20.231520, valid precision: 0.834800, valid loss: 185.612095
epoch: 3624, train precision: 0.986133, train loss: 17.921387, valid precision: 0.840800, valid loss: 201.941285
epoch: 3625, train precision: 0.983622, train loss: 18.558569, valid precision: 0.835400, valid loss: 198.542781
epoch: 3626, train precision: 0.986778, train loss: 17.050544, valid precision: 0.839800, valid loss: 212.915576
epoch: 3627, train precision: 0.984667, train loss: 18.019984, valid precision: 0.834800, valid loss: 200.106110
epoch: 3628, train precision: 0.983622, train loss: 18.183159, valid precision: 0.836600, valid loss: 196.938594
epoch: 3629, train precision: 0.983467, train loss: 18.871392, valid precision: 0.837400, valid loss: 211.069247
epoch: 3630, train precision: 0.979089, train loss: 20.477692, valid precision: 0.835800, valid loss: 193.825541
epoch: 3631, train precision: 0.986444, train loss: 17.522409, valid precision: 0.836800, valid loss: 218.665641
epoch: 3632, train precision: 0.982044, train loss: 19.643741, valid precision: 0.835200, valid loss: 214.387335
epoch: 3633, train precision: 0.985711, train loss: 18.148085, valid precision: 0.840800, valid loss: 217.974015
epoch: 3634, train precision: 0.985067, train loss: 17.767410, valid precision: 0.834200, valid loss: 212.718899
epoch: 3635, train precision: 0.987867, train loss: 16.825198, valid precision: 0.842800, valid loss: 222.733087
epoch: 3636, train precision: 0.983644, train loss: 19.112968, valid precision: 0.835800, valid loss: 222.416988
epoch: 3637, train precision: 0.981067, train loss: 20.575673, valid precision: 0.832000, valid loss: 226.166383
epoch: 3638, train precision: 0.984600, train loss: 19.314648, valid precision: 0.831800, valid loss: 247.142047
epoch: 3639, train precision: 0.978844, train loss: 20.756277, valid precision: 0.834000, valid loss: 180.111743
epoch: 3640, train precision: 0.984800, train loss: 18.207120, valid precision: 0.837200, valid loss: 204.407861
epoch: 3641, train precision: 0.981956, train loss: 19.096909, valid precision: 0.835200, valid loss: 213.986277
epoch: 3642, train precision: 0.978644, train loss: 20.938859, valid precision: 0.831000, valid loss: 190.107140
epoch: 3643, train precision: 0.980956, train loss: 20.200631, valid precision: 0.836000, valid loss: 191.491939
epoch: 3644, train precision: 0.985689, train loss: 18.615662, valid precision: 0.837400, valid loss: 240.591983
epoch: 3645, train precision: 0.984467, train loss: 18.091169, valid precision: 0.834800, valid loss: 200.824464
epoch: 3646, train precision: 0.984178, train loss: 18.536787, valid precision: 0.835800, valid loss: 212.419147
epoch: 3647, train precision: 0.985600, train loss: 17.500165, valid precision: 0.846800, valid loss: 211.639828
epoch: 3648, train precision: 0.980222, train loss: 19.713619, valid precision: 0.837600, valid loss: 167.066677
epoch: 3649, train precision: 0.981267, train loss: 19.213360, valid precision: 0.827800, valid loss: 200.414971
epoch: 3650, train precision: 0.988000, train loss: 16.828057, valid precision: 0.841000, valid loss: 226.225420
epoch: 3651, train precision: 0.983556, train loss: 18.891385, valid precision: 0.836200, valid loss: 206.249139
epoch: 3652, train precision: 0.979044, train loss: 20.807741, valid precision: 0.836000, valid loss: 205.365192
epoch: 3653, train precision: 0.981467, train loss: 20.157386, valid precision: 0.837400, valid loss: 218.868169
epoch: 3654, train precision: 0.985200, train loss: 18.240818, valid precision: 0.834200, valid loss: 218.896680
epoch: 3655, train precision: 0.984067, train loss: 18.873706, valid precision: 0.840600, valid loss: 197.919863
epoch: 3656, train precision: 0.982956, train loss: 18.659010, valid precision: 0.840000, valid loss: 188.998185
epoch: 3657, train precision: 0.984089, train loss: 18.201321, valid precision: 0.838600, valid loss: 186.910269
epoch: 3658, train precision: 0.981444, train loss: 20.419500, valid precision: 0.834800, valid loss: 233.920451
epoch: 3659, train precision: 0.986800, train loss: 16.832251, valid precision: 0.840000, valid loss: 198.575160
epoch: 3660, train precision: 0.986889, train loss: 17.237542, valid precision: 0.841800, valid loss: 206.434433
epoch: 3661, train precision: 0.981111, train loss: 20.400622, valid precision: 0.836800, valid loss: 219.326946
epoch: 3662, train precision: 0.986311, train loss: 17.643783, valid precision: 0.839400, valid loss: 230.475820
epoch: 3663, train precision: 0.986467, train loss: 17.252604, valid precision: 0.838200, valid loss: 207.040480
epoch: 3664, train precision: 0.982133, train loss: 19.899622, valid precision: 0.835000, valid loss: 201.062751
epoch: 3665, train precision: 0.982356, train loss: 19.732411, valid precision: 0.830600, valid loss: 208.168254
epoch: 3666, train precision: 0.985400, train loss: 18.441452, valid precision: 0.834400, valid loss: 241.306534
epoch: 3667, train precision: 0.985422, train loss: 18.153245, valid precision: 0.834800, valid loss: 213.237946
epoch: 3668, train precision: 0.983800, train loss: 18.073522, valid precision: 0.834000, valid loss: 219.377239
epoch: 3669, train precision: 0.980400, train loss: 20.115798, valid precision: 0.827800, valid loss: 205.303700
epoch: 3670, train precision: 0.984556, train loss: 18.221329, valid precision: 0.835200, valid loss: 198.619055
epoch: 3671, train precision: 0.978778, train loss: 21.490787, valid precision: 0.824000, valid loss: 224.236527
epoch: 3672, train precision: 0.983333, train loss: 19.682849, valid precision: 0.833800, valid loss: 225.259810
epoch: 3673, train precision: 0.980489, train loss: 20.739543, valid precision: 0.826800, valid loss: 224.432522
epoch: 3674, train precision: 0.983400, train loss: 19.120347, valid precision: 0.833200, valid loss: 217.143995
epoch: 3675, train precision: 0.985378, train loss: 17.927652, valid precision: 0.836600, valid loss: 224.412351
epoch: 3676, train precision: 0.981689, train loss: 19.193641, valid precision: 0.839200, valid loss: 194.283009
epoch: 3677, train precision: 0.984889, train loss: 17.661689, valid precision: 0.838800, valid loss: 197.114070
epoch: 3678, train precision: 0.981467, train loss: 19.015768, valid precision: 0.834400, valid loss: 181.962353
epoch: 3679, train precision: 0.983156, train loss: 19.019257, valid precision: 0.833400, valid loss: 207.573956
epoch: 3680, train precision: 0.976644, train loss: 21.915677, valid precision: 0.836600, valid loss: 189.696386
epoch: 3681, train precision: 0.986289, train loss: 17.293875, valid precision: 0.837600, valid loss: 217.525452
epoch: 3682, train precision: 0.982022, train loss: 19.496742, valid precision: 0.838200, valid loss: 198.125595
epoch: 3683, train precision: 0.984489, train loss: 17.972512, valid precision: 0.840000, valid loss: 193.815125
epoch: 3684, train precision: 0.984889, train loss: 18.485211, valid precision: 0.837600, valid loss: 206.089759
epoch: 3685, train precision: 0.983822, train loss: 18.380096, valid precision: 0.833800, valid loss: 216.042032
epoch: 3686, train precision: 0.983778, train loss: 19.494445, valid precision: 0.836600, valid loss: 237.523359
epoch: 3687, train precision: 0.986444, train loss: 17.273191, valid precision: 0.834800, valid loss: 225.703434
epoch: 3688, train precision: 0.982022, train loss: 20.783687, valid precision: 0.837000, valid loss: 240.021850
epoch: 3689, train precision: 0.984911, train loss: 18.261627, valid precision: 0.835000, valid loss: 207.102772
epoch: 3690, train precision: 0.984756, train loss: 18.343711, valid precision: 0.838200, valid loss: 207.627533
epoch: 3691, train precision: 0.981844, train loss: 20.224466, valid precision: 0.839400, valid loss: 216.576596
epoch: 3692, train precision: 0.986356, train loss: 17.267650, valid precision: 0.835400, valid loss: 218.293971
epoch: 3693, train precision: 0.984467, train loss: 19.573819, valid precision: 0.835200, valid loss: 243.024298
epoch: 3694, train precision: 0.984667, train loss: 18.423061, valid precision: 0.835800, valid loss: 202.766295
epoch: 3695, train precision: 0.984800, train loss: 18.255230, valid precision: 0.840400, valid loss: 225.076059
epoch: 3696, train precision: 0.983489, train loss: 19.006237, valid precision: 0.832200, valid loss: 222.952661
epoch: 3697, train precision: 0.983533, train loss: 18.626735, valid precision: 0.836800, valid loss: 202.780242
epoch: 3698, train precision: 0.985178, train loss: 18.194981, valid precision: 0.838200, valid loss: 218.671881
epoch: 3699, train precision: 0.984689, train loss: 17.925552, valid precision: 0.836800, valid loss: 201.185083
epoch: 3700, train precision: 0.979333, train loss: 20.970643, valid precision: 0.828800, valid loss: 223.596263
epoch: 3701, train precision: 0.985156, train loss: 17.813756, valid precision: 0.831000, valid loss: 218.660926
epoch: 3702, train precision: 0.987533, train loss: 16.963232, valid precision: 0.836600, valid loss: 212.760131
epoch: 3703, train precision: 0.987311, train loss: 17.781879, valid precision: 0.836400, valid loss: 248.749793
epoch: 3704, train precision: 0.978689, train loss: 22.242880, valid precision: 0.834600, valid loss: 227.992813
epoch: 3705, train precision: 0.984533, train loss: 17.992130, valid precision: 0.833800, valid loss: 188.497192
epoch: 3706, train precision: 0.981667, train loss: 20.401686, valid precision: 0.836800, valid loss: 231.097779
epoch: 3707, train precision: 0.983422, train loss: 19.032779, valid precision: 0.835800, valid loss: 219.367015
epoch: 3708, train precision: 0.986711, train loss: 17.518509, valid precision: 0.833800, valid loss: 231.247368
epoch: 3709, train precision: 0.984000, train loss: 18.454161, valid precision: 0.833400, valid loss: 202.524915
epoch: 3710, train precision: 0.985311, train loss: 18.226844, valid precision: 0.837400, valid loss: 203.450505
epoch: 3711, train precision: 0.977267, train loss: 21.349337, valid precision: 0.829600, valid loss: 185.573976
epoch: 3712, train precision: 0.974289, train loss: 22.489554, valid precision: 0.825600, valid loss: 171.968859
epoch: 3713, train precision: 0.978889, train loss: 21.895598, valid precision: 0.835000, valid loss: 216.002814
epoch: 3714, train precision: 0.985444, train loss: 17.857276, valid precision: 0.835200, valid loss: 210.627852
epoch: 3715, train precision: 0.986022, train loss: 17.405160, valid precision: 0.830400, valid loss: 220.247553
epoch: 3716, train precision: 0.983267, train loss: 18.683044, valid precision: 0.831400, valid loss: 196.500740
epoch: 3717, train precision: 0.981133, train loss: 19.624145, valid precision: 0.830400, valid loss: 196.657784
epoch: 3718, train precision: 0.982000, train loss: 20.241286, valid precision: 0.836400, valid loss: 229.739477
epoch: 3719, train precision: 0.982622, train loss: 18.700189, valid precision: 0.832800, valid loss: 192.484669
epoch: 3720, train precision: 0.982800, train loss: 19.256427, valid precision: 0.828400, valid loss: 218.068658
epoch: 3721, train precision: 0.984600, train loss: 18.223262, valid precision: 0.835800, valid loss: 229.885601
epoch: 3722, train precision: 0.984067, train loss: 19.002165, valid precision: 0.835200, valid loss: 195.761528
epoch: 3723, train precision: 0.981644, train loss: 20.854946, valid precision: 0.824400, valid loss: 222.335503
epoch: 3724, train precision: 0.983333, train loss: 18.736651, valid precision: 0.837000, valid loss: 210.215056
epoch: 3725, train precision: 0.987400, train loss: 16.927929, valid precision: 0.842600, valid loss: 197.620679
epoch: 3726, train precision: 0.983111, train loss: 18.827148, valid precision: 0.836200, valid loss: 188.342593
epoch: 3727, train precision: 0.981000, train loss: 20.536808, valid precision: 0.835000, valid loss: 209.804970
epoch: 3728, train precision: 0.981978, train loss: 20.611787, valid precision: 0.833800, valid loss: 227.421265
epoch: 3729, train precision: 0.984422, train loss: 18.463729, valid precision: 0.830000, valid loss: 198.223079
epoch: 3730, train precision: 0.982222, train loss: 19.276533, valid precision: 0.830200, valid loss: 197.724647
epoch: 3731, train precision: 0.982244, train loss: 19.143276, valid precision: 0.830400, valid loss: 216.327833
epoch: 3732, train precision: 0.986244, train loss: 17.680263, valid precision: 0.834000, valid loss: 218.330918
epoch: 3733, train precision: 0.985578, train loss: 18.103681, valid precision: 0.837000, valid loss: 229.066006
epoch: 3734, train precision: 0.986622, train loss: 17.464746, valid precision: 0.834800, valid loss: 221.661297
epoch: 3735, train precision: 0.982644, train loss: 19.766694, valid precision: 0.837200, valid loss: 224.801356
epoch: 3736, train precision: 0.987867, train loss: 17.898162, valid precision: 0.832800, valid loss: 252.188645
epoch: 3737, train precision: 0.984756, train loss: 18.565335, valid precision: 0.836200, valid loss: 233.910562
epoch: 3738, train precision: 0.984600, train loss: 18.483673, valid precision: 0.836800, valid loss: 209.308574
epoch: 3739, train precision: 0.976956, train loss: 21.111017, valid precision: 0.836600, valid loss: 173.434182
epoch: 3740, train precision: 0.980556, train loss: 20.881658, valid precision: 0.838600, valid loss: 209.042533
epoch: 3741, train precision: 0.982644, train loss: 19.930466, valid precision: 0.839200, valid loss: 218.250457
epoch: 3742, train precision: 0.983844, train loss: 19.121493, valid precision: 0.835800, valid loss: 225.400545
epoch: 3743, train precision: 0.984178, train loss: 18.972533, valid precision: 0.832600, valid loss: 212.536445
epoch: 3744, train precision: 0.979067, train loss: 21.833795, valid precision: 0.831400, valid loss: 226.390286
epoch: 3745, train precision: 0.976400, train loss: 21.741135, valid precision: 0.826800, valid loss: 195.465251
epoch: 3746, train precision: 0.980400, train loss: 20.751105, valid precision: 0.834000, valid loss: 205.624466
epoch: 3747, train precision: 0.983644, train loss: 18.598799, valid precision: 0.833400, valid loss: 206.693473
epoch: 3748, train precision: 0.984022, train loss: 18.669183, valid precision: 0.830600, valid loss: 207.904661
epoch: 3749, train precision: 0.986222, train loss: 17.660379, valid precision: 0.835200, valid loss: 225.934917
epoch: 3750, train precision: 0.984178, train loss: 18.825064, valid precision: 0.839200, valid loss: 218.567763
epoch: 3751, train precision: 0.986600, train loss: 17.185151, valid precision: 0.838400, valid loss: 226.219064
epoch: 3752, train precision: 0.982667, train loss: 19.178862, valid precision: 0.833800, valid loss: 210.618510
epoch: 3753, train precision: 0.985822, train loss: 17.320426, valid precision: 0.830800, valid loss: 205.031001
epoch: 3754, train precision: 0.985867, train loss: 17.697012, valid precision: 0.836200, valid loss: 237.559980
epoch: 3755, train precision: 0.985222, train loss: 18.010921, valid precision: 0.839400, valid loss: 197.188060
epoch: 3756, train precision: 0.983933, train loss: 18.753868, valid precision: 0.836400, valid loss: 227.974846
epoch: 3757, train precision: 0.977400, train loss: 22.230404, valid precision: 0.829000, valid loss: 221.709362
epoch: 3758, train precision: 0.984400, train loss: 19.241062, valid precision: 0.836800, valid loss: 235.073214
epoch: 3759, train precision: 0.983600, train loss: 19.087069, valid precision: 0.840400, valid loss: 209.078872
epoch: 3760, train precision: 0.982244, train loss: 20.435262, valid precision: 0.838600, valid loss: 202.666779
epoch: 3761, train precision: 0.980311, train loss: 20.441821, valid precision: 0.833400, valid loss: 210.480486
epoch: 3762, train precision: 0.983844, train loss: 18.581774, valid precision: 0.829600, valid loss: 213.403921
epoch: 3763, train precision: 0.985067, train loss: 19.037921, valid precision: 0.833200, valid loss: 240.089384
epoch: 3764, train precision: 0.984756, train loss: 18.098574, valid precision: 0.840200, valid loss: 204.389343
epoch: 3765, train precision: 0.977689, train loss: 21.067181, valid precision: 0.831800, valid loss: 190.435864
epoch: 3766, train precision: 0.977133, train loss: 21.919910, valid precision: 0.834600, valid loss: 216.849083
epoch: 3767, train precision: 0.982933, train loss: 18.956501, valid precision: 0.841600, valid loss: 196.943272
epoch: 3768, train precision: 0.980067, train loss: 20.184533, valid precision: 0.836600, valid loss: 200.683987
epoch: 3769, train precision: 0.977178, train loss: 21.898822, valid precision: 0.829400, valid loss: 201.596122
epoch: 3770, train precision: 0.984578, train loss: 18.197414, valid precision: 0.835800, valid loss: 217.703408
epoch: 3771, train precision: 0.979356, train loss: 21.440807, valid precision: 0.840800, valid loss: 225.498130
epoch: 3772, train precision: 0.983867, train loss: 18.433670, valid precision: 0.831800, valid loss: 207.734280
epoch: 3773, train precision: 0.983044, train loss: 20.354047, valid precision: 0.833600, valid loss: 246.239923
epoch: 3774, train precision: 0.986356, train loss: 16.901804, valid precision: 0.830400, valid loss: 206.513636
epoch: 3775, train precision: 0.982044, train loss: 19.079125, valid precision: 0.834800, valid loss: 200.149765
epoch: 3776, train precision: 0.983022, train loss: 18.757721, valid precision: 0.833800, valid loss: 195.788236
epoch: 3777, train precision: 0.982289, train loss: 18.875374, valid precision: 0.836000, valid loss: 181.269189
epoch: 3778, train precision: 0.984178, train loss: 18.767837, valid precision: 0.832400, valid loss: 203.451173
epoch: 3779, train precision: 0.983689, train loss: 19.310419, valid precision: 0.834400, valid loss: 227.979915
epoch: 3780, train precision: 0.985511, train loss: 17.345425, valid precision: 0.840600, valid loss: 204.532222
epoch: 3781, train precision: 0.987178, train loss: 17.254569, valid precision: 0.838800, valid loss: 204.807418
epoch: 3782, train precision: 0.983733, train loss: 19.291838, valid precision: 0.835800, valid loss: 225.768269
epoch: 3783, train precision: 0.983667, train loss: 17.958782, valid precision: 0.832800, valid loss: 201.533697
epoch: 3784, train precision: 0.975356, train loss: 22.038947, valid precision: 0.825200, valid loss: 185.288569
epoch: 3785, train precision: 0.982200, train loss: 19.399632, valid precision: 0.837000, valid loss: 198.542692
epoch: 3786, train precision: 0.983867, train loss: 18.257270, valid precision: 0.838800, valid loss: 197.366738
epoch: 3787, train precision: 0.988378, train loss: 16.060510, valid precision: 0.839400, valid loss: 199.082437
epoch: 3788, train precision: 0.976978, train loss: 21.839119, valid precision: 0.831800, valid loss: 202.964034
epoch: 3789, train precision: 0.976244, train loss: 21.913313, valid precision: 0.829200, valid loss: 165.520506
epoch: 3790, train precision: 0.981578, train loss: 20.091205, valid precision: 0.832800, valid loss: 210.111115
epoch: 3791, train precision: 0.984333, train loss: 19.025063, valid precision: 0.836800, valid loss: 225.521333
epoch: 3792, train precision: 0.985711, train loss: 17.412158, valid precision: 0.848800, valid loss: 192.799431
epoch: 3793, train precision: 0.985889, train loss: 18.064371, valid precision: 0.833600, valid loss: 230.496529
epoch: 3794, train precision: 0.981289, train loss: 19.860196, valid precision: 0.837600, valid loss: 184.440495
epoch: 3795, train precision: 0.980800, train loss: 20.537717, valid precision: 0.833600, valid loss: 227.218034
epoch: 3796, train precision: 0.983089, train loss: 19.255824, valid precision: 0.833600, valid loss: 206.665867
epoch: 3797, train precision: 0.986000, train loss: 17.505734, valid precision: 0.835000, valid loss: 229.173737
epoch: 3798, train precision: 0.985444, train loss: 18.485222, valid precision: 0.835400, valid loss: 233.898031
epoch: 3799, train precision: 0.984422, train loss: 17.988069, valid precision: 0.830000, valid loss: 209.649076
epoch: 3800, train precision: 0.984467, train loss: 19.153865, valid precision: 0.843000, valid loss: 230.097535
epoch: 3801, train precision: 0.981578, train loss: 19.895721, valid precision: 0.834800, valid loss: 207.298969
epoch: 3802, train precision: 0.981044, train loss: 19.747980, valid precision: 0.834800, valid loss: 180.146364
epoch: 3803, train precision: 0.981289, train loss: 20.051949, valid precision: 0.838800, valid loss: 210.116749
epoch: 3804, train precision: 0.982044, train loss: 19.771010, valid precision: 0.832000, valid loss: 223.365537
epoch: 3805, train precision: 0.983067, train loss: 19.168150, valid precision: 0.837800, valid loss: 201.106913
epoch: 3806, train precision: 0.975333, train loss: 22.398552, valid precision: 0.835600, valid loss: 178.383825
epoch: 3807, train precision: 0.985622, train loss: 17.191304, valid precision: 0.838200, valid loss: 182.635695
epoch: 3808, train precision: 0.983244, train loss: 19.477571, valid precision: 0.835800, valid loss: 228.907080
epoch: 3809, train precision: 0.981867, train loss: 19.863762, valid precision: 0.836000, valid loss: 187.414613
epoch: 3810, train precision: 0.986689, train loss: 17.273756, valid precision: 0.834200, valid loss: 203.822735
epoch: 3811, train precision: 0.984356, train loss: 18.487769, valid precision: 0.834000, valid loss: 206.241120
epoch: 3812, train precision: 0.986644, train loss: 17.703632, valid precision: 0.839800, valid loss: 219.509059
epoch: 3813, train precision: 0.983489, train loss: 18.880702, valid precision: 0.835200, valid loss: 218.469865
epoch: 3814, train precision: 0.979289, train loss: 20.064390, valid precision: 0.837600, valid loss: 189.342900
epoch: 3815, train precision: 0.985733, train loss: 17.588180, valid precision: 0.840400, valid loss: 225.112677
epoch: 3816, train precision: 0.984178, train loss: 19.346946, valid precision: 0.839200, valid loss: 251.417751
epoch: 3817, train precision: 0.983000, train loss: 18.849579, valid precision: 0.833000, valid loss: 211.569440
epoch: 3818, train precision: 0.986556, train loss: 17.685678, valid precision: 0.840800, valid loss: 212.560108
epoch: 3819, train precision: 0.984044, train loss: 18.116668, valid precision: 0.838800, valid loss: 206.775008
epoch: 3820, train precision: 0.982733, train loss: 18.796049, valid precision: 0.839400, valid loss: 211.964109
epoch: 3821, train precision: 0.990222, train loss: 15.622651, valid precision: 0.846800, valid loss: 230.151056
epoch: 3822, train precision: 0.985333, train loss: 17.721644, valid precision: 0.840200, valid loss: 204.225260
epoch: 3823, train precision: 0.983156, train loss: 19.000413, valid precision: 0.838600, valid loss: 210.995304
epoch: 3824, train precision: 0.981556, train loss: 19.121858, valid precision: 0.831800, valid loss: 208.632046
epoch: 3825, train precision: 0.986422, train loss: 17.783313, valid precision: 0.840200, valid loss: 204.384209
epoch: 3826, train precision: 0.984222, train loss: 18.284621, valid precision: 0.834200, valid loss: 211.340878
epoch: 3827, train precision: 0.986400, train loss: 17.563519, valid precision: 0.834000, valid loss: 212.308177
epoch: 3828, train precision: 0.981622, train loss: 21.193392, valid precision: 0.837400, valid loss: 232.155630
epoch: 3829, train precision: 0.985689, train loss: 18.294889, valid precision: 0.838800, valid loss: 223.232618
epoch: 3830, train precision: 0.980200, train loss: 21.579911, valid precision: 0.833000, valid loss: 225.943306
epoch: 3831, train precision: 0.985111, train loss: 18.316896, valid precision: 0.837600, valid loss: 226.771280
epoch: 3832, train precision: 0.980200, train loss: 20.499830, valid precision: 0.827600, valid loss: 211.433807
epoch: 3833, train precision: 0.986667, train loss: 17.321668, valid precision: 0.831600, valid loss: 209.147419
epoch: 3834, train precision: 0.982311, train loss: 19.895701, valid precision: 0.830800, valid loss: 221.057502
epoch: 3835, train precision: 0.980267, train loss: 19.750666, valid precision: 0.832600, valid loss: 204.415187
epoch: 3836, train precision: 0.981200, train loss: 20.623639, valid precision: 0.841000, valid loss: 228.018174
epoch: 3837, train precision: 0.981067, train loss: 20.034431, valid precision: 0.830000, valid loss: 216.902511
epoch: 3838, train precision: 0.982822, train loss: 19.388419, valid precision: 0.838600, valid loss: 198.577150
epoch: 3839, train precision: 0.983511, train loss: 19.357566, valid precision: 0.838000, valid loss: 224.074197
epoch: 3840, train precision: 0.984178, train loss: 19.179916, valid precision: 0.840800, valid loss: 214.831284
epoch: 3841, train precision: 0.983911, train loss: 18.524064, valid precision: 0.843600, valid loss: 199.598136
epoch: 3842, train precision: 0.989733, train loss: 15.766377, valid precision: 0.848400, valid loss: 221.141979
epoch: 3843, train precision: 0.977778, train loss: 23.221847, valid precision: 0.832600, valid loss: 214.311875
epoch: 3844, train precision: 0.981356, train loss: 19.709518, valid precision: 0.835800, valid loss: 208.034755
epoch: 3845, train precision: 0.985733, train loss: 17.735465, valid precision: 0.839600, valid loss: 209.886906
epoch: 3846, train precision: 0.983822, train loss: 18.628997, valid precision: 0.836400, valid loss: 180.575439
epoch: 3847, train precision: 0.985444, train loss: 18.194662, valid precision: 0.838800, valid loss: 225.898001
epoch: 3848, train precision: 0.979400, train loss: 20.172318, valid precision: 0.834200, valid loss: 186.775671
epoch: 3849, train precision: 0.984733, train loss: 17.854730, valid precision: 0.835600, valid loss: 204.717118
epoch: 3850, train precision: 0.986200, train loss: 17.011946, valid precision: 0.841800, valid loss: 195.786807
epoch: 3851, train precision: 0.979444, train loss: 20.878087, valid precision: 0.828200, valid loss: 201.840710
epoch: 3852, train precision: 0.984400, train loss: 18.979063, valid precision: 0.839400, valid loss: 216.803080
epoch: 3853, train precision: 0.986578, train loss: 17.268389, valid precision: 0.846000, valid loss: 217.216530
epoch: 3854, train precision: 0.979489, train loss: 21.490078, valid precision: 0.831800, valid loss: 214.698168
epoch: 3855, train precision: 0.983311, train loss: 18.456967, valid precision: 0.836200, valid loss: 186.984496
epoch: 3856, train precision: 0.983378, train loss: 18.818415, valid precision: 0.835600, valid loss: 201.114555
epoch: 3857, train precision: 0.979133, train loss: 20.596865, valid precision: 0.831200, valid loss: 195.155067
epoch: 3858, train precision: 0.985400, train loss: 18.158422, valid precision: 0.838600, valid loss: 217.138315
epoch: 3859, train precision: 0.980844, train loss: 19.800332, valid precision: 0.830800, valid loss: 194.119375
epoch: 3860, train precision: 0.984044, train loss: 18.748704, valid precision: 0.834200, valid loss: 210.422526
epoch: 3861, train precision: 0.987044, train loss: 17.760006, valid precision: 0.836000, valid loss: 225.683202
epoch: 3862, train precision: 0.985067, train loss: 18.679599, valid precision: 0.837800, valid loss: 211.893244
epoch: 3863, train precision: 0.980444, train loss: 19.849976, valid precision: 0.834200, valid loss: 178.199890
epoch: 3864, train precision: 0.986778, train loss: 16.866744, valid precision: 0.838200, valid loss: 229.983978
epoch: 3865, train precision: 0.981556, train loss: 19.512271, valid precision: 0.834800, valid loss: 210.894870
epoch: 3866, train precision: 0.984267, train loss: 18.677254, valid precision: 0.836800, valid loss: 223.392313
epoch: 3867, train precision: 0.980533, train loss: 19.377950, valid precision: 0.836600, valid loss: 186.684147
epoch: 3868, train precision: 0.981956, train loss: 20.203926, valid precision: 0.832600, valid loss: 222.274357
epoch: 3869, train precision: 0.986111, train loss: 17.841368, valid precision: 0.832600, valid loss: 213.468276
epoch: 3870, train precision: 0.981089, train loss: 20.389163, valid precision: 0.835600, valid loss: 206.232639
epoch: 3871, train precision: 0.985400, train loss: 18.035226, valid precision: 0.841000, valid loss: 219.652904
epoch: 3872, train precision: 0.982956, train loss: 19.262232, valid precision: 0.836400, valid loss: 186.581181
epoch: 3873, train precision: 0.982756, train loss: 18.882514, valid precision: 0.834000, valid loss: 219.470481
epoch: 3874, train precision: 0.981022, train loss: 20.011830, valid precision: 0.833200, valid loss: 203.773783
epoch: 3875, train precision: 0.984111, train loss: 18.336665, valid precision: 0.838000, valid loss: 196.819897
epoch: 3876, train precision: 0.983289, train loss: 20.550247, valid precision: 0.840200, valid loss: 241.734884
epoch: 3877, train precision: 0.984467, train loss: 18.963421, valid precision: 0.841400, valid loss: 225.824382
epoch: 3878, train precision: 0.983844, train loss: 18.799294, valid precision: 0.838400, valid loss: 213.356599
epoch: 3879, train precision: 0.978267, train loss: 22.310549, valid precision: 0.829800, valid loss: 237.020800
epoch: 3880, train precision: 0.984200, train loss: 19.047007, valid precision: 0.832600, valid loss: 233.229943
epoch: 3881, train precision: 0.985089, train loss: 17.989073, valid precision: 0.836000, valid loss: 205.115919
epoch: 3882, train precision: 0.986378, train loss: 17.743739, valid precision: 0.837800, valid loss: 202.318063
epoch: 3883, train precision: 0.984822, train loss: 18.105545, valid precision: 0.831800, valid loss: 205.072037
epoch: 3884, train precision: 0.982133, train loss: 19.721828, valid precision: 0.836600, valid loss: 210.173518
epoch: 3885, train precision: 0.984400, train loss: 18.810132, valid precision: 0.838400, valid loss: 214.661013
epoch: 3886, train precision: 0.977711, train loss: 22.302084, valid precision: 0.829800, valid loss: 209.039560
epoch: 3887, train precision: 0.978511, train loss: 20.765813, valid precision: 0.822600, valid loss: 180.023431
epoch: 3888, train precision: 0.982222, train loss: 20.666507, valid precision: 0.834400, valid loss: 250.045892
epoch: 3889, train precision: 0.979556, train loss: 19.931564, valid precision: 0.833800, valid loss: 180.962573
epoch: 3890, train precision: 0.985800, train loss: 18.479316, valid precision: 0.839800, valid loss: 212.715289
epoch: 3891, train precision: 0.985556, train loss: 18.903516, valid precision: 0.835200, valid loss: 226.727319
epoch: 3892, train precision: 0.985489, train loss: 18.174934, valid precision: 0.838000, valid loss: 216.961058
epoch: 3893, train precision: 0.983000, train loss: 20.206302, valid precision: 0.837000, valid loss: 224.245635
epoch: 3894, train precision: 0.984578, train loss: 18.192500, valid precision: 0.833400, valid loss: 204.412226
epoch: 3895, train precision: 0.985911, train loss: 17.555413, valid precision: 0.837600, valid loss: 204.396228
epoch: 3896, train precision: 0.984133, train loss: 18.623653, valid precision: 0.836800, valid loss: 212.509594
epoch: 3897, train precision: 0.986800, train loss: 16.825314, valid precision: 0.839000, valid loss: 208.447732
epoch: 3898, train precision: 0.985200, train loss: 18.108664, valid precision: 0.838200, valid loss: 228.883718
epoch: 3899, train precision: 0.983800, train loss: 18.645652, valid precision: 0.830800, valid loss: 222.178662
epoch: 3900, train precision: 0.984089, train loss: 19.322245, valid precision: 0.827000, valid loss: 220.873553
epoch: 3901, train precision: 0.983667, train loss: 19.229138, valid precision: 0.831600, valid loss: 219.134317
epoch: 3902, train precision: 0.982000, train loss: 20.431006, valid precision: 0.831800, valid loss: 225.175345
epoch: 3903, train precision: 0.984444, train loss: 18.321233, valid precision: 0.835800, valid loss: 202.730600
epoch: 3904, train precision: 0.984200, train loss: 18.702004, valid precision: 0.829600, valid loss: 220.889368
epoch: 3905, train precision: 0.980644, train loss: 19.842193, valid precision: 0.829200, valid loss: 196.103690
epoch: 3906, train precision: 0.982778, train loss: 19.159015, valid precision: 0.832000, valid loss: 218.174613
epoch: 3907, train precision: 0.983311, train loss: 19.484518, valid precision: 0.834200, valid loss: 213.637782
epoch: 3908, train precision: 0.985822, train loss: 17.477547, valid precision: 0.836400, valid loss: 211.889820
epoch: 3909, train precision: 0.984622, train loss: 17.725931, valid precision: 0.843200, valid loss: 196.233888
epoch: 3910, train precision: 0.979578, train loss: 21.021957, valid precision: 0.824200, valid loss: 210.314425
epoch: 3911, train precision: 0.985533, train loss: 18.207383, valid precision: 0.832400, valid loss: 220.660106
epoch: 3912, train precision: 0.983667, train loss: 18.506499, valid precision: 0.830200, valid loss: 223.761218
epoch: 3913, train precision: 0.983844, train loss: 19.157493, valid precision: 0.831400, valid loss: 221.477125
epoch: 3914, train precision: 0.980689, train loss: 19.744115, valid precision: 0.832800, valid loss: 190.867719
epoch: 3915, train precision: 0.983511, train loss: 18.645039, valid precision: 0.835600, valid loss: 202.535273
epoch: 3916, train precision: 0.982022, train loss: 19.687549, valid precision: 0.839600, valid loss: 221.119569
epoch: 3917, train precision: 0.981489, train loss: 19.578154, valid precision: 0.833400, valid loss: 192.783844
epoch: 3918, train precision: 0.984778, train loss: 18.724043, valid precision: 0.839200, valid loss: 201.364110
epoch: 3919, train precision: 0.981844, train loss: 20.022849, valid precision: 0.829000, valid loss: 206.061364
epoch: 3920, train precision: 0.981844, train loss: 20.844320, valid precision: 0.831800, valid loss: 255.485592
epoch: 3921, train precision: 0.986733, train loss: 17.480000, valid precision: 0.839200, valid loss: 242.331173
epoch: 3922, train precision: 0.983511, train loss: 18.989717, valid precision: 0.837800, valid loss: 210.951664
epoch: 3923, train precision: 0.982511, train loss: 20.272232, valid precision: 0.837400, valid loss: 239.466174
epoch: 3924, train precision: 0.983667, train loss: 19.579670, valid precision: 0.835800, valid loss: 244.500030
epoch: 3925, train precision: 0.982467, train loss: 18.678585, valid precision: 0.832000, valid loss: 196.719721
epoch: 3926, train precision: 0.979533, train loss: 21.452249, valid precision: 0.828200, valid loss: 226.070051
epoch: 3927, train precision: 0.985244, train loss: 18.053390, valid precision: 0.838600, valid loss: 217.836753
epoch: 3928, train precision: 0.983778, train loss: 18.849589, valid precision: 0.838400, valid loss: 215.845954
epoch: 3929, train precision: 0.981667, train loss: 19.902564, valid precision: 0.833000, valid loss: 202.649960
epoch: 3930, train precision: 0.981622, train loss: 19.521719, valid precision: 0.835400, valid loss: 200.367899
epoch: 3931, train precision: 0.983867, train loss: 18.624194, valid precision: 0.836600, valid loss: 215.474741
epoch: 3932, train precision: 0.979578, train loss: 20.450582, valid precision: 0.834000, valid loss: 194.364047
epoch: 3933, train precision: 0.984289, train loss: 18.944696, valid precision: 0.831800, valid loss: 228.195650
epoch: 3934, train precision: 0.986400, train loss: 17.677536, valid precision: 0.836800, valid loss: 225.561947
epoch: 3935, train precision: 0.980711, train loss: 20.139068, valid precision: 0.836200, valid loss: 212.762033
epoch: 3936, train precision: 0.983378, train loss: 18.907372, valid precision: 0.834600, valid loss: 217.698959
epoch: 3937, train precision: 0.984778, train loss: 18.136488, valid precision: 0.831000, valid loss: 201.381382
epoch: 3938, train precision: 0.978889, train loss: 21.161519, valid precision: 0.826400, valid loss: 205.824327
epoch: 3939, train precision: 0.983978, train loss: 18.331595, valid precision: 0.834000, valid loss: 191.470623
epoch: 3940, train precision: 0.985800, train loss: 17.790413, valid precision: 0.839400, valid loss: 200.977122
epoch: 3941, train precision: 0.986533, train loss: 17.683051, valid precision: 0.834600, valid loss: 207.846860
epoch: 3942, train precision: 0.982956, train loss: 18.631510, valid precision: 0.837400, valid loss: 177.799677
epoch: 3943, train precision: 0.983467, train loss: 19.589412, valid precision: 0.835600, valid loss: 222.991619
epoch: 3944, train precision: 0.980911, train loss: 19.804840, valid precision: 0.831400, valid loss: 195.242061
epoch: 3945, train precision: 0.977533, train loss: 20.911509, valid precision: 0.830400, valid loss: 181.967626
epoch: 3946, train precision: 0.981156, train loss: 20.913368, valid precision: 0.833600, valid loss: 217.714030
epoch: 3947, train precision: 0.986089, train loss: 18.137348, valid precision: 0.833800, valid loss: 229.311972
epoch: 3948, train precision: 0.987000, train loss: 17.152967, valid precision: 0.844200, valid loss: 228.253021
epoch: 3949, train precision: 0.982978, train loss: 18.732926, valid precision: 0.836600, valid loss: 226.221696
epoch: 3950, train precision: 0.985978, train loss: 17.931386, valid precision: 0.840800, valid loss: 211.288125
epoch: 3951, train precision: 0.985911, train loss: 17.977017, valid precision: 0.839200, valid loss: 219.590336
epoch: 3952, train precision: 0.983444, train loss: 19.434743, valid precision: 0.833400, valid loss: 231.066970
epoch: 3953, train precision: 0.986000, train loss: 18.227499, valid precision: 0.836000, valid loss: 224.617464
epoch: 3954, train precision: 0.982267, train loss: 19.364110, valid precision: 0.831600, valid loss: 194.325645
epoch: 3955, train precision: 0.984422, train loss: 19.496915, valid precision: 0.830800, valid loss: 220.154441
epoch: 3956, train precision: 0.987711, train loss: 16.796630, valid precision: 0.837800, valid loss: 224.989463
epoch: 3957, train precision: 0.986067, train loss: 17.747258, valid precision: 0.839600, valid loss: 216.101216
epoch: 3958, train precision: 0.975178, train loss: 22.606930, valid precision: 0.832200, valid loss: 180.442518
epoch: 3959, train precision: 0.979022, train loss: 20.872320, valid precision: 0.832000, valid loss: 215.202415
epoch: 3960, train precision: 0.981556, train loss: 19.548252, valid precision: 0.837400, valid loss: 204.431107
epoch: 3961, train precision: 0.983600, train loss: 18.648126, valid precision: 0.835400, valid loss: 197.353000
epoch: 3962, train precision: 0.984311, train loss: 18.517526, valid precision: 0.835600, valid loss: 225.389930
epoch: 3963, train precision: 0.977933, train loss: 21.942779, valid precision: 0.835800, valid loss: 196.227307
epoch: 3964, train precision: 0.983689, train loss: 19.350393, valid precision: 0.830000, valid loss: 235.283528
epoch: 3965, train precision: 0.983578, train loss: 18.702229, valid precision: 0.833800, valid loss: 211.919663
epoch: 3966, train precision: 0.982822, train loss: 20.261726, valid precision: 0.833000, valid loss: 229.352697
epoch: 3967, train precision: 0.983133, train loss: 19.062653, valid precision: 0.834800, valid loss: 225.333563
epoch: 3968, train precision: 0.986311, train loss: 17.489616, valid precision: 0.838400, valid loss: 217.700647
epoch: 3969, train precision: 0.981489, train loss: 19.726259, valid precision: 0.832400, valid loss: 196.459845
epoch: 3970, train precision: 0.986933, train loss: 17.138591, valid precision: 0.837400, valid loss: 230.915997
epoch: 3971, train precision: 0.980756, train loss: 19.715863, valid precision: 0.837800, valid loss: 198.841378
epoch: 3972, train precision: 0.982489, train loss: 18.712481, valid precision: 0.831800, valid loss: 180.479498
epoch: 3973, train precision: 0.984911, train loss: 19.414991, valid precision: 0.836000, valid loss: 238.710240
epoch: 3974, train precision: 0.983689, train loss: 19.069936, valid precision: 0.832600, valid loss: 229.596978
epoch: 3975, train precision: 0.977733, train loss: 21.986585, valid precision: 0.831800, valid loss: 197.451951
epoch: 3976, train precision: 0.983489, train loss: 19.726465, valid precision: 0.833600, valid loss: 251.364447
epoch: 3977, train precision: 0.982778, train loss: 19.123445, valid precision: 0.837400, valid loss: 199.426154
epoch: 3978, train precision: 0.983378, train loss: 18.456945, valid precision: 0.831600, valid loss: 189.316391
epoch: 3979, train precision: 0.979289, train loss: 20.061137, valid precision: 0.827600, valid loss: 181.793893
epoch: 3980, train precision: 0.977511, train loss: 21.597648, valid precision: 0.831000, valid loss: 203.341357
epoch: 3981, train precision: 0.987244, train loss: 16.798164, valid precision: 0.843400, valid loss: 207.545658
epoch: 3982, train precision: 0.983111, train loss: 19.342916, valid precision: 0.830400, valid loss: 226.136954
epoch: 3983, train precision: 0.982600, train loss: 19.700931, valid precision: 0.836200, valid loss: 207.061310
epoch: 3984, train precision: 0.987822, train loss: 16.883649, valid precision: 0.839600, valid loss: 214.079384
epoch: 3985, train precision: 0.982444, train loss: 19.068512, valid precision: 0.836200, valid loss: 211.716192
epoch: 3986, train precision: 0.978089, train loss: 21.223604, valid precision: 0.839200, valid loss: 215.341267
epoch: 3987, train precision: 0.980200, train loss: 20.920447, valid precision: 0.832000, valid loss: 222.995738
epoch: 3988, train precision: 0.981778, train loss: 19.918617, valid precision: 0.827200, valid loss: 214.408980
epoch: 3989, train precision: 0.985022, train loss: 18.637591, valid precision: 0.831200, valid loss: 225.194830
epoch: 3990, train precision: 0.981667, train loss: 20.497908, valid precision: 0.831400, valid loss: 219.635036
epoch: 3991, train precision: 0.985822, train loss: 18.571695, valid precision: 0.838200, valid loss: 276.502893
epoch: 3992, train precision: 0.980800, train loss: 20.738508, valid precision: 0.831600, valid loss: 212.309957
epoch: 3993, train precision: 0.982000, train loss: 19.695643, valid precision: 0.829000, valid loss: 245.640469
epoch: 3994, train precision: 0.984378, train loss: 18.673066, valid precision: 0.833400, valid loss: 215.094776
epoch: 3995, train precision: 0.984067, train loss: 18.776951, valid precision: 0.832800, valid loss: 228.198946
epoch: 3996, train precision: 0.981667, train loss: 19.366806, valid precision: 0.837000, valid loss: 213.232915
epoch: 3997, train precision: 0.981044, train loss: 20.162893, valid precision: 0.826800, valid loss: 221.477233
epoch: 3998, train precision: 0.985667, train loss: 17.445237, valid precision: 0.833400, valid loss: 214.462165
epoch: 3999, train precision: 0.978289, train loss: 21.543128, valid precision: 0.830600, valid loss: 202.520204
epoch: 4000, train precision: 0.987111, train loss: 17.449703, valid precision: 0.837200, valid loss: 217.950319
epoch: 4001, train precision: 0.976578, train loss: 22.949678, valid precision: 0.821000, valid loss: 214.998109
epoch: 4002, train precision: 0.986467, train loss: 17.849104, valid precision: 0.834000, valid loss: 257.493965
epoch: 4003, train precision: 0.982556, train loss: 19.315707, valid precision: 0.835000, valid loss: 216.327939
epoch: 4004, train precision: 0.985867, train loss: 17.053067, valid precision: 0.833800, valid loss: 215.475493
epoch: 4005, train precision: 0.981733, train loss: 19.375665, valid precision: 0.834400, valid loss: 212.521675
epoch: 4006, train precision: 0.985067, train loss: 18.152231, valid precision: 0.837000, valid loss: 199.138214
epoch: 4007, train precision: 0.985400, train loss: 18.116620, valid precision: 0.836000, valid loss: 241.494431
epoch: 4008, train precision: 0.986756, train loss: 16.956755, valid precision: 0.842200, valid loss: 219.489361
epoch: 4009, train precision: 0.983978, train loss: 18.104602, valid precision: 0.838000, valid loss: 193.803466
epoch: 4010, train precision: 0.984467, train loss: 18.975150, valid precision: 0.838000, valid loss: 234.160660
epoch: 4011, train precision: 0.985667, train loss: 18.339027, valid precision: 0.837800, valid loss: 247.479541
epoch: 4012, train precision: 0.986822, train loss: 17.113012, valid precision: 0.837800, valid loss: 214.448484
epoch: 4013, train precision: 0.985156, train loss: 18.393557, valid precision: 0.838200, valid loss: 237.637367
epoch: 4014, train precision: 0.982978, train loss: 19.330615, valid precision: 0.836800, valid loss: 214.866467
epoch: 4015, train precision: 0.983422, train loss: 19.367422, valid precision: 0.840200, valid loss: 227.799358
epoch: 4016, train precision: 0.981489, train loss: 20.262433, valid precision: 0.832600, valid loss: 218.952490
epoch: 4017, train precision: 0.985911, train loss: 18.335631, valid precision: 0.836400, valid loss: 243.682292
epoch: 4018, train precision: 0.985644, train loss: 17.848920, valid precision: 0.839400, valid loss: 212.724906
epoch: 4019, train precision: 0.986622, train loss: 17.506349, valid precision: 0.835400, valid loss: 211.276362
epoch: 4020, train precision: 0.984867, train loss: 17.858631, valid precision: 0.841200, valid loss: 204.586602
epoch: 4021, train precision: 0.986378, train loss: 17.713394, valid precision: 0.843800, valid loss: 226.978233
epoch: 4022, train precision: 0.982844, train loss: 19.687890, valid precision: 0.839800, valid loss: 247.821972
epoch: 4023, train precision: 0.982778, train loss: 18.827641, valid precision: 0.836000, valid loss: 196.074289
epoch: 4024, train precision: 0.977333, train loss: 22.134231, valid precision: 0.832800, valid loss: 209.271191
epoch: 4025, train precision: 0.986378, train loss: 17.429855, valid precision: 0.841000, valid loss: 237.202706
epoch: 4026, train precision: 0.982067, train loss: 19.363187, valid precision: 0.833600, valid loss: 217.942872
epoch: 4027, train precision: 0.986467, train loss: 17.619346, valid precision: 0.845800, valid loss: 234.962869
epoch: 4028, train precision: 0.980844, train loss: 21.013045, valid precision: 0.834400, valid loss: 225.755726
epoch: 4029, train precision: 0.980289, train loss: 20.757971, valid precision: 0.830600, valid loss: 219.911687
epoch: 4030, train precision: 0.987022, train loss: 16.749909, valid precision: 0.839400, valid loss: 211.543793
epoch: 4031, train precision: 0.984444, train loss: 18.168718, valid precision: 0.841600, valid loss: 218.551491
epoch: 4032, train precision: 0.981689, train loss: 20.163074, valid precision: 0.828800, valid loss: 229.472621
epoch: 4033, train precision: 0.985022, train loss: 18.140078, valid precision: 0.838400, valid loss: 238.542133
epoch: 4034, train precision: 0.981867, train loss: 20.334270, valid precision: 0.833800, valid loss: 233.651951
epoch: 4035, train precision: 0.984533, train loss: 18.472991, valid precision: 0.835000, valid loss: 213.888577
epoch: 4036, train precision: 0.986711, train loss: 17.408863, valid precision: 0.836000, valid loss: 223.419013
epoch: 4037, train precision: 0.981467, train loss: 19.922899, valid precision: 0.836400, valid loss: 216.835898
epoch: 4038, train precision: 0.981644, train loss: 19.896586, valid precision: 0.833000, valid loss: 226.433680
epoch: 4039, train precision: 0.982800, train loss: 19.792245, valid precision: 0.835000, valid loss: 230.565527
epoch: 4040, train precision: 0.984600, train loss: 19.141661, valid precision: 0.841400, valid loss: 228.482018
epoch: 4041, train precision: 0.982489, train loss: 19.011191, valid precision: 0.832600, valid loss: 216.951411
epoch: 4042, train precision: 0.984111, train loss: 19.053465, valid precision: 0.839000, valid loss: 226.700108
epoch: 4043, train precision: 0.982133, train loss: 19.987150, valid precision: 0.831000, valid loss: 213.829759
epoch: 4044, train precision: 0.984244, train loss: 18.371288, valid precision: 0.832000, valid loss: 208.433800
epoch: 4045, train precision: 0.974289, train loss: 23.546873, valid precision: 0.825600, valid loss: 210.061929
epoch: 4046, train precision: 0.980244, train loss: 21.090803, valid precision: 0.828400, valid loss: 228.906350
epoch: 4047, train precision: 0.983222, train loss: 19.192691, valid precision: 0.831600, valid loss: 221.725879
epoch: 4048, train precision: 0.981756, train loss: 19.635426, valid precision: 0.832400, valid loss: 227.131085
epoch: 4049, train precision: 0.981956, train loss: 20.758166, valid precision: 0.829400, valid loss: 226.798174
epoch: 4050, train precision: 0.983222, train loss: 19.084752, valid precision: 0.830000, valid loss: 218.511265
epoch: 4051, train precision: 0.984156, train loss: 18.849587, valid precision: 0.834400, valid loss: 212.041908
epoch: 4052, train precision: 0.981467, train loss: 20.103653, valid precision: 0.833200, valid loss: 221.739629
epoch: 4053, train precision: 0.982867, train loss: 18.984065, valid precision: 0.837800, valid loss: 210.891543
epoch: 4054, train precision: 0.983222, train loss: 19.505314, valid precision: 0.836000, valid loss: 233.526973
epoch: 4055, train precision: 0.981956, train loss: 19.936028, valid precision: 0.840400, valid loss: 199.638942
epoch: 4056, train precision: 0.983844, train loss: 18.896446, valid precision: 0.836800, valid loss: 221.782888
epoch: 4057, train precision: 0.985489, train loss: 17.849557, valid precision: 0.840400, valid loss: 228.387057
epoch: 4058, train precision: 0.985111, train loss: 17.539278, valid precision: 0.843600, valid loss: 201.372281
epoch: 4059, train precision: 0.980356, train loss: 20.318158, valid precision: 0.833600, valid loss: 209.840273
epoch: 4060, train precision: 0.983267, train loss: 18.857625, valid precision: 0.836200, valid loss: 222.132527
epoch: 4061, train precision: 0.983378, train loss: 19.518693, valid precision: 0.836600, valid loss: 216.403564
epoch: 4062, train precision: 0.984667, train loss: 18.254774, valid precision: 0.834600, valid loss: 197.129236
epoch: 4063, train precision: 0.972800, train loss: 24.209625, valid precision: 0.827200, valid loss: 197.298907
epoch: 4064, train precision: 0.983756, train loss: 19.346096, valid precision: 0.837000, valid loss: 235.556853
epoch: 4065, train precision: 0.983356, train loss: 19.128172, valid precision: 0.835600, valid loss: 211.011587
epoch: 4066, train precision: 0.980956, train loss: 19.779292, valid precision: 0.825800, valid loss: 189.468599
epoch: 4067, train precision: 0.988311, train loss: 17.149151, valid precision: 0.838200, valid loss: 237.028233
epoch: 4068, train precision: 0.981911, train loss: 19.612838, valid precision: 0.836200, valid loss: 209.339179
epoch: 4069, train precision: 0.983267, train loss: 18.941912, valid precision: 0.832600, valid loss: 209.304683
epoch: 4070, train precision: 0.982733, train loss: 19.099786, valid precision: 0.830800, valid loss: 200.514407
epoch: 4071, train precision: 0.981267, train loss: 19.496733, valid precision: 0.835200, valid loss: 191.143827
epoch: 4072, train precision: 0.980022, train loss: 19.631539, valid precision: 0.832600, valid loss: 181.877465
epoch: 4073, train precision: 0.982822, train loss: 19.106570, valid precision: 0.837800, valid loss: 201.282449
epoch: 4074, train precision: 0.985778, train loss: 17.944074, valid precision: 0.837000, valid loss: 215.305806
epoch: 4075, train precision: 0.985533, train loss: 18.561930, valid precision: 0.838200, valid loss: 232.925560
epoch: 4076, train precision: 0.985111, train loss: 17.983405, valid precision: 0.841200, valid loss: 199.256196
epoch: 4077, train precision: 0.984600, train loss: 18.317119, valid precision: 0.837800, valid loss: 187.972896
epoch: 4078, train precision: 0.983311, train loss: 20.330324, valid precision: 0.837000, valid loss: 239.666179
epoch: 4079, train precision: 0.979778, train loss: 20.967493, valid precision: 0.833400, valid loss: 212.030724
epoch: 4080, train precision: 0.981911, train loss: 21.368201, valid precision: 0.841200, valid loss: 249.744342
epoch: 4081, train precision: 0.979556, train loss: 20.448932, valid precision: 0.833200, valid loss: 197.683159
epoch: 4082, train precision: 0.984022, train loss: 18.829136, valid precision: 0.835400, valid loss: 190.886502
epoch: 4083, train precision: 0.977511, train loss: 22.122702, valid precision: 0.825800, valid loss: 181.352887
epoch: 4084, train precision: 0.978689, train loss: 20.581085, valid precision: 0.833000, valid loss: 174.145040
epoch: 4085, train precision: 0.981644, train loss: 20.260680, valid precision: 0.831800, valid loss: 211.264330
epoch: 4086, train precision: 0.979311, train loss: 20.791827, valid precision: 0.831800, valid loss: 192.834912
epoch: 4087, train precision: 0.980911, train loss: 19.765747, valid precision: 0.833600, valid loss: 198.850362
epoch: 4088, train precision: 0.986422, train loss: 17.728295, valid precision: 0.839600, valid loss: 236.380779
epoch: 4089, train precision: 0.984867, train loss: 18.493228, valid precision: 0.837600, valid loss: 213.442496
epoch: 4090, train precision: 0.980044, train loss: 21.618943, valid precision: 0.833800, valid loss: 226.740953
epoch: 4091, train precision: 0.979933, train loss: 21.142023, valid precision: 0.827400, valid loss: 192.725105
epoch: 4092, train precision: 0.980644, train loss: 20.823678, valid precision: 0.833600, valid loss: 214.859013
epoch: 4093, train precision: 0.985222, train loss: 17.958007, valid precision: 0.840000, valid loss: 199.775324
epoch: 4094, train precision: 0.986333, train loss: 17.486828, valid precision: 0.837600, valid loss: 192.971494
epoch: 4095, train precision: 0.984089, train loss: 18.326044, valid precision: 0.840400, valid loss: 192.724831
epoch: 4096, train precision: 0.983667, train loss: 19.703506, valid precision: 0.844000, valid loss: 234.637553
epoch: 4097, train precision: 0.985089, train loss: 18.247688, valid precision: 0.838400, valid loss: 228.481450
epoch: 4098, train precision: 0.982667, train loss: 19.323420, valid precision: 0.839400, valid loss: 210.870586
epoch: 4099, train precision: 0.983378, train loss: 19.723534, valid precision: 0.838000, valid loss: 220.753910
epoch: 4100, train precision: 0.982333, train loss: 18.815844, valid precision: 0.835400, valid loss: 186.475331
epoch: 4101, train precision: 0.982400, train loss: 19.910269, valid precision: 0.833800, valid loss: 178.973774
epoch: 4102, train precision: 0.985133, train loss: 18.266956, valid precision: 0.836800, valid loss: 210.182874
epoch: 4103, train precision: 0.982333, train loss: 19.794479, valid precision: 0.831000, valid loss: 216.899409
epoch: 4104, train precision: 0.981667, train loss: 19.341576, valid precision: 0.832400, valid loss: 188.325992
epoch: 4105, train precision: 0.978911, train loss: 21.962728, valid precision: 0.834000, valid loss: 215.329352
epoch: 4106, train precision: 0.982689, train loss: 19.728991, valid precision: 0.834000, valid loss: 215.995904
epoch: 4107, train precision: 0.985133, train loss: 17.845372, valid precision: 0.838400, valid loss: 192.049429
epoch: 4108, train precision: 0.983422, train loss: 18.594566, valid precision: 0.835600, valid loss: 206.777970
epoch: 4109, train precision: 0.979133, train loss: 21.814383, valid precision: 0.829000, valid loss: 219.959204
epoch: 4110, train precision: 0.984200, train loss: 18.238567, valid precision: 0.837200, valid loss: 208.119035
epoch: 4111, train precision: 0.981244, train loss: 19.825712, valid precision: 0.830200, valid loss: 188.498490
epoch: 4112, train precision: 0.985289, train loss: 17.710480, valid precision: 0.832800, valid loss: 204.221825
epoch: 4113, train precision: 0.975444, train loss: 22.028649, valid precision: 0.832400, valid loss: 195.246140
epoch: 4114, train precision: 0.981556, train loss: 20.995685, valid precision: 0.824000, valid loss: 218.580569
epoch: 4115, train precision: 0.979467, train loss: 21.123322, valid precision: 0.831400, valid loss: 195.243626
epoch: 4116, train precision: 0.979889, train loss: 19.959926, valid precision: 0.832000, valid loss: 192.049202
epoch: 4117, train precision: 0.980756, train loss: 20.132996, valid precision: 0.837800, valid loss: 201.699758
epoch: 4118, train precision: 0.983578, train loss: 19.039678, valid precision: 0.834600, valid loss: 212.391538
epoch: 4119, train precision: 0.981978, train loss: 19.487655, valid precision: 0.832600, valid loss: 196.243529
epoch: 4120, train precision: 0.985689, train loss: 18.160528, valid precision: 0.844400, valid loss: 197.635657
epoch: 4121, train precision: 0.983511, train loss: 18.926946, valid precision: 0.834400, valid loss: 205.797354
epoch: 4122, train precision: 0.982911, train loss: 22.001016, valid precision: 0.832400, valid loss: 242.694353
epoch: 4123, train precision: 0.981311, train loss: 19.543997, valid precision: 0.834400, valid loss: 207.184251
epoch: 4124, train precision: 0.978133, train loss: 21.317012, valid precision: 0.828600, valid loss: 211.524025
epoch: 4125, train precision: 0.987200, train loss: 17.280365, valid precision: 0.837600, valid loss: 234.171860
epoch: 4126, train precision: 0.983356, train loss: 19.181808, valid precision: 0.833400, valid loss: 214.347623
epoch: 4127, train precision: 0.985267, train loss: 18.600372, valid precision: 0.838600, valid loss: 221.527551
epoch: 4128, train precision: 0.983222, train loss: 19.361202, valid precision: 0.832600, valid loss: 216.194248
epoch: 4129, train precision: 0.985933, train loss: 17.794935, valid precision: 0.831400, valid loss: 210.656402
epoch: 4130, train precision: 0.981178, train loss: 20.551982, valid precision: 0.826600, valid loss: 216.614945
epoch: 4131, train precision: 0.986400, train loss: 17.550824, valid precision: 0.834400, valid loss: 222.216150
epoch: 4132, train precision: 0.982667, train loss: 19.842468, valid precision: 0.831000, valid loss: 234.750869
epoch: 4133, train precision: 0.981067, train loss: 20.928415, valid precision: 0.832600, valid loss: 217.004754
epoch: 4134, train precision: 0.986867, train loss: 17.201764, valid precision: 0.837400, valid loss: 195.759320
epoch: 4135, train precision: 0.984111, train loss: 18.913785, valid precision: 0.828400, valid loss: 231.483088
epoch: 4136, train precision: 0.983756, train loss: 19.754565, valid precision: 0.831400, valid loss: 235.860071
epoch: 4137, train precision: 0.981889, train loss: 19.236161, valid precision: 0.829600, valid loss: 207.276101
epoch: 4138, train precision: 0.985800, train loss: 18.764634, valid precision: 0.838400, valid loss: 220.470778
epoch: 4139, train precision: 0.983756, train loss: 19.243780, valid precision: 0.835200, valid loss: 213.232324
epoch: 4140, train precision: 0.979733, train loss: 22.486915, valid precision: 0.828800, valid loss: 250.204765
epoch: 4141, train precision: 0.983400, train loss: 19.225913, valid precision: 0.828400, valid loss: 215.620098
epoch: 4142, train precision: 0.978800, train loss: 20.947846, valid precision: 0.826800, valid loss: 186.398016
epoch: 4143, train precision: 0.983778, train loss: 18.849522, valid precision: 0.835800, valid loss: 215.918498
epoch: 4144, train precision: 0.982622, train loss: 19.578649, valid precision: 0.832800, valid loss: 220.265237
epoch: 4145, train precision: 0.977622, train loss: 21.576765, valid precision: 0.830000, valid loss: 185.366251
epoch: 4146, train precision: 0.985933, train loss: 17.544748, valid precision: 0.833600, valid loss: 210.528886
epoch: 4147, train precision: 0.984267, train loss: 18.808828, valid precision: 0.837400, valid loss: 216.365747
epoch: 4148, train precision: 0.982622, train loss: 19.595924, valid precision: 0.831000, valid loss: 216.471172
epoch: 4149, train precision: 0.984022, train loss: 18.828291, valid precision: 0.832200, valid loss: 244.542992
epoch: 4150, train precision: 0.984733, train loss: 18.308272, valid precision: 0.831400, valid loss: 208.944353
epoch: 4151, train precision: 0.985800, train loss: 17.916017, valid precision: 0.831400, valid loss: 222.758187
epoch: 4152, train precision: 0.985222, train loss: 18.126836, valid precision: 0.837600, valid loss: 229.577098
epoch: 4153, train precision: 0.987022, train loss: 17.361601, valid precision: 0.837600, valid loss: 197.820844
epoch: 4154, train precision: 0.981289, train loss: 20.046439, valid precision: 0.831200, valid loss: 217.643010
epoch: 4155, train precision: 0.980711, train loss: 20.027198, valid precision: 0.831000, valid loss: 214.435217
epoch: 4156, train precision: 0.980222, train loss: 20.121381, valid precision: 0.831600, valid loss: 201.068419
epoch: 4157, train precision: 0.982644, train loss: 20.129824, valid precision: 0.828200, valid loss: 235.241412
epoch: 4158, train precision: 0.976667, train loss: 22.798961, valid precision: 0.830600, valid loss: 229.664979
epoch: 4159, train precision: 0.984489, train loss: 18.947477, valid precision: 0.837000, valid loss: 233.019803
epoch: 4160, train precision: 0.976444, train loss: 21.919718, valid precision: 0.828000, valid loss: 198.529126
epoch: 4161, train precision: 0.984178, train loss: 18.479354, valid precision: 0.834400, valid loss: 198.586639
epoch: 4162, train precision: 0.983578, train loss: 19.039667, valid precision: 0.833800, valid loss: 223.904989
epoch: 4163, train precision: 0.986622, train loss: 17.983734, valid precision: 0.840000, valid loss: 232.879618
epoch: 4164, train precision: 0.982089, train loss: 19.132933, valid precision: 0.832000, valid loss: 207.533601
epoch: 4165, train precision: 0.987178, train loss: 16.826702, valid precision: 0.840600, valid loss: 225.997095
epoch: 4166, train precision: 0.982822, train loss: 18.623729, valid precision: 0.838600, valid loss: 196.392950
epoch: 4167, train precision: 0.986044, train loss: 17.369310, valid precision: 0.836600, valid loss: 220.254580
epoch: 4168, train precision: 0.982889, train loss: 19.170652, valid precision: 0.831200, valid loss: 201.249248
epoch: 4169, train precision: 0.982200, train loss: 19.733300, valid precision: 0.833800, valid loss: 215.592976
epoch: 4170, train precision: 0.982533, train loss: 18.718674, valid precision: 0.831000, valid loss: 182.181918
epoch: 4171, train precision: 0.986356, train loss: 17.457639, valid precision: 0.832800, valid loss: 203.877410
epoch: 4172, train precision: 0.984689, train loss: 18.530138, valid precision: 0.835800, valid loss: 209.103761
epoch: 4173, train precision: 0.985778, train loss: 18.690901, valid precision: 0.838200, valid loss: 241.190345
epoch: 4174, train precision: 0.981444, train loss: 19.822444, valid precision: 0.834000, valid loss: 200.335694
epoch: 4175, train precision: 0.979111, train loss: 20.923696, valid precision: 0.829200, valid loss: 192.626357
epoch: 4176, train precision: 0.983067, train loss: 19.485358, valid precision: 0.834600, valid loss: 199.219858
epoch: 4177, train precision: 0.978311, train loss: 21.660406, valid precision: 0.825400, valid loss: 197.209368
epoch: 4178, train precision: 0.981289, train loss: 20.420368, valid precision: 0.822600, valid loss: 210.725984
epoch: 4179, train precision: 0.984022, train loss: 18.349126, valid precision: 0.833200, valid loss: 208.040183
epoch: 4180, train precision: 0.985178, train loss: 18.472143, valid precision: 0.838400, valid loss: 244.230291
epoch: 4181, train precision: 0.984822, train loss: 18.228553, valid precision: 0.834000, valid loss: 217.544257
epoch: 4182, train precision: 0.984778, train loss: 17.819965, valid precision: 0.833400, valid loss: 222.509230
epoch: 4183, train precision: 0.973978, train loss: 23.116509, valid precision: 0.824000, valid loss: 197.447901
epoch: 4184, train precision: 0.983022, train loss: 19.118012, valid precision: 0.833200, valid loss: 218.688886
epoch: 4185, train precision: 0.978600, train loss: 20.909309, valid precision: 0.833000, valid loss: 209.588675
epoch: 4186, train precision: 0.979644, train loss: 21.886541, valid precision: 0.830200, valid loss: 232.599330
epoch: 4187, train precision: 0.983333, train loss: 19.489418, valid precision: 0.839000, valid loss: 227.623517
epoch: 4188, train precision: 0.986733, train loss: 17.834073, valid precision: 0.837800, valid loss: 236.886219
epoch: 4189, train precision: 0.982222, train loss: 19.304231, valid precision: 0.832000, valid loss: 226.117975
epoch: 4190, train precision: 0.980711, train loss: 19.625657, valid precision: 0.832000, valid loss: 210.241903
epoch: 4191, train precision: 0.985622, train loss: 18.708495, valid precision: 0.834200, valid loss: 238.798274
epoch: 4192, train precision: 0.981844, train loss: 20.002433, valid precision: 0.832800, valid loss: 232.534454
epoch: 4193, train precision: 0.985400, train loss: 17.563200, valid precision: 0.833200, valid loss: 192.761996
epoch: 4194, train precision: 0.986156, train loss: 17.435029, valid precision: 0.834800, valid loss: 228.408707
epoch: 4195, train precision: 0.983244, train loss: 18.900481, valid precision: 0.834200, valid loss: 198.881897
epoch: 4196, train precision: 0.978067, train loss: 21.290312, valid precision: 0.831600, valid loss: 219.252869
epoch: 4197, train precision: 0.983511, train loss: 19.492692, valid precision: 0.830600, valid loss: 223.568344
epoch: 4198, train precision: 0.979956, train loss: 19.951385, valid precision: 0.837600, valid loss: 189.198898
epoch: 4199, train precision: 0.986889, train loss: 16.825084, valid precision: 0.833200, valid loss: 211.552774
epoch: 4200, train precision: 0.983178, train loss: 18.692271, valid precision: 0.838200, valid loss: 228.336829
epoch: 4201, train precision: 0.983600, train loss: 19.418971, valid precision: 0.836800, valid loss: 215.647189
epoch: 4202, train precision: 0.983489, train loss: 19.467573, valid precision: 0.835400, valid loss: 240.705520
epoch: 4203, train precision: 0.983156, train loss: 19.547117, valid precision: 0.838600, valid loss: 235.979078
epoch: 4204, train precision: 0.981600, train loss: 19.506752, valid precision: 0.831200, valid loss: 207.201717
epoch: 4205, train precision: 0.983689, train loss: 20.445616, valid precision: 0.837800, valid loss: 235.391795
epoch: 4206, train precision: 0.984511, train loss: 17.977945, valid precision: 0.836800, valid loss: 196.924117
epoch: 4207, train precision: 0.981267, train loss: 19.836976, valid precision: 0.827600, valid loss: 209.411854
epoch: 4208, train precision: 0.984111, train loss: 19.110202, valid precision: 0.837000, valid loss: 219.807796
epoch: 4209, train precision: 0.982644, train loss: 19.528843, valid precision: 0.829200, valid loss: 220.837988
epoch: 4210, train precision: 0.983756, train loss: 18.665661, valid precision: 0.830600, valid loss: 221.490375
epoch: 4211, train precision: 0.987200, train loss: 17.513651, valid precision: 0.839400, valid loss: 226.182419
epoch: 4212, train precision: 0.984467, train loss: 18.412572, valid precision: 0.834200, valid loss: 205.111823
epoch: 4213, train precision: 0.982556, train loss: 19.142141, valid precision: 0.830600, valid loss: 200.527801
epoch: 4214, train precision: 0.980844, train loss: 19.811340, valid precision: 0.836200, valid loss: 182.520681
epoch: 4215, train precision: 0.984356, train loss: 18.589223, valid precision: 0.833800, valid loss: 216.235447
epoch: 4216, train precision: 0.986156, train loss: 18.400716, valid precision: 0.840200, valid loss: 242.490300
epoch: 4217, train precision: 0.981822, train loss: 20.075273, valid precision: 0.836200, valid loss: 203.748464
epoch: 4218, train precision: 0.980356, train loss: 19.684384, valid precision: 0.833600, valid loss: 195.151387
epoch: 4219, train precision: 0.983444, train loss: 19.655569, valid precision: 0.827800, valid loss: 239.857042
epoch: 4220, train precision: 0.978044, train loss: 20.848914, valid precision: 0.837400, valid loss: 188.179549
epoch: 4221, train precision: 0.980956, train loss: 20.398517, valid precision: 0.835400, valid loss: 204.562012
epoch: 4222, train precision: 0.981556, train loss: 19.937565, valid precision: 0.839200, valid loss: 220.787370
epoch: 4223, train precision: 0.986378, train loss: 17.661452, valid precision: 0.838400, valid loss: 241.938091
epoch: 4224, train precision: 0.986556, train loss: 17.722145, valid precision: 0.838000, valid loss: 204.652096
epoch: 4225, train precision: 0.983200, train loss: 18.716296, valid precision: 0.837200, valid loss: 203.133654
epoch: 4226, train precision: 0.985022, train loss: 18.151381, valid precision: 0.839800, valid loss: 192.337073
epoch: 4227, train precision: 0.983489, train loss: 18.718026, valid precision: 0.840400, valid loss: 219.303711
epoch: 4228, train precision: 0.985267, train loss: 18.917746, valid precision: 0.831000, valid loss: 238.142735
epoch: 4229, train precision: 0.978889, train loss: 22.101019, valid precision: 0.829400, valid loss: 210.043925
epoch: 4230, train precision: 0.977156, train loss: 22.152716, valid precision: 0.826800, valid loss: 221.153546
epoch: 4231, train precision: 0.983111, train loss: 19.062607, valid precision: 0.831200, valid loss: 209.866919
epoch: 4232, train precision: 0.981911, train loss: 20.065544, valid precision: 0.829400, valid loss: 220.663917
epoch: 4233, train precision: 0.985400, train loss: 17.765932, valid precision: 0.838800, valid loss: 206.749014
epoch: 4234, train precision: 0.987133, train loss: 17.151876, valid precision: 0.837400, valid loss: 209.478386
epoch: 4235, train precision: 0.978444, train loss: 22.145134, valid precision: 0.829200, valid loss: 219.258236
epoch: 4236, train precision: 0.978400, train loss: 22.357834, valid precision: 0.832600, valid loss: 221.960041
epoch: 4237, train precision: 0.983333, train loss: 20.898570, valid precision: 0.831200, valid loss: 252.785118
epoch: 4238, train precision: 0.985133, train loss: 18.061199, valid precision: 0.836000, valid loss: 221.348804
epoch: 4239, train precision: 0.982556, train loss: 19.976140, valid precision: 0.835600, valid loss: 208.387583
epoch: 4240, train precision: 0.984822, train loss: 18.121849, valid precision: 0.834000, valid loss: 208.681952
epoch: 4241, train precision: 0.984311, train loss: 18.621099, valid precision: 0.838800, valid loss: 218.860588
epoch: 4242, train precision: 0.984200, train loss: 18.923352, valid precision: 0.835000, valid loss: 230.948396
epoch: 4243, train precision: 0.981867, train loss: 19.999052, valid precision: 0.833600, valid loss: 196.354256
epoch: 4244, train precision: 0.982444, train loss: 19.423098, valid precision: 0.835400, valid loss: 201.788357
epoch: 4245, train precision: 0.983956, train loss: 18.203227, valid precision: 0.836600, valid loss: 200.081511
epoch: 4246, train precision: 0.986111, train loss: 17.655784, valid precision: 0.838600, valid loss: 223.893975
epoch: 4247, train precision: 0.977156, train loss: 23.430218, valid precision: 0.834600, valid loss: 199.684957
epoch: 4248, train precision: 0.981156, train loss: 19.973232, valid precision: 0.836400, valid loss: 204.805491
epoch: 4249, train precision: 0.984778, train loss: 17.929784, valid precision: 0.837800, valid loss: 202.597620
epoch: 4250, train precision: 0.980533, train loss: 20.551203, valid precision: 0.827600, valid loss: 214.346815
epoch: 4251, train precision: 0.978511, train loss: 21.829843, valid precision: 0.825000, valid loss: 222.938041
epoch: 4252, train precision: 0.982844, train loss: 19.238498, valid precision: 0.837800, valid loss: 203.333651
epoch: 4253, train precision: 0.984822, train loss: 19.137318, valid precision: 0.834400, valid loss: 227.126230
epoch: 4254, train precision: 0.983511, train loss: 18.246459, valid precision: 0.834000, valid loss: 188.444160
epoch: 4255, train precision: 0.988267, train loss: 16.758992, valid precision: 0.839400, valid loss: 216.329456
epoch: 4256, train precision: 0.987889, train loss: 16.916037, valid precision: 0.839000, valid loss: 220.025470
epoch: 4257, train precision: 0.980956, train loss: 20.611173, valid precision: 0.832000, valid loss: 214.863486
epoch: 4258, train precision: 0.985556, train loss: 18.617625, valid precision: 0.841200, valid loss: 251.348991
epoch: 4259, train precision: 0.982667, train loss: 19.627069, valid precision: 0.838400, valid loss: 200.227044
epoch: 4260, train precision: 0.986667, train loss: 16.949606, valid precision: 0.836000, valid loss: 210.656517
epoch: 4261, train precision: 0.979711, train loss: 20.881024, valid precision: 0.838400, valid loss: 209.061956
epoch: 4262, train precision: 0.986578, train loss: 17.334130, valid precision: 0.837600, valid loss: 204.763939
epoch: 4263, train precision: 0.984267, train loss: 17.977092, valid precision: 0.837600, valid loss: 190.744102
epoch: 4264, train precision: 0.981800, train loss: 19.510538, valid precision: 0.837600, valid loss: 194.264502
epoch: 4265, train precision: 0.976867, train loss: 22.667088, valid precision: 0.832400, valid loss: 206.828758
epoch: 4266, train precision: 0.982000, train loss: 19.601448, valid precision: 0.836000, valid loss: 210.829749
epoch: 4267, train precision: 0.982378, train loss: 19.960042, valid precision: 0.836000, valid loss: 215.136695
epoch: 4268, train precision: 0.978667, train loss: 22.100241, valid precision: 0.831000, valid loss: 199.427304
epoch: 4269, train precision: 0.974956, train loss: 22.959218, valid precision: 0.830000, valid loss: 192.546807
epoch: 4270, train precision: 0.985556, train loss: 17.547870, valid precision: 0.837200, valid loss: 204.636325
epoch: 4271, train precision: 0.982044, train loss: 19.155249, valid precision: 0.833000, valid loss: 189.910963
epoch: 4272, train precision: 0.977800, train loss: 21.054826, valid precision: 0.827200, valid loss: 183.955672
epoch: 4273, train precision: 0.982867, train loss: 18.588992, valid precision: 0.826400, valid loss: 208.575405
epoch: 4274, train precision: 0.980933, train loss: 19.913254, valid precision: 0.831000, valid loss: 202.222861
epoch: 4275, train precision: 0.980778, train loss: 19.885591, valid precision: 0.828800, valid loss: 191.606060
epoch: 4276, train precision: 0.986956, train loss: 17.259062, valid precision: 0.834400, valid loss: 219.896562
epoch: 4277, train precision: 0.984733, train loss: 18.027267, valid precision: 0.838600, valid loss: 187.206384
epoch: 4278, train precision: 0.981889, train loss: 19.295276, valid precision: 0.834800, valid loss: 194.459590
epoch: 4279, train precision: 0.980733, train loss: 20.199822, valid precision: 0.830400, valid loss: 206.035936
epoch: 4280, train precision: 0.984667, train loss: 17.935605, valid precision: 0.838800, valid loss: 192.653764
epoch: 4281, train precision: 0.982667, train loss: 21.075124, valid precision: 0.832000, valid loss: 230.044480
epoch: 4282, train precision: 0.985578, train loss: 18.739681, valid precision: 0.836200, valid loss: 237.424925
epoch: 4283, train precision: 0.987778, train loss: 17.503708, valid precision: 0.838000, valid loss: 246.159229
epoch: 4284, train precision: 0.979133, train loss: 21.209355, valid precision: 0.829600, valid loss: 206.295188
epoch: 4285, train precision: 0.986733, train loss: 17.428910, valid precision: 0.837800, valid loss: 206.062923
epoch: 4286, train precision: 0.987022, train loss: 17.236890, valid precision: 0.842600, valid loss: 230.863136
epoch: 4287, train precision: 0.983333, train loss: 18.882705, valid precision: 0.839800, valid loss: 203.373454
epoch: 4288, train precision: 0.981022, train loss: 20.759971, valid precision: 0.835000, valid loss: 208.471017
epoch: 4289, train precision: 0.983444, train loss: 20.527101, valid precision: 0.833800, valid loss: 247.338912
epoch: 4290, train precision: 0.983511, train loss: 18.921045, valid precision: 0.836400, valid loss: 184.631091
epoch: 4291, train precision: 0.980556, train loss: 20.249503, valid precision: 0.835800, valid loss: 199.092343
epoch: 4292, train precision: 0.978511, train loss: 20.857561, valid precision: 0.827600, valid loss: 178.997881
epoch: 4293, train precision: 0.980889, train loss: 20.340214, valid precision: 0.828400, valid loss: 187.005404
epoch: 4294, train precision: 0.987489, train loss: 16.847081, valid precision: 0.839600, valid loss: 207.115228
epoch: 4295, train precision: 0.978022, train loss: 21.371073, valid precision: 0.835000, valid loss: 191.013605
epoch: 4296, train precision: 0.980111, train loss: 20.854722, valid precision: 0.837400, valid loss: 216.146855
epoch: 4297, train precision: 0.981778, train loss: 20.662971, valid precision: 0.840800, valid loss: 223.482919
epoch: 4298, train precision: 0.979244, train loss: 21.108559, valid precision: 0.833200, valid loss: 210.968838
epoch: 4299, train precision: 0.985711, train loss: 18.266625, valid precision: 0.838600, valid loss: 221.602834
epoch: 4300, train precision: 0.977200, train loss: 21.367601, valid precision: 0.834200, valid loss: 184.155130
epoch: 4301, train precision: 0.981733, train loss: 19.748764, valid precision: 0.831400, valid loss: 206.279386
epoch: 4302, train precision: 0.982222, train loss: 19.497602, valid precision: 0.835000, valid loss: 182.694331
epoch: 4303, train precision: 0.986200, train loss: 17.647421, valid precision: 0.837000, valid loss: 221.956067
epoch: 4304, train precision: 0.980067, train loss: 21.035511, valid precision: 0.829200, valid loss: 198.889316
epoch: 4305, train precision: 0.985311, train loss: 18.099245, valid precision: 0.834000, valid loss: 225.696104
epoch: 4306, train precision: 0.983467, train loss: 19.285199, valid precision: 0.837000, valid loss: 210.564494
epoch: 4307, train precision: 0.984356, train loss: 18.533829, valid precision: 0.838000, valid loss: 210.974211
epoch: 4308, train precision: 0.984822, train loss: 18.564423, valid precision: 0.837200, valid loss: 226.802525
epoch: 4309, train precision: 0.978556, train loss: 22.051930, valid precision: 0.828800, valid loss: 206.008425
epoch: 4310, train precision: 0.981111, train loss: 19.882695, valid precision: 0.832600, valid loss: 186.016073
epoch: 4311, train precision: 0.977800, train loss: 21.594019, valid precision: 0.831200, valid loss: 194.848218
epoch: 4312, train precision: 0.984067, train loss: 18.513481, valid precision: 0.830600, valid loss: 200.982480
epoch: 4313, train precision: 0.982511, train loss: 19.723462, valid precision: 0.835600, valid loss: 204.337086
epoch: 4314, train precision: 0.981489, train loss: 19.789059, valid precision: 0.836200, valid loss: 199.473545
epoch: 4315, train precision: 0.982911, train loss: 18.997409, valid precision: 0.836400, valid loss: 195.951406
epoch: 4316, train precision: 0.978089, train loss: 22.150815, valid precision: 0.835000, valid loss: 215.357958
epoch: 4317, train precision: 0.977244, train loss: 21.678356, valid precision: 0.830200, valid loss: 213.562691
epoch: 4318, train precision: 0.984889, train loss: 17.982883, valid precision: 0.835600, valid loss: 202.071403
epoch: 4319, train precision: 0.982933, train loss: 19.402538, valid precision: 0.832600, valid loss: 200.096621
epoch: 4320, train precision: 0.981200, train loss: 20.072282, valid precision: 0.839800, valid loss: 194.004875
epoch: 4321, train precision: 0.981400, train loss: 19.706691, valid precision: 0.834400, valid loss: 195.931141
epoch: 4322, train precision: 0.983267, train loss: 19.350003, valid precision: 0.840800, valid loss: 223.516890
epoch: 4323, train precision: 0.979378, train loss: 21.175535, valid precision: 0.830400, valid loss: 203.406689
epoch: 4324, train precision: 0.983689, train loss: 18.857372, valid precision: 0.832000, valid loss: 207.427748
epoch: 4325, train precision: 0.982800, train loss: 18.722652, valid precision: 0.839400, valid loss: 194.278847
epoch: 4326, train precision: 0.983956, train loss: 18.646331, valid precision: 0.832200, valid loss: 214.879378
epoch: 4327, train precision: 0.979289, train loss: 21.874518, valid precision: 0.831600, valid loss: 233.450068
epoch: 4328, train precision: 0.983333, train loss: 21.813634, valid precision: 0.834200, valid loss: 285.806252
epoch: 4329, train precision: 0.982311, train loss: 20.356583, valid precision: 0.837800, valid loss: 242.811142
epoch: 4330, train precision: 0.981467, train loss: 20.214898, valid precision: 0.838000, valid loss: 209.996916
epoch: 4331, train precision: 0.979067, train loss: 21.692693, valid precision: 0.838600, valid loss: 201.239314
epoch: 4332, train precision: 0.986200, train loss: 17.242200, valid precision: 0.841000, valid loss: 195.950849
epoch: 4333, train precision: 0.977133, train loss: 24.236395, valid precision: 0.826600, valid loss: 235.435375
epoch: 4334, train precision: 0.980711, train loss: 20.307647, valid precision: 0.829800, valid loss: 213.430560
epoch: 4335, train precision: 0.984844, train loss: 19.122449, valid precision: 0.832200, valid loss: 243.212528
epoch: 4336, train precision: 0.982311, train loss: 19.875403, valid precision: 0.833200, valid loss: 219.359296
epoch: 4337, train precision: 0.985867, train loss: 17.483170, valid precision: 0.835600, valid loss: 216.104070
epoch: 4338, train precision: 0.981733, train loss: 19.104157, valid precision: 0.832400, valid loss: 206.277884
epoch: 4339, train precision: 0.983956, train loss: 20.018306, valid precision: 0.839800, valid loss: 233.681285
epoch: 4340, train precision: 0.983444, train loss: 18.983568, valid precision: 0.833400, valid loss: 217.045298
epoch: 4341, train precision: 0.980933, train loss: 19.430791, valid precision: 0.833000, valid loss: 180.873557
epoch: 4342, train precision: 0.983689, train loss: 19.836900, valid precision: 0.831000, valid loss: 217.565793
epoch: 4343, train precision: 0.983822, train loss: 18.311321, valid precision: 0.837600, valid loss: 177.699747
epoch: 4344, train precision: 0.986489, train loss: 18.089417, valid precision: 0.836600, valid loss: 231.927886
epoch: 4345, train precision: 0.980044, train loss: 19.994004, valid precision: 0.835600, valid loss: 191.166299
epoch: 4346, train precision: 0.984089, train loss: 18.807671, valid precision: 0.830800, valid loss: 221.554996
epoch: 4347, train precision: 0.985267, train loss: 17.737902, valid precision: 0.837400, valid loss: 197.796518
epoch: 4348, train precision: 0.983489, train loss: 20.443706, valid precision: 0.834200, valid loss: 262.628664
epoch: 4349, train precision: 0.983467, train loss: 18.762559, valid precision: 0.835200, valid loss: 204.414000
epoch: 4350, train precision: 0.979867, train loss: 20.536983, valid precision: 0.835000, valid loss: 208.316041
epoch: 4351, train precision: 0.984222, train loss: 19.432553, valid precision: 0.837000, valid loss: 220.021990
epoch: 4352, train precision: 0.979444, train loss: 21.460654, valid precision: 0.835200, valid loss: 199.816098
epoch: 4353, train precision: 0.986111, train loss: 17.491013, valid precision: 0.836600, valid loss: 201.791503
epoch: 4354, train precision: 0.983178, train loss: 18.775220, valid precision: 0.836000, valid loss: 197.885291
epoch: 4355, train precision: 0.977444, train loss: 21.894481, valid precision: 0.826600, valid loss: 201.766331
epoch: 4356, train precision: 0.983911, train loss: 18.377905, valid precision: 0.839800, valid loss: 200.475319
epoch: 4357, train precision: 0.984089, train loss: 19.626609, valid precision: 0.838800, valid loss: 235.291284
epoch: 4358, train precision: 0.977422, train loss: 21.925024, valid precision: 0.833400, valid loss: 200.226136
epoch: 4359, train precision: 0.982889, train loss: 19.387507, valid precision: 0.833000, valid loss: 212.728858
epoch: 4360, train precision: 0.983133, train loss: 18.990656, valid precision: 0.833400, valid loss: 204.260705
epoch: 4361, train precision: 0.981311, train loss: 19.771266, valid precision: 0.835000, valid loss: 192.595079
epoch: 4362, train precision: 0.984200, train loss: 18.407000, valid precision: 0.836200, valid loss: 206.402609
epoch: 4363, train precision: 0.978133, train loss: 20.712637, valid precision: 0.832400, valid loss: 186.232534
epoch: 4364, train precision: 0.984200, train loss: 19.583872, valid precision: 0.839200, valid loss: 252.290222
epoch: 4365, train precision: 0.981867, train loss: 19.370632, valid precision: 0.836400, valid loss: 190.750367
epoch: 4366, train precision: 0.983822, train loss: 18.326238, valid precision: 0.834400, valid loss: 203.967262
epoch: 4367, train precision: 0.979044, train loss: 21.540481, valid precision: 0.830200, valid loss: 236.433720
epoch: 4368, train precision: 0.987289, train loss: 17.475543, valid precision: 0.842600, valid loss: 235.756959
epoch: 4369, train precision: 0.980422, train loss: 19.974370, valid precision: 0.832800, valid loss: 210.650945
epoch: 4370, train precision: 0.981156, train loss: 21.326759, valid precision: 0.835400, valid loss: 229.875295
epoch: 4371, train precision: 0.980311, train loss: 21.998701, valid precision: 0.830400, valid loss: 224.655330
epoch: 4372, train precision: 0.983733, train loss: 18.494465, valid precision: 0.839200, valid loss: 215.765864
epoch: 4373, train precision: 0.985022, train loss: 18.992330, valid precision: 0.835800, valid loss: 218.091926
epoch: 4374, train precision: 0.983178, train loss: 19.816031, valid precision: 0.839400, valid loss: 208.109057
epoch: 4375, train precision: 0.980822, train loss: 19.859052, valid precision: 0.835200, valid loss: 200.122333
epoch: 4376, train precision: 0.983267, train loss: 18.880647, valid precision: 0.837800, valid loss: 206.391561
epoch: 4377, train precision: 0.970000, train loss: 25.561770, valid precision: 0.829800, valid loss: 188.833371
epoch: 4378, train precision: 0.984311, train loss: 19.354286, valid precision: 0.837000, valid loss: 220.168041
epoch: 4379, train precision: 0.981089, train loss: 20.051819, valid precision: 0.839400, valid loss: 193.782506
epoch: 4380, train precision: 0.978311, train loss: 21.528233, valid precision: 0.833800, valid loss: 199.423996
epoch: 4381, train precision: 0.982756, train loss: 20.498071, valid precision: 0.833200, valid loss: 241.513144
epoch: 4382, train precision: 0.980844, train loss: 20.210535, valid precision: 0.835000, valid loss: 201.215239
epoch: 4383, train precision: 0.986133, train loss: 17.761262, valid precision: 0.835400, valid loss: 206.572409
epoch: 4384, train precision: 0.982333, train loss: 19.076044, valid precision: 0.831800, valid loss: 181.044394
epoch: 4385, train precision: 0.984022, train loss: 18.717385, valid precision: 0.837800, valid loss: 225.379294
epoch: 4386, train precision: 0.982333, train loss: 18.771165, valid precision: 0.837200, valid loss: 192.361435
epoch: 4387, train precision: 0.984311, train loss: 18.239385, valid precision: 0.839000, valid loss: 192.195875
epoch: 4388, train precision: 0.983156, train loss: 19.376309, valid precision: 0.837400, valid loss: 188.541825
epoch: 4389, train precision: 0.981311, train loss: 20.006100, valid precision: 0.831200, valid loss: 183.068461
epoch: 4390, train precision: 0.983467, train loss: 19.054568, valid precision: 0.833000, valid loss: 208.208778
epoch: 4391, train precision: 0.980733, train loss: 20.435373, valid precision: 0.830600, valid loss: 198.979322
epoch: 4392, train precision: 0.980044, train loss: 20.240136, valid precision: 0.834400, valid loss: 184.910781
epoch: 4393, train precision: 0.978000, train loss: 22.279783, valid precision: 0.829400, valid loss: 204.453156
epoch: 4394, train precision: 0.985978, train loss: 18.258457, valid precision: 0.836600, valid loss: 234.640470
epoch: 4395, train precision: 0.982133, train loss: 19.633157, valid precision: 0.832800, valid loss: 200.888813
epoch: 4396, train precision: 0.982378, train loss: 19.248503, valid precision: 0.834200, valid loss: 202.271451
epoch: 4397, train precision: 0.985200, train loss: 18.493092, valid precision: 0.833600, valid loss: 237.957418
epoch: 4398, train precision: 0.977444, train loss: 22.363951, valid precision: 0.836200, valid loss: 201.087545
epoch: 4399, train precision: 0.982800, train loss: 19.922649, valid precision: 0.837600, valid loss: 204.351056
epoch: 4400, train precision: 0.979533, train loss: 20.447231, valid precision: 0.835400, valid loss: 178.466451
epoch: 4401, train precision: 0.984422, train loss: 18.584233, valid precision: 0.837600, valid loss: 202.276538
epoch: 4402, train precision: 0.980067, train loss: 20.134536, valid precision: 0.835800, valid loss: 193.037864
epoch: 4403, train precision: 0.983044, train loss: 18.802891, valid precision: 0.837600, valid loss: 180.421859
epoch: 4404, train precision: 0.985044, train loss: 18.189153, valid precision: 0.839400, valid loss: 214.422128
epoch: 4405, train precision: 0.983356, train loss: 19.400748, valid precision: 0.835000, valid loss: 230.771039
epoch: 4406, train precision: 0.983800, train loss: 18.565901, valid precision: 0.834400, valid loss: 193.515937
epoch: 4407, train precision: 0.981267, train loss: 19.841802, valid precision: 0.830800, valid loss: 200.312124
epoch: 4408, train precision: 0.986089, train loss: 17.033459, valid precision: 0.835800, valid loss: 208.094958
epoch: 4409, train precision: 0.983311, train loss: 19.537070, valid precision: 0.833600, valid loss: 228.539113
epoch: 4410, train precision: 0.980511, train loss: 20.911257, valid precision: 0.835400, valid loss: 224.908602
epoch: 4411, train precision: 0.977156, train loss: 21.512730, valid precision: 0.830400, valid loss: 191.764974
epoch: 4412, train precision: 0.984356, train loss: 18.725017, valid precision: 0.834400, valid loss: 188.538460
epoch: 4413, train precision: 0.982289, train loss: 20.109555, valid precision: 0.830600, valid loss: 232.554375
epoch: 4414, train precision: 0.980622, train loss: 20.172078, valid precision: 0.835600, valid loss: 202.678337
epoch: 4415, train precision: 0.983356, train loss: 19.461633, valid precision: 0.835400, valid loss: 215.313793
epoch: 4416, train precision: 0.985756, train loss: 18.358180, valid precision: 0.839400, valid loss: 233.163059
epoch: 4417, train precision: 0.979333, train loss: 20.821909, valid precision: 0.827200, valid loss: 197.009019
epoch: 4418, train precision: 0.984156, train loss: 19.204486, valid precision: 0.835600, valid loss: 236.028624
epoch: 4419, train precision: 0.980533, train loss: 21.490895, valid precision: 0.836000, valid loss: 232.160358
epoch: 4420, train precision: 0.980133, train loss: 20.967679, valid precision: 0.829400, valid loss: 211.186784
epoch: 4421, train precision: 0.970800, train loss: 25.192083, valid precision: 0.822800, valid loss: 194.316085
epoch: 4422, train precision: 0.986222, train loss: 17.766418, valid precision: 0.835200, valid loss: 204.357338
epoch: 4423, train precision: 0.982511, train loss: 18.849453, valid precision: 0.835000, valid loss: 210.854839
epoch: 4424, train precision: 0.978289, train loss: 21.475987, valid precision: 0.833600, valid loss: 189.266075
epoch: 4425, train precision: 0.981978, train loss: 19.516497, valid precision: 0.836800, valid loss: 198.972445
epoch: 4426, train precision: 0.980200, train loss: 20.273819, valid precision: 0.833000, valid loss: 203.359474
epoch: 4427, train precision: 0.979711, train loss: 20.821311, valid precision: 0.831400, valid loss: 213.251657
epoch: 4428, train precision: 0.983111, train loss: 18.842405, valid precision: 0.835800, valid loss: 200.077271
epoch: 4429, train precision: 0.980400, train loss: 20.406005, valid precision: 0.835400, valid loss: 209.798585
epoch: 4430, train precision: 0.977289, train loss: 23.204716, valid precision: 0.829000, valid loss: 224.122029
epoch: 4431, train precision: 0.979978, train loss: 20.681502, valid precision: 0.832400, valid loss: 198.791933
epoch: 4432, train precision: 0.984378, train loss: 18.543733, valid precision: 0.833600, valid loss: 211.708878
epoch: 4433, train precision: 0.979667, train loss: 21.391577, valid precision: 0.831600, valid loss: 219.426747
epoch: 4434, train precision: 0.986156, train loss: 17.545385, valid precision: 0.838400, valid loss: 195.489136
epoch: 4435, train precision: 0.982289, train loss: 19.419616, valid precision: 0.835600, valid loss: 203.101221
epoch: 4436, train precision: 0.984867, train loss: 18.193133, valid precision: 0.838000, valid loss: 198.104089
epoch: 4437, train precision: 0.984022, train loss: 19.075108, valid precision: 0.836600, valid loss: 213.610207
epoch: 4438, train precision: 0.979400, train loss: 20.640556, valid precision: 0.833600, valid loss: 208.763108
epoch: 4439, train precision: 0.981622, train loss: 20.769737, valid precision: 0.832600, valid loss: 223.210028
epoch: 4440, train precision: 0.981822, train loss: 20.240038, valid precision: 0.836800, valid loss: 204.203225
epoch: 4441, train precision: 0.980778, train loss: 20.092901, valid precision: 0.830600, valid loss: 213.109692
epoch: 4442, train precision: 0.980156, train loss: 20.250171, valid precision: 0.836000, valid loss: 179.944851
epoch: 4443, train precision: 0.979756, train loss: 21.447641, valid precision: 0.833000, valid loss: 217.625558
epoch: 4444, train precision: 0.983800, train loss: 18.873803, valid precision: 0.837600, valid loss: 224.660513
epoch: 4445, train precision: 0.979600, train loss: 19.635351, valid precision: 0.835200, valid loss: 181.651744
epoch: 4446, train precision: 0.983978, train loss: 19.009206, valid precision: 0.834600, valid loss: 223.731774
epoch: 4447, train precision: 0.980111, train loss: 20.294562, valid precision: 0.834800, valid loss: 178.681059
epoch: 4448, train precision: 0.977800, train loss: 22.209745, valid precision: 0.829200, valid loss: 203.438377
epoch: 4449, train precision: 0.983267, train loss: 18.814135, valid precision: 0.833000, valid loss: 202.143179
epoch: 4450, train precision: 0.985089, train loss: 18.177277, valid precision: 0.836600, valid loss: 199.939483
epoch: 4451, train precision: 0.982444, train loss: 20.920838, valid precision: 0.831800, valid loss: 276.237493
epoch: 4452, train precision: 0.981889, train loss: 19.633782, valid precision: 0.829200, valid loss: 196.998428
epoch: 4453, train precision: 0.987111, train loss: 17.224673, valid precision: 0.838000, valid loss: 211.011987
epoch: 4454, train precision: 0.984044, train loss: 18.862250, valid precision: 0.831200, valid loss: 197.264658
epoch: 4455, train precision: 0.980956, train loss: 20.590727, valid precision: 0.829000, valid loss: 219.454580
epoch: 4456, train precision: 0.982156, train loss: 19.896304, valid precision: 0.836600, valid loss: 219.349529
epoch: 4457, train precision: 0.977089, train loss: 21.619153, valid precision: 0.835400, valid loss: 185.187533
epoch: 4458, train precision: 0.980644, train loss: 19.909722, valid precision: 0.835400, valid loss: 203.436168
epoch: 4459, train precision: 0.980889, train loss: 20.723485, valid precision: 0.838800, valid loss: 221.124770
epoch: 4460, train precision: 0.983067, train loss: 19.548230, valid precision: 0.835600, valid loss: 206.272143
epoch: 4461, train precision: 0.980400, train loss: 20.763811, valid precision: 0.832400, valid loss: 214.040877
epoch: 4462, train precision: 0.984467, train loss: 18.363626, valid precision: 0.832800, valid loss: 228.036478
epoch: 4463, train precision: 0.985689, train loss: 17.749875, valid precision: 0.839200, valid loss: 205.196232
epoch: 4464, train precision: 0.982800, train loss: 19.453066, valid precision: 0.838400, valid loss: 215.680752
epoch: 4465, train precision: 0.983644, train loss: 19.306959, valid precision: 0.840800, valid loss: 239.363195
epoch: 4466, train precision: 0.984667, train loss: 19.713835, valid precision: 0.835200, valid loss: 235.347399
epoch: 4467, train precision: 0.982067, train loss: 20.140992, valid precision: 0.836600, valid loss: 218.267652
epoch: 4468, train precision: 0.986378, train loss: 18.085731, valid precision: 0.839400, valid loss: 215.145626
epoch: 4469, train precision: 0.984756, train loss: 19.132817, valid precision: 0.836800, valid loss: 222.272730
epoch: 4470, train precision: 0.983156, train loss: 18.966346, valid precision: 0.828400, valid loss: 203.118941
epoch: 4471, train precision: 0.979333, train loss: 20.459308, valid precision: 0.834800, valid loss: 179.206325
epoch: 4472, train precision: 0.980333, train loss: 21.082744, valid precision: 0.832000, valid loss: 216.195396
epoch: 4473, train precision: 0.979511, train loss: 20.311904, valid precision: 0.832400, valid loss: 193.718967
epoch: 4474, train precision: 0.981689, train loss: 19.115748, valid precision: 0.835400, valid loss: 183.566633
epoch: 4475, train precision: 0.984489, train loss: 20.029541, valid precision: 0.837600, valid loss: 238.150035
epoch: 4476, train precision: 0.981622, train loss: 19.915683, valid precision: 0.840000, valid loss: 186.584841
epoch: 4477, train precision: 0.975444, train loss: 23.433571, valid precision: 0.831800, valid loss: 190.791400
epoch: 4478, train precision: 0.980689, train loss: 20.524262, valid precision: 0.833200, valid loss: 201.721938
epoch: 4479, train precision: 0.981333, train loss: 19.986072, valid precision: 0.836400, valid loss: 201.015657
epoch: 4480, train precision: 0.982711, train loss: 19.609788, valid precision: 0.834000, valid loss: 217.950453
epoch: 4481, train precision: 0.981911, train loss: 20.251392, valid precision: 0.836400, valid loss: 211.643588
epoch: 4482, train precision: 0.983156, train loss: 19.471168, valid precision: 0.832400, valid loss: 220.754551
epoch: 4483, train precision: 0.982733, train loss: 19.656258, valid precision: 0.838200, valid loss: 231.686177
epoch: 4484, train precision: 0.979822, train loss: 23.573682, valid precision: 0.835600, valid loss: 217.865307
epoch: 4485, train precision: 0.984378, train loss: 18.569043, valid precision: 0.837200, valid loss: 193.905423
epoch: 4486, train precision: 0.982489, train loss: 19.929522, valid precision: 0.835000, valid loss: 216.082598
epoch: 4487, train precision: 0.982733, train loss: 19.579523, valid precision: 0.830400, valid loss: 205.965486
epoch: 4488, train precision: 0.983156, train loss: 18.609578, valid precision: 0.832000, valid loss: 216.629313
epoch: 4489, train precision: 0.985756, train loss: 18.342719, valid precision: 0.835000, valid loss: 221.362244
epoch: 4490, train precision: 0.980600, train loss: 19.992661, valid precision: 0.830800, valid loss: 214.024810
epoch: 4491, train precision: 0.978867, train loss: 22.273033, valid precision: 0.835200, valid loss: 233.751079
epoch: 4492, train precision: 0.988000, train loss: 16.929332, valid precision: 0.841000, valid loss: 208.824045
epoch: 4493, train precision: 0.982911, train loss: 19.209707, valid precision: 0.841000, valid loss: 199.938512
epoch: 4494, train precision: 0.981978, train loss: 20.008624, valid precision: 0.834800, valid loss: 226.448093
epoch: 4495, train precision: 0.984044, train loss: 18.814746, valid precision: 0.837200, valid loss: 228.649082
epoch: 4496, train precision: 0.983244, train loss: 19.668974, valid precision: 0.832200, valid loss: 203.720070
epoch: 4497, train precision: 0.983244, train loss: 19.020211, valid precision: 0.830200, valid loss: 209.143577
epoch: 4498, train precision: 0.982867, train loss: 19.370989, valid precision: 0.835400, valid loss: 223.195792
epoch: 4499, train precision: 0.983267, train loss: 19.627799, valid precision: 0.836400, valid loss: 216.820298
epoch: 4500, train precision: 0.980867, train loss: 20.367706, valid precision: 0.831000, valid loss: 203.143844
epoch: 4501, train precision: 0.980911, train loss: 20.468796, valid precision: 0.835800, valid loss: 224.228353
epoch: 4502, train precision: 0.981778, train loss: 20.115448, valid precision: 0.829800, valid loss: 203.396823
epoch: 4503, train precision: 0.983022, train loss: 19.929814, valid precision: 0.833400, valid loss: 229.627471
epoch: 4504, train precision: 0.983222, train loss: 19.358315, valid precision: 0.831400, valid loss: 199.631447
epoch: 4505, train precision: 0.980800, train loss: 20.554410, valid precision: 0.832600, valid loss: 213.209292
epoch: 4506, train precision: 0.983111, train loss: 20.138741, valid precision: 0.834600, valid loss: 245.365566
epoch: 4507, train precision: 0.981133, train loss: 20.375680, valid precision: 0.830600, valid loss: 205.773987
epoch: 4508, train precision: 0.982844, train loss: 20.263230, valid precision: 0.834600, valid loss: 210.974070
epoch: 4509, train precision: 0.983689, train loss: 20.105464, valid precision: 0.832600, valid loss: 225.727107
epoch: 4510, train precision: 0.984244, train loss: 19.217098, valid precision: 0.837400, valid loss: 244.673766
epoch: 4511, train precision: 0.981444, train loss: 20.110325, valid precision: 0.833800, valid loss: 205.932695
epoch: 4512, train precision: 0.983467, train loss: 18.749048, valid precision: 0.839400, valid loss: 193.965540
epoch: 4513, train precision: 0.984022, train loss: 19.035000, valid precision: 0.833000, valid loss: 216.724412
epoch: 4514, train precision: 0.982400, train loss: 19.355639, valid precision: 0.834600, valid loss: 207.874945
epoch: 4515, train precision: 0.982044, train loss: 19.270829, valid precision: 0.838800, valid loss: 202.222688
epoch: 4516, train precision: 0.981622, train loss: 19.345183, valid precision: 0.840600, valid loss: 193.820318
epoch: 4517, train precision: 0.980711, train loss: 20.330335, valid precision: 0.840400, valid loss: 197.222413
epoch: 4518, train precision: 0.983444, train loss: 19.283422, valid precision: 0.836400, valid loss: 257.246584
epoch: 4519, train precision: 0.980044, train loss: 21.155681, valid precision: 0.832400, valid loss: 224.145446
epoch: 4520, train precision: 0.984289, train loss: 18.851187, valid precision: 0.837200, valid loss: 222.490959
epoch: 4521, train precision: 0.981422, train loss: 20.613109, valid precision: 0.834200, valid loss: 244.948126
epoch: 4522, train precision: 0.981178, train loss: 20.212261, valid precision: 0.832000, valid loss: 197.984083
epoch: 4523, train precision: 0.984000, train loss: 18.841947, valid precision: 0.835200, valid loss: 208.344878
epoch: 4524, train precision: 0.980800, train loss: 20.232563, valid precision: 0.832200, valid loss: 202.664898
epoch: 4525, train precision: 0.983333, train loss: 18.758133, valid precision: 0.831800, valid loss: 196.928551
epoch: 4526, train precision: 0.976956, train loss: 22.295927, valid precision: 0.835000, valid loss: 188.253251
epoch: 4527, train precision: 0.983933, train loss: 19.005101, valid precision: 0.835200, valid loss: 219.826458
epoch: 4528, train precision: 0.984489, train loss: 18.020300, valid precision: 0.843200, valid loss: 212.893800
epoch: 4529, train precision: 0.980956, train loss: 20.868203, valid precision: 0.838400, valid loss: 206.043344
epoch: 4530, train precision: 0.980356, train loss: 20.519076, valid precision: 0.838600, valid loss: 213.421436
epoch: 4531, train precision: 0.982378, train loss: 20.368658, valid precision: 0.835200, valid loss: 228.876658
epoch: 4532, train precision: 0.984800, train loss: 18.427352, valid precision: 0.837000, valid loss: 231.865446
epoch: 4533, train precision: 0.979533, train loss: 20.290786, valid precision: 0.834000, valid loss: 176.085276
epoch: 4534, train precision: 0.983111, train loss: 19.871473, valid precision: 0.845600, valid loss: 209.855788
epoch: 4535, train precision: 0.977889, train loss: 21.111505, valid precision: 0.830000, valid loss: 185.840010
epoch: 4536, train precision: 0.982000, train loss: 19.359116, valid precision: 0.837400, valid loss: 188.955655
epoch: 4537, train precision: 0.982511, train loss: 19.786471, valid precision: 0.839600, valid loss: 222.058156
epoch: 4538, train precision: 0.979222, train loss: 20.950877, valid precision: 0.831800, valid loss: 200.956848
epoch: 4539, train precision: 0.978022, train loss: 21.189395, valid precision: 0.835800, valid loss: 194.768686
epoch: 4540, train precision: 0.984289, train loss: 18.393714, valid precision: 0.835000, valid loss: 235.526972
epoch: 4541, train precision: 0.983133, train loss: 20.114373, valid precision: 0.834800, valid loss: 219.587393
epoch: 4542, train precision: 0.981444, train loss: 20.203824, valid precision: 0.830000, valid loss: 197.917332
epoch: 4543, train precision: 0.976733, train loss: 22.683486, valid precision: 0.830600, valid loss: 201.050936
epoch: 4544, train precision: 0.981422, train loss: 21.005481, valid precision: 0.829800, valid loss: 227.767727
epoch: 4545, train precision: 0.985600, train loss: 17.841626, valid precision: 0.840000, valid loss: 226.222597
epoch: 4546, train precision: 0.981978, train loss: 19.625938, valid precision: 0.833000, valid loss: 241.086827
epoch: 4547, train precision: 0.983667, train loss: 19.232430, valid precision: 0.840200, valid loss: 221.081189
epoch: 4548, train precision: 0.984022, train loss: 19.024353, valid precision: 0.837400, valid loss: 191.274766
epoch: 4549, train precision: 0.979756, train loss: 20.603627, valid precision: 0.837400, valid loss: 192.290431
epoch: 4550, train precision: 0.979733, train loss: 21.215110, valid precision: 0.831200, valid loss: 225.475584
epoch: 4551, train precision: 0.978289, train loss: 21.761055, valid precision: 0.830800, valid loss: 202.302300
epoch: 4552, train precision: 0.982089, train loss: 19.152947, valid precision: 0.836600, valid loss: 188.574938
epoch: 4553, train precision: 0.984089, train loss: 18.302859, valid precision: 0.841600, valid loss: 204.791442
epoch: 4554, train precision: 0.982422, train loss: 19.471125, valid precision: 0.839400, valid loss: 214.874382
epoch: 4555, train precision: 0.976200, train loss: 22.091386, valid precision: 0.831800, valid loss: 178.420666
epoch: 4556, train precision: 0.980044, train loss: 21.099696, valid precision: 0.834400, valid loss: 213.352775
epoch: 4557, train precision: 0.981111, train loss: 19.719987, valid precision: 0.834400, valid loss: 192.633891
epoch: 4558, train precision: 0.979400, train loss: 21.855640, valid precision: 0.830800, valid loss: 235.890671
epoch: 4559, train precision: 0.981400, train loss: 19.510106, valid precision: 0.833200, valid loss: 202.042640
epoch: 4560, train precision: 0.980022, train loss: 20.913205, valid precision: 0.836800, valid loss: 239.393420
epoch: 4561, train precision: 0.982844, train loss: 18.517637, valid precision: 0.837000, valid loss: 191.719704
epoch: 4562, train precision: 0.978356, train loss: 21.815996, valid precision: 0.832800, valid loss: 215.004658
epoch: 4563, train precision: 0.987489, train loss: 17.173297, valid precision: 0.836800, valid loss: 233.364403
epoch: 4564, train precision: 0.981200, train loss: 20.263214, valid precision: 0.836400, valid loss: 213.751380
epoch: 4565, train precision: 0.981711, train loss: 20.284808, valid precision: 0.832800, valid loss: 233.491297
epoch: 4566, train precision: 0.977311, train loss: 21.755092, valid precision: 0.834000, valid loss: 198.872246
epoch: 4567, train precision: 0.977600, train loss: 22.047457, valid precision: 0.829000, valid loss: 200.174026
epoch: 4568, train precision: 0.983600, train loss: 18.565130, valid precision: 0.840400, valid loss: 217.226499
epoch: 4569, train precision: 0.983644, train loss: 18.592410, valid precision: 0.841000, valid loss: 201.174363
epoch: 4570, train precision: 0.983289, train loss: 19.813583, valid precision: 0.837600, valid loss: 224.681500
epoch: 4571, train precision: 0.973356, train loss: 24.083805, valid precision: 0.825400, valid loss: 196.904797
epoch: 4572, train precision: 0.984044, train loss: 18.705627, valid precision: 0.830600, valid loss: 216.951434
epoch: 4573, train precision: 0.984133, train loss: 18.656765, valid precision: 0.835200, valid loss: 230.616310
epoch: 4574, train precision: 0.982133, train loss: 19.144749, valid precision: 0.836000, valid loss: 189.610203
epoch: 4575, train precision: 0.980667, train loss: 21.850237, valid precision: 0.834400, valid loss: 247.054666
epoch: 4576, train precision: 0.978356, train loss: 20.260293, valid precision: 0.836000, valid loss: 187.583515
epoch: 4577, train precision: 0.982356, train loss: 19.694301, valid precision: 0.833800, valid loss: 220.606458
epoch: 4578, train precision: 0.984067, train loss: 19.154417, valid precision: 0.836600, valid loss: 220.421896
epoch: 4579, train precision: 0.978689, train loss: 21.285436, valid precision: 0.834000, valid loss: 214.709643
epoch: 4580, train precision: 0.984067, train loss: 18.032574, valid precision: 0.837400, valid loss: 200.284681
epoch: 4581, train precision: 0.974600, train loss: 22.654028, valid precision: 0.827800, valid loss: 197.850614
epoch: 4582, train precision: 0.983044, train loss: 20.015213, valid precision: 0.841400, valid loss: 236.102737
epoch: 4583, train precision: 0.983556, train loss: 19.028860, valid precision: 0.833800, valid loss: 225.165949
epoch: 4584, train precision: 0.983822, train loss: 18.965628, valid precision: 0.832400, valid loss: 248.091394
epoch: 4585, train precision: 0.981333, train loss: 19.604181, valid precision: 0.831200, valid loss: 197.889543
epoch: 4586, train precision: 0.980000, train loss: 21.225979, valid precision: 0.834000, valid loss: 203.599057
epoch: 4587, train precision: 0.985622, train loss: 18.638902, valid precision: 0.829800, valid loss: 239.554351
epoch: 4588, train precision: 0.975489, train loss: 23.072670, valid precision: 0.834400, valid loss: 199.623802
epoch: 4589, train precision: 0.981089, train loss: 20.229672, valid precision: 0.831800, valid loss: 211.817792
epoch: 4590, train precision: 0.978622, train loss: 21.002788, valid precision: 0.829400, valid loss: 212.325046
epoch: 4591, train precision: 0.978289, train loss: 21.428048, valid precision: 0.831000, valid loss: 195.740638
epoch: 4592, train precision: 0.981733, train loss: 19.829973, valid precision: 0.838000, valid loss: 201.316162
epoch: 4593, train precision: 0.984022, train loss: 18.410402, valid precision: 0.832800, valid loss: 196.207767
epoch: 4594, train precision: 0.982578, train loss: 19.113762, valid precision: 0.844600, valid loss: 203.007789
epoch: 4595, train precision: 0.982778, train loss: 19.176060, valid precision: 0.833800, valid loss: 205.182548
epoch: 4596, train precision: 0.981556, train loss: 19.907459, valid precision: 0.835800, valid loss: 208.593073
epoch: 4597, train precision: 0.983022, train loss: 19.006378, valid precision: 0.838000, valid loss: 190.662946
epoch: 4598, train precision: 0.980733, train loss: 21.705133, valid precision: 0.838200, valid loss: 224.907312
epoch: 4599, train precision: 0.984978, train loss: 18.945487, valid precision: 0.836200, valid loss: 237.035192
epoch: 4600, train precision: 0.983000, train loss: 19.107963, valid precision: 0.840000, valid loss: 209.972081
epoch: 4601, train precision: 0.984778, train loss: 17.923409, valid precision: 0.837000, valid loss: 196.641154
epoch: 4602, train precision: 0.979911, train loss: 22.283418, valid precision: 0.835800, valid loss: 256.231274
epoch: 4603, train precision: 0.978511, train loss: 21.331475, valid precision: 0.834200, valid loss: 186.978705
epoch: 4604, train precision: 0.979133, train loss: 21.402755, valid precision: 0.827200, valid loss: 194.849447
epoch: 4605, train precision: 0.984622, train loss: 19.403961, valid precision: 0.834400, valid loss: 240.476708
epoch: 4606, train precision: 0.979178, train loss: 20.838709, valid precision: 0.835400, valid loss: 177.394823
epoch: 4607, train precision: 0.983311, train loss: 18.695316, valid precision: 0.837400, valid loss: 208.848484
epoch: 4608, train precision: 0.976244, train loss: 22.869648, valid precision: 0.827400, valid loss: 228.328243
epoch: 4609, train precision: 0.980467, train loss: 20.294943, valid precision: 0.836000, valid loss: 213.874441
epoch: 4610, train precision: 0.982356, train loss: 19.597933, valid precision: 0.836000, valid loss: 206.968045
epoch: 4611, train precision: 0.984467, train loss: 18.347309, valid precision: 0.835600, valid loss: 200.993415
epoch: 4612, train precision: 0.977311, train loss: 22.421921, valid precision: 0.831000, valid loss: 223.429515
epoch: 4613, train precision: 0.979067, train loss: 21.269071, valid precision: 0.836600, valid loss: 209.440901
epoch: 4614, train precision: 0.983089, train loss: 20.177426, valid precision: 0.833600, valid loss: 223.269072
epoch: 4615, train precision: 0.975867, train loss: 22.334811, valid precision: 0.832600, valid loss: 177.096469
epoch: 4616, train precision: 0.973267, train loss: 23.034160, valid precision: 0.827800, valid loss: 185.031030
epoch: 4617, train precision: 0.980711, train loss: 20.194534, valid precision: 0.831800, valid loss: 204.537807
epoch: 4618, train precision: 0.984533, train loss: 18.924639, valid precision: 0.834400, valid loss: 241.677094
epoch: 4619, train precision: 0.981778, train loss: 19.721225, valid precision: 0.830400, valid loss: 188.102874
epoch: 4620, train precision: 0.986711, train loss: 17.158118, valid precision: 0.837600, valid loss: 209.905652
epoch: 4621, train precision: 0.985756, train loss: 18.203628, valid precision: 0.843200, valid loss: 240.117364
epoch: 4622, train precision: 0.980933, train loss: 20.084641, valid precision: 0.841200, valid loss: 199.407621
epoch: 4623, train precision: 0.984889, train loss: 18.524509, valid precision: 0.837600, valid loss: 199.556723
epoch: 4624, train precision: 0.984578, train loss: 18.631501, valid precision: 0.838000, valid loss: 204.703298
epoch: 4625, train precision: 0.975200, train loss: 22.828340, valid precision: 0.829400, valid loss: 184.799090
epoch: 4626, train precision: 0.980200, train loss: 20.455189, valid precision: 0.835800, valid loss: 190.986969
epoch: 4627, train precision: 0.979756, train loss: 20.531919, valid precision: 0.833800, valid loss: 203.434492
epoch: 4628, train precision: 0.984533, train loss: 19.045272, valid precision: 0.838200, valid loss: 205.199873
epoch: 4629, train precision: 0.981667, train loss: 20.206318, valid precision: 0.838200, valid loss: 189.772674
epoch: 4630, train precision: 0.982422, train loss: 19.463549, valid precision: 0.838600, valid loss: 202.249956
epoch: 4631, train precision: 0.978111, train loss: 21.404997, valid precision: 0.833800, valid loss: 183.255001
epoch: 4632, train precision: 0.976911, train loss: 20.913329, valid precision: 0.835800, valid loss: 172.541783
epoch: 4633, train precision: 0.982844, train loss: 18.609469, valid precision: 0.839200, valid loss: 190.129815
epoch: 4634, train precision: 0.980911, train loss: 19.304606, valid precision: 0.836600, valid loss: 181.251989
epoch: 4635, train precision: 0.984200, train loss: 18.636760, valid precision: 0.841000, valid loss: 200.498668
epoch: 4636, train precision: 0.981133, train loss: 19.574314, valid precision: 0.836600, valid loss: 193.199568
epoch: 4637, train precision: 0.984089, train loss: 19.217777, valid precision: 0.836000, valid loss: 230.117378
epoch: 4638, train precision: 0.980800, train loss: 20.696111, valid precision: 0.836400, valid loss: 217.203347
epoch: 4639, train precision: 0.981911, train loss: 20.228915, valid precision: 0.837800, valid loss: 211.349498
epoch: 4640, train precision: 0.982911, train loss: 18.968454, valid precision: 0.838200, valid loss: 191.231783
epoch: 4641, train precision: 0.982578, train loss: 19.218653, valid precision: 0.838800, valid loss: 194.737779
epoch: 4642, train precision: 0.981200, train loss: 19.954584, valid precision: 0.830400, valid loss: 221.412631
epoch: 4643, train precision: 0.982511, train loss: 19.262882, valid precision: 0.833600, valid loss: 193.952456
epoch: 4644, train precision: 0.981889, train loss: 19.929598, valid precision: 0.834000, valid loss: 197.516701
epoch: 4645, train precision: 0.985267, train loss: 18.769999, valid precision: 0.834600, valid loss: 220.323752
epoch: 4646, train precision: 0.973311, train loss: 25.761355, valid precision: 0.825600, valid loss: 227.095570
epoch: 4647, train precision: 0.983533, train loss: 19.298501, valid precision: 0.836400, valid loss: 206.738174
epoch: 4648, train precision: 0.982178, train loss: 20.607256, valid precision: 0.834600, valid loss: 230.269043
epoch: 4649, train precision: 0.981711, train loss: 20.443284, valid precision: 0.842200, valid loss: 213.316025
epoch: 4650, train precision: 0.983356, train loss: 19.385082, valid precision: 0.838200, valid loss: 219.629219
epoch: 4651, train precision: 0.984600, train loss: 18.969628, valid precision: 0.836400, valid loss: 232.044581
epoch: 4652, train precision: 0.979556, train loss: 20.123750, valid precision: 0.834000, valid loss: 207.343811
epoch: 4653, train precision: 0.983356, train loss: 19.272079, valid precision: 0.837400, valid loss: 208.464792
epoch: 4654, train precision: 0.984822, train loss: 18.496512, valid precision: 0.838800, valid loss: 227.460281
epoch: 4655, train precision: 0.980800, train loss: 21.916367, valid precision: 0.833800, valid loss: 224.776762
epoch: 4656, train precision: 0.980444, train loss: 20.463565, valid precision: 0.830200, valid loss: 202.798743
epoch: 4657, train precision: 0.982400, train loss: 19.089457, valid precision: 0.836600, valid loss: 209.560447
epoch: 4658, train precision: 0.977556, train loss: 22.213412, valid precision: 0.832000, valid loss: 217.838995
epoch: 4659, train precision: 0.986867, train loss: 17.450123, valid precision: 0.845200, valid loss: 226.955671
epoch: 4660, train precision: 0.983533, train loss: 18.905610, valid precision: 0.842800, valid loss: 232.446488
epoch: 4661, train precision: 0.981067, train loss: 20.934368, valid precision: 0.839200, valid loss: 210.783278
epoch: 4662, train precision: 0.982333, train loss: 19.579460, valid precision: 0.834600, valid loss: 202.473043
epoch: 4663, train precision: 0.984467, train loss: 18.529223, valid precision: 0.837600, valid loss: 219.100851
epoch: 4664, train precision: 0.983222, train loss: 18.879689, valid precision: 0.836800, valid loss: 204.437572
epoch: 4665, train precision: 0.983667, train loss: 19.453774, valid precision: 0.840600, valid loss: 213.058327
epoch: 4666, train precision: 0.980311, train loss: 20.974070, valid precision: 0.837600, valid loss: 215.047469
epoch: 4667, train precision: 0.984956, train loss: 18.173430, valid precision: 0.842400, valid loss: 200.337512
epoch: 4668, train precision: 0.984689, train loss: 18.839072, valid precision: 0.838600, valid loss: 229.250034
epoch: 4669, train precision: 0.980444, train loss: 20.288577, valid precision: 0.839800, valid loss: 193.993947
epoch: 4670, train precision: 0.983444, train loss: 19.593318, valid precision: 0.832600, valid loss: 230.435696
epoch: 4671, train precision: 0.975867, train loss: 21.852400, valid precision: 0.831000, valid loss: 186.678917
epoch: 4672, train precision: 0.979911, train loss: 21.130312, valid precision: 0.835200, valid loss: 214.755061
epoch: 4673, train precision: 0.982067, train loss: 20.522833, valid precision: 0.840400, valid loss: 219.151081
epoch: 4674, train precision: 0.983578, train loss: 18.795181, valid precision: 0.841200, valid loss: 212.124833
epoch: 4675, train precision: 0.982844, train loss: 19.949782, valid precision: 0.841800, valid loss: 212.613682
epoch: 4676, train precision: 0.985578, train loss: 19.181843, valid precision: 0.838200, valid loss: 259.306479
epoch: 4677, train precision: 0.984889, train loss: 17.929639, valid precision: 0.836000, valid loss: 222.689389
epoch: 4678, train precision: 0.982222, train loss: 20.076704, valid precision: 0.835200, valid loss: 233.684781
epoch: 4679, train precision: 0.981111, train loss: 21.489900, valid precision: 0.836200, valid loss: 221.680782
epoch: 4680, train precision: 0.978311, train loss: 22.226069, valid precision: 0.835800, valid loss: 199.835107
epoch: 4681, train precision: 0.984800, train loss: 19.082633, valid precision: 0.839200, valid loss: 227.483419
epoch: 4682, train precision: 0.976556, train loss: 23.267496, valid precision: 0.831000, valid loss: 210.388297
epoch: 4683, train precision: 0.976511, train loss: 23.131839, valid precision: 0.831200, valid loss: 212.452383
epoch: 4684, train precision: 0.983578, train loss: 19.207657, valid precision: 0.837000, valid loss: 209.195500
epoch: 4685, train precision: 0.984889, train loss: 18.437619, valid precision: 0.836400, valid loss: 199.212190
epoch: 4686, train precision: 0.978222, train loss: 21.431422, valid precision: 0.835800, valid loss: 182.356278
epoch: 4687, train precision: 0.983800, train loss: 19.582535, valid precision: 0.837200, valid loss: 212.829268
epoch: 4688, train precision: 0.983289, train loss: 18.942090, valid precision: 0.838400, valid loss: 213.475639
epoch: 4689, train precision: 0.983200, train loss: 20.049258, valid precision: 0.839000, valid loss: 231.713120
epoch: 4690, train precision: 0.984244, train loss: 18.380054, valid precision: 0.838800, valid loss: 204.092460
epoch: 4691, train precision: 0.982600, train loss: 19.425994, valid precision: 0.835400, valid loss: 197.801164
epoch: 4692, train precision: 0.969267, train loss: 25.441232, valid precision: 0.828800, valid loss: 182.136875
epoch: 4693, train precision: 0.982667, train loss: 19.339326, valid precision: 0.842800, valid loss: 189.251633
epoch: 4694, train precision: 0.979956, train loss: 20.902820, valid precision: 0.838600, valid loss: 213.448875
epoch: 4695, train precision: 0.976600, train loss: 22.651051, valid precision: 0.829000, valid loss: 205.692717
epoch: 4696, train precision: 0.980511, train loss: 20.322298, valid precision: 0.842200, valid loss: 186.269142
epoch: 4697, train precision: 0.984222, train loss: 18.316713, valid precision: 0.841400, valid loss: 211.475074
epoch: 4698, train precision: 0.981022, train loss: 19.597746, valid precision: 0.843000, valid loss: 180.158399
epoch: 4699, train precision: 0.978600, train loss: 22.490935, valid precision: 0.837200, valid loss: 219.561385
epoch: 4700, train precision: 0.983756, train loss: 18.992300, valid precision: 0.835800, valid loss: 212.914385
epoch: 4701, train precision: 0.979111, train loss: 21.575707, valid precision: 0.830800, valid loss: 212.621004
epoch: 4702, train precision: 0.980311, train loss: 19.665256, valid precision: 0.843800, valid loss: 183.917537
epoch: 4703, train precision: 0.984444, train loss: 19.688561, valid precision: 0.836400, valid loss: 252.951532
epoch: 4704, train precision: 0.976978, train loss: 21.798896, valid precision: 0.834400, valid loss: 207.950052
epoch: 4705, train precision: 0.981756, train loss: 20.626045, valid precision: 0.835600, valid loss: 233.324913
epoch: 4706, train precision: 0.978756, train loss: 21.734306, valid precision: 0.836000, valid loss: 207.942544
epoch: 4707, train precision: 0.982422, train loss: 19.824103, valid precision: 0.835400, valid loss: 229.133900
epoch: 4708, train precision: 0.979178, train loss: 20.729293, valid precision: 0.833000, valid loss: 187.591938
epoch: 4709, train precision: 0.983489, train loss: 19.620398, valid precision: 0.837000, valid loss: 245.520958
epoch: 4710, train precision: 0.984200, train loss: 18.556090, valid precision: 0.839800, valid loss: 201.156343
epoch: 4711, train precision: 0.984022, train loss: 18.267633, valid precision: 0.841600, valid loss: 206.993965
epoch: 4712, train precision: 0.977022, train loss: 21.088875, valid precision: 0.830600, valid loss: 182.389004
epoch: 4713, train precision: 0.980467, train loss: 20.294381, valid precision: 0.832000, valid loss: 210.661754
epoch: 4714, train precision: 0.983822, train loss: 19.141036, valid precision: 0.843400, valid loss: 216.180742
epoch: 4715, train precision: 0.979622, train loss: 21.438982, valid precision: 0.832800, valid loss: 218.746834
epoch: 4716, train precision: 0.980133, train loss: 19.651723, valid precision: 0.834000, valid loss: 199.543553
epoch: 4717, train precision: 0.981667, train loss: 19.769891, valid precision: 0.838200, valid loss: 205.268677
epoch: 4718, train precision: 0.983756, train loss: 19.878153, valid precision: 0.838000, valid loss: 229.455102
epoch: 4719, train precision: 0.982267, train loss: 19.452002, valid precision: 0.834400, valid loss: 200.821962
epoch: 4720, train precision: 0.985067, train loss: 18.880773, valid precision: 0.837800, valid loss: 234.446277
epoch: 4721, train precision: 0.983600, train loss: 19.108109, valid precision: 0.837400, valid loss: 212.298079
epoch: 4722, train precision: 0.980133, train loss: 20.720782, valid precision: 0.834400, valid loss: 212.967913
epoch: 4723, train precision: 0.981933, train loss: 19.520595, valid precision: 0.834800, valid loss: 202.937027
epoch: 4724, train precision: 0.975711, train loss: 22.673269, valid precision: 0.832400, valid loss: 201.513684
epoch: 4725, train precision: 0.984356, train loss: 18.337825, valid precision: 0.842400, valid loss: 216.276376
epoch: 4726, train precision: 0.977822, train loss: 21.210622, valid precision: 0.830800, valid loss: 181.173168
epoch: 4727, train precision: 0.978956, train loss: 21.148214, valid precision: 0.838400, valid loss: 197.522787
epoch: 4728, train precision: 0.978689, train loss: 20.629467, valid precision: 0.832000, valid loss: 186.293112
epoch: 4729, train precision: 0.980467, train loss: 20.107128, valid precision: 0.831200, valid loss: 194.904216
epoch: 4730, train precision: 0.986711, train loss: 17.919163, valid precision: 0.839200, valid loss: 234.909511
epoch: 4731, train precision: 0.983111, train loss: 19.491858, valid precision: 0.837800, valid loss: 214.621431
epoch: 4732, train precision: 0.976733, train loss: 21.805881, valid precision: 0.833400, valid loss: 185.833185
epoch: 4733, train precision: 0.981244, train loss: 19.833740, valid precision: 0.839600, valid loss: 191.710151
epoch: 4734, train precision: 0.980689, train loss: 20.420299, valid precision: 0.836000, valid loss: 200.465782
epoch: 4735, train precision: 0.986067, train loss: 17.912505, valid precision: 0.836200, valid loss: 242.045173
epoch: 4736, train precision: 0.977378, train loss: 22.121241, valid precision: 0.836000, valid loss: 195.979584
epoch: 4737, train precision: 0.985311, train loss: 18.077275, valid precision: 0.837800, valid loss: 228.375004
epoch: 4738, train precision: 0.982622, train loss: 19.250625, valid precision: 0.835600, valid loss: 206.221555
epoch: 4739, train precision: 0.976133, train loss: 22.944526, valid precision: 0.833800, valid loss: 213.517277
epoch: 4740, train precision: 0.981844, train loss: 19.833227, valid precision: 0.840000, valid loss: 187.486541
epoch: 4741, train precision: 0.984733, train loss: 19.091411, valid precision: 0.838600, valid loss: 255.904095
epoch: 4742, train precision: 0.979889, train loss: 20.852732, valid precision: 0.833400, valid loss: 210.169952
epoch: 4743, train precision: 0.981067, train loss: 20.353802, valid precision: 0.836600, valid loss: 207.691235
epoch: 4744, train precision: 0.981444, train loss: 20.363535, valid precision: 0.839200, valid loss: 206.763787
epoch: 4745, train precision: 0.983111, train loss: 19.165200, valid precision: 0.840600, valid loss: 231.229779
epoch: 4746, train precision: 0.982933, train loss: 20.646154, valid precision: 0.841200, valid loss: 242.933647
epoch: 4747, train precision: 0.975200, train loss: 23.820637, valid precision: 0.824800, valid loss: 233.209193
epoch: 4748, train precision: 0.980400, train loss: 20.399903, valid precision: 0.836400, valid loss: 206.741114
epoch: 4749, train precision: 0.982444, train loss: 19.088954, valid precision: 0.834400, valid loss: 199.533565
epoch: 4750, train precision: 0.982822, train loss: 19.614373, valid precision: 0.838000, valid loss: 229.774660
epoch: 4751, train precision: 0.977400, train loss: 21.354056, valid precision: 0.832600, valid loss: 209.930329
epoch: 4752, train precision: 0.982911, train loss: 19.258489, valid precision: 0.831200, valid loss: 208.827885
epoch: 4753, train precision: 0.981533, train loss: 20.315070, valid precision: 0.829400, valid loss: 217.889905
epoch: 4754, train precision: 0.982511, train loss: 19.293559, valid precision: 0.833200, valid loss: 207.722945
epoch: 4755, train precision: 0.983533, train loss: 18.860436, valid precision: 0.827200, valid loss: 209.930941
epoch: 4756, train precision: 0.981778, train loss: 20.268955, valid precision: 0.830600, valid loss: 211.906143
epoch: 4757, train precision: 0.980311, train loss: 20.386426, valid precision: 0.831200, valid loss: 213.427354
epoch: 4758, train precision: 0.977422, train loss: 22.104774, valid precision: 0.835000, valid loss: 202.478267
epoch: 4759, train precision: 0.980933, train loss: 20.798830, valid precision: 0.834400, valid loss: 212.210951
epoch: 4760, train precision: 0.982667, train loss: 18.625445, valid precision: 0.835400, valid loss: 182.980969
epoch: 4761, train precision: 0.985756, train loss: 18.429527, valid precision: 0.837200, valid loss: 210.628893
epoch: 4762, train precision: 0.981044, train loss: 20.206421, valid precision: 0.838000, valid loss: 217.600644
epoch: 4763, train precision: 0.979600, train loss: 22.137450, valid precision: 0.831000, valid loss: 243.031016
epoch: 4764, train precision: 0.982022, train loss: 20.867910, valid precision: 0.832000, valid loss: 241.865747
epoch: 4765, train precision: 0.983244, train loss: 18.954120, valid precision: 0.836400, valid loss: 212.136768
epoch: 4766, train precision: 0.979267, train loss: 21.776090, valid precision: 0.834600, valid loss: 202.294261
epoch: 4767, train precision: 0.979933, train loss: 20.786781, valid precision: 0.836600, valid loss: 204.772369
epoch: 4768, train precision: 0.977533, train loss: 22.070870, valid precision: 0.831200, valid loss: 204.621911
epoch: 4769, train precision: 0.985933, train loss: 18.637335, valid precision: 0.841400, valid loss: 229.292563
epoch: 4770, train precision: 0.981400, train loss: 20.633283, valid precision: 0.836000, valid loss: 210.601219
epoch: 4771, train precision: 0.983289, train loss: 18.761244, valid precision: 0.835200, valid loss: 199.895810
epoch: 4772, train precision: 0.984911, train loss: 18.631091, valid precision: 0.836800, valid loss: 220.792557
epoch: 4773, train precision: 0.982044, train loss: 19.759477, valid precision: 0.831400, valid loss: 220.496827
epoch: 4774, train precision: 0.976933, train loss: 22.573558, valid precision: 0.831800, valid loss: 188.292138
epoch: 4775, train precision: 0.980622, train loss: 21.331396, valid precision: 0.833200, valid loss: 234.191553
epoch: 4776, train precision: 0.985178, train loss: 17.883660, valid precision: 0.838200, valid loss: 190.429999
epoch: 4777, train precision: 0.977933, train loss: 22.188475, valid precision: 0.831000, valid loss: 173.940306
epoch: 4778, train precision: 0.984756, train loss: 18.417562, valid precision: 0.837000, valid loss: 215.061279
epoch: 4779, train precision: 0.979533, train loss: 21.037747, valid precision: 0.835000, valid loss: 207.571468
epoch: 4780, train precision: 0.984267, train loss: 18.273375, valid precision: 0.841800, valid loss: 196.580801
epoch: 4781, train precision: 0.985267, train loss: 17.803934, valid precision: 0.841600, valid loss: 196.870233
epoch: 4782, train precision: 0.977489, train loss: 22.397432, valid precision: 0.832000, valid loss: 207.132141
epoch: 4783, train precision: 0.981911, train loss: 20.528801, valid precision: 0.839000, valid loss: 216.572565
epoch: 4784, train precision: 0.983400, train loss: 19.430006, valid precision: 0.838000, valid loss: 210.251376
epoch: 4785, train precision: 0.983222, train loss: 19.317695, valid precision: 0.837400, valid loss: 210.811265
epoch: 4786, train precision: 0.982933, train loss: 18.963746, valid precision: 0.836000, valid loss: 203.233502
epoch: 4787, train precision: 0.984844, train loss: 17.816367, valid precision: 0.834800, valid loss: 187.308461
epoch: 4788, train precision: 0.973133, train loss: 23.592039, valid precision: 0.828400, valid loss: 196.873843
epoch: 4789, train precision: 0.977711, train loss: 21.305673, valid precision: 0.834000, valid loss: 180.187260
epoch: 4790, train precision: 0.981511, train loss: 19.438022, valid precision: 0.836200, valid loss: 199.255745
epoch: 4791, train precision: 0.982333, train loss: 19.903987, valid precision: 0.841200, valid loss: 208.455899
epoch: 4792, train precision: 0.983711, train loss: 18.675654, valid precision: 0.842400, valid loss: 186.542194
epoch: 4793, train precision: 0.980289, train loss: 20.426694, valid precision: 0.832000, valid loss: 193.374444
epoch: 4794, train precision: 0.985156, train loss: 18.108646, valid precision: 0.834800, valid loss: 196.033473
epoch: 4795, train precision: 0.981378, train loss: 20.313732, valid precision: 0.834600, valid loss: 217.182742
epoch: 4796, train precision: 0.979356, train loss: 20.631116, valid precision: 0.834800, valid loss: 200.936182
epoch: 4797, train precision: 0.978778, train loss: 21.744030, valid precision: 0.832200, valid loss: 221.396793
epoch: 4798, train precision: 0.978222, train loss: 22.127148, valid precision: 0.832200, valid loss: 197.131756
epoch: 4799, train precision: 0.974444, train loss: 22.735537, valid precision: 0.823800, valid loss: 178.264156
epoch: 4800, train precision: 0.980489, train loss: 20.230525, valid precision: 0.836800, valid loss: 188.619050
epoch: 4801, train precision: 0.977333, train loss: 21.696023, valid precision: 0.827600, valid loss: 189.048727
epoch: 4802, train precision: 0.983711, train loss: 19.617381, valid precision: 0.836400, valid loss: 232.332093
epoch: 4803, train precision: 0.984467, train loss: 18.808635, valid precision: 0.832600, valid loss: 224.000698
epoch: 4804, train precision: 0.981756, train loss: 19.853352, valid precision: 0.828600, valid loss: 210.173192
epoch: 4805, train precision: 0.983244, train loss: 19.065344, valid precision: 0.834800, valid loss: 222.897525
epoch: 4806, train precision: 0.982622, train loss: 18.855734, valid precision: 0.839000, valid loss: 192.540819
epoch: 4807, train precision: 0.981778, train loss: 19.415044, valid precision: 0.832200, valid loss: 184.437068
epoch: 4808, train precision: 0.982667, train loss: 19.006753, valid precision: 0.836400, valid loss: 200.696385
epoch: 4809, train precision: 0.981933, train loss: 19.756959, valid precision: 0.837800, valid loss: 196.830095
epoch: 4810, train precision: 0.982578, train loss: 19.830390, valid precision: 0.838800, valid loss: 197.753946
epoch: 4811, train precision: 0.985800, train loss: 18.461082, valid precision: 0.836000, valid loss: 256.167502
epoch: 4812, train precision: 0.979778, train loss: 20.465663, valid precision: 0.835600, valid loss: 194.612714
epoch: 4813, train precision: 0.985689, train loss: 18.196553, valid precision: 0.836400, valid loss: 229.018867
epoch: 4814, train precision: 0.982356, train loss: 20.063054, valid precision: 0.832000, valid loss: 232.216951
epoch: 4815, train precision: 0.980333, train loss: 20.344011, valid precision: 0.831000, valid loss: 219.639051
epoch: 4816, train precision: 0.981600, train loss: 19.953692, valid precision: 0.829800, valid loss: 203.810040
epoch: 4817, train precision: 0.983667, train loss: 18.703918, valid precision: 0.833800, valid loss: 202.440274
epoch: 4818, train precision: 0.983867, train loss: 18.496750, valid precision: 0.840000, valid loss: 211.324517
epoch: 4819, train precision: 0.983467, train loss: 19.690963, valid precision: 0.838000, valid loss: 215.643708
epoch: 4820, train precision: 0.983622, train loss: 19.484775, valid precision: 0.836400, valid loss: 232.250409
epoch: 4821, train precision: 0.981444, train loss: 19.597749, valid precision: 0.838400, valid loss: 205.418839
epoch: 4822, train precision: 0.985222, train loss: 18.498802, valid precision: 0.840200, valid loss: 226.862615
epoch: 4823, train precision: 0.974844, train loss: 22.657374, valid precision: 0.835200, valid loss: 196.229344
epoch: 4824, train precision: 0.980600, train loss: 20.964040, valid precision: 0.828800, valid loss: 248.800190
epoch: 4825, train precision: 0.985200, train loss: 18.965181, valid precision: 0.834400, valid loss: 221.328265
epoch: 4826, train precision: 0.981867, train loss: 19.601023, valid precision: 0.834200, valid loss: 211.276648
epoch: 4827, train precision: 0.983311, train loss: 18.881084, valid precision: 0.839800, valid loss: 211.377401
epoch: 4828, train precision: 0.981000, train loss: 20.030373, valid precision: 0.835600, valid loss: 198.758231
epoch: 4829, train precision: 0.980778, train loss: 20.869725, valid precision: 0.835000, valid loss: 207.978840
epoch: 4830, train precision: 0.986400, train loss: 17.701754, valid precision: 0.834600, valid loss: 238.715487
epoch: 4831, train precision: 0.979889, train loss: 19.811414, valid precision: 0.837400, valid loss: 172.028010
epoch: 4832, train precision: 0.982400, train loss: 19.925158, valid precision: 0.838400, valid loss: 209.248776
epoch: 4833, train precision: 0.981533, train loss: 19.373579, valid precision: 0.835200, valid loss: 194.319903
epoch: 4834, train precision: 0.982711, train loss: 19.276075, valid precision: 0.836600, valid loss: 206.556247
epoch: 4835, train precision: 0.980267, train loss: 21.509105, valid precision: 0.830800, valid loss: 248.099216
epoch: 4836, train precision: 0.980067, train loss: 20.243945, valid precision: 0.835000, valid loss: 197.959395
epoch: 4837, train precision: 0.974444, train loss: 24.183014, valid precision: 0.830200, valid loss: 207.734585
epoch: 4838, train precision: 0.983667, train loss: 19.186775, valid precision: 0.833600, valid loss: 219.868521
epoch: 4839, train precision: 0.984889, train loss: 18.093283, valid precision: 0.833400, valid loss: 217.727605
epoch: 4840, train precision: 0.977689, train loss: 22.092418, valid precision: 0.828000, valid loss: 218.122626
epoch: 4841, train precision: 0.978956, train loss: 20.793813, valid precision: 0.828000, valid loss: 181.891279
epoch: 4842, train precision: 0.979844, train loss: 22.793713, valid precision: 0.836000, valid loss: 241.161745
epoch: 4843, train precision: 0.984244, train loss: 18.741265, valid precision: 0.835600, valid loss: 207.673341
epoch: 4844, train precision: 0.986267, train loss: 17.645026, valid precision: 0.831800, valid loss: 220.437795
epoch: 4845, train precision: 0.979622, train loss: 21.101816, valid precision: 0.834600, valid loss: 203.728587
epoch: 4846, train precision: 0.980089, train loss: 20.020150, valid precision: 0.830200, valid loss: 178.876435
epoch: 4847, train precision: 0.983467, train loss: 19.356389, valid precision: 0.829000, valid loss: 217.273775
epoch: 4848, train precision: 0.985733, train loss: 17.687964, valid precision: 0.837600, valid loss: 187.066766
epoch: 4849, train precision: 0.984778, train loss: 18.636315, valid precision: 0.832600, valid loss: 210.894334
epoch: 4850, train precision: 0.980133, train loss: 21.131069, valid precision: 0.826600, valid loss: 219.473925
epoch: 4851, train precision: 0.982511, train loss: 19.586714, valid precision: 0.833800, valid loss: 202.438474
epoch: 4852, train precision: 0.982133, train loss: 19.201977, valid precision: 0.830200, valid loss: 205.226904
epoch: 4853, train precision: 0.980889, train loss: 19.692107, valid precision: 0.842000, valid loss: 191.591583
epoch: 4854, train precision: 0.983000, train loss: 18.871950, valid precision: 0.837000, valid loss: 201.845958
epoch: 4855, train precision: 0.984200, train loss: 19.562534, valid precision: 0.839800, valid loss: 227.980991
epoch: 4856, train precision: 0.982956, train loss: 19.010804, valid precision: 0.831000, valid loss: 176.990624
epoch: 4857, train precision: 0.982511, train loss: 19.652342, valid precision: 0.835600, valid loss: 208.679491
epoch: 4858, train precision: 0.985089, train loss: 18.685878, valid precision: 0.836400, valid loss: 229.369164
epoch: 4859, train precision: 0.981111, train loss: 20.563479, valid precision: 0.833400, valid loss: 212.961958
epoch: 4860, train precision: 0.978956, train loss: 20.352804, valid precision: 0.832400, valid loss: 199.324026
epoch: 4861, train precision: 0.979422, train loss: 21.456202, valid precision: 0.838400, valid loss: 218.547314
epoch: 4862, train precision: 0.978889, train loss: 21.084103, valid precision: 0.834000, valid loss: 194.287705
epoch: 4863, train precision: 0.982911, train loss: 19.580544, valid precision: 0.836000, valid loss: 230.736728
epoch: 4864, train precision: 0.985244, train loss: 18.876306, valid precision: 0.837600, valid loss: 229.506656
epoch: 4865, train precision: 0.982222, train loss: 19.387272, valid precision: 0.830200, valid loss: 207.720274
epoch: 4866, train precision: 0.977533, train loss: 21.805824, valid precision: 0.830200, valid loss: 192.490563
epoch: 4867, train precision: 0.983778, train loss: 18.694469, valid precision: 0.835000, valid loss: 208.645260
epoch: 4868, train precision: 0.985111, train loss: 18.644897, valid precision: 0.832000, valid loss: 235.243754
epoch: 4869, train precision: 0.980378, train loss: 20.423864, valid precision: 0.835600, valid loss: 191.801552
epoch: 4870, train precision: 0.983844, train loss: 20.634804, valid precision: 0.839400, valid loss: 258.483602
epoch: 4871, train precision: 0.981711, train loss: 20.353840, valid precision: 0.830400, valid loss: 217.567372
epoch: 4872, train precision: 0.981844, train loss: 20.276962, valid precision: 0.832400, valid loss: 217.122213
epoch: 4873, train precision: 0.980644, train loss: 20.871780, valid precision: 0.828200, valid loss: 206.464464
epoch: 4874, train precision: 0.983333, train loss: 19.285619, valid precision: 0.838800, valid loss: 198.103921
epoch: 4875, train precision: 0.983378, train loss: 18.536939, valid precision: 0.836200, valid loss: 180.487256
epoch: 4876, train precision: 0.979311, train loss: 20.537769, valid precision: 0.835200, valid loss: 192.913788
epoch: 4877, train precision: 0.984400, train loss: 18.954075, valid precision: 0.829800, valid loss: 211.494002
epoch: 4878, train precision: 0.983600, train loss: 18.730016, valid precision: 0.835200, valid loss: 214.132276
epoch: 4879, train precision: 0.980422, train loss: 19.960787, valid precision: 0.834400, valid loss: 200.045848
epoch: 4880, train precision: 0.983356, train loss: 18.750168, valid precision: 0.835600, valid loss: 187.282755
epoch: 4881, train precision: 0.975400, train loss: 22.637602, valid precision: 0.830400, valid loss: 178.683662
epoch: 4882, train precision: 0.976200, train loss: 21.425800, valid precision: 0.833800, valid loss: 174.486328
epoch: 4883, train precision: 0.983267, train loss: 19.313778, valid precision: 0.835200, valid loss: 188.216085
epoch: 4884, train precision: 0.970378, train loss: 23.752452, valid precision: 0.828800, valid loss: 172.286471
epoch: 4885, train precision: 0.983444, train loss: 19.534477, valid precision: 0.838600, valid loss: 234.112899
epoch: 4886, train precision: 0.979911, train loss: 21.506315, valid precision: 0.832400, valid loss: 229.100757
epoch: 4887, train precision: 0.983689, train loss: 18.591037, valid precision: 0.841400, valid loss: 196.942460
epoch: 4888, train precision: 0.982933, train loss: 19.661186, valid precision: 0.831400, valid loss: 219.544577
epoch: 4889, train precision: 0.984378, train loss: 19.134676, valid precision: 0.839800, valid loss: 244.033930
epoch: 4890, train precision: 0.983911, train loss: 19.616510, valid precision: 0.839600, valid loss: 223.756164
epoch: 4891, train precision: 0.982111, train loss: 19.148264, valid precision: 0.843600, valid loss: 196.708047
epoch: 4892, train precision: 0.987444, train loss: 16.749123, valid precision: 0.835800, valid loss: 199.970095
epoch: 4893, train precision: 0.983644, train loss: 19.135726, valid precision: 0.842400, valid loss: 217.411255
epoch: 4894, train precision: 0.980644, train loss: 21.177431, valid precision: 0.833000, valid loss: 242.484545
epoch: 4895, train precision: 0.983711, train loss: 18.870557, valid precision: 0.836000, valid loss: 185.250261
epoch: 4896, train precision: 0.982733, train loss: 19.103931, valid precision: 0.833800, valid loss: 187.759181
epoch: 4897, train precision: 0.979622, train loss: 20.959131, valid precision: 0.836400, valid loss: 171.867402
epoch: 4898, train precision: 0.982156, train loss: 20.295535, valid precision: 0.827400, valid loss: 237.771799
epoch: 4899, train precision: 0.983089, train loss: 19.540970, valid precision: 0.835400, valid loss: 234.545131
epoch: 4900, train precision: 0.979356, train loss: 20.839304, valid precision: 0.836800, valid loss: 198.449080
epoch: 4901, train precision: 0.979022, train loss: 23.147410, valid precision: 0.832000, valid loss: 242.162796
epoch: 4902, train precision: 0.986644, train loss: 16.968579, valid precision: 0.842200, valid loss: 202.376126
epoch: 4903, train precision: 0.980822, train loss: 19.892120, valid precision: 0.835000, valid loss: 182.745124
epoch: 4904, train precision: 0.983511, train loss: 19.356812, valid precision: 0.840000, valid loss: 222.500503
epoch: 4905, train precision: 0.984533, train loss: 18.661643, valid precision: 0.838200, valid loss: 223.035395
epoch: 4906, train precision: 0.981222, train loss: 20.994903, valid precision: 0.839600, valid loss: 205.689175
epoch: 4907, train precision: 0.978756, train loss: 20.272792, valid precision: 0.834000, valid loss: 184.427622
epoch: 4908, train precision: 0.985289, train loss: 18.456411, valid precision: 0.843800, valid loss: 217.323811
epoch: 4909, train precision: 0.979689, train loss: 20.485296, valid precision: 0.833200, valid loss: 194.221493
epoch: 4910, train precision: 0.978333, train loss: 20.464882, valid precision: 0.835200, valid loss: 175.931026
epoch: 4911, train precision: 0.978400, train loss: 21.232807, valid precision: 0.837800, valid loss: 201.755912
epoch: 4912, train precision: 0.978978, train loss: 21.306685, valid precision: 0.834400, valid loss: 214.160545
epoch: 4913, train precision: 0.975933, train loss: 22.759677, valid precision: 0.831800, valid loss: 197.665894
epoch: 4914, train precision: 0.975267, train loss: 22.493034, valid precision: 0.826000, valid loss: 189.269090
epoch: 4915, train precision: 0.980933, train loss: 20.305565, valid precision: 0.828600, valid loss: 226.140989
epoch: 4916, train precision: 0.977933, train loss: 20.973513, valid precision: 0.832000, valid loss: 196.275687
epoch: 4917, train precision: 0.977911, train loss: 21.784605, valid precision: 0.826800, valid loss: 200.431119
epoch: 4918, train precision: 0.978378, train loss: 21.022158, valid precision: 0.826800, valid loss: 190.465070
epoch: 4919, train precision: 0.986489, train loss: 17.976775, valid precision: 0.840800, valid loss: 231.020164
epoch: 4920, train precision: 0.985267, train loss: 18.586017, valid precision: 0.837600, valid loss: 201.745413
epoch: 4921, train precision: 0.985289, train loss: 18.704528, valid precision: 0.837600, valid loss: 232.717940
epoch: 4922, train precision: 0.983467, train loss: 18.608492, valid precision: 0.832400, valid loss: 196.017831
epoch: 4923, train precision: 0.979778, train loss: 20.655203, valid precision: 0.833800, valid loss: 196.505249
epoch: 4924, train precision: 0.980644, train loss: 20.506970, valid precision: 0.835800, valid loss: 207.595773
epoch: 4925, train precision: 0.983422, train loss: 19.546661, valid precision: 0.840800, valid loss: 215.596337
epoch: 4926, train precision: 0.984844, train loss: 18.886975, valid precision: 0.841400, valid loss: 210.051700
epoch: 4927, train precision: 0.973911, train loss: 22.887854, valid precision: 0.835200, valid loss: 162.261195
epoch: 4928, train precision: 0.979756, train loss: 20.641048, valid precision: 0.839600, valid loss: 165.901351
epoch: 4929, train precision: 0.980422, train loss: 19.709513, valid precision: 0.835600, valid loss: 182.531728
epoch: 4930, train precision: 0.982778, train loss: 19.256127, valid precision: 0.833400, valid loss: 196.774705
epoch: 4931, train precision: 0.981911, train loss: 19.696142, valid precision: 0.836800, valid loss: 182.808691
epoch: 4932, train precision: 0.984822, train loss: 18.859303, valid precision: 0.837800, valid loss: 235.030523
epoch: 4933, train precision: 0.979289, train loss: 21.042001, valid precision: 0.830600, valid loss: 210.114356
epoch: 4934, train precision: 0.982667, train loss: 19.892146, valid precision: 0.835800, valid loss: 201.549471
epoch: 4935, train precision: 0.983667, train loss: 19.297421, valid precision: 0.842400, valid loss: 210.953275
epoch: 4936, train precision: 0.983044, train loss: 19.099129, valid precision: 0.836000, valid loss: 197.071228
epoch: 4937, train precision: 0.982378, train loss: 19.393571, valid precision: 0.836400, valid loss: 204.353452
epoch: 4938, train precision: 0.980867, train loss: 20.289883, valid precision: 0.830400, valid loss: 209.709407
epoch: 4939, train precision: 0.983089, train loss: 18.724558, valid precision: 0.828200, valid loss: 222.909074
epoch: 4940, train precision: 0.986200, train loss: 17.913722, valid precision: 0.839600, valid loss: 225.441301
epoch: 4941, train precision: 0.982111, train loss: 19.293514, valid precision: 0.838200, valid loss: 194.065699
epoch: 4942, train precision: 0.982111, train loss: 19.446720, valid precision: 0.833400, valid loss: 190.075477
epoch: 4943, train precision: 0.983244, train loss: 19.351479, valid precision: 0.833000, valid loss: 216.328849
epoch: 4944, train precision: 0.984333, train loss: 18.760854, valid precision: 0.830800, valid loss: 230.235555
epoch: 4945, train precision: 0.978000, train loss: 22.007341, valid precision: 0.824200, valid loss: 205.648075
epoch: 4946, train precision: 0.981600, train loss: 20.513150, valid precision: 0.831800, valid loss: 205.605627
epoch: 4947, train precision: 0.983178, train loss: 19.918713, valid precision: 0.830200, valid loss: 252.987317
epoch: 4948, train precision: 0.969133, train loss: 25.407289, valid precision: 0.826000, valid loss: 200.604181
epoch: 4949, train precision: 0.983511, train loss: 19.145950, valid precision: 0.830600, valid loss: 211.756762
epoch: 4950, train precision: 0.983022, train loss: 18.662205, valid precision: 0.828400, valid loss: 192.936579
epoch: 4951, train precision: 0.981867, train loss: 20.450643, valid precision: 0.834200, valid loss: 230.811635
epoch: 4952, train precision: 0.984778, train loss: 18.609762, valid precision: 0.834200, valid loss: 228.352986
epoch: 4953, train precision: 0.982867, train loss: 19.591534, valid precision: 0.834000, valid loss: 184.374340
epoch: 4954, train precision: 0.979600, train loss: 20.385677, valid precision: 0.835600, valid loss: 190.182146
epoch: 4955, train precision: 0.979844, train loss: 20.684492, valid precision: 0.827800, valid loss: 201.477474
epoch: 4956, train precision: 0.984400, train loss: 19.412116, valid precision: 0.835800, valid loss: 234.843493
epoch: 4957, train precision: 0.983022, train loss: 19.105465, valid precision: 0.834000, valid loss: 202.351739
epoch: 4958, train precision: 0.985578, train loss: 18.510526, valid precision: 0.839800, valid loss: 224.334229
epoch: 4959, train precision: 0.985156, train loss: 18.494111, valid precision: 0.834600, valid loss: 214.061147
epoch: 4960, train precision: 0.980356, train loss: 20.263564, valid precision: 0.832600, valid loss: 190.167324
epoch: 4961, train precision: 0.979600, train loss: 22.819238, valid precision: 0.836200, valid loss: 245.466461
epoch: 4962, train precision: 0.973111, train loss: 24.456250, valid precision: 0.837200, valid loss: 210.543180
epoch: 4963, train precision: 0.977022, train loss: 21.741056, valid precision: 0.830600, valid loss: 188.237441
epoch: 4964, train precision: 0.985822, train loss: 18.151706, valid precision: 0.838800, valid loss: 218.454126
epoch: 4965, train precision: 0.978511, train loss: 21.516559, valid precision: 0.828800, valid loss: 208.448199
epoch: 4966, train precision: 0.982711, train loss: 19.644879, valid precision: 0.833200, valid loss: 216.226958
epoch: 4967, train precision: 0.982289, train loss: 19.460641, valid precision: 0.834600, valid loss: 194.805703
epoch: 4968, train precision: 0.981200, train loss: 21.479019, valid precision: 0.826600, valid loss: 259.108037
epoch: 4969, train precision: 0.983578, train loss: 18.891756, valid precision: 0.837600, valid loss: 209.478062
epoch: 4970, train precision: 0.981667, train loss: 19.531771, valid precision: 0.831000, valid loss: 201.025761
epoch: 4971, train precision: 0.984200, train loss: 18.728571, valid precision: 0.834200, valid loss: 211.454638
epoch: 4972, train precision: 0.980822, train loss: 20.676260, valid precision: 0.830400, valid loss: 214.866681
epoch: 4973, train precision: 0.980978, train loss: 19.567422, valid precision: 0.837200, valid loss: 183.371886
epoch: 4974, train precision: 0.981889, train loss: 20.505333, valid precision: 0.832400, valid loss: 220.198090
epoch: 4975, train precision: 0.978422, train loss: 21.399725, valid precision: 0.830800, valid loss: 189.739797
epoch: 4976, train precision: 0.981422, train loss: 19.914315, valid precision: 0.838000, valid loss: 213.013429
epoch: 4977, train precision: 0.982556, train loss: 19.717656, valid precision: 0.837000, valid loss: 211.663994
epoch: 4978, train precision: 0.979400, train loss: 22.303343, valid precision: 0.823200, valid loss: 223.631039
epoch: 4979, train precision: 0.973533, train loss: 23.623733, valid precision: 0.827200, valid loss: 200.564526
epoch: 4980, train precision: 0.984044, train loss: 19.774090, valid precision: 0.838600, valid loss: 234.499373
epoch: 4981, train precision: 0.981400, train loss: 19.706671, valid precision: 0.837400, valid loss: 183.031509
epoch: 4982, train precision: 0.977022, train loss: 21.586390, valid precision: 0.837400, valid loss: 199.797045
epoch: 4983, train precision: 0.982867, train loss: 19.261548, valid precision: 0.840000, valid loss: 211.285636
epoch: 4984, train precision: 0.983556, train loss: 19.332365, valid precision: 0.833000, valid loss: 221.680216
epoch: 4985, train precision: 0.983356, train loss: 18.726296, valid precision: 0.838600, valid loss: 199.851330
epoch: 4986, train precision: 0.977933, train loss: 22.364987, valid precision: 0.837000, valid loss: 199.596275
epoch: 4987, train precision: 0.978689, train loss: 21.772878, valid precision: 0.833400, valid loss: 204.660969
epoch: 4988, train precision: 0.976889, train loss: 21.197756, valid precision: 0.827400, valid loss: 165.317474
epoch: 4989, train precision: 0.982467, train loss: 19.685127, valid precision: 0.837600, valid loss: 225.474397
epoch: 4990, train precision: 0.981400, train loss: 20.060735, valid precision: 0.837200, valid loss: 181.242621
epoch: 4991, train precision: 0.984911, train loss: 19.151413, valid precision: 0.839000, valid loss: 246.639771
epoch: 4992, train precision: 0.983200, train loss: 18.987594, valid precision: 0.836200, valid loss: 216.272441
epoch: 4993, train precision: 0.981533, train loss: 20.326782, valid precision: 0.831200, valid loss: 223.216149
epoch: 4994, train precision: 0.971600, train loss: 24.298993, valid precision: 0.829000, valid loss: 169.376881
epoch: 4995, train precision: 0.977778, train loss: 20.864480, valid precision: 0.831800, valid loss: 177.806970
epoch: 4996, train precision: 0.982533, train loss: 19.702446, valid precision: 0.833400, valid loss: 205.304624
epoch: 4997, train precision: 0.971067, train loss: 24.215435, valid precision: 0.824000, valid loss: 162.077999
epoch: 4998, train precision: 0.980178, train loss: 21.214631, valid precision: 0.835600, valid loss: 204.669904
epoch: 4999, train precision: 0.982844, train loss: 19.852105, valid precision: 0.834800, valid loss: 213.762209
epoch: 5000, train precision: 0.986044, train loss: 17.718967, valid precision: 0.833000, valid loss: 215.619567
