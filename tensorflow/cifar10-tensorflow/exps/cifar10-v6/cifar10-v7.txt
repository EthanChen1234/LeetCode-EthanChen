nohup: ignoring input
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:83:00.0
Total memory: 11.90GiB
Free memory: 7.77GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:83:00.0)
epoch: 0, train precision: 0.565622, train loss: 159.091352, valid precision: 0.588800, valid loss: 151.171704
epoch: 1, train precision: 0.642444, train loss: 131.033301, valid precision: 0.661800, valid loss: 124.615899
epoch: 2, train precision: 0.703578, train loss: 108.332395, valid precision: 0.702200, valid loss: 108.567440
epoch: 3, train precision: 0.733622, train loss: 99.856692, valid precision: 0.731200, valid loss: 100.421175
epoch: 4, train precision: 0.762644, train loss: 88.732050, valid precision: 0.749400, valid loss: 92.747242
epoch: 5, train precision: 0.772067, train loss: 84.387096, valid precision: 0.756200, valid loss: 90.057527
epoch: 6, train precision: 0.789400, train loss: 79.269420, valid precision: 0.763200, valid loss: 87.313002
epoch: 7, train precision: 0.807489, train loss: 72.689074, valid precision: 0.774800, valid loss: 82.710838
epoch: 8, train precision: 0.812756, train loss: 70.435011, valid precision: 0.783200, valid loss: 80.121042
epoch: 9, train precision: 0.828356, train loss: 65.458904, valid precision: 0.791400, valid loss: 77.234226
epoch: 10, train precision: 0.822111, train loss: 66.086090, valid precision: 0.788000, valid loss: 79.155072
epoch: 11, train precision: 0.826333, train loss: 64.221896, valid precision: 0.785800, valid loss: 79.804162
epoch: 12, train precision: 0.838711, train loss: 61.640595, valid precision: 0.795400, valid loss: 75.154761
epoch: 13, train precision: 0.840533, train loss: 59.274654, valid precision: 0.795000, valid loss: 76.961464
epoch: 14, train precision: 0.850333, train loss: 56.768998, valid precision: 0.795800, valid loss: 76.517944
epoch: 15, train precision: 0.852844, train loss: 56.957602, valid precision: 0.797000, valid loss: 74.321096
epoch: 16, train precision: 0.856533, train loss: 54.381097, valid precision: 0.800800, valid loss: 73.566022
epoch: 17, train precision: 0.864089, train loss: 52.664621, valid precision: 0.808000, valid loss: 71.767228
epoch: 18, train precision: 0.867778, train loss: 50.866974, valid precision: 0.809800, valid loss: 71.609135
epoch: 19, train precision: 0.869222, train loss: 49.256836, valid precision: 0.804400, valid loss: 72.210356
epoch: 20, train precision: 0.875756, train loss: 48.029340, valid precision: 0.813600, valid loss: 69.986862
epoch: 21, train precision: 0.872600, train loss: 48.992516, valid precision: 0.810400, valid loss: 71.660749
epoch: 22, train precision: 0.877956, train loss: 47.287229, valid precision: 0.807200, valid loss: 72.155920
epoch: 23, train precision: 0.880111, train loss: 46.627088, valid precision: 0.818200, valid loss: 69.711884
epoch: 24, train precision: 0.881022, train loss: 45.745741, valid precision: 0.815400, valid loss: 69.005139
epoch: 25, train precision: 0.895200, train loss: 41.889918, valid precision: 0.824600, valid loss: 66.265742
epoch: 26, train precision: 0.882867, train loss: 45.476460, valid precision: 0.808000, valid loss: 72.563670
epoch: 27, train precision: 0.889933, train loss: 42.607716, valid precision: 0.821800, valid loss: 68.601196
epoch: 28, train precision: 0.894933, train loss: 41.234240, valid precision: 0.825000, valid loss: 67.637859
epoch: 29, train precision: 0.893467, train loss: 41.439502, valid precision: 0.818600, valid loss: 69.518533
epoch: 30, train precision: 0.898733, train loss: 40.473063, valid precision: 0.824200, valid loss: 65.720985
epoch: 31, train precision: 0.892156, train loss: 42.065260, valid precision: 0.812200, valid loss: 70.761336
epoch: 32, train precision: 0.900222, train loss: 39.199647, valid precision: 0.819200, valid loss: 69.487825
epoch: 33, train precision: 0.897489, train loss: 39.963428, valid precision: 0.819600, valid loss: 68.710833
epoch: 34, train precision: 0.899667, train loss: 38.604466, valid precision: 0.816400, valid loss: 70.030121
epoch: 35, train precision: 0.905267, train loss: 37.612309, valid precision: 0.820400, valid loss: 68.366136
epoch: 36, train precision: 0.905333, train loss: 36.183347, valid precision: 0.824400, valid loss: 66.804089
epoch: 37, train precision: 0.902289, train loss: 38.701297, valid precision: 0.818600, valid loss: 69.464156
epoch: 38, train precision: 0.901000, train loss: 38.528582, valid precision: 0.825000, valid loss: 69.582574
epoch: 39, train precision: 0.899778, train loss: 38.186771, valid precision: 0.819600, valid loss: 69.986712
epoch: 40, train precision: 0.904689, train loss: 37.046480, valid precision: 0.820000, valid loss: 70.120372
epoch: 41, train precision: 0.913022, train loss: 35.267583, valid precision: 0.826200, valid loss: 70.113185
epoch: 42, train precision: 0.912111, train loss: 35.212518, valid precision: 0.822200, valid loss: 70.532865
epoch: 43, train precision: 0.912978, train loss: 34.751990, valid precision: 0.823800, valid loss: 67.539109
epoch: 44, train precision: 0.917311, train loss: 34.074332, valid precision: 0.823400, valid loss: 68.620617
epoch: 45, train precision: 0.909844, train loss: 35.829601, valid precision: 0.818800, valid loss: 69.124709
epoch: 46, train precision: 0.917133, train loss: 33.304951, valid precision: 0.825800, valid loss: 68.719128
epoch: 47, train precision: 0.917244, train loss: 33.777948, valid precision: 0.829600, valid loss: 67.974987
epoch: 48, train precision: 0.913511, train loss: 33.980672, valid precision: 0.826200, valid loss: 70.323629
epoch: 49, train precision: 0.915422, train loss: 33.547054, valid precision: 0.826000, valid loss: 68.405376
epoch: 50, train precision: 0.920933, train loss: 31.845464, valid precision: 0.834000, valid loss: 66.991321
epoch: 51, train precision: 0.911667, train loss: 34.682103, valid precision: 0.826200, valid loss: 70.518835
epoch: 52, train precision: 0.908244, train loss: 35.657960, valid precision: 0.824800, valid loss: 72.110547
epoch: 53, train precision: 0.926489, train loss: 31.224824, valid precision: 0.832200, valid loss: 66.146714
epoch: 54, train precision: 0.912622, train loss: 35.168384, valid precision: 0.821400, valid loss: 72.816364
epoch: 55, train precision: 0.926356, train loss: 30.519577, valid precision: 0.835800, valid loss: 66.690243
epoch: 56, train precision: 0.913356, train loss: 34.218079, valid precision: 0.822200, valid loss: 74.332366
epoch: 57, train precision: 0.920933, train loss: 31.365423, valid precision: 0.836200, valid loss: 67.507963
epoch: 58, train precision: 0.916978, train loss: 32.574439, valid precision: 0.828400, valid loss: 71.364567
epoch: 59, train precision: 0.927333, train loss: 30.495981, valid precision: 0.835200, valid loss: 66.735609
epoch: 60, train precision: 0.922911, train loss: 30.608598, valid precision: 0.831000, valid loss: 70.655960
epoch: 61, train precision: 0.928778, train loss: 28.941664, valid precision: 0.835800, valid loss: 70.626916
epoch: 62, train precision: 0.931467, train loss: 28.567004, valid precision: 0.836400, valid loss: 70.102838
epoch: 63, train precision: 0.921511, train loss: 30.472751, valid precision: 0.831400, valid loss: 72.647255
epoch: 64, train precision: 0.926222, train loss: 29.958872, valid precision: 0.830000, valid loss: 70.725598
epoch: 65, train precision: 0.924756, train loss: 29.877854, valid precision: 0.831000, valid loss: 72.074163
epoch: 66, train precision: 0.923867, train loss: 30.462281, valid precision: 0.828400, valid loss: 70.186148
epoch: 67, train precision: 0.932422, train loss: 27.703964, valid precision: 0.834400, valid loss: 70.793286
epoch: 68, train precision: 0.933267, train loss: 27.122107, valid precision: 0.833200, valid loss: 68.745938
epoch: 69, train precision: 0.924822, train loss: 30.453811, valid precision: 0.832400, valid loss: 71.322248
epoch: 70, train precision: 0.923867, train loss: 30.309299, valid precision: 0.830400, valid loss: 70.949892
epoch: 71, train precision: 0.923933, train loss: 30.572080, valid precision: 0.827200, valid loss: 71.915816
epoch: 72, train precision: 0.933711, train loss: 27.836058, valid precision: 0.837600, valid loss: 69.329771
epoch: 73, train precision: 0.931267, train loss: 27.931501, valid precision: 0.832200, valid loss: 71.492843
epoch: 74, train precision: 0.934756, train loss: 27.453618, valid precision: 0.836800, valid loss: 69.616382
epoch: 75, train precision: 0.919067, train loss: 32.163725, valid precision: 0.821600, valid loss: 77.762003
epoch: 76, train precision: 0.931222, train loss: 28.530767, valid precision: 0.832200, valid loss: 69.466943
epoch: 77, train precision: 0.930200, train loss: 29.003378, valid precision: 0.836200, valid loss: 71.183041
epoch: 78, train precision: 0.931333, train loss: 27.403095, valid precision: 0.837000, valid loss: 71.942466
epoch: 79, train precision: 0.931467, train loss: 28.080488, valid precision: 0.827600, valid loss: 73.178690
epoch: 80, train precision: 0.928044, train loss: 29.512307, valid precision: 0.833200, valid loss: 71.818059
epoch: 81, train precision: 0.940200, train loss: 25.173427, valid precision: 0.837600, valid loss: 68.768007
epoch: 82, train precision: 0.932711, train loss: 27.975701, valid precision: 0.836600, valid loss: 71.152939
epoch: 83, train precision: 0.931267, train loss: 28.184016, valid precision: 0.837400, valid loss: 70.212530
epoch: 84, train precision: 0.934111, train loss: 27.642270, valid precision: 0.834600, valid loss: 70.684986
epoch: 85, train precision: 0.941422, train loss: 25.580225, valid precision: 0.846800, valid loss: 66.665459
epoch: 86, train precision: 0.933422, train loss: 27.608630, valid precision: 0.828400, valid loss: 72.230097
epoch: 87, train precision: 0.937533, train loss: 26.052071, valid precision: 0.841200, valid loss: 67.708441
epoch: 88, train precision: 0.930400, train loss: 28.913058, valid precision: 0.837000, valid loss: 70.816858
epoch: 89, train precision: 0.927711, train loss: 29.612191, valid precision: 0.828200, valid loss: 72.982884
epoch: 90, train precision: 0.940911, train loss: 25.509412, valid precision: 0.843800, valid loss: 68.991295
epoch: 91, train precision: 0.940911, train loss: 25.736299, valid precision: 0.838400, valid loss: 68.264937
epoch: 92, train precision: 0.931044, train loss: 27.425276, valid precision: 0.836800, valid loss: 73.195884
epoch: 93, train precision: 0.939933, train loss: 25.097472, valid precision: 0.838400, valid loss: 70.016427
epoch: 94, train precision: 0.938311, train loss: 25.938852, valid precision: 0.839000, valid loss: 71.299844
epoch: 95, train precision: 0.936267, train loss: 26.412564, valid precision: 0.836600, valid loss: 72.788568
epoch: 96, train precision: 0.942933, train loss: 25.128113, valid precision: 0.841600, valid loss: 71.689640
epoch: 97, train precision: 0.941889, train loss: 24.775840, valid precision: 0.838600, valid loss: 72.909579
epoch: 98, train precision: 0.933689, train loss: 27.141428, valid precision: 0.835000, valid loss: 73.868649
epoch: 99, train precision: 0.939711, train loss: 25.882074, valid precision: 0.837400, valid loss: 68.432889
epoch: 100, train precision: 0.939556, train loss: 24.921131, valid precision: 0.833800, valid loss: 72.113537
epoch: 101, train precision: 0.936822, train loss: 26.954568, valid precision: 0.837600, valid loss: 70.511903
epoch: 102, train precision: 0.938822, train loss: 25.694850, valid precision: 0.840000, valid loss: 73.503724
epoch: 103, train precision: 0.941200, train loss: 24.913952, valid precision: 0.839400, valid loss: 70.944836
epoch: 104, train precision: 0.933822, train loss: 27.206254, valid precision: 0.834800, valid loss: 72.639345
epoch: 105, train precision: 0.941844, train loss: 24.984052, valid precision: 0.842400, valid loss: 70.682403
epoch: 106, train precision: 0.943667, train loss: 24.571570, valid precision: 0.838400, valid loss: 72.109504
epoch: 107, train precision: 0.943689, train loss: 24.226017, valid precision: 0.836800, valid loss: 72.554762
epoch: 108, train precision: 0.942911, train loss: 24.832219, valid precision: 0.843600, valid loss: 69.405063
epoch: 109, train precision: 0.936711, train loss: 26.300659, valid precision: 0.832600, valid loss: 76.658985
epoch: 110, train precision: 0.946156, train loss: 23.398334, valid precision: 0.840800, valid loss: 70.872017
epoch: 111, train precision: 0.947267, train loss: 23.375634, valid precision: 0.843000, valid loss: 70.680614
epoch: 112, train precision: 0.946333, train loss: 23.692535, valid precision: 0.835200, valid loss: 74.014801
epoch: 113, train precision: 0.935978, train loss: 26.418306, valid precision: 0.838600, valid loss: 73.532576
epoch: 114, train precision: 0.936911, train loss: 26.592988, valid precision: 0.831200, valid loss: 77.073687
epoch: 115, train precision: 0.943600, train loss: 24.687772, valid precision: 0.841400, valid loss: 70.569557
epoch: 116, train precision: 0.947533, train loss: 23.322857, valid precision: 0.842800, valid loss: 70.499865
epoch: 117, train precision: 0.935556, train loss: 26.135483, valid precision: 0.841600, valid loss: 76.151137
epoch: 118, train precision: 0.946711, train loss: 23.888723, valid precision: 0.840600, valid loss: 71.933533
epoch: 119, train precision: 0.940444, train loss: 25.397681, valid precision: 0.837600, valid loss: 75.222434
epoch: 120, train precision: 0.944044, train loss: 23.825718, valid precision: 0.844400, valid loss: 71.806812
epoch: 121, train precision: 0.937644, train loss: 26.016898, valid precision: 0.835800, valid loss: 77.173524
epoch: 122, train precision: 0.942911, train loss: 24.597945, valid precision: 0.843200, valid loss: 72.510038
epoch: 123, train precision: 0.949089, train loss: 22.916610, valid precision: 0.840600, valid loss: 71.725155
epoch: 124, train precision: 0.947044, train loss: 23.044281, valid precision: 0.838000, valid loss: 71.816871
epoch: 125, train precision: 0.937711, train loss: 26.249561, valid precision: 0.833600, valid loss: 78.827053
epoch: 126, train precision: 0.944422, train loss: 24.130860, valid precision: 0.836000, valid loss: 73.943013
epoch: 127, train precision: 0.949556, train loss: 22.616920, valid precision: 0.842800, valid loss: 70.027274
epoch: 128, train precision: 0.940578, train loss: 24.583852, valid precision: 0.843800, valid loss: 72.221543
epoch: 129, train precision: 0.946156, train loss: 23.678255, valid precision: 0.840200, valid loss: 72.729984
epoch: 130, train precision: 0.947200, train loss: 23.077966, valid precision: 0.839400, valid loss: 72.798530
epoch: 131, train precision: 0.941956, train loss: 24.934737, valid precision: 0.843400, valid loss: 73.175910
epoch: 132, train precision: 0.949622, train loss: 22.368128, valid precision: 0.841000, valid loss: 70.075674
epoch: 133, train precision: 0.939289, train loss: 26.038944, valid precision: 0.835800, valid loss: 74.424665
epoch: 134, train precision: 0.947311, train loss: 22.613312, valid precision: 0.847800, valid loss: 70.698084
epoch: 135, train precision: 0.942733, train loss: 24.845323, valid precision: 0.840200, valid loss: 71.502303
epoch: 136, train precision: 0.944644, train loss: 24.269676, valid precision: 0.836800, valid loss: 76.340430
epoch: 137, train precision: 0.945556, train loss: 23.936741, valid precision: 0.837000, valid loss: 74.206948
epoch: 138, train precision: 0.950400, train loss: 22.289557, valid precision: 0.847800, valid loss: 70.674679
epoch: 139, train precision: 0.947178, train loss: 23.086382, valid precision: 0.844800, valid loss: 72.451320
epoch: 140, train precision: 0.947689, train loss: 22.728984, valid precision: 0.838600, valid loss: 73.099586
epoch: 141, train precision: 0.951044, train loss: 21.946568, valid precision: 0.841600, valid loss: 72.007093
epoch: 142, train precision: 0.948867, train loss: 23.000440, valid precision: 0.847200, valid loss: 71.114703
epoch: 143, train precision: 0.946800, train loss: 23.710054, valid precision: 0.837800, valid loss: 70.791213
epoch: 144, train precision: 0.953289, train loss: 21.710922, valid precision: 0.840400, valid loss: 70.019983
epoch: 145, train precision: 0.950444, train loss: 22.837317, valid precision: 0.840800, valid loss: 72.041427
epoch: 146, train precision: 0.943733, train loss: 24.026176, valid precision: 0.837800, valid loss: 73.400772
epoch: 147, train precision: 0.954244, train loss: 21.281742, valid precision: 0.840600, valid loss: 69.252046
epoch: 148, train precision: 0.949311, train loss: 22.849551, valid precision: 0.845200, valid loss: 73.416957
epoch: 149, train precision: 0.945289, train loss: 24.018719, valid precision: 0.843400, valid loss: 71.802468
epoch: 150, train precision: 0.954022, train loss: 21.095288, valid precision: 0.840600, valid loss: 72.213020
epoch: 151, train precision: 0.953289, train loss: 21.518752, valid precision: 0.850000, valid loss: 68.137300
epoch: 152, train precision: 0.950156, train loss: 23.018558, valid precision: 0.847400, valid loss: 68.356065
epoch: 153, train precision: 0.952022, train loss: 21.949571, valid precision: 0.841400, valid loss: 73.350031
epoch: 154, train precision: 0.948489, train loss: 22.835505, valid precision: 0.837200, valid loss: 73.248241
epoch: 155, train precision: 0.946800, train loss: 23.643428, valid precision: 0.841600, valid loss: 72.085032
epoch: 156, train precision: 0.953089, train loss: 21.576215, valid precision: 0.845600, valid loss: 71.759175
epoch: 157, train precision: 0.951244, train loss: 21.727730, valid precision: 0.843600, valid loss: 71.730908
epoch: 158, train precision: 0.948689, train loss: 23.222022, valid precision: 0.841600, valid loss: 74.791798
epoch: 159, train precision: 0.951600, train loss: 21.564292, valid precision: 0.841800, valid loss: 72.046355
epoch: 160, train precision: 0.948378, train loss: 23.108359, valid precision: 0.837800, valid loss: 74.533217
epoch: 161, train precision: 0.950911, train loss: 21.598083, valid precision: 0.842800, valid loss: 73.932339
epoch: 162, train precision: 0.957067, train loss: 20.365353, valid precision: 0.853000, valid loss: 70.762096
epoch: 163, train precision: 0.947311, train loss: 23.288444, valid precision: 0.845200, valid loss: 70.058559
epoch: 164, train precision: 0.948533, train loss: 22.671407, valid precision: 0.841600, valid loss: 71.301819
epoch: 165, train precision: 0.946356, train loss: 23.622913, valid precision: 0.842000, valid loss: 75.612686
epoch: 166, train precision: 0.955978, train loss: 21.192564, valid precision: 0.847600, valid loss: 69.447891
epoch: 167, train precision: 0.944956, train loss: 23.963132, valid precision: 0.843400, valid loss: 73.705357
epoch: 168, train precision: 0.949222, train loss: 22.984207, valid precision: 0.850000, valid loss: 71.138996
epoch: 169, train precision: 0.954511, train loss: 20.856483, valid precision: 0.849200, valid loss: 73.475117
epoch: 170, train precision: 0.951222, train loss: 22.425605, valid precision: 0.845000, valid loss: 73.504576
epoch: 171, train precision: 0.944178, train loss: 24.209537, valid precision: 0.842000, valid loss: 75.609317
epoch: 172, train precision: 0.950044, train loss: 22.642796, valid precision: 0.847200, valid loss: 75.636467
epoch: 173, train precision: 0.951244, train loss: 22.545784, valid precision: 0.841600, valid loss: 73.949758
epoch: 174, train precision: 0.951978, train loss: 21.947563, valid precision: 0.841800, valid loss: 76.011660
epoch: 175, train precision: 0.957400, train loss: 19.959985, valid precision: 0.849000, valid loss: 71.592225
epoch: 176, train precision: 0.953133, train loss: 21.322412, valid precision: 0.842600, valid loss: 75.115699
epoch: 177, train precision: 0.958489, train loss: 20.011073, valid precision: 0.844400, valid loss: 72.189069
epoch: 178, train precision: 0.951533, train loss: 22.250585, valid precision: 0.849800, valid loss: 72.338242
epoch: 179, train precision: 0.954667, train loss: 21.311197, valid precision: 0.843200, valid loss: 76.914032
epoch: 180, train precision: 0.953311, train loss: 21.642119, valid precision: 0.839200, valid loss: 77.065037
epoch: 181, train precision: 0.950644, train loss: 22.734994, valid precision: 0.847000, valid loss: 75.184794
epoch: 182, train precision: 0.955667, train loss: 21.001642, valid precision: 0.848800, valid loss: 73.061635
epoch: 183, train precision: 0.951000, train loss: 22.423891, valid precision: 0.847200, valid loss: 72.764879
epoch: 184, train precision: 0.951000, train loss: 22.485307, valid precision: 0.844800, valid loss: 72.676453
epoch: 185, train precision: 0.954667, train loss: 21.618133, valid precision: 0.845800, valid loss: 68.672299
epoch: 186, train precision: 0.955511, train loss: 20.844872, valid precision: 0.844800, valid loss: 73.733974
epoch: 187, train precision: 0.959022, train loss: 19.664751, valid precision: 0.850800, valid loss: 71.863317
epoch: 188, train precision: 0.949933, train loss: 23.110973, valid precision: 0.836800, valid loss: 74.149508
epoch: 189, train precision: 0.957422, train loss: 19.888821, valid precision: 0.849400, valid loss: 71.972604
epoch: 190, train precision: 0.951289, train loss: 22.368097, valid precision: 0.846800, valid loss: 73.706664
epoch: 191, train precision: 0.951689, train loss: 22.593849, valid precision: 0.849200, valid loss: 70.576181
epoch: 192, train precision: 0.953356, train loss: 21.558417, valid precision: 0.852000, valid loss: 71.835265
epoch: 193, train precision: 0.950600, train loss: 23.402457, valid precision: 0.841200, valid loss: 73.247753
epoch: 194, train precision: 0.956978, train loss: 20.672401, valid precision: 0.846800, valid loss: 73.999048
epoch: 195, train precision: 0.954978, train loss: 21.483971, valid precision: 0.843600, valid loss: 73.209168
epoch: 196, train precision: 0.952378, train loss: 22.491423, valid precision: 0.841600, valid loss: 75.458921
epoch: 197, train precision: 0.957733, train loss: 19.974525, valid precision: 0.856400, valid loss: 71.858966
epoch: 198, train precision: 0.952044, train loss: 22.522759, valid precision: 0.849400, valid loss: 71.221459
epoch: 199, train precision: 0.961022, train loss: 19.366157, valid precision: 0.851200, valid loss: 75.515664
epoch: 200, train precision: 0.953822, train loss: 22.115417, valid precision: 0.839000, valid loss: 78.134311
epoch: 201, train precision: 0.952556, train loss: 21.539351, valid precision: 0.840200, valid loss: 77.265607
epoch: 202, train precision: 0.954356, train loss: 21.515439, valid precision: 0.843800, valid loss: 78.464953
epoch: 203, train precision: 0.954578, train loss: 21.760616, valid precision: 0.842600, valid loss: 75.602479
epoch: 204, train precision: 0.958289, train loss: 20.645014, valid precision: 0.847000, valid loss: 74.775789
epoch: 205, train precision: 0.952756, train loss: 21.978709, valid precision: 0.844000, valid loss: 75.194088
epoch: 206, train precision: 0.949489, train loss: 23.234546, valid precision: 0.844400, valid loss: 76.510180
epoch: 207, train precision: 0.954422, train loss: 21.177053, valid precision: 0.849600, valid loss: 73.329782
epoch: 208, train precision: 0.955311, train loss: 21.166693, valid precision: 0.844200, valid loss: 78.456957
epoch: 209, train precision: 0.950222, train loss: 22.578374, valid precision: 0.841800, valid loss: 77.997741
epoch: 210, train precision: 0.955222, train loss: 21.359582, valid precision: 0.841400, valid loss: 76.999447
epoch: 211, train precision: 0.948800, train loss: 23.396177, valid precision: 0.838000, valid loss: 78.814202
epoch: 212, train precision: 0.951867, train loss: 22.370294, valid precision: 0.840200, valid loss: 77.279279
epoch: 213, train precision: 0.956622, train loss: 20.880347, valid precision: 0.844400, valid loss: 76.080936
epoch: 214, train precision: 0.951800, train loss: 22.393758, valid precision: 0.840200, valid loss: 78.876421
epoch: 215, train precision: 0.954778, train loss: 21.186724, valid precision: 0.843400, valid loss: 76.091368
epoch: 216, train precision: 0.951444, train loss: 22.192330, valid precision: 0.842800, valid loss: 78.745227
epoch: 217, train precision: 0.955622, train loss: 21.248828, valid precision: 0.846600, valid loss: 73.936942
epoch: 218, train precision: 0.959978, train loss: 20.155904, valid precision: 0.850000, valid loss: 75.542131
epoch: 219, train precision: 0.956400, train loss: 20.789241, valid precision: 0.844400, valid loss: 76.673707
epoch: 220, train precision: 0.954533, train loss: 21.821205, valid precision: 0.840000, valid loss: 76.080251
epoch: 221, train precision: 0.952800, train loss: 22.611656, valid precision: 0.839400, valid loss: 75.359113
epoch: 222, train precision: 0.957289, train loss: 20.308271, valid precision: 0.844400, valid loss: 77.427546
epoch: 223, train precision: 0.959956, train loss: 19.591250, valid precision: 0.842400, valid loss: 78.035694
epoch: 224, train precision: 0.956156, train loss: 20.979346, valid precision: 0.844200, valid loss: 78.769487
epoch: 225, train precision: 0.960867, train loss: 19.617991, valid precision: 0.845600, valid loss: 77.073660
epoch: 226, train precision: 0.955533, train loss: 21.092079, valid precision: 0.842000, valid loss: 77.198834
epoch: 227, train precision: 0.952578, train loss: 22.329846, valid precision: 0.837800, valid loss: 82.777163
epoch: 228, train precision: 0.960400, train loss: 19.500300, valid precision: 0.845200, valid loss: 76.535068
epoch: 229, train precision: 0.960467, train loss: 19.650071, valid precision: 0.850000, valid loss: 75.808746
epoch: 230, train precision: 0.956222, train loss: 21.358064, valid precision: 0.841800, valid loss: 78.466079
epoch: 231, train precision: 0.948556, train loss: 23.489020, valid precision: 0.838600, valid loss: 81.687282
epoch: 232, train precision: 0.956889, train loss: 20.686464, valid precision: 0.844200, valid loss: 79.666435
epoch: 233, train precision: 0.958756, train loss: 20.392876, valid precision: 0.844000, valid loss: 75.556846
epoch: 234, train precision: 0.953444, train loss: 22.015101, valid precision: 0.847400, valid loss: 77.560498
epoch: 235, train precision: 0.956156, train loss: 21.069400, valid precision: 0.845400, valid loss: 77.066072
epoch: 236, train precision: 0.958022, train loss: 20.609239, valid precision: 0.847600, valid loss: 77.479783
epoch: 237, train precision: 0.955022, train loss: 21.449566, valid precision: 0.840400, valid loss: 76.973946
epoch: 238, train precision: 0.962089, train loss: 19.412289, valid precision: 0.839800, valid loss: 79.229805
epoch: 239, train precision: 0.954000, train loss: 21.923481, valid precision: 0.836600, valid loss: 86.750165
epoch: 240, train precision: 0.955711, train loss: 20.466705, valid precision: 0.842600, valid loss: 81.773025
epoch: 241, train precision: 0.957356, train loss: 20.659011, valid precision: 0.845400, valid loss: 79.175529
epoch: 242, train precision: 0.957867, train loss: 20.353301, valid precision: 0.843000, valid loss: 79.179504
epoch: 243, train precision: 0.959311, train loss: 19.931219, valid precision: 0.850000, valid loss: 77.721263
epoch: 244, train precision: 0.958511, train loss: 20.629020, valid precision: 0.844400, valid loss: 76.394535
epoch: 245, train precision: 0.962400, train loss: 19.435682, valid precision: 0.839200, valid loss: 77.827408
epoch: 246, train precision: 0.954933, train loss: 21.687766, valid precision: 0.844000, valid loss: 79.154342
epoch: 247, train precision: 0.954800, train loss: 21.473141, valid precision: 0.845000, valid loss: 79.215561
epoch: 248, train precision: 0.958022, train loss: 20.418210, valid precision: 0.843000, valid loss: 81.058201
epoch: 249, train precision: 0.960511, train loss: 19.760763, valid precision: 0.849400, valid loss: 75.665569
epoch: 250, train precision: 0.960467, train loss: 19.505145, valid precision: 0.850400, valid loss: 78.694846
epoch: 251, train precision: 0.952378, train loss: 22.113501, valid precision: 0.841200, valid loss: 79.333084
epoch: 252, train precision: 0.960422, train loss: 19.610680, valid precision: 0.856400, valid loss: 70.516578
epoch: 253, train precision: 0.950578, train loss: 23.050641, valid precision: 0.841200, valid loss: 78.634259
epoch: 254, train precision: 0.962200, train loss: 19.197012, valid precision: 0.851400, valid loss: 74.118118
epoch: 255, train precision: 0.962000, train loss: 19.181761, valid precision: 0.848000, valid loss: 77.266141
epoch: 256, train precision: 0.959511, train loss: 19.958035, valid precision: 0.846400, valid loss: 77.587943
epoch: 257, train precision: 0.961533, train loss: 19.812184, valid precision: 0.843000, valid loss: 78.375223
epoch: 258, train precision: 0.960200, train loss: 19.936335, valid precision: 0.848400, valid loss: 74.067542
epoch: 259, train precision: 0.961356, train loss: 19.164864, valid precision: 0.847400, valid loss: 78.601625
epoch: 260, train precision: 0.964378, train loss: 18.992840, valid precision: 0.853800, valid loss: 75.383150
epoch: 261, train precision: 0.963556, train loss: 19.138585, valid precision: 0.846600, valid loss: 75.774259
epoch: 262, train precision: 0.962200, train loss: 18.974296, valid precision: 0.844800, valid loss: 78.310286
epoch: 263, train precision: 0.954978, train loss: 21.941527, valid precision: 0.840000, valid loss: 77.873739
epoch: 264, train precision: 0.960222, train loss: 19.650131, valid precision: 0.845200, valid loss: 77.167176
epoch: 265, train precision: 0.958911, train loss: 20.065242, valid precision: 0.846600, valid loss: 77.646465
epoch: 266, train precision: 0.957000, train loss: 21.321662, valid precision: 0.846800, valid loss: 79.125700
epoch: 267, train precision: 0.957089, train loss: 21.117720, valid precision: 0.845400, valid loss: 78.514533
epoch: 268, train precision: 0.954067, train loss: 22.067042, valid precision: 0.841600, valid loss: 88.185096
epoch: 269, train precision: 0.962622, train loss: 19.114890, valid precision: 0.844800, valid loss: 77.285308
epoch: 270, train precision: 0.957956, train loss: 20.682407, valid precision: 0.847400, valid loss: 80.046738
epoch: 271, train precision: 0.959756, train loss: 19.842490, valid precision: 0.845600, valid loss: 79.707260
epoch: 272, train precision: 0.959956, train loss: 19.951537, valid precision: 0.846000, valid loss: 80.386388
epoch: 273, train precision: 0.961733, train loss: 20.038653, valid precision: 0.846600, valid loss: 80.180823
epoch: 274, train precision: 0.956778, train loss: 21.094139, valid precision: 0.845200, valid loss: 79.196518
epoch: 275, train precision: 0.956244, train loss: 21.831370, valid precision: 0.837400, valid loss: 82.915503
epoch: 276, train precision: 0.958111, train loss: 20.985224, valid precision: 0.847800, valid loss: 74.216722
epoch: 277, train precision: 0.955889, train loss: 21.567159, valid precision: 0.845800, valid loss: 80.753245
epoch: 278, train precision: 0.951422, train loss: 23.300849, valid precision: 0.845600, valid loss: 79.626737
epoch: 279, train precision: 0.960667, train loss: 20.249276, valid precision: 0.844800, valid loss: 78.048723
epoch: 280, train precision: 0.963089, train loss: 19.534372, valid precision: 0.846000, valid loss: 80.535374
epoch: 281, train precision: 0.958956, train loss: 20.981489, valid precision: 0.842400, valid loss: 80.661227
epoch: 282, train precision: 0.958200, train loss: 20.995578, valid precision: 0.844400, valid loss: 79.961830
epoch: 283, train precision: 0.956956, train loss: 21.113766, valid precision: 0.843600, valid loss: 83.122680
epoch: 284, train precision: 0.958156, train loss: 20.993788, valid precision: 0.841600, valid loss: 84.021644
epoch: 285, train precision: 0.961267, train loss: 20.261556, valid precision: 0.839600, valid loss: 79.063790
epoch: 286, train precision: 0.960822, train loss: 20.324346, valid precision: 0.843200, valid loss: 78.631909
epoch: 287, train precision: 0.955889, train loss: 21.619921, valid precision: 0.836800, valid loss: 85.244882
epoch: 288, train precision: 0.961600, train loss: 19.529090, valid precision: 0.850200, valid loss: 79.238953
epoch: 289, train precision: 0.964311, train loss: 18.761755, valid precision: 0.841800, valid loss: 82.283696
epoch: 290, train precision: 0.959467, train loss: 20.325775, valid precision: 0.842000, valid loss: 85.986393
epoch: 291, train precision: 0.962111, train loss: 19.337769, valid precision: 0.844200, valid loss: 83.482605
epoch: 292, train precision: 0.963200, train loss: 19.364177, valid precision: 0.841000, valid loss: 80.687281
epoch: 293, train precision: 0.955044, train loss: 22.050748, valid precision: 0.843800, valid loss: 83.254520
epoch: 294, train precision: 0.951333, train loss: 22.808779, valid precision: 0.840200, valid loss: 84.972372
epoch: 295, train precision: 0.959556, train loss: 20.955373, valid precision: 0.846200, valid loss: 79.567893
epoch: 296, train precision: 0.961711, train loss: 19.700746, valid precision: 0.843600, valid loss: 79.907552
epoch: 297, train precision: 0.960378, train loss: 20.146981, valid precision: 0.847200, valid loss: 77.891253
epoch: 298, train precision: 0.962400, train loss: 19.268852, valid precision: 0.849800, valid loss: 82.684596
epoch: 299, train precision: 0.961956, train loss: 19.777044, valid precision: 0.845800, valid loss: 84.319633
epoch: 300, train precision: 0.965044, train loss: 19.157298, valid precision: 0.848600, valid loss: 78.292767
epoch: 301, train precision: 0.959533, train loss: 20.632511, valid precision: 0.842800, valid loss: 81.731460
epoch: 302, train precision: 0.962267, train loss: 19.554739, valid precision: 0.846600, valid loss: 81.658340
epoch: 303, train precision: 0.958778, train loss: 20.888064, valid precision: 0.846200, valid loss: 81.338323
epoch: 304, train precision: 0.962511, train loss: 19.311306, valid precision: 0.847600, valid loss: 82.061318
epoch: 305, train precision: 0.959311, train loss: 20.596503, valid precision: 0.845800, valid loss: 80.978164
epoch: 306, train precision: 0.959867, train loss: 20.809388, valid precision: 0.845000, valid loss: 83.025451
epoch: 307, train precision: 0.962867, train loss: 20.351124, valid precision: 0.843200, valid loss: 80.076338
epoch: 308, train precision: 0.957778, train loss: 20.601550, valid precision: 0.841400, valid loss: 85.799764
epoch: 309, train precision: 0.960111, train loss: 21.175310, valid precision: 0.843400, valid loss: 77.989609
epoch: 310, train precision: 0.961511, train loss: 19.522028, valid precision: 0.848600, valid loss: 80.556448
epoch: 311, train precision: 0.956756, train loss: 21.807604, valid precision: 0.838600, valid loss: 84.485350
epoch: 312, train precision: 0.960978, train loss: 19.942323, valid precision: 0.848800, valid loss: 79.050728
epoch: 313, train precision: 0.963089, train loss: 19.293705, valid precision: 0.847600, valid loss: 79.477389
epoch: 314, train precision: 0.960889, train loss: 20.420232, valid precision: 0.839000, valid loss: 80.920827
epoch: 315, train precision: 0.964133, train loss: 19.327464, valid precision: 0.850200, valid loss: 81.021187
epoch: 316, train precision: 0.963556, train loss: 19.667961, valid precision: 0.850600, valid loss: 76.901462
epoch: 317, train precision: 0.960578, train loss: 20.349589, valid precision: 0.846200, valid loss: 79.051829
epoch: 318, train precision: 0.962000, train loss: 19.706647, valid precision: 0.848800, valid loss: 82.247911
epoch: 319, train precision: 0.962489, train loss: 19.927521, valid precision: 0.844600, valid loss: 84.216340
epoch: 320, train precision: 0.962711, train loss: 19.350149, valid precision: 0.849800, valid loss: 83.432854
epoch: 321, train precision: 0.963067, train loss: 19.468982, valid precision: 0.846400, valid loss: 85.138386
epoch: 322, train precision: 0.965867, train loss: 18.584631, valid precision: 0.854200, valid loss: 82.287240
epoch: 323, train precision: 0.962756, train loss: 19.268527, valid precision: 0.848000, valid loss: 82.065201
epoch: 324, train precision: 0.959222, train loss: 20.935560, valid precision: 0.847800, valid loss: 80.222866
epoch: 325, train precision: 0.963911, train loss: 19.535471, valid precision: 0.849000, valid loss: 83.362158
epoch: 326, train precision: 0.961400, train loss: 20.730305, valid precision: 0.847800, valid loss: 77.312938
epoch: 327, train precision: 0.958044, train loss: 21.275124, valid precision: 0.847600, valid loss: 83.338184
epoch: 328, train precision: 0.963978, train loss: 19.159343, valid precision: 0.848400, valid loss: 79.929121
epoch: 329, train precision: 0.962689, train loss: 20.144248, valid precision: 0.841800, valid loss: 79.800999
epoch: 330, train precision: 0.961444, train loss: 19.629453, valid precision: 0.843000, valid loss: 83.896100
epoch: 331, train precision: 0.960511, train loss: 20.866054, valid precision: 0.841600, valid loss: 80.786903
epoch: 332, train precision: 0.965689, train loss: 18.699725, valid precision: 0.853800, valid loss: 77.122208
epoch: 333, train precision: 0.960556, train loss: 20.313144, valid precision: 0.844600, valid loss: 83.810993
epoch: 334, train precision: 0.960711, train loss: 20.688517, valid precision: 0.843200, valid loss: 81.616147
epoch: 335, train precision: 0.964311, train loss: 19.109055, valid precision: 0.855000, valid loss: 76.403277
epoch: 336, train precision: 0.959733, train loss: 20.901258, valid precision: 0.842600, valid loss: 81.900486
epoch: 337, train precision: 0.962956, train loss: 20.282535, valid precision: 0.844200, valid loss: 80.958940
epoch: 338, train precision: 0.963644, train loss: 19.252492, valid precision: 0.850200, valid loss: 83.220955
epoch: 339, train precision: 0.962822, train loss: 19.389914, valid precision: 0.847000, valid loss: 83.339548
epoch: 340, train precision: 0.962778, train loss: 19.694891, valid precision: 0.847200, valid loss: 79.435618
epoch: 341, train precision: 0.965822, train loss: 18.382489, valid precision: 0.848800, valid loss: 81.341873
epoch: 342, train precision: 0.959000, train loss: 20.666833, valid precision: 0.847200, valid loss: 82.716799
epoch: 343, train precision: 0.959400, train loss: 20.758162, valid precision: 0.846200, valid loss: 81.497861
epoch: 344, train precision: 0.957933, train loss: 21.260113, valid precision: 0.842000, valid loss: 82.560413
epoch: 345, train precision: 0.964756, train loss: 19.788313, valid precision: 0.849200, valid loss: 80.068895
epoch: 346, train precision: 0.966422, train loss: 18.589896, valid precision: 0.847600, valid loss: 82.868982
epoch: 347, train precision: 0.956800, train loss: 21.642013, valid precision: 0.845000, valid loss: 87.397932
epoch: 348, train precision: 0.964733, train loss: 19.373169, valid precision: 0.848800, valid loss: 78.872406
epoch: 349, train precision: 0.966400, train loss: 18.355229, valid precision: 0.853200, valid loss: 81.785403
epoch: 350, train precision: 0.963333, train loss: 19.597460, valid precision: 0.854200, valid loss: 79.013478
epoch: 351, train precision: 0.958711, train loss: 21.129465, valid precision: 0.843600, valid loss: 81.909082
epoch: 352, train precision: 0.957733, train loss: 21.811873, valid precision: 0.842800, valid loss: 83.672741
epoch: 353, train precision: 0.962644, train loss: 19.586751, valid precision: 0.847600, valid loss: 82.983331
epoch: 354, train precision: 0.961489, train loss: 20.582334, valid precision: 0.844200, valid loss: 78.493138
epoch: 355, train precision: 0.964578, train loss: 19.285017, valid precision: 0.853800, valid loss: 78.455562
epoch: 356, train precision: 0.959489, train loss: 21.246426, valid precision: 0.849400, valid loss: 81.723356
epoch: 357, train precision: 0.965422, train loss: 18.722228, valid precision: 0.847000, valid loss: 85.359502
epoch: 358, train precision: 0.960267, train loss: 20.491496, valid precision: 0.848000, valid loss: 85.825249
epoch: 359, train precision: 0.963444, train loss: 19.898656, valid precision: 0.849000, valid loss: 83.766315
epoch: 360, train precision: 0.957467, train loss: 21.747542, valid precision: 0.842800, valid loss: 85.415077
epoch: 361, train precision: 0.963333, train loss: 19.836624, valid precision: 0.849200, valid loss: 78.200216
epoch: 362, train precision: 0.960378, train loss: 20.470490, valid precision: 0.845400, valid loss: 86.951103
epoch: 363, train precision: 0.959667, train loss: 20.846082, valid precision: 0.845600, valid loss: 85.815585
epoch: 364, train precision: 0.952311, train loss: 23.568970, valid precision: 0.841000, valid loss: 81.066051
epoch: 365, train precision: 0.965267, train loss: 19.239114, valid precision: 0.848800, valid loss: 81.365965
epoch: 366, train precision: 0.962689, train loss: 19.927120, valid precision: 0.848400, valid loss: 80.841117
epoch: 367, train precision: 0.962844, train loss: 19.683261, valid precision: 0.847200, valid loss: 84.049468
epoch: 368, train precision: 0.959200, train loss: 21.128072, valid precision: 0.836400, valid loss: 86.694366
epoch: 369, train precision: 0.965778, train loss: 18.980565, valid precision: 0.843800, valid loss: 83.301351
epoch: 370, train precision: 0.963422, train loss: 19.370845, valid precision: 0.846800, valid loss: 83.126317
epoch: 371, train precision: 0.962422, train loss: 20.054129, valid precision: 0.845600, valid loss: 82.650839
epoch: 372, train precision: 0.964067, train loss: 19.520289, valid precision: 0.845600, valid loss: 84.893234
epoch: 373, train precision: 0.971800, train loss: 16.972436, valid precision: 0.850600, valid loss: 81.642247
epoch: 374, train precision: 0.965533, train loss: 18.717161, valid precision: 0.846800, valid loss: 83.703529
epoch: 375, train precision: 0.963356, train loss: 20.145430, valid precision: 0.844600, valid loss: 82.898323
epoch: 376, train precision: 0.962667, train loss: 19.997260, valid precision: 0.840600, valid loss: 85.158804
epoch: 377, train precision: 0.967089, train loss: 18.555123, valid precision: 0.849400, valid loss: 80.958194
epoch: 378, train precision: 0.964311, train loss: 19.138773, valid precision: 0.847200, valid loss: 84.565795
epoch: 379, train precision: 0.965000, train loss: 19.149993, valid precision: 0.846600, valid loss: 81.288936
epoch: 380, train precision: 0.963000, train loss: 19.693967, valid precision: 0.848200, valid loss: 89.138794
epoch: 381, train precision: 0.965911, train loss: 19.407825, valid precision: 0.844800, valid loss: 80.828307
epoch: 382, train precision: 0.959911, train loss: 20.732569, valid precision: 0.843200, valid loss: 83.881743
epoch: 383, train precision: 0.962178, train loss: 19.960364, valid precision: 0.841400, valid loss: 86.040942
epoch: 384, train precision: 0.965756, train loss: 19.040257, valid precision: 0.848200, valid loss: 80.876118
epoch: 385, train precision: 0.964067, train loss: 19.588176, valid precision: 0.852000, valid loss: 80.872580
epoch: 386, train precision: 0.966378, train loss: 19.047728, valid precision: 0.851800, valid loss: 79.690764
epoch: 387, train precision: 0.966444, train loss: 19.107916, valid precision: 0.844200, valid loss: 83.998640
epoch: 388, train precision: 0.959956, train loss: 21.229371, valid precision: 0.843000, valid loss: 86.540264
epoch: 389, train precision: 0.959356, train loss: 21.013239, valid precision: 0.840000, valid loss: 85.299225
epoch: 390, train precision: 0.965733, train loss: 19.318457, valid precision: 0.848600, valid loss: 83.054632
epoch: 391, train precision: 0.962978, train loss: 19.738115, valid precision: 0.846000, valid loss: 83.211552
epoch: 392, train precision: 0.963111, train loss: 19.600874, valid precision: 0.845000, valid loss: 83.884929
epoch: 393, train precision: 0.966711, train loss: 18.794147, valid precision: 0.848600, valid loss: 80.513518
epoch: 394, train precision: 0.957600, train loss: 22.145053, valid precision: 0.836400, valid loss: 86.872026
epoch: 395, train precision: 0.962800, train loss: 19.921296, valid precision: 0.847000, valid loss: 85.890955
epoch: 396, train precision: 0.963778, train loss: 19.682251, valid precision: 0.845200, valid loss: 81.932309
epoch: 397, train precision: 0.959844, train loss: 21.107637, valid precision: 0.840800, valid loss: 92.455202
epoch: 398, train precision: 0.960422, train loss: 21.129917, valid precision: 0.843200, valid loss: 83.498171
epoch: 399, train precision: 0.958844, train loss: 21.364151, valid precision: 0.843400, valid loss: 82.750429
epoch: 400, train precision: 0.962022, train loss: 20.391214, valid precision: 0.847600, valid loss: 84.847381
epoch: 401, train precision: 0.957267, train loss: 21.764905, valid precision: 0.848600, valid loss: 91.439287
epoch: 402, train precision: 0.959444, train loss: 21.264644, valid precision: 0.834600, valid loss: 88.799927
epoch: 403, train precision: 0.963756, train loss: 19.963493, valid precision: 0.845200, valid loss: 86.343722
epoch: 404, train precision: 0.966844, train loss: 18.901762, valid precision: 0.847800, valid loss: 86.681563
epoch: 405, train precision: 0.955622, train loss: 22.251686, valid precision: 0.834400, valid loss: 90.382820
epoch: 406, train precision: 0.958889, train loss: 21.156344, valid precision: 0.848600, valid loss: 84.967231
epoch: 407, train precision: 0.963267, train loss: 20.670748, valid precision: 0.847200, valid loss: 85.020026
epoch: 408, train precision: 0.964933, train loss: 19.555316, valid precision: 0.842200, valid loss: 85.933575
epoch: 409, train precision: 0.969044, train loss: 18.212977, valid precision: 0.852000, valid loss: 85.643088
epoch: 410, train precision: 0.960644, train loss: 21.151958, valid precision: 0.839000, valid loss: 94.646560
epoch: 411, train precision: 0.966956, train loss: 18.886160, valid precision: 0.846000, valid loss: 85.790362
epoch: 412, train precision: 0.958533, train loss: 21.815832, valid precision: 0.843800, valid loss: 87.328967
epoch: 413, train precision: 0.963644, train loss: 19.387208, valid precision: 0.844200, valid loss: 88.090182
epoch: 414, train precision: 0.969422, train loss: 17.643100, valid precision: 0.850200, valid loss: 88.616977
epoch: 415, train precision: 0.962467, train loss: 20.158917, valid precision: 0.845200, valid loss: 88.984417
epoch: 416, train precision: 0.964156, train loss: 19.497638, valid precision: 0.843400, valid loss: 85.362756
epoch: 417, train precision: 0.966733, train loss: 18.930121, valid precision: 0.849200, valid loss: 87.057836
epoch: 418, train precision: 0.966800, train loss: 18.882983, valid precision: 0.851000, valid loss: 83.297615
epoch: 419, train precision: 0.966978, train loss: 18.674552, valid precision: 0.850800, valid loss: 84.798156
epoch: 420, train precision: 0.963667, train loss: 20.291331, valid precision: 0.845200, valid loss: 86.229718
epoch: 421, train precision: 0.970044, train loss: 17.823319, valid precision: 0.850200, valid loss: 83.237721
epoch: 422, train precision: 0.968444, train loss: 18.549680, valid precision: 0.849200, valid loss: 83.368653
epoch: 423, train precision: 0.965378, train loss: 19.445926, valid precision: 0.852800, valid loss: 85.777187
epoch: 424, train precision: 0.965756, train loss: 19.153772, valid precision: 0.847600, valid loss: 81.324357
epoch: 425, train precision: 0.964378, train loss: 20.085675, valid precision: 0.846600, valid loss: 79.971119
epoch: 426, train precision: 0.967022, train loss: 18.832293, valid precision: 0.844800, valid loss: 85.728042
epoch: 427, train precision: 0.968222, train loss: 18.102349, valid precision: 0.851600, valid loss: 87.037831
epoch: 428, train precision: 0.965333, train loss: 19.255735, valid precision: 0.851000, valid loss: 84.480127
epoch: 429, train precision: 0.967044, train loss: 18.927951, valid precision: 0.848200, valid loss: 82.248611
epoch: 430, train precision: 0.965622, train loss: 18.933317, valid precision: 0.847600, valid loss: 84.095924
epoch: 431, train precision: 0.960178, train loss: 21.062540, valid precision: 0.835600, valid loss: 89.589981
epoch: 432, train precision: 0.958356, train loss: 21.978251, valid precision: 0.844400, valid loss: 86.738379
epoch: 433, train precision: 0.968400, train loss: 18.353902, valid precision: 0.846800, valid loss: 81.262283
epoch: 434, train precision: 0.962800, train loss: 20.316943, valid precision: 0.842200, valid loss: 89.504418
epoch: 435, train precision: 0.965800, train loss: 19.578482, valid precision: 0.847000, valid loss: 83.734123
epoch: 436, train precision: 0.968089, train loss: 18.456099, valid precision: 0.845000, valid loss: 84.121223
epoch: 437, train precision: 0.955667, train loss: 23.169803, valid precision: 0.837200, valid loss: 92.875862
epoch: 438, train precision: 0.964800, train loss: 20.160438, valid precision: 0.848000, valid loss: 85.750652
epoch: 439, train precision: 0.966289, train loss: 19.348145, valid precision: 0.853400, valid loss: 83.571045
epoch: 440, train precision: 0.966000, train loss: 19.175610, valid precision: 0.851200, valid loss: 87.367626
epoch: 441, train precision: 0.968800, train loss: 17.984666, valid precision: 0.850000, valid loss: 87.849902
epoch: 442, train precision: 0.967556, train loss: 18.703876, valid precision: 0.854400, valid loss: 85.969771
epoch: 443, train precision: 0.961978, train loss: 20.584541, valid precision: 0.848000, valid loss: 82.451963
epoch: 444, train precision: 0.966200, train loss: 19.234206, valid precision: 0.850400, valid loss: 81.614987
epoch: 445, train precision: 0.966378, train loss: 19.339084, valid precision: 0.851400, valid loss: 83.037714
epoch: 446, train precision: 0.962422, train loss: 20.634816, valid precision: 0.846000, valid loss: 85.690143
epoch: 447, train precision: 0.966733, train loss: 19.225038, valid precision: 0.847000, valid loss: 84.646262
epoch: 448, train precision: 0.961178, train loss: 20.805495, valid precision: 0.848600, valid loss: 85.921115
epoch: 449, train precision: 0.966333, train loss: 19.218689, valid precision: 0.849400, valid loss: 85.190303
epoch: 450, train precision: 0.968889, train loss: 18.555572, valid precision: 0.849600, valid loss: 84.247388
epoch: 451, train precision: 0.967400, train loss: 19.296449, valid precision: 0.849200, valid loss: 87.376708
epoch: 452, train precision: 0.965533, train loss: 19.285110, valid precision: 0.850800, valid loss: 87.370392
epoch: 453, train precision: 0.962067, train loss: 20.441858, valid precision: 0.846200, valid loss: 88.162209
epoch: 454, train precision: 0.964911, train loss: 19.866019, valid precision: 0.847200, valid loss: 83.734798
epoch: 455, train precision: 0.964489, train loss: 20.019599, valid precision: 0.851200, valid loss: 81.921630
epoch: 456, train precision: 0.967822, train loss: 18.542713, valid precision: 0.848600, valid loss: 83.659283
epoch: 457, train precision: 0.967089, train loss: 19.228126, valid precision: 0.853800, valid loss: 83.352879
epoch: 458, train precision: 0.962822, train loss: 20.156283, valid precision: 0.845000, valid loss: 89.916165
epoch: 459, train precision: 0.965444, train loss: 19.553674, valid precision: 0.848000, valid loss: 84.808232
epoch: 460, train precision: 0.969556, train loss: 18.465395, valid precision: 0.852600, valid loss: 83.286517
epoch: 461, train precision: 0.965400, train loss: 19.612964, valid precision: 0.851000, valid loss: 82.661933
epoch: 462, train precision: 0.969289, train loss: 18.078330, valid precision: 0.853600, valid loss: 85.413725
epoch: 463, train precision: 0.967178, train loss: 18.904332, valid precision: 0.846800, valid loss: 84.678614
epoch: 464, train precision: 0.959622, train loss: 22.067797, valid precision: 0.846000, valid loss: 86.578507
epoch: 465, train precision: 0.959267, train loss: 21.367304, valid precision: 0.846000, valid loss: 91.690866
epoch: 466, train precision: 0.961000, train loss: 21.095995, valid precision: 0.845000, valid loss: 90.627237
epoch: 467, train precision: 0.966156, train loss: 18.955726, valid precision: 0.851000, valid loss: 84.961276
epoch: 468, train precision: 0.963844, train loss: 20.200337, valid precision: 0.848600, valid loss: 83.480380
epoch: 469, train precision: 0.970200, train loss: 17.656593, valid precision: 0.852800, valid loss: 84.978778
epoch: 470, train precision: 0.958822, train loss: 21.896575, valid precision: 0.848200, valid loss: 83.913526
epoch: 471, train precision: 0.963578, train loss: 19.801433, valid precision: 0.846800, valid loss: 86.386563
epoch: 472, train precision: 0.965444, train loss: 19.734099, valid precision: 0.841200, valid loss: 88.217971
epoch: 473, train precision: 0.966467, train loss: 19.226973, valid precision: 0.851000, valid loss: 82.223199
epoch: 474, train precision: 0.968378, train loss: 18.149365, valid precision: 0.850800, valid loss: 85.845381
epoch: 475, train precision: 0.965200, train loss: 19.544882, valid precision: 0.850200, valid loss: 85.476489
epoch: 476, train precision: 0.964689, train loss: 20.209388, valid precision: 0.845400, valid loss: 85.206491
epoch: 477, train precision: 0.968111, train loss: 18.627593, valid precision: 0.853400, valid loss: 85.015594
epoch: 478, train precision: 0.966756, train loss: 19.041924, valid precision: 0.848400, valid loss: 84.669658
epoch: 479, train precision: 0.964222, train loss: 19.892938, valid precision: 0.850400, valid loss: 86.230154
epoch: 480, train precision: 0.963489, train loss: 20.346044, valid precision: 0.846600, valid loss: 84.794913
epoch: 481, train precision: 0.966289, train loss: 19.339173, valid precision: 0.853000, valid loss: 85.469319
epoch: 482, train precision: 0.969556, train loss: 18.192913, valid precision: 0.853200, valid loss: 84.937182
epoch: 483, train precision: 0.963822, train loss: 19.813957, valid precision: 0.839600, valid loss: 88.325945
epoch: 484, train precision: 0.960733, train loss: 21.174843, valid precision: 0.847600, valid loss: 83.965157
epoch: 485, train precision: 0.966778, train loss: 19.655582, valid precision: 0.853200, valid loss: 80.579295
epoch: 486, train precision: 0.964378, train loss: 19.703464, valid precision: 0.853400, valid loss: 84.778009
epoch: 487, train precision: 0.962556, train loss: 20.907664, valid precision: 0.850400, valid loss: 83.374638
epoch: 488, train precision: 0.966511, train loss: 19.286345, valid precision: 0.851600, valid loss: 87.993173
epoch: 489, train precision: 0.952733, train loss: 24.384529, valid precision: 0.836800, valid loss: 87.596730
epoch: 490, train precision: 0.962044, train loss: 20.609908, valid precision: 0.847200, valid loss: 88.809427
epoch: 491, train precision: 0.963267, train loss: 20.815490, valid precision: 0.838000, valid loss: 90.538091
epoch: 492, train precision: 0.965356, train loss: 19.856990, valid precision: 0.844000, valid loss: 84.595194
epoch: 493, train precision: 0.972978, train loss: 16.967413, valid precision: 0.858400, valid loss: 84.494626
epoch: 494, train precision: 0.965067, train loss: 19.856029, valid precision: 0.847600, valid loss: 90.627300
epoch: 495, train precision: 0.964756, train loss: 20.579370, valid precision: 0.842400, valid loss: 89.666909
epoch: 496, train precision: 0.966844, train loss: 19.459302, valid precision: 0.849600, valid loss: 88.124780
epoch: 497, train precision: 0.969489, train loss: 18.367211, valid precision: 0.848800, valid loss: 85.743564
epoch: 498, train precision: 0.968067, train loss: 18.963018, valid precision: 0.852000, valid loss: 87.027404
epoch: 499, train precision: 0.968956, train loss: 18.907079, valid precision: 0.849400, valid loss: 86.021320
epoch: 500, train precision: 0.969489, train loss: 18.135846, valid precision: 0.853800, valid loss: 86.323994
epoch: 501, train precision: 0.968333, train loss: 19.169808, valid precision: 0.854600, valid loss: 85.494781
epoch: 502, train precision: 0.967556, train loss: 19.038980, valid precision: 0.849200, valid loss: 88.429942
epoch: 503, train precision: 0.962733, train loss: 21.075736, valid precision: 0.845000, valid loss: 92.992399
epoch: 504, train precision: 0.968644, train loss: 18.769517, valid precision: 0.852600, valid loss: 86.520719
epoch: 505, train precision: 0.965778, train loss: 20.101002, valid precision: 0.848200, valid loss: 83.573985
epoch: 506, train precision: 0.963289, train loss: 20.830927, valid precision: 0.851200, valid loss: 83.920536
epoch: 507, train precision: 0.965422, train loss: 19.532008, valid precision: 0.842000, valid loss: 92.468205
epoch: 508, train precision: 0.968844, train loss: 18.444425, valid precision: 0.853800, valid loss: 87.057671
epoch: 509, train precision: 0.963800, train loss: 20.212639, valid precision: 0.846000, valid loss: 86.638121
epoch: 510, train precision: 0.961356, train loss: 21.063589, valid precision: 0.847400, valid loss: 86.983056
epoch: 511, train precision: 0.966800, train loss: 19.262560, valid precision: 0.852000, valid loss: 90.050606
epoch: 512, train precision: 0.968333, train loss: 18.644597, valid precision: 0.850000, valid loss: 86.707653
epoch: 513, train precision: 0.966622, train loss: 19.044894, valid precision: 0.854000, valid loss: 89.410924
epoch: 514, train precision: 0.963089, train loss: 20.244927, valid precision: 0.851800, valid loss: 87.295076
epoch: 515, train precision: 0.962978, train loss: 20.538860, valid precision: 0.849600, valid loss: 87.740860
epoch: 516, train precision: 0.967556, train loss: 19.098973, valid precision: 0.853000, valid loss: 88.834095
epoch: 517, train precision: 0.958244, train loss: 22.842372, valid precision: 0.845600, valid loss: 86.928475
epoch: 518, train precision: 0.964267, train loss: 20.011329, valid precision: 0.846000, valid loss: 87.292020
epoch: 519, train precision: 0.965644, train loss: 19.798627, valid precision: 0.847400, valid loss: 89.224258
epoch: 520, train precision: 0.966089, train loss: 20.052632, valid precision: 0.847600, valid loss: 89.401085
epoch: 521, train precision: 0.963467, train loss: 20.281986, valid precision: 0.846000, valid loss: 88.551010
epoch: 522, train precision: 0.964778, train loss: 19.884545, valid precision: 0.848400, valid loss: 93.033189
epoch: 523, train precision: 0.966889, train loss: 19.300748, valid precision: 0.846600, valid loss: 91.659267
epoch: 524, train precision: 0.964511, train loss: 20.216348, valid precision: 0.842800, valid loss: 92.798231
epoch: 525, train precision: 0.963156, train loss: 20.272531, valid precision: 0.842800, valid loss: 95.790765
epoch: 526, train precision: 0.959489, train loss: 22.246072, valid precision: 0.842800, valid loss: 93.581995
epoch: 527, train precision: 0.965756, train loss: 19.836866, valid precision: 0.846400, valid loss: 86.016917
epoch: 528, train precision: 0.969867, train loss: 18.509948, valid precision: 0.845200, valid loss: 86.406621
epoch: 529, train precision: 0.964467, train loss: 20.119332, valid precision: 0.843800, valid loss: 87.425334
epoch: 530, train precision: 0.967200, train loss: 19.288915, valid precision: 0.844400, valid loss: 84.054845
epoch: 531, train precision: 0.963533, train loss: 20.998343, valid precision: 0.837600, valid loss: 93.547353
epoch: 532, train precision: 0.970333, train loss: 18.025997, valid precision: 0.854800, valid loss: 84.531213
epoch: 533, train precision: 0.964956, train loss: 20.138714, valid precision: 0.843200, valid loss: 88.199532
epoch: 534, train precision: 0.969644, train loss: 18.397014, valid precision: 0.849600, valid loss: 85.432082
epoch: 535, train precision: 0.966556, train loss: 19.453552, valid precision: 0.851000, valid loss: 85.413759
epoch: 536, train precision: 0.964644, train loss: 20.069950, valid precision: 0.847000, valid loss: 85.525926
epoch: 537, train precision: 0.968089, train loss: 19.280985, valid precision: 0.848800, valid loss: 83.647951
epoch: 538, train precision: 0.969067, train loss: 18.635596, valid precision: 0.851200, valid loss: 86.076964
epoch: 539, train precision: 0.962111, train loss: 20.981790, valid precision: 0.850400, valid loss: 86.188745
epoch: 540, train precision: 0.962356, train loss: 20.919538, valid precision: 0.848800, valid loss: 85.484529
epoch: 541, train precision: 0.968022, train loss: 18.867041, valid precision: 0.850000, valid loss: 87.495413
epoch: 542, train precision: 0.963467, train loss: 20.631797, valid precision: 0.853200, valid loss: 89.947042
epoch: 543, train precision: 0.969422, train loss: 18.267554, valid precision: 0.852800, valid loss: 89.346809
epoch: 544, train precision: 0.964822, train loss: 20.389175, valid precision: 0.846200, valid loss: 87.904575
epoch: 545, train precision: 0.966222, train loss: 19.746112, valid precision: 0.844400, valid loss: 87.115056
epoch: 546, train precision: 0.967556, train loss: 19.303889, valid precision: 0.847800, valid loss: 88.222137
epoch: 547, train precision: 0.964111, train loss: 20.363951, valid precision: 0.845800, valid loss: 90.217108
epoch: 548, train precision: 0.963800, train loss: 20.672868, valid precision: 0.847600, valid loss: 86.332853
epoch: 549, train precision: 0.968733, train loss: 19.048338, valid precision: 0.854400, valid loss: 81.743405
epoch: 550, train precision: 0.961133, train loss: 21.494858, valid precision: 0.850200, valid loss: 85.943222
epoch: 551, train precision: 0.964889, train loss: 20.114021, valid precision: 0.846800, valid loss: 92.526527
epoch: 552, train precision: 0.968756, train loss: 18.818335, valid precision: 0.848200, valid loss: 84.909471
epoch: 553, train precision: 0.967000, train loss: 19.310915, valid precision: 0.851800, valid loss: 85.273512
epoch: 554, train precision: 0.965444, train loss: 20.379307, valid precision: 0.845200, valid loss: 89.657004
epoch: 555, train precision: 0.964267, train loss: 20.415449, valid precision: 0.850200, valid loss: 89.603167
epoch: 556, train precision: 0.960644, train loss: 22.599506, valid precision: 0.841800, valid loss: 94.645639
epoch: 557, train precision: 0.965933, train loss: 19.865707, valid precision: 0.848000, valid loss: 89.298925
epoch: 558, train precision: 0.966422, train loss: 19.991983, valid precision: 0.843000, valid loss: 92.945296
epoch: 559, train precision: 0.966533, train loss: 19.343868, valid precision: 0.850200, valid loss: 87.546402
epoch: 560, train precision: 0.966333, train loss: 19.723273, valid precision: 0.849200, valid loss: 86.275095
epoch: 561, train precision: 0.968556, train loss: 19.064232, valid precision: 0.849000, valid loss: 87.000528
epoch: 562, train precision: 0.963889, train loss: 20.466305, valid precision: 0.846000, valid loss: 87.449217
epoch: 563, train precision: 0.969044, train loss: 18.992274, valid precision: 0.851400, valid loss: 87.239927
epoch: 564, train precision: 0.966178, train loss: 19.546682, valid precision: 0.845200, valid loss: 90.817045
epoch: 565, train precision: 0.967667, train loss: 19.815148, valid precision: 0.855000, valid loss: 82.863964
epoch: 566, train precision: 0.968711, train loss: 18.271598, valid precision: 0.853800, valid loss: 88.699312
epoch: 567, train precision: 0.961289, train loss: 21.431848, valid precision: 0.844200, valid loss: 86.157794
epoch: 568, train precision: 0.966489, train loss: 19.850023, valid precision: 0.849800, valid loss: 88.439317
epoch: 569, train precision: 0.966933, train loss: 19.579878, valid precision: 0.853200, valid loss: 86.109330
epoch: 570, train precision: 0.966556, train loss: 19.668894, valid precision: 0.850800, valid loss: 87.135046
epoch: 571, train precision: 0.965978, train loss: 20.280151, valid precision: 0.854400, valid loss: 83.658268
epoch: 572, train precision: 0.966578, train loss: 19.673644, valid precision: 0.858000, valid loss: 85.654297
epoch: 573, train precision: 0.968689, train loss: 18.940022, valid precision: 0.852400, valid loss: 83.789256
epoch: 574, train precision: 0.962933, train loss: 20.603009, valid precision: 0.847800, valid loss: 87.855089
epoch: 575, train precision: 0.970111, train loss: 18.911486, valid precision: 0.851800, valid loss: 87.840491
epoch: 576, train precision: 0.964733, train loss: 20.556148, valid precision: 0.845800, valid loss: 90.324090
epoch: 577, train precision: 0.968267, train loss: 18.507756, valid precision: 0.848000, valid loss: 92.255223
epoch: 578, train precision: 0.966533, train loss: 19.692024, valid precision: 0.851800, valid loss: 88.973268
epoch: 579, train precision: 0.963044, train loss: 21.215958, valid precision: 0.849600, valid loss: 87.077622
epoch: 580, train precision: 0.965067, train loss: 20.115486, valid precision: 0.847800, valid loss: 89.227349
epoch: 581, train precision: 0.969422, train loss: 18.609891, valid precision: 0.850600, valid loss: 86.000453
epoch: 582, train precision: 0.960222, train loss: 21.820243, valid precision: 0.845200, valid loss: 91.221731
epoch: 583, train precision: 0.971911, train loss: 17.873145, valid precision: 0.856600, valid loss: 86.425835
epoch: 584, train precision: 0.965422, train loss: 20.099102, valid precision: 0.851200, valid loss: 86.149711
epoch: 585, train precision: 0.965067, train loss: 20.361076, valid precision: 0.851600, valid loss: 85.019180
epoch: 586, train precision: 0.965578, train loss: 20.197376, valid precision: 0.845600, valid loss: 86.469884
epoch: 587, train precision: 0.969178, train loss: 18.643892, valid precision: 0.849000, valid loss: 88.891218
epoch: 588, train precision: 0.966356, train loss: 19.662327, valid precision: 0.851800, valid loss: 90.059654
epoch: 589, train precision: 0.967178, train loss: 19.453363, valid precision: 0.850200, valid loss: 91.425887
epoch: 590, train precision: 0.964756, train loss: 20.427877, valid precision: 0.847600, valid loss: 91.527050
epoch: 591, train precision: 0.960844, train loss: 21.799394, valid precision: 0.848600, valid loss: 96.932131
epoch: 592, train precision: 0.964933, train loss: 19.829597, valid precision: 0.851600, valid loss: 91.033271
epoch: 593, train precision: 0.968911, train loss: 19.426795, valid precision: 0.854200, valid loss: 88.741387
epoch: 594, train precision: 0.969622, train loss: 18.646023, valid precision: 0.855600, valid loss: 84.722089
epoch: 595, train precision: 0.963667, train loss: 20.927990, valid precision: 0.847200, valid loss: 86.303615
epoch: 596, train precision: 0.970467, train loss: 18.268450, valid precision: 0.855200, valid loss: 88.713231
epoch: 597, train precision: 0.974356, train loss: 16.866871, valid precision: 0.854800, valid loss: 87.664209
epoch: 598, train precision: 0.963089, train loss: 21.153859, valid precision: 0.846800, valid loss: 89.450736
epoch: 599, train precision: 0.967711, train loss: 19.414753, valid precision: 0.846600, valid loss: 88.764822
epoch: 600, train precision: 0.966578, train loss: 19.667840, valid precision: 0.853800, valid loss: 88.684355
epoch: 601, train precision: 0.968733, train loss: 19.390979, valid precision: 0.851400, valid loss: 88.495559
epoch: 602, train precision: 0.971133, train loss: 18.401320, valid precision: 0.849800, valid loss: 86.048931
epoch: 603, train precision: 0.956556, train loss: 23.443237, valid precision: 0.841400, valid loss: 91.882318
epoch: 604, train precision: 0.970867, train loss: 18.070857, valid precision: 0.856400, valid loss: 89.766944
epoch: 605, train precision: 0.965622, train loss: 19.966195, valid precision: 0.849000, valid loss: 92.001275
epoch: 606, train precision: 0.967778, train loss: 19.232184, valid precision: 0.851800, valid loss: 92.052599
epoch: 607, train precision: 0.970000, train loss: 18.614476, valid precision: 0.856800, valid loss: 82.401152
epoch: 608, train precision: 0.966956, train loss: 19.914046, valid precision: 0.847400, valid loss: 83.623834
epoch: 609, train precision: 0.964400, train loss: 20.632987, valid precision: 0.847600, valid loss: 92.802239
epoch: 610, train precision: 0.967244, train loss: 19.446522, valid precision: 0.858000, valid loss: 86.786299
epoch: 611, train precision: 0.965067, train loss: 20.089181, valid precision: 0.852800, valid loss: 96.570796
epoch: 612, train precision: 0.965022, train loss: 20.678997, valid precision: 0.846000, valid loss: 93.109212
epoch: 613, train precision: 0.968400, train loss: 19.216528, valid precision: 0.852200, valid loss: 92.513001
epoch: 614, train precision: 0.969956, train loss: 19.067305, valid precision: 0.851800, valid loss: 83.440787
epoch: 615, train precision: 0.965111, train loss: 20.225285, valid precision: 0.848800, valid loss: 91.484459
epoch: 616, train precision: 0.970444, train loss: 18.759300, valid precision: 0.855200, valid loss: 84.282272
epoch: 617, train precision: 0.964756, train loss: 20.568250, valid precision: 0.852400, valid loss: 86.550602
epoch: 618, train precision: 0.967200, train loss: 19.743670, valid precision: 0.851600, valid loss: 88.007679
epoch: 619, train precision: 0.966533, train loss: 19.749392, valid precision: 0.854000, valid loss: 89.960180
epoch: 620, train precision: 0.966778, train loss: 20.078411, valid precision: 0.847200, valid loss: 86.736053
epoch: 621, train precision: 0.967622, train loss: 19.400949, valid precision: 0.853200, valid loss: 87.420494
epoch: 622, train precision: 0.970822, train loss: 18.462187, valid precision: 0.856600, valid loss: 86.574673
epoch: 623, train precision: 0.964622, train loss: 20.158735, valid precision: 0.847400, valid loss: 88.546498
epoch: 624, train precision: 0.968844, train loss: 19.209802, valid precision: 0.853000, valid loss: 88.517786
epoch: 625, train precision: 0.966733, train loss: 20.339861, valid precision: 0.847000, valid loss: 89.949734
epoch: 626, train precision: 0.969689, train loss: 18.674605, valid precision: 0.850600, valid loss: 92.058478
epoch: 627, train precision: 0.958933, train loss: 22.365631, valid precision: 0.842800, valid loss: 91.864372
epoch: 628, train precision: 0.963489, train loss: 20.984204, valid precision: 0.842600, valid loss: 91.718315
epoch: 629, train precision: 0.967644, train loss: 19.591774, valid precision: 0.849600, valid loss: 89.086375
epoch: 630, train precision: 0.963667, train loss: 21.056479, valid precision: 0.844600, valid loss: 91.840971
epoch: 631, train precision: 0.965711, train loss: 20.433383, valid precision: 0.852000, valid loss: 90.242535
epoch: 632, train precision: 0.970444, train loss: 18.354719, valid precision: 0.847200, valid loss: 93.246217
epoch: 633, train precision: 0.965400, train loss: 20.794874, valid precision: 0.852400, valid loss: 82.604902
epoch: 634, train precision: 0.967111, train loss: 19.648724, valid precision: 0.849400, valid loss: 87.818562
epoch: 635, train precision: 0.964911, train loss: 20.803039, valid precision: 0.851600, valid loss: 90.463006
epoch: 636, train precision: 0.964889, train loss: 20.489893, valid precision: 0.848800, valid loss: 94.950293
epoch: 637, train precision: 0.970444, train loss: 18.876238, valid precision: 0.854600, valid loss: 85.794323
epoch: 638, train precision: 0.971622, train loss: 18.186412, valid precision: 0.855200, valid loss: 82.384567
epoch: 639, train precision: 0.970133, train loss: 19.048085, valid precision: 0.854400, valid loss: 87.134726
epoch: 640, train precision: 0.968911, train loss: 19.553423, valid precision: 0.850400, valid loss: 87.127317
epoch: 641, train precision: 0.969956, train loss: 18.762780, valid precision: 0.853400, valid loss: 87.924794
epoch: 642, train precision: 0.965200, train loss: 20.441226, valid precision: 0.841800, valid loss: 88.627482
epoch: 643, train precision: 0.970111, train loss: 18.506177, valid precision: 0.851800, valid loss: 91.956445
epoch: 644, train precision: 0.968244, train loss: 19.375346, valid precision: 0.855000, valid loss: 86.898286
epoch: 645, train precision: 0.968400, train loss: 18.835734, valid precision: 0.856800, valid loss: 89.604607
epoch: 646, train precision: 0.968667, train loss: 19.319865, valid precision: 0.852200, valid loss: 89.404345
epoch: 647, train precision: 0.972400, train loss: 18.007410, valid precision: 0.854200, valid loss: 84.215858
epoch: 648, train precision: 0.963200, train loss: 21.353945, valid precision: 0.848200, valid loss: 94.900411
epoch: 649, train precision: 0.966644, train loss: 19.605537, valid precision: 0.846600, valid loss: 93.882483
epoch: 650, train precision: 0.968422, train loss: 19.841119, valid precision: 0.845000, valid loss: 90.458853
epoch: 651, train precision: 0.960867, train loss: 22.221820, valid precision: 0.846400, valid loss: 90.655077
epoch: 652, train precision: 0.965000, train loss: 21.136795, valid precision: 0.849200, valid loss: 93.181709
epoch: 653, train precision: 0.970156, train loss: 18.240292, valid precision: 0.852200, valid loss: 90.678940
epoch: 654, train precision: 0.971578, train loss: 18.252558, valid precision: 0.855000, valid loss: 89.906428
epoch: 655, train precision: 0.970156, train loss: 19.059627, valid precision: 0.853800, valid loss: 91.559534
epoch: 656, train precision: 0.966178, train loss: 20.542110, valid precision: 0.845800, valid loss: 90.234364
epoch: 657, train precision: 0.969733, train loss: 18.936398, valid precision: 0.851000, valid loss: 90.455878
epoch: 658, train precision: 0.969800, train loss: 18.669196, valid precision: 0.854400, valid loss: 87.432383
epoch: 659, train precision: 0.966667, train loss: 20.231312, valid precision: 0.847400, valid loss: 88.653639
epoch: 660, train precision: 0.962178, train loss: 21.593648, valid precision: 0.848000, valid loss: 90.661926
epoch: 661, train precision: 0.970400, train loss: 18.511855, valid precision: 0.853600, valid loss: 89.582461
epoch: 662, train precision: 0.969533, train loss: 19.107837, valid precision: 0.850600, valid loss: 89.646143
epoch: 663, train precision: 0.963956, train loss: 21.127332, valid precision: 0.850200, valid loss: 90.958610
epoch: 664, train precision: 0.967422, train loss: 19.516299, valid precision: 0.844600, valid loss: 90.684229
epoch: 665, train precision: 0.964578, train loss: 21.266583, valid precision: 0.844400, valid loss: 87.752292
epoch: 666, train precision: 0.972244, train loss: 18.374667, valid precision: 0.857600, valid loss: 85.140239
epoch: 667, train precision: 0.968178, train loss: 19.554555, valid precision: 0.848200, valid loss: 92.918271
epoch: 668, train precision: 0.966667, train loss: 20.088266, valid precision: 0.852400, valid loss: 95.861974
epoch: 669, train precision: 0.965533, train loss: 20.454736, valid precision: 0.851200, valid loss: 88.868162
epoch: 670, train precision: 0.965067, train loss: 20.429743, valid precision: 0.846800, valid loss: 91.451235
epoch: 671, train precision: 0.963267, train loss: 21.211784, valid precision: 0.844800, valid loss: 92.658204
epoch: 672, train precision: 0.966800, train loss: 20.137037, valid precision: 0.857000, valid loss: 85.720780
epoch: 673, train precision: 0.964311, train loss: 20.927850, valid precision: 0.845400, valid loss: 88.933884
epoch: 674, train precision: 0.970111, train loss: 18.937501, valid precision: 0.857200, valid loss: 88.965423
epoch: 675, train precision: 0.965467, train loss: 20.623222, valid precision: 0.849200, valid loss: 89.106686
epoch: 676, train precision: 0.968889, train loss: 19.119988, valid precision: 0.855800, valid loss: 85.804545
epoch: 677, train precision: 0.967800, train loss: 19.845576, valid precision: 0.851600, valid loss: 87.202364
epoch: 678, train precision: 0.967289, train loss: 20.176303, valid precision: 0.858200, valid loss: 82.744970
epoch: 679, train precision: 0.972911, train loss: 18.042458, valid precision: 0.848800, valid loss: 86.816596
epoch: 680, train precision: 0.969933, train loss: 18.435877, valid precision: 0.854000, valid loss: 88.397085
epoch: 681, train precision: 0.962889, train loss: 21.901454, valid precision: 0.849000, valid loss: 93.953072
epoch: 682, train precision: 0.966467, train loss: 20.205495, valid precision: 0.851400, valid loss: 89.282256
epoch: 683, train precision: 0.968267, train loss: 19.236678, valid precision: 0.854000, valid loss: 89.075078
epoch: 684, train precision: 0.965867, train loss: 20.031530, valid precision: 0.853400, valid loss: 85.312195
epoch: 685, train precision: 0.962578, train loss: 21.328286, valid precision: 0.847600, valid loss: 93.491931
epoch: 686, train precision: 0.969311, train loss: 19.335775, valid precision: 0.858800, valid loss: 87.486673
epoch: 687, train precision: 0.968978, train loss: 19.341974, valid precision: 0.853600, valid loss: 88.279701
epoch: 688, train precision: 0.969956, train loss: 18.803955, valid precision: 0.855600, valid loss: 86.529291
epoch: 689, train precision: 0.968133, train loss: 19.479996, valid precision: 0.854200, valid loss: 90.737743
epoch: 690, train precision: 0.966711, train loss: 20.029071, valid precision: 0.853800, valid loss: 90.833638
epoch: 691, train precision: 0.970444, train loss: 18.608309, valid precision: 0.851200, valid loss: 87.761067
epoch: 692, train precision: 0.965911, train loss: 20.779100, valid precision: 0.853000, valid loss: 82.798268
epoch: 693, train precision: 0.965822, train loss: 20.506445, valid precision: 0.853800, valid loss: 87.632645
epoch: 694, train precision: 0.964200, train loss: 20.784411, valid precision: 0.852800, valid loss: 88.922779
epoch: 695, train precision: 0.968822, train loss: 19.204807, valid precision: 0.849800, valid loss: 88.472321
epoch: 696, train precision: 0.965044, train loss: 21.071040, valid precision: 0.846600, valid loss: 93.497441
epoch: 697, train precision: 0.967733, train loss: 19.270902, valid precision: 0.850600, valid loss: 96.390751
epoch: 698, train precision: 0.971911, train loss: 18.151917, valid precision: 0.853800, valid loss: 100.056402
epoch: 699, train precision: 0.973756, train loss: 17.547254, valid precision: 0.856000, valid loss: 90.258625
epoch: 700, train precision: 0.970044, train loss: 18.646530, valid precision: 0.855000, valid loss: 97.996850
epoch: 701, train precision: 0.965422, train loss: 20.716980, valid precision: 0.846200, valid loss: 93.745233
epoch: 702, train precision: 0.968556, train loss: 19.495459, valid precision: 0.850200, valid loss: 95.465826
epoch: 703, train precision: 0.968978, train loss: 19.562701, valid precision: 0.849000, valid loss: 87.687453
epoch: 704, train precision: 0.967711, train loss: 19.583372, valid precision: 0.847400, valid loss: 99.979291
epoch: 705, train precision: 0.966756, train loss: 20.358684, valid precision: 0.856000, valid loss: 87.154098
epoch: 706, train precision: 0.972244, train loss: 18.549646, valid precision: 0.852800, valid loss: 90.754463
epoch: 707, train precision: 0.968000, train loss: 19.828872, valid precision: 0.849200, valid loss: 92.545202
epoch: 708, train precision: 0.966978, train loss: 19.990878, valid precision: 0.847000, valid loss: 94.623289
epoch: 709, train precision: 0.968356, train loss: 19.331371, valid precision: 0.848600, valid loss: 94.379796
epoch: 710, train precision: 0.968067, train loss: 19.555431, valid precision: 0.853800, valid loss: 96.067108
epoch: 711, train precision: 0.971267, train loss: 18.366455, valid precision: 0.854000, valid loss: 88.425876
epoch: 712, train precision: 0.964689, train loss: 21.063499, valid precision: 0.848400, valid loss: 87.483398
epoch: 713, train precision: 0.967000, train loss: 20.179905, valid precision: 0.848200, valid loss: 93.494381
epoch: 714, train precision: 0.970756, train loss: 18.992568, valid precision: 0.857800, valid loss: 91.097090
epoch: 715, train precision: 0.965178, train loss: 20.899535, valid precision: 0.846600, valid loss: 98.022976
epoch: 716, train precision: 0.966533, train loss: 20.588648, valid precision: 0.845200, valid loss: 95.011506
epoch: 717, train precision: 0.970156, train loss: 18.874992, valid precision: 0.850800, valid loss: 93.476163
epoch: 718, train precision: 0.967200, train loss: 20.508032, valid precision: 0.844600, valid loss: 90.210652
epoch: 719, train precision: 0.966244, train loss: 20.332000, valid precision: 0.850000, valid loss: 90.503796
epoch: 720, train precision: 0.972933, train loss: 17.866011, valid precision: 0.853000, valid loss: 93.331976
epoch: 721, train precision: 0.963533, train loss: 21.740586, valid precision: 0.847600, valid loss: 94.148557
epoch: 722, train precision: 0.961867, train loss: 22.101608, valid precision: 0.852000, valid loss: 94.078726
epoch: 723, train precision: 0.971089, train loss: 18.289644, valid precision: 0.858600, valid loss: 90.329469
epoch: 724, train precision: 0.968333, train loss: 19.750305, valid precision: 0.849600, valid loss: 88.394673
epoch: 725, train precision: 0.967800, train loss: 19.580316, valid precision: 0.850000, valid loss: 94.295920
epoch: 726, train precision: 0.967978, train loss: 19.721439, valid precision: 0.846800, valid loss: 94.929420
epoch: 727, train precision: 0.966178, train loss: 20.527706, valid precision: 0.846600, valid loss: 91.309467
epoch: 728, train precision: 0.968800, train loss: 19.493695, valid precision: 0.847000, valid loss: 90.958079
epoch: 729, train precision: 0.971978, train loss: 18.276781, valid precision: 0.851400, valid loss: 89.713270
epoch: 730, train precision: 0.965644, train loss: 20.131195, valid precision: 0.849800, valid loss: 94.717180
epoch: 731, train precision: 0.968311, train loss: 20.030715, valid precision: 0.849000, valid loss: 89.548485
epoch: 732, train precision: 0.967022, train loss: 19.761680, valid precision: 0.848000, valid loss: 94.869966
epoch: 733, train precision: 0.969489, train loss: 19.205969, valid precision: 0.852000, valid loss: 89.476860
epoch: 734, train precision: 0.973133, train loss: 17.636242, valid precision: 0.852600, valid loss: 90.152366
epoch: 735, train precision: 0.967378, train loss: 19.996433, valid precision: 0.847400, valid loss: 89.368930
epoch: 736, train precision: 0.966400, train loss: 20.092888, valid precision: 0.851800, valid loss: 92.394993
epoch: 737, train precision: 0.963333, train loss: 21.935166, valid precision: 0.844400, valid loss: 92.377619
epoch: 738, train precision: 0.968444, train loss: 20.021029, valid precision: 0.852000, valid loss: 92.860912
epoch: 739, train precision: 0.967378, train loss: 19.921722, valid precision: 0.850600, valid loss: 91.480770
epoch: 740, train precision: 0.970711, train loss: 19.216188, valid precision: 0.850200, valid loss: 91.418733
epoch: 741, train precision: 0.971222, train loss: 18.621895, valid precision: 0.851000, valid loss: 92.665331
epoch: 742, train precision: 0.964933, train loss: 20.811444, valid precision: 0.844000, valid loss: 93.876268
epoch: 743, train precision: 0.962467, train loss: 21.629733, valid precision: 0.844800, valid loss: 96.358139
epoch: 744, train precision: 0.968222, train loss: 19.724233, valid precision: 0.849200, valid loss: 88.345285
epoch: 745, train precision: 0.966311, train loss: 20.095181, valid precision: 0.847000, valid loss: 98.967263
epoch: 746, train precision: 0.965089, train loss: 21.316050, valid precision: 0.841600, valid loss: 90.780652
epoch: 747, train precision: 0.967867, train loss: 19.482246, valid precision: 0.850400, valid loss: 98.141849
epoch: 748, train precision: 0.966733, train loss: 20.628645, valid precision: 0.846200, valid loss: 102.699958
epoch: 749, train precision: 0.969778, train loss: 19.035623, valid precision: 0.851600, valid loss: 94.912565
epoch: 750, train precision: 0.964867, train loss: 20.986123, valid precision: 0.850200, valid loss: 90.388291
epoch: 751, train precision: 0.967400, train loss: 20.378186, valid precision: 0.854000, valid loss: 83.214349
epoch: 752, train precision: 0.968133, train loss: 19.587532, valid precision: 0.850000, valid loss: 90.890089
epoch: 753, train precision: 0.961200, train loss: 21.548276, valid precision: 0.842000, valid loss: 93.311418
epoch: 754, train precision: 0.967044, train loss: 19.907828, valid precision: 0.850200, valid loss: 95.006484
epoch: 755, train precision: 0.969111, train loss: 19.418730, valid precision: 0.854400, valid loss: 93.866330
epoch: 756, train precision: 0.970400, train loss: 19.257517, valid precision: 0.846800, valid loss: 100.396141
epoch: 757, train precision: 0.971822, train loss: 18.660519, valid precision: 0.854200, valid loss: 84.861741
epoch: 758, train precision: 0.965711, train loss: 20.408136, valid precision: 0.852000, valid loss: 97.144656
epoch: 759, train precision: 0.968133, train loss: 20.039565, valid precision: 0.857200, valid loss: 94.289279
epoch: 760, train precision: 0.966556, train loss: 20.017552, valid precision: 0.850400, valid loss: 92.195766
epoch: 761, train precision: 0.966889, train loss: 20.009376, valid precision: 0.846600, valid loss: 96.330579
epoch: 762, train precision: 0.964444, train loss: 21.378582, valid precision: 0.842800, valid loss: 95.157521
epoch: 763, train precision: 0.969356, train loss: 19.902828, valid precision: 0.844200, valid loss: 90.884853
epoch: 764, train precision: 0.965311, train loss: 20.593815, valid precision: 0.845400, valid loss: 96.831917
epoch: 765, train precision: 0.970333, train loss: 18.738091, valid precision: 0.849000, valid loss: 97.724634
epoch: 766, train precision: 0.971000, train loss: 18.646311, valid precision: 0.850800, valid loss: 91.325925
epoch: 767, train precision: 0.967222, train loss: 19.920387, valid precision: 0.848400, valid loss: 92.722398
epoch: 768, train precision: 0.968067, train loss: 19.718740, valid precision: 0.845800, valid loss: 97.748897
epoch: 769, train precision: 0.966422, train loss: 20.529739, valid precision: 0.848200, valid loss: 99.471343
epoch: 770, train precision: 0.969356, train loss: 19.390815, valid precision: 0.848400, valid loss: 91.162014
epoch: 771, train precision: 0.968689, train loss: 19.397864, valid precision: 0.847400, valid loss: 93.172469
epoch: 772, train precision: 0.967800, train loss: 19.875293, valid precision: 0.854200, valid loss: 89.136160
epoch: 773, train precision: 0.970267, train loss: 19.261117, valid precision: 0.850000, valid loss: 88.875787
epoch: 774, train precision: 0.971133, train loss: 18.939319, valid precision: 0.849800, valid loss: 95.607778
epoch: 775, train precision: 0.969089, train loss: 19.597082, valid precision: 0.854600, valid loss: 89.579548
epoch: 776, train precision: 0.968400, train loss: 19.712222, valid precision: 0.848800, valid loss: 92.635045
epoch: 777, train precision: 0.964022, train loss: 21.794530, valid precision: 0.849400, valid loss: 90.374066
epoch: 778, train precision: 0.967622, train loss: 19.547709, valid precision: 0.848200, valid loss: 96.722960
epoch: 779, train precision: 0.966267, train loss: 20.582907, valid precision: 0.846800, valid loss: 99.588955
epoch: 780, train precision: 0.967644, train loss: 20.291791, valid precision: 0.848800, valid loss: 89.741951
epoch: 781, train precision: 0.967733, train loss: 19.682464, valid precision: 0.854800, valid loss: 87.122495
epoch: 782, train precision: 0.968733, train loss: 20.115045, valid precision: 0.843400, valid loss: 91.447800
epoch: 783, train precision: 0.971711, train loss: 18.337946, valid precision: 0.851400, valid loss: 97.555003
epoch: 784, train precision: 0.973133, train loss: 18.366547, valid precision: 0.852000, valid loss: 91.523614
epoch: 785, train precision: 0.969956, train loss: 19.747896, valid precision: 0.847000, valid loss: 96.136852
epoch: 786, train precision: 0.967067, train loss: 20.266846, valid precision: 0.852000, valid loss: 95.830696
epoch: 787, train precision: 0.970756, train loss: 18.759680, valid precision: 0.852000, valid loss: 90.771428
epoch: 788, train precision: 0.968111, train loss: 19.925908, valid precision: 0.850000, valid loss: 89.271082
epoch: 789, train precision: 0.967467, train loss: 20.541790, valid precision: 0.849400, valid loss: 89.459101
epoch: 790, train precision: 0.968889, train loss: 19.461504, valid precision: 0.849200, valid loss: 94.202249
epoch: 791, train precision: 0.963600, train loss: 22.242451, valid precision: 0.841600, valid loss: 96.212276
epoch: 792, train precision: 0.968422, train loss: 20.250015, valid precision: 0.850200, valid loss: 86.186625
epoch: 793, train precision: 0.961600, train loss: 22.493796, valid precision: 0.847400, valid loss: 86.143189
epoch: 794, train precision: 0.964667, train loss: 21.703202, valid precision: 0.849400, valid loss: 91.722157
epoch: 795, train precision: 0.968222, train loss: 20.033920, valid precision: 0.855200, valid loss: 93.956970
epoch: 796, train precision: 0.966622, train loss: 20.472217, valid precision: 0.850000, valid loss: 94.325592
epoch: 797, train precision: 0.969489, train loss: 19.042248, valid precision: 0.852400, valid loss: 89.894356
epoch: 798, train precision: 0.968956, train loss: 19.237493, valid precision: 0.855800, valid loss: 87.960483
epoch: 799, train precision: 0.967089, train loss: 19.784459, valid precision: 0.846600, valid loss: 94.227013
epoch: 800, train precision: 0.969422, train loss: 19.458591, valid precision: 0.850200, valid loss: 88.869781
epoch: 801, train precision: 0.964733, train loss: 21.098243, valid precision: 0.844000, valid loss: 93.415756
epoch: 802, train precision: 0.964933, train loss: 20.809024, valid precision: 0.852400, valid loss: 96.676314
epoch: 803, train precision: 0.968889, train loss: 19.720621, valid precision: 0.848000, valid loss: 90.427583
epoch: 804, train precision: 0.968889, train loss: 19.810598, valid precision: 0.851400, valid loss: 97.944711
epoch: 805, train precision: 0.964067, train loss: 21.951111, valid precision: 0.846400, valid loss: 91.620824
epoch: 806, train precision: 0.969156, train loss: 19.875884, valid precision: 0.848000, valid loss: 91.327484
epoch: 807, train precision: 0.970400, train loss: 19.469358, valid precision: 0.850800, valid loss: 87.451013
epoch: 808, train precision: 0.968156, train loss: 20.051018, valid precision: 0.845600, valid loss: 92.223837
epoch: 809, train precision: 0.971578, train loss: 18.439501, valid precision: 0.850200, valid loss: 96.045902
epoch: 810, train precision: 0.970133, train loss: 19.356120, valid precision: 0.852200, valid loss: 88.586128
epoch: 811, train precision: 0.966489, train loss: 21.060713, valid precision: 0.848200, valid loss: 89.956580
epoch: 812, train precision: 0.968933, train loss: 19.857891, valid precision: 0.850800, valid loss: 95.697422
epoch: 813, train precision: 0.967844, train loss: 20.295363, valid precision: 0.845200, valid loss: 96.397558
epoch: 814, train precision: 0.962778, train loss: 22.400383, valid precision: 0.852200, valid loss: 98.082224
epoch: 815, train precision: 0.968467, train loss: 20.268582, valid precision: 0.852200, valid loss: 86.625678
epoch: 816, train precision: 0.969044, train loss: 19.622526, valid precision: 0.850800, valid loss: 90.133999
epoch: 817, train precision: 0.971067, train loss: 19.163071, valid precision: 0.851800, valid loss: 90.358858
epoch: 818, train precision: 0.967889, train loss: 20.044424, valid precision: 0.844600, valid loss: 94.339801
epoch: 819, train precision: 0.970044, train loss: 19.463185, valid precision: 0.852200, valid loss: 94.310547
epoch: 820, train precision: 0.968089, train loss: 20.072326, valid precision: 0.852200, valid loss: 91.560680
epoch: 821, train precision: 0.970044, train loss: 19.484110, valid precision: 0.849000, valid loss: 97.673608
epoch: 822, train precision: 0.964733, train loss: 21.127556, valid precision: 0.855800, valid loss: 92.228058
epoch: 823, train precision: 0.964267, train loss: 21.600377, valid precision: 0.847000, valid loss: 95.476812
epoch: 824, train precision: 0.966156, train loss: 20.990710, valid precision: 0.848800, valid loss: 94.072477
epoch: 825, train precision: 0.965022, train loss: 21.095036, valid precision: 0.849200, valid loss: 96.661235
epoch: 826, train precision: 0.968578, train loss: 19.824828, valid precision: 0.849000, valid loss: 94.474459
epoch: 827, train precision: 0.964822, train loss: 21.352770, valid precision: 0.849400, valid loss: 91.740723
epoch: 828, train precision: 0.954467, train loss: 25.461894, valid precision: 0.839200, valid loss: 99.805294
epoch: 829, train precision: 0.966644, train loss: 20.753899, valid precision: 0.847000, valid loss: 93.961573
epoch: 830, train precision: 0.971933, train loss: 18.945110, valid precision: 0.855400, valid loss: 88.335821
epoch: 831, train precision: 0.964289, train loss: 21.779407, valid precision: 0.849600, valid loss: 96.311715
epoch: 832, train precision: 0.963067, train loss: 21.987816, valid precision: 0.843400, valid loss: 97.100274
epoch: 833, train precision: 0.967311, train loss: 20.264212, valid precision: 0.844000, valid loss: 96.661317
epoch: 834, train precision: 0.966156, train loss: 20.688939, valid precision: 0.849000, valid loss: 94.563350
epoch: 835, train precision: 0.965000, train loss: 21.029910, valid precision: 0.846400, valid loss: 95.883795
epoch: 836, train precision: 0.969378, train loss: 19.530842, valid precision: 0.848400, valid loss: 93.074813
epoch: 837, train precision: 0.969978, train loss: 19.410668, valid precision: 0.858400, valid loss: 95.974225
epoch: 838, train precision: 0.961822, train loss: 22.642105, valid precision: 0.851200, valid loss: 90.318749
epoch: 839, train precision: 0.969578, train loss: 19.377607, valid precision: 0.849000, valid loss: 94.325536
epoch: 840, train precision: 0.968467, train loss: 19.853266, valid precision: 0.853000, valid loss: 91.402164
epoch: 841, train precision: 0.966911, train loss: 20.792722, valid precision: 0.844800, valid loss: 90.292064
epoch: 842, train precision: 0.966378, train loss: 21.053628, valid precision: 0.843800, valid loss: 94.354532
epoch: 843, train precision: 0.965156, train loss: 21.485006, valid precision: 0.840600, valid loss: 95.442671
epoch: 844, train precision: 0.964889, train loss: 21.394349, valid precision: 0.841400, valid loss: 91.943092
epoch: 845, train precision: 0.968378, train loss: 19.709228, valid precision: 0.852600, valid loss: 93.603470
epoch: 846, train precision: 0.964000, train loss: 22.038038, valid precision: 0.846400, valid loss: 94.118374
epoch: 847, train precision: 0.968867, train loss: 19.589953, valid precision: 0.850200, valid loss: 96.459418
epoch: 848, train precision: 0.966667, train loss: 20.393358, valid precision: 0.847400, valid loss: 99.348481
epoch: 849, train precision: 0.968978, train loss: 19.609677, valid precision: 0.847200, valid loss: 96.363931
epoch: 850, train precision: 0.971289, train loss: 19.222277, valid precision: 0.850000, valid loss: 87.119416
epoch: 851, train precision: 0.962667, train loss: 21.822340, valid precision: 0.849200, valid loss: 90.181977
epoch: 852, train precision: 0.970089, train loss: 19.748359, valid precision: 0.853600, valid loss: 92.805528
epoch: 853, train precision: 0.969156, train loss: 20.473329, valid precision: 0.850400, valid loss: 86.205077
epoch: 854, train precision: 0.970844, train loss: 19.104026, valid precision: 0.853200, valid loss: 96.915186
epoch: 855, train precision: 0.968600, train loss: 20.094432, valid precision: 0.849000, valid loss: 92.461897
epoch: 856, train precision: 0.967978, train loss: 20.041467, valid precision: 0.848600, valid loss: 89.287377
epoch: 857, train precision: 0.970933, train loss: 19.506553, valid precision: 0.849000, valid loss: 89.566625
epoch: 858, train precision: 0.970156, train loss: 19.393683, valid precision: 0.854400, valid loss: 93.937016
epoch: 859, train precision: 0.967711, train loss: 20.258629, valid precision: 0.849600, valid loss: 100.645720
epoch: 860, train precision: 0.972422, train loss: 18.583496, valid precision: 0.855400, valid loss: 89.369960
epoch: 861, train precision: 0.971067, train loss: 18.903640, valid precision: 0.854200, valid loss: 92.562434
epoch: 862, train precision: 0.967800, train loss: 20.296486, valid precision: 0.849000, valid loss: 93.108653
epoch: 863, train precision: 0.957000, train loss: 24.399013, valid precision: 0.839400, valid loss: 93.308694
epoch: 864, train precision: 0.964244, train loss: 21.887705, valid precision: 0.843200, valid loss: 97.960009
epoch: 865, train precision: 0.972667, train loss: 18.759325, valid precision: 0.852400, valid loss: 92.068069
epoch: 866, train precision: 0.966933, train loss: 20.772122, valid precision: 0.854400, valid loss: 90.352319
epoch: 867, train precision: 0.968889, train loss: 20.242686, valid precision: 0.851000, valid loss: 90.698868
epoch: 868, train precision: 0.971911, train loss: 19.044916, valid precision: 0.851200, valid loss: 92.817018
epoch: 869, train precision: 0.970778, train loss: 19.573860, valid precision: 0.853800, valid loss: 91.375090
epoch: 870, train precision: 0.972022, train loss: 18.927624, valid precision: 0.856000, valid loss: 91.249203
epoch: 871, train precision: 0.969000, train loss: 19.934613, valid precision: 0.848800, valid loss: 94.836838
epoch: 872, train precision: 0.961444, train loss: 23.203418, valid precision: 0.842400, valid loss: 103.856583
epoch: 873, train precision: 0.973667, train loss: 18.329412, valid precision: 0.851200, valid loss: 94.975573
epoch: 874, train precision: 0.969044, train loss: 19.649267, valid precision: 0.849400, valid loss: 95.324368
epoch: 875, train precision: 0.972778, train loss: 17.979878, valid precision: 0.853400, valid loss: 99.942083
epoch: 876, train precision: 0.966778, train loss: 21.169412, valid precision: 0.846400, valid loss: 97.187942
epoch: 877, train precision: 0.968444, train loss: 19.516182, valid precision: 0.855000, valid loss: 98.451191
epoch: 878, train precision: 0.967178, train loss: 20.902534, valid precision: 0.852600, valid loss: 93.467809
epoch: 879, train precision: 0.966044, train loss: 21.082900, valid precision: 0.851800, valid loss: 100.478359
epoch: 880, train precision: 0.970111, train loss: 19.416286, valid precision: 0.847200, valid loss: 96.870208
epoch: 881, train precision: 0.966511, train loss: 21.570355, valid precision: 0.844200, valid loss: 91.899094
epoch: 882, train precision: 0.968778, train loss: 19.447981, valid precision: 0.850600, valid loss: 96.664670
epoch: 883, train precision: 0.973489, train loss: 18.300295, valid precision: 0.850800, valid loss: 96.283271
epoch: 884, train precision: 0.973244, train loss: 18.146380, valid precision: 0.854000, valid loss: 97.415420
epoch: 885, train precision: 0.965711, train loss: 21.131251, valid precision: 0.845800, valid loss: 103.071606
epoch: 886, train precision: 0.967511, train loss: 20.401300, valid precision: 0.854200, valid loss: 97.654791
epoch: 887, train precision: 0.970022, train loss: 20.083888, valid precision: 0.848200, valid loss: 92.770725
epoch: 888, train precision: 0.968600, train loss: 20.274726, valid precision: 0.853800, valid loss: 90.940335
epoch: 889, train precision: 0.969911, train loss: 19.825901, valid precision: 0.847200, valid loss: 95.326467
epoch: 890, train precision: 0.970044, train loss: 19.868436, valid precision: 0.850800, valid loss: 90.942399
epoch: 891, train precision: 0.972244, train loss: 18.700104, valid precision: 0.847400, valid loss: 95.459502
epoch: 892, train precision: 0.969578, train loss: 20.502729, valid precision: 0.848400, valid loss: 94.541265
epoch: 893, train precision: 0.970644, train loss: 19.754979, valid precision: 0.847800, valid loss: 95.804797
epoch: 894, train precision: 0.972000, train loss: 19.168454, valid precision: 0.845200, valid loss: 95.050291
epoch: 895, train precision: 0.971000, train loss: 19.449783, valid precision: 0.853200, valid loss: 96.165594
epoch: 896, train precision: 0.967933, train loss: 20.677086, valid precision: 0.850200, valid loss: 93.540522
epoch: 897, train precision: 0.968911, train loss: 20.005034, valid precision: 0.848800, valid loss: 101.930669
epoch: 898, train precision: 0.971311, train loss: 19.378135, valid precision: 0.851000, valid loss: 92.627288
epoch: 899, train precision: 0.968778, train loss: 20.805052, valid precision: 0.848000, valid loss: 91.466267
epoch: 900, train precision: 0.970756, train loss: 18.880309, valid precision: 0.851200, valid loss: 95.691057
epoch: 901, train precision: 0.964311, train loss: 21.720656, valid precision: 0.844400, valid loss: 101.163224
epoch: 902, train precision: 0.969933, train loss: 20.253317, valid precision: 0.852400, valid loss: 92.103960
epoch: 903, train precision: 0.970622, train loss: 19.230380, valid precision: 0.853000, valid loss: 98.017966
epoch: 904, train precision: 0.967333, train loss: 20.141598, valid precision: 0.849600, valid loss: 98.449989
epoch: 905, train precision: 0.967911, train loss: 20.992011, valid precision: 0.850600, valid loss: 93.012704
epoch: 906, train precision: 0.969667, train loss: 19.461289, valid precision: 0.849200, valid loss: 104.215115
epoch: 907, train precision: 0.965978, train loss: 21.815200, valid precision: 0.848000, valid loss: 99.218064
epoch: 908, train precision: 0.968844, train loss: 20.534430, valid precision: 0.847800, valid loss: 97.025128
epoch: 909, train precision: 0.969556, train loss: 19.989047, valid precision: 0.857000, valid loss: 91.194026
epoch: 910, train precision: 0.965800, train loss: 21.191265, valid precision: 0.852200, valid loss: 90.265322
epoch: 911, train precision: 0.972067, train loss: 19.105500, valid precision: 0.856000, valid loss: 94.305341
epoch: 912, train precision: 0.970200, train loss: 19.433558, valid precision: 0.850800, valid loss: 99.341596
epoch: 913, train precision: 0.968356, train loss: 20.488938, valid precision: 0.843000, valid loss: 97.017606
epoch: 914, train precision: 0.967244, train loss: 21.019013, valid precision: 0.848600, valid loss: 94.188304
epoch: 915, train precision: 0.971467, train loss: 19.277677, valid precision: 0.851800, valid loss: 98.743002
epoch: 916, train precision: 0.966267, train loss: 21.108806, valid precision: 0.851200, valid loss: 100.841892
epoch: 917, train precision: 0.969800, train loss: 19.791982, valid precision: 0.844400, valid loss: 93.252806
epoch: 918, train precision: 0.966089, train loss: 21.247669, valid precision: 0.845200, valid loss: 94.323619
epoch: 919, train precision: 0.967267, train loss: 20.357607, valid precision: 0.846000, valid loss: 95.418455
epoch: 920, train precision: 0.965622, train loss: 20.916837, valid precision: 0.845600, valid loss: 96.257666
epoch: 921, train precision: 0.958200, train loss: 24.174535, valid precision: 0.845000, valid loss: 100.302646
epoch: 922, train precision: 0.971244, train loss: 19.150241, valid precision: 0.854400, valid loss: 95.330174
epoch: 923, train precision: 0.969756, train loss: 19.598155, valid precision: 0.850400, valid loss: 104.485766
epoch: 924, train precision: 0.970022, train loss: 19.347579, valid precision: 0.849600, valid loss: 98.744452
epoch: 925, train precision: 0.970911, train loss: 19.371722, valid precision: 0.846000, valid loss: 90.048511
epoch: 926, train precision: 0.970511, train loss: 19.376953, valid precision: 0.848800, valid loss: 94.549481
epoch: 927, train precision: 0.972089, train loss: 18.787040, valid precision: 0.849200, valid loss: 98.391086
epoch: 928, train precision: 0.966356, train loss: 21.016212, valid precision: 0.851600, valid loss: 97.738583
epoch: 929, train precision: 0.969556, train loss: 19.154152, valid precision: 0.849800, valid loss: 101.756110
epoch: 930, train precision: 0.972978, train loss: 18.308645, valid precision: 0.848600, valid loss: 92.231170
epoch: 931, train precision: 0.968956, train loss: 20.212592, valid precision: 0.850800, valid loss: 92.807431
epoch: 932, train precision: 0.970600, train loss: 19.140113, valid precision: 0.846000, valid loss: 93.354657
epoch: 933, train precision: 0.968511, train loss: 20.578208, valid precision: 0.851600, valid loss: 93.066691
epoch: 934, train precision: 0.961600, train loss: 22.664312, valid precision: 0.843800, valid loss: 95.466105
epoch: 935, train precision: 0.966467, train loss: 20.732660, valid precision: 0.845000, valid loss: 98.348561
epoch: 936, train precision: 0.969800, train loss: 19.715563, valid precision: 0.848200, valid loss: 95.353010
epoch: 937, train precision: 0.969511, train loss: 19.966543, valid precision: 0.853400, valid loss: 95.584682
epoch: 938, train precision: 0.970778, train loss: 19.161371, valid precision: 0.855000, valid loss: 94.187482
epoch: 939, train precision: 0.963000, train loss: 22.429000, valid precision: 0.852600, valid loss: 97.630828
epoch: 940, train precision: 0.970200, train loss: 19.950461, valid precision: 0.851200, valid loss: 93.808626
epoch: 941, train precision: 0.967889, train loss: 20.838822, valid precision: 0.852200, valid loss: 97.471520
epoch: 942, train precision: 0.968111, train loss: 20.280297, valid precision: 0.852600, valid loss: 96.728382
epoch: 943, train precision: 0.965067, train loss: 22.167868, valid precision: 0.847800, valid loss: 94.763416
epoch: 944, train precision: 0.962067, train loss: 22.332872, valid precision: 0.845200, valid loss: 98.311401
epoch: 945, train precision: 0.969800, train loss: 19.836050, valid precision: 0.854000, valid loss: 93.814903
epoch: 946, train precision: 0.963511, train loss: 21.985887, valid precision: 0.850400, valid loss: 93.035442
epoch: 947, train precision: 0.968956, train loss: 19.952015, valid precision: 0.849200, valid loss: 98.023086
epoch: 948, train precision: 0.966156, train loss: 21.005059, valid precision: 0.848800, valid loss: 102.325027
epoch: 949, train precision: 0.964556, train loss: 22.106143, valid precision: 0.847600, valid loss: 98.982266
epoch: 950, train precision: 0.964111, train loss: 22.191978, valid precision: 0.843000, valid loss: 96.062744
epoch: 951, train precision: 0.967778, train loss: 20.234726, valid precision: 0.850400, valid loss: 95.699894
epoch: 952, train precision: 0.968667, train loss: 20.229115, valid precision: 0.846000, valid loss: 103.895333
epoch: 953, train precision: 0.967044, train loss: 20.897234, valid precision: 0.848200, valid loss: 93.081944
epoch: 954, train precision: 0.962400, train loss: 22.535073, valid precision: 0.847600, valid loss: 94.431165
epoch: 955, train precision: 0.969556, train loss: 19.729297, valid precision: 0.848400, valid loss: 96.585394
epoch: 956, train precision: 0.971089, train loss: 19.179094, valid precision: 0.857400, valid loss: 93.236687
epoch: 957, train precision: 0.969400, train loss: 19.351611, valid precision: 0.846200, valid loss: 101.172981
epoch: 958, train precision: 0.970111, train loss: 19.811370, valid precision: 0.852000, valid loss: 97.466499
epoch: 959, train precision: 0.971889, train loss: 18.806220, valid precision: 0.853000, valid loss: 104.741217
epoch: 960, train precision: 0.972667, train loss: 18.697900, valid precision: 0.854800, valid loss: 97.077113
epoch: 961, train precision: 0.968311, train loss: 20.516719, valid precision: 0.848800, valid loss: 97.679558
epoch: 962, train precision: 0.969000, train loss: 20.226096, valid precision: 0.847000, valid loss: 98.588733
epoch: 963, train precision: 0.964844, train loss: 22.180471, valid precision: 0.848800, valid loss: 97.334741
epoch: 964, train precision: 0.966911, train loss: 21.091279, valid precision: 0.847600, valid loss: 96.348398
epoch: 965, train precision: 0.960711, train loss: 23.325499, valid precision: 0.846400, valid loss: 98.437453
epoch: 966, train precision: 0.968044, train loss: 20.498662, valid precision: 0.856000, valid loss: 97.693157
epoch: 967, train precision: 0.965911, train loss: 21.600219, valid precision: 0.846000, valid loss: 98.342742
epoch: 968, train precision: 0.967356, train loss: 21.092913, valid precision: 0.850200, valid loss: 95.338577
epoch: 969, train precision: 0.970556, train loss: 19.718021, valid precision: 0.854400, valid loss: 99.921658
epoch: 970, train precision: 0.956022, train loss: 24.749592, valid precision: 0.844400, valid loss: 104.070077
epoch: 971, train precision: 0.967000, train loss: 20.474650, valid precision: 0.847600, valid loss: 101.713089
epoch: 972, train precision: 0.966644, train loss: 20.991871, valid precision: 0.846000, valid loss: 102.143494
epoch: 973, train precision: 0.967844, train loss: 20.693159, valid precision: 0.848800, valid loss: 98.084338
epoch: 974, train precision: 0.966489, train loss: 20.837848, valid precision: 0.843600, valid loss: 99.298191
epoch: 975, train precision: 0.969511, train loss: 19.676912, valid precision: 0.849800, valid loss: 97.522863
epoch: 976, train precision: 0.970044, train loss: 19.872395, valid precision: 0.856200, valid loss: 90.821785
epoch: 977, train precision: 0.966711, train loss: 21.010211, valid precision: 0.852000, valid loss: 99.588004
epoch: 978, train precision: 0.968378, train loss: 19.920582, valid precision: 0.849000, valid loss: 105.138965
epoch: 979, train precision: 0.964422, train loss: 21.547013, valid precision: 0.847800, valid loss: 95.194482
epoch: 980, train precision: 0.970844, train loss: 19.704929, valid precision: 0.858000, valid loss: 92.293953
epoch: 981, train precision: 0.971089, train loss: 19.761812, valid precision: 0.857000, valid loss: 87.343920
epoch: 982, train precision: 0.973733, train loss: 18.357816, valid precision: 0.851000, valid loss: 93.240454
epoch: 983, train precision: 0.963867, train loss: 21.871918, valid precision: 0.849000, valid loss: 106.995294
epoch: 984, train precision: 0.968111, train loss: 20.307770, valid precision: 0.853800, valid loss: 91.552086
epoch: 985, train precision: 0.963178, train loss: 22.352651, valid precision: 0.845000, valid loss: 97.227751
epoch: 986, train precision: 0.967867, train loss: 20.585763, valid precision: 0.845600, valid loss: 95.424408
epoch: 987, train precision: 0.965844, train loss: 21.738185, valid precision: 0.845800, valid loss: 92.218967
epoch: 988, train precision: 0.962489, train loss: 23.139022, valid precision: 0.852400, valid loss: 96.622821
epoch: 989, train precision: 0.966267, train loss: 20.861238, valid precision: 0.849600, valid loss: 100.101357
epoch: 990, train precision: 0.962111, train loss: 22.886208, valid precision: 0.845200, valid loss: 95.586429
epoch: 991, train precision: 0.970889, train loss: 19.516438, valid precision: 0.853800, valid loss: 95.555918
epoch: 992, train precision: 0.968711, train loss: 20.023495, valid precision: 0.854200, valid loss: 97.892240
epoch: 993, train precision: 0.964933, train loss: 21.669202, valid precision: 0.842400, valid loss: 96.798665
epoch: 994, train precision: 0.969933, train loss: 19.626552, valid precision: 0.849800, valid loss: 95.679477
epoch: 995, train precision: 0.971000, train loss: 19.272494, valid precision: 0.845800, valid loss: 97.717312
epoch: 996, train precision: 0.966978, train loss: 20.743405, valid precision: 0.854000, valid loss: 92.003625
epoch: 997, train precision: 0.967711, train loss: 20.969650, valid precision: 0.846000, valid loss: 93.192472
epoch: 998, train precision: 0.966444, train loss: 21.034047, valid precision: 0.848200, valid loss: 94.686295
epoch: 999, train precision: 0.965000, train loss: 21.463876, valid precision: 0.853400, valid loss: 100.211145
epoch: 1000, train precision: 0.965111, train loss: 21.550247, valid precision: 0.844400, valid loss: 93.892220
epoch: 1001, train precision: 0.959600, train loss: 23.209514, valid precision: 0.843200, valid loss: 95.587664
epoch: 1002, train precision: 0.967822, train loss: 21.268334, valid precision: 0.852200, valid loss: 91.931581
epoch: 1003, train precision: 0.971133, train loss: 19.205736, valid precision: 0.847600, valid loss: 101.248245
epoch: 1004, train precision: 0.967289, train loss: 21.240797, valid precision: 0.849200, valid loss: 97.777540
epoch: 1005, train precision: 0.966089, train loss: 20.759475, valid precision: 0.848400, valid loss: 99.417905
epoch: 1006, train precision: 0.966200, train loss: 20.720439, valid precision: 0.846400, valid loss: 102.472421
epoch: 1007, train precision: 0.969711, train loss: 19.709168, valid precision: 0.852200, valid loss: 93.332655
epoch: 1008, train precision: 0.968778, train loss: 20.491240, valid precision: 0.854600, valid loss: 93.815352
epoch: 1009, train precision: 0.968889, train loss: 20.731939, valid precision: 0.845600, valid loss: 95.976885
epoch: 1010, train precision: 0.968156, train loss: 20.757358, valid precision: 0.850000, valid loss: 95.039462
epoch: 1011, train precision: 0.968289, train loss: 20.611933, valid precision: 0.848000, valid loss: 102.577360
epoch: 1012, train precision: 0.968933, train loss: 19.990337, valid precision: 0.846800, valid loss: 103.055907
epoch: 1013, train precision: 0.966667, train loss: 20.925199, valid precision: 0.847400, valid loss: 92.480438
epoch: 1014, train precision: 0.963800, train loss: 22.325647, valid precision: 0.849200, valid loss: 99.445106
epoch: 1015, train precision: 0.967822, train loss: 20.724755, valid precision: 0.851400, valid loss: 93.851925
epoch: 1016, train precision: 0.967289, train loss: 20.484299, valid precision: 0.847000, valid loss: 96.971671
epoch: 1017, train precision: 0.968733, train loss: 20.091678, valid precision: 0.852000, valid loss: 99.361998
epoch: 1018, train precision: 0.969911, train loss: 20.092079, valid precision: 0.851400, valid loss: 96.759842
epoch: 1019, train precision: 0.967867, train loss: 20.616597, valid precision: 0.850000, valid loss: 98.603013
epoch: 1020, train precision: 0.969378, train loss: 20.194759, valid precision: 0.848200, valid loss: 101.481275
epoch: 1021, train precision: 0.967022, train loss: 21.254432, valid precision: 0.845800, valid loss: 104.062901
epoch: 1022, train precision: 0.964956, train loss: 21.874344, valid precision: 0.851400, valid loss: 98.722741
epoch: 1023, train precision: 0.963022, train loss: 22.459201, valid precision: 0.844400, valid loss: 96.548685
epoch: 1024, train precision: 0.973489, train loss: 18.491376, valid precision: 0.851800, valid loss: 99.862163
epoch: 1025, train precision: 0.971022, train loss: 19.358422, valid precision: 0.852400, valid loss: 95.620709
epoch: 1026, train precision: 0.971978, train loss: 18.794606, valid precision: 0.851800, valid loss: 94.090736
epoch: 1027, train precision: 0.956133, train loss: 25.194772, valid precision: 0.847000, valid loss: 104.664232
epoch: 1028, train precision: 0.966067, train loss: 21.484455, valid precision: 0.850000, valid loss: 100.610143
epoch: 1029, train precision: 0.966467, train loss: 21.002508, valid precision: 0.852200, valid loss: 95.217741
epoch: 1030, train precision: 0.968622, train loss: 20.226197, valid precision: 0.848200, valid loss: 94.668929
epoch: 1031, train precision: 0.971889, train loss: 19.655742, valid precision: 0.851200, valid loss: 91.323388
epoch: 1032, train precision: 0.974667, train loss: 17.909931, valid precision: 0.846200, valid loss: 104.544356
epoch: 1033, train precision: 0.969911, train loss: 20.133817, valid precision: 0.851600, valid loss: 98.759152
epoch: 1034, train precision: 0.967978, train loss: 20.139732, valid precision: 0.843600, valid loss: 99.540163
epoch: 1035, train precision: 0.967489, train loss: 21.161636, valid precision: 0.846600, valid loss: 100.441779
epoch: 1036, train precision: 0.969089, train loss: 20.176653, valid precision: 0.848400, valid loss: 104.484404
epoch: 1037, train precision: 0.969111, train loss: 20.606589, valid precision: 0.852600, valid loss: 95.882029
epoch: 1038, train precision: 0.966956, train loss: 21.142349, valid precision: 0.840400, valid loss: 104.516760
epoch: 1039, train precision: 0.969044, train loss: 20.416896, valid precision: 0.848200, valid loss: 98.368008
epoch: 1040, train precision: 0.971933, train loss: 19.355053, valid precision: 0.852200, valid loss: 96.151619
epoch: 1041, train precision: 0.971378, train loss: 19.635302, valid precision: 0.845600, valid loss: 104.680134
epoch: 1042, train precision: 0.966533, train loss: 20.906581, valid precision: 0.848400, valid loss: 98.776758
epoch: 1043, train precision: 0.972822, train loss: 18.799708, valid precision: 0.853400, valid loss: 100.998556
epoch: 1044, train precision: 0.966889, train loss: 20.924285, valid precision: 0.849200, valid loss: 106.166754
epoch: 1045, train precision: 0.967622, train loss: 20.766375, valid precision: 0.849800, valid loss: 101.792132
epoch: 1046, train precision: 0.968156, train loss: 20.702072, valid precision: 0.846800, valid loss: 95.251064
epoch: 1047, train precision: 0.968800, train loss: 20.684277, valid precision: 0.850800, valid loss: 92.675565
epoch: 1048, train precision: 0.965733, train loss: 21.887568, valid precision: 0.848800, valid loss: 94.905945
epoch: 1049, train precision: 0.968822, train loss: 20.443531, valid precision: 0.854600, valid loss: 95.657471
epoch: 1050, train precision: 0.966022, train loss: 21.247020, valid precision: 0.848400, valid loss: 101.501282
epoch: 1051, train precision: 0.968911, train loss: 20.658158, valid precision: 0.844400, valid loss: 100.063704
epoch: 1052, train precision: 0.967444, train loss: 20.808186, valid precision: 0.843400, valid loss: 104.263337
epoch: 1053, train precision: 0.971422, train loss: 19.717569, valid precision: 0.845800, valid loss: 108.857946
epoch: 1054, train precision: 0.967289, train loss: 21.560840, valid precision: 0.846600, valid loss: 99.093597
epoch: 1055, train precision: 0.967978, train loss: 20.048732, valid precision: 0.845600, valid loss: 109.239226
epoch: 1056, train precision: 0.971222, train loss: 19.804570, valid precision: 0.851000, valid loss: 101.651830
epoch: 1057, train precision: 0.970067, train loss: 20.326303, valid precision: 0.847400, valid loss: 98.881607
epoch: 1058, train precision: 0.970044, train loss: 19.378596, valid precision: 0.849400, valid loss: 102.789739
epoch: 1059, train precision: 0.968156, train loss: 20.499814, valid precision: 0.848400, valid loss: 99.936094
epoch: 1060, train precision: 0.965800, train loss: 21.419965, valid precision: 0.849000, valid loss: 103.315980
epoch: 1061, train precision: 0.971333, train loss: 19.301474, valid precision: 0.854400, valid loss: 99.917576
epoch: 1062, train precision: 0.966067, train loss: 22.123973, valid precision: 0.847200, valid loss: 97.813734
epoch: 1063, train precision: 0.972489, train loss: 19.144851, valid precision: 0.852800, valid loss: 102.056865
epoch: 1064, train precision: 0.967267, train loss: 20.644481, valid precision: 0.853600, valid loss: 104.037490
epoch: 1065, train precision: 0.970067, train loss: 20.162624, valid precision: 0.853200, valid loss: 96.402417
epoch: 1066, train precision: 0.968200, train loss: 20.528454, valid precision: 0.842600, valid loss: 100.933050
epoch: 1067, train precision: 0.961311, train loss: 23.346531, valid precision: 0.841400, valid loss: 98.257234
epoch: 1068, train precision: 0.967222, train loss: 21.637614, valid precision: 0.844000, valid loss: 94.879756
epoch: 1069, train precision: 0.966356, train loss: 21.322037, valid precision: 0.844600, valid loss: 98.113550
epoch: 1070, train precision: 0.970444, train loss: 19.936507, valid precision: 0.848200, valid loss: 99.939642
epoch: 1071, train precision: 0.970267, train loss: 19.678326, valid precision: 0.852200, valid loss: 103.584674
epoch: 1072, train precision: 0.968378, train loss: 20.385160, valid precision: 0.854400, valid loss: 98.076906
epoch: 1073, train precision: 0.965911, train loss: 21.523796, valid precision: 0.850000, valid loss: 102.237162
epoch: 1074, train precision: 0.968778, train loss: 20.114568, valid precision: 0.850800, valid loss: 101.768497
epoch: 1075, train precision: 0.961711, train loss: 22.801848, valid precision: 0.845000, valid loss: 94.583541
epoch: 1076, train precision: 0.968444, train loss: 20.736411, valid precision: 0.851200, valid loss: 93.429883
epoch: 1077, train precision: 0.968689, train loss: 20.833868, valid precision: 0.850200, valid loss: 97.468589
epoch: 1078, train precision: 0.966978, train loss: 20.939223, valid precision: 0.854400, valid loss: 97.186215
epoch: 1079, train precision: 0.965333, train loss: 21.702906, valid precision: 0.847200, valid loss: 103.048655
epoch: 1080, train precision: 0.967089, train loss: 21.124513, valid precision: 0.852800, valid loss: 103.659558
epoch: 1081, train precision: 0.961067, train loss: 23.468672, valid precision: 0.843600, valid loss: 100.741877
epoch: 1082, train precision: 0.969711, train loss: 20.353597, valid precision: 0.847800, valid loss: 95.890284
epoch: 1083, train precision: 0.968667, train loss: 20.404738, valid precision: 0.852800, valid loss: 100.474301
epoch: 1084, train precision: 0.966800, train loss: 21.348701, valid precision: 0.850800, valid loss: 102.095364
epoch: 1085, train precision: 0.971489, train loss: 19.897847, valid precision: 0.850000, valid loss: 108.083040
epoch: 1086, train precision: 0.963956, train loss: 22.719008, valid precision: 0.850400, valid loss: 100.209868
epoch: 1087, train precision: 0.968978, train loss: 19.950455, valid precision: 0.850400, valid loss: 108.950189
epoch: 1088, train precision: 0.966378, train loss: 21.200126, valid precision: 0.843600, valid loss: 105.070153
epoch: 1089, train precision: 0.965978, train loss: 22.006184, valid precision: 0.846600, valid loss: 99.980325
epoch: 1090, train precision: 0.966311, train loss: 21.560335, valid precision: 0.850200, valid loss: 93.412823
epoch: 1091, train precision: 0.967067, train loss: 21.591638, valid precision: 0.852200, valid loss: 96.608291
epoch: 1092, train precision: 0.961933, train loss: 23.106263, valid precision: 0.849400, valid loss: 94.800008
epoch: 1093, train precision: 0.970178, train loss: 20.104938, valid precision: 0.851200, valid loss: 101.403699
epoch: 1094, train precision: 0.969378, train loss: 19.861586, valid precision: 0.852800, valid loss: 101.572334
epoch: 1095, train precision: 0.969111, train loss: 20.251618, valid precision: 0.848000, valid loss: 93.792145
epoch: 1096, train precision: 0.967844, train loss: 20.542005, valid precision: 0.852000, valid loss: 107.794440
epoch: 1097, train precision: 0.970978, train loss: 19.656416, valid precision: 0.851600, valid loss: 94.496560
epoch: 1098, train precision: 0.967378, train loss: 21.320902, valid precision: 0.844600, valid loss: 96.343870
epoch: 1099, train precision: 0.968489, train loss: 20.582513, valid precision: 0.847600, valid loss: 103.951164
epoch: 1100, train precision: 0.966822, train loss: 21.277194, valid precision: 0.851200, valid loss: 111.618964
epoch: 1101, train precision: 0.970733, train loss: 20.267901, valid precision: 0.852600, valid loss: 94.632931
epoch: 1102, train precision: 0.971044, train loss: 19.872900, valid precision: 0.850800, valid loss: 97.687327
epoch: 1103, train precision: 0.971867, train loss: 19.340283, valid precision: 0.852400, valid loss: 101.439053
epoch: 1104, train precision: 0.968156, train loss: 20.892913, valid precision: 0.846200, valid loss: 103.132571
epoch: 1105, train precision: 0.967444, train loss: 21.199189, valid precision: 0.845800, valid loss: 102.095359
epoch: 1106, train precision: 0.969044, train loss: 20.565121, valid precision: 0.847200, valid loss: 104.463796
epoch: 1107, train precision: 0.969067, train loss: 20.515028, valid precision: 0.844200, valid loss: 102.558864
epoch: 1108, train precision: 0.970400, train loss: 20.804021, valid precision: 0.847800, valid loss: 95.747598
epoch: 1109, train precision: 0.964356, train loss: 22.372048, valid precision: 0.849000, valid loss: 97.253758
epoch: 1110, train precision: 0.963467, train loss: 22.342509, valid precision: 0.844000, valid loss: 103.553978
epoch: 1111, train precision: 0.967422, train loss: 21.162988, valid precision: 0.851400, valid loss: 103.882967
epoch: 1112, train precision: 0.969400, train loss: 20.613716, valid precision: 0.855800, valid loss: 93.971548
epoch: 1113, train precision: 0.967133, train loss: 21.295788, valid precision: 0.846600, valid loss: 99.131063
epoch: 1114, train precision: 0.968422, train loss: 20.591030, valid precision: 0.850400, valid loss: 93.544478
epoch: 1115, train precision: 0.967444, train loss: 21.118296, valid precision: 0.852200, valid loss: 94.315119
epoch: 1116, train precision: 0.966556, train loss: 21.100563, valid precision: 0.849600, valid loss: 101.298339
epoch: 1117, train precision: 0.970667, train loss: 19.627103, valid precision: 0.851800, valid loss: 99.447227
epoch: 1118, train precision: 0.969333, train loss: 20.286146, valid precision: 0.852400, valid loss: 105.408359
epoch: 1119, train precision: 0.970378, train loss: 19.281967, valid precision: 0.849400, valid loss: 104.042026
epoch: 1120, train precision: 0.969044, train loss: 20.151491, valid precision: 0.852200, valid loss: 103.007318
epoch: 1121, train precision: 0.969867, train loss: 20.372419, valid precision: 0.851200, valid loss: 97.145287
epoch: 1122, train precision: 0.965822, train loss: 21.412109, valid precision: 0.844000, valid loss: 99.497196
epoch: 1123, train precision: 0.971956, train loss: 19.494305, valid precision: 0.847000, valid loss: 101.156932
epoch: 1124, train precision: 0.972467, train loss: 19.710193, valid precision: 0.850600, valid loss: 98.096561
epoch: 1125, train precision: 0.971511, train loss: 19.715649, valid precision: 0.848600, valid loss: 99.353620
epoch: 1126, train precision: 0.962289, train loss: 22.836811, valid precision: 0.848000, valid loss: 102.244547
epoch: 1127, train precision: 0.970933, train loss: 19.715596, valid precision: 0.848200, valid loss: 102.897853
epoch: 1128, train precision: 0.967000, train loss: 21.081947, valid precision: 0.850400, valid loss: 105.287528
epoch: 1129, train precision: 0.966444, train loss: 21.283482, valid precision: 0.850400, valid loss: 97.526891
epoch: 1130, train precision: 0.965422, train loss: 21.930757, valid precision: 0.846000, valid loss: 103.149727
epoch: 1131, train precision: 0.965489, train loss: 21.615001, valid precision: 0.851600, valid loss: 103.701788
epoch: 1132, train precision: 0.965844, train loss: 21.633235, valid precision: 0.846600, valid loss: 102.442677
epoch: 1133, train precision: 0.968200, train loss: 21.098985, valid precision: 0.847200, valid loss: 96.168000
epoch: 1134, train precision: 0.966111, train loss: 21.241261, valid precision: 0.850200, valid loss: 104.416162
epoch: 1135, train precision: 0.967756, train loss: 21.851217, valid precision: 0.844800, valid loss: 97.826630
epoch: 1136, train precision: 0.969533, train loss: 20.430919, valid precision: 0.853400, valid loss: 107.573410
epoch: 1137, train precision: 0.968089, train loss: 21.194597, valid precision: 0.851200, valid loss: 94.509528
epoch: 1138, train precision: 0.963467, train loss: 22.307183, valid precision: 0.850600, valid loss: 99.572720
epoch: 1139, train precision: 0.971000, train loss: 20.013090, valid precision: 0.853400, valid loss: 104.163063
epoch: 1140, train precision: 0.968200, train loss: 20.737727, valid precision: 0.850800, valid loss: 98.988644
epoch: 1141, train precision: 0.967489, train loss: 21.387772, valid precision: 0.850400, valid loss: 100.656141
epoch: 1142, train precision: 0.965800, train loss: 21.354479, valid precision: 0.847600, valid loss: 105.092522
epoch: 1143, train precision: 0.971489, train loss: 19.732840, valid precision: 0.855600, valid loss: 97.777558
epoch: 1144, train precision: 0.969489, train loss: 20.354847, valid precision: 0.851400, valid loss: 105.830244
epoch: 1145, train precision: 0.967067, train loss: 21.663029, valid precision: 0.855000, valid loss: 97.164856
epoch: 1146, train precision: 0.970467, train loss: 20.182036, valid precision: 0.852600, valid loss: 101.118732
epoch: 1147, train precision: 0.969489, train loss: 20.103352, valid precision: 0.848400, valid loss: 106.850110
epoch: 1148, train precision: 0.971622, train loss: 19.340740, valid precision: 0.855000, valid loss: 102.564739
epoch: 1149, train precision: 0.966778, train loss: 21.557935, valid precision: 0.852400, valid loss: 99.174215
epoch: 1150, train precision: 0.957244, train loss: 25.018470, valid precision: 0.841000, valid loss: 100.260249
epoch: 1151, train precision: 0.964844, train loss: 22.170196, valid precision: 0.849800, valid loss: 100.127491
epoch: 1152, train precision: 0.966578, train loss: 21.470917, valid precision: 0.843400, valid loss: 105.442307
epoch: 1153, train precision: 0.967444, train loss: 21.321495, valid precision: 0.846600, valid loss: 100.810931
epoch: 1154, train precision: 0.971000, train loss: 19.695708, valid precision: 0.854000, valid loss: 95.544900
epoch: 1155, train precision: 0.972556, train loss: 19.020671, valid precision: 0.853400, valid loss: 97.264402
epoch: 1156, train precision: 0.969622, train loss: 20.299931, valid precision: 0.853800, valid loss: 99.690104
epoch: 1157, train precision: 0.966400, train loss: 21.611045, valid precision: 0.841800, valid loss: 111.878225
epoch: 1158, train precision: 0.970067, train loss: 20.042329, valid precision: 0.849000, valid loss: 103.571749
epoch: 1159, train precision: 0.968733, train loss: 20.472138, valid precision: 0.850800, valid loss: 99.976320
epoch: 1160, train precision: 0.971333, train loss: 19.529990, valid precision: 0.857400, valid loss: 99.701822
epoch: 1161, train precision: 0.965067, train loss: 21.760927, valid precision: 0.848200, valid loss: 106.125736
epoch: 1162, train precision: 0.965889, train loss: 21.667458, valid precision: 0.851800, valid loss: 103.217254
epoch: 1163, train precision: 0.966711, train loss: 21.872593, valid precision: 0.849800, valid loss: 100.749925
epoch: 1164, train precision: 0.964733, train loss: 22.144612, valid precision: 0.846800, valid loss: 99.301464
epoch: 1165, train precision: 0.971489, train loss: 19.616452, valid precision: 0.851000, valid loss: 100.226821
epoch: 1166, train precision: 0.964822, train loss: 21.868640, valid precision: 0.849600, valid loss: 95.800527
epoch: 1167, train precision: 0.971422, train loss: 19.734670, valid precision: 0.854400, valid loss: 106.959514
epoch: 1168, train precision: 0.966400, train loss: 22.085060, valid precision: 0.849200, valid loss: 99.592225
epoch: 1169, train precision: 0.967400, train loss: 21.207193, valid precision: 0.846200, valid loss: 99.788938
epoch: 1170, train precision: 0.965578, train loss: 21.845437, valid precision: 0.848400, valid loss: 101.416580
epoch: 1171, train precision: 0.967533, train loss: 20.998865, valid precision: 0.848600, valid loss: 96.925784
epoch: 1172, train precision: 0.970400, train loss: 20.071272, valid precision: 0.853800, valid loss: 101.449683
epoch: 1173, train precision: 0.970622, train loss: 19.907868, valid precision: 0.853200, valid loss: 97.776795
epoch: 1174, train precision: 0.966044, train loss: 21.366050, valid precision: 0.844600, valid loss: 107.557523
epoch: 1175, train precision: 0.968156, train loss: 20.974025, valid precision: 0.854400, valid loss: 98.475779
epoch: 1176, train precision: 0.965689, train loss: 21.848337, valid precision: 0.845200, valid loss: 108.328708
epoch: 1177, train precision: 0.965511, train loss: 21.635576, valid precision: 0.844400, valid loss: 103.425753
epoch: 1178, train precision: 0.964356, train loss: 22.009127, valid precision: 0.848400, valid loss: 104.584273
epoch: 1179, train precision: 0.964422, train loss: 22.702181, valid precision: 0.844000, valid loss: 99.651459
epoch: 1180, train precision: 0.969578, train loss: 20.527585, valid precision: 0.854200, valid loss: 97.771891
epoch: 1181, train precision: 0.966600, train loss: 21.563546, valid precision: 0.850000, valid loss: 101.331389
epoch: 1182, train precision: 0.971644, train loss: 19.109009, valid precision: 0.853400, valid loss: 108.514411
epoch: 1183, train precision: 0.959867, train loss: 24.474448, valid precision: 0.843200, valid loss: 111.944387
epoch: 1184, train precision: 0.967600, train loss: 21.452906, valid precision: 0.852200, valid loss: 103.541509
epoch: 1185, train precision: 0.973333, train loss: 18.840952, valid precision: 0.859800, valid loss: 103.548019
epoch: 1186, train precision: 0.968844, train loss: 20.364229, valid precision: 0.856200, valid loss: 95.808674
epoch: 1187, train precision: 0.968733, train loss: 21.274622, valid precision: 0.850600, valid loss: 93.904834
epoch: 1188, train precision: 0.968600, train loss: 20.553624, valid precision: 0.848800, valid loss: 100.925769
epoch: 1189, train precision: 0.968689, train loss: 20.683583, valid precision: 0.846200, valid loss: 101.428963
epoch: 1190, train precision: 0.964556, train loss: 22.473110, valid precision: 0.844200, valid loss: 103.230258
epoch: 1191, train precision: 0.961356, train loss: 23.012743, valid precision: 0.843800, valid loss: 103.033909
epoch: 1192, train precision: 0.969622, train loss: 21.040140, valid precision: 0.854400, valid loss: 100.872329
epoch: 1193, train precision: 0.971867, train loss: 19.403534, valid precision: 0.856600, valid loss: 98.710689
epoch: 1194, train precision: 0.965378, train loss: 22.142076, valid precision: 0.851600, valid loss: 97.473139
epoch: 1195, train precision: 0.967267, train loss: 21.686627, valid precision: 0.847600, valid loss: 104.836532
epoch: 1196, train precision: 0.968000, train loss: 20.995534, valid precision: 0.848400, valid loss: 103.447695
epoch: 1197, train precision: 0.969778, train loss: 20.252180, valid precision: 0.853600, valid loss: 97.717308
epoch: 1198, train precision: 0.968133, train loss: 20.448602, valid precision: 0.853800, valid loss: 107.871076
epoch: 1199, train precision: 0.970622, train loss: 19.720337, valid precision: 0.850000, valid loss: 102.902176
epoch: 1200, train precision: 0.968533, train loss: 20.994774, valid precision: 0.851800, valid loss: 98.273299
epoch: 1201, train precision: 0.966400, train loss: 21.710292, valid precision: 0.852800, valid loss: 104.756344
epoch: 1202, train precision: 0.964000, train loss: 22.470270, valid precision: 0.852600, valid loss: 97.352755
epoch: 1203, train precision: 0.966822, train loss: 21.504842, valid precision: 0.854200, valid loss: 95.311169
epoch: 1204, train precision: 0.970933, train loss: 19.487758, valid precision: 0.852200, valid loss: 101.797913
epoch: 1205, train precision: 0.969511, train loss: 20.436354, valid precision: 0.851800, valid loss: 97.282266
epoch: 1206, train precision: 0.961578, train loss: 23.367857, valid precision: 0.847600, valid loss: 102.787108
epoch: 1207, train precision: 0.969578, train loss: 20.167520, valid precision: 0.854200, valid loss: 98.033904
epoch: 1208, train precision: 0.966222, train loss: 21.223406, valid precision: 0.851200, valid loss: 98.483446
epoch: 1209, train precision: 0.970022, train loss: 19.919785, valid precision: 0.850600, valid loss: 98.245190
epoch: 1210, train precision: 0.972044, train loss: 19.628799, valid precision: 0.852400, valid loss: 99.151614
epoch: 1211, train precision: 0.968556, train loss: 20.947596, valid precision: 0.840600, valid loss: 114.979260
epoch: 1212, train precision: 0.970022, train loss: 20.468453, valid precision: 0.847800, valid loss: 97.512151
epoch: 1213, train precision: 0.965067, train loss: 22.218505, valid precision: 0.846400, valid loss: 107.529536
epoch: 1214, train precision: 0.968378, train loss: 21.112837, valid precision: 0.849800, valid loss: 100.771434
epoch: 1215, train precision: 0.972244, train loss: 19.461451, valid precision: 0.854400, valid loss: 97.373984
epoch: 1216, train precision: 0.964067, train loss: 22.226851, valid precision: 0.847600, valid loss: 108.196851
epoch: 1217, train precision: 0.968222, train loss: 20.904501, valid precision: 0.846600, valid loss: 104.575990
epoch: 1218, train precision: 0.967311, train loss: 20.946296, valid precision: 0.844000, valid loss: 109.092305
epoch: 1219, train precision: 0.972889, train loss: 18.727940, valid precision: 0.854200, valid loss: 100.280974
epoch: 1220, train precision: 0.964422, train loss: 22.557197, valid precision: 0.850200, valid loss: 88.931238
epoch: 1221, train precision: 0.965133, train loss: 22.166762, valid precision: 0.848200, valid loss: 93.655498
epoch: 1222, train precision: 0.970733, train loss: 19.984534, valid precision: 0.853400, valid loss: 100.670897
epoch: 1223, train precision: 0.966844, train loss: 21.659909, valid precision: 0.854800, valid loss: 104.824022
epoch: 1224, train precision: 0.970044, train loss: 20.349847, valid precision: 0.856400, valid loss: 98.733309
epoch: 1225, train precision: 0.971578, train loss: 19.976277, valid precision: 0.847600, valid loss: 103.082388
epoch: 1226, train precision: 0.967067, train loss: 21.466845, valid precision: 0.847600, valid loss: 101.584001
epoch: 1227, train precision: 0.969378, train loss: 20.514039, valid precision: 0.851800, valid loss: 101.184122
epoch: 1228, train precision: 0.968067, train loss: 20.289125, valid precision: 0.854600, valid loss: 100.275628
epoch: 1229, train precision: 0.969489, train loss: 20.303788, valid precision: 0.856600, valid loss: 101.018800
epoch: 1230, train precision: 0.967956, train loss: 21.080249, valid precision: 0.850800, valid loss: 106.662058
epoch: 1231, train precision: 0.964267, train loss: 22.348033, valid precision: 0.845400, valid loss: 106.302098
epoch: 1232, train precision: 0.968756, train loss: 20.613589, valid precision: 0.853000, valid loss: 104.880222
epoch: 1233, train precision: 0.962733, train loss: 23.005399, valid precision: 0.846000, valid loss: 103.136219
epoch: 1234, train precision: 0.963733, train loss: 22.453012, valid precision: 0.852400, valid loss: 94.092091
epoch: 1235, train precision: 0.969489, train loss: 20.719097, valid precision: 0.848600, valid loss: 96.309926
epoch: 1236, train precision: 0.965867, train loss: 22.737963, valid precision: 0.853800, valid loss: 99.921181
epoch: 1237, train precision: 0.967044, train loss: 21.381970, valid precision: 0.854600, valid loss: 100.858665
epoch: 1238, train precision: 0.968778, train loss: 20.951776, valid precision: 0.848200, valid loss: 108.487932
epoch: 1239, train precision: 0.967378, train loss: 21.608271, valid precision: 0.851000, valid loss: 95.817252
epoch: 1240, train precision: 0.963622, train loss: 23.324437, valid precision: 0.845200, valid loss: 98.984352
epoch: 1241, train precision: 0.966067, train loss: 21.410349, valid precision: 0.847200, valid loss: 101.548057
epoch: 1242, train precision: 0.969000, train loss: 20.742331, valid precision: 0.850800, valid loss: 96.106400
epoch: 1243, train precision: 0.968667, train loss: 20.800305, valid precision: 0.853600, valid loss: 95.861851
epoch: 1244, train precision: 0.964356, train loss: 22.151009, valid precision: 0.847000, valid loss: 108.284820
epoch: 1245, train precision: 0.967356, train loss: 21.199335, valid precision: 0.855400, valid loss: 99.203116
epoch: 1246, train precision: 0.969267, train loss: 21.070553, valid precision: 0.848800, valid loss: 95.724629
epoch: 1247, train precision: 0.964822, train loss: 22.388093, valid precision: 0.844400, valid loss: 107.130144
epoch: 1248, train precision: 0.965600, train loss: 21.574546, valid precision: 0.851600, valid loss: 102.989034
epoch: 1249, train precision: 0.967244, train loss: 21.125057, valid precision: 0.847200, valid loss: 104.447545
epoch: 1250, train precision: 0.974422, train loss: 18.792091, valid precision: 0.855200, valid loss: 99.325083
epoch: 1251, train precision: 0.963711, train loss: 22.789211, valid precision: 0.848200, valid loss: 102.798836
epoch: 1252, train precision: 0.962911, train loss: 22.860520, valid precision: 0.850400, valid loss: 102.705748
epoch: 1253, train precision: 0.969356, train loss: 20.704004, valid precision: 0.851800, valid loss: 103.823590
epoch: 1254, train precision: 0.968311, train loss: 21.781982, valid precision: 0.850800, valid loss: 99.015603
epoch: 1255, train precision: 0.963644, train loss: 23.482422, valid precision: 0.845400, valid loss: 101.747673
epoch: 1256, train precision: 0.967822, train loss: 20.956724, valid precision: 0.847800, valid loss: 106.001348
epoch: 1257, train precision: 0.971400, train loss: 19.435765, valid precision: 0.855800, valid loss: 99.559934
epoch: 1258, train precision: 0.967044, train loss: 20.924185, valid precision: 0.852200, valid loss: 98.588348
epoch: 1259, train precision: 0.970644, train loss: 19.878105, valid precision: 0.853400, valid loss: 103.189582
epoch: 1260, train precision: 0.967222, train loss: 20.984724, valid precision: 0.849800, valid loss: 105.782876
epoch: 1261, train precision: 0.964511, train loss: 22.137603, valid precision: 0.848000, valid loss: 107.660294
epoch: 1262, train precision: 0.970511, train loss: 20.081610, valid precision: 0.850400, valid loss: 98.330422
epoch: 1263, train precision: 0.964933, train loss: 22.243208, valid precision: 0.848000, valid loss: 97.410888
epoch: 1264, train precision: 0.967333, train loss: 20.933625, valid precision: 0.850400, valid loss: 102.131656
epoch: 1265, train precision: 0.965756, train loss: 22.023857, valid precision: 0.847800, valid loss: 100.292981
epoch: 1266, train precision: 0.964089, train loss: 22.780638, valid precision: 0.850200, valid loss: 94.729709
epoch: 1267, train precision: 0.970200, train loss: 19.921855, valid precision: 0.857200, valid loss: 97.800546
epoch: 1268, train precision: 0.965244, train loss: 22.439739, valid precision: 0.844400, valid loss: 109.260830
epoch: 1269, train precision: 0.972756, train loss: 19.509585, valid precision: 0.854000, valid loss: 102.233129
epoch: 1270, train precision: 0.966689, train loss: 21.994617, valid precision: 0.852200, valid loss: 116.509376
epoch: 1271, train precision: 0.966333, train loss: 21.610904, valid precision: 0.849800, valid loss: 99.251005
epoch: 1272, train precision: 0.970200, train loss: 20.402301, valid precision: 0.855600, valid loss: 96.267391
epoch: 1273, train precision: 0.969022, train loss: 20.344636, valid precision: 0.844400, valid loss: 98.495536
epoch: 1274, train precision: 0.966844, train loss: 21.758186, valid precision: 0.846800, valid loss: 96.528010
epoch: 1275, train precision: 0.967444, train loss: 21.618701, valid precision: 0.848000, valid loss: 111.784540
epoch: 1276, train precision: 0.965444, train loss: 22.158665, valid precision: 0.848000, valid loss: 101.528331
epoch: 1277, train precision: 0.965711, train loss: 21.583105, valid precision: 0.853800, valid loss: 99.308238
epoch: 1278, train precision: 0.969578, train loss: 20.562870, valid precision: 0.849400, valid loss: 101.783588
epoch: 1279, train precision: 0.972489, train loss: 19.246715, valid precision: 0.853600, valid loss: 108.948179
epoch: 1280, train precision: 0.970489, train loss: 20.090799, valid precision: 0.851000, valid loss: 109.452361
epoch: 1281, train precision: 0.965356, train loss: 21.930865, valid precision: 0.847600, valid loss: 102.415029
epoch: 1282, train precision: 0.965111, train loss: 23.103288, valid precision: 0.848000, valid loss: 96.455572
epoch: 1283, train precision: 0.966600, train loss: 21.683715, valid precision: 0.847400, valid loss: 98.563349
epoch: 1284, train precision: 0.964889, train loss: 22.243607, valid precision: 0.850800, valid loss: 99.395355
epoch: 1285, train precision: 0.964378, train loss: 22.570610, valid precision: 0.849000, valid loss: 99.398591
epoch: 1286, train precision: 0.967644, train loss: 22.042444, valid precision: 0.845800, valid loss: 110.153630
epoch: 1287, train precision: 0.966511, train loss: 22.066932, valid precision: 0.853000, valid loss: 100.961390
epoch: 1288, train precision: 0.963244, train loss: 22.459470, valid precision: 0.847200, valid loss: 106.565985
epoch: 1289, train precision: 0.969067, train loss: 20.433780, valid precision: 0.855200, valid loss: 101.003729
epoch: 1290, train precision: 0.969756, train loss: 20.843368, valid precision: 0.845400, valid loss: 106.990550
epoch: 1291, train precision: 0.967422, train loss: 22.069736, valid precision: 0.847800, valid loss: 95.729290
epoch: 1292, train precision: 0.969067, train loss: 20.511988, valid precision: 0.853600, valid loss: 109.758643
epoch: 1293, train precision: 0.967933, train loss: 21.035127, valid precision: 0.850000, valid loss: 99.820875
epoch: 1294, train precision: 0.963644, train loss: 23.034449, valid precision: 0.847800, valid loss: 95.995803
epoch: 1295, train precision: 0.964667, train loss: 22.091457, valid precision: 0.846800, valid loss: 101.824150
epoch: 1296, train precision: 0.963467, train loss: 22.349460, valid precision: 0.842000, valid loss: 103.041911
epoch: 1297, train precision: 0.966222, train loss: 21.671899, valid precision: 0.848200, valid loss: 108.164198
epoch: 1298, train precision: 0.965467, train loss: 21.731114, valid precision: 0.849600, valid loss: 104.901261
epoch: 1299, train precision: 0.966578, train loss: 21.362187, valid precision: 0.849400, valid loss: 97.384642
epoch: 1300, train precision: 0.970067, train loss: 20.061858, valid precision: 0.854200, valid loss: 93.091871
epoch: 1301, train precision: 0.965911, train loss: 22.213187, valid precision: 0.847200, valid loss: 93.765399
epoch: 1302, train precision: 0.963467, train loss: 23.495251, valid precision: 0.841800, valid loss: 102.453794
epoch: 1303, train precision: 0.966267, train loss: 21.893578, valid precision: 0.849800, valid loss: 105.791191
epoch: 1304, train precision: 0.968667, train loss: 21.610719, valid precision: 0.848400, valid loss: 103.681584
epoch: 1305, train precision: 0.965533, train loss: 21.935174, valid precision: 0.846600, valid loss: 99.622017
epoch: 1306, train precision: 0.968378, train loss: 21.258897, valid precision: 0.851800, valid loss: 94.280904
epoch: 1307, train precision: 0.970867, train loss: 20.035167, valid precision: 0.856000, valid loss: 99.701277
epoch: 1308, train precision: 0.963356, train loss: 22.839290, valid precision: 0.848400, valid loss: 101.862694
epoch: 1309, train precision: 0.966356, train loss: 21.457085, valid precision: 0.849000, valid loss: 108.334640
epoch: 1310, train precision: 0.968156, train loss: 21.082224, valid precision: 0.851800, valid loss: 102.614631
epoch: 1311, train precision: 0.968778, train loss: 20.916278, valid precision: 0.845000, valid loss: 99.808732
epoch: 1312, train precision: 0.969178, train loss: 20.775787, valid precision: 0.849800, valid loss: 101.725761
epoch: 1313, train precision: 0.968378, train loss: 20.978278, valid precision: 0.850000, valid loss: 105.739168
epoch: 1314, train precision: 0.964600, train loss: 22.501017, valid precision: 0.849000, valid loss: 101.876100
epoch: 1315, train precision: 0.967711, train loss: 21.039952, valid precision: 0.849800, valid loss: 109.801355
epoch: 1316, train precision: 0.965778, train loss: 21.660711, valid precision: 0.843200, valid loss: 112.478443
epoch: 1317, train precision: 0.965600, train loss: 22.020454, valid precision: 0.848600, valid loss: 113.661052
epoch: 1318, train precision: 0.966578, train loss: 21.171476, valid precision: 0.854200, valid loss: 111.786175
epoch: 1319, train precision: 0.970000, train loss: 20.688130, valid precision: 0.852800, valid loss: 112.497777
epoch: 1320, train precision: 0.964200, train loss: 22.021862, valid precision: 0.853800, valid loss: 108.093274
epoch: 1321, train precision: 0.970867, train loss: 19.886791, valid precision: 0.857400, valid loss: 106.881789
epoch: 1322, train precision: 0.963022, train loss: 22.767443, valid precision: 0.851600, valid loss: 102.049147
epoch: 1323, train precision: 0.967511, train loss: 21.545195, valid precision: 0.854400, valid loss: 105.261443
epoch: 1324, train precision: 0.962867, train loss: 23.342995, valid precision: 0.845800, valid loss: 101.495598
epoch: 1325, train precision: 0.970133, train loss: 20.317747, valid precision: 0.855000, valid loss: 104.425885
epoch: 1326, train precision: 0.967222, train loss: 21.211033, valid precision: 0.852800, valid loss: 100.489296
epoch: 1327, train precision: 0.963244, train loss: 22.677903, valid precision: 0.852600, valid loss: 100.864157
epoch: 1328, train precision: 0.968356, train loss: 21.237288, valid precision: 0.851600, valid loss: 102.280216
epoch: 1329, train precision: 0.966933, train loss: 21.331483, valid precision: 0.846400, valid loss: 117.053021
epoch: 1330, train precision: 0.967200, train loss: 21.483688, valid precision: 0.851600, valid loss: 111.971981
epoch: 1331, train precision: 0.965289, train loss: 22.687749, valid precision: 0.845600, valid loss: 106.751112
epoch: 1332, train precision: 0.966867, train loss: 21.778739, valid precision: 0.846600, valid loss: 104.616531
epoch: 1333, train precision: 0.965956, train loss: 21.847617, valid precision: 0.843800, valid loss: 108.503881
epoch: 1334, train precision: 0.968000, train loss: 20.835468, valid precision: 0.851000, valid loss: 107.171426
epoch: 1335, train precision: 0.967511, train loss: 21.602807, valid precision: 0.852600, valid loss: 93.633598
epoch: 1336, train precision: 0.962089, train loss: 22.962142, valid precision: 0.845000, valid loss: 104.698672
epoch: 1337, train precision: 0.969200, train loss: 20.541928, valid precision: 0.853800, valid loss: 104.716407
epoch: 1338, train precision: 0.965867, train loss: 21.542059, valid precision: 0.855000, valid loss: 103.640653
epoch: 1339, train precision: 0.971289, train loss: 20.389782, valid precision: 0.849600, valid loss: 106.987888
epoch: 1340, train precision: 0.967178, train loss: 21.002925, valid precision: 0.852200, valid loss: 108.404979
epoch: 1341, train precision: 0.967022, train loss: 21.863357, valid precision: 0.848000, valid loss: 97.355493
epoch: 1342, train precision: 0.970733, train loss: 19.951644, valid precision: 0.850400, valid loss: 110.312628
epoch: 1343, train precision: 0.965511, train loss: 22.047159, valid precision: 0.851200, valid loss: 98.242598
epoch: 1344, train precision: 0.969378, train loss: 20.152611, valid precision: 0.852200, valid loss: 111.073375
epoch: 1345, train precision: 0.967978, train loss: 21.101323, valid precision: 0.853200, valid loss: 102.739083
epoch: 1346, train precision: 0.966444, train loss: 21.764836, valid precision: 0.845200, valid loss: 98.356328
epoch: 1347, train precision: 0.961489, train loss: 23.539182, valid precision: 0.845000, valid loss: 106.214594
epoch: 1348, train precision: 0.963400, train loss: 22.884722, valid precision: 0.844800, valid loss: 107.348757
epoch: 1349, train precision: 0.961556, train loss: 23.148536, valid precision: 0.844600, valid loss: 115.318310
epoch: 1350, train precision: 0.968667, train loss: 21.134163, valid precision: 0.850200, valid loss: 97.126690
epoch: 1351, train precision: 0.967911, train loss: 20.761451, valid precision: 0.846000, valid loss: 106.084945
epoch: 1352, train precision: 0.969667, train loss: 20.385813, valid precision: 0.854000, valid loss: 99.040150
epoch: 1353, train precision: 0.963689, train loss: 22.396128, valid precision: 0.842800, valid loss: 104.036390
epoch: 1354, train precision: 0.971156, train loss: 20.073114, valid precision: 0.851200, valid loss: 101.108452
epoch: 1355, train precision: 0.969867, train loss: 20.741291, valid precision: 0.848800, valid loss: 104.893463
epoch: 1356, train precision: 0.967933, train loss: 21.653754, valid precision: 0.846800, valid loss: 102.260299
epoch: 1357, train precision: 0.965867, train loss: 22.010440, valid precision: 0.851800, valid loss: 109.865598
epoch: 1358, train precision: 0.965622, train loss: 22.265871, valid precision: 0.847200, valid loss: 118.394874
epoch: 1359, train precision: 0.966733, train loss: 21.466220, valid precision: 0.848800, valid loss: 106.674599
epoch: 1360, train precision: 0.966600, train loss: 21.256229, valid precision: 0.849600, valid loss: 106.148103
epoch: 1361, train precision: 0.963533, train loss: 22.458036, valid precision: 0.852000, valid loss: 104.668759
epoch: 1362, train precision: 0.962400, train loss: 23.308061, valid precision: 0.845600, valid loss: 106.692081
epoch: 1363, train precision: 0.968956, train loss: 20.406059, valid precision: 0.852200, valid loss: 113.384842
epoch: 1364, train precision: 0.971022, train loss: 19.959947, valid precision: 0.856200, valid loss: 98.167768
epoch: 1365, train precision: 0.962978, train loss: 23.294337, valid precision: 0.848600, valid loss: 106.606683
epoch: 1366, train precision: 0.967378, train loss: 21.680228, valid precision: 0.850600, valid loss: 99.476634
epoch: 1367, train precision: 0.962667, train loss: 23.796773, valid precision: 0.846200, valid loss: 101.404606
epoch: 1368, train precision: 0.967000, train loss: 21.823460, valid precision: 0.843600, valid loss: 100.501145
epoch: 1369, train precision: 0.969267, train loss: 20.515286, valid precision: 0.851400, valid loss: 111.181837
epoch: 1370, train precision: 0.965622, train loss: 22.323074, valid precision: 0.851800, valid loss: 99.815804
epoch: 1371, train precision: 0.958089, train loss: 25.602306, valid precision: 0.842600, valid loss: 105.435552
epoch: 1372, train precision: 0.969089, train loss: 21.417519, valid precision: 0.852000, valid loss: 102.814614
epoch: 1373, train precision: 0.968267, train loss: 21.271324, valid precision: 0.855400, valid loss: 99.721059
epoch: 1374, train precision: 0.966844, train loss: 21.328376, valid precision: 0.854200, valid loss: 107.237317
epoch: 1375, train precision: 0.966778, train loss: 21.627969, valid precision: 0.847000, valid loss: 97.024048
epoch: 1376, train precision: 0.965822, train loss: 22.406779, valid precision: 0.847400, valid loss: 106.008514
epoch: 1377, train precision: 0.965356, train loss: 22.473034, valid precision: 0.850600, valid loss: 97.887476
epoch: 1378, train precision: 0.971711, train loss: 20.196433, valid precision: 0.853800, valid loss: 98.581710
epoch: 1379, train precision: 0.966156, train loss: 21.635813, valid precision: 0.849400, valid loss: 107.652681
epoch: 1380, train precision: 0.962311, train loss: 23.245614, valid precision: 0.839600, valid loss: 105.594261
epoch: 1381, train precision: 0.969178, train loss: 20.832160, valid precision: 0.851800, valid loss: 101.332490
epoch: 1382, train precision: 0.970578, train loss: 20.205423, valid precision: 0.854000, valid loss: 103.299074
epoch: 1383, train precision: 0.963933, train loss: 23.090550, valid precision: 0.840800, valid loss: 104.342704
epoch: 1384, train precision: 0.963911, train loss: 22.798195, valid precision: 0.850600, valid loss: 107.589798
epoch: 1385, train precision: 0.967422, train loss: 21.339832, valid precision: 0.846000, valid loss: 113.972810
epoch: 1386, train precision: 0.959511, train loss: 24.626864, valid precision: 0.845800, valid loss: 102.681123
epoch: 1387, train precision: 0.960911, train loss: 23.845266, valid precision: 0.844200, valid loss: 104.243405
epoch: 1388, train precision: 0.968822, train loss: 20.526957, valid precision: 0.848600, valid loss: 110.193193
epoch: 1389, train precision: 0.960000, train loss: 24.065436, valid precision: 0.849000, valid loss: 96.944656
epoch: 1390, train precision: 0.971867, train loss: 19.249662, valid precision: 0.852000, valid loss: 107.171872
epoch: 1391, train precision: 0.970689, train loss: 20.211640, valid precision: 0.851600, valid loss: 100.420402
epoch: 1392, train precision: 0.969133, train loss: 20.672784, valid precision: 0.845200, valid loss: 100.060587
epoch: 1393, train precision: 0.965822, train loss: 21.972979, valid precision: 0.847000, valid loss: 99.686715
epoch: 1394, train precision: 0.964689, train loss: 21.821187, valid precision: 0.845200, valid loss: 100.680607
epoch: 1395, train precision: 0.967844, train loss: 21.772777, valid precision: 0.848800, valid loss: 101.372319
epoch: 1396, train precision: 0.966044, train loss: 21.888621, valid precision: 0.843000, valid loss: 102.584769
epoch: 1397, train precision: 0.963422, train loss: 23.033629, valid precision: 0.842800, valid loss: 98.569722
epoch: 1398, train precision: 0.970578, train loss: 20.115953, valid precision: 0.848800, valid loss: 105.073633
epoch: 1399, train precision: 0.967867, train loss: 21.763716, valid precision: 0.850800, valid loss: 98.778333
epoch: 1400, train precision: 0.970867, train loss: 19.819064, valid precision: 0.845000, valid loss: 113.820793
epoch: 1401, train precision: 0.970133, train loss: 20.407107, valid precision: 0.852800, valid loss: 99.423317
epoch: 1402, train precision: 0.966933, train loss: 21.208668, valid precision: 0.855000, valid loss: 104.251790
epoch: 1403, train precision: 0.966911, train loss: 22.196165, valid precision: 0.845600, valid loss: 109.130447
epoch: 1404, train precision: 0.968422, train loss: 21.201245, valid precision: 0.846400, valid loss: 108.525961
epoch: 1405, train precision: 0.968378, train loss: 20.844024, valid precision: 0.847800, valid loss: 104.910453
epoch: 1406, train precision: 0.966844, train loss: 21.943515, valid precision: 0.843000, valid loss: 103.347914
epoch: 1407, train precision: 0.964489, train loss: 22.037896, valid precision: 0.850200, valid loss: 107.256694
epoch: 1408, train precision: 0.966822, train loss: 21.612309, valid precision: 0.850800, valid loss: 109.006248
epoch: 1409, train precision: 0.964733, train loss: 22.518631, valid precision: 0.850400, valid loss: 111.030474
epoch: 1410, train precision: 0.964622, train loss: 22.589183, valid precision: 0.847200, valid loss: 107.154628
epoch: 1411, train precision: 0.967711, train loss: 21.375029, valid precision: 0.851000, valid loss: 105.779097
epoch: 1412, train precision: 0.967311, train loss: 21.384369, valid precision: 0.843000, valid loss: 108.409157
epoch: 1413, train precision: 0.963711, train loss: 22.644621, valid precision: 0.842200, valid loss: 111.071869
epoch: 1414, train precision: 0.963178, train loss: 23.177964, valid precision: 0.845800, valid loss: 103.509697
epoch: 1415, train precision: 0.959533, train loss: 25.276538, valid precision: 0.847200, valid loss: 103.040365
epoch: 1416, train precision: 0.967222, train loss: 21.786261, valid precision: 0.851200, valid loss: 104.530666
epoch: 1417, train precision: 0.964311, train loss: 22.709804, valid precision: 0.851000, valid loss: 100.159429
epoch: 1418, train precision: 0.965867, train loss: 22.317996, valid precision: 0.849800, valid loss: 99.236185
epoch: 1419, train precision: 0.966067, train loss: 22.245937, valid precision: 0.848400, valid loss: 110.547897
epoch: 1420, train precision: 0.970022, train loss: 20.737040, valid precision: 0.853200, valid loss: 107.768622
epoch: 1421, train precision: 0.967156, train loss: 21.837271, valid precision: 0.850800, valid loss: 95.325069
epoch: 1422, train precision: 0.970600, train loss: 20.824860, valid precision: 0.850000, valid loss: 97.457041
epoch: 1423, train precision: 0.966422, train loss: 21.914626, valid precision: 0.850600, valid loss: 91.840836
epoch: 1424, train precision: 0.959622, train loss: 24.131488, valid precision: 0.847600, valid loss: 96.112325
epoch: 1425, train precision: 0.964156, train loss: 22.261601, valid precision: 0.851000, valid loss: 106.937594
epoch: 1426, train precision: 0.970978, train loss: 20.013738, valid precision: 0.854600, valid loss: 104.027389
epoch: 1427, train precision: 0.968000, train loss: 21.151667, valid precision: 0.856800, valid loss: 107.743673
epoch: 1428, train precision: 0.961489, train loss: 23.656730, valid precision: 0.841400, valid loss: 108.211842
epoch: 1429, train precision: 0.964733, train loss: 22.254244, valid precision: 0.847200, valid loss: 111.429483
epoch: 1430, train precision: 0.965889, train loss: 22.041450, valid precision: 0.846000, valid loss: 99.261242
epoch: 1431, train precision: 0.970622, train loss: 20.437708, valid precision: 0.853000, valid loss: 108.577627
epoch: 1432, train precision: 0.969222, train loss: 20.444962, valid precision: 0.844400, valid loss: 111.415845
epoch: 1433, train precision: 0.960689, train loss: 24.786951, valid precision: 0.841800, valid loss: 101.688236
epoch: 1434, train precision: 0.964356, train loss: 22.869845, valid precision: 0.841400, valid loss: 102.919168
epoch: 1435, train precision: 0.968844, train loss: 20.430935, valid precision: 0.852200, valid loss: 99.704572
epoch: 1436, train precision: 0.962022, train loss: 23.140019, valid precision: 0.851800, valid loss: 103.857089
epoch: 1437, train precision: 0.964578, train loss: 22.418745, valid precision: 0.850600, valid loss: 102.294278
epoch: 1438, train precision: 0.963867, train loss: 22.765374, valid precision: 0.845600, valid loss: 95.687033
epoch: 1439, train precision: 0.968444, train loss: 20.849596, valid precision: 0.852400, valid loss: 98.896308
epoch: 1440, train precision: 0.968911, train loss: 21.186763, valid precision: 0.857400, valid loss: 100.238785
epoch: 1441, train precision: 0.967133, train loss: 22.544781, valid precision: 0.854000, valid loss: 98.128142
epoch: 1442, train precision: 0.964511, train loss: 22.878235, valid precision: 0.851000, valid loss: 98.342537
epoch: 1443, train precision: 0.966111, train loss: 22.049903, valid precision: 0.851000, valid loss: 115.004324
epoch: 1444, train precision: 0.959933, train loss: 24.504087, valid precision: 0.848800, valid loss: 114.236084
epoch: 1445, train precision: 0.965133, train loss: 22.302912, valid precision: 0.843400, valid loss: 100.809201
epoch: 1446, train precision: 0.961333, train loss: 23.605564, valid precision: 0.849600, valid loss: 99.086252
epoch: 1447, train precision: 0.967400, train loss: 21.535512, valid precision: 0.848600, valid loss: 97.988741
epoch: 1448, train precision: 0.968600, train loss: 20.635104, valid precision: 0.850400, valid loss: 102.690339
epoch: 1449, train precision: 0.968133, train loss: 21.001975, valid precision: 0.850800, valid loss: 96.490314
epoch: 1450, train precision: 0.967133, train loss: 21.649447, valid precision: 0.852000, valid loss: 98.361072
epoch: 1451, train precision: 0.964578, train loss: 22.771988, valid precision: 0.840600, valid loss: 107.896651
epoch: 1452, train precision: 0.965089, train loss: 22.040628, valid precision: 0.849200, valid loss: 94.892489
epoch: 1453, train precision: 0.967889, train loss: 21.280301, valid precision: 0.849800, valid loss: 107.834130
epoch: 1454, train precision: 0.966711, train loss: 21.652748, valid precision: 0.851600, valid loss: 105.155335
epoch: 1455, train precision: 0.968467, train loss: 21.184710, valid precision: 0.850200, valid loss: 105.743699
epoch: 1456, train precision: 0.968089, train loss: 21.224659, valid precision: 0.853600, valid loss: 102.890782
epoch: 1457, train precision: 0.965244, train loss: 22.754898, valid precision: 0.854200, valid loss: 97.477853
epoch: 1458, train precision: 0.966867, train loss: 21.242092, valid precision: 0.848200, valid loss: 105.200067
epoch: 1459, train precision: 0.965578, train loss: 21.955184, valid precision: 0.849200, valid loss: 105.695302
epoch: 1460, train precision: 0.967556, train loss: 21.354183, valid precision: 0.855000, valid loss: 104.188266
epoch: 1461, train precision: 0.964556, train loss: 22.427159, valid precision: 0.854800, valid loss: 109.889025
epoch: 1462, train precision: 0.964578, train loss: 22.181060, valid precision: 0.850600, valid loss: 101.819650
epoch: 1463, train precision: 0.967822, train loss: 21.132711, valid precision: 0.851800, valid loss: 99.734556
epoch: 1464, train precision: 0.968067, train loss: 21.413933, valid precision: 0.851400, valid loss: 103.612185
epoch: 1465, train precision: 0.966978, train loss: 21.700520, valid precision: 0.850200, valid loss: 98.541799
epoch: 1466, train precision: 0.970156, train loss: 20.381317, valid precision: 0.849600, valid loss: 102.183860
epoch: 1467, train precision: 0.965156, train loss: 22.431610, valid precision: 0.853800, valid loss: 97.254215
epoch: 1468, train precision: 0.968933, train loss: 21.310933, valid precision: 0.843400, valid loss: 108.333286
epoch: 1469, train precision: 0.966600, train loss: 21.634151, valid precision: 0.843800, valid loss: 108.419794
epoch: 1470, train precision: 0.967222, train loss: 21.581539, valid precision: 0.849200, valid loss: 107.430059
epoch: 1471, train precision: 0.967222, train loss: 21.339923, valid precision: 0.851600, valid loss: 103.484878
epoch: 1472, train precision: 0.970222, train loss: 19.864166, valid precision: 0.853200, valid loss: 105.787843
epoch: 1473, train precision: 0.968533, train loss: 21.139996, valid precision: 0.851800, valid loss: 103.408112
epoch: 1474, train precision: 0.964467, train loss: 22.386300, valid precision: 0.848800, valid loss: 99.599362
epoch: 1475, train precision: 0.965111, train loss: 22.487497, valid precision: 0.853200, valid loss: 97.491951
epoch: 1476, train precision: 0.959511, train loss: 25.107439, valid precision: 0.846400, valid loss: 111.094100
epoch: 1477, train precision: 0.962444, train loss: 23.402715, valid precision: 0.847800, valid loss: 119.186033
epoch: 1478, train precision: 0.963733, train loss: 22.663483, valid precision: 0.853200, valid loss: 98.995376
epoch: 1479, train precision: 0.963533, train loss: 22.609142, valid precision: 0.854400, valid loss: 99.658649
epoch: 1480, train precision: 0.964089, train loss: 22.652029, valid precision: 0.840800, valid loss: 111.549921
epoch: 1481, train precision: 0.962600, train loss: 22.727018, valid precision: 0.851200, valid loss: 100.312096
epoch: 1482, train precision: 0.964133, train loss: 22.453353, valid precision: 0.846000, valid loss: 105.171807
epoch: 1483, train precision: 0.958200, train loss: 24.996259, valid precision: 0.847600, valid loss: 104.700074
epoch: 1484, train precision: 0.965511, train loss: 22.001362, valid precision: 0.853800, valid loss: 105.351127
epoch: 1485, train precision: 0.964267, train loss: 22.312246, valid precision: 0.849600, valid loss: 104.806303
epoch: 1486, train precision: 0.971000, train loss: 20.025406, valid precision: 0.855400, valid loss: 101.383483
epoch: 1487, train precision: 0.968000, train loss: 20.746874, valid precision: 0.849200, valid loss: 110.890163
epoch: 1488, train precision: 0.965289, train loss: 22.496600, valid precision: 0.851200, valid loss: 105.812174
epoch: 1489, train precision: 0.964156, train loss: 22.618545, valid precision: 0.851200, valid loss: 96.926697
epoch: 1490, train precision: 0.967156, train loss: 21.641556, valid precision: 0.848200, valid loss: 96.108697
epoch: 1491, train precision: 0.965178, train loss: 22.386118, valid precision: 0.845000, valid loss: 107.140953
epoch: 1492, train precision: 0.968600, train loss: 21.311526, valid precision: 0.848600, valid loss: 102.443178
epoch: 1493, train precision: 0.969156, train loss: 21.269146, valid precision: 0.851800, valid loss: 106.244883
epoch: 1494, train precision: 0.966644, train loss: 21.521959, valid precision: 0.845800, valid loss: 104.747949
epoch: 1495, train precision: 0.964733, train loss: 22.370753, valid precision: 0.845000, valid loss: 104.155205
epoch: 1496, train precision: 0.962111, train loss: 23.364121, valid precision: 0.846200, valid loss: 107.784693
epoch: 1497, train precision: 0.962756, train loss: 23.422504, valid precision: 0.846600, valid loss: 95.622940
epoch: 1498, train precision: 0.959400, train loss: 24.730245, valid precision: 0.843800, valid loss: 113.319981
epoch: 1499, train precision: 0.969333, train loss: 20.374225, valid precision: 0.853400, valid loss: 103.947196
epoch: 1500, train precision: 0.968800, train loss: 20.742894, valid precision: 0.851800, valid loss: 98.627662
epoch: 1501, train precision: 0.969356, train loss: 20.638896, valid precision: 0.850600, valid loss: 96.432109
epoch: 1502, train precision: 0.967267, train loss: 21.757094, valid precision: 0.855200, valid loss: 102.074979
epoch: 1503, train precision: 0.964067, train loss: 22.390837, valid precision: 0.847600, valid loss: 101.992184
epoch: 1504, train precision: 0.963867, train loss: 22.986419, valid precision: 0.845600, valid loss: 108.459973
epoch: 1505, train precision: 0.964778, train loss: 22.197883, valid precision: 0.845800, valid loss: 103.296225
epoch: 1506, train precision: 0.966933, train loss: 21.219251, valid precision: 0.850400, valid loss: 104.409845
epoch: 1507, train precision: 0.965022, train loss: 22.181241, valid precision: 0.843400, valid loss: 106.052086
epoch: 1508, train precision: 0.968533, train loss: 20.801917, valid precision: 0.847600, valid loss: 104.578035
epoch: 1509, train precision: 0.964533, train loss: 22.473357, valid precision: 0.848200, valid loss: 108.325705
epoch: 1510, train precision: 0.971356, train loss: 19.876132, valid precision: 0.849800, valid loss: 102.274318
epoch: 1511, train precision: 0.962756, train loss: 22.958216, valid precision: 0.841200, valid loss: 102.668338
epoch: 1512, train precision: 0.964978, train loss: 22.616302, valid precision: 0.848400, valid loss: 96.512545
epoch: 1513, train precision: 0.962733, train loss: 22.989629, valid precision: 0.848800, valid loss: 106.807203
epoch: 1514, train precision: 0.968600, train loss: 21.205454, valid precision: 0.849400, valid loss: 102.288098
epoch: 1515, train precision: 0.970844, train loss: 20.196918, valid precision: 0.848000, valid loss: 108.771060
epoch: 1516, train precision: 0.961511, train loss: 23.732544, valid precision: 0.846200, valid loss: 116.591445
epoch: 1517, train precision: 0.967422, train loss: 21.778338, valid precision: 0.847200, valid loss: 102.408101
epoch: 1518, train precision: 0.968911, train loss: 20.898186, valid precision: 0.851400, valid loss: 113.301703
epoch: 1519, train precision: 0.967000, train loss: 21.514829, valid precision: 0.850000, valid loss: 107.519980
epoch: 1520, train precision: 0.964156, train loss: 22.337696, valid precision: 0.846600, valid loss: 108.131517
epoch: 1521, train precision: 0.967578, train loss: 21.327120, valid precision: 0.851200, valid loss: 114.123190
epoch: 1522, train precision: 0.967667, train loss: 21.118595, valid precision: 0.850600, valid loss: 110.477815
epoch: 1523, train precision: 0.967356, train loss: 20.988427, valid precision: 0.849800, valid loss: 106.090377
epoch: 1524, train precision: 0.965133, train loss: 21.796009, valid precision: 0.855200, valid loss: 107.408821
epoch: 1525, train precision: 0.964689, train loss: 21.999055, valid precision: 0.852400, valid loss: 101.230253
epoch: 1526, train precision: 0.961444, train loss: 23.649362, valid precision: 0.846600, valid loss: 105.990571
epoch: 1527, train precision: 0.966978, train loss: 21.603845, valid precision: 0.846400, valid loss: 103.636121
epoch: 1528, train precision: 0.967956, train loss: 21.711515, valid precision: 0.846000, valid loss: 110.821233
epoch: 1529, train precision: 0.969200, train loss: 20.859594, valid precision: 0.852200, valid loss: 109.623096
epoch: 1530, train precision: 0.964511, train loss: 23.390752, valid precision: 0.845000, valid loss: 101.135203
epoch: 1531, train precision: 0.963178, train loss: 23.199386, valid precision: 0.841600, valid loss: 109.089906
epoch: 1532, train precision: 0.964178, train loss: 22.690707, valid precision: 0.842400, valid loss: 105.057916
epoch: 1533, train precision: 0.965156, train loss: 22.619948, valid precision: 0.849000, valid loss: 99.797503
epoch: 1534, train precision: 0.969422, train loss: 21.370415, valid precision: 0.847800, valid loss: 103.012948
epoch: 1535, train precision: 0.970600, train loss: 20.680820, valid precision: 0.847200, valid loss: 104.718480
epoch: 1536, train precision: 0.966778, train loss: 21.700186, valid precision: 0.850800, valid loss: 113.336242
epoch: 1537, train precision: 0.963511, train loss: 23.826284, valid precision: 0.842400, valid loss: 106.452325
epoch: 1538, train precision: 0.960978, train loss: 23.450881, valid precision: 0.848200, valid loss: 108.154543
epoch: 1539, train precision: 0.969267, train loss: 21.572057, valid precision: 0.846400, valid loss: 105.906143
epoch: 1540, train precision: 0.966111, train loss: 22.097823, valid precision: 0.847200, valid loss: 113.732209
epoch: 1541, train precision: 0.970356, train loss: 20.707621, valid precision: 0.853000, valid loss: 100.688035
epoch: 1542, train precision: 0.966778, train loss: 21.856002, valid precision: 0.848800, valid loss: 111.302778
epoch: 1543, train precision: 0.963044, train loss: 23.153602, valid precision: 0.848600, valid loss: 105.578815
epoch: 1544, train precision: 0.965022, train loss: 22.351946, valid precision: 0.847000, valid loss: 106.015059
epoch: 1545, train precision: 0.960889, train loss: 23.498541, valid precision: 0.845200, valid loss: 111.959295
epoch: 1546, train precision: 0.965089, train loss: 22.686671, valid precision: 0.843400, valid loss: 101.284215
epoch: 1547, train precision: 0.964867, train loss: 22.560973, valid precision: 0.848800, valid loss: 104.463458
epoch: 1548, train precision: 0.962489, train loss: 23.335554, valid precision: 0.842600, valid loss: 108.942940
epoch: 1549, train precision: 0.963622, train loss: 22.758502, valid precision: 0.844200, valid loss: 103.495354
epoch: 1550, train precision: 0.964556, train loss: 22.627431, valid precision: 0.848000, valid loss: 104.118289
epoch: 1551, train precision: 0.965378, train loss: 22.486168, valid precision: 0.846800, valid loss: 107.542958
epoch: 1552, train precision: 0.964711, train loss: 23.138014, valid precision: 0.849800, valid loss: 101.436713
epoch: 1553, train precision: 0.962222, train loss: 23.148031, valid precision: 0.846800, valid loss: 109.423320
epoch: 1554, train precision: 0.971289, train loss: 20.298931, valid precision: 0.853800, valid loss: 98.203328
epoch: 1555, train precision: 0.966867, train loss: 21.708686, valid precision: 0.854400, valid loss: 109.377769
epoch: 1556, train precision: 0.966667, train loss: 21.937639, valid precision: 0.851600, valid loss: 106.754662
epoch: 1557, train precision: 0.967578, train loss: 21.355702, valid precision: 0.845400, valid loss: 101.751839
epoch: 1558, train precision: 0.967889, train loss: 21.188829, valid precision: 0.847600, valid loss: 102.334214
epoch: 1559, train precision: 0.968667, train loss: 21.280950, valid precision: 0.851200, valid loss: 103.351875
epoch: 1560, train precision: 0.963667, train loss: 23.205536, valid precision: 0.851000, valid loss: 99.795658
epoch: 1561, train precision: 0.963378, train loss: 22.622101, valid precision: 0.851000, valid loss: 99.751206
epoch: 1562, train precision: 0.963933, train loss: 22.746426, valid precision: 0.848000, valid loss: 105.629124
epoch: 1563, train precision: 0.967578, train loss: 21.615350, valid precision: 0.853600, valid loss: 105.855348
epoch: 1564, train precision: 0.957689, train loss: 25.236929, valid precision: 0.848200, valid loss: 100.517112
epoch: 1565, train precision: 0.965356, train loss: 22.075200, valid precision: 0.847800, valid loss: 109.961724
epoch: 1566, train precision: 0.959756, train loss: 24.815766, valid precision: 0.844000, valid loss: 99.623538
epoch: 1567, train precision: 0.967489, train loss: 21.594034, valid precision: 0.853800, valid loss: 99.358110
epoch: 1568, train precision: 0.964289, train loss: 23.021917, valid precision: 0.848200, valid loss: 103.196813
epoch: 1569, train precision: 0.959178, train loss: 24.802094, valid precision: 0.848400, valid loss: 107.532441
epoch: 1570, train precision: 0.967200, train loss: 21.580951, valid precision: 0.852000, valid loss: 111.655906
epoch: 1571, train precision: 0.968089, train loss: 21.412086, valid precision: 0.846400, valid loss: 102.214333
epoch: 1572, train precision: 0.969133, train loss: 20.859519, valid precision: 0.848600, valid loss: 101.218013
epoch: 1573, train precision: 0.966356, train loss: 21.617159, valid precision: 0.844400, valid loss: 114.713065
epoch: 1574, train precision: 0.965733, train loss: 21.954980, valid precision: 0.848600, valid loss: 107.156464
epoch: 1575, train precision: 0.963378, train loss: 22.955475, valid precision: 0.845400, valid loss: 110.294111
epoch: 1576, train precision: 0.963044, train loss: 23.253781, valid precision: 0.846200, valid loss: 109.023730
epoch: 1577, train precision: 0.960867, train loss: 23.613771, valid precision: 0.847000, valid loss: 106.833020
epoch: 1578, train precision: 0.967844, train loss: 21.346883, valid precision: 0.847400, valid loss: 102.658864
epoch: 1579, train precision: 0.965444, train loss: 22.406148, valid precision: 0.850000, valid loss: 101.914463
epoch: 1580, train precision: 0.966022, train loss: 22.069925, valid precision: 0.850800, valid loss: 103.122476
epoch: 1581, train precision: 0.961089, train loss: 23.886947, valid precision: 0.845200, valid loss: 115.321911
epoch: 1582, train precision: 0.960733, train loss: 23.789123, valid precision: 0.844200, valid loss: 106.460788
epoch: 1583, train precision: 0.971533, train loss: 19.723945, valid precision: 0.854600, valid loss: 105.745046
epoch: 1584, train precision: 0.965911, train loss: 22.228050, valid precision: 0.846200, valid loss: 106.285047
epoch: 1585, train precision: 0.965756, train loss: 22.416315, valid precision: 0.848400, valid loss: 107.022045
epoch: 1586, train precision: 0.962444, train loss: 23.676105, valid precision: 0.845200, valid loss: 118.404161
epoch: 1587, train precision: 0.965822, train loss: 22.209018, valid precision: 0.850800, valid loss: 104.839462
epoch: 1588, train precision: 0.962956, train loss: 23.094992, valid precision: 0.842000, valid loss: 110.518043
epoch: 1589, train precision: 0.963444, train loss: 23.045101, valid precision: 0.843400, valid loss: 99.875760
epoch: 1590, train precision: 0.964956, train loss: 22.295513, valid precision: 0.851800, valid loss: 109.592336
epoch: 1591, train precision: 0.966489, train loss: 21.505325, valid precision: 0.851000, valid loss: 105.405139
epoch: 1592, train precision: 0.967978, train loss: 21.400186, valid precision: 0.847200, valid loss: 102.672291
epoch: 1593, train precision: 0.966178, train loss: 21.726981, valid precision: 0.846800, valid loss: 104.561480
epoch: 1594, train precision: 0.964756, train loss: 22.226872, valid precision: 0.853600, valid loss: 101.950265
epoch: 1595, train precision: 0.960378, train loss: 24.464252, valid precision: 0.848800, valid loss: 98.960852
epoch: 1596, train precision: 0.959533, train loss: 24.831594, valid precision: 0.846600, valid loss: 99.255294
epoch: 1597, train precision: 0.965511, train loss: 22.153615, valid precision: 0.843600, valid loss: 109.794173
epoch: 1598, train precision: 0.961978, train loss: 23.556775, valid precision: 0.844800, valid loss: 105.779135
epoch: 1599, train precision: 0.964178, train loss: 22.381435, valid precision: 0.850600, valid loss: 100.287779
epoch: 1600, train precision: 0.965889, train loss: 22.146168, valid precision: 0.854600, valid loss: 100.256627
epoch: 1601, train precision: 0.967756, train loss: 21.273850, valid precision: 0.845000, valid loss: 107.470598
epoch: 1602, train precision: 0.966844, train loss: 21.428210, valid precision: 0.845400, valid loss: 113.105575
epoch: 1603, train precision: 0.962733, train loss: 23.164322, valid precision: 0.846800, valid loss: 107.120338
epoch: 1604, train precision: 0.966556, train loss: 21.829928, valid precision: 0.841800, valid loss: 99.751682
epoch: 1605, train precision: 0.970289, train loss: 20.315140, valid precision: 0.848200, valid loss: 104.122082
epoch: 1606, train precision: 0.966667, train loss: 21.515336, valid precision: 0.846800, valid loss: 104.224057
epoch: 1607, train precision: 0.964444, train loss: 22.421032, valid precision: 0.846200, valid loss: 112.487458
epoch: 1608, train precision: 0.966422, train loss: 21.675972, valid precision: 0.846400, valid loss: 101.703829
epoch: 1609, train precision: 0.959267, train loss: 24.260466, valid precision: 0.846800, valid loss: 104.854688
epoch: 1610, train precision: 0.964911, train loss: 22.458137, valid precision: 0.847600, valid loss: 108.336106
epoch: 1611, train precision: 0.967756, train loss: 20.942620, valid precision: 0.848600, valid loss: 106.131373
epoch: 1612, train precision: 0.958622, train loss: 25.000057, valid precision: 0.846000, valid loss: 100.419575
epoch: 1613, train precision: 0.960911, train loss: 23.558492, valid precision: 0.848400, valid loss: 100.347991
epoch: 1614, train precision: 0.963644, train loss: 22.845878, valid precision: 0.853600, valid loss: 98.608879
epoch: 1615, train precision: 0.967644, train loss: 21.662520, valid precision: 0.853000, valid loss: 100.578588
epoch: 1616, train precision: 0.963822, train loss: 22.627729, valid precision: 0.854800, valid loss: 99.891138
epoch: 1617, train precision: 0.967644, train loss: 21.342544, valid precision: 0.854400, valid loss: 103.000149
epoch: 1618, train precision: 0.967889, train loss: 21.262213, valid precision: 0.851600, valid loss: 102.508738
epoch: 1619, train precision: 0.965444, train loss: 21.961636, valid precision: 0.852800, valid loss: 101.189323
epoch: 1620, train precision: 0.964867, train loss: 22.548380, valid precision: 0.848600, valid loss: 98.541656
epoch: 1621, train precision: 0.966156, train loss: 22.435094, valid precision: 0.850400, valid loss: 96.388533
epoch: 1622, train precision: 0.966067, train loss: 21.848874, valid precision: 0.852200, valid loss: 101.990813
epoch: 1623, train precision: 0.958022, train loss: 25.555328, valid precision: 0.845200, valid loss: 93.871554
epoch: 1624, train precision: 0.963689, train loss: 22.919486, valid precision: 0.851800, valid loss: 90.277557
epoch: 1625, train precision: 0.960622, train loss: 23.894383, valid precision: 0.847200, valid loss: 102.322671
epoch: 1626, train precision: 0.963489, train loss: 22.732170, valid precision: 0.852800, valid loss: 107.083584
epoch: 1627, train precision: 0.966689, train loss: 21.392394, valid precision: 0.854000, valid loss: 106.607160
epoch: 1628, train precision: 0.964422, train loss: 22.877050, valid precision: 0.849400, valid loss: 110.813146
epoch: 1629, train precision: 0.972089, train loss: 19.855311, valid precision: 0.858000, valid loss: 101.462862
epoch: 1630, train precision: 0.965956, train loss: 22.093519, valid precision: 0.851400, valid loss: 101.881295
epoch: 1631, train precision: 0.951111, train loss: 27.689860, valid precision: 0.838400, valid loss: 99.591519
epoch: 1632, train precision: 0.965689, train loss: 22.534414, valid precision: 0.854600, valid loss: 95.975191
epoch: 1633, train precision: 0.961533, train loss: 23.436677, valid precision: 0.847400, valid loss: 100.590072
epoch: 1634, train precision: 0.968444, train loss: 20.894746, valid precision: 0.855400, valid loss: 104.502089
epoch: 1635, train precision: 0.961711, train loss: 23.913136, valid precision: 0.852200, valid loss: 97.524392
epoch: 1636, train precision: 0.965289, train loss: 22.651570, valid precision: 0.853400, valid loss: 98.829796
epoch: 1637, train precision: 0.962556, train loss: 22.842205, valid precision: 0.846800, valid loss: 99.326187
epoch: 1638, train precision: 0.964733, train loss: 22.496152, valid precision: 0.848600, valid loss: 103.011427
epoch: 1639, train precision: 0.963467, train loss: 22.784871, valid precision: 0.856800, valid loss: 96.019208
epoch: 1640, train precision: 0.967578, train loss: 21.406770, valid precision: 0.850600, valid loss: 115.582604
epoch: 1641, train precision: 0.964333, train loss: 23.076017, valid precision: 0.844400, valid loss: 102.982245
epoch: 1642, train precision: 0.964289, train loss: 22.887795, valid precision: 0.846400, valid loss: 114.962089
epoch: 1643, train precision: 0.960778, train loss: 24.175144, valid precision: 0.850400, valid loss: 99.363997
epoch: 1644, train precision: 0.966711, train loss: 21.474347, valid precision: 0.851400, valid loss: 98.096367
epoch: 1645, train precision: 0.965422, train loss: 22.317947, valid precision: 0.850200, valid loss: 102.552884
epoch: 1646, train precision: 0.964333, train loss: 22.582273, valid precision: 0.844400, valid loss: 109.001854
epoch: 1647, train precision: 0.965089, train loss: 22.030497, valid precision: 0.846800, valid loss: 102.268513
epoch: 1648, train precision: 0.967356, train loss: 21.327057, valid precision: 0.853800, valid loss: 107.370293
epoch: 1649, train precision: 0.967511, train loss: 21.510500, valid precision: 0.852000, valid loss: 116.732192
epoch: 1650, train precision: 0.963600, train loss: 22.927009, valid precision: 0.848200, valid loss: 98.139024
epoch: 1651, train precision: 0.965756, train loss: 21.910492, valid precision: 0.848600, valid loss: 112.707401
epoch: 1652, train precision: 0.966178, train loss: 21.354168, valid precision: 0.849600, valid loss: 108.871884
epoch: 1653, train precision: 0.965111, train loss: 22.217058, valid precision: 0.847800, valid loss: 111.627572
epoch: 1654, train precision: 0.966667, train loss: 22.201821, valid precision: 0.842400, valid loss: 113.473658
epoch: 1655, train precision: 0.962711, train loss: 23.534219, valid precision: 0.843800, valid loss: 106.443002
epoch: 1656, train precision: 0.960578, train loss: 24.430586, valid precision: 0.848800, valid loss: 98.870004
epoch: 1657, train precision: 0.960978, train loss: 23.646145, valid precision: 0.847000, valid loss: 112.414767
epoch: 1658, train precision: 0.967289, train loss: 21.891205, valid precision: 0.852400, valid loss: 99.114339
epoch: 1659, train precision: 0.969022, train loss: 21.004459, valid precision: 0.849800, valid loss: 103.481671
epoch: 1660, train precision: 0.965422, train loss: 22.201717, valid precision: 0.848200, valid loss: 101.047362
epoch: 1661, train precision: 0.956133, train loss: 25.595037, valid precision: 0.848200, valid loss: 104.584818
epoch: 1662, train precision: 0.968733, train loss: 20.279179, valid precision: 0.848400, valid loss: 107.043042
epoch: 1663, train precision: 0.961711, train loss: 23.443055, valid precision: 0.851600, valid loss: 96.863623
epoch: 1664, train precision: 0.968089, train loss: 20.961183, valid precision: 0.851800, valid loss: 111.762058
epoch: 1665, train precision: 0.962756, train loss: 23.102953, valid precision: 0.848000, valid loss: 116.326473
epoch: 1666, train precision: 0.964689, train loss: 22.598402, valid precision: 0.845400, valid loss: 108.608877
epoch: 1667, train precision: 0.964844, train loss: 22.781848, valid precision: 0.851800, valid loss: 104.885704
epoch: 1668, train precision: 0.959978, train loss: 25.496119, valid precision: 0.848200, valid loss: 103.691705
epoch: 1669, train precision: 0.963511, train loss: 22.776742, valid precision: 0.851800, valid loss: 107.996768
epoch: 1670, train precision: 0.963489, train loss: 22.831949, valid precision: 0.851000, valid loss: 99.091277
epoch: 1671, train precision: 0.963311, train loss: 22.970080, valid precision: 0.850600, valid loss: 102.502666
epoch: 1672, train precision: 0.963689, train loss: 22.812889, valid precision: 0.849200, valid loss: 108.416845
epoch: 1673, train precision: 0.966400, train loss: 21.666484, valid precision: 0.852800, valid loss: 106.374406
epoch: 1674, train precision: 0.965867, train loss: 21.965597, valid precision: 0.854200, valid loss: 102.964402
epoch: 1675, train precision: 0.962533, train loss: 23.390580, valid precision: 0.852000, valid loss: 100.981475
epoch: 1676, train precision: 0.959400, train loss: 23.977089, valid precision: 0.847200, valid loss: 97.034061
epoch: 1677, train precision: 0.966156, train loss: 21.910858, valid precision: 0.848600, valid loss: 105.357458
epoch: 1678, train precision: 0.961467, train loss: 23.703558, valid precision: 0.848000, valid loss: 95.938787
epoch: 1679, train precision: 0.958467, train loss: 25.376172, valid precision: 0.845800, valid loss: 109.428246
epoch: 1680, train precision: 0.964244, train loss: 22.182095, valid precision: 0.850000, valid loss: 103.307057
epoch: 1681, train precision: 0.966978, train loss: 21.679509, valid precision: 0.851600, valid loss: 104.114601
epoch: 1682, train precision: 0.965222, train loss: 22.184582, valid precision: 0.851400, valid loss: 103.311081
epoch: 1683, train precision: 0.962644, train loss: 23.233324, valid precision: 0.847200, valid loss: 99.379437
epoch: 1684, train precision: 0.963156, train loss: 23.153299, valid precision: 0.849200, valid loss: 105.500144
epoch: 1685, train precision: 0.965400, train loss: 22.000951, valid precision: 0.851800, valid loss: 103.020526
epoch: 1686, train precision: 0.958911, train loss: 24.847206, valid precision: 0.846400, valid loss: 100.447595
epoch: 1687, train precision: 0.962467, train loss: 23.062640, valid precision: 0.849600, valid loss: 118.033274
epoch: 1688, train precision: 0.962289, train loss: 24.181615, valid precision: 0.851400, valid loss: 113.609542
epoch: 1689, train precision: 0.956111, train loss: 25.564788, valid precision: 0.840600, valid loss: 103.062551
epoch: 1690, train precision: 0.961733, train loss: 23.496575, valid precision: 0.851000, valid loss: 96.599261
epoch: 1691, train precision: 0.960422, train loss: 24.183976, valid precision: 0.850000, valid loss: 99.454650
epoch: 1692, train precision: 0.957911, train loss: 24.816098, valid precision: 0.849600, valid loss: 99.355186
epoch: 1693, train precision: 0.961978, train loss: 23.867507, valid precision: 0.849600, valid loss: 95.892802
epoch: 1694, train precision: 0.968133, train loss: 21.206377, valid precision: 0.850600, valid loss: 105.972167
epoch: 1695, train precision: 0.964244, train loss: 22.737647, valid precision: 0.848600, valid loss: 104.279294
epoch: 1696, train precision: 0.956556, train loss: 25.730189, valid precision: 0.842600, valid loss: 113.901657
epoch: 1697, train precision: 0.969111, train loss: 20.636587, valid precision: 0.853000, valid loss: 112.060414
epoch: 1698, train precision: 0.964933, train loss: 22.923927, valid precision: 0.853200, valid loss: 103.138805
epoch: 1699, train precision: 0.956178, train loss: 25.489835, valid precision: 0.849200, valid loss: 103.434277
epoch: 1700, train precision: 0.965556, train loss: 22.098544, valid precision: 0.853400, valid loss: 99.420703
epoch: 1701, train precision: 0.965756, train loss: 22.021205, valid precision: 0.851600, valid loss: 98.306219
epoch: 1702, train precision: 0.962844, train loss: 23.182869, valid precision: 0.848600, valid loss: 111.147342
epoch: 1703, train precision: 0.963778, train loss: 23.010896, valid precision: 0.853200, valid loss: 103.185232
epoch: 1704, train precision: 0.963222, train loss: 22.883867, valid precision: 0.851000, valid loss: 96.290539
epoch: 1705, train precision: 0.965911, train loss: 22.243952, valid precision: 0.847200, valid loss: 97.887207
epoch: 1706, train precision: 0.960467, train loss: 24.101263, valid precision: 0.850200, valid loss: 93.781038
epoch: 1707, train precision: 0.967222, train loss: 21.550423, valid precision: 0.851600, valid loss: 99.069119
epoch: 1708, train precision: 0.961978, train loss: 23.471501, valid precision: 0.852800, valid loss: 107.023755
epoch: 1709, train precision: 0.965733, train loss: 22.298803, valid precision: 0.852200, valid loss: 103.984711
epoch: 1710, train precision: 0.965289, train loss: 22.649163, valid precision: 0.848200, valid loss: 95.473262
epoch: 1711, train precision: 0.961244, train loss: 23.494737, valid precision: 0.856200, valid loss: 96.591750
epoch: 1712, train precision: 0.964756, train loss: 22.464603, valid precision: 0.851600, valid loss: 103.402417
epoch: 1713, train precision: 0.969244, train loss: 20.244823, valid precision: 0.858400, valid loss: 110.851700
epoch: 1714, train precision: 0.963289, train loss: 23.151560, valid precision: 0.847600, valid loss: 103.244378
epoch: 1715, train precision: 0.957533, train loss: 25.728335, valid precision: 0.849400, valid loss: 102.342483
epoch: 1716, train precision: 0.967667, train loss: 21.740148, valid precision: 0.856200, valid loss: 100.163450
epoch: 1717, train precision: 0.962067, train loss: 23.337683, valid precision: 0.847600, valid loss: 102.814227
epoch: 1718, train precision: 0.965844, train loss: 22.021555, valid precision: 0.848400, valid loss: 106.805406
epoch: 1719, train precision: 0.966111, train loss: 21.896906, valid precision: 0.853800, valid loss: 106.140982
epoch: 1720, train precision: 0.963978, train loss: 23.094501, valid precision: 0.848800, valid loss: 95.930705
epoch: 1721, train precision: 0.959489, train loss: 24.301442, valid precision: 0.846600, valid loss: 103.154102
epoch: 1722, train precision: 0.963333, train loss: 22.622992, valid precision: 0.850800, valid loss: 103.698399
epoch: 1723, train precision: 0.967133, train loss: 21.438559, valid precision: 0.853000, valid loss: 94.626174
epoch: 1724, train precision: 0.964356, train loss: 22.917747, valid precision: 0.852200, valid loss: 104.359378
epoch: 1725, train precision: 0.964956, train loss: 22.987287, valid precision: 0.853600, valid loss: 93.284527
epoch: 1726, train precision: 0.960111, train loss: 24.179190, valid precision: 0.850600, valid loss: 107.524091
epoch: 1727, train precision: 0.966733, train loss: 21.313069, valid precision: 0.853000, valid loss: 102.774426
epoch: 1728, train precision: 0.961600, train loss: 24.181537, valid precision: 0.848400, valid loss: 100.593589
epoch: 1729, train precision: 0.962089, train loss: 23.535515, valid precision: 0.850400, valid loss: 96.420201
epoch: 1730, train precision: 0.960844, train loss: 24.038201, valid precision: 0.843800, valid loss: 100.077891
epoch: 1731, train precision: 0.964111, train loss: 23.173397, valid precision: 0.853600, valid loss: 105.317342
epoch: 1732, train precision: 0.964600, train loss: 22.361127, valid precision: 0.856600, valid loss: 102.483122
epoch: 1733, train precision: 0.961556, train loss: 24.029877, valid precision: 0.856200, valid loss: 90.657401
epoch: 1734, train precision: 0.966044, train loss: 22.027816, valid precision: 0.854600, valid loss: 100.878452
epoch: 1735, train precision: 0.966111, train loss: 21.827799, valid precision: 0.854600, valid loss: 111.849838
epoch: 1736, train precision: 0.967244, train loss: 21.905818, valid precision: 0.854400, valid loss: 111.447930
epoch: 1737, train precision: 0.965533, train loss: 21.763914, valid precision: 0.851000, valid loss: 110.727318
epoch: 1738, train precision: 0.961489, train loss: 23.625958, valid precision: 0.848000, valid loss: 95.850245
epoch: 1739, train precision: 0.960289, train loss: 23.828856, valid precision: 0.853000, valid loss: 94.472119
epoch: 1740, train precision: 0.962667, train loss: 23.256603, valid precision: 0.851600, valid loss: 96.219514
epoch: 1741, train precision: 0.961089, train loss: 23.753365, valid precision: 0.854400, valid loss: 101.946157
epoch: 1742, train precision: 0.962156, train loss: 23.228322, valid precision: 0.849600, valid loss: 102.491453
epoch: 1743, train precision: 0.967778, train loss: 21.963170, valid precision: 0.857200, valid loss: 91.802579
epoch: 1744, train precision: 0.959889, train loss: 24.626528, valid precision: 0.848200, valid loss: 98.563467
epoch: 1745, train precision: 0.959089, train loss: 24.564935, valid precision: 0.848600, valid loss: 106.253915
epoch: 1746, train precision: 0.964978, train loss: 22.641464, valid precision: 0.848600, valid loss: 110.934752
epoch: 1747, train precision: 0.961022, train loss: 24.202909, valid precision: 0.842400, valid loss: 98.998203
epoch: 1748, train precision: 0.961533, train loss: 23.879992, valid precision: 0.852200, valid loss: 118.108279
epoch: 1749, train precision: 0.965711, train loss: 22.188629, valid precision: 0.855400, valid loss: 96.757538
epoch: 1750, train precision: 0.963711, train loss: 22.457842, valid precision: 0.852200, valid loss: 97.796533
epoch: 1751, train precision: 0.964356, train loss: 22.276932, valid precision: 0.852400, valid loss: 111.299994
epoch: 1752, train precision: 0.961711, train loss: 23.565033, valid precision: 0.849400, valid loss: 100.035982
epoch: 1753, train precision: 0.963222, train loss: 23.161818, valid precision: 0.845800, valid loss: 107.375925
epoch: 1754, train precision: 0.958622, train loss: 24.581147, valid precision: 0.848000, valid loss: 97.599303
epoch: 1755, train precision: 0.962644, train loss: 22.987490, valid precision: 0.847400, valid loss: 108.462050
epoch: 1756, train precision: 0.964067, train loss: 22.827511, valid precision: 0.849200, valid loss: 105.966919
epoch: 1757, train precision: 0.967089, train loss: 21.431922, valid precision: 0.853000, valid loss: 107.687000
epoch: 1758, train precision: 0.964933, train loss: 22.765359, valid precision: 0.852000, valid loss: 96.300994
epoch: 1759, train precision: 0.960156, train loss: 24.280523, valid precision: 0.849200, valid loss: 100.308290
epoch: 1760, train precision: 0.961356, train loss: 23.049187, valid precision: 0.852000, valid loss: 101.930436
epoch: 1761, train precision: 0.967822, train loss: 21.488531, valid precision: 0.855600, valid loss: 97.682212
epoch: 1762, train precision: 0.962578, train loss: 23.348862, valid precision: 0.848000, valid loss: 113.578178
epoch: 1763, train precision: 0.966133, train loss: 21.369527, valid precision: 0.853800, valid loss: 105.189521
epoch: 1764, train precision: 0.961244, train loss: 23.668999, valid precision: 0.848000, valid loss: 97.704027
epoch: 1765, train precision: 0.966578, train loss: 21.374581, valid precision: 0.853600, valid loss: 105.229031
epoch: 1766, train precision: 0.964822, train loss: 22.625339, valid precision: 0.845600, valid loss: 107.315776
epoch: 1767, train precision: 0.967000, train loss: 21.661644, valid precision: 0.854200, valid loss: 109.359061
epoch: 1768, train precision: 0.966711, train loss: 21.673178, valid precision: 0.855800, valid loss: 101.826896
epoch: 1769, train precision: 0.961133, train loss: 24.378757, valid precision: 0.852600, valid loss: 94.647646
epoch: 1770, train precision: 0.957200, train loss: 24.859110, valid precision: 0.845200, valid loss: 111.963084
epoch: 1771, train precision: 0.962267, train loss: 23.263934, valid precision: 0.849200, valid loss: 104.588289
epoch: 1772, train precision: 0.963800, train loss: 22.873845, valid precision: 0.854800, valid loss: 96.976673
epoch: 1773, train precision: 0.966533, train loss: 21.801864, valid precision: 0.852800, valid loss: 103.084247
epoch: 1774, train precision: 0.961000, train loss: 23.683953, valid precision: 0.848600, valid loss: 106.387407
epoch: 1775, train precision: 0.963333, train loss: 23.056485, valid precision: 0.847200, valid loss: 105.409629
epoch: 1776, train precision: 0.959444, train loss: 24.581753, valid precision: 0.847000, valid loss: 101.522291
epoch: 1777, train precision: 0.959556, train loss: 25.020953, valid precision: 0.846800, valid loss: 100.756865
epoch: 1778, train precision: 0.962778, train loss: 23.502380, valid precision: 0.851800, valid loss: 100.709735
epoch: 1779, train precision: 0.966578, train loss: 21.403076, valid precision: 0.851600, valid loss: 115.128328
epoch: 1780, train precision: 0.961978, train loss: 23.467403, valid precision: 0.848400, valid loss: 98.100935
epoch: 1781, train precision: 0.964778, train loss: 22.311862, valid precision: 0.847600, valid loss: 104.186816
epoch: 1782, train precision: 0.965467, train loss: 22.147871, valid precision: 0.854400, valid loss: 103.186147
epoch: 1783, train precision: 0.961889, train loss: 23.880656, valid precision: 0.849400, valid loss: 101.719305
epoch: 1784, train precision: 0.965200, train loss: 22.176844, valid precision: 0.852200, valid loss: 101.017620
epoch: 1785, train precision: 0.960133, train loss: 24.345346, valid precision: 0.851400, valid loss: 99.840332
epoch: 1786, train precision: 0.965889, train loss: 21.698093, valid precision: 0.851600, valid loss: 108.429933
epoch: 1787, train precision: 0.954933, train loss: 26.370238, valid precision: 0.839000, valid loss: 102.231069
epoch: 1788, train precision: 0.963578, train loss: 22.890345, valid precision: 0.851600, valid loss: 109.525957
epoch: 1789, train precision: 0.965733, train loss: 21.910099, valid precision: 0.855200, valid loss: 103.221120
epoch: 1790, train precision: 0.963889, train loss: 22.841024, valid precision: 0.851400, valid loss: 110.925369
epoch: 1791, train precision: 0.960644, train loss: 23.619472, valid precision: 0.848000, valid loss: 105.581303
epoch: 1792, train precision: 0.962378, train loss: 23.614459, valid precision: 0.847600, valid loss: 98.382581
epoch: 1793, train precision: 0.963467, train loss: 22.636871, valid precision: 0.852600, valid loss: 107.680052
epoch: 1794, train precision: 0.960089, train loss: 24.474844, valid precision: 0.842400, valid loss: 101.792772
epoch: 1795, train precision: 0.966933, train loss: 21.280438, valid precision: 0.857800, valid loss: 101.219977
epoch: 1796, train precision: 0.965467, train loss: 22.046556, valid precision: 0.854600, valid loss: 105.476204
epoch: 1797, train precision: 0.963489, train loss: 22.396651, valid precision: 0.854600, valid loss: 108.845926
epoch: 1798, train precision: 0.963222, train loss: 22.838530, valid precision: 0.851000, valid loss: 106.245873
epoch: 1799, train precision: 0.962556, train loss: 23.326227, valid precision: 0.847800, valid loss: 99.776353
epoch: 1800, train precision: 0.957800, train loss: 24.710428, valid precision: 0.851800, valid loss: 99.072937
epoch: 1801, train precision: 0.967022, train loss: 21.914292, valid precision: 0.853600, valid loss: 101.125955
epoch: 1802, train precision: 0.961778, train loss: 23.246794, valid precision: 0.854600, valid loss: 97.557638
epoch: 1803, train precision: 0.962000, train loss: 23.244326, valid precision: 0.852600, valid loss: 103.526505
epoch: 1804, train precision: 0.958822, train loss: 24.684077, valid precision: 0.851800, valid loss: 97.567442
epoch: 1805, train precision: 0.958956, train loss: 24.342248, valid precision: 0.850600, valid loss: 94.825078
epoch: 1806, train precision: 0.960933, train loss: 23.834985, valid precision: 0.850400, valid loss: 94.691060
epoch: 1807, train precision: 0.962089, train loss: 23.058589, valid precision: 0.849200, valid loss: 102.487051
epoch: 1808, train precision: 0.964600, train loss: 22.752696, valid precision: 0.853200, valid loss: 98.507529
epoch: 1809, train precision: 0.962689, train loss: 22.722500, valid precision: 0.852800, valid loss: 105.269384
epoch: 1810, train precision: 0.961489, train loss: 23.036420, valid precision: 0.854800, valid loss: 105.304859
epoch: 1811, train precision: 0.965289, train loss: 21.970217, valid precision: 0.853800, valid loss: 101.189619
epoch: 1812, train precision: 0.952911, train loss: 26.192651, valid precision: 0.843000, valid loss: 107.127393
epoch: 1813, train precision: 0.962578, train loss: 22.848224, valid precision: 0.847600, valid loss: 100.893490
epoch: 1814, train precision: 0.959556, train loss: 24.108404, valid precision: 0.845800, valid loss: 106.915069
epoch: 1815, train precision: 0.966911, train loss: 21.640402, valid precision: 0.854400, valid loss: 103.144493
epoch: 1816, train precision: 0.965756, train loss: 21.805901, valid precision: 0.855200, valid loss: 94.864036
epoch: 1817, train precision: 0.963489, train loss: 23.070237, valid precision: 0.848000, valid loss: 110.760371
epoch: 1818, train precision: 0.952400, train loss: 27.679806, valid precision: 0.844000, valid loss: 96.724126
epoch: 1819, train precision: 0.960178, train loss: 24.501527, valid precision: 0.845200, valid loss: 98.758038
epoch: 1820, train precision: 0.963289, train loss: 22.476233, valid precision: 0.851400, valid loss: 106.717254
epoch: 1821, train precision: 0.965044, train loss: 22.212633, valid precision: 0.850400, valid loss: 104.393926
epoch: 1822, train precision: 0.964622, train loss: 22.825173, valid precision: 0.855600, valid loss: 100.733769
epoch: 1823, train precision: 0.965978, train loss: 21.820638, valid precision: 0.854600, valid loss: 103.922396
epoch: 1824, train precision: 0.967978, train loss: 20.972616, valid precision: 0.855400, valid loss: 100.523599
epoch: 1825, train precision: 0.960956, train loss: 23.888430, valid precision: 0.851600, valid loss: 93.529982
epoch: 1826, train precision: 0.959867, train loss: 24.301494, valid precision: 0.848400, valid loss: 100.007986
epoch: 1827, train precision: 0.958022, train loss: 24.634837, valid precision: 0.845000, valid loss: 100.909669
epoch: 1828, train precision: 0.966378, train loss: 21.668283, valid precision: 0.852800, valid loss: 102.843981
epoch: 1829, train precision: 0.963933, train loss: 22.152117, valid precision: 0.856000, valid loss: 110.452078
epoch: 1830, train precision: 0.958800, train loss: 24.738276, valid precision: 0.848600, valid loss: 100.228294
epoch: 1831, train precision: 0.959689, train loss: 24.424750, valid precision: 0.849000, valid loss: 100.404917
epoch: 1832, train precision: 0.964511, train loss: 22.601436, valid precision: 0.851400, valid loss: 94.462522
epoch: 1833, train precision: 0.964689, train loss: 22.081559, valid precision: 0.848600, valid loss: 105.403605
epoch: 1834, train precision: 0.966667, train loss: 21.792169, valid precision: 0.851400, valid loss: 103.953769
epoch: 1835, train precision: 0.960022, train loss: 24.530508, valid precision: 0.849600, valid loss: 110.545298
epoch: 1836, train precision: 0.962267, train loss: 23.562991, valid precision: 0.850400, valid loss: 99.379164
epoch: 1837, train precision: 0.963400, train loss: 22.934627, valid precision: 0.854400, valid loss: 105.092315
epoch: 1838, train precision: 0.955622, train loss: 25.954574, valid precision: 0.849000, valid loss: 104.251780
epoch: 1839, train precision: 0.964244, train loss: 22.266176, valid precision: 0.850400, valid loss: 101.597672
epoch: 1840, train precision: 0.964267, train loss: 22.148250, valid precision: 0.847400, valid loss: 102.254917
epoch: 1841, train precision: 0.964533, train loss: 22.321043, valid precision: 0.846800, valid loss: 98.610248
epoch: 1842, train precision: 0.965311, train loss: 22.389694, valid precision: 0.851400, valid loss: 119.781854
epoch: 1843, train precision: 0.963022, train loss: 22.644172, valid precision: 0.849400, valid loss: 103.839535
epoch: 1844, train precision: 0.960644, train loss: 24.802820, valid precision: 0.850200, valid loss: 97.507923
epoch: 1845, train precision: 0.962356, train loss: 23.476345, valid precision: 0.851400, valid loss: 101.834338
epoch: 1846, train precision: 0.963800, train loss: 22.611136, valid precision: 0.847800, valid loss: 113.309548
epoch: 1847, train precision: 0.966133, train loss: 21.917335, valid precision: 0.851400, valid loss: 102.506850
epoch: 1848, train precision: 0.960733, train loss: 23.206555, valid precision: 0.848800, valid loss: 110.274325
epoch: 1849, train precision: 0.960733, train loss: 24.384901, valid precision: 0.851800, valid loss: 101.477720
epoch: 1850, train precision: 0.966533, train loss: 21.640686, valid precision: 0.855800, valid loss: 97.632317
epoch: 1851, train precision: 0.963511, train loss: 23.054628, valid precision: 0.851000, valid loss: 99.371013
epoch: 1852, train precision: 0.958844, train loss: 24.616939, valid precision: 0.847400, valid loss: 111.921957
epoch: 1853, train precision: 0.964133, train loss: 22.163553, valid precision: 0.850800, valid loss: 116.309568
epoch: 1854, train precision: 0.959533, train loss: 24.432617, valid precision: 0.842800, valid loss: 107.020722
epoch: 1855, train precision: 0.963778, train loss: 22.431756, valid precision: 0.847400, valid loss: 102.807977
epoch: 1856, train precision: 0.967822, train loss: 21.328379, valid precision: 0.859800, valid loss: 103.522287
epoch: 1857, train precision: 0.964000, train loss: 22.542470, valid precision: 0.857200, valid loss: 104.337004
epoch: 1858, train precision: 0.963356, train loss: 22.997004, valid precision: 0.856000, valid loss: 96.201093
epoch: 1859, train precision: 0.964756, train loss: 22.622431, valid precision: 0.854800, valid loss: 111.430152
epoch: 1860, train precision: 0.958178, train loss: 23.859756, valid precision: 0.854400, valid loss: 97.500092
epoch: 1861, train precision: 0.955867, train loss: 25.982807, valid precision: 0.848400, valid loss: 100.177590
epoch: 1862, train precision: 0.964244, train loss: 22.385174, valid precision: 0.847000, valid loss: 105.085554
epoch: 1863, train precision: 0.963378, train loss: 22.705969, valid precision: 0.849200, valid loss: 96.564411
epoch: 1864, train precision: 0.959156, train loss: 24.643324, valid precision: 0.845600, valid loss: 98.126510
epoch: 1865, train precision: 0.960000, train loss: 24.057355, valid precision: 0.847000, valid loss: 104.877955
epoch: 1866, train precision: 0.962778, train loss: 23.133918, valid precision: 0.845600, valid loss: 108.341920
epoch: 1867, train precision: 0.954844, train loss: 26.204073, valid precision: 0.847400, valid loss: 94.947061
epoch: 1868, train precision: 0.964600, train loss: 21.956692, valid precision: 0.853600, valid loss: 94.366047
epoch: 1869, train precision: 0.965200, train loss: 21.725975, valid precision: 0.855000, valid loss: 107.981780
epoch: 1870, train precision: 0.963667, train loss: 23.056377, valid precision: 0.851800, valid loss: 103.003557
epoch: 1871, train precision: 0.955356, train loss: 25.720638, valid precision: 0.844800, valid loss: 105.349003
epoch: 1872, train precision: 0.962333, train loss: 23.129579, valid precision: 0.854400, valid loss: 100.153757
epoch: 1873, train precision: 0.963600, train loss: 23.124286, valid precision: 0.849400, valid loss: 107.627200
epoch: 1874, train precision: 0.960689, train loss: 23.777585, valid precision: 0.842400, valid loss: 99.970666
epoch: 1875, train precision: 0.957956, train loss: 25.116614, valid precision: 0.847800, valid loss: 91.410520
epoch: 1876, train precision: 0.964222, train loss: 21.962818, valid precision: 0.852000, valid loss: 100.712735
epoch: 1877, train precision: 0.958067, train loss: 25.037930, valid precision: 0.851200, valid loss: 93.623625
epoch: 1878, train precision: 0.962067, train loss: 23.005192, valid precision: 0.851200, valid loss: 101.591069
epoch: 1879, train precision: 0.962556, train loss: 23.343947, valid precision: 0.849800, valid loss: 100.192155
epoch: 1880, train precision: 0.963044, train loss: 22.999331, valid precision: 0.850800, valid loss: 105.130357
epoch: 1881, train precision: 0.964889, train loss: 21.931819, valid precision: 0.857800, valid loss: 104.995557
epoch: 1882, train precision: 0.966711, train loss: 21.100741, valid precision: 0.854000, valid loss: 103.477994
epoch: 1883, train precision: 0.962911, train loss: 22.679408, valid precision: 0.853000, valid loss: 102.040271
epoch: 1884, train precision: 0.961067, train loss: 23.753378, valid precision: 0.855800, valid loss: 99.591221
epoch: 1885, train precision: 0.958400, train loss: 24.770975, valid precision: 0.844600, valid loss: 103.484594
epoch: 1886, train precision: 0.964111, train loss: 22.136611, valid precision: 0.852000, valid loss: 98.590577
epoch: 1887, train precision: 0.961533, train loss: 23.678871, valid precision: 0.850000, valid loss: 95.043741
epoch: 1888, train precision: 0.963044, train loss: 23.496448, valid precision: 0.851000, valid loss: 102.404079
epoch: 1889, train precision: 0.955956, train loss: 25.606082, valid precision: 0.843000, valid loss: 111.065837
epoch: 1890, train precision: 0.958822, train loss: 24.377939, valid precision: 0.853000, valid loss: 94.602164
epoch: 1891, train precision: 0.961111, train loss: 23.989344, valid precision: 0.846000, valid loss: 100.267193
epoch: 1892, train precision: 0.963356, train loss: 23.158933, valid precision: 0.851400, valid loss: 115.016980
epoch: 1893, train precision: 0.959622, train loss: 23.803705, valid precision: 0.847200, valid loss: 101.795546
epoch: 1894, train precision: 0.960711, train loss: 23.902703, valid precision: 0.847200, valid loss: 108.285386
epoch: 1895, train precision: 0.955978, train loss: 25.529795, valid precision: 0.848200, valid loss: 109.052060
epoch: 1896, train precision: 0.956511, train loss: 25.216065, valid precision: 0.841800, valid loss: 102.734850
epoch: 1897, train precision: 0.952289, train loss: 27.025776, valid precision: 0.847400, valid loss: 105.249511
epoch: 1898, train precision: 0.963133, train loss: 22.048488, valid precision: 0.849000, valid loss: 101.456248
epoch: 1899, train precision: 0.958778, train loss: 24.068849, valid precision: 0.849000, valid loss: 103.204189
epoch: 1900, train precision: 0.965400, train loss: 22.451250, valid precision: 0.849400, valid loss: 100.119042
epoch: 1901, train precision: 0.963378, train loss: 22.413709, valid precision: 0.849400, valid loss: 107.213132
epoch: 1902, train precision: 0.959311, train loss: 23.887292, valid precision: 0.847400, valid loss: 112.066249
epoch: 1903, train precision: 0.963289, train loss: 22.538519, valid precision: 0.849600, valid loss: 106.504865
epoch: 1904, train precision: 0.965578, train loss: 21.241727, valid precision: 0.849200, valid loss: 108.018776
epoch: 1905, train precision: 0.962978, train loss: 22.619352, valid precision: 0.851400, valid loss: 108.885710
epoch: 1906, train precision: 0.962333, train loss: 23.709669, valid precision: 0.850000, valid loss: 98.577070
epoch: 1907, train precision: 0.962644, train loss: 22.998088, valid precision: 0.848800, valid loss: 99.696473
epoch: 1908, train precision: 0.965044, train loss: 21.874622, valid precision: 0.846000, valid loss: 112.242070
epoch: 1909, train precision: 0.957756, train loss: 24.711314, valid precision: 0.846000, valid loss: 106.630546
epoch: 1910, train precision: 0.964044, train loss: 22.694032, valid precision: 0.854400, valid loss: 100.820612
epoch: 1911, train precision: 0.967267, train loss: 21.150144, valid precision: 0.845000, valid loss: 108.499598
epoch: 1912, train precision: 0.960111, train loss: 23.702807, valid precision: 0.847000, valid loss: 104.140952
epoch: 1913, train precision: 0.962467, train loss: 22.607156, valid precision: 0.847800, valid loss: 105.466003
epoch: 1914, train precision: 0.963778, train loss: 22.411004, valid precision: 0.851000, valid loss: 108.195615
epoch: 1915, train precision: 0.956178, train loss: 25.409847, valid precision: 0.847400, valid loss: 100.833631
epoch: 1916, train precision: 0.964844, train loss: 21.839694, valid precision: 0.851800, valid loss: 109.536744
epoch: 1917, train precision: 0.961911, train loss: 22.919114, valid precision: 0.850400, valid loss: 102.136978
epoch: 1918, train precision: 0.961356, train loss: 23.313950, valid precision: 0.851000, valid loss: 109.908605
epoch: 1919, train precision: 0.960800, train loss: 23.787394, valid precision: 0.844400, valid loss: 101.252083
epoch: 1920, train precision: 0.963578, train loss: 22.697374, valid precision: 0.846200, valid loss: 104.087791
epoch: 1921, train precision: 0.960400, train loss: 23.700555, valid precision: 0.848400, valid loss: 105.979504
epoch: 1922, train precision: 0.962022, train loss: 22.711249, valid precision: 0.851000, valid loss: 100.132756
epoch: 1923, train precision: 0.956778, train loss: 25.113394, valid precision: 0.846600, valid loss: 102.053350
epoch: 1924, train precision: 0.960111, train loss: 24.224008, valid precision: 0.847400, valid loss: 96.676631
epoch: 1925, train precision: 0.959689, train loss: 23.169773, valid precision: 0.848200, valid loss: 99.127338
epoch: 1926, train precision: 0.960622, train loss: 23.404077, valid precision: 0.847800, valid loss: 100.149364
epoch: 1927, train precision: 0.964356, train loss: 21.729396, valid precision: 0.855200, valid loss: 95.000179
epoch: 1928, train precision: 0.956911, train loss: 24.638813, valid precision: 0.847200, valid loss: 100.826916
epoch: 1929, train precision: 0.959689, train loss: 23.839662, valid precision: 0.850000, valid loss: 111.478476
epoch: 1930, train precision: 0.961822, train loss: 22.683480, valid precision: 0.853400, valid loss: 99.195689
epoch: 1931, train precision: 0.960822, train loss: 23.832292, valid precision: 0.848200, valid loss: 100.839363
epoch: 1932, train precision: 0.965689, train loss: 21.989615, valid precision: 0.851800, valid loss: 104.573293
epoch: 1933, train precision: 0.964356, train loss: 22.267201, valid precision: 0.847800, valid loss: 100.620872
epoch: 1934, train precision: 0.960156, train loss: 24.259081, valid precision: 0.847800, valid loss: 99.857404
epoch: 1935, train precision: 0.959933, train loss: 24.257361, valid precision: 0.845000, valid loss: 102.109290
epoch: 1936, train precision: 0.959644, train loss: 24.031487, valid precision: 0.852400, valid loss: 106.596846
epoch: 1937, train precision: 0.966267, train loss: 21.206372, valid precision: 0.855400, valid loss: 105.933720
epoch: 1938, train precision: 0.956511, train loss: 24.855040, valid precision: 0.844800, valid loss: 102.923289
epoch: 1939, train precision: 0.963000, train loss: 23.200671, valid precision: 0.853800, valid loss: 97.608833
epoch: 1940, train precision: 0.957578, train loss: 24.797762, valid precision: 0.852200, valid loss: 97.708869
epoch: 1941, train precision: 0.962400, train loss: 23.075573, valid precision: 0.847800, valid loss: 105.820531
epoch: 1942, train precision: 0.959889, train loss: 24.341589, valid precision: 0.850400, valid loss: 95.791829
epoch: 1943, train precision: 0.964133, train loss: 22.309555, valid precision: 0.850400, valid loss: 101.722555
epoch: 1944, train precision: 0.965400, train loss: 21.753555, valid precision: 0.852400, valid loss: 103.723663
epoch: 1945, train precision: 0.959978, train loss: 24.204086, valid precision: 0.847000, valid loss: 103.586116
epoch: 1946, train precision: 0.959244, train loss: 24.006013, valid precision: 0.851000, valid loss: 109.668118
epoch: 1947, train precision: 0.954022, train loss: 26.391000, valid precision: 0.844200, valid loss: 100.981918
epoch: 1948, train precision: 0.965978, train loss: 21.929964, valid precision: 0.853200, valid loss: 96.217866
epoch: 1949, train precision: 0.960400, train loss: 24.106999, valid precision: 0.853400, valid loss: 94.006707
epoch: 1950, train precision: 0.964711, train loss: 21.877092, valid precision: 0.852000, valid loss: 106.212626
epoch: 1951, train precision: 0.967022, train loss: 21.243329, valid precision: 0.850800, valid loss: 102.533007
epoch: 1952, train precision: 0.964267, train loss: 22.021183, valid precision: 0.851400, valid loss: 104.737508
epoch: 1953, train precision: 0.957067, train loss: 25.022166, valid precision: 0.848800, valid loss: 104.852804
epoch: 1954, train precision: 0.955867, train loss: 25.900260, valid precision: 0.840800, valid loss: 118.331901
epoch: 1955, train precision: 0.962622, train loss: 23.085890, valid precision: 0.847800, valid loss: 105.166145
epoch: 1956, train precision: 0.957756, train loss: 24.355398, valid precision: 0.845200, valid loss: 110.911692
epoch: 1957, train precision: 0.965911, train loss: 21.268771, valid precision: 0.853000, valid loss: 99.888743
epoch: 1958, train precision: 0.958889, train loss: 23.682964, valid precision: 0.844800, valid loss: 113.255763
epoch: 1959, train precision: 0.962244, train loss: 23.370166, valid precision: 0.842400, valid loss: 102.583324
epoch: 1960, train precision: 0.963111, train loss: 22.987817, valid precision: 0.847600, valid loss: 100.419909
epoch: 1961, train precision: 0.964844, train loss: 21.684228, valid precision: 0.851400, valid loss: 107.073832
epoch: 1962, train precision: 0.963467, train loss: 22.004997, valid precision: 0.846200, valid loss: 117.588096
epoch: 1963, train precision: 0.967222, train loss: 21.377116, valid precision: 0.850200, valid loss: 107.979609
epoch: 1964, train precision: 0.962511, train loss: 23.027674, valid precision: 0.850800, valid loss: 110.503221
epoch: 1965, train precision: 0.959644, train loss: 23.612924, valid precision: 0.847000, valid loss: 103.541758
epoch: 1966, train precision: 0.960044, train loss: 24.194718, valid precision: 0.850400, valid loss: 94.186678
epoch: 1967, train precision: 0.966000, train loss: 21.680484, valid precision: 0.855800, valid loss: 100.437675
epoch: 1968, train precision: 0.964444, train loss: 21.619183, valid precision: 0.850200, valid loss: 105.657548
epoch: 1969, train precision: 0.963511, train loss: 22.409841, valid precision: 0.844600, valid loss: 113.406184
epoch: 1970, train precision: 0.957467, train loss: 24.406176, valid precision: 0.844600, valid loss: 103.160052
epoch: 1971, train precision: 0.956244, train loss: 25.474012, valid precision: 0.838800, valid loss: 109.550410
epoch: 1972, train precision: 0.963689, train loss: 22.226923, valid precision: 0.852200, valid loss: 107.867497
epoch: 1973, train precision: 0.961756, train loss: 23.008228, valid precision: 0.851000, valid loss: 95.035688
epoch: 1974, train precision: 0.961044, train loss: 23.016129, valid precision: 0.846800, valid loss: 103.268570
epoch: 1975, train precision: 0.960600, train loss: 24.063420, valid precision: 0.848600, valid loss: 100.313498
epoch: 1976, train precision: 0.963644, train loss: 21.890176, valid precision: 0.851600, valid loss: 105.489916
epoch: 1977, train precision: 0.955978, train loss: 25.300300, valid precision: 0.843600, valid loss: 101.570602
epoch: 1978, train precision: 0.964489, train loss: 22.157834, valid precision: 0.845000, valid loss: 110.877858
epoch: 1979, train precision: 0.960000, train loss: 23.964281, valid precision: 0.844200, valid loss: 96.223567
epoch: 1980, train precision: 0.961844, train loss: 23.342663, valid precision: 0.842200, valid loss: 114.197800
epoch: 1981, train precision: 0.960933, train loss: 23.597014, valid precision: 0.848000, valid loss: 107.533274
epoch: 1982, train precision: 0.961422, train loss: 22.961966, valid precision: 0.847000, valid loss: 107.072053
epoch: 1983, train precision: 0.962178, train loss: 22.655301, valid precision: 0.846200, valid loss: 100.676826
epoch: 1984, train precision: 0.963000, train loss: 22.927618, valid precision: 0.847400, valid loss: 105.863405
epoch: 1985, train precision: 0.962578, train loss: 22.726766, valid precision: 0.848600, valid loss: 106.020342
epoch: 1986, train precision: 0.962000, train loss: 23.023453, valid precision: 0.850800, valid loss: 98.862885
epoch: 1987, train precision: 0.954600, train loss: 25.624200, valid precision: 0.846400, valid loss: 98.369655
epoch: 1988, train precision: 0.964600, train loss: 21.958067, valid precision: 0.850000, valid loss: 100.747798
epoch: 1989, train precision: 0.966267, train loss: 21.984329, valid precision: 0.848800, valid loss: 112.104192
epoch: 1990, train precision: 0.962556, train loss: 22.935165, valid precision: 0.849200, valid loss: 96.899655
epoch: 1991, train precision: 0.963267, train loss: 23.042466, valid precision: 0.849800, valid loss: 97.085991
epoch: 1992, train precision: 0.958800, train loss: 24.172076, valid precision: 0.851200, valid loss: 103.527522
epoch: 1993, train precision: 0.962511, train loss: 22.817218, valid precision: 0.849800, valid loss: 100.275325
epoch: 1994, train precision: 0.962444, train loss: 22.555903, valid precision: 0.849800, valid loss: 101.382169
epoch: 1995, train precision: 0.960911, train loss: 23.063678, valid precision: 0.847600, valid loss: 102.575284
epoch: 1996, train precision: 0.961378, train loss: 23.364252, valid precision: 0.852800, valid loss: 108.503786
epoch: 1997, train precision: 0.959044, train loss: 24.248751, valid precision: 0.845000, valid loss: 98.613200
epoch: 1998, train precision: 0.967222, train loss: 20.954834, valid precision: 0.853400, valid loss: 106.556091
epoch: 1999, train precision: 0.961867, train loss: 22.653398, valid precision: 0.849800, valid loss: 98.172592
epoch: 2000, train precision: 0.962089, train loss: 23.275103, valid precision: 0.847200, valid loss: 98.430654
epoch: 2001, train precision: 0.964778, train loss: 21.360291, valid precision: 0.848600, valid loss: 103.946807
epoch: 2002, train precision: 0.958533, train loss: 24.407416, valid precision: 0.850600, valid loss: 99.537000
epoch: 2003, train precision: 0.964533, train loss: 22.006584, valid precision: 0.848200, valid loss: 101.101097
epoch: 2004, train precision: 0.960578, train loss: 23.280783, valid precision: 0.850800, valid loss: 100.220855
epoch: 2005, train precision: 0.965533, train loss: 21.806532, valid precision: 0.850000, valid loss: 96.366431
epoch: 2006, train precision: 0.964911, train loss: 21.696318, valid precision: 0.855000, valid loss: 99.963463
epoch: 2007, train precision: 0.956156, train loss: 25.816845, valid precision: 0.843600, valid loss: 99.003757
epoch: 2008, train precision: 0.960133, train loss: 23.736055, valid precision: 0.847000, valid loss: 103.928776
epoch: 2009, train precision: 0.961911, train loss: 23.049419, valid precision: 0.855600, valid loss: 109.676857
epoch: 2010, train precision: 0.956222, train loss: 24.873825, valid precision: 0.849600, valid loss: 106.537824
epoch: 2011, train precision: 0.960111, train loss: 23.589948, valid precision: 0.851400, valid loss: 100.961998
epoch: 2012, train precision: 0.960644, train loss: 24.115238, valid precision: 0.843800, valid loss: 101.473735
epoch: 2013, train precision: 0.965578, train loss: 22.319256, valid precision: 0.844000, valid loss: 108.465083
epoch: 2014, train precision: 0.959622, train loss: 23.580313, valid precision: 0.846800, valid loss: 99.754622
epoch: 2015, train precision: 0.964578, train loss: 21.619636, valid precision: 0.851000, valid loss: 108.181032
epoch: 2016, train precision: 0.960933, train loss: 23.209599, valid precision: 0.850600, valid loss: 101.660677
epoch: 2017, train precision: 0.959733, train loss: 23.884362, valid precision: 0.844400, valid loss: 97.782007
epoch: 2018, train precision: 0.964022, train loss: 22.535265, valid precision: 0.849800, valid loss: 99.787140
epoch: 2019, train precision: 0.957889, train loss: 24.579851, valid precision: 0.845000, valid loss: 96.388540
epoch: 2020, train precision: 0.951578, train loss: 27.062090, valid precision: 0.842000, valid loss: 100.615131
epoch: 2021, train precision: 0.962911, train loss: 22.722500, valid precision: 0.849000, valid loss: 94.679113
epoch: 2022, train precision: 0.957556, train loss: 24.469485, valid precision: 0.842400, valid loss: 120.940961
epoch: 2023, train precision: 0.957889, train loss: 24.505949, valid precision: 0.843200, valid loss: 104.377792
epoch: 2024, train precision: 0.958289, train loss: 23.831926, valid precision: 0.849400, valid loss: 100.250201
epoch: 2025, train precision: 0.961622, train loss: 23.347578, valid precision: 0.850000, valid loss: 96.980405
epoch: 2026, train precision: 0.958556, train loss: 24.440917, valid precision: 0.846800, valid loss: 104.972815
epoch: 2027, train precision: 0.957156, train loss: 24.910778, valid precision: 0.843800, valid loss: 112.333245
epoch: 2028, train precision: 0.959222, train loss: 24.268492, valid precision: 0.843400, valid loss: 94.789213
epoch: 2029, train precision: 0.964578, train loss: 22.030592, valid precision: 0.851400, valid loss: 94.659824
epoch: 2030, train precision: 0.958467, train loss: 25.315643, valid precision: 0.847400, valid loss: 99.568846
epoch: 2031, train precision: 0.960244, train loss: 23.478653, valid precision: 0.843600, valid loss: 99.102595
epoch: 2032, train precision: 0.955800, train loss: 25.525806, valid precision: 0.847800, valid loss: 103.936968
epoch: 2033, train precision: 0.956044, train loss: 24.649618, valid precision: 0.846000, valid loss: 98.746854
epoch: 2034, train precision: 0.961800, train loss: 22.619662, valid precision: 0.854200, valid loss: 100.533681
epoch: 2035, train precision: 0.955911, train loss: 25.590047, valid precision: 0.844400, valid loss: 98.877434
epoch: 2036, train precision: 0.964133, train loss: 22.407433, valid precision: 0.850400, valid loss: 101.895806
epoch: 2037, train precision: 0.963444, train loss: 22.464986, valid precision: 0.848000, valid loss: 100.831322
epoch: 2038, train precision: 0.960200, train loss: 23.548042, valid precision: 0.847400, valid loss: 106.276141
epoch: 2039, train precision: 0.956622, train loss: 24.999194, valid precision: 0.843800, valid loss: 99.202354
epoch: 2040, train precision: 0.957489, train loss: 24.671322, valid precision: 0.853600, valid loss: 98.348495
epoch: 2041, train precision: 0.957422, train loss: 24.688251, valid precision: 0.849000, valid loss: 95.784994
epoch: 2042, train precision: 0.965822, train loss: 21.688827, valid precision: 0.851600, valid loss: 99.648534
epoch: 2043, train precision: 0.957822, train loss: 24.473380, valid precision: 0.846200, valid loss: 103.154102
epoch: 2044, train precision: 0.955556, train loss: 25.438773, valid precision: 0.844600, valid loss: 96.851600
epoch: 2045, train precision: 0.956467, train loss: 25.108658, valid precision: 0.847200, valid loss: 96.482599
epoch: 2046, train precision: 0.959978, train loss: 23.710078, valid precision: 0.850000, valid loss: 102.974506
epoch: 2047, train precision: 0.963267, train loss: 22.323099, valid precision: 0.854200, valid loss: 103.493129
epoch: 2048, train precision: 0.958244, train loss: 24.450391, valid precision: 0.843200, valid loss: 91.152183
epoch: 2049, train precision: 0.955822, train loss: 24.990462, valid precision: 0.839400, valid loss: 96.203347
epoch: 2050, train precision: 0.956356, train loss: 25.491751, valid precision: 0.845400, valid loss: 112.189624
epoch: 2051, train precision: 0.957333, train loss: 25.404330, valid precision: 0.847000, valid loss: 93.668138
epoch: 2052, train precision: 0.959178, train loss: 23.957409, valid precision: 0.848400, valid loss: 95.667267
epoch: 2053, train precision: 0.960867, train loss: 23.386129, valid precision: 0.850400, valid loss: 97.924561
epoch: 2054, train precision: 0.957378, train loss: 24.863607, valid precision: 0.847400, valid loss: 102.043916
epoch: 2055, train precision: 0.960289, train loss: 23.360571, valid precision: 0.848200, valid loss: 111.477451
epoch: 2056, train precision: 0.956511, train loss: 24.569138, valid precision: 0.848200, valid loss: 104.450657
epoch: 2057, train precision: 0.958422, train loss: 24.047542, valid precision: 0.841400, valid loss: 109.470840
epoch: 2058, train precision: 0.959222, train loss: 23.921390, valid precision: 0.842200, valid loss: 104.122399
epoch: 2059, train precision: 0.956956, train loss: 25.113230, valid precision: 0.845000, valid loss: 98.615249
epoch: 2060, train precision: 0.959622, train loss: 24.094660, valid precision: 0.839000, valid loss: 98.827178
epoch: 2061, train precision: 0.959089, train loss: 23.855062, valid precision: 0.847600, valid loss: 108.240181
epoch: 2062, train precision: 0.963067, train loss: 22.321828, valid precision: 0.851600, valid loss: 98.881724
epoch: 2063, train precision: 0.964356, train loss: 21.552571, valid precision: 0.853600, valid loss: 110.395705
epoch: 2064, train precision: 0.955511, train loss: 24.392092, valid precision: 0.847800, valid loss: 105.158268
epoch: 2065, train precision: 0.959289, train loss: 24.783260, valid precision: 0.849400, valid loss: 94.710612
epoch: 2066, train precision: 0.957711, train loss: 24.417808, valid precision: 0.844400, valid loss: 100.128200
epoch: 2067, train precision: 0.962644, train loss: 22.423886, valid precision: 0.846800, valid loss: 110.629397
epoch: 2068, train precision: 0.963867, train loss: 22.215701, valid precision: 0.850000, valid loss: 102.225986
epoch: 2069, train precision: 0.960711, train loss: 23.663334, valid precision: 0.848400, valid loss: 102.170491
epoch: 2070, train precision: 0.958800, train loss: 23.735832, valid precision: 0.842400, valid loss: 104.518155
epoch: 2071, train precision: 0.956333, train loss: 24.806755, valid precision: 0.845800, valid loss: 104.984589
epoch: 2072, train precision: 0.960200, train loss: 23.365666, valid precision: 0.846200, valid loss: 103.858724
epoch: 2073, train precision: 0.963178, train loss: 22.317538, valid precision: 0.852200, valid loss: 99.188474
epoch: 2074, train precision: 0.960489, train loss: 23.483066, valid precision: 0.847600, valid loss: 98.198295
epoch: 2075, train precision: 0.959444, train loss: 23.437665, valid precision: 0.852600, valid loss: 103.655919
epoch: 2076, train precision: 0.953600, train loss: 26.235379, valid precision: 0.846400, valid loss: 91.066637
epoch: 2077, train precision: 0.965156, train loss: 21.823740, valid precision: 0.855600, valid loss: 97.550116
epoch: 2078, train precision: 0.954889, train loss: 25.317299, valid precision: 0.848600, valid loss: 111.395081
epoch: 2079, train precision: 0.959733, train loss: 23.346635, valid precision: 0.850200, valid loss: 100.256068
epoch: 2080, train precision: 0.961822, train loss: 23.637812, valid precision: 0.853200, valid loss: 103.937473
epoch: 2081, train precision: 0.955600, train loss: 25.867450, valid precision: 0.844200, valid loss: 97.417605
epoch: 2082, train precision: 0.958511, train loss: 24.110828, valid precision: 0.844600, valid loss: 105.713709
epoch: 2083, train precision: 0.961378, train loss: 23.072631, valid precision: 0.852800, valid loss: 112.043443
epoch: 2084, train precision: 0.957867, train loss: 24.859947, valid precision: 0.848600, valid loss: 101.589649
epoch: 2085, train precision: 0.958933, train loss: 24.194667, valid precision: 0.851600, valid loss: 99.383636
epoch: 2086, train precision: 0.961667, train loss: 23.176087, valid precision: 0.845600, valid loss: 98.620805
epoch: 2087, train precision: 0.964111, train loss: 22.020559, valid precision: 0.851600, valid loss: 96.811096
epoch: 2088, train precision: 0.961022, train loss: 23.421101, valid precision: 0.853000, valid loss: 98.711370
epoch: 2089, train precision: 0.959933, train loss: 23.102730, valid precision: 0.852800, valid loss: 99.904819
epoch: 2090, train precision: 0.958889, train loss: 24.028930, valid precision: 0.851200, valid loss: 95.083752
epoch: 2091, train precision: 0.956867, train loss: 24.265266, valid precision: 0.850200, valid loss: 95.844558
epoch: 2092, train precision: 0.964356, train loss: 21.944438, valid precision: 0.846600, valid loss: 101.933655
epoch: 2093, train precision: 0.962222, train loss: 22.796932, valid precision: 0.847800, valid loss: 99.680055
epoch: 2094, train precision: 0.963511, train loss: 22.278274, valid precision: 0.854200, valid loss: 103.584538
epoch: 2095, train precision: 0.961844, train loss: 23.013710, valid precision: 0.847600, valid loss: 98.955450
epoch: 2096, train precision: 0.963756, train loss: 21.928084, valid precision: 0.852200, valid loss: 107.909710
epoch: 2097, train precision: 0.954867, train loss: 25.521899, valid precision: 0.846600, valid loss: 97.360482
epoch: 2098, train precision: 0.957289, train loss: 24.117689, valid precision: 0.849000, valid loss: 99.235378
epoch: 2099, train precision: 0.962444, train loss: 22.712366, valid precision: 0.852400, valid loss: 94.707379
epoch: 2100, train precision: 0.958556, train loss: 23.679298, valid precision: 0.851200, valid loss: 104.727171
epoch: 2101, train precision: 0.961156, train loss: 22.894234, valid precision: 0.853000, valid loss: 103.134626
epoch: 2102, train precision: 0.958822, train loss: 24.186398, valid precision: 0.848400, valid loss: 97.313081
epoch: 2103, train precision: 0.953733, train loss: 25.860259, valid precision: 0.845600, valid loss: 100.115433
epoch: 2104, train precision: 0.959578, train loss: 23.441974, valid precision: 0.847000, valid loss: 100.265546
epoch: 2105, train precision: 0.963711, train loss: 21.901562, valid precision: 0.853400, valid loss: 103.492405
epoch: 2106, train precision: 0.960933, train loss: 22.836572, valid precision: 0.854600, valid loss: 98.907293
epoch: 2107, train precision: 0.959600, train loss: 23.682077, valid precision: 0.845400, valid loss: 95.517826
epoch: 2108, train precision: 0.961267, train loss: 22.886905, valid precision: 0.851800, valid loss: 102.344842
epoch: 2109, train precision: 0.960378, train loss: 23.425865, valid precision: 0.847800, valid loss: 104.021311
epoch: 2110, train precision: 0.965089, train loss: 21.702892, valid precision: 0.849200, valid loss: 109.796234
epoch: 2111, train precision: 0.961600, train loss: 22.619976, valid precision: 0.853200, valid loss: 101.323719
epoch: 2112, train precision: 0.960467, train loss: 23.385487, valid precision: 0.846800, valid loss: 99.695598
epoch: 2113, train precision: 0.960778, train loss: 23.706715, valid precision: 0.848600, valid loss: 98.801334
epoch: 2114, train precision: 0.967311, train loss: 20.586986, valid precision: 0.856400, valid loss: 106.665198
epoch: 2115, train precision: 0.961622, train loss: 23.074168, valid precision: 0.846800, valid loss: 105.461601
epoch: 2116, train precision: 0.962022, train loss: 22.789095, valid precision: 0.845000, valid loss: 111.264430
epoch: 2117, train precision: 0.963533, train loss: 22.069802, valid precision: 0.850800, valid loss: 100.894948
epoch: 2118, train precision: 0.957911, train loss: 24.418269, valid precision: 0.843600, valid loss: 96.603707
epoch: 2119, train precision: 0.959822, train loss: 23.956433, valid precision: 0.851200, valid loss: 95.674045
epoch: 2120, train precision: 0.962178, train loss: 22.603390, valid precision: 0.854200, valid loss: 99.201543
epoch: 2121, train precision: 0.953511, train loss: 26.513197, valid precision: 0.847800, valid loss: 94.786582
epoch: 2122, train precision: 0.959444, train loss: 23.506923, valid precision: 0.848600, valid loss: 107.237312
epoch: 2123, train precision: 0.962333, train loss: 22.444469, valid precision: 0.853800, valid loss: 105.865407
epoch: 2124, train precision: 0.956156, train loss: 25.188209, valid precision: 0.847800, valid loss: 101.636653
epoch: 2125, train precision: 0.956733, train loss: 24.565410, valid precision: 0.842200, valid loss: 110.527471
epoch: 2126, train precision: 0.960689, train loss: 23.430218, valid precision: 0.846200, valid loss: 105.734985
epoch: 2127, train precision: 0.962356, train loss: 23.036456, valid precision: 0.846000, valid loss: 94.456853
epoch: 2128, train precision: 0.951867, train loss: 26.203978, valid precision: 0.844600, valid loss: 99.010530
epoch: 2129, train precision: 0.955600, train loss: 24.813024, valid precision: 0.844600, valid loss: 105.668669
epoch: 2130, train precision: 0.960622, train loss: 23.576127, valid precision: 0.842000, valid loss: 98.506430
epoch: 2131, train precision: 0.961222, train loss: 23.059551, valid precision: 0.849200, valid loss: 104.078557
epoch: 2132, train precision: 0.957400, train loss: 24.257272, valid precision: 0.843800, valid loss: 108.615428
epoch: 2133, train precision: 0.959378, train loss: 23.414404, valid precision: 0.848600, valid loss: 104.280520
epoch: 2134, train precision: 0.963311, train loss: 22.134232, valid precision: 0.853400, valid loss: 96.784264
epoch: 2135, train precision: 0.966511, train loss: 20.548210, valid precision: 0.853000, valid loss: 99.840144
epoch: 2136, train precision: 0.956756, train loss: 24.463485, valid precision: 0.843800, valid loss: 102.175571
epoch: 2137, train precision: 0.950267, train loss: 27.085413, valid precision: 0.841000, valid loss: 98.916028
epoch: 2138, train precision: 0.959756, train loss: 23.255980, valid precision: 0.850400, valid loss: 101.166852
epoch: 2139, train precision: 0.962711, train loss: 22.689100, valid precision: 0.846800, valid loss: 107.877007
epoch: 2140, train precision: 0.961956, train loss: 22.897637, valid precision: 0.849800, valid loss: 102.835550
epoch: 2141, train precision: 0.962356, train loss: 22.027211, valid precision: 0.845400, valid loss: 104.242959
epoch: 2142, train precision: 0.958000, train loss: 24.320755, valid precision: 0.850400, valid loss: 99.607725
epoch: 2143, train precision: 0.954800, train loss: 25.481069, valid precision: 0.849400, valid loss: 104.096847
epoch: 2144, train precision: 0.964822, train loss: 21.241299, valid precision: 0.852600, valid loss: 99.670359
epoch: 2145, train precision: 0.957333, train loss: 24.841889, valid precision: 0.848000, valid loss: 105.320272
epoch: 2146, train precision: 0.967867, train loss: 20.394121, valid precision: 0.856400, valid loss: 104.061119
epoch: 2147, train precision: 0.959156, train loss: 24.247152, valid precision: 0.845600, valid loss: 106.928807
epoch: 2148, train precision: 0.963067, train loss: 22.228105, valid precision: 0.853400, valid loss: 100.504015
epoch: 2149, train precision: 0.956689, train loss: 24.496802, valid precision: 0.846200, valid loss: 103.936883
epoch: 2150, train precision: 0.963556, train loss: 22.044431, valid precision: 0.843600, valid loss: 102.535517
epoch: 2151, train precision: 0.962644, train loss: 22.852206, valid precision: 0.850400, valid loss: 98.077678
epoch: 2152, train precision: 0.960578, train loss: 22.803838, valid precision: 0.850600, valid loss: 99.168339
epoch: 2153, train precision: 0.960600, train loss: 23.272298, valid precision: 0.846600, valid loss: 92.963227
epoch: 2154, train precision: 0.958956, train loss: 23.937207, valid precision: 0.845200, valid loss: 100.215594
epoch: 2155, train precision: 0.961133, train loss: 22.696985, valid precision: 0.848200, valid loss: 91.757835
epoch: 2156, train precision: 0.961222, train loss: 22.679080, valid precision: 0.852800, valid loss: 105.561275
epoch: 2157, train precision: 0.958733, train loss: 24.240118, valid precision: 0.848400, valid loss: 99.178780
epoch: 2158, train precision: 0.965400, train loss: 21.115900, valid precision: 0.853800, valid loss: 99.359836
epoch: 2159, train precision: 0.964311, train loss: 21.820172, valid precision: 0.853600, valid loss: 108.999070
epoch: 2160, train precision: 0.957889, train loss: 24.149879, valid precision: 0.851400, valid loss: 97.687863
epoch: 2161, train precision: 0.957111, train loss: 24.127992, valid precision: 0.848400, valid loss: 98.594206
epoch: 2162, train precision: 0.960822, train loss: 23.377541, valid precision: 0.849400, valid loss: 103.878072
epoch: 2163, train precision: 0.962711, train loss: 22.333462, valid precision: 0.847200, valid loss: 98.352586
epoch: 2164, train precision: 0.959444, train loss: 23.979041, valid precision: 0.846800, valid loss: 93.531569
epoch: 2165, train precision: 0.959111, train loss: 23.946161, valid precision: 0.845800, valid loss: 101.154065
epoch: 2166, train precision: 0.961111, train loss: 23.334960, valid precision: 0.849600, valid loss: 105.866092
epoch: 2167, train precision: 0.962378, train loss: 22.494793, valid precision: 0.846800, valid loss: 105.172798
epoch: 2168, train precision: 0.956978, train loss: 24.034075, valid precision: 0.847200, valid loss: 94.826531
epoch: 2169, train precision: 0.959511, train loss: 23.625663, valid precision: 0.850200, valid loss: 103.451243
epoch: 2170, train precision: 0.963111, train loss: 22.266673, valid precision: 0.847800, valid loss: 103.259345
epoch: 2171, train precision: 0.960511, train loss: 24.036351, valid precision: 0.842000, valid loss: 96.020493
epoch: 2172, train precision: 0.960111, train loss: 23.735162, valid precision: 0.851400, valid loss: 98.593769
epoch: 2173, train precision: 0.962267, train loss: 22.643772, valid precision: 0.847000, valid loss: 108.271919
epoch: 2174, train precision: 0.950933, train loss: 26.960576, valid precision: 0.841400, valid loss: 102.405297
epoch: 2175, train precision: 0.962822, train loss: 21.746782, valid precision: 0.855400, valid loss: 108.758887
epoch: 2176, train precision: 0.957489, train loss: 24.281867, valid precision: 0.844600, valid loss: 105.162898
epoch: 2177, train precision: 0.956089, train loss: 24.618479, valid precision: 0.847000, valid loss: 92.894605
epoch: 2178, train precision: 0.961800, train loss: 22.458550, valid precision: 0.851000, valid loss: 103.694044
epoch: 2179, train precision: 0.962600, train loss: 22.637527, valid precision: 0.845000, valid loss: 101.251555
epoch: 2180, train precision: 0.965289, train loss: 21.389328, valid precision: 0.852400, valid loss: 107.282228
epoch: 2181, train precision: 0.953444, train loss: 25.418656, valid precision: 0.852400, valid loss: 107.850574
epoch: 2182, train precision: 0.954556, train loss: 25.875788, valid precision: 0.849400, valid loss: 92.502031
epoch: 2183, train precision: 0.962244, train loss: 22.627565, valid precision: 0.854000, valid loss: 100.124860
epoch: 2184, train precision: 0.961222, train loss: 22.876328, valid precision: 0.847400, valid loss: 98.287707
epoch: 2185, train precision: 0.955111, train loss: 25.516236, valid precision: 0.844400, valid loss: 106.843591
epoch: 2186, train precision: 0.958689, train loss: 23.614885, valid precision: 0.850800, valid loss: 95.091032
epoch: 2187, train precision: 0.956956, train loss: 23.767345, valid precision: 0.849600, valid loss: 103.298527
epoch: 2188, train precision: 0.953089, train loss: 26.586711, valid precision: 0.847600, valid loss: 88.642819
epoch: 2189, train precision: 0.957000, train loss: 24.730744, valid precision: 0.847000, valid loss: 95.183073
epoch: 2190, train precision: 0.959756, train loss: 23.384023, valid precision: 0.845600, valid loss: 96.589493
epoch: 2191, train precision: 0.962156, train loss: 22.364470, valid precision: 0.850800, valid loss: 100.558043
epoch: 2192, train precision: 0.964622, train loss: 21.580623, valid precision: 0.848600, valid loss: 105.269248
epoch: 2193, train precision: 0.958800, train loss: 24.251859, valid precision: 0.850200, valid loss: 103.100239
epoch: 2194, train precision: 0.959778, train loss: 23.275485, valid precision: 0.846600, valid loss: 104.694937
epoch: 2195, train precision: 0.958311, train loss: 23.953037, valid precision: 0.848600, valid loss: 90.384868
epoch: 2196, train precision: 0.962533, train loss: 22.506884, valid precision: 0.851600, valid loss: 97.724257
epoch: 2197, train precision: 0.959422, train loss: 23.294515, valid precision: 0.846200, valid loss: 98.335383
epoch: 2198, train precision: 0.960867, train loss: 23.650078, valid precision: 0.847600, valid loss: 107.843741
epoch: 2199, train precision: 0.959844, train loss: 23.104291, valid precision: 0.853000, valid loss: 106.198511
epoch: 2200, train precision: 0.964156, train loss: 21.962789, valid precision: 0.850200, valid loss: 98.123758
epoch: 2201, train precision: 0.963778, train loss: 22.114301, valid precision: 0.853000, valid loss: 98.791902
epoch: 2202, train precision: 0.960578, train loss: 23.231199, valid precision: 0.853400, valid loss: 97.554666
epoch: 2203, train precision: 0.958467, train loss: 23.786658, valid precision: 0.852400, valid loss: 91.142712
epoch: 2204, train precision: 0.963600, train loss: 21.792774, valid precision: 0.859200, valid loss: 97.810042
epoch: 2205, train precision: 0.955156, train loss: 24.572840, valid precision: 0.850800, valid loss: 102.873970
epoch: 2206, train precision: 0.963667, train loss: 21.814074, valid precision: 0.857800, valid loss: 96.376950
epoch: 2207, train precision: 0.958911, train loss: 23.820245, valid precision: 0.845000, valid loss: 99.543863
epoch: 2208, train precision: 0.962267, train loss: 22.234407, valid precision: 0.848400, valid loss: 102.404343
epoch: 2209, train precision: 0.947600, train loss: 28.278621, valid precision: 0.843000, valid loss: 97.325708
epoch: 2210, train precision: 0.961111, train loss: 22.954753, valid precision: 0.850600, valid loss: 97.384230
epoch: 2211, train precision: 0.954133, train loss: 25.802290, valid precision: 0.845200, valid loss: 96.632163
epoch: 2212, train precision: 0.960889, train loss: 23.489022, valid precision: 0.845400, valid loss: 100.071101
epoch: 2213, train precision: 0.959511, train loss: 24.434058, valid precision: 0.849000, valid loss: 102.225780
epoch: 2214, train precision: 0.953956, train loss: 25.677101, valid precision: 0.844600, valid loss: 95.534010
epoch: 2215, train precision: 0.963756, train loss: 22.297100, valid precision: 0.849000, valid loss: 102.495681
epoch: 2216, train precision: 0.959067, train loss: 24.091634, valid precision: 0.846200, valid loss: 103.627552
epoch: 2217, train precision: 0.962689, train loss: 21.774951, valid precision: 0.847400, valid loss: 106.276502
epoch: 2218, train precision: 0.954578, train loss: 24.849409, valid precision: 0.847200, valid loss: 104.092057
epoch: 2219, train precision: 0.953222, train loss: 26.035306, valid precision: 0.845000, valid loss: 96.511948
epoch: 2220, train precision: 0.960822, train loss: 23.009510, valid precision: 0.850800, valid loss: 103.431473
epoch: 2221, train precision: 0.958778, train loss: 24.481429, valid precision: 0.843600, valid loss: 94.386119
epoch: 2222, train precision: 0.962067, train loss: 22.579115, valid precision: 0.851400, valid loss: 110.063405
epoch: 2223, train precision: 0.959822, train loss: 23.408352, valid precision: 0.847400, valid loss: 105.215436
epoch: 2224, train precision: 0.955822, train loss: 24.806261, valid precision: 0.846800, valid loss: 95.449112
epoch: 2225, train precision: 0.960000, train loss: 22.683198, valid precision: 0.851800, valid loss: 106.160275
epoch: 2226, train precision: 0.956622, train loss: 24.408157, valid precision: 0.846400, valid loss: 100.054403
epoch: 2227, train precision: 0.958467, train loss: 24.014560, valid precision: 0.846800, valid loss: 94.031352
epoch: 2228, train precision: 0.964889, train loss: 21.513545, valid precision: 0.854000, valid loss: 101.700711
epoch: 2229, train precision: 0.949111, train loss: 27.435393, valid precision: 0.843000, valid loss: 95.306720
epoch: 2230, train precision: 0.962156, train loss: 22.467951, valid precision: 0.851200, valid loss: 98.852103
epoch: 2231, train precision: 0.961200, train loss: 22.418249, valid precision: 0.849200, valid loss: 100.983917
epoch: 2232, train precision: 0.961178, train loss: 22.828839, valid precision: 0.850000, valid loss: 104.953791
epoch: 2233, train precision: 0.962444, train loss: 22.724911, valid precision: 0.852200, valid loss: 99.050969
epoch: 2234, train precision: 0.956533, train loss: 24.844538, valid precision: 0.848600, valid loss: 103.083526
epoch: 2235, train precision: 0.956644, train loss: 25.076060, valid precision: 0.845200, valid loss: 100.564189
epoch: 2236, train precision: 0.950600, train loss: 27.271334, valid precision: 0.837600, valid loss: 106.692212
epoch: 2237, train precision: 0.955289, train loss: 24.968308, valid precision: 0.843200, valid loss: 94.473074
epoch: 2238, train precision: 0.957689, train loss: 24.005977, valid precision: 0.847200, valid loss: 98.288174
epoch: 2239, train precision: 0.960467, train loss: 23.526434, valid precision: 0.850800, valid loss: 95.555845
epoch: 2240, train precision: 0.958933, train loss: 23.309553, valid precision: 0.845000, valid loss: 101.988096
epoch: 2241, train precision: 0.954133, train loss: 25.806524, valid precision: 0.842000, valid loss: 100.584100
epoch: 2242, train precision: 0.958889, train loss: 23.722870, valid precision: 0.855400, valid loss: 102.420032
epoch: 2243, train precision: 0.960778, train loss: 22.635120, valid precision: 0.847800, valid loss: 104.320935
epoch: 2244, train precision: 0.958356, train loss: 23.573840, valid precision: 0.854800, valid loss: 98.221866
epoch: 2245, train precision: 0.957756, train loss: 23.779825, valid precision: 0.844200, valid loss: 98.549823
epoch: 2246, train precision: 0.962756, train loss: 22.294424, valid precision: 0.851200, valid loss: 97.218503
epoch: 2247, train precision: 0.962711, train loss: 22.235900, valid precision: 0.854200, valid loss: 98.574627
epoch: 2248, train precision: 0.951622, train loss: 26.836698, valid precision: 0.837200, valid loss: 101.053891
epoch: 2249, train precision: 0.954578, train loss: 24.808927, valid precision: 0.852000, valid loss: 98.746257
epoch: 2250, train precision: 0.954667, train loss: 25.409007, valid precision: 0.843400, valid loss: 104.868793
epoch: 2251, train precision: 0.961556, train loss: 22.342351, valid precision: 0.849800, valid loss: 102.749769
epoch: 2252, train precision: 0.962289, train loss: 22.088237, valid precision: 0.851600, valid loss: 99.418025
epoch: 2253, train precision: 0.959822, train loss: 23.574464, valid precision: 0.844600, valid loss: 97.862216
epoch: 2254, train precision: 0.960511, train loss: 22.858704, valid precision: 0.850800, valid loss: 91.492968
epoch: 2255, train precision: 0.959844, train loss: 23.040326, valid precision: 0.848000, valid loss: 99.856098
epoch: 2256, train precision: 0.959156, train loss: 23.448890, valid precision: 0.852600, valid loss: 96.346754
epoch: 2257, train precision: 0.960556, train loss: 22.755284, valid precision: 0.851200, valid loss: 100.414724
epoch: 2258, train precision: 0.959533, train loss: 23.160818, valid precision: 0.847200, valid loss: 99.830005
epoch: 2259, train precision: 0.960067, train loss: 23.336846, valid precision: 0.851200, valid loss: 110.418350
epoch: 2260, train precision: 0.954489, train loss: 24.943111, valid precision: 0.850200, valid loss: 100.606635
epoch: 2261, train precision: 0.961356, train loss: 22.615017, valid precision: 0.849600, valid loss: 101.781195
epoch: 2262, train precision: 0.957133, train loss: 24.319739, valid precision: 0.847600, valid loss: 103.007041
epoch: 2263, train precision: 0.959911, train loss: 23.030456, valid precision: 0.850000, valid loss: 99.495386
epoch: 2264, train precision: 0.959222, train loss: 22.727618, valid precision: 0.846600, valid loss: 101.471204
epoch: 2265, train precision: 0.960311, train loss: 23.499468, valid precision: 0.855600, valid loss: 98.368034
epoch: 2266, train precision: 0.954489, train loss: 24.783236, valid precision: 0.846400, valid loss: 102.323690
epoch: 2267, train precision: 0.960867, train loss: 22.589183, valid precision: 0.853200, valid loss: 96.466145
epoch: 2268, train precision: 0.960356, train loss: 23.034349, valid precision: 0.851000, valid loss: 103.473213
epoch: 2269, train precision: 0.954178, train loss: 25.140174, valid precision: 0.846200, valid loss: 93.978162
epoch: 2270, train precision: 0.963378, train loss: 21.599724, valid precision: 0.856400, valid loss: 107.117683
epoch: 2271, train precision: 0.960533, train loss: 22.975653, valid precision: 0.853600, valid loss: 97.068152
epoch: 2272, train precision: 0.961578, train loss: 22.833571, valid precision: 0.854400, valid loss: 98.737906
epoch: 2273, train precision: 0.956689, train loss: 24.384905, valid precision: 0.853000, valid loss: 90.007021
epoch: 2274, train precision: 0.957956, train loss: 23.774514, valid precision: 0.849000, valid loss: 96.342676
epoch: 2275, train precision: 0.954933, train loss: 25.439271, valid precision: 0.847000, valid loss: 99.835847
epoch: 2276, train precision: 0.956600, train loss: 23.880835, valid precision: 0.849000, valid loss: 99.062214
epoch: 2277, train precision: 0.958444, train loss: 23.246306, valid precision: 0.852400, valid loss: 100.817684
epoch: 2278, train precision: 0.962711, train loss: 22.027257, valid precision: 0.852600, valid loss: 105.785171
epoch: 2279, train precision: 0.958867, train loss: 23.537901, valid precision: 0.846200, valid loss: 103.314459
epoch: 2280, train precision: 0.957222, train loss: 23.400535, valid precision: 0.851400, valid loss: 101.245034
epoch: 2281, train precision: 0.962378, train loss: 21.976774, valid precision: 0.850600, valid loss: 98.315601
epoch: 2282, train precision: 0.962156, train loss: 22.404672, valid precision: 0.855400, valid loss: 101.698394
epoch: 2283, train precision: 0.960867, train loss: 23.002519, valid precision: 0.851600, valid loss: 112.824386
epoch: 2284, train precision: 0.956578, train loss: 24.430928, valid precision: 0.845800, valid loss: 101.554445
epoch: 2285, train precision: 0.963222, train loss: 21.500390, valid precision: 0.854800, valid loss: 94.109200
epoch: 2286, train precision: 0.958644, train loss: 23.701717, valid precision: 0.850400, valid loss: 110.653819
epoch: 2287, train precision: 0.964556, train loss: 21.015756, valid precision: 0.857600, valid loss: 114.690580
epoch: 2288, train precision: 0.956089, train loss: 25.112511, valid precision: 0.846800, valid loss: 99.222308
epoch: 2289, train precision: 0.958200, train loss: 23.738226, valid precision: 0.849400, valid loss: 106.158491
epoch: 2290, train precision: 0.959556, train loss: 22.996006, valid precision: 0.844000, valid loss: 102.202951
epoch: 2291, train precision: 0.956422, train loss: 24.771741, valid precision: 0.846400, valid loss: 99.654574
epoch: 2292, train precision: 0.952711, train loss: 25.794840, valid precision: 0.844000, valid loss: 103.588737
epoch: 2293, train precision: 0.957044, train loss: 24.309962, valid precision: 0.840400, valid loss: 105.205839
epoch: 2294, train precision: 0.960156, train loss: 23.136418, valid precision: 0.852600, valid loss: 107.949109
epoch: 2295, train precision: 0.953000, train loss: 25.982000, valid precision: 0.841200, valid loss: 94.147239
epoch: 2296, train precision: 0.951978, train loss: 26.375301, valid precision: 0.844400, valid loss: 91.112298
epoch: 2297, train precision: 0.958089, train loss: 24.184948, valid precision: 0.851800, valid loss: 92.789413
epoch: 2298, train precision: 0.956444, train loss: 23.963196, valid precision: 0.844200, valid loss: 102.126094
epoch: 2299, train precision: 0.961089, train loss: 22.177943, valid precision: 0.848400, valid loss: 95.310575
epoch: 2300, train precision: 0.959111, train loss: 23.732851, valid precision: 0.849000, valid loss: 97.810311
epoch: 2301, train precision: 0.962400, train loss: 22.634926, valid precision: 0.848600, valid loss: 95.732865
epoch: 2302, train precision: 0.957933, train loss: 23.950514, valid precision: 0.844000, valid loss: 101.325980
epoch: 2303, train precision: 0.959289, train loss: 22.823330, valid precision: 0.851000, valid loss: 106.172212
epoch: 2304, train precision: 0.959200, train loss: 23.523315, valid precision: 0.847000, valid loss: 98.787453
epoch: 2305, train precision: 0.947200, train loss: 28.773715, valid precision: 0.839000, valid loss: 110.718688
epoch: 2306, train precision: 0.958822, train loss: 24.194504, valid precision: 0.847800, valid loss: 106.092401
epoch: 2307, train precision: 0.959289, train loss: 23.341737, valid precision: 0.846800, valid loss: 101.945877
epoch: 2308, train precision: 0.957311, train loss: 24.063873, valid precision: 0.842800, valid loss: 102.757976
epoch: 2309, train precision: 0.962156, train loss: 21.901673, valid precision: 0.854400, valid loss: 98.777287
epoch: 2310, train precision: 0.958933, train loss: 23.316436, valid precision: 0.848200, valid loss: 98.036841
epoch: 2311, train precision: 0.959311, train loss: 23.144379, valid precision: 0.846200, valid loss: 96.721016
epoch: 2312, train precision: 0.961378, train loss: 22.921904, valid precision: 0.848200, valid loss: 106.590897
epoch: 2313, train precision: 0.959689, train loss: 23.161312, valid precision: 0.850200, valid loss: 106.690145
epoch: 2314, train precision: 0.961756, train loss: 22.495197, valid precision: 0.846800, valid loss: 103.445764
epoch: 2315, train precision: 0.960467, train loss: 22.587395, valid precision: 0.848800, valid loss: 98.375561
epoch: 2316, train precision: 0.950578, train loss: 26.915852, valid precision: 0.844800, valid loss: 104.237908
epoch: 2317, train precision: 0.961778, train loss: 22.272821, valid precision: 0.846600, valid loss: 108.245085
epoch: 2318, train precision: 0.957089, train loss: 24.279073, valid precision: 0.847200, valid loss: 93.964657
epoch: 2319, train precision: 0.957356, train loss: 23.584101, valid precision: 0.854400, valid loss: 93.806766
epoch: 2320, train precision: 0.964956, train loss: 21.034829, valid precision: 0.852800, valid loss: 100.284331
epoch: 2321, train precision: 0.960889, train loss: 22.522179, valid precision: 0.849000, valid loss: 102.699023
epoch: 2322, train precision: 0.954267, train loss: 24.906956, valid precision: 0.845600, valid loss: 101.104178
epoch: 2323, train precision: 0.958067, train loss: 23.820924, valid precision: 0.847400, valid loss: 97.693645
epoch: 2324, train precision: 0.961200, train loss: 22.832116, valid precision: 0.843400, valid loss: 99.457319
epoch: 2325, train precision: 0.957222, train loss: 24.307934, valid precision: 0.849800, valid loss: 93.861499
epoch: 2326, train precision: 0.959178, train loss: 22.838025, valid precision: 0.852800, valid loss: 101.415358
epoch: 2327, train precision: 0.958422, train loss: 23.533611, valid precision: 0.851200, valid loss: 104.021653
epoch: 2328, train precision: 0.961089, train loss: 22.776012, valid precision: 0.850000, valid loss: 95.647102
epoch: 2329, train precision: 0.960422, train loss: 22.731941, valid precision: 0.848200, valid loss: 105.995808
epoch: 2330, train precision: 0.956200, train loss: 24.022730, valid precision: 0.842200, valid loss: 103.924654
epoch: 2331, train precision: 0.954156, train loss: 25.257961, valid precision: 0.840600, valid loss: 102.129171
epoch: 2332, train precision: 0.960156, train loss: 22.987983, valid precision: 0.850400, valid loss: 102.327393
epoch: 2333, train precision: 0.960156, train loss: 22.892639, valid precision: 0.849200, valid loss: 106.819991
epoch: 2334, train precision: 0.956378, train loss: 23.946132, valid precision: 0.849200, valid loss: 102.085305
epoch: 2335, train precision: 0.960578, train loss: 22.632413, valid precision: 0.850800, valid loss: 93.112810
epoch: 2336, train precision: 0.955800, train loss: 24.735913, valid precision: 0.849400, valid loss: 104.110735
epoch: 2337, train precision: 0.958756, train loss: 23.778331, valid precision: 0.854400, valid loss: 102.874875
epoch: 2338, train precision: 0.959556, train loss: 22.452766, valid precision: 0.851000, valid loss: 102.088792
epoch: 2339, train precision: 0.962044, train loss: 22.367577, valid precision: 0.852600, valid loss: 102.261439
epoch: 2340, train precision: 0.959511, train loss: 23.406024, valid precision: 0.844400, valid loss: 105.323645
epoch: 2341, train precision: 0.958467, train loss: 23.521234, valid precision: 0.846200, valid loss: 101.957415
epoch: 2342, train precision: 0.961422, train loss: 22.227938, valid precision: 0.848600, valid loss: 114.660423
epoch: 2343, train precision: 0.954222, train loss: 24.932540, valid precision: 0.841000, valid loss: 104.453073
epoch: 2344, train precision: 0.959089, train loss: 23.580957, valid precision: 0.848800, valid loss: 92.207257
epoch: 2345, train precision: 0.953422, train loss: 25.343614, valid precision: 0.844400, valid loss: 100.953735
epoch: 2346, train precision: 0.957600, train loss: 23.763062, valid precision: 0.845200, valid loss: 104.257629
epoch: 2347, train precision: 0.958467, train loss: 23.419638, valid precision: 0.846000, valid loss: 99.649696
epoch: 2348, train precision: 0.954822, train loss: 24.919188, valid precision: 0.845200, valid loss: 98.252603
epoch: 2349, train precision: 0.960156, train loss: 23.025160, valid precision: 0.844600, valid loss: 101.013238
epoch: 2350, train precision: 0.954533, train loss: 24.710070, valid precision: 0.845400, valid loss: 102.956690
epoch: 2351, train precision: 0.956556, train loss: 24.248640, valid precision: 0.851600, valid loss: 105.796170
epoch: 2352, train precision: 0.961111, train loss: 22.225886, valid precision: 0.849400, valid loss: 96.910933
epoch: 2353, train precision: 0.956756, train loss: 24.417679, valid precision: 0.846600, valid loss: 93.085052
epoch: 2354, train precision: 0.959378, train loss: 23.075626, valid precision: 0.847800, valid loss: 100.603656
epoch: 2355, train precision: 0.960756, train loss: 22.650036, valid precision: 0.851800, valid loss: 103.698813
epoch: 2356, train precision: 0.953200, train loss: 25.629246, valid precision: 0.843800, valid loss: 102.104138
epoch: 2357, train precision: 0.956689, train loss: 24.332748, valid precision: 0.844600, valid loss: 96.118586
epoch: 2358, train precision: 0.963933, train loss: 21.458813, valid precision: 0.849800, valid loss: 106.100259
epoch: 2359, train precision: 0.958444, train loss: 23.490575, valid precision: 0.851200, valid loss: 97.215583
epoch: 2360, train precision: 0.953356, train loss: 26.215796, valid precision: 0.844000, valid loss: 101.374806
epoch: 2361, train precision: 0.959467, train loss: 22.619481, valid precision: 0.848400, valid loss: 100.528058
epoch: 2362, train precision: 0.953356, train loss: 25.151225, valid precision: 0.849400, valid loss: 104.513787
epoch: 2363, train precision: 0.958444, train loss: 23.466289, valid precision: 0.851600, valid loss: 98.543621
epoch: 2364, train precision: 0.959311, train loss: 22.804809, valid precision: 0.853200, valid loss: 98.185879
epoch: 2365, train precision: 0.954933, train loss: 24.680567, valid precision: 0.849200, valid loss: 92.254416
epoch: 2366, train precision: 0.957756, train loss: 23.516769, valid precision: 0.848800, valid loss: 106.794487
epoch: 2367, train precision: 0.959489, train loss: 23.293991, valid precision: 0.852600, valid loss: 98.752791
epoch: 2368, train precision: 0.959844, train loss: 22.939926, valid precision: 0.851200, valid loss: 100.227041
epoch: 2369, train precision: 0.959956, train loss: 23.328273, valid precision: 0.849600, valid loss: 97.335191
epoch: 2370, train precision: 0.957778, train loss: 23.839164, valid precision: 0.843400, valid loss: 95.021358
epoch: 2371, train precision: 0.959556, train loss: 22.690821, valid precision: 0.849600, valid loss: 102.994282
epoch: 2372, train precision: 0.953578, train loss: 25.254716, valid precision: 0.848200, valid loss: 93.778138
epoch: 2373, train precision: 0.957156, train loss: 24.456110, valid precision: 0.846200, valid loss: 95.947254
epoch: 2374, train precision: 0.959222, train loss: 22.999523, valid precision: 0.851200, valid loss: 94.714485
epoch: 2375, train precision: 0.963067, train loss: 21.596564, valid precision: 0.849000, valid loss: 109.134851
epoch: 2376, train precision: 0.959511, train loss: 23.404218, valid precision: 0.848400, valid loss: 93.766905
epoch: 2377, train precision: 0.953844, train loss: 25.346429, valid precision: 0.848400, valid loss: 91.786114
epoch: 2378, train precision: 0.958511, train loss: 23.736406, valid precision: 0.848400, valid loss: 111.834369
epoch: 2379, train precision: 0.959778, train loss: 22.787205, valid precision: 0.847200, valid loss: 104.102038
epoch: 2380, train precision: 0.956089, train loss: 23.991949, valid precision: 0.848000, valid loss: 95.328936
epoch: 2381, train precision: 0.956800, train loss: 24.273098, valid precision: 0.842600, valid loss: 100.408671
epoch: 2382, train precision: 0.953622, train loss: 24.403120, valid precision: 0.844400, valid loss: 97.597470
epoch: 2383, train precision: 0.962222, train loss: 22.407223, valid precision: 0.848000, valid loss: 100.001128
epoch: 2384, train precision: 0.963111, train loss: 21.649113, valid precision: 0.853400, valid loss: 98.762079
epoch: 2385, train precision: 0.959133, train loss: 23.022768, valid precision: 0.849600, valid loss: 106.991998
epoch: 2386, train precision: 0.956844, train loss: 24.105677, valid precision: 0.846200, valid loss: 104.513039
epoch: 2387, train precision: 0.961978, train loss: 22.038615, valid precision: 0.852000, valid loss: 107.327130
epoch: 2388, train precision: 0.958467, train loss: 23.188055, valid precision: 0.855400, valid loss: 97.930752
epoch: 2389, train precision: 0.954978, train loss: 24.991052, valid precision: 0.846600, valid loss: 93.884942
epoch: 2390, train precision: 0.952556, train loss: 25.909944, valid precision: 0.844000, valid loss: 110.276960
epoch: 2391, train precision: 0.956933, train loss: 23.975990, valid precision: 0.847600, valid loss: 99.620487
epoch: 2392, train precision: 0.955156, train loss: 24.455092, valid precision: 0.850000, valid loss: 100.012933
epoch: 2393, train precision: 0.957000, train loss: 23.636275, valid precision: 0.847000, valid loss: 103.881371
epoch: 2394, train precision: 0.954867, train loss: 25.134173, valid precision: 0.841600, valid loss: 112.474975
epoch: 2395, train precision: 0.958067, train loss: 23.896099, valid precision: 0.849200, valid loss: 104.675931
epoch: 2396, train precision: 0.955867, train loss: 24.108378, valid precision: 0.845200, valid loss: 109.248944
epoch: 2397, train precision: 0.957556, train loss: 23.776876, valid precision: 0.849600, valid loss: 100.765040
epoch: 2398, train precision: 0.954022, train loss: 24.285539, valid precision: 0.843400, valid loss: 94.427730
epoch: 2399, train precision: 0.959911, train loss: 22.573992, valid precision: 0.847200, valid loss: 105.068152
epoch: 2400, train precision: 0.959178, train loss: 23.294523, valid precision: 0.849400, valid loss: 97.202311
epoch: 2401, train precision: 0.959822, train loss: 22.532088, valid precision: 0.849400, valid loss: 99.979972
epoch: 2402, train precision: 0.952711, train loss: 25.333783, valid precision: 0.839600, valid loss: 105.271977
epoch: 2403, train precision: 0.957800, train loss: 23.813441, valid precision: 0.846400, valid loss: 99.370151
epoch: 2404, train precision: 0.948978, train loss: 26.760809, valid precision: 0.838800, valid loss: 107.819233
epoch: 2405, train precision: 0.958511, train loss: 23.495672, valid precision: 0.845200, valid loss: 95.218222
epoch: 2406, train precision: 0.960578, train loss: 22.736469, valid precision: 0.849600, valid loss: 101.912345
epoch: 2407, train precision: 0.962156, train loss: 22.485330, valid precision: 0.846400, valid loss: 102.491648
epoch: 2408, train precision: 0.952733, train loss: 26.187794, valid precision: 0.847000, valid loss: 102.416273
epoch: 2409, train precision: 0.944178, train loss: 30.327201, valid precision: 0.835800, valid loss: 121.675568
epoch: 2410, train precision: 0.959156, train loss: 22.942060, valid precision: 0.844800, valid loss: 102.292826
epoch: 2411, train precision: 0.959267, train loss: 22.680319, valid precision: 0.848800, valid loss: 105.523893
epoch: 2412, train precision: 0.960600, train loss: 22.675031, valid precision: 0.852400, valid loss: 106.224308
epoch: 2413, train precision: 0.959178, train loss: 23.010949, valid precision: 0.845000, valid loss: 97.185208
epoch: 2414, train precision: 0.962156, train loss: 21.951030, valid precision: 0.853200, valid loss: 102.316264
epoch: 2415, train precision: 0.958022, train loss: 23.277546, valid precision: 0.851400, valid loss: 101.698606
epoch: 2416, train precision: 0.959822, train loss: 22.600615, valid precision: 0.852000, valid loss: 104.433106
epoch: 2417, train precision: 0.962311, train loss: 21.796520, valid precision: 0.855600, valid loss: 109.203167
epoch: 2418, train precision: 0.957467, train loss: 23.684169, valid precision: 0.848600, valid loss: 100.992449
epoch: 2419, train precision: 0.958867, train loss: 23.401594, valid precision: 0.855400, valid loss: 101.083922
epoch: 2420, train precision: 0.958400, train loss: 23.496279, valid precision: 0.854000, valid loss: 96.626479
epoch: 2421, train precision: 0.959556, train loss: 23.161049, valid precision: 0.852800, valid loss: 96.412042
epoch: 2422, train precision: 0.960800, train loss: 22.086303, valid precision: 0.851800, valid loss: 100.362219
epoch: 2423, train precision: 0.962933, train loss: 21.162448, valid precision: 0.847600, valid loss: 102.339151
epoch: 2424, train precision: 0.960178, train loss: 22.437184, valid precision: 0.848800, valid loss: 98.508424
epoch: 2425, train precision: 0.957289, train loss: 23.824108, valid precision: 0.847000, valid loss: 107.005149
epoch: 2426, train precision: 0.959867, train loss: 22.796893, valid precision: 0.846400, valid loss: 105.507305
epoch: 2427, train precision: 0.957222, train loss: 24.167913, valid precision: 0.845000, valid loss: 101.397988
epoch: 2428, train precision: 0.958578, train loss: 23.448619, valid precision: 0.847200, valid loss: 111.166204
epoch: 2429, train precision: 0.956267, train loss: 23.944627, valid precision: 0.845200, valid loss: 109.092073
epoch: 2430, train precision: 0.958378, train loss: 23.708602, valid precision: 0.846200, valid loss: 113.533771
epoch: 2431, train precision: 0.957422, train loss: 24.418240, valid precision: 0.850200, valid loss: 92.679565
epoch: 2432, train precision: 0.950000, train loss: 26.734141, valid precision: 0.841200, valid loss: 98.211778
epoch: 2433, train precision: 0.957244, train loss: 23.938441, valid precision: 0.846400, valid loss: 99.015442
epoch: 2434, train precision: 0.962644, train loss: 21.454788, valid precision: 0.847800, valid loss: 102.543477
epoch: 2435, train precision: 0.961489, train loss: 22.040119, valid precision: 0.849600, valid loss: 102.564076
epoch: 2436, train precision: 0.957689, train loss: 24.055487, valid precision: 0.849200, valid loss: 97.320152
epoch: 2437, train precision: 0.958022, train loss: 23.389594, valid precision: 0.845400, valid loss: 98.994450
epoch: 2438, train precision: 0.956911, train loss: 23.874176, valid precision: 0.852600, valid loss: 94.665579
epoch: 2439, train precision: 0.957556, train loss: 23.669352, valid precision: 0.845800, valid loss: 107.009399
epoch: 2440, train precision: 0.956178, train loss: 24.248544, valid precision: 0.846600, valid loss: 100.638836
epoch: 2441, train precision: 0.963222, train loss: 21.298098, valid precision: 0.844200, valid loss: 105.206666
epoch: 2442, train precision: 0.960889, train loss: 22.581825, valid precision: 0.853800, valid loss: 98.713018
epoch: 2443, train precision: 0.959178, train loss: 23.530478, valid precision: 0.843400, valid loss: 94.443364
epoch: 2444, train precision: 0.960556, train loss: 22.165989, valid precision: 0.844000, valid loss: 106.595277
epoch: 2445, train precision: 0.955822, train loss: 24.046484, valid precision: 0.849800, valid loss: 93.864985
epoch: 2446, train precision: 0.960911, train loss: 22.108944, valid precision: 0.852000, valid loss: 106.751678
epoch: 2447, train precision: 0.956556, train loss: 23.625029, valid precision: 0.844800, valid loss: 104.464711
epoch: 2448, train precision: 0.957422, train loss: 23.476409, valid precision: 0.851800, valid loss: 98.157410
epoch: 2449, train precision: 0.962000, train loss: 22.201030, valid precision: 0.849200, valid loss: 102.417310
epoch: 2450, train precision: 0.961378, train loss: 22.538374, valid precision: 0.850200, valid loss: 107.656733
epoch: 2451, train precision: 0.959467, train loss: 23.474826, valid precision: 0.843200, valid loss: 105.664449
epoch: 2452, train precision: 0.961622, train loss: 22.657152, valid precision: 0.848800, valid loss: 98.216042
epoch: 2453, train precision: 0.957911, train loss: 23.888169, valid precision: 0.852800, valid loss: 95.172392
epoch: 2454, train precision: 0.950200, train loss: 26.613055, valid precision: 0.843400, valid loss: 97.035564
epoch: 2455, train precision: 0.961111, train loss: 22.340169, valid precision: 0.848000, valid loss: 102.090041
epoch: 2456, train precision: 0.956267, train loss: 23.802457, valid precision: 0.846200, valid loss: 94.285099
epoch: 2457, train precision: 0.960133, train loss: 22.573888, valid precision: 0.847200, valid loss: 99.104516
epoch: 2458, train precision: 0.959689, train loss: 22.873004, valid precision: 0.844800, valid loss: 102.414720
epoch: 2459, train precision: 0.961156, train loss: 21.958265, valid precision: 0.848000, valid loss: 98.365072
epoch: 2460, train precision: 0.959600, train loss: 23.101554, valid precision: 0.847600, valid loss: 97.395503
epoch: 2461, train precision: 0.955644, train loss: 24.038852, valid precision: 0.843000, valid loss: 103.539089
epoch: 2462, train precision: 0.953467, train loss: 24.893805, valid precision: 0.839400, valid loss: 99.285262
epoch: 2463, train precision: 0.955578, train loss: 24.552556, valid precision: 0.846000, valid loss: 104.099230
epoch: 2464, train precision: 0.957778, train loss: 23.305466, valid precision: 0.845600, valid loss: 97.517949
epoch: 2465, train precision: 0.961133, train loss: 21.721114, valid precision: 0.851400, valid loss: 103.699200
epoch: 2466, train precision: 0.962667, train loss: 21.824508, valid precision: 0.848400, valid loss: 103.891065
epoch: 2467, train precision: 0.947467, train loss: 28.006461, valid precision: 0.836000, valid loss: 114.958764
epoch: 2468, train precision: 0.960022, train loss: 22.601978, valid precision: 0.843200, valid loss: 103.216140
epoch: 2469, train precision: 0.954956, train loss: 24.592181, valid precision: 0.843200, valid loss: 103.141741
epoch: 2470, train precision: 0.961533, train loss: 22.047387, valid precision: 0.852000, valid loss: 106.682532
epoch: 2471, train precision: 0.960133, train loss: 22.688130, valid precision: 0.850400, valid loss: 96.864788
epoch: 2472, train precision: 0.958489, train loss: 23.561044, valid precision: 0.844200, valid loss: 108.764086
epoch: 2473, train precision: 0.963556, train loss: 20.913199, valid precision: 0.852000, valid loss: 108.018842
epoch: 2474, train precision: 0.961844, train loss: 21.609380, valid precision: 0.851200, valid loss: 96.977783
epoch: 2475, train precision: 0.959778, train loss: 22.757006, valid precision: 0.849800, valid loss: 104.518122
epoch: 2476, train precision: 0.962356, train loss: 21.554879, valid precision: 0.853400, valid loss: 106.376788
epoch: 2477, train precision: 0.955333, train loss: 24.413934, valid precision: 0.841400, valid loss: 95.057709
epoch: 2478, train precision: 0.955956, train loss: 23.992348, valid precision: 0.843200, valid loss: 103.369628
epoch: 2479, train precision: 0.960133, train loss: 23.023446, valid precision: 0.848400, valid loss: 103.936665
epoch: 2480, train precision: 0.961622, train loss: 22.049333, valid precision: 0.852800, valid loss: 95.601118
epoch: 2481, train precision: 0.957222, train loss: 23.411341, valid precision: 0.851800, valid loss: 98.606512
epoch: 2482, train precision: 0.963378, train loss: 21.243230, valid precision: 0.846400, valid loss: 101.993369
epoch: 2483, train precision: 0.957244, train loss: 23.913217, valid precision: 0.851400, valid loss: 98.205736
epoch: 2484, train precision: 0.961556, train loss: 21.897030, valid precision: 0.852200, valid loss: 99.374053
epoch: 2485, train precision: 0.956822, train loss: 23.179213, valid precision: 0.845200, valid loss: 103.898849
epoch: 2486, train precision: 0.962222, train loss: 21.889708, valid precision: 0.849800, valid loss: 98.286949
epoch: 2487, train precision: 0.953289, train loss: 25.129997, valid precision: 0.842800, valid loss: 101.008363
epoch: 2488, train precision: 0.960200, train loss: 22.500238, valid precision: 0.850600, valid loss: 95.515581
epoch: 2489, train precision: 0.959422, train loss: 23.076891, valid precision: 0.845600, valid loss: 102.180370
epoch: 2490, train precision: 0.959956, train loss: 22.746976, valid precision: 0.847400, valid loss: 104.481779
epoch: 2491, train precision: 0.959622, train loss: 23.150212, valid precision: 0.849600, valid loss: 101.492760
epoch: 2492, train precision: 0.960889, train loss: 22.855829, valid precision: 0.847200, valid loss: 110.694553
epoch: 2493, train precision: 0.957422, train loss: 23.809165, valid precision: 0.844800, valid loss: 105.065790
epoch: 2494, train precision: 0.960222, train loss: 22.329158, valid precision: 0.845800, valid loss: 104.913539
epoch: 2495, train precision: 0.955222, train loss: 24.153555, valid precision: 0.852400, valid loss: 104.166103
epoch: 2496, train precision: 0.960689, train loss: 22.076141, valid precision: 0.847000, valid loss: 99.446466
epoch: 2497, train precision: 0.959667, train loss: 23.219714, valid precision: 0.845800, valid loss: 99.847383
epoch: 2498, train precision: 0.956422, train loss: 23.824164, valid precision: 0.845600, valid loss: 99.668358
epoch: 2499, train precision: 0.954978, train loss: 24.969099, valid precision: 0.843800, valid loss: 108.727037
epoch: 2500, train precision: 0.954444, train loss: 24.789583, valid precision: 0.842400, valid loss: 101.386409
epoch: 2501, train precision: 0.958511, train loss: 23.338837, valid precision: 0.848800, valid loss: 102.553804
epoch: 2502, train precision: 0.958533, train loss: 23.070726, valid precision: 0.849600, valid loss: 104.659731
epoch: 2503, train precision: 0.959556, train loss: 22.580882, valid precision: 0.847600, valid loss: 100.931473
epoch: 2504, train precision: 0.951844, train loss: 25.579366, valid precision: 0.849000, valid loss: 99.797448
epoch: 2505, train precision: 0.963289, train loss: 20.888555, valid precision: 0.850400, valid loss: 104.680808
epoch: 2506, train precision: 0.961556, train loss: 21.995846, valid precision: 0.847000, valid loss: 98.567156
epoch: 2507, train precision: 0.961178, train loss: 21.866250, valid precision: 0.853800, valid loss: 98.463772
epoch: 2508, train precision: 0.960467, train loss: 23.160673, valid precision: 0.845200, valid loss: 95.098857
epoch: 2509, train precision: 0.960222, train loss: 22.522232, valid precision: 0.850000, valid loss: 99.224443
epoch: 2510, train precision: 0.958200, train loss: 23.416712, valid precision: 0.847800, valid loss: 96.989333
epoch: 2511, train precision: 0.956444, train loss: 23.451866, valid precision: 0.846600, valid loss: 100.852517
epoch: 2512, train precision: 0.954689, train loss: 24.464194, valid precision: 0.841200, valid loss: 97.594303
epoch: 2513, train precision: 0.956578, train loss: 23.742920, valid precision: 0.845800, valid loss: 93.961293
epoch: 2514, train precision: 0.961200, train loss: 21.728690, valid precision: 0.850000, valid loss: 95.072288
epoch: 2515, train precision: 0.954111, train loss: 24.935228, valid precision: 0.843000, valid loss: 102.403712
epoch: 2516, train precision: 0.958311, train loss: 23.296045, valid precision: 0.843000, valid loss: 102.623228
epoch: 2517, train precision: 0.957578, train loss: 23.503925, valid precision: 0.844200, valid loss: 100.509430
epoch: 2518, train precision: 0.959822, train loss: 22.577169, valid precision: 0.846000, valid loss: 104.287600
epoch: 2519, train precision: 0.960667, train loss: 22.442190, valid precision: 0.849000, valid loss: 91.952519
epoch: 2520, train precision: 0.951578, train loss: 25.714602, valid precision: 0.834800, valid loss: 107.315623
epoch: 2521, train precision: 0.959000, train loss: 22.786136, valid precision: 0.846800, valid loss: 101.708984
epoch: 2522, train precision: 0.962889, train loss: 21.378786, valid precision: 0.846000, valid loss: 94.610835
epoch: 2523, train precision: 0.951667, train loss: 25.763614, valid precision: 0.842200, valid loss: 105.491824
epoch: 2524, train precision: 0.955600, train loss: 23.893454, valid precision: 0.843400, valid loss: 101.364487
epoch: 2525, train precision: 0.955644, train loss: 23.947175, valid precision: 0.844200, valid loss: 98.834878
epoch: 2526, train precision: 0.959178, train loss: 23.120018, valid precision: 0.844000, valid loss: 103.146953
epoch: 2527, train precision: 0.957889, train loss: 23.060144, valid precision: 0.841200, valid loss: 98.823386
epoch: 2528, train precision: 0.960067, train loss: 22.535923, valid precision: 0.849200, valid loss: 103.327411
epoch: 2529, train precision: 0.958467, train loss: 23.359469, valid precision: 0.845200, valid loss: 96.381013
epoch: 2530, train precision: 0.959867, train loss: 22.093488, valid precision: 0.846200, valid loss: 96.031874
epoch: 2531, train precision: 0.956511, train loss: 24.401666, valid precision: 0.846400, valid loss: 99.492974
epoch: 2532, train precision: 0.956778, train loss: 23.497564, valid precision: 0.853200, valid loss: 109.631372
epoch: 2533, train precision: 0.959111, train loss: 22.295869, valid precision: 0.849000, valid loss: 99.266556
epoch: 2534, train precision: 0.955267, train loss: 24.930784, valid precision: 0.844800, valid loss: 100.089576
epoch: 2535, train precision: 0.960200, train loss: 22.994003, valid precision: 0.846200, valid loss: 94.400599
epoch: 2536, train precision: 0.959222, train loss: 22.616718, valid precision: 0.848400, valid loss: 97.302760
epoch: 2537, train precision: 0.958111, train loss: 23.192854, valid precision: 0.850200, valid loss: 103.111750
epoch: 2538, train precision: 0.961178, train loss: 22.186958, valid precision: 0.847000, valid loss: 101.888174
epoch: 2539, train precision: 0.961533, train loss: 21.981704, valid precision: 0.848800, valid loss: 96.575306
epoch: 2540, train precision: 0.956733, train loss: 23.930078, valid precision: 0.843400, valid loss: 95.893941
epoch: 2541, train precision: 0.953067, train loss: 25.204849, valid precision: 0.837800, valid loss: 102.557089
epoch: 2542, train precision: 0.959444, train loss: 22.975477, valid precision: 0.842400, valid loss: 95.687947
epoch: 2543, train precision: 0.952711, train loss: 24.843224, valid precision: 0.839200, valid loss: 100.321621
epoch: 2544, train precision: 0.959533, train loss: 22.886777, valid precision: 0.846000, valid loss: 103.593806
epoch: 2545, train precision: 0.955467, train loss: 24.540812, valid precision: 0.844800, valid loss: 108.083875
epoch: 2546, train precision: 0.953822, train loss: 24.792511, valid precision: 0.839200, valid loss: 102.019839
epoch: 2547, train precision: 0.953822, train loss: 25.013909, valid precision: 0.848800, valid loss: 102.592872
epoch: 2548, train precision: 0.955267, train loss: 24.351916, valid precision: 0.841400, valid loss: 104.962965
epoch: 2549, train precision: 0.961467, train loss: 21.927136, valid precision: 0.846400, valid loss: 101.829761
epoch: 2550, train precision: 0.954556, train loss: 24.055664, valid precision: 0.844800, valid loss: 99.559610
epoch: 2551, train precision: 0.956289, train loss: 23.906409, valid precision: 0.845800, valid loss: 103.440251
epoch: 2552, train precision: 0.957778, train loss: 23.108263, valid precision: 0.849000, valid loss: 98.434272
epoch: 2553, train precision: 0.961933, train loss: 21.550114, valid precision: 0.851600, valid loss: 106.241209
epoch: 2554, train precision: 0.961289, train loss: 22.497042, valid precision: 0.845600, valid loss: 98.451435
epoch: 2555, train precision: 0.962511, train loss: 22.005194, valid precision: 0.847200, valid loss: 93.138233
epoch: 2556, train precision: 0.955244, train loss: 24.108981, valid precision: 0.837600, valid loss: 96.005415
epoch: 2557, train precision: 0.961356, train loss: 21.938183, valid precision: 0.849400, valid loss: 102.142904
epoch: 2558, train precision: 0.956867, train loss: 23.121442, valid precision: 0.846200, valid loss: 105.393088
epoch: 2559, train precision: 0.959289, train loss: 22.943940, valid precision: 0.845200, valid loss: 100.532636
epoch: 2560, train precision: 0.961133, train loss: 22.285217, valid precision: 0.850400, valid loss: 94.864208
epoch: 2561, train precision: 0.964489, train loss: 20.807266, valid precision: 0.850800, valid loss: 99.608439
epoch: 2562, train precision: 0.959867, train loss: 23.220772, valid precision: 0.851800, valid loss: 97.435707
epoch: 2563, train precision: 0.956067, train loss: 23.619527, valid precision: 0.849600, valid loss: 95.670202
epoch: 2564, train precision: 0.958733, train loss: 22.686045, valid precision: 0.847400, valid loss: 102.804870
epoch: 2565, train precision: 0.958956, train loss: 23.033737, valid precision: 0.849000, valid loss: 96.870396
epoch: 2566, train precision: 0.953244, train loss: 24.489117, valid precision: 0.846800, valid loss: 97.107859
epoch: 2567, train precision: 0.961200, train loss: 22.206280, valid precision: 0.846200, valid loss: 105.778124
epoch: 2568, train precision: 0.960022, train loss: 22.328103, valid precision: 0.846000, valid loss: 95.266078
epoch: 2569, train precision: 0.963067, train loss: 21.553478, valid precision: 0.845600, valid loss: 109.942390
epoch: 2570, train precision: 0.959756, train loss: 22.767904, valid precision: 0.849000, valid loss: 97.587618
epoch: 2571, train precision: 0.960400, train loss: 22.061760, valid precision: 0.846800, valid loss: 96.357107
epoch: 2572, train precision: 0.955667, train loss: 24.073114, valid precision: 0.847600, valid loss: 94.932140
epoch: 2573, train precision: 0.954378, train loss: 24.982717, valid precision: 0.843600, valid loss: 100.768493
epoch: 2574, train precision: 0.957244, train loss: 23.612695, valid precision: 0.848600, valid loss: 99.143534
epoch: 2575, train precision: 0.952089, train loss: 25.445729, valid precision: 0.840400, valid loss: 103.100505
epoch: 2576, train precision: 0.961689, train loss: 21.902139, valid precision: 0.852800, valid loss: 103.165054
epoch: 2577, train precision: 0.956733, train loss: 23.989352, valid precision: 0.844200, valid loss: 102.240049
epoch: 2578, train precision: 0.958511, train loss: 22.576339, valid precision: 0.850000, valid loss: 101.014996
epoch: 2579, train precision: 0.959022, train loss: 22.864000, valid precision: 0.851000, valid loss: 92.200852
epoch: 2580, train precision: 0.957000, train loss: 23.593624, valid precision: 0.837800, valid loss: 106.575067
epoch: 2581, train precision: 0.956089, train loss: 23.821964, valid precision: 0.849000, valid loss: 100.539497
epoch: 2582, train precision: 0.957533, train loss: 23.326165, valid precision: 0.840000, valid loss: 107.478551
epoch: 2583, train precision: 0.958956, train loss: 23.184217, valid precision: 0.846200, valid loss: 102.425036
epoch: 2584, train precision: 0.958644, train loss: 22.896165, valid precision: 0.844800, valid loss: 98.516526
epoch: 2585, train precision: 0.957644, train loss: 23.482677, valid precision: 0.841200, valid loss: 106.071105
epoch: 2586, train precision: 0.961933, train loss: 22.450669, valid precision: 0.853800, valid loss: 96.260890
epoch: 2587, train precision: 0.959600, train loss: 22.604027, valid precision: 0.851400, valid loss: 102.898359
epoch: 2588, train precision: 0.951244, train loss: 26.046155, valid precision: 0.845400, valid loss: 104.263212
epoch: 2589, train precision: 0.956911, train loss: 23.657576, valid precision: 0.847000, valid loss: 98.620656
epoch: 2590, train precision: 0.948911, train loss: 26.405863, valid precision: 0.844400, valid loss: 93.352376
epoch: 2591, train precision: 0.960622, train loss: 22.189313, valid precision: 0.853800, valid loss: 96.705240
epoch: 2592, train precision: 0.955289, train loss: 24.431616, valid precision: 0.846800, valid loss: 90.503106
epoch: 2593, train precision: 0.955822, train loss: 24.050128, valid precision: 0.850200, valid loss: 93.441865
epoch: 2594, train precision: 0.954711, train loss: 24.335279, valid precision: 0.850000, valid loss: 94.237856
epoch: 2595, train precision: 0.959600, train loss: 22.970207, valid precision: 0.847600, valid loss: 93.035245
epoch: 2596, train precision: 0.959711, train loss: 21.888220, valid precision: 0.849600, valid loss: 97.984600
epoch: 2597, train precision: 0.954000, train loss: 24.238111, valid precision: 0.849400, valid loss: 102.975185
epoch: 2598, train precision: 0.958911, train loss: 22.701808, valid precision: 0.847400, valid loss: 100.517730
epoch: 2599, train precision: 0.955778, train loss: 23.843376, valid precision: 0.843000, valid loss: 101.256327
epoch: 2600, train precision: 0.959400, train loss: 22.247097, valid precision: 0.848000, valid loss: 104.232151
epoch: 2601, train precision: 0.963089, train loss: 21.197816, valid precision: 0.856000, valid loss: 100.489653
epoch: 2602, train precision: 0.954956, train loss: 24.246096, valid precision: 0.844400, valid loss: 96.558802
epoch: 2603, train precision: 0.955378, train loss: 23.800609, valid precision: 0.845000, valid loss: 104.102646
epoch: 2604, train precision: 0.961844, train loss: 21.299818, valid precision: 0.850200, valid loss: 94.525220
epoch: 2605, train precision: 0.957489, train loss: 23.195933, valid precision: 0.849400, valid loss: 102.207077
epoch: 2606, train precision: 0.955956, train loss: 23.544698, valid precision: 0.845600, valid loss: 95.415984
epoch: 2607, train precision: 0.955867, train loss: 23.511484, valid precision: 0.847200, valid loss: 108.038834
epoch: 2608, train precision: 0.953133, train loss: 25.446496, valid precision: 0.846800, valid loss: 91.505019
epoch: 2609, train precision: 0.956178, train loss: 23.893850, valid precision: 0.846400, valid loss: 102.406031
epoch: 2610, train precision: 0.959178, train loss: 22.282291, valid precision: 0.852800, valid loss: 105.364868
epoch: 2611, train precision: 0.957956, train loss: 23.095169, valid precision: 0.841200, valid loss: 99.183446
epoch: 2612, train precision: 0.959222, train loss: 23.032463, valid precision: 0.845200, valid loss: 97.661078
epoch: 2613, train precision: 0.955222, train loss: 24.394659, valid precision: 0.846200, valid loss: 101.369863
epoch: 2614, train precision: 0.961356, train loss: 21.711775, valid precision: 0.851600, valid loss: 98.499747
epoch: 2615, train precision: 0.951756, train loss: 25.183053, valid precision: 0.848000, valid loss: 103.520703
epoch: 2616, train precision: 0.955889, train loss: 24.064288, valid precision: 0.845800, valid loss: 97.107387
epoch: 2617, train precision: 0.954422, train loss: 24.731695, valid precision: 0.842600, valid loss: 90.391723
epoch: 2618, train precision: 0.960022, train loss: 22.056107, valid precision: 0.850400, valid loss: 101.513877
epoch: 2619, train precision: 0.963600, train loss: 21.027532, valid precision: 0.849800, valid loss: 101.532592
epoch: 2620, train precision: 0.952178, train loss: 25.141212, valid precision: 0.839000, valid loss: 107.365778
epoch: 2621, train precision: 0.957200, train loss: 22.993150, valid precision: 0.844200, valid loss: 95.757852
epoch: 2622, train precision: 0.958622, train loss: 22.676817, valid precision: 0.849600, valid loss: 99.425166
epoch: 2623, train precision: 0.954267, train loss: 24.460245, valid precision: 0.845800, valid loss: 100.417805
epoch: 2624, train precision: 0.955000, train loss: 24.327123, valid precision: 0.848000, valid loss: 96.919016
epoch: 2625, train precision: 0.959778, train loss: 22.587559, valid precision: 0.846400, valid loss: 110.821206
epoch: 2626, train precision: 0.960800, train loss: 21.964154, valid precision: 0.851000, valid loss: 105.280992
epoch: 2627, train precision: 0.956244, train loss: 24.217525, valid precision: 0.846200, valid loss: 105.745846
epoch: 2628, train precision: 0.958778, train loss: 22.427893, valid precision: 0.849400, valid loss: 103.142561
epoch: 2629, train precision: 0.956089, train loss: 24.325203, valid precision: 0.841400, valid loss: 92.919753
epoch: 2630, train precision: 0.957400, train loss: 23.621780, valid precision: 0.845600, valid loss: 95.871814
epoch: 2631, train precision: 0.954644, train loss: 24.229394, valid precision: 0.845600, valid loss: 100.778399
epoch: 2632, train precision: 0.960733, train loss: 21.620217, valid precision: 0.849800, valid loss: 102.334316
epoch: 2633, train precision: 0.961400, train loss: 21.482238, valid precision: 0.848800, valid loss: 101.894948
epoch: 2634, train precision: 0.954733, train loss: 24.275094, valid precision: 0.843200, valid loss: 106.702250
epoch: 2635, train precision: 0.956067, train loss: 23.367862, valid precision: 0.841000, valid loss: 99.907159
epoch: 2636, train precision: 0.957400, train loss: 23.265055, valid precision: 0.848400, valid loss: 95.268285
epoch: 2637, train precision: 0.957600, train loss: 22.998402, valid precision: 0.852400, valid loss: 96.823233
epoch: 2638, train precision: 0.955289, train loss: 24.130370, valid precision: 0.847200, valid loss: 96.830233
epoch: 2639, train precision: 0.947644, train loss: 26.832301, valid precision: 0.843200, valid loss: 101.747658
epoch: 2640, train precision: 0.960800, train loss: 22.367610, valid precision: 0.844600, valid loss: 99.159854
epoch: 2641, train precision: 0.954978, train loss: 24.796576, valid precision: 0.845200, valid loss: 108.259260
epoch: 2642, train precision: 0.957067, train loss: 23.216980, valid precision: 0.847000, valid loss: 95.003441
epoch: 2643, train precision: 0.957200, train loss: 23.915565, valid precision: 0.846800, valid loss: 93.893672
epoch: 2644, train precision: 0.958333, train loss: 23.406716, valid precision: 0.851800, valid loss: 98.086933
epoch: 2645, train precision: 0.955800, train loss: 23.594307, valid precision: 0.846600, valid loss: 99.039511
epoch: 2646, train precision: 0.956956, train loss: 23.895804, valid precision: 0.847400, valid loss: 101.618824
epoch: 2647, train precision: 0.956556, train loss: 23.756707, valid precision: 0.847800, valid loss: 92.700019
epoch: 2648, train precision: 0.950178, train loss: 25.631131, valid precision: 0.840600, valid loss: 94.166506
epoch: 2649, train precision: 0.961978, train loss: 21.242966, valid precision: 0.849200, valid loss: 109.425848
epoch: 2650, train precision: 0.953556, train loss: 24.783234, valid precision: 0.843200, valid loss: 94.194596
epoch: 2651, train precision: 0.962622, train loss: 21.599188, valid precision: 0.854800, valid loss: 102.928530
epoch: 2652, train precision: 0.956600, train loss: 23.518957, valid precision: 0.849800, valid loss: 91.209714
epoch: 2653, train precision: 0.953489, train loss: 25.330688, valid precision: 0.843200, valid loss: 98.388063
epoch: 2654, train precision: 0.954778, train loss: 24.658764, valid precision: 0.839200, valid loss: 100.375243
epoch: 2655, train precision: 0.955400, train loss: 23.847256, valid precision: 0.848000, valid loss: 104.377024
epoch: 2656, train precision: 0.957267, train loss: 22.975452, valid precision: 0.851000, valid loss: 100.306945
epoch: 2657, train precision: 0.960956, train loss: 21.642307, valid precision: 0.852400, valid loss: 99.398835
epoch: 2658, train precision: 0.954133, train loss: 24.743331, valid precision: 0.844600, valid loss: 105.608083
epoch: 2659, train precision: 0.958756, train loss: 22.790595, valid precision: 0.847000, valid loss: 106.809603
epoch: 2660, train precision: 0.962467, train loss: 21.763053, valid precision: 0.843400, valid loss: 106.130484
epoch: 2661, train precision: 0.960733, train loss: 21.516346, valid precision: 0.848600, valid loss: 108.413280
epoch: 2662, train precision: 0.950844, train loss: 25.928304, valid precision: 0.840200, valid loss: 99.683179
epoch: 2663, train precision: 0.956778, train loss: 23.467590, valid precision: 0.842000, valid loss: 106.889247
epoch: 2664, train precision: 0.954067, train loss: 24.653025, valid precision: 0.843400, valid loss: 108.798018
epoch: 2665, train precision: 0.957867, train loss: 23.708426, valid precision: 0.841600, valid loss: 98.444269
epoch: 2666, train precision: 0.956489, train loss: 23.413322, valid precision: 0.843200, valid loss: 103.845426
epoch: 2667, train precision: 0.957533, train loss: 23.795866, valid precision: 0.844800, valid loss: 109.160654
epoch: 2668, train precision: 0.955800, train loss: 23.886589, valid precision: 0.839600, valid loss: 101.161499
epoch: 2669, train precision: 0.958867, train loss: 22.576417, valid precision: 0.848600, valid loss: 97.823042
epoch: 2670, train precision: 0.959911, train loss: 21.918620, valid precision: 0.852800, valid loss: 102.740063
epoch: 2671, train precision: 0.951667, train loss: 25.741396, valid precision: 0.843400, valid loss: 102.087094
epoch: 2672, train precision: 0.954200, train loss: 24.306116, valid precision: 0.848400, valid loss: 98.639124
epoch: 2673, train precision: 0.962578, train loss: 21.208051, valid precision: 0.851600, valid loss: 96.056468
epoch: 2674, train precision: 0.959089, train loss: 23.019846, valid precision: 0.845200, valid loss: 103.464363
epoch: 2675, train precision: 0.955489, train loss: 24.359806, valid precision: 0.844000, valid loss: 92.301178
epoch: 2676, train precision: 0.956889, train loss: 22.955589, valid precision: 0.845800, valid loss: 99.777303
epoch: 2677, train precision: 0.961556, train loss: 21.771225, valid precision: 0.848200, valid loss: 98.361790
epoch: 2678, train precision: 0.957511, train loss: 23.500039, valid precision: 0.841600, valid loss: 96.402278
epoch: 2679, train precision: 0.955844, train loss: 23.616881, valid precision: 0.849400, valid loss: 105.520780
epoch: 2680, train precision: 0.959578, train loss: 21.929661, valid precision: 0.846400, valid loss: 110.834698
epoch: 2681, train precision: 0.955800, train loss: 24.141890, valid precision: 0.846800, valid loss: 94.567142
epoch: 2682, train precision: 0.960644, train loss: 21.752287, valid precision: 0.850000, valid loss: 104.960903
epoch: 2683, train precision: 0.961044, train loss: 22.031190, valid precision: 0.850200, valid loss: 106.592437
epoch: 2684, train precision: 0.960556, train loss: 22.362147, valid precision: 0.848600, valid loss: 102.120343
epoch: 2685, train precision: 0.953622, train loss: 24.587562, valid precision: 0.843000, valid loss: 96.131700
epoch: 2686, train precision: 0.956244, train loss: 23.592285, valid precision: 0.846000, valid loss: 102.435724
epoch: 2687, train precision: 0.957133, train loss: 22.527914, valid precision: 0.843600, valid loss: 105.867176
epoch: 2688, train precision: 0.960022, train loss: 22.322841, valid precision: 0.843600, valid loss: 102.479718
epoch: 2689, train precision: 0.955489, train loss: 23.486454, valid precision: 0.844400, valid loss: 98.836925
epoch: 2690, train precision: 0.960200, train loss: 22.191751, valid precision: 0.845400, valid loss: 106.560816
epoch: 2691, train precision: 0.954156, train loss: 24.139615, valid precision: 0.849400, valid loss: 103.690316
epoch: 2692, train precision: 0.959600, train loss: 22.439481, valid precision: 0.848400, valid loss: 100.863546
epoch: 2693, train precision: 0.955822, train loss: 24.137969, valid precision: 0.843600, valid loss: 96.133279
epoch: 2694, train precision: 0.961156, train loss: 22.675743, valid precision: 0.843800, valid loss: 96.853325
epoch: 2695, train precision: 0.953244, train loss: 23.982516, valid precision: 0.842200, valid loss: 102.757335
epoch: 2696, train precision: 0.958222, train loss: 22.661828, valid precision: 0.848800, valid loss: 99.077556
epoch: 2697, train precision: 0.956578, train loss: 23.138955, valid precision: 0.847600, valid loss: 103.145133
epoch: 2698, train precision: 0.959511, train loss: 22.491046, valid precision: 0.848600, valid loss: 110.219454
epoch: 2699, train precision: 0.958156, train loss: 23.198833, valid precision: 0.846600, valid loss: 97.135964
epoch: 2700, train precision: 0.953822, train loss: 24.350409, valid precision: 0.849600, valid loss: 104.744875
epoch: 2701, train precision: 0.962733, train loss: 21.729621, valid precision: 0.851000, valid loss: 92.434088
epoch: 2702, train precision: 0.959311, train loss: 22.708218, valid precision: 0.849000, valid loss: 96.385363
epoch: 2703, train precision: 0.956022, train loss: 23.291551, valid precision: 0.847200, valid loss: 97.481777
epoch: 2704, train precision: 0.957289, train loss: 23.688327, valid precision: 0.838400, valid loss: 90.332267
epoch: 2705, train precision: 0.955111, train loss: 23.531188, valid precision: 0.842400, valid loss: 96.992387
epoch: 2706, train precision: 0.956556, train loss: 23.569816, valid precision: 0.844400, valid loss: 93.495013
epoch: 2707, train precision: 0.957422, train loss: 22.785559, valid precision: 0.844200, valid loss: 110.365528
epoch: 2708, train precision: 0.961711, train loss: 21.365911, valid precision: 0.850800, valid loss: 95.087293
epoch: 2709, train precision: 0.952089, train loss: 24.949291, valid precision: 0.841200, valid loss: 103.337924
epoch: 2710, train precision: 0.960911, train loss: 21.995025, valid precision: 0.846000, valid loss: 98.701183
epoch: 2711, train precision: 0.957289, train loss: 23.222354, valid precision: 0.851000, valid loss: 89.393599
epoch: 2712, train precision: 0.952267, train loss: 24.912113, valid precision: 0.844000, valid loss: 91.989969
epoch: 2713, train precision: 0.958800, train loss: 22.367991, valid precision: 0.843800, valid loss: 102.149029
epoch: 2714, train precision: 0.954022, train loss: 23.807684, valid precision: 0.848000, valid loss: 95.974411
epoch: 2715, train precision: 0.954689, train loss: 23.715319, valid precision: 0.847000, valid loss: 94.958821
epoch: 2716, train precision: 0.957044, train loss: 23.473524, valid precision: 0.840800, valid loss: 90.142521
epoch: 2717, train precision: 0.955000, train loss: 24.445638, valid precision: 0.847000, valid loss: 99.501789
epoch: 2718, train precision: 0.958511, train loss: 22.343966, valid precision: 0.847200, valid loss: 105.905431
epoch: 2719, train precision: 0.957044, train loss: 22.882620, valid precision: 0.846400, valid loss: 104.680521
epoch: 2720, train precision: 0.962533, train loss: 21.368064, valid precision: 0.849200, valid loss: 98.376587
epoch: 2721, train precision: 0.958222, train loss: 22.425483, valid precision: 0.850000, valid loss: 111.146136
epoch: 2722, train precision: 0.958689, train loss: 22.541268, valid precision: 0.845800, valid loss: 98.858100
epoch: 2723, train precision: 0.955622, train loss: 24.063904, valid precision: 0.840600, valid loss: 100.116515
epoch: 2724, train precision: 0.957089, train loss: 23.250771, valid precision: 0.842400, valid loss: 100.022867
epoch: 2725, train precision: 0.952867, train loss: 24.313677, valid precision: 0.843800, valid loss: 96.165240
epoch: 2726, train precision: 0.953378, train loss: 24.220178, valid precision: 0.839200, valid loss: 97.013473
epoch: 2727, train precision: 0.960378, train loss: 22.224253, valid precision: 0.843200, valid loss: 98.608046
epoch: 2728, train precision: 0.954778, train loss: 23.819690, valid precision: 0.843800, valid loss: 97.183609
epoch: 2729, train precision: 0.954178, train loss: 24.724044, valid precision: 0.844800, valid loss: 95.967671
epoch: 2730, train precision: 0.955089, train loss: 23.664531, valid precision: 0.841200, valid loss: 104.317804
epoch: 2731, train precision: 0.958000, train loss: 22.960556, valid precision: 0.842000, valid loss: 99.626628
epoch: 2732, train precision: 0.961778, train loss: 21.167722, valid precision: 0.845400, valid loss: 97.308541
epoch: 2733, train precision: 0.952600, train loss: 24.324060, valid precision: 0.838400, valid loss: 93.669075
epoch: 2734, train precision: 0.960244, train loss: 21.902295, valid precision: 0.846000, valid loss: 99.344540
epoch: 2735, train precision: 0.960378, train loss: 21.518500, valid precision: 0.845400, valid loss: 101.478241
epoch: 2736, train precision: 0.957689, train loss: 22.998728, valid precision: 0.847400, valid loss: 90.196626
epoch: 2737, train precision: 0.957556, train loss: 23.475279, valid precision: 0.845200, valid loss: 98.433067
epoch: 2738, train precision: 0.953422, train loss: 25.025927, valid precision: 0.839600, valid loss: 104.693582
epoch: 2739, train precision: 0.961044, train loss: 21.717078, valid precision: 0.841000, valid loss: 93.751933
epoch: 2740, train precision: 0.953156, train loss: 24.383514, valid precision: 0.844600, valid loss: 101.546891
epoch: 2741, train precision: 0.951578, train loss: 25.002720, valid precision: 0.843400, valid loss: 99.359166
epoch: 2742, train precision: 0.955511, train loss: 23.231143, valid precision: 0.847200, valid loss: 102.018644
epoch: 2743, train precision: 0.957133, train loss: 22.765255, valid precision: 0.848600, valid loss: 94.939407
epoch: 2744, train precision: 0.959556, train loss: 22.679284, valid precision: 0.843800, valid loss: 98.331614
epoch: 2745, train precision: 0.957267, train loss: 23.359658, valid precision: 0.849200, valid loss: 94.774159
epoch: 2746, train precision: 0.951333, train loss: 25.090382, valid precision: 0.843800, valid loss: 95.447657
epoch: 2747, train precision: 0.959444, train loss: 22.480934, valid precision: 0.854600, valid loss: 95.706652
epoch: 2748, train precision: 0.954178, train loss: 24.411579, valid precision: 0.842800, valid loss: 99.118320
epoch: 2749, train precision: 0.955333, train loss: 24.005961, valid precision: 0.842600, valid loss: 103.521197
epoch: 2750, train precision: 0.961133, train loss: 21.541675, valid precision: 0.841200, valid loss: 100.501257
epoch: 2751, train precision: 0.958311, train loss: 23.062355, valid precision: 0.851200, valid loss: 104.650558
epoch: 2752, train precision: 0.957178, train loss: 23.456895, valid precision: 0.845600, valid loss: 102.652693
epoch: 2753, train precision: 0.956778, train loss: 23.157728, valid precision: 0.843800, valid loss: 98.111231
epoch: 2754, train precision: 0.959600, train loss: 22.375624, valid precision: 0.844000, valid loss: 102.062389
epoch: 2755, train precision: 0.954311, train loss: 23.919880, valid precision: 0.841200, valid loss: 97.210259
epoch: 2756, train precision: 0.955178, train loss: 23.663686, valid precision: 0.844000, valid loss: 99.377443
epoch: 2757, train precision: 0.962889, train loss: 21.108117, valid precision: 0.848200, valid loss: 101.398424
epoch: 2758, train precision: 0.952000, train loss: 24.963637, valid precision: 0.851200, valid loss: 95.146902
epoch: 2759, train precision: 0.956244, train loss: 23.824116, valid precision: 0.842600, valid loss: 110.516305
epoch: 2760, train precision: 0.953889, train loss: 24.935229, valid precision: 0.839800, valid loss: 105.294075
epoch: 2761, train precision: 0.954978, train loss: 23.562670, valid precision: 0.842800, valid loss: 103.009364
epoch: 2762, train precision: 0.958622, train loss: 23.356235, valid precision: 0.847400, valid loss: 100.982997
epoch: 2763, train precision: 0.956333, train loss: 23.390553, valid precision: 0.846200, valid loss: 98.683652
epoch: 2764, train precision: 0.955222, train loss: 23.646077, valid precision: 0.844800, valid loss: 101.150704
epoch: 2765, train precision: 0.960044, train loss: 21.978399, valid precision: 0.839600, valid loss: 95.914743
epoch: 2766, train precision: 0.957778, train loss: 22.728698, valid precision: 0.844800, valid loss: 97.784742
epoch: 2767, train precision: 0.957533, train loss: 22.955727, valid precision: 0.839200, valid loss: 107.630938
epoch: 2768, train precision: 0.961267, train loss: 21.664136, valid precision: 0.846000, valid loss: 94.137573
epoch: 2769, train precision: 0.958378, train loss: 22.873748, valid precision: 0.842200, valid loss: 106.263513
epoch: 2770, train precision: 0.955578, train loss: 23.676135, valid precision: 0.844800, valid loss: 95.475001
epoch: 2771, train precision: 0.954978, train loss: 23.711608, valid precision: 0.847400, valid loss: 97.214968
epoch: 2772, train precision: 0.957378, train loss: 23.281023, valid precision: 0.843800, valid loss: 104.020468
epoch: 2773, train precision: 0.955378, train loss: 23.692172, valid precision: 0.851000, valid loss: 94.099353
epoch: 2774, train precision: 0.953022, train loss: 24.334235, valid precision: 0.844800, valid loss: 92.995787
epoch: 2775, train precision: 0.954511, train loss: 24.300646, valid precision: 0.846400, valid loss: 93.602184
epoch: 2776, train precision: 0.957467, train loss: 22.826753, valid precision: 0.851600, valid loss: 102.083311
epoch: 2777, train precision: 0.959000, train loss: 21.968674, valid precision: 0.851800, valid loss: 94.612036
epoch: 2778, train precision: 0.953200, train loss: 24.535296, valid precision: 0.841800, valid loss: 102.179827
epoch: 2779, train precision: 0.953089, train loss: 24.876705, valid precision: 0.846800, valid loss: 93.188470
epoch: 2780, train precision: 0.958778, train loss: 22.416977, valid precision: 0.849200, valid loss: 97.894763
epoch: 2781, train precision: 0.954667, train loss: 23.665360, valid precision: 0.844800, valid loss: 103.173777
epoch: 2782, train precision: 0.957778, train loss: 22.799297, valid precision: 0.848600, valid loss: 102.949359
epoch: 2783, train precision: 0.954133, train loss: 24.555622, valid precision: 0.843000, valid loss: 115.227791
epoch: 2784, train precision: 0.958067, train loss: 23.534434, valid precision: 0.847200, valid loss: 95.240627
epoch: 2785, train precision: 0.955378, train loss: 23.487369, valid precision: 0.851000, valid loss: 102.066048
epoch: 2786, train precision: 0.956089, train loss: 23.387442, valid precision: 0.844200, valid loss: 94.653913
epoch: 2787, train precision: 0.956200, train loss: 23.514985, valid precision: 0.848000, valid loss: 97.737807
epoch: 2788, train precision: 0.949756, train loss: 26.022439, valid precision: 0.840200, valid loss: 98.183280
epoch: 2789, train precision: 0.951289, train loss: 24.709730, valid precision: 0.840800, valid loss: 97.099294
epoch: 2790, train precision: 0.949911, train loss: 25.698204, valid precision: 0.838200, valid loss: 98.249213
epoch: 2791, train precision: 0.953533, train loss: 24.420081, valid precision: 0.839800, valid loss: 92.138575
epoch: 2792, train precision: 0.956978, train loss: 22.831890, valid precision: 0.841000, valid loss: 93.606937
epoch: 2793, train precision: 0.959889, train loss: 22.283256, valid precision: 0.845000, valid loss: 95.570173
epoch: 2794, train precision: 0.957467, train loss: 22.321987, valid precision: 0.844000, valid loss: 110.445880
epoch: 2795, train precision: 0.961200, train loss: 21.894392, valid precision: 0.846600, valid loss: 105.099433
epoch: 2796, train precision: 0.950689, train loss: 25.445895, valid precision: 0.840600, valid loss: 92.509027
epoch: 2797, train precision: 0.957578, train loss: 22.887836, valid precision: 0.848000, valid loss: 96.967380
epoch: 2798, train precision: 0.957400, train loss: 22.697616, valid precision: 0.850600, valid loss: 101.820361
epoch: 2799, train precision: 0.958222, train loss: 22.873002, valid precision: 0.841400, valid loss: 103.762296
epoch: 2800, train precision: 0.959400, train loss: 22.080389, valid precision: 0.844600, valid loss: 98.050464
epoch: 2801, train precision: 0.956289, train loss: 23.220644, valid precision: 0.847600, valid loss: 96.662399
epoch: 2802, train precision: 0.956867, train loss: 23.431417, valid precision: 0.848600, valid loss: 101.077592
epoch: 2803, train precision: 0.955689, train loss: 24.025278, valid precision: 0.843200, valid loss: 98.338695
epoch: 2804, train precision: 0.957133, train loss: 22.642812, valid precision: 0.844400, valid loss: 97.590375
epoch: 2805, train precision: 0.956600, train loss: 23.303715, valid precision: 0.846000, valid loss: 106.236452
epoch: 2806, train precision: 0.957800, train loss: 22.417667, valid precision: 0.844600, valid loss: 97.329974
epoch: 2807, train precision: 0.954156, train loss: 24.141596, valid precision: 0.846400, valid loss: 94.482338
epoch: 2808, train precision: 0.959467, train loss: 21.926476, valid precision: 0.845600, valid loss: 102.314004
epoch: 2809, train precision: 0.960111, train loss: 21.956227, valid precision: 0.847200, valid loss: 99.834547
epoch: 2810, train precision: 0.958356, train loss: 22.493975, valid precision: 0.850000, valid loss: 100.199620
epoch: 2811, train precision: 0.960600, train loss: 21.822226, valid precision: 0.849200, valid loss: 99.960807
epoch: 2812, train precision: 0.957044, train loss: 22.966626, valid precision: 0.846200, valid loss: 96.428991
epoch: 2813, train precision: 0.954044, train loss: 23.996225, valid precision: 0.841600, valid loss: 100.026426
epoch: 2814, train precision: 0.953400, train loss: 24.512190, valid precision: 0.841800, valid loss: 99.460956
epoch: 2815, train precision: 0.959111, train loss: 21.971720, valid precision: 0.849600, valid loss: 95.675155
epoch: 2816, train precision: 0.957356, train loss: 23.056719, valid precision: 0.842400, valid loss: 95.913191
epoch: 2817, train precision: 0.957089, train loss: 22.830784, valid precision: 0.841200, valid loss: 98.467010
epoch: 2818, train precision: 0.959178, train loss: 21.897433, valid precision: 0.843000, valid loss: 104.657820
epoch: 2819, train precision: 0.958222, train loss: 22.780809, valid precision: 0.846000, valid loss: 103.282976
epoch: 2820, train precision: 0.955244, train loss: 23.882495, valid precision: 0.843800, valid loss: 92.694900
epoch: 2821, train precision: 0.958933, train loss: 22.258528, valid precision: 0.844600, valid loss: 99.922248
epoch: 2822, train precision: 0.957444, train loss: 22.352550, valid precision: 0.846800, valid loss: 101.193199
epoch: 2823, train precision: 0.954489, train loss: 24.006636, valid precision: 0.845800, valid loss: 97.637836
epoch: 2824, train precision: 0.961444, train loss: 21.585537, valid precision: 0.842800, valid loss: 103.281445
epoch: 2825, train precision: 0.954556, train loss: 23.549231, valid precision: 0.852600, valid loss: 99.846634
epoch: 2826, train precision: 0.957533, train loss: 23.325098, valid precision: 0.845600, valid loss: 97.989009
epoch: 2827, train precision: 0.959333, train loss: 21.664561, valid precision: 0.849400, valid loss: 101.541568
epoch: 2828, train precision: 0.956156, train loss: 23.283296, valid precision: 0.844800, valid loss: 100.591151
epoch: 2829, train precision: 0.957600, train loss: 22.617410, valid precision: 0.841000, valid loss: 100.241003
epoch: 2830, train precision: 0.958956, train loss: 22.565887, valid precision: 0.845000, valid loss: 96.988823
epoch: 2831, train precision: 0.960067, train loss: 21.807209, valid precision: 0.851600, valid loss: 92.958964
epoch: 2832, train precision: 0.955911, train loss: 23.501126, valid precision: 0.846800, valid loss: 104.515917
epoch: 2833, train precision: 0.961867, train loss: 21.130888, valid precision: 0.851400, valid loss: 99.915900
epoch: 2834, train precision: 0.956356, train loss: 23.235391, valid precision: 0.844400, valid loss: 96.884937
epoch: 2835, train precision: 0.950378, train loss: 25.892639, valid precision: 0.836000, valid loss: 95.083545
epoch: 2836, train precision: 0.953667, train loss: 24.420018, valid precision: 0.845800, valid loss: 97.315465
epoch: 2837, train precision: 0.952133, train loss: 24.756266, valid precision: 0.841400, valid loss: 94.547612
epoch: 2838, train precision: 0.961044, train loss: 21.456140, valid precision: 0.845400, valid loss: 106.350238
epoch: 2839, train precision: 0.957600, train loss: 22.503567, valid precision: 0.845200, valid loss: 97.008689
epoch: 2840, train precision: 0.958289, train loss: 22.333463, valid precision: 0.844800, valid loss: 105.298046
epoch: 2841, train precision: 0.961622, train loss: 21.061897, valid precision: 0.844800, valid loss: 103.807321
epoch: 2842, train precision: 0.957511, train loss: 22.504045, valid precision: 0.844000, valid loss: 100.421613
epoch: 2843, train precision: 0.957111, train loss: 22.786204, valid precision: 0.838600, valid loss: 102.658321
epoch: 2844, train precision: 0.955289, train loss: 23.445875, valid precision: 0.844000, valid loss: 99.475146
epoch: 2845, train precision: 0.955978, train loss: 22.863653, valid precision: 0.841800, valid loss: 95.753187
epoch: 2846, train precision: 0.956556, train loss: 23.050125, valid precision: 0.839800, valid loss: 99.088030
epoch: 2847, train precision: 0.958111, train loss: 22.711718, valid precision: 0.847000, valid loss: 97.243771
epoch: 2848, train precision: 0.954133, train loss: 23.796462, valid precision: 0.837400, valid loss: 101.048737
epoch: 2849, train precision: 0.960222, train loss: 21.696455, valid precision: 0.846000, valid loss: 97.523532
epoch: 2850, train precision: 0.959533, train loss: 22.276662, valid precision: 0.844200, valid loss: 103.458511
epoch: 2851, train precision: 0.955467, train loss: 23.309481, valid precision: 0.836200, valid loss: 101.226920
epoch: 2852, train precision: 0.956244, train loss: 23.466508, valid precision: 0.846400, valid loss: 98.285107
epoch: 2853, train precision: 0.953956, train loss: 23.845055, valid precision: 0.839200, valid loss: 107.219284
epoch: 2854, train precision: 0.951400, train loss: 25.315583, valid precision: 0.838800, valid loss: 107.385467
epoch: 2855, train precision: 0.960022, train loss: 21.898858, valid precision: 0.844400, valid loss: 98.225202
epoch: 2856, train precision: 0.957444, train loss: 22.705670, valid precision: 0.841000, valid loss: 97.086431
epoch: 2857, train precision: 0.955422, train loss: 23.480794, valid precision: 0.840400, valid loss: 99.376363
epoch: 2858, train precision: 0.957311, train loss: 22.513148, valid precision: 0.845000, valid loss: 104.260250
epoch: 2859, train precision: 0.954222, train loss: 23.944747, valid precision: 0.846600, valid loss: 98.067618
epoch: 2860, train precision: 0.961889, train loss: 21.184593, valid precision: 0.849000, valid loss: 88.947368
epoch: 2861, train precision: 0.957889, train loss: 22.617394, valid precision: 0.843200, valid loss: 101.089139
epoch: 2862, train precision: 0.958267, train loss: 22.087467, valid precision: 0.844800, valid loss: 108.088964
epoch: 2863, train precision: 0.957822, train loss: 22.305391, valid precision: 0.844800, valid loss: 94.290510
epoch: 2864, train precision: 0.954089, train loss: 24.007640, valid precision: 0.847200, valid loss: 100.461488
epoch: 2865, train precision: 0.958556, train loss: 22.661247, valid precision: 0.842400, valid loss: 102.842228
epoch: 2866, train precision: 0.955000, train loss: 23.784177, valid precision: 0.842400, valid loss: 96.632096
epoch: 2867, train precision: 0.956933, train loss: 23.091326, valid precision: 0.844000, valid loss: 102.156420
epoch: 2868, train precision: 0.954978, train loss: 23.017272, valid precision: 0.848600, valid loss: 94.910321
epoch: 2869, train precision: 0.961711, train loss: 21.161181, valid precision: 0.853800, valid loss: 100.410697
epoch: 2870, train precision: 0.957844, train loss: 22.450214, valid precision: 0.849800, valid loss: 94.921482
epoch: 2871, train precision: 0.951378, train loss: 25.252955, valid precision: 0.849800, valid loss: 96.997721
epoch: 2872, train precision: 0.953600, train loss: 23.863473, valid precision: 0.846200, valid loss: 90.307365
epoch: 2873, train precision: 0.954444, train loss: 24.326474, valid precision: 0.845000, valid loss: 99.330511
epoch: 2874, train precision: 0.954089, train loss: 24.081089, valid precision: 0.848400, valid loss: 100.555950
epoch: 2875, train precision: 0.960644, train loss: 21.614025, valid precision: 0.848200, valid loss: 104.237858
epoch: 2876, train precision: 0.950822, train loss: 25.495577, valid precision: 0.843400, valid loss: 92.498309
epoch: 2877, train precision: 0.957978, train loss: 22.245110, valid precision: 0.846400, valid loss: 100.433643
epoch: 2878, train precision: 0.950422, train loss: 26.045574, valid precision: 0.845600, valid loss: 102.274462
epoch: 2879, train precision: 0.954533, train loss: 23.548481, valid precision: 0.839400, valid loss: 97.534971
epoch: 2880, train precision: 0.953533, train loss: 23.730225, valid precision: 0.847600, valid loss: 99.128992
epoch: 2881, train precision: 0.957422, train loss: 22.977409, valid precision: 0.848400, valid loss: 92.975433
epoch: 2882, train precision: 0.954467, train loss: 23.744704, valid precision: 0.849600, valid loss: 90.578682
epoch: 2883, train precision: 0.956244, train loss: 22.974149, valid precision: 0.845000, valid loss: 97.841577
epoch: 2884, train precision: 0.959444, train loss: 22.051114, valid precision: 0.845800, valid loss: 95.496283
epoch: 2885, train precision: 0.957267, train loss: 23.294090, valid precision: 0.843400, valid loss: 102.410753
epoch: 2886, train precision: 0.951000, train loss: 24.867920, valid precision: 0.848400, valid loss: 93.824746
epoch: 2887, train precision: 0.957911, train loss: 23.103869, valid precision: 0.849800, valid loss: 94.590904
epoch: 2888, train precision: 0.958333, train loss: 22.467810, valid precision: 0.850000, valid loss: 99.253809
epoch: 2889, train precision: 0.956689, train loss: 22.893537, valid precision: 0.853800, valid loss: 92.461944
epoch: 2890, train precision: 0.952756, train loss: 24.759190, valid precision: 0.839200, valid loss: 96.153668
epoch: 2891, train precision: 0.953400, train loss: 24.097819, valid precision: 0.846200, valid loss: 102.426878
epoch: 2892, train precision: 0.959089, train loss: 22.390116, valid precision: 0.847200, valid loss: 103.810077
epoch: 2893, train precision: 0.960556, train loss: 21.191795, valid precision: 0.851000, valid loss: 104.377025
epoch: 2894, train precision: 0.955133, train loss: 23.846877, valid precision: 0.848000, valid loss: 96.526202
epoch: 2895, train precision: 0.957578, train loss: 22.956159, valid precision: 0.846600, valid loss: 96.711935
epoch: 2896, train precision: 0.954467, train loss: 23.931171, valid precision: 0.847400, valid loss: 93.255419
epoch: 2897, train precision: 0.955067, train loss: 23.607015, valid precision: 0.850800, valid loss: 104.707367
epoch: 2898, train precision: 0.959289, train loss: 22.289254, valid precision: 0.849600, valid loss: 94.956658
epoch: 2899, train precision: 0.954244, train loss: 24.416188, valid precision: 0.847600, valid loss: 98.294473
epoch: 2900, train precision: 0.953067, train loss: 24.422359, valid precision: 0.845000, valid loss: 111.403355
epoch: 2901, train precision: 0.955667, train loss: 22.948021, valid precision: 0.847000, valid loss: 95.883336
epoch: 2902, train precision: 0.953400, train loss: 24.036973, valid precision: 0.841800, valid loss: 100.233051
epoch: 2903, train precision: 0.955689, train loss: 23.278734, valid precision: 0.845400, valid loss: 98.109100
epoch: 2904, train precision: 0.949267, train loss: 26.808823, valid precision: 0.836800, valid loss: 99.528850
epoch: 2905, train precision: 0.956756, train loss: 23.103676, valid precision: 0.850400, valid loss: 93.852509
epoch: 2906, train precision: 0.956000, train loss: 23.106845, valid precision: 0.847200, valid loss: 90.269487
epoch: 2907, train precision: 0.949022, train loss: 26.297211, valid precision: 0.839200, valid loss: 101.631161
epoch: 2908, train precision: 0.951844, train loss: 24.209004, valid precision: 0.845000, valid loss: 89.817831
epoch: 2909, train precision: 0.953467, train loss: 23.866456, valid precision: 0.847800, valid loss: 96.875129
epoch: 2910, train precision: 0.958467, train loss: 22.077376, valid precision: 0.852600, valid loss: 94.359559
epoch: 2911, train precision: 0.952111, train loss: 25.113642, valid precision: 0.847400, valid loss: 97.004185
epoch: 2912, train precision: 0.958356, train loss: 22.098076, valid precision: 0.854000, valid loss: 92.539229
epoch: 2913, train precision: 0.954667, train loss: 23.822476, valid precision: 0.848800, valid loss: 90.799849
epoch: 2914, train precision: 0.954644, train loss: 23.486944, valid precision: 0.851200, valid loss: 99.323331
epoch: 2915, train precision: 0.956600, train loss: 23.192177, valid precision: 0.849000, valid loss: 93.595016
epoch: 2916, train precision: 0.958133, train loss: 22.209474, valid precision: 0.850200, valid loss: 98.852505
epoch: 2917, train precision: 0.959578, train loss: 21.960033, valid precision: 0.851200, valid loss: 92.227902
epoch: 2918, train precision: 0.953800, train loss: 24.566161, valid precision: 0.845400, valid loss: 115.562751
epoch: 2919, train precision: 0.954533, train loss: 24.238111, valid precision: 0.847200, valid loss: 94.494119
epoch: 2920, train precision: 0.960711, train loss: 21.728490, valid precision: 0.848400, valid loss: 101.369148
epoch: 2921, train precision: 0.959889, train loss: 22.015448, valid precision: 0.852000, valid loss: 105.218629
epoch: 2922, train precision: 0.957244, train loss: 22.722030, valid precision: 0.849400, valid loss: 92.968359
epoch: 2923, train precision: 0.956022, train loss: 23.026033, valid precision: 0.847200, valid loss: 92.314724
epoch: 2924, train precision: 0.959556, train loss: 21.458838, valid precision: 0.853800, valid loss: 99.970414
epoch: 2925, train precision: 0.952711, train loss: 24.406106, valid precision: 0.845200, valid loss: 91.300112
epoch: 2926, train precision: 0.951933, train loss: 24.836315, valid precision: 0.843400, valid loss: 101.356074
epoch: 2927, train precision: 0.957600, train loss: 22.733179, valid precision: 0.847800, valid loss: 100.442287
epoch: 2928, train precision: 0.956178, train loss: 22.933807, valid precision: 0.852400, valid loss: 95.296585
epoch: 2929, train precision: 0.954267, train loss: 23.804828, valid precision: 0.851400, valid loss: 98.397430
epoch: 2930, train precision: 0.950689, train loss: 24.811840, valid precision: 0.847400, valid loss: 101.438158
epoch: 2931, train precision: 0.956067, train loss: 23.377740, valid precision: 0.848800, valid loss: 101.779352
epoch: 2932, train precision: 0.958356, train loss: 22.591321, valid precision: 0.844200, valid loss: 93.364777
epoch: 2933, train precision: 0.957111, train loss: 22.969177, valid precision: 0.842600, valid loss: 91.155571
epoch: 2934, train precision: 0.952156, train loss: 24.413662, valid precision: 0.841200, valid loss: 95.737938
epoch: 2935, train precision: 0.954667, train loss: 23.363498, valid precision: 0.846400, valid loss: 103.878629
epoch: 2936, train precision: 0.957533, train loss: 22.878598, valid precision: 0.853800, valid loss: 100.034731
epoch: 2937, train precision: 0.957578, train loss: 22.457608, valid precision: 0.847200, valid loss: 98.980147
epoch: 2938, train precision: 0.953867, train loss: 23.702993, valid precision: 0.846600, valid loss: 94.535309
epoch: 2939, train precision: 0.958000, train loss: 22.681257, valid precision: 0.842600, valid loss: 107.102636
epoch: 2940, train precision: 0.955378, train loss: 23.630295, valid precision: 0.847400, valid loss: 99.980263
epoch: 2941, train precision: 0.953111, train loss: 24.321629, valid precision: 0.840400, valid loss: 105.872702
epoch: 2942, train precision: 0.952400, train loss: 24.503678, valid precision: 0.842600, valid loss: 94.791938
epoch: 2943, train precision: 0.954578, train loss: 23.520460, valid precision: 0.848800, valid loss: 98.541993
epoch: 2944, train precision: 0.954333, train loss: 23.657333, valid precision: 0.840200, valid loss: 96.652614
epoch: 2945, train precision: 0.954089, train loss: 23.915598, valid precision: 0.845200, valid loss: 94.289296
epoch: 2946, train precision: 0.949956, train loss: 25.307341, valid precision: 0.847000, valid loss: 100.675198
epoch: 2947, train precision: 0.957867, train loss: 22.477573, valid precision: 0.842000, valid loss: 98.875810
epoch: 2948, train precision: 0.958933, train loss: 22.580474, valid precision: 0.851000, valid loss: 94.264569
epoch: 2949, train precision: 0.958667, train loss: 22.077515, valid precision: 0.853800, valid loss: 96.535395
epoch: 2950, train precision: 0.955289, train loss: 23.798513, valid precision: 0.844000, valid loss: 99.820958
epoch: 2951, train precision: 0.950200, train loss: 24.911444, valid precision: 0.843800, valid loss: 92.341076
epoch: 2952, train precision: 0.949267, train loss: 25.126769, valid precision: 0.844400, valid loss: 94.339574
epoch: 2953, train precision: 0.956622, train loss: 22.938648, valid precision: 0.844400, valid loss: 103.102886
epoch: 2954, train precision: 0.956711, train loss: 22.731292, valid precision: 0.851000, valid loss: 93.891019
epoch: 2955, train precision: 0.958778, train loss: 22.301316, valid precision: 0.847600, valid loss: 97.722187
epoch: 2956, train precision: 0.961067, train loss: 21.067064, valid precision: 0.845800, valid loss: 102.332790
epoch: 2957, train precision: 0.960667, train loss: 21.074944, valid precision: 0.852000, valid loss: 100.178535
epoch: 2958, train precision: 0.956244, train loss: 22.916074, valid precision: 0.845000, valid loss: 95.899288
epoch: 2959, train precision: 0.956889, train loss: 22.602934, valid precision: 0.849000, valid loss: 100.658707
epoch: 2960, train precision: 0.959067, train loss: 22.591466, valid precision: 0.843000, valid loss: 99.730093
epoch: 2961, train precision: 0.956000, train loss: 23.368805, valid precision: 0.838800, valid loss: 100.759245
epoch: 2962, train precision: 0.960533, train loss: 21.715499, valid precision: 0.846200, valid loss: 96.506856
epoch: 2963, train precision: 0.957400, train loss: 22.567889, valid precision: 0.842200, valid loss: 94.311023
epoch: 2964, train precision: 0.960156, train loss: 21.327102, valid precision: 0.847200, valid loss: 91.828929
epoch: 2965, train precision: 0.960867, train loss: 21.324130, valid precision: 0.851000, valid loss: 94.789219
epoch: 2966, train precision: 0.957622, train loss: 22.018877, valid precision: 0.851000, valid loss: 97.231007
epoch: 2967, train precision: 0.957956, train loss: 22.125110, valid precision: 0.843400, valid loss: 103.636889
epoch: 2968, train precision: 0.955511, train loss: 23.219977, valid precision: 0.844600, valid loss: 98.703306
epoch: 2969, train precision: 0.953711, train loss: 23.179536, valid precision: 0.842800, valid loss: 96.229871
epoch: 2970, train precision: 0.952222, train loss: 24.544520, valid precision: 0.841200, valid loss: 99.699782
epoch: 2971, train precision: 0.956289, train loss: 22.900172, valid precision: 0.852200, valid loss: 93.970242
epoch: 2972, train precision: 0.956200, train loss: 23.283564, valid precision: 0.843800, valid loss: 95.317860
epoch: 2973, train precision: 0.956156, train loss: 23.230629, valid precision: 0.847800, valid loss: 95.634717
epoch: 2974, train precision: 0.955467, train loss: 23.426350, valid precision: 0.843000, valid loss: 98.911739
epoch: 2975, train precision: 0.956956, train loss: 23.208357, valid precision: 0.847600, valid loss: 101.397720
epoch: 2976, train precision: 0.958867, train loss: 22.016243, valid precision: 0.848000, valid loss: 97.397345
epoch: 2977, train precision: 0.958200, train loss: 21.860087, valid precision: 0.846000, valid loss: 98.752036
epoch: 2978, train precision: 0.956467, train loss: 22.425903, valid precision: 0.849600, valid loss: 92.875050
epoch: 2979, train precision: 0.954956, train loss: 23.020231, valid precision: 0.846000, valid loss: 94.992077
epoch: 2980, train precision: 0.959778, train loss: 21.619119, valid precision: 0.848400, valid loss: 100.402835
epoch: 2981, train precision: 0.953467, train loss: 23.963850, valid precision: 0.843800, valid loss: 99.817519
epoch: 2982, train precision: 0.950067, train loss: 25.236469, valid precision: 0.838000, valid loss: 104.156655
epoch: 2983, train precision: 0.953556, train loss: 23.703010, valid precision: 0.848800, valid loss: 92.161943
epoch: 2984, train precision: 0.955844, train loss: 22.999486, valid precision: 0.849000, valid loss: 97.112018
epoch: 2985, train precision: 0.953556, train loss: 23.805367, valid precision: 0.842200, valid loss: 94.618414
epoch: 2986, train precision: 0.953867, train loss: 23.686792, valid precision: 0.844600, valid loss: 99.628987
epoch: 2987, train precision: 0.955533, train loss: 23.256796, valid precision: 0.841800, valid loss: 94.765637
epoch: 2988, train precision: 0.952956, train loss: 23.724640, valid precision: 0.846400, valid loss: 87.039142
epoch: 2989, train precision: 0.955800, train loss: 22.905423, valid precision: 0.842000, valid loss: 97.210919
epoch: 2990, train precision: 0.953733, train loss: 23.815326, valid precision: 0.847800, valid loss: 93.440493
epoch: 2991, train precision: 0.958511, train loss: 22.287157, valid precision: 0.845600, valid loss: 95.130591
epoch: 2992, train precision: 0.961378, train loss: 20.912047, valid precision: 0.850600, valid loss: 92.923406
epoch: 2993, train precision: 0.958578, train loss: 22.042175, valid precision: 0.842400, valid loss: 98.572710
epoch: 2994, train precision: 0.956889, train loss: 22.558314, valid precision: 0.844400, valid loss: 92.751157
epoch: 2995, train precision: 0.957956, train loss: 22.661905, valid precision: 0.852600, valid loss: 85.724029
epoch: 2996, train precision: 0.959422, train loss: 21.397950, valid precision: 0.853000, valid loss: 92.365969
epoch: 2997, train precision: 0.956667, train loss: 23.143281, valid precision: 0.847800, valid loss: 93.138990
epoch: 2998, train precision: 0.958111, train loss: 21.777332, valid precision: 0.846200, valid loss: 97.851497
epoch: 2999, train precision: 0.957400, train loss: 22.675638, valid precision: 0.842800, valid loss: 101.567119
epoch: 3000, train precision: 0.958267, train loss: 22.131155, valid precision: 0.838800, valid loss: 95.868101
epoch: 3001, train precision: 0.956289, train loss: 22.834156, valid precision: 0.840400, valid loss: 100.041085
epoch: 3002, train precision: 0.955422, train loss: 23.856885, valid precision: 0.844800, valid loss: 96.819205
epoch: 3003, train precision: 0.956556, train loss: 22.909855, valid precision: 0.850400, valid loss: 97.996469
epoch: 3004, train precision: 0.955711, train loss: 23.196002, valid precision: 0.851400, valid loss: 91.582631
epoch: 3005, train precision: 0.954178, train loss: 23.534150, valid precision: 0.844600, valid loss: 99.380891
epoch: 3006, train precision: 0.955756, train loss: 22.546805, valid precision: 0.846800, valid loss: 95.690404
epoch: 3007, train precision: 0.950089, train loss: 25.638851, valid precision: 0.846800, valid loss: 100.548187
epoch: 3008, train precision: 0.955778, train loss: 22.829823, valid precision: 0.843600, valid loss: 99.255281
epoch: 3009, train precision: 0.961622, train loss: 21.150984, valid precision: 0.849400, valid loss: 96.418213
epoch: 3010, train precision: 0.952933, train loss: 23.881613, valid precision: 0.846800, valid loss: 98.603178
epoch: 3011, train precision: 0.960489, train loss: 21.486872, valid precision: 0.850200, valid loss: 106.645807
epoch: 3012, train precision: 0.954489, train loss: 23.489849, valid precision: 0.847200, valid loss: 102.635198
epoch: 3013, train precision: 0.960689, train loss: 21.084627, valid precision: 0.846200, valid loss: 106.780213
epoch: 3014, train precision: 0.953244, train loss: 24.006481, valid precision: 0.846000, valid loss: 95.898783
epoch: 3015, train precision: 0.958556, train loss: 22.263663, valid precision: 0.848800, valid loss: 90.803331
epoch: 3016, train precision: 0.948867, train loss: 25.096060, valid precision: 0.846800, valid loss: 104.272847
epoch: 3017, train precision: 0.960289, train loss: 21.495001, valid precision: 0.845600, valid loss: 99.790793
epoch: 3018, train precision: 0.957556, train loss: 22.881666, valid precision: 0.841400, valid loss: 97.386001
epoch: 3019, train precision: 0.957133, train loss: 22.546737, valid precision: 0.847600, valid loss: 94.121585
epoch: 3020, train precision: 0.956622, train loss: 22.750472, valid precision: 0.848000, valid loss: 96.373846
epoch: 3021, train precision: 0.957889, train loss: 22.357362, valid precision: 0.843200, valid loss: 97.488545
epoch: 3022, train precision: 0.963422, train loss: 19.949078, valid precision: 0.848400, valid loss: 105.491330
epoch: 3023, train precision: 0.954422, train loss: 23.715735, valid precision: 0.848400, valid loss: 100.108576
epoch: 3024, train precision: 0.958267, train loss: 22.301564, valid precision: 0.847800, valid loss: 99.906092
epoch: 3025, train precision: 0.958267, train loss: 22.053347, valid precision: 0.847600, valid loss: 96.171210
epoch: 3026, train precision: 0.956778, train loss: 22.732343, valid precision: 0.840800, valid loss: 94.368897
epoch: 3027, train precision: 0.954822, train loss: 23.640393, valid precision: 0.846200, valid loss: 95.649673
epoch: 3028, train precision: 0.953778, train loss: 23.875768, valid precision: 0.844800, valid loss: 101.944835
epoch: 3029, train precision: 0.952822, train loss: 24.423065, valid precision: 0.847800, valid loss: 92.967123
epoch: 3030, train precision: 0.958022, train loss: 21.921678, valid precision: 0.846200, valid loss: 100.667088
epoch: 3031, train precision: 0.947756, train loss: 26.771311, valid precision: 0.837000, valid loss: 102.220246
epoch: 3032, train precision: 0.950378, train loss: 25.163207, valid precision: 0.841600, valid loss: 96.658006
epoch: 3033, train precision: 0.956178, train loss: 22.860320, valid precision: 0.841800, valid loss: 96.198783
epoch: 3034, train precision: 0.951467, train loss: 24.577031, valid precision: 0.842600, valid loss: 94.317990
epoch: 3035, train precision: 0.956911, train loss: 22.013603, valid precision: 0.846200, valid loss: 97.545764
epoch: 3036, train precision: 0.957911, train loss: 22.359067, valid precision: 0.842600, valid loss: 106.539089
epoch: 3037, train precision: 0.954422, train loss: 23.213658, valid precision: 0.842600, valid loss: 99.037466
epoch: 3038, train precision: 0.957422, train loss: 23.311351, valid precision: 0.842400, valid loss: 91.880294
epoch: 3039, train precision: 0.956000, train loss: 22.804769, valid precision: 0.844800, valid loss: 97.797645
epoch: 3040, train precision: 0.959089, train loss: 21.927124, valid precision: 0.847600, valid loss: 96.365551
epoch: 3041, train precision: 0.952400, train loss: 24.264854, valid precision: 0.845800, valid loss: 96.802074
epoch: 3042, train precision: 0.958133, train loss: 21.717726, valid precision: 0.848000, valid loss: 102.023126
epoch: 3043, train precision: 0.954111, train loss: 24.080262, valid precision: 0.842600, valid loss: 92.879265
epoch: 3044, train precision: 0.957844, train loss: 22.606296, valid precision: 0.845200, valid loss: 92.102428
epoch: 3045, train precision: 0.958556, train loss: 22.698835, valid precision: 0.843200, valid loss: 97.856169
epoch: 3046, train precision: 0.956422, train loss: 22.891193, valid precision: 0.844200, valid loss: 105.854619
epoch: 3047, train precision: 0.956467, train loss: 22.587273, valid precision: 0.843000, valid loss: 93.261431
epoch: 3048, train precision: 0.960667, train loss: 21.252498, valid precision: 0.847200, valid loss: 95.734460
epoch: 3049, train precision: 0.959822, train loss: 21.272606, valid precision: 0.848200, valid loss: 101.703211
epoch: 3050, train precision: 0.952444, train loss: 24.204727, valid precision: 0.839800, valid loss: 96.129660
epoch: 3051, train precision: 0.954600, train loss: 23.486634, valid precision: 0.844000, valid loss: 95.028918
epoch: 3052, train precision: 0.947311, train loss: 26.353213, valid precision: 0.844800, valid loss: 91.147598
epoch: 3053, train precision: 0.954222, train loss: 23.536820, valid precision: 0.839400, valid loss: 97.371190
epoch: 3054, train precision: 0.952378, train loss: 24.131461, valid precision: 0.842400, valid loss: 97.980880
epoch: 3055, train precision: 0.953778, train loss: 23.815403, valid precision: 0.844600, valid loss: 98.825601
epoch: 3056, train precision: 0.950956, train loss: 24.893567, valid precision: 0.844200, valid loss: 98.789065
epoch: 3057, train precision: 0.951711, train loss: 24.600224, valid precision: 0.842400, valid loss: 95.571549
epoch: 3058, train precision: 0.955867, train loss: 23.010232, valid precision: 0.847400, valid loss: 99.842970
epoch: 3059, train precision: 0.956867, train loss: 23.150982, valid precision: 0.847400, valid loss: 99.239953
epoch: 3060, train precision: 0.952244, train loss: 24.259417, valid precision: 0.839200, valid loss: 100.910991
epoch: 3061, train precision: 0.957978, train loss: 22.032350, valid precision: 0.850200, valid loss: 93.664110
epoch: 3062, train precision: 0.958844, train loss: 21.556307, valid precision: 0.843400, valid loss: 100.756074
epoch: 3063, train precision: 0.955089, train loss: 23.234257, valid precision: 0.848600, valid loss: 95.693220
epoch: 3064, train precision: 0.959622, train loss: 21.571018, valid precision: 0.849000, valid loss: 99.981682
epoch: 3065, train precision: 0.953911, train loss: 23.389652, valid precision: 0.844800, valid loss: 100.427824
epoch: 3066, train precision: 0.955644, train loss: 23.054611, valid precision: 0.843000, valid loss: 97.783763
epoch: 3067, train precision: 0.957711, train loss: 22.486188, valid precision: 0.848800, valid loss: 97.034266
epoch: 3068, train precision: 0.956933, train loss: 22.723606, valid precision: 0.840000, valid loss: 99.476391
epoch: 3069, train precision: 0.953689, train loss: 23.317039, valid precision: 0.843600, valid loss: 94.773520
epoch: 3070, train precision: 0.951133, train loss: 25.252444, valid precision: 0.833000, valid loss: 104.680939
epoch: 3071, train precision: 0.957533, train loss: 22.248082, valid precision: 0.844600, valid loss: 95.936328
epoch: 3072, train precision: 0.956622, train loss: 22.454463, valid precision: 0.842400, valid loss: 101.485428
epoch: 3073, train precision: 0.959711, train loss: 21.509571, valid precision: 0.847200, valid loss: 102.881521
epoch: 3074, train precision: 0.959978, train loss: 21.473059, valid precision: 0.845000, valid loss: 100.154915
epoch: 3075, train precision: 0.952556, train loss: 24.079909, valid precision: 0.843600, valid loss: 93.005254
epoch: 3076, train precision: 0.961067, train loss: 21.056358, valid precision: 0.854400, valid loss: 96.334034
epoch: 3077, train precision: 0.956756, train loss: 23.010043, valid precision: 0.842400, valid loss: 104.554747
epoch: 3078, train precision: 0.957000, train loss: 22.320372, valid precision: 0.845600, valid loss: 99.300620
epoch: 3079, train precision: 0.957444, train loss: 22.706838, valid precision: 0.844600, valid loss: 88.930860
epoch: 3080, train precision: 0.961311, train loss: 20.952387, valid precision: 0.851600, valid loss: 94.985304
epoch: 3081, train precision: 0.957200, train loss: 22.645441, valid precision: 0.847600, valid loss: 93.711356
epoch: 3082, train precision: 0.954289, train loss: 23.615398, valid precision: 0.838400, valid loss: 98.092238
epoch: 3083, train precision: 0.955111, train loss: 22.631377, valid precision: 0.847000, valid loss: 97.181597
epoch: 3084, train precision: 0.954778, train loss: 23.577009, valid precision: 0.847600, valid loss: 97.350077
epoch: 3085, train precision: 0.953667, train loss: 23.949730, valid precision: 0.836200, valid loss: 88.283159
epoch: 3086, train precision: 0.956844, train loss: 21.904261, valid precision: 0.846600, valid loss: 97.293658
epoch: 3087, train precision: 0.957022, train loss: 22.482473, valid precision: 0.843800, valid loss: 97.764567
epoch: 3088, train precision: 0.958644, train loss: 21.824938, valid precision: 0.844200, valid loss: 93.522675
epoch: 3089, train precision: 0.956689, train loss: 22.491570, valid precision: 0.846000, valid loss: 97.311035
epoch: 3090, train precision: 0.954000, train loss: 23.300667, valid precision: 0.849600, valid loss: 90.882531
epoch: 3091, train precision: 0.954111, train loss: 23.616287, valid precision: 0.842200, valid loss: 97.374614
epoch: 3092, train precision: 0.956911, train loss: 22.172428, valid precision: 0.841600, valid loss: 95.889731
epoch: 3093, train precision: 0.958200, train loss: 21.301716, valid precision: 0.843000, valid loss: 94.546230
epoch: 3094, train precision: 0.960756, train loss: 21.139627, valid precision: 0.844000, valid loss: 98.241550
epoch: 3095, train precision: 0.958533, train loss: 21.587597, valid precision: 0.846600, valid loss: 99.927954
epoch: 3096, train precision: 0.955867, train loss: 23.267037, valid precision: 0.841600, valid loss: 92.857654
epoch: 3097, train precision: 0.955244, train loss: 22.808570, valid precision: 0.843600, valid loss: 91.577907
epoch: 3098, train precision: 0.954978, train loss: 23.114631, valid precision: 0.848000, valid loss: 90.546095
epoch: 3099, train precision: 0.956978, train loss: 23.233253, valid precision: 0.846600, valid loss: 99.561143
epoch: 3100, train precision: 0.951956, train loss: 24.636781, valid precision: 0.839000, valid loss: 105.546389
epoch: 3101, train precision: 0.961289, train loss: 20.689478, valid precision: 0.848800, valid loss: 102.421527
epoch: 3102, train precision: 0.954178, train loss: 23.562846, valid precision: 0.837600, valid loss: 106.935914
epoch: 3103, train precision: 0.954800, train loss: 22.913110, valid precision: 0.845000, valid loss: 93.771669
epoch: 3104, train precision: 0.955067, train loss: 23.037920, valid precision: 0.847000, valid loss: 91.035028
epoch: 3105, train precision: 0.952889, train loss: 23.759753, valid precision: 0.843600, valid loss: 100.165070
epoch: 3106, train precision: 0.954378, train loss: 23.088894, valid precision: 0.845200, valid loss: 92.849230
epoch: 3107, train precision: 0.957511, train loss: 22.166089, valid precision: 0.847200, valid loss: 99.588078
epoch: 3108, train precision: 0.950111, train loss: 25.178190, valid precision: 0.840200, valid loss: 101.405899
epoch: 3109, train precision: 0.957933, train loss: 21.995041, valid precision: 0.847400, valid loss: 106.869496
epoch: 3110, train precision: 0.954467, train loss: 23.500087, valid precision: 0.845200, valid loss: 95.753557
epoch: 3111, train precision: 0.959756, train loss: 21.522944, valid precision: 0.845200, valid loss: 90.893649
epoch: 3112, train precision: 0.956911, train loss: 22.221511, valid precision: 0.850600, valid loss: 89.386167
epoch: 3113, train precision: 0.954356, train loss: 23.541945, valid precision: 0.845000, valid loss: 93.864442
epoch: 3114, train precision: 0.960978, train loss: 21.097924, valid precision: 0.849600, valid loss: 97.436578
epoch: 3115, train precision: 0.954756, train loss: 24.208124, valid precision: 0.840000, valid loss: 95.035106
epoch: 3116, train precision: 0.957422, train loss: 22.655154, valid precision: 0.844000, valid loss: 98.893164
epoch: 3117, train precision: 0.955489, train loss: 23.319816, valid precision: 0.847600, valid loss: 102.416588
epoch: 3118, train precision: 0.959067, train loss: 21.794472, valid precision: 0.851400, valid loss: 94.975877
epoch: 3119, train precision: 0.951000, train loss: 24.647987, valid precision: 0.845400, valid loss: 96.244268
epoch: 3120, train precision: 0.949556, train loss: 25.064053, valid precision: 0.839600, valid loss: 95.102362
epoch: 3121, train precision: 0.957044, train loss: 22.084234, valid precision: 0.846600, valid loss: 95.680883
epoch: 3122, train precision: 0.953889, train loss: 23.882261, valid precision: 0.833200, valid loss: 101.685342
epoch: 3123, train precision: 0.955511, train loss: 23.226437, valid precision: 0.842200, valid loss: 100.032252
epoch: 3124, train precision: 0.959311, train loss: 21.495463, valid precision: 0.846000, valid loss: 96.272624
epoch: 3125, train precision: 0.961111, train loss: 20.413359, valid precision: 0.850600, valid loss: 103.197441
epoch: 3126, train precision: 0.962244, train loss: 20.627190, valid precision: 0.846800, valid loss: 98.235829
epoch: 3127, train precision: 0.955889, train loss: 22.989304, valid precision: 0.840200, valid loss: 102.386949
epoch: 3128, train precision: 0.960200, train loss: 21.187609, valid precision: 0.846400, valid loss: 100.106961
epoch: 3129, train precision: 0.960933, train loss: 20.784384, valid precision: 0.849800, valid loss: 97.772352
epoch: 3130, train precision: 0.953556, train loss: 23.704975, valid precision: 0.840600, valid loss: 93.920091
epoch: 3131, train precision: 0.953333, train loss: 23.450011, valid precision: 0.849200, valid loss: 88.748347
epoch: 3132, train precision: 0.957911, train loss: 22.046420, valid precision: 0.848200, valid loss: 86.003673
epoch: 3133, train precision: 0.948911, train loss: 25.147158, valid precision: 0.850400, valid loss: 89.817590
epoch: 3134, train precision: 0.950956, train loss: 24.630816, valid precision: 0.847600, valid loss: 94.176353
epoch: 3135, train precision: 0.954889, train loss: 23.036309, valid precision: 0.848200, valid loss: 100.717091
epoch: 3136, train precision: 0.957533, train loss: 22.050762, valid precision: 0.844600, valid loss: 97.459558
epoch: 3137, train precision: 0.959156, train loss: 21.273951, valid precision: 0.851200, valid loss: 95.407670
epoch: 3138, train precision: 0.955067, train loss: 23.512521, valid precision: 0.843200, valid loss: 92.520391
epoch: 3139, train precision: 0.957200, train loss: 22.408857, valid precision: 0.845800, valid loss: 98.731655
epoch: 3140, train precision: 0.955267, train loss: 22.904104, valid precision: 0.838800, valid loss: 98.069951
epoch: 3141, train precision: 0.955156, train loss: 22.955905, valid precision: 0.844200, valid loss: 93.157083
epoch: 3142, train precision: 0.957156, train loss: 22.854898, valid precision: 0.847600, valid loss: 101.396666
epoch: 3143, train precision: 0.958244, train loss: 21.928150, valid precision: 0.849600, valid loss: 97.111041
epoch: 3144, train precision: 0.957422, train loss: 22.403021, valid precision: 0.847600, valid loss: 95.346507
epoch: 3145, train precision: 0.957289, train loss: 22.185665, valid precision: 0.849400, valid loss: 89.578134
epoch: 3146, train precision: 0.958222, train loss: 22.079803, valid precision: 0.848200, valid loss: 96.673588
epoch: 3147, train precision: 0.959044, train loss: 21.651012, valid precision: 0.852400, valid loss: 97.406252
epoch: 3148, train precision: 0.955689, train loss: 23.069558, valid precision: 0.850600, valid loss: 95.894058
epoch: 3149, train precision: 0.962711, train loss: 20.566638, valid precision: 0.857400, valid loss: 89.232432
epoch: 3150, train precision: 0.954933, train loss: 23.072578, valid precision: 0.846800, valid loss: 92.560576
epoch: 3151, train precision: 0.955533, train loss: 23.057391, valid precision: 0.844600, valid loss: 98.697168
epoch: 3152, train precision: 0.957111, train loss: 22.777198, valid precision: 0.843400, valid loss: 91.803539
epoch: 3153, train precision: 0.957711, train loss: 22.642520, valid precision: 0.849200, valid loss: 96.358178
epoch: 3154, train precision: 0.959689, train loss: 21.769716, valid precision: 0.848400, valid loss: 99.475318
epoch: 3155, train precision: 0.956444, train loss: 22.559493, valid precision: 0.846200, valid loss: 98.401663
epoch: 3156, train precision: 0.952756, train loss: 24.229244, valid precision: 0.847600, valid loss: 98.933080
epoch: 3157, train precision: 0.950867, train loss: 24.567999, valid precision: 0.840800, valid loss: 96.185201
epoch: 3158, train precision: 0.956933, train loss: 22.493002, valid precision: 0.846000, valid loss: 95.874715
epoch: 3159, train precision: 0.956267, train loss: 22.653644, valid precision: 0.844800, valid loss: 100.925283
epoch: 3160, train precision: 0.958333, train loss: 21.812139, valid precision: 0.848400, valid loss: 101.785839
epoch: 3161, train precision: 0.960444, train loss: 21.132557, valid precision: 0.851200, valid loss: 92.710879
epoch: 3162, train precision: 0.955422, train loss: 23.222178, valid precision: 0.848000, valid loss: 93.468647
epoch: 3163, train precision: 0.959822, train loss: 21.258682, valid precision: 0.847400, valid loss: 93.759466
epoch: 3164, train precision: 0.957800, train loss: 22.275056, valid precision: 0.851200, valid loss: 96.343569
epoch: 3165, train precision: 0.954200, train loss: 23.099871, valid precision: 0.851600, valid loss: 96.012062
epoch: 3166, train precision: 0.959489, train loss: 21.335706, valid precision: 0.852000, valid loss: 95.519029
epoch: 3167, train precision: 0.949156, train loss: 25.189761, valid precision: 0.845400, valid loss: 96.897502
epoch: 3168, train precision: 0.949556, train loss: 25.112940, valid precision: 0.844800, valid loss: 103.801156
epoch: 3169, train precision: 0.954356, train loss: 23.047465, valid precision: 0.842000, valid loss: 100.602184
epoch: 3170, train precision: 0.955133, train loss: 23.087073, valid precision: 0.845800, valid loss: 97.877858
epoch: 3171, train precision: 0.954422, train loss: 23.469099, valid precision: 0.847400, valid loss: 95.142424
epoch: 3172, train precision: 0.958533, train loss: 21.397255, valid precision: 0.853400, valid loss: 91.007287
epoch: 3173, train precision: 0.957156, train loss: 22.490403, valid precision: 0.848000, valid loss: 97.251047
epoch: 3174, train precision: 0.957978, train loss: 21.876267, valid precision: 0.846800, valid loss: 100.815099
epoch: 3175, train precision: 0.958133, train loss: 21.596306, valid precision: 0.846400, valid loss: 101.517684
epoch: 3176, train precision: 0.963178, train loss: 19.876005, valid precision: 0.849200, valid loss: 103.029037
epoch: 3177, train precision: 0.957133, train loss: 22.439511, valid precision: 0.851600, valid loss: 92.785881
epoch: 3178, train precision: 0.958222, train loss: 21.899370, valid precision: 0.852000, valid loss: 101.148638
epoch: 3179, train precision: 0.955844, train loss: 22.669369, valid precision: 0.850200, valid loss: 92.340004
epoch: 3180, train precision: 0.958311, train loss: 22.129421, valid precision: 0.847600, valid loss: 97.628621
epoch: 3181, train precision: 0.954689, train loss: 23.412897, valid precision: 0.848200, valid loss: 88.864393
epoch: 3182, train precision: 0.959822, train loss: 21.130331, valid precision: 0.850600, valid loss: 100.031044
epoch: 3183, train precision: 0.957911, train loss: 21.987278, valid precision: 0.845800, valid loss: 99.579559
epoch: 3184, train precision: 0.956000, train loss: 22.067465, valid precision: 0.848000, valid loss: 98.120887
epoch: 3185, train precision: 0.955600, train loss: 23.128329, valid precision: 0.846600, valid loss: 94.849550
epoch: 3186, train precision: 0.948200, train loss: 25.145577, valid precision: 0.847400, valid loss: 86.043107
epoch: 3187, train precision: 0.961778, train loss: 20.747275, valid precision: 0.847000, valid loss: 103.828310
epoch: 3188, train precision: 0.955644, train loss: 22.503858, valid precision: 0.843800, valid loss: 96.744553
epoch: 3189, train precision: 0.957600, train loss: 21.738533, valid precision: 0.846200, valid loss: 99.782958
epoch: 3190, train precision: 0.956511, train loss: 22.951033, valid precision: 0.843200, valid loss: 94.858819
epoch: 3191, train precision: 0.954578, train loss: 23.032697, valid precision: 0.846600, valid loss: 97.730206
epoch: 3192, train precision: 0.960578, train loss: 20.979996, valid precision: 0.846200, valid loss: 97.496856
epoch: 3193, train precision: 0.956044, train loss: 22.469598, valid precision: 0.848400, valid loss: 92.927301
epoch: 3194, train precision: 0.961533, train loss: 20.640192, valid precision: 0.849000, valid loss: 91.243612
epoch: 3195, train precision: 0.957267, train loss: 22.272509, valid precision: 0.848600, valid loss: 93.468946
epoch: 3196, train precision: 0.955378, train loss: 22.698641, valid precision: 0.845200, valid loss: 99.558449
epoch: 3197, train precision: 0.955422, train loss: 22.512935, valid precision: 0.847000, valid loss: 98.465927
epoch: 3198, train precision: 0.950689, train loss: 24.594801, valid precision: 0.841200, valid loss: 98.651965
epoch: 3199, train precision: 0.954556, train loss: 23.243486, valid precision: 0.843400, valid loss: 95.186912
epoch: 3200, train precision: 0.950822, train loss: 24.413508, valid precision: 0.841000, valid loss: 90.182180
epoch: 3201, train precision: 0.959578, train loss: 21.081761, valid precision: 0.846200, valid loss: 98.325352
epoch: 3202, train precision: 0.952800, train loss: 23.800229, valid precision: 0.843200, valid loss: 97.108020
epoch: 3203, train precision: 0.955000, train loss: 23.126732, valid precision: 0.848800, valid loss: 92.794279
epoch: 3204, train precision: 0.955756, train loss: 22.836496, valid precision: 0.851800, valid loss: 92.056824
epoch: 3205, train precision: 0.957311, train loss: 21.706271, valid precision: 0.844200, valid loss: 98.111500
epoch: 3206, train precision: 0.958622, train loss: 22.146567, valid precision: 0.843800, valid loss: 102.776651
epoch: 3207, train precision: 0.957200, train loss: 22.282588, valid precision: 0.848000, valid loss: 95.103714
epoch: 3208, train precision: 0.956356, train loss: 22.652412, valid precision: 0.847800, valid loss: 95.294507
epoch: 3209, train precision: 0.956578, train loss: 23.109474, valid precision: 0.844800, valid loss: 97.220560
epoch: 3210, train precision: 0.955956, train loss: 22.811610, valid precision: 0.845400, valid loss: 104.168508
epoch: 3211, train precision: 0.960222, train loss: 21.193714, valid precision: 0.849600, valid loss: 97.717930
epoch: 3212, train precision: 0.953867, train loss: 23.842907, valid precision: 0.844400, valid loss: 110.370402
epoch: 3213, train precision: 0.956333, train loss: 22.522428, valid precision: 0.847600, valid loss: 101.328920
epoch: 3214, train precision: 0.957156, train loss: 22.290792, valid precision: 0.846800, valid loss: 99.563331
epoch: 3215, train precision: 0.956733, train loss: 22.491027, valid precision: 0.842800, valid loss: 100.856655
epoch: 3216, train precision: 0.957956, train loss: 21.726985, valid precision: 0.841800, valid loss: 105.288983
epoch: 3217, train precision: 0.954733, train loss: 22.837287, valid precision: 0.844200, valid loss: 102.848490
epoch: 3218, train precision: 0.955333, train loss: 22.819004, valid precision: 0.842800, valid loss: 99.016077
epoch: 3219, train precision: 0.956378, train loss: 22.514004, valid precision: 0.846000, valid loss: 99.740253
epoch: 3220, train precision: 0.955467, train loss: 23.211438, valid precision: 0.847800, valid loss: 96.680524
epoch: 3221, train precision: 0.956200, train loss: 22.674474, valid precision: 0.848200, valid loss: 100.573534
epoch: 3222, train precision: 0.951889, train loss: 23.694660, valid precision: 0.849600, valid loss: 101.402236
epoch: 3223, train precision: 0.955489, train loss: 22.847750, valid precision: 0.844200, valid loss: 97.893984
epoch: 3224, train precision: 0.959556, train loss: 21.230639, valid precision: 0.843200, valid loss: 100.781223
epoch: 3225, train precision: 0.953467, train loss: 23.682896, valid precision: 0.838400, valid loss: 101.753821
epoch: 3226, train precision: 0.959756, train loss: 21.085968, valid precision: 0.845200, valid loss: 100.025402
epoch: 3227, train precision: 0.956400, train loss: 22.313649, valid precision: 0.845800, valid loss: 98.530694
epoch: 3228, train precision: 0.959356, train loss: 21.379554, valid precision: 0.846200, valid loss: 101.948067
epoch: 3229, train precision: 0.955289, train loss: 23.167892, valid precision: 0.842400, valid loss: 101.114923
epoch: 3230, train precision: 0.957622, train loss: 21.740395, valid precision: 0.845600, valid loss: 96.955497
epoch: 3231, train precision: 0.957933, train loss: 22.285155, valid precision: 0.844400, valid loss: 96.409511
epoch: 3232, train precision: 0.950311, train loss: 25.170612, valid precision: 0.841200, valid loss: 101.801910
epoch: 3233, train precision: 0.952022, train loss: 24.089759, valid precision: 0.841400, valid loss: 95.651783
epoch: 3234, train precision: 0.955022, train loss: 22.910552, valid precision: 0.840600, valid loss: 97.088387
epoch: 3235, train precision: 0.956311, train loss: 22.479583, valid precision: 0.845600, valid loss: 106.731568
epoch: 3236, train precision: 0.959333, train loss: 21.376533, valid precision: 0.847400, valid loss: 102.638137
epoch: 3237, train precision: 0.955000, train loss: 22.933640, valid precision: 0.841000, valid loss: 101.154905
epoch: 3238, train precision: 0.958467, train loss: 21.506545, valid precision: 0.849800, valid loss: 107.032869
epoch: 3239, train precision: 0.950867, train loss: 23.968708, valid precision: 0.835400, valid loss: 106.958223
epoch: 3240, train precision: 0.953000, train loss: 24.221342, valid precision: 0.842000, valid loss: 95.392040
epoch: 3241, train precision: 0.949978, train loss: 24.492008, valid precision: 0.841400, valid loss: 98.817954
epoch: 3242, train precision: 0.956378, train loss: 21.947278, valid precision: 0.845400, valid loss: 99.202793
epoch: 3243, train precision: 0.957911, train loss: 21.776217, valid precision: 0.844800, valid loss: 96.730897
epoch: 3244, train precision: 0.952311, train loss: 24.269319, valid precision: 0.844200, valid loss: 103.515541
epoch: 3245, train precision: 0.958133, train loss: 21.918343, valid precision: 0.845000, valid loss: 94.721843
epoch: 3246, train precision: 0.957044, train loss: 22.297673, valid precision: 0.844000, valid loss: 96.810161
epoch: 3247, train precision: 0.951489, train loss: 23.999684, valid precision: 0.847200, valid loss: 96.366493
epoch: 3248, train precision: 0.958933, train loss: 21.398046, valid precision: 0.848000, valid loss: 96.751126
epoch: 3249, train precision: 0.951378, train loss: 24.574034, valid precision: 0.842800, valid loss: 92.291960
epoch: 3250, train precision: 0.962867, train loss: 19.739863, valid precision: 0.851600, valid loss: 100.740230
epoch: 3251, train precision: 0.953578, train loss: 23.402705, valid precision: 0.841600, valid loss: 97.791015
epoch: 3252, train precision: 0.955511, train loss: 22.863660, valid precision: 0.845000, valid loss: 96.051692
epoch: 3253, train precision: 0.953244, train loss: 23.554061, valid precision: 0.841800, valid loss: 97.626034
epoch: 3254, train precision: 0.948222, train loss: 25.611091, valid precision: 0.839400, valid loss: 106.849506
epoch: 3255, train precision: 0.959756, train loss: 21.317111, valid precision: 0.841800, valid loss: 101.221703
epoch: 3256, train precision: 0.955511, train loss: 22.758509, valid precision: 0.841000, valid loss: 97.335061
epoch: 3257, train precision: 0.952267, train loss: 23.612720, valid precision: 0.840800, valid loss: 93.755829
epoch: 3258, train precision: 0.960978, train loss: 20.515637, valid precision: 0.849400, valid loss: 101.328649
epoch: 3259, train precision: 0.954867, train loss: 23.075015, valid precision: 0.845000, valid loss: 100.580113
epoch: 3260, train precision: 0.949444, train loss: 25.571789, valid precision: 0.841800, valid loss: 96.559569
epoch: 3261, train precision: 0.953956, train loss: 23.359076, valid precision: 0.845800, valid loss: 93.428063
epoch: 3262, train precision: 0.958800, train loss: 21.683596, valid precision: 0.850400, valid loss: 96.469302
epoch: 3263, train precision: 0.957267, train loss: 22.469916, valid precision: 0.841400, valid loss: 101.925929
epoch: 3264, train precision: 0.956689, train loss: 22.551695, valid precision: 0.844000, valid loss: 93.097832
epoch: 3265, train precision: 0.953556, train loss: 23.756859, valid precision: 0.840600, valid loss: 101.809056
epoch: 3266, train precision: 0.955733, train loss: 22.425558, valid precision: 0.844800, valid loss: 94.621373
epoch: 3267, train precision: 0.954622, train loss: 23.320062, valid precision: 0.845600, valid loss: 102.302854
epoch: 3268, train precision: 0.956889, train loss: 21.937184, valid precision: 0.850400, valid loss: 101.489023
epoch: 3269, train precision: 0.953356, train loss: 23.255585, valid precision: 0.841800, valid loss: 99.956543
epoch: 3270, train precision: 0.956600, train loss: 22.368275, valid precision: 0.843400, valid loss: 99.551571
epoch: 3271, train precision: 0.956733, train loss: 22.185839, valid precision: 0.845600, valid loss: 108.527875
epoch: 3272, train precision: 0.952889, train loss: 23.653788, valid precision: 0.844200, valid loss: 92.540803
epoch: 3273, train precision: 0.956111, train loss: 22.588193, valid precision: 0.842200, valid loss: 95.251605
epoch: 3274, train precision: 0.955711, train loss: 22.249991, valid precision: 0.850000, valid loss: 99.887175
epoch: 3275, train precision: 0.955000, train loss: 22.486604, valid precision: 0.842800, valid loss: 99.453442
epoch: 3276, train precision: 0.953644, train loss: 23.447298, valid precision: 0.845600, valid loss: 95.472459
epoch: 3277, train precision: 0.957156, train loss: 21.745186, valid precision: 0.850400, valid loss: 96.948229
epoch: 3278, train precision: 0.957644, train loss: 21.987451, valid precision: 0.847800, valid loss: 102.543711
epoch: 3279, train precision: 0.954044, train loss: 23.073129, valid precision: 0.846400, valid loss: 98.228176
epoch: 3280, train precision: 0.956911, train loss: 22.076637, valid precision: 0.847600, valid loss: 92.603905
epoch: 3281, train precision: 0.959911, train loss: 21.225759, valid precision: 0.843400, valid loss: 97.892985
epoch: 3282, train precision: 0.956422, train loss: 22.494731, valid precision: 0.844000, valid loss: 104.273241
epoch: 3283, train precision: 0.959311, train loss: 21.483450, valid precision: 0.845400, valid loss: 97.672346
epoch: 3284, train precision: 0.954333, train loss: 23.331916, valid precision: 0.842400, valid loss: 95.240956
epoch: 3285, train precision: 0.954200, train loss: 23.345716, valid precision: 0.843600, valid loss: 93.502154
epoch: 3286, train precision: 0.959689, train loss: 21.585269, valid precision: 0.848000, valid loss: 100.866261
epoch: 3287, train precision: 0.958556, train loss: 21.641500, valid precision: 0.847400, valid loss: 94.842279
epoch: 3288, train precision: 0.955933, train loss: 22.444919, valid precision: 0.843400, valid loss: 101.057875
epoch: 3289, train precision: 0.957333, train loss: 21.999915, valid precision: 0.848800, valid loss: 102.680060
epoch: 3290, train precision: 0.956800, train loss: 22.164398, valid precision: 0.851600, valid loss: 95.865731
epoch: 3291, train precision: 0.958867, train loss: 21.422259, valid precision: 0.848600, valid loss: 96.280264
epoch: 3292, train precision: 0.958778, train loss: 21.098258, valid precision: 0.848800, valid loss: 101.047453
epoch: 3293, train precision: 0.951711, train loss: 24.305019, valid precision: 0.841000, valid loss: 104.126362
epoch: 3294, train precision: 0.955889, train loss: 22.495326, valid precision: 0.842200, valid loss: 97.130141
epoch: 3295, train precision: 0.957044, train loss: 21.937684, valid precision: 0.841400, valid loss: 98.351834
epoch: 3296, train precision: 0.950689, train loss: 24.658671, valid precision: 0.842800, valid loss: 95.434263
epoch: 3297, train precision: 0.952622, train loss: 23.751614, valid precision: 0.836400, valid loss: 100.678452
epoch: 3298, train precision: 0.954911, train loss: 22.510464, valid precision: 0.841800, valid loss: 105.942455
epoch: 3299, train precision: 0.958178, train loss: 21.538700, valid precision: 0.841200, valid loss: 101.620400
epoch: 3300, train precision: 0.953378, train loss: 23.413766, valid precision: 0.841200, valid loss: 101.714819
epoch: 3301, train precision: 0.958089, train loss: 21.935050, valid precision: 0.847600, valid loss: 111.089030
epoch: 3302, train precision: 0.954578, train loss: 23.147740, valid precision: 0.840800, valid loss: 99.531326
epoch: 3303, train precision: 0.953711, train loss: 23.679830, valid precision: 0.844800, valid loss: 97.803579
epoch: 3304, train precision: 0.959333, train loss: 20.920062, valid precision: 0.845400, valid loss: 98.996289
epoch: 3305, train precision: 0.953733, train loss: 23.689129, valid precision: 0.837600, valid loss: 106.473012
epoch: 3306, train precision: 0.957933, train loss: 21.423902, valid precision: 0.845400, valid loss: 96.478684
epoch: 3307, train precision: 0.957889, train loss: 21.495532, valid precision: 0.841000, valid loss: 94.723562
epoch: 3308, train precision: 0.955844, train loss: 22.781062, valid precision: 0.842600, valid loss: 100.227136
epoch: 3309, train precision: 0.957778, train loss: 22.131285, valid precision: 0.839800, valid loss: 97.964902
epoch: 3310, train precision: 0.958089, train loss: 21.583541, valid precision: 0.844000, valid loss: 95.986834
epoch: 3311, train precision: 0.955333, train loss: 22.814137, valid precision: 0.847400, valid loss: 95.376693
epoch: 3312, train precision: 0.951600, train loss: 23.594872, valid precision: 0.847200, valid loss: 98.931371
epoch: 3313, train precision: 0.959311, train loss: 21.284287, valid precision: 0.846000, valid loss: 100.568625
epoch: 3314, train precision: 0.955667, train loss: 22.895102, valid precision: 0.840800, valid loss: 99.802939
epoch: 3315, train precision: 0.954311, train loss: 22.725706, valid precision: 0.845400, valid loss: 96.466389
epoch: 3316, train precision: 0.955200, train loss: 22.380982, valid precision: 0.847200, valid loss: 95.334767
epoch: 3317, train precision: 0.958911, train loss: 21.468662, valid precision: 0.848200, valid loss: 100.404298
epoch: 3318, train precision: 0.956689, train loss: 22.227700, valid precision: 0.844000, valid loss: 93.907808
epoch: 3319, train precision: 0.954467, train loss: 23.169497, valid precision: 0.842200, valid loss: 102.417716
epoch: 3320, train precision: 0.954556, train loss: 22.941930, valid precision: 0.847000, valid loss: 90.564768
epoch: 3321, train precision: 0.956444, train loss: 22.286264, valid precision: 0.847200, valid loss: 98.046321
epoch: 3322, train precision: 0.953444, train loss: 23.303440, valid precision: 0.842800, valid loss: 96.402708
epoch: 3323, train precision: 0.955511, train loss: 22.318330, valid precision: 0.844800, valid loss: 93.373231
epoch: 3324, train precision: 0.955533, train loss: 22.808234, valid precision: 0.845800, valid loss: 93.899005
epoch: 3325, train precision: 0.958444, train loss: 22.091944, valid precision: 0.846400, valid loss: 94.545093
epoch: 3326, train precision: 0.952044, train loss: 24.084698, valid precision: 0.845200, valid loss: 93.568664
epoch: 3327, train precision: 0.954133, train loss: 22.992373, valid precision: 0.847800, valid loss: 94.152390
epoch: 3328, train precision: 0.958844, train loss: 21.323513, valid precision: 0.848000, valid loss: 93.928438
epoch: 3329, train precision: 0.957200, train loss: 21.913627, valid precision: 0.847200, valid loss: 97.026971
epoch: 3330, train precision: 0.956844, train loss: 22.204662, valid precision: 0.847800, valid loss: 92.146183
epoch: 3331, train precision: 0.954711, train loss: 23.412395, valid precision: 0.845400, valid loss: 99.017643
epoch: 3332, train precision: 0.958178, train loss: 21.566587, valid precision: 0.842600, valid loss: 98.701586
epoch: 3333, train precision: 0.958289, train loss: 21.644248, valid precision: 0.849800, valid loss: 102.137778
epoch: 3334, train precision: 0.956400, train loss: 22.397338, valid precision: 0.842800, valid loss: 95.978921
epoch: 3335, train precision: 0.958022, train loss: 22.110773, valid precision: 0.850400, valid loss: 91.289018
epoch: 3336, train precision: 0.953511, train loss: 23.495227, valid precision: 0.842000, valid loss: 99.246742
epoch: 3337, train precision: 0.952733, train loss: 22.966087, valid precision: 0.842600, valid loss: 100.636172
epoch: 3338, train precision: 0.956778, train loss: 22.526696, valid precision: 0.845400, valid loss: 94.270589
epoch: 3339, train precision: 0.955467, train loss: 22.445365, valid precision: 0.852800, valid loss: 99.158763
epoch: 3340, train precision: 0.959533, train loss: 20.746117, valid precision: 0.847800, valid loss: 99.012131
epoch: 3341, train precision: 0.954644, train loss: 23.045398, valid precision: 0.840600, valid loss: 100.933245
epoch: 3342, train precision: 0.946844, train loss: 25.805807, valid precision: 0.839400, valid loss: 96.629872
epoch: 3343, train precision: 0.963178, train loss: 19.408661, valid precision: 0.852200, valid loss: 98.859841
epoch: 3344, train precision: 0.956733, train loss: 22.227020, valid precision: 0.840800, valid loss: 110.731634
epoch: 3345, train precision: 0.952711, train loss: 23.761010, valid precision: 0.842800, valid loss: 93.207456
epoch: 3346, train precision: 0.952911, train loss: 23.391104, valid precision: 0.839600, valid loss: 96.281099
epoch: 3347, train precision: 0.949489, train loss: 24.628574, valid precision: 0.847400, valid loss: 97.220362
epoch: 3348, train precision: 0.957600, train loss: 21.735656, valid precision: 0.848200, valid loss: 96.427530
epoch: 3349, train precision: 0.956000, train loss: 22.402634, valid precision: 0.842800, valid loss: 96.654800
epoch: 3350, train precision: 0.954822, train loss: 23.059614, valid precision: 0.839600, valid loss: 99.084053
epoch: 3351, train precision: 0.955711, train loss: 22.655290, valid precision: 0.843600, valid loss: 95.684708
epoch: 3352, train precision: 0.956800, train loss: 22.509931, valid precision: 0.845600, valid loss: 99.348490
epoch: 3353, train precision: 0.952800, train loss: 23.142494, valid precision: 0.842200, valid loss: 107.123551
epoch: 3354, train precision: 0.950933, train loss: 24.598410, valid precision: 0.842200, valid loss: 95.151155
epoch: 3355, train precision: 0.952000, train loss: 24.198038, valid precision: 0.844600, valid loss: 97.074660
epoch: 3356, train precision: 0.957889, train loss: 22.006651, valid precision: 0.838400, valid loss: 92.433862
epoch: 3357, train precision: 0.956156, train loss: 22.390422, valid precision: 0.845200, valid loss: 95.477620
epoch: 3358, train precision: 0.953222, train loss: 23.822510, valid precision: 0.847800, valid loss: 100.567822
epoch: 3359, train precision: 0.959644, train loss: 20.802618, valid precision: 0.848000, valid loss: 99.930878
epoch: 3360, train precision: 0.953911, train loss: 22.846254, valid precision: 0.841800, valid loss: 97.397305
epoch: 3361, train precision: 0.958578, train loss: 21.395044, valid precision: 0.846000, valid loss: 106.861672
epoch: 3362, train precision: 0.954267, train loss: 23.135696, valid precision: 0.842000, valid loss: 94.939547
epoch: 3363, train precision: 0.959311, train loss: 21.185283, valid precision: 0.844200, valid loss: 90.862653
epoch: 3364, train precision: 0.955622, train loss: 23.266928, valid precision: 0.843400, valid loss: 85.862527
epoch: 3365, train precision: 0.954644, train loss: 23.101940, valid precision: 0.841600, valid loss: 100.593333
epoch: 3366, train precision: 0.954733, train loss: 23.613869, valid precision: 0.845200, valid loss: 97.851538
epoch: 3367, train precision: 0.951889, train loss: 23.975605, valid precision: 0.845200, valid loss: 101.293385
epoch: 3368, train precision: 0.956222, train loss: 22.135635, valid precision: 0.847600, valid loss: 95.361384
epoch: 3369, train precision: 0.954378, train loss: 22.619402, valid precision: 0.846200, valid loss: 91.589038
epoch: 3370, train precision: 0.955778, train loss: 22.323907, valid precision: 0.841800, valid loss: 99.372315
epoch: 3371, train precision: 0.953578, train loss: 23.676083, valid precision: 0.841000, valid loss: 95.110136
epoch: 3372, train precision: 0.956600, train loss: 22.531860, valid precision: 0.841800, valid loss: 96.305462
epoch: 3373, train precision: 0.953089, train loss: 23.840335, valid precision: 0.842400, valid loss: 97.629634
epoch: 3374, train precision: 0.957644, train loss: 21.863854, valid precision: 0.840400, valid loss: 99.362243
epoch: 3375, train precision: 0.951733, train loss: 24.153388, valid precision: 0.844800, valid loss: 98.245652
epoch: 3376, train precision: 0.956822, train loss: 22.134571, valid precision: 0.848000, valid loss: 97.421452
epoch: 3377, train precision: 0.960044, train loss: 20.837283, valid precision: 0.852400, valid loss: 91.333747
epoch: 3378, train precision: 0.955756, train loss: 22.207711, valid precision: 0.839400, valid loss: 97.971182
epoch: 3379, train precision: 0.956133, train loss: 22.420428, valid precision: 0.845600, valid loss: 98.228609
epoch: 3380, train precision: 0.958533, train loss: 21.070431, valid precision: 0.851600, valid loss: 93.830354
epoch: 3381, train precision: 0.952267, train loss: 23.842424, valid precision: 0.843200, valid loss: 90.362799
epoch: 3382, train precision: 0.955244, train loss: 22.544218, valid precision: 0.843200, valid loss: 100.323916
epoch: 3383, train precision: 0.953244, train loss: 23.006565, valid precision: 0.846400, valid loss: 87.936775
epoch: 3384, train precision: 0.960200, train loss: 21.019222, valid precision: 0.842200, valid loss: 93.524535
epoch: 3385, train precision: 0.959156, train loss: 21.209310, valid precision: 0.844400, valid loss: 96.572437
epoch: 3386, train precision: 0.949689, train loss: 25.156096, valid precision: 0.836600, valid loss: 96.081143
epoch: 3387, train precision: 0.957222, train loss: 21.833430, valid precision: 0.849400, valid loss: 92.679820
epoch: 3388, train precision: 0.954622, train loss: 22.671006, valid precision: 0.844600, valid loss: 94.119943
epoch: 3389, train precision: 0.955578, train loss: 22.190000, valid precision: 0.845000, valid loss: 93.178991
epoch: 3390, train precision: 0.953511, train loss: 23.543070, valid precision: 0.845200, valid loss: 88.083302
epoch: 3391, train precision: 0.956311, train loss: 21.769104, valid precision: 0.842200, valid loss: 93.426935
epoch: 3392, train precision: 0.952333, train loss: 23.755418, valid precision: 0.843200, valid loss: 96.330214
epoch: 3393, train precision: 0.956311, train loss: 22.739570, valid precision: 0.841200, valid loss: 90.058149
epoch: 3394, train precision: 0.957289, train loss: 21.889674, valid precision: 0.840800, valid loss: 90.299959
epoch: 3395, train precision: 0.954956, train loss: 22.594373, valid precision: 0.844400, valid loss: 90.135609
epoch: 3396, train precision: 0.955689, train loss: 22.418670, valid precision: 0.843600, valid loss: 95.218108
epoch: 3397, train precision: 0.956489, train loss: 22.455721, valid precision: 0.846200, valid loss: 94.525696
epoch: 3398, train precision: 0.954667, train loss: 23.236289, valid precision: 0.841400, valid loss: 92.785671
epoch: 3399, train precision: 0.955600, train loss: 22.180580, valid precision: 0.845600, valid loss: 92.244820
epoch: 3400, train precision: 0.955867, train loss: 21.761414, valid precision: 0.843600, valid loss: 95.839779
epoch: 3401, train precision: 0.950600, train loss: 24.179971, valid precision: 0.837800, valid loss: 94.037251
epoch: 3402, train precision: 0.955867, train loss: 21.802295, valid precision: 0.843400, valid loss: 97.601510
epoch: 3403, train precision: 0.947756, train loss: 25.947542, valid precision: 0.835800, valid loss: 95.395045
epoch: 3404, train precision: 0.956200, train loss: 22.243013, valid precision: 0.845400, valid loss: 99.914881
epoch: 3405, train precision: 0.952222, train loss: 23.992480, valid precision: 0.838000, valid loss: 97.664687
epoch: 3406, train precision: 0.954489, train loss: 22.422216, valid precision: 0.839600, valid loss: 101.653314
epoch: 3407, train precision: 0.957667, train loss: 21.562920, valid precision: 0.847600, valid loss: 101.100381
epoch: 3408, train precision: 0.958644, train loss: 21.507796, valid precision: 0.844800, valid loss: 92.472473
epoch: 3409, train precision: 0.952133, train loss: 23.458324, valid precision: 0.840000, valid loss: 102.853945
epoch: 3410, train precision: 0.954178, train loss: 22.517348, valid precision: 0.841000, valid loss: 99.031760
epoch: 3411, train precision: 0.949778, train loss: 24.806970, valid precision: 0.835000, valid loss: 103.609487
epoch: 3412, train precision: 0.952689, train loss: 23.523623, valid precision: 0.842400, valid loss: 88.651733
epoch: 3413, train precision: 0.958200, train loss: 21.269755, valid precision: 0.845800, valid loss: 96.636168
epoch: 3414, train precision: 0.959978, train loss: 21.255259, valid precision: 0.846400, valid loss: 101.719011
epoch: 3415, train precision: 0.954356, train loss: 22.495265, valid precision: 0.845600, valid loss: 97.636408
epoch: 3416, train precision: 0.957422, train loss: 21.807800, valid precision: 0.847800, valid loss: 92.787789
epoch: 3417, train precision: 0.957978, train loss: 21.746039, valid precision: 0.850000, valid loss: 93.331074
epoch: 3418, train precision: 0.955022, train loss: 22.520576, valid precision: 0.850600, valid loss: 92.016533
epoch: 3419, train precision: 0.957111, train loss: 21.881809, valid precision: 0.843400, valid loss: 95.191796
epoch: 3420, train precision: 0.957533, train loss: 22.271127, valid precision: 0.845200, valid loss: 91.013806
epoch: 3421, train precision: 0.955156, train loss: 22.566981, valid precision: 0.844000, valid loss: 96.625535
epoch: 3422, train precision: 0.952044, train loss: 23.862099, valid precision: 0.838800, valid loss: 94.555138
epoch: 3423, train precision: 0.957356, train loss: 22.028359, valid precision: 0.843000, valid loss: 88.750936
epoch: 3424, train precision: 0.952733, train loss: 23.830067, valid precision: 0.844200, valid loss: 97.369337
epoch: 3425, train precision: 0.956133, train loss: 22.122258, valid precision: 0.847800, valid loss: 95.193702
epoch: 3426, train precision: 0.956356, train loss: 22.282471, valid precision: 0.847200, valid loss: 92.585852
epoch: 3427, train precision: 0.952978, train loss: 23.764356, valid precision: 0.842800, valid loss: 99.821096
epoch: 3428, train precision: 0.961000, train loss: 19.979561, valid precision: 0.844600, valid loss: 101.395732
epoch: 3429, train precision: 0.949333, train loss: 24.683455, valid precision: 0.841000, valid loss: 94.433211
epoch: 3430, train precision: 0.954822, train loss: 23.389271, valid precision: 0.843000, valid loss: 94.153122
epoch: 3431, train precision: 0.957756, train loss: 21.491402, valid precision: 0.844000, valid loss: 96.865486
epoch: 3432, train precision: 0.952289, train loss: 23.851011, valid precision: 0.847400, valid loss: 91.897532
epoch: 3433, train precision: 0.963644, train loss: 19.820390, valid precision: 0.848000, valid loss: 94.309196
epoch: 3434, train precision: 0.950222, train loss: 24.496247, valid precision: 0.844200, valid loss: 99.177333
epoch: 3435, train precision: 0.953244, train loss: 23.779655, valid precision: 0.844200, valid loss: 89.305707
epoch: 3436, train precision: 0.952867, train loss: 23.737572, valid precision: 0.847600, valid loss: 92.285370
epoch: 3437, train precision: 0.957822, train loss: 21.455027, valid precision: 0.847800, valid loss: 97.285097
epoch: 3438, train precision: 0.951222, train loss: 24.099665, valid precision: 0.839200, valid loss: 104.015135
epoch: 3439, train precision: 0.955333, train loss: 22.855120, valid precision: 0.844000, valid loss: 94.662058
epoch: 3440, train precision: 0.962600, train loss: 20.132910, valid precision: 0.845200, valid loss: 95.220412
epoch: 3441, train precision: 0.953267, train loss: 22.958487, valid precision: 0.847000, valid loss: 89.069853
epoch: 3442, train precision: 0.952889, train loss: 23.651903, valid precision: 0.842400, valid loss: 97.164705
epoch: 3443, train precision: 0.955667, train loss: 22.099243, valid precision: 0.844400, valid loss: 105.724204
epoch: 3444, train precision: 0.956667, train loss: 21.547403, valid precision: 0.848600, valid loss: 96.349008
epoch: 3445, train precision: 0.957844, train loss: 21.504459, valid precision: 0.842800, valid loss: 93.041745
epoch: 3446, train precision: 0.950644, train loss: 24.214330, valid precision: 0.839200, valid loss: 97.414221
epoch: 3447, train precision: 0.954267, train loss: 22.762268, valid precision: 0.842200, valid loss: 101.625014
epoch: 3448, train precision: 0.955733, train loss: 22.644133, valid precision: 0.844400, valid loss: 97.004108
epoch: 3449, train precision: 0.957711, train loss: 21.571648, valid precision: 0.849200, valid loss: 91.170256
epoch: 3450, train precision: 0.955933, train loss: 22.675758, valid precision: 0.845400, valid loss: 95.268644
epoch: 3451, train precision: 0.956333, train loss: 22.608878, valid precision: 0.841400, valid loss: 94.205377
epoch: 3452, train precision: 0.959000, train loss: 21.353580, valid precision: 0.842400, valid loss: 92.547556
epoch: 3453, train precision: 0.952089, train loss: 23.575206, valid precision: 0.836800, valid loss: 102.192290
epoch: 3454, train precision: 0.954578, train loss: 22.531183, valid precision: 0.845800, valid loss: 100.281479
epoch: 3455, train precision: 0.951467, train loss: 24.024510, valid precision: 0.849400, valid loss: 94.278430
epoch: 3456, train precision: 0.958911, train loss: 21.188544, valid precision: 0.846400, valid loss: 89.423892
epoch: 3457, train precision: 0.958133, train loss: 20.829238, valid precision: 0.845800, valid loss: 101.569596
epoch: 3458, train precision: 0.957822, train loss: 21.378730, valid precision: 0.843600, valid loss: 100.321411
epoch: 3459, train precision: 0.958467, train loss: 21.144546, valid precision: 0.850200, valid loss: 95.524708
epoch: 3460, train precision: 0.955022, train loss: 22.532272, valid precision: 0.842600, valid loss: 99.745780
epoch: 3461, train precision: 0.955356, train loss: 22.547916, valid precision: 0.842400, valid loss: 105.428583
epoch: 3462, train precision: 0.955533, train loss: 22.088499, valid precision: 0.844400, valid loss: 98.196932
epoch: 3463, train precision: 0.953911, train loss: 23.139125, valid precision: 0.839400, valid loss: 102.847250
epoch: 3464, train precision: 0.954978, train loss: 22.116234, valid precision: 0.842200, valid loss: 100.283376
epoch: 3465, train precision: 0.957733, train loss: 21.328548, valid precision: 0.846200, valid loss: 106.404867
epoch: 3466, train precision: 0.957444, train loss: 21.255673, valid precision: 0.847600, valid loss: 98.787435
epoch: 3467, train precision: 0.957133, train loss: 21.818519, valid precision: 0.847200, valid loss: 107.298055
epoch: 3468, train precision: 0.959756, train loss: 20.887887, valid precision: 0.848400, valid loss: 98.545665
epoch: 3469, train precision: 0.951933, train loss: 23.239956, valid precision: 0.841600, valid loss: 101.086880
epoch: 3470, train precision: 0.954067, train loss: 22.624459, valid precision: 0.845000, valid loss: 98.448550
epoch: 3471, train precision: 0.957956, train loss: 21.937446, valid precision: 0.843200, valid loss: 99.017451
epoch: 3472, train precision: 0.949289, train loss: 25.516548, valid precision: 0.836600, valid loss: 102.161390
epoch: 3473, train precision: 0.956956, train loss: 22.426812, valid precision: 0.840200, valid loss: 94.317376
epoch: 3474, train precision: 0.953378, train loss: 23.408980, valid precision: 0.843000, valid loss: 95.561173
epoch: 3475, train precision: 0.943933, train loss: 27.488003, valid precision: 0.838600, valid loss: 102.381700
epoch: 3476, train precision: 0.953289, train loss: 23.709343, valid precision: 0.844000, valid loss: 90.915519
epoch: 3477, train precision: 0.959289, train loss: 21.022862, valid precision: 0.841800, valid loss: 96.220463
epoch: 3478, train precision: 0.957022, train loss: 22.021610, valid precision: 0.842600, valid loss: 102.721144
epoch: 3479, train precision: 0.951778, train loss: 23.332921, valid precision: 0.838400, valid loss: 104.364263
epoch: 3480, train precision: 0.954422, train loss: 22.656874, valid precision: 0.845000, valid loss: 98.495991
epoch: 3481, train precision: 0.955222, train loss: 22.494807, valid precision: 0.847000, valid loss: 94.736354
epoch: 3482, train precision: 0.954711, train loss: 22.517200, valid precision: 0.849000, valid loss: 92.327703
epoch: 3483, train precision: 0.955622, train loss: 22.257116, valid precision: 0.846800, valid loss: 92.293554
epoch: 3484, train precision: 0.958000, train loss: 21.601725, valid precision: 0.849400, valid loss: 100.518714
epoch: 3485, train precision: 0.960244, train loss: 20.856218, valid precision: 0.846000, valid loss: 96.154945
epoch: 3486, train precision: 0.952511, train loss: 23.192166, valid precision: 0.842800, valid loss: 92.509249
epoch: 3487, train precision: 0.956822, train loss: 21.884591, valid precision: 0.847800, valid loss: 95.092416
epoch: 3488, train precision: 0.951200, train loss: 24.766825, valid precision: 0.843600, valid loss: 90.470602
epoch: 3489, train precision: 0.949489, train loss: 25.051339, valid precision: 0.843400, valid loss: 94.764193
epoch: 3490, train precision: 0.955711, train loss: 22.863256, valid precision: 0.842800, valid loss: 96.605934
epoch: 3491, train precision: 0.958667, train loss: 21.315713, valid precision: 0.848200, valid loss: 95.583123
epoch: 3492, train precision: 0.958156, train loss: 21.698909, valid precision: 0.845200, valid loss: 98.870697
epoch: 3493, train precision: 0.955156, train loss: 22.900857, valid precision: 0.843600, valid loss: 91.022376
epoch: 3494, train precision: 0.958511, train loss: 21.309543, valid precision: 0.850800, valid loss: 93.247823
epoch: 3495, train precision: 0.956378, train loss: 21.807133, valid precision: 0.848000, valid loss: 94.042629
epoch: 3496, train precision: 0.955267, train loss: 22.654478, valid precision: 0.844800, valid loss: 94.871312
epoch: 3497, train precision: 0.952933, train loss: 23.484087, valid precision: 0.846200, valid loss: 93.659117
epoch: 3498, train precision: 0.959000, train loss: 20.978223, valid precision: 0.848200, valid loss: 97.957693
epoch: 3499, train precision: 0.955422, train loss: 21.686014, valid precision: 0.842200, valid loss: 94.214063
epoch: 3500, train precision: 0.956511, train loss: 21.819116, valid precision: 0.849200, valid loss: 96.843118
epoch: 3501, train precision: 0.957356, train loss: 21.411295, valid precision: 0.841800, valid loss: 102.825045
epoch: 3502, train precision: 0.949956, train loss: 24.679283, valid precision: 0.842800, valid loss: 93.750770
epoch: 3503, train precision: 0.955133, train loss: 22.340918, valid precision: 0.852400, valid loss: 89.645013
epoch: 3504, train precision: 0.950689, train loss: 24.529693, valid precision: 0.850200, valid loss: 88.955363
epoch: 3505, train precision: 0.957222, train loss: 21.712813, valid precision: 0.844000, valid loss: 100.646172
epoch: 3506, train precision: 0.953711, train loss: 23.024782, valid precision: 0.842800, valid loss: 90.027113
epoch: 3507, train precision: 0.957867, train loss: 21.970569, valid precision: 0.850600, valid loss: 95.565939
epoch: 3508, train precision: 0.951667, train loss: 23.457272, valid precision: 0.846800, valid loss: 105.026386
epoch: 3509, train precision: 0.953822, train loss: 23.013670, valid precision: 0.845200, valid loss: 93.817879
epoch: 3510, train precision: 0.950711, train loss: 23.794514, valid precision: 0.841800, valid loss: 96.474137
epoch: 3511, train precision: 0.951889, train loss: 23.737122, valid precision: 0.843200, valid loss: 92.013070
epoch: 3512, train precision: 0.957956, train loss: 20.956114, valid precision: 0.853000, valid loss: 99.954864
epoch: 3513, train precision: 0.955222, train loss: 22.824875, valid precision: 0.848800, valid loss: 89.039102
epoch: 3514, train precision: 0.959956, train loss: 20.776369, valid precision: 0.846400, valid loss: 93.449526
epoch: 3515, train precision: 0.953356, train loss: 23.322507, valid precision: 0.841000, valid loss: 98.856946
epoch: 3516, train precision: 0.952489, train loss: 23.205888, valid precision: 0.848800, valid loss: 98.913667
epoch: 3517, train precision: 0.958578, train loss: 21.492900, valid precision: 0.848000, valid loss: 93.884257
epoch: 3518, train precision: 0.956511, train loss: 22.442150, valid precision: 0.848200, valid loss: 92.115433
epoch: 3519, train precision: 0.955844, train loss: 22.403794, valid precision: 0.846000, valid loss: 98.146788
epoch: 3520, train precision: 0.955311, train loss: 22.807380, valid precision: 0.847400, valid loss: 97.717500
epoch: 3521, train precision: 0.956222, train loss: 22.272824, valid precision: 0.851200, valid loss: 91.947351
epoch: 3522, train precision: 0.955444, train loss: 22.088915, valid precision: 0.848000, valid loss: 96.992939
epoch: 3523, train precision: 0.953222, train loss: 23.343323, valid precision: 0.841000, valid loss: 103.718710
epoch: 3524, train precision: 0.956978, train loss: 21.780681, valid precision: 0.846000, valid loss: 99.355067
epoch: 3525, train precision: 0.957400, train loss: 21.389056, valid precision: 0.844000, valid loss: 97.648035
epoch: 3526, train precision: 0.957267, train loss: 21.885598, valid precision: 0.843400, valid loss: 101.306998
epoch: 3527, train precision: 0.955822, train loss: 22.653152, valid precision: 0.841600, valid loss: 95.716319
epoch: 3528, train precision: 0.953778, train loss: 23.103686, valid precision: 0.841000, valid loss: 99.821137
epoch: 3529, train precision: 0.951889, train loss: 23.609253, valid precision: 0.841800, valid loss: 99.518973
epoch: 3530, train precision: 0.957378, train loss: 21.762633, valid precision: 0.842800, valid loss: 94.030364
epoch: 3531, train precision: 0.952422, train loss: 23.959582, valid precision: 0.842000, valid loss: 100.196501
epoch: 3532, train precision: 0.955622, train loss: 22.829997, valid precision: 0.840800, valid loss: 95.282223
epoch: 3533, train precision: 0.947244, train loss: 26.330720, valid precision: 0.837000, valid loss: 104.598962
epoch: 3534, train precision: 0.954267, train loss: 23.021293, valid precision: 0.845000, valid loss: 95.237101
epoch: 3535, train precision: 0.959178, train loss: 20.992002, valid precision: 0.843000, valid loss: 97.557266
epoch: 3536, train precision: 0.956933, train loss: 21.680038, valid precision: 0.845000, valid loss: 99.748353
epoch: 3537, train precision: 0.952200, train loss: 23.334771, valid precision: 0.841200, valid loss: 99.605832
epoch: 3538, train precision: 0.956711, train loss: 22.044563, valid precision: 0.845200, valid loss: 94.848168
epoch: 3539, train precision: 0.948578, train loss: 25.204712, valid precision: 0.834000, valid loss: 101.589626
epoch: 3540, train precision: 0.947933, train loss: 25.285456, valid precision: 0.839600, valid loss: 101.027093
epoch: 3541, train precision: 0.954111, train loss: 22.963298, valid precision: 0.845000, valid loss: 86.665367
epoch: 3542, train precision: 0.956289, train loss: 21.572179, valid precision: 0.846000, valid loss: 99.945386
epoch: 3543, train precision: 0.954356, train loss: 22.963264, valid precision: 0.836200, valid loss: 101.662673
epoch: 3544, train precision: 0.955222, train loss: 22.755722, valid precision: 0.842600, valid loss: 101.740004
epoch: 3545, train precision: 0.957222, train loss: 21.695542, valid precision: 0.842600, valid loss: 97.587147
epoch: 3546, train precision: 0.951756, train loss: 23.961007, valid precision: 0.836400, valid loss: 93.088203
epoch: 3547, train precision: 0.955311, train loss: 22.925654, valid precision: 0.840800, valid loss: 103.505908
epoch: 3548, train precision: 0.957956, train loss: 21.389173, valid precision: 0.844600, valid loss: 100.307273
epoch: 3549, train precision: 0.953022, train loss: 23.525478, valid precision: 0.844800, valid loss: 93.164036
epoch: 3550, train precision: 0.955244, train loss: 22.374473, valid precision: 0.843000, valid loss: 97.081180
epoch: 3551, train precision: 0.956956, train loss: 21.945628, valid precision: 0.841600, valid loss: 99.286024
epoch: 3552, train precision: 0.950511, train loss: 24.193750, valid precision: 0.843000, valid loss: 94.923017
epoch: 3553, train precision: 0.952578, train loss: 24.395817, valid precision: 0.844800, valid loss: 100.833516
epoch: 3554, train precision: 0.954222, train loss: 22.476391, valid precision: 0.832800, valid loss: 102.959298
epoch: 3555, train precision: 0.949000, train loss: 24.569761, valid precision: 0.848200, valid loss: 92.371404
epoch: 3556, train precision: 0.953133, train loss: 23.264492, valid precision: 0.842000, valid loss: 95.937819
epoch: 3557, train precision: 0.955000, train loss: 23.548454, valid precision: 0.845000, valid loss: 89.403483
epoch: 3558, train precision: 0.959333, train loss: 21.197261, valid precision: 0.849400, valid loss: 94.910473
epoch: 3559, train precision: 0.952822, train loss: 23.401581, valid precision: 0.842200, valid loss: 95.726677
epoch: 3560, train precision: 0.951689, train loss: 23.894210, valid precision: 0.845400, valid loss: 101.210365
epoch: 3561, train precision: 0.953978, train loss: 23.171810, valid precision: 0.844800, valid loss: 97.984304
epoch: 3562, train precision: 0.955044, train loss: 22.719327, valid precision: 0.847200, valid loss: 89.764228
epoch: 3563, train precision: 0.955133, train loss: 22.683835, valid precision: 0.847400, valid loss: 94.680655
epoch: 3564, train precision: 0.954444, train loss: 22.585318, valid precision: 0.845800, valid loss: 96.044862
epoch: 3565, train precision: 0.957000, train loss: 21.374405, valid precision: 0.843800, valid loss: 90.028212
epoch: 3566, train precision: 0.957956, train loss: 21.560363, valid precision: 0.847200, valid loss: 87.840552
epoch: 3567, train precision: 0.950400, train loss: 24.241086, valid precision: 0.842400, valid loss: 96.228269
epoch: 3568, train precision: 0.958467, train loss: 21.133832, valid precision: 0.849000, valid loss: 99.949178
epoch: 3569, train precision: 0.948978, train loss: 24.121046, valid precision: 0.839800, valid loss: 93.313793
epoch: 3570, train precision: 0.955378, train loss: 22.606999, valid precision: 0.845000, valid loss: 100.297081
epoch: 3571, train precision: 0.958156, train loss: 21.465539, valid precision: 0.844000, valid loss: 94.732483
epoch: 3572, train precision: 0.960311, train loss: 20.654715, valid precision: 0.848800, valid loss: 91.375655
epoch: 3573, train precision: 0.948289, train loss: 24.579479, valid precision: 0.834200, valid loss: 100.828817
epoch: 3574, train precision: 0.951844, train loss: 24.118104, valid precision: 0.838800, valid loss: 95.342566
epoch: 3575, train precision: 0.950289, train loss: 24.294949, valid precision: 0.840000, valid loss: 92.117347
epoch: 3576, train precision: 0.949111, train loss: 24.730233, valid precision: 0.836600, valid loss: 93.921739
epoch: 3577, train precision: 0.957933, train loss: 21.770107, valid precision: 0.840800, valid loss: 98.054449
epoch: 3578, train precision: 0.950089, train loss: 24.471395, valid precision: 0.839000, valid loss: 95.550228
epoch: 3579, train precision: 0.956667, train loss: 22.020559, valid precision: 0.841600, valid loss: 92.886928
epoch: 3580, train precision: 0.954667, train loss: 22.274771, valid precision: 0.845800, valid loss: 96.175944
epoch: 3581, train precision: 0.952067, train loss: 23.161960, valid precision: 0.844200, valid loss: 87.408801
epoch: 3582, train precision: 0.949089, train loss: 24.439106, valid precision: 0.842200, valid loss: 103.646280
epoch: 3583, train precision: 0.959200, train loss: 21.550416, valid precision: 0.843600, valid loss: 90.306848
epoch: 3584, train precision: 0.959933, train loss: 20.813554, valid precision: 0.851400, valid loss: 98.813642
epoch: 3585, train precision: 0.954978, train loss: 22.327832, valid precision: 0.844400, valid loss: 96.637388
epoch: 3586, train precision: 0.954867, train loss: 22.154571, valid precision: 0.848600, valid loss: 96.150255
epoch: 3587, train precision: 0.955444, train loss: 22.211367, valid precision: 0.842600, valid loss: 98.816580
epoch: 3588, train precision: 0.954600, train loss: 22.095682, valid precision: 0.843000, valid loss: 97.535339
epoch: 3589, train precision: 0.953422, train loss: 24.149657, valid precision: 0.841200, valid loss: 101.733488
epoch: 3590, train precision: 0.950933, train loss: 23.981588, valid precision: 0.834800, valid loss: 98.651007
epoch: 3591, train precision: 0.952578, train loss: 23.762562, valid precision: 0.845000, valid loss: 101.596577
epoch: 3592, train precision: 0.956067, train loss: 22.402839, valid precision: 0.842600, valid loss: 106.846316
epoch: 3593, train precision: 0.951400, train loss: 24.112994, valid precision: 0.837800, valid loss: 100.239845
epoch: 3594, train precision: 0.956022, train loss: 22.529184, valid precision: 0.839200, valid loss: 97.653309
epoch: 3595, train precision: 0.960778, train loss: 20.374499, valid precision: 0.847600, valid loss: 94.854475
epoch: 3596, train precision: 0.949822, train loss: 24.610247, valid precision: 0.837400, valid loss: 89.072036
epoch: 3597, train precision: 0.957911, train loss: 21.462075, valid precision: 0.842800, valid loss: 99.261326
epoch: 3598, train precision: 0.949733, train loss: 24.627894, valid precision: 0.834800, valid loss: 90.027793
epoch: 3599, train precision: 0.951133, train loss: 23.385668, valid precision: 0.840000, valid loss: 96.299845
epoch: 3600, train precision: 0.961956, train loss: 20.088486, valid precision: 0.845000, valid loss: 98.385442
epoch: 3601, train precision: 0.957222, train loss: 21.827325, valid precision: 0.839600, valid loss: 100.079657
epoch: 3602, train precision: 0.950978, train loss: 23.718956, valid precision: 0.838800, valid loss: 97.944437
epoch: 3603, train precision: 0.953267, train loss: 22.793355, valid precision: 0.842600, valid loss: 97.494944
epoch: 3604, train precision: 0.958400, train loss: 21.239911, valid precision: 0.843600, valid loss: 90.686354
epoch: 3605, train precision: 0.956222, train loss: 21.690635, valid precision: 0.838400, valid loss: 98.017688
epoch: 3606, train precision: 0.956467, train loss: 21.449096, valid precision: 0.844400, valid loss: 100.588044
epoch: 3607, train precision: 0.954267, train loss: 22.355068, valid precision: 0.840400, valid loss: 97.253965
epoch: 3608, train precision: 0.955244, train loss: 22.096914, valid precision: 0.840400, valid loss: 90.886057
epoch: 3609, train precision: 0.959311, train loss: 21.100408, valid precision: 0.845200, valid loss: 93.672825
epoch: 3610, train precision: 0.952244, train loss: 23.705881, valid precision: 0.839800, valid loss: 101.095897
epoch: 3611, train precision: 0.958400, train loss: 21.160419, valid precision: 0.844000, valid loss: 93.774163
epoch: 3612, train precision: 0.953667, train loss: 23.335895, valid precision: 0.841400, valid loss: 93.277270
epoch: 3613, train precision: 0.953733, train loss: 23.110304, valid precision: 0.839400, valid loss: 106.691625
epoch: 3614, train precision: 0.956889, train loss: 22.014088, valid precision: 0.839800, valid loss: 96.753879
epoch: 3615, train precision: 0.957422, train loss: 21.812139, valid precision: 0.839200, valid loss: 105.413352
epoch: 3616, train precision: 0.957444, train loss: 21.729060, valid precision: 0.841600, valid loss: 101.280257
epoch: 3617, train precision: 0.957733, train loss: 21.295035, valid precision: 0.842600, valid loss: 92.907866
epoch: 3618, train precision: 0.953067, train loss: 23.179059, valid precision: 0.841200, valid loss: 95.680609
epoch: 3619, train precision: 0.955689, train loss: 22.137985, valid precision: 0.844400, valid loss: 92.939997
epoch: 3620, train precision: 0.958200, train loss: 21.263456, valid precision: 0.848200, valid loss: 93.871981
epoch: 3621, train precision: 0.954889, train loss: 21.931721, valid precision: 0.844600, valid loss: 102.884819
epoch: 3622, train precision: 0.952422, train loss: 23.122010, valid precision: 0.840000, valid loss: 104.922477
epoch: 3623, train precision: 0.959578, train loss: 20.802775, valid precision: 0.840200, valid loss: 99.741612
epoch: 3624, train precision: 0.959978, train loss: 20.556966, valid precision: 0.839800, valid loss: 99.246464
epoch: 3625, train precision: 0.951444, train loss: 24.310336, valid precision: 0.837000, valid loss: 89.982584
epoch: 3626, train precision: 0.954933, train loss: 22.346640, valid precision: 0.840000, valid loss: 103.798884
epoch: 3627, train precision: 0.957644, train loss: 21.464477, valid precision: 0.836600, valid loss: 101.040551
epoch: 3628, train precision: 0.956889, train loss: 21.908392, valid precision: 0.843400, valid loss: 94.128015
epoch: 3629, train precision: 0.957444, train loss: 21.470705, valid precision: 0.838000, valid loss: 98.191098
epoch: 3630, train precision: 0.958800, train loss: 21.702201, valid precision: 0.838800, valid loss: 92.029617
epoch: 3631, train precision: 0.958244, train loss: 21.251425, valid precision: 0.840000, valid loss: 103.086868
epoch: 3632, train precision: 0.952867, train loss: 23.151405, valid precision: 0.836600, valid loss: 95.357301
epoch: 3633, train precision: 0.951489, train loss: 23.625045, valid precision: 0.843600, valid loss: 93.061465
epoch: 3634, train precision: 0.958311, train loss: 21.607641, valid precision: 0.840400, valid loss: 95.476292
epoch: 3635, train precision: 0.957844, train loss: 20.806674, valid precision: 0.846000, valid loss: 97.164611
epoch: 3636, train precision: 0.951000, train loss: 23.846390, valid precision: 0.839600, valid loss: 93.962293
epoch: 3637, train precision: 0.958244, train loss: 20.991476, valid precision: 0.841600, valid loss: 101.655432
epoch: 3638, train precision: 0.952444, train loss: 23.176960, valid precision: 0.835800, valid loss: 103.695075
epoch: 3639, train precision: 0.958733, train loss: 21.497935, valid precision: 0.842200, valid loss: 102.890889
epoch: 3640, train precision: 0.952178, train loss: 23.684089, valid precision: 0.839600, valid loss: 108.724007
epoch: 3641, train precision: 0.959000, train loss: 20.677448, valid precision: 0.844400, valid loss: 96.099296
epoch: 3642, train precision: 0.955800, train loss: 21.761669, valid precision: 0.845200, valid loss: 100.306135
epoch: 3643, train precision: 0.957756, train loss: 21.288627, valid precision: 0.845600, valid loss: 97.452271
epoch: 3644, train precision: 0.956978, train loss: 21.435545, valid precision: 0.841400, valid loss: 97.741447
epoch: 3645, train precision: 0.954911, train loss: 22.317527, valid precision: 0.841400, valid loss: 101.858217
epoch: 3646, train precision: 0.952622, train loss: 23.465647, valid precision: 0.839000, valid loss: 99.535715
epoch: 3647, train precision: 0.957244, train loss: 21.332987, valid precision: 0.841200, valid loss: 98.845378
epoch: 3648, train precision: 0.958067, train loss: 21.168276, valid precision: 0.842600, valid loss: 96.580514
epoch: 3649, train precision: 0.953511, train loss: 22.824406, valid precision: 0.839800, valid loss: 101.600481
epoch: 3650, train precision: 0.955711, train loss: 22.167500, valid precision: 0.839000, valid loss: 103.135502
epoch: 3651, train precision: 0.960667, train loss: 20.415356, valid precision: 0.842600, valid loss: 96.898190
epoch: 3652, train precision: 0.954867, train loss: 22.512678, valid precision: 0.839200, valid loss: 93.125880
epoch: 3653, train precision: 0.957622, train loss: 21.607746, valid precision: 0.839400, valid loss: 92.828102
epoch: 3654, train precision: 0.957111, train loss: 21.662294, valid precision: 0.840600, valid loss: 98.913628
epoch: 3655, train precision: 0.950844, train loss: 24.103355, valid precision: 0.841800, valid loss: 100.636795
epoch: 3656, train precision: 0.954289, train loss: 22.573592, valid precision: 0.841600, valid loss: 90.069068
epoch: 3657, train precision: 0.953800, train loss: 23.281709, valid precision: 0.840000, valid loss: 93.989456
epoch: 3658, train precision: 0.956733, train loss: 21.510624, valid precision: 0.843000, valid loss: 101.820041
epoch: 3659, train precision: 0.954022, train loss: 22.752847, valid precision: 0.841000, valid loss: 105.371611
epoch: 3660, train precision: 0.950822, train loss: 23.724745, valid precision: 0.835800, valid loss: 97.073180
epoch: 3661, train precision: 0.958600, train loss: 20.630887, valid precision: 0.843200, valid loss: 103.360389
epoch: 3662, train precision: 0.953089, train loss: 22.571704, valid precision: 0.841600, valid loss: 95.110185
epoch: 3663, train precision: 0.958000, train loss: 21.448283, valid precision: 0.840600, valid loss: 96.896492
epoch: 3664, train precision: 0.956667, train loss: 22.338503, valid precision: 0.836800, valid loss: 104.703753
epoch: 3665, train precision: 0.955244, train loss: 22.194090, valid precision: 0.837800, valid loss: 98.184179
epoch: 3666, train precision: 0.958089, train loss: 21.656156, valid precision: 0.845800, valid loss: 93.833449
epoch: 3667, train precision: 0.959067, train loss: 20.934286, valid precision: 0.842800, valid loss: 97.806623
epoch: 3668, train precision: 0.959911, train loss: 20.766789, valid precision: 0.847400, valid loss: 112.011439
epoch: 3669, train precision: 0.960111, train loss: 20.311147, valid precision: 0.844200, valid loss: 105.016576
epoch: 3670, train precision: 0.956378, train loss: 21.989824, valid precision: 0.844800, valid loss: 99.782279
epoch: 3671, train precision: 0.956111, train loss: 21.821005, valid precision: 0.846000, valid loss: 99.706654
epoch: 3672, train precision: 0.955111, train loss: 22.591512, valid precision: 0.834400, valid loss: 105.681546
epoch: 3673, train precision: 0.949667, train loss: 24.922404, valid precision: 0.841800, valid loss: 97.485583
epoch: 3674, train precision: 0.953978, train loss: 22.610022, valid precision: 0.841400, valid loss: 97.859821
epoch: 3675, train precision: 0.949089, train loss: 24.289686, valid precision: 0.839400, valid loss: 95.397872
epoch: 3676, train precision: 0.956289, train loss: 21.829021, valid precision: 0.842800, valid loss: 96.991634
epoch: 3677, train precision: 0.952956, train loss: 23.097407, valid precision: 0.840600, valid loss: 102.909496
epoch: 3678, train precision: 0.960133, train loss: 20.689475, valid precision: 0.843400, valid loss: 95.233608
epoch: 3679, train precision: 0.957311, train loss: 21.844683, valid precision: 0.837400, valid loss: 107.410471
epoch: 3680, train precision: 0.957111, train loss: 22.024000, valid precision: 0.840400, valid loss: 97.160550
epoch: 3681, train precision: 0.956022, train loss: 21.867857, valid precision: 0.844400, valid loss: 94.352814
epoch: 3682, train precision: 0.956511, train loss: 21.758770, valid precision: 0.844600, valid loss: 108.782328
epoch: 3683, train precision: 0.957156, train loss: 21.533003, valid precision: 0.844800, valid loss: 95.281249
epoch: 3684, train precision: 0.955511, train loss: 21.918414, valid precision: 0.845200, valid loss: 95.979277
epoch: 3685, train precision: 0.950733, train loss: 23.752138, valid precision: 0.840600, valid loss: 93.027923
epoch: 3686, train precision: 0.957489, train loss: 21.440842, valid precision: 0.844600, valid loss: 99.488968
epoch: 3687, train precision: 0.959933, train loss: 20.008402, valid precision: 0.843600, valid loss: 101.974659
epoch: 3688, train precision: 0.955956, train loss: 22.153460, valid precision: 0.843600, valid loss: 99.811506
epoch: 3689, train precision: 0.955689, train loss: 21.785479, valid precision: 0.842400, valid loss: 92.154371
epoch: 3690, train precision: 0.954822, train loss: 22.617508, valid precision: 0.843400, valid loss: 102.613118
epoch: 3691, train precision: 0.960067, train loss: 20.184123, valid precision: 0.850600, valid loss: 104.293302
epoch: 3692, train precision: 0.955600, train loss: 22.364813, valid precision: 0.846400, valid loss: 95.801691
epoch: 3693, train precision: 0.954800, train loss: 22.263768, valid precision: 0.841000, valid loss: 100.692026
epoch: 3694, train precision: 0.951267, train loss: 23.944105, valid precision: 0.835400, valid loss: 104.636337
epoch: 3695, train precision: 0.952778, train loss: 22.948183, valid precision: 0.832800, valid loss: 99.708500
epoch: 3696, train precision: 0.954289, train loss: 22.416722, valid precision: 0.839200, valid loss: 101.071755
epoch: 3697, train precision: 0.954800, train loss: 21.969034, valid precision: 0.838800, valid loss: 102.800655
epoch: 3698, train precision: 0.953689, train loss: 23.399420, valid precision: 0.833600, valid loss: 99.246271
epoch: 3699, train precision: 0.951689, train loss: 23.773720, valid precision: 0.842600, valid loss: 109.888790
epoch: 3700, train precision: 0.954889, train loss: 22.328945, valid precision: 0.844400, valid loss: 98.490416
epoch: 3701, train precision: 0.954756, train loss: 21.897276, valid precision: 0.838400, valid loss: 106.324903
epoch: 3702, train precision: 0.954600, train loss: 22.777716, valid precision: 0.842400, valid loss: 99.250925
epoch: 3703, train precision: 0.953133, train loss: 22.834847, valid precision: 0.840600, valid loss: 100.951609
epoch: 3704, train precision: 0.957822, train loss: 21.039689, valid precision: 0.844200, valid loss: 98.584813
epoch: 3705, train precision: 0.956844, train loss: 21.567347, valid precision: 0.844600, valid loss: 101.188378
epoch: 3706, train precision: 0.957600, train loss: 21.657350, valid precision: 0.841200, valid loss: 98.557783
epoch: 3707, train precision: 0.954911, train loss: 21.909292, valid precision: 0.842800, valid loss: 97.755767
epoch: 3708, train precision: 0.953689, train loss: 23.416291, valid precision: 0.847000, valid loss: 101.964003
epoch: 3709, train precision: 0.951067, train loss: 23.755103, valid precision: 0.842000, valid loss: 94.485737
epoch: 3710, train precision: 0.953933, train loss: 22.485109, valid precision: 0.839600, valid loss: 95.945247
epoch: 3711, train precision: 0.950222, train loss: 24.774222, valid precision: 0.840600, valid loss: 94.062927
epoch: 3712, train precision: 0.963356, train loss: 19.214601, valid precision: 0.849200, valid loss: 93.535882
epoch: 3713, train precision: 0.951600, train loss: 23.559937, valid precision: 0.838200, valid loss: 104.648550
epoch: 3714, train precision: 0.958756, train loss: 20.803809, valid precision: 0.843800, valid loss: 99.715676
epoch: 3715, train precision: 0.954978, train loss: 22.390973, valid precision: 0.843400, valid loss: 98.318117
epoch: 3716, train precision: 0.956356, train loss: 21.539002, valid precision: 0.846400, valid loss: 102.019710
epoch: 3717, train precision: 0.958044, train loss: 21.688908, valid precision: 0.838600, valid loss: 100.028280
epoch: 3718, train precision: 0.950800, train loss: 23.888916, valid precision: 0.840000, valid loss: 98.043836
epoch: 3719, train precision: 0.955733, train loss: 22.190302, valid precision: 0.845200, valid loss: 95.393264
epoch: 3720, train precision: 0.960267, train loss: 20.121018, valid precision: 0.845800, valid loss: 100.698087
epoch: 3721, train precision: 0.952067, train loss: 23.081441, valid precision: 0.839600, valid loss: 100.194306
epoch: 3722, train precision: 0.957000, train loss: 20.991404, valid precision: 0.852200, valid loss: 97.403326
epoch: 3723, train precision: 0.955422, train loss: 22.089921, valid precision: 0.839000, valid loss: 93.649766
epoch: 3724, train precision: 0.960044, train loss: 20.616774, valid precision: 0.845800, valid loss: 101.030900
epoch: 3725, train precision: 0.951978, train loss: 23.141281, valid precision: 0.843400, valid loss: 99.759672
epoch: 3726, train precision: 0.955978, train loss: 22.034656, valid precision: 0.841600, valid loss: 100.002935
epoch: 3727, train precision: 0.957511, train loss: 21.458371, valid precision: 0.844600, valid loss: 95.139070
epoch: 3728, train precision: 0.959089, train loss: 20.457982, valid precision: 0.845200, valid loss: 102.498401
epoch: 3729, train precision: 0.957889, train loss: 21.340035, valid precision: 0.842000, valid loss: 103.210863
epoch: 3730, train precision: 0.952156, train loss: 23.373198, valid precision: 0.840800, valid loss: 100.451218
epoch: 3731, train precision: 0.955067, train loss: 22.612424, valid precision: 0.836600, valid loss: 101.295945
epoch: 3732, train precision: 0.960467, train loss: 20.209982, valid precision: 0.853200, valid loss: 97.230766
epoch: 3733, train precision: 0.955222, train loss: 22.346777, valid precision: 0.838800, valid loss: 100.404471
epoch: 3734, train precision: 0.952422, train loss: 23.328405, valid precision: 0.838800, valid loss: 92.599266
epoch: 3735, train precision: 0.952333, train loss: 22.923380, valid precision: 0.838800, valid loss: 103.825710
epoch: 3736, train precision: 0.959400, train loss: 20.824582, valid precision: 0.848600, valid loss: 99.094080
epoch: 3737, train precision: 0.955711, train loss: 21.975151, valid precision: 0.843200, valid loss: 102.662783
epoch: 3738, train precision: 0.949200, train loss: 24.657686, valid precision: 0.838000, valid loss: 100.805613
epoch: 3739, train precision: 0.955578, train loss: 22.252152, valid precision: 0.841400, valid loss: 103.175518
epoch: 3740, train precision: 0.950022, train loss: 24.126475, valid precision: 0.837600, valid loss: 110.033290
epoch: 3741, train precision: 0.960200, train loss: 20.614178, valid precision: 0.841200, valid loss: 97.055596
epoch: 3742, train precision: 0.955911, train loss: 21.641442, valid precision: 0.842000, valid loss: 100.060735
epoch: 3743, train precision: 0.956956, train loss: 21.222767, valid precision: 0.846200, valid loss: 102.243555
epoch: 3744, train precision: 0.956422, train loss: 22.026357, valid precision: 0.840800, valid loss: 104.296380
epoch: 3745, train precision: 0.954067, train loss: 22.662053, valid precision: 0.839000, valid loss: 100.106492
epoch: 3746, train precision: 0.952422, train loss: 23.428173, valid precision: 0.842400, valid loss: 99.988457
epoch: 3747, train precision: 0.955044, train loss: 22.132146, valid precision: 0.843400, valid loss: 100.580462
epoch: 3748, train precision: 0.951778, train loss: 23.574978, valid precision: 0.839000, valid loss: 96.420168
epoch: 3749, train precision: 0.956867, train loss: 21.314816, valid precision: 0.845800, valid loss: 97.275635
epoch: 3750, train precision: 0.955889, train loss: 22.253777, valid precision: 0.842400, valid loss: 104.165747
epoch: 3751, train precision: 0.959422, train loss: 21.004191, valid precision: 0.844200, valid loss: 94.031968
epoch: 3752, train precision: 0.954911, train loss: 22.269263, valid precision: 0.843400, valid loss: 100.546308
epoch: 3753, train precision: 0.959156, train loss: 20.885234, valid precision: 0.844200, valid loss: 101.639896
epoch: 3754, train precision: 0.959756, train loss: 20.090800, valid precision: 0.843400, valid loss: 99.764683
epoch: 3755, train precision: 0.960467, train loss: 20.760294, valid precision: 0.853400, valid loss: 94.566990
epoch: 3756, train precision: 0.956911, train loss: 21.479152, valid precision: 0.852400, valid loss: 96.053438
epoch: 3757, train precision: 0.954467, train loss: 22.845451, valid precision: 0.846200, valid loss: 97.942214
epoch: 3758, train precision: 0.953578, train loss: 22.777388, valid precision: 0.843400, valid loss: 103.953075
epoch: 3759, train precision: 0.955067, train loss: 21.603920, valid precision: 0.844200, valid loss: 100.730268
epoch: 3760, train precision: 0.958111, train loss: 21.014832, valid precision: 0.848000, valid loss: 98.173452
epoch: 3761, train precision: 0.950444, train loss: 24.400617, valid precision: 0.838800, valid loss: 99.073814
epoch: 3762, train precision: 0.955333, train loss: 22.331552, valid precision: 0.843400, valid loss: 96.922026
epoch: 3763, train precision: 0.956511, train loss: 21.305782, valid precision: 0.840600, valid loss: 100.972558
epoch: 3764, train precision: 0.955844, train loss: 22.197625, valid precision: 0.842000, valid loss: 98.319195
epoch: 3765, train precision: 0.954356, train loss: 22.848030, valid precision: 0.839400, valid loss: 105.297607
epoch: 3766, train precision: 0.951667, train loss: 23.017914, valid precision: 0.846800, valid loss: 100.058953
epoch: 3767, train precision: 0.950244, train loss: 23.520914, valid precision: 0.839800, valid loss: 95.949377
epoch: 3768, train precision: 0.957578, train loss: 21.209805, valid precision: 0.849000, valid loss: 98.561568
epoch: 3769, train precision: 0.953644, train loss: 22.370017, valid precision: 0.841600, valid loss: 106.382019
epoch: 3770, train precision: 0.957022, train loss: 21.184595, valid precision: 0.844000, valid loss: 98.661621
epoch: 3771, train precision: 0.955533, train loss: 21.588446, valid precision: 0.844600, valid loss: 104.479665
epoch: 3772, train precision: 0.956267, train loss: 21.675138, valid precision: 0.848800, valid loss: 94.990821
epoch: 3773, train precision: 0.957622, train loss: 21.227380, valid precision: 0.846600, valid loss: 99.378114
epoch: 3774, train precision: 0.951289, train loss: 23.707374, valid precision: 0.839400, valid loss: 103.195147
epoch: 3775, train precision: 0.957844, train loss: 21.535204, valid precision: 0.843200, valid loss: 95.790392
epoch: 3776, train precision: 0.951800, train loss: 23.567619, valid precision: 0.841000, valid loss: 97.337386
epoch: 3777, train precision: 0.956956, train loss: 21.596784, valid precision: 0.840000, valid loss: 102.604570
epoch: 3778, train precision: 0.956600, train loss: 21.457241, valid precision: 0.846800, valid loss: 95.558796
epoch: 3779, train precision: 0.954089, train loss: 22.711049, valid precision: 0.842800, valid loss: 109.327371
epoch: 3780, train precision: 0.957622, train loss: 21.311997, valid precision: 0.850400, valid loss: 98.305608
epoch: 3781, train precision: 0.956911, train loss: 21.882998, valid precision: 0.845200, valid loss: 95.997430
epoch: 3782, train precision: 0.955267, train loss: 22.202732, valid precision: 0.845400, valid loss: 95.625372
epoch: 3783, train precision: 0.955733, train loss: 22.191340, valid precision: 0.845200, valid loss: 93.134177
epoch: 3784, train precision: 0.957644, train loss: 21.686398, valid precision: 0.844800, valid loss: 95.506648
epoch: 3785, train precision: 0.957422, train loss: 21.147991, valid precision: 0.846000, valid loss: 99.297506
epoch: 3786, train precision: 0.961356, train loss: 20.162011, valid precision: 0.848800, valid loss: 103.246328
epoch: 3787, train precision: 0.960067, train loss: 20.570806, valid precision: 0.846800, valid loss: 98.091727
epoch: 3788, train precision: 0.952067, train loss: 23.094758, valid precision: 0.844200, valid loss: 103.022744
epoch: 3789, train precision: 0.953156, train loss: 23.024576, valid precision: 0.843600, valid loss: 106.973843
epoch: 3790, train precision: 0.956556, train loss: 21.703898, valid precision: 0.846200, valid loss: 99.939574
epoch: 3791, train precision: 0.957956, train loss: 20.866061, valid precision: 0.848400, valid loss: 104.685584
epoch: 3792, train precision: 0.958778, train loss: 20.577908, valid precision: 0.849000, valid loss: 100.296375
epoch: 3793, train precision: 0.957556, train loss: 21.822492, valid precision: 0.840000, valid loss: 107.892577
epoch: 3794, train precision: 0.955333, train loss: 21.945470, valid precision: 0.843800, valid loss: 107.929740
epoch: 3795, train precision: 0.950422, train loss: 24.071777, valid precision: 0.837600, valid loss: 107.014717
epoch: 3796, train precision: 0.956444, train loss: 21.727047, valid precision: 0.841200, valid loss: 106.104016
epoch: 3797, train precision: 0.958178, train loss: 20.920724, valid precision: 0.841400, valid loss: 96.084082
epoch: 3798, train precision: 0.957778, train loss: 21.568456, valid precision: 0.841200, valid loss: 105.392624
epoch: 3799, train precision: 0.951622, train loss: 23.311630, valid precision: 0.843400, valid loss: 95.924576
epoch: 3800, train precision: 0.955600, train loss: 21.864601, valid precision: 0.847400, valid loss: 106.086501
epoch: 3801, train precision: 0.952867, train loss: 22.407441, valid precision: 0.842600, valid loss: 108.221146
epoch: 3802, train precision: 0.954311, train loss: 21.946172, valid precision: 0.843800, valid loss: 97.918993
epoch: 3803, train precision: 0.952489, train loss: 23.089502, valid precision: 0.835200, valid loss: 95.726721
epoch: 3804, train precision: 0.957444, train loss: 21.448010, valid precision: 0.842800, valid loss: 98.460384
epoch: 3805, train precision: 0.955644, train loss: 22.004631, valid precision: 0.839400, valid loss: 98.744942
epoch: 3806, train precision: 0.956956, train loss: 21.173572, valid precision: 0.847600, valid loss: 104.572865
epoch: 3807, train precision: 0.957444, train loss: 21.387468, valid precision: 0.849000, valid loss: 96.733562
epoch: 3808, train precision: 0.958267, train loss: 21.363003, valid precision: 0.843800, valid loss: 101.827704
epoch: 3809, train precision: 0.957267, train loss: 21.134609, valid precision: 0.846800, valid loss: 97.072370
epoch: 3810, train precision: 0.951200, train loss: 23.087310, valid precision: 0.840600, valid loss: 92.414747
epoch: 3811, train precision: 0.956756, train loss: 22.242794, valid precision: 0.847200, valid loss: 94.262120
epoch: 3812, train precision: 0.960289, train loss: 19.870182, valid precision: 0.843800, valid loss: 98.289983
epoch: 3813, train precision: 0.959622, train loss: 20.789890, valid precision: 0.841800, valid loss: 99.934353
epoch: 3814, train precision: 0.953556, train loss: 23.156102, valid precision: 0.840600, valid loss: 94.471598
epoch: 3815, train precision: 0.954600, train loss: 22.398694, valid precision: 0.845000, valid loss: 97.312144
epoch: 3816, train precision: 0.955978, train loss: 21.766864, valid precision: 0.851000, valid loss: 94.737067
epoch: 3817, train precision: 0.951489, train loss: 23.126272, valid precision: 0.844000, valid loss: 91.740842
epoch: 3818, train precision: 0.957333, train loss: 21.166784, valid precision: 0.843200, valid loss: 106.552166
epoch: 3819, train precision: 0.945067, train loss: 26.212320, valid precision: 0.836600, valid loss: 96.666091
epoch: 3820, train precision: 0.954822, train loss: 21.831349, valid precision: 0.844000, valid loss: 96.557467
epoch: 3821, train precision: 0.954622, train loss: 22.138667, valid precision: 0.849000, valid loss: 100.208878
epoch: 3822, train precision: 0.956533, train loss: 21.687705, valid precision: 0.847400, valid loss: 100.500873
epoch: 3823, train precision: 0.955933, train loss: 21.891868, valid precision: 0.848600, valid loss: 90.565426
epoch: 3824, train precision: 0.944578, train loss: 26.096105, valid precision: 0.842400, valid loss: 100.710795
epoch: 3825, train precision: 0.958244, train loss: 21.064007, valid precision: 0.845800, valid loss: 98.615144
epoch: 3826, train precision: 0.955422, train loss: 22.459718, valid precision: 0.841800, valid loss: 96.353094
epoch: 3827, train precision: 0.953956, train loss: 22.204245, valid precision: 0.843200, valid loss: 103.267059
epoch: 3828, train precision: 0.952978, train loss: 22.181759, valid precision: 0.838800, valid loss: 95.204723
epoch: 3829, train precision: 0.952600, train loss: 23.820756, valid precision: 0.844200, valid loss: 94.026285
epoch: 3830, train precision: 0.953822, train loss: 22.308633, valid precision: 0.841600, valid loss: 97.237997
epoch: 3831, train precision: 0.949644, train loss: 24.795707, valid precision: 0.840400, valid loss: 94.291836
epoch: 3832, train precision: 0.948311, train loss: 25.126570, valid precision: 0.836600, valid loss: 97.273052
epoch: 3833, train precision: 0.961089, train loss: 20.112067, valid precision: 0.845600, valid loss: 94.811852
epoch: 3834, train precision: 0.957844, train loss: 21.003386, valid precision: 0.847400, valid loss: 95.193971
epoch: 3835, train precision: 0.951956, train loss: 23.342072, valid precision: 0.840400, valid loss: 99.241807
epoch: 3836, train precision: 0.959289, train loss: 20.501346, valid precision: 0.843000, valid loss: 95.148416
epoch: 3837, train precision: 0.954222, train loss: 22.726655, valid precision: 0.840600, valid loss: 91.125712
epoch: 3838, train precision: 0.959022, train loss: 20.717001, valid precision: 0.845200, valid loss: 101.383468
epoch: 3839, train precision: 0.951667, train loss: 24.116310, valid precision: 0.841000, valid loss: 99.841586
epoch: 3840, train precision: 0.957222, train loss: 21.202780, valid precision: 0.844000, valid loss: 98.874081
epoch: 3841, train precision: 0.955911, train loss: 21.812333, valid precision: 0.845000, valid loss: 97.001282
epoch: 3842, train precision: 0.956267, train loss: 21.469863, valid precision: 0.844800, valid loss: 95.360038
epoch: 3843, train precision: 0.953911, train loss: 22.588832, valid precision: 0.842400, valid loss: 94.837842
epoch: 3844, train precision: 0.952778, train loss: 22.935546, valid precision: 0.843200, valid loss: 98.860850
epoch: 3845, train precision: 0.958222, train loss: 20.879047, valid precision: 0.848400, valid loss: 93.808062
epoch: 3846, train precision: 0.956533, train loss: 21.569674, valid precision: 0.841200, valid loss: 96.349487
epoch: 3847, train precision: 0.949933, train loss: 24.489851, valid precision: 0.841200, valid loss: 101.864946
epoch: 3848, train precision: 0.961822, train loss: 19.279997, valid precision: 0.840000, valid loss: 100.040946
epoch: 3849, train precision: 0.954778, train loss: 21.918938, valid precision: 0.843800, valid loss: 100.137127
epoch: 3850, train precision: 0.960311, train loss: 20.159957, valid precision: 0.847000, valid loss: 98.831419
epoch: 3851, train precision: 0.957622, train loss: 21.449347, valid precision: 0.843400, valid loss: 97.704687
epoch: 3852, train precision: 0.955822, train loss: 21.494811, valid precision: 0.843400, valid loss: 98.088154
epoch: 3853, train precision: 0.952467, train loss: 23.418282, valid precision: 0.838000, valid loss: 106.616775
epoch: 3854, train precision: 0.951178, train loss: 23.691814, valid precision: 0.838400, valid loss: 108.918604
epoch: 3855, train precision: 0.951844, train loss: 23.290536, valid precision: 0.838800, valid loss: 97.289322
epoch: 3856, train precision: 0.959378, train loss: 20.466881, valid precision: 0.846000, valid loss: 100.592924
epoch: 3857, train precision: 0.954356, train loss: 22.601284, valid precision: 0.845600, valid loss: 95.919719
epoch: 3858, train precision: 0.955467, train loss: 21.880529, valid precision: 0.845200, valid loss: 99.740027
epoch: 3859, train precision: 0.951756, train loss: 22.868286, valid precision: 0.842400, valid loss: 102.146540
epoch: 3860, train precision: 0.957178, train loss: 21.612018, valid precision: 0.841600, valid loss: 104.046949
epoch: 3861, train precision: 0.951978, train loss: 22.591428, valid precision: 0.848200, valid loss: 99.575939
epoch: 3862, train precision: 0.949533, train loss: 24.582409, valid precision: 0.843000, valid loss: 87.567112
epoch: 3863, train precision: 0.950889, train loss: 23.447429, valid precision: 0.844200, valid loss: 104.489897
epoch: 3864, train precision: 0.952400, train loss: 22.891349, valid precision: 0.840400, valid loss: 97.244215
epoch: 3865, train precision: 0.956778, train loss: 21.169457, valid precision: 0.849600, valid loss: 93.227187
epoch: 3866, train precision: 0.954311, train loss: 22.616122, valid precision: 0.840400, valid loss: 99.685624
epoch: 3867, train precision: 0.959756, train loss: 20.438082, valid precision: 0.846600, valid loss: 95.713288
epoch: 3868, train precision: 0.954422, train loss: 22.671488, valid precision: 0.839800, valid loss: 92.489765
epoch: 3869, train precision: 0.960000, train loss: 20.563228, valid precision: 0.849800, valid loss: 96.109073
epoch: 3870, train precision: 0.958267, train loss: 21.079789, valid precision: 0.844600, valid loss: 97.281086
epoch: 3871, train precision: 0.952467, train loss: 23.313748, valid precision: 0.845200, valid loss: 98.074906
epoch: 3872, train precision: 0.954489, train loss: 22.723409, valid precision: 0.842600, valid loss: 102.582305
epoch: 3873, train precision: 0.956111, train loss: 22.063716, valid precision: 0.842800, valid loss: 102.995622
epoch: 3874, train precision: 0.953733, train loss: 23.089313, valid precision: 0.844400, valid loss: 90.960931
epoch: 3875, train precision: 0.950422, train loss: 24.247065, valid precision: 0.842000, valid loss: 96.728311
epoch: 3876, train precision: 0.958133, train loss: 20.629031, valid precision: 0.848200, valid loss: 100.853943
epoch: 3877, train precision: 0.955267, train loss: 21.810175, valid precision: 0.844600, valid loss: 100.296607
epoch: 3878, train precision: 0.958800, train loss: 20.620500, valid precision: 0.845800, valid loss: 99.753541
epoch: 3879, train precision: 0.957800, train loss: 21.199760, valid precision: 0.844200, valid loss: 97.430218
epoch: 3880, train precision: 0.954044, train loss: 22.370216, valid precision: 0.846600, valid loss: 108.453928
epoch: 3881, train precision: 0.957089, train loss: 21.886191, valid precision: 0.843200, valid loss: 95.903443
epoch: 3882, train precision: 0.959933, train loss: 20.221839, valid precision: 0.842200, valid loss: 102.158927
epoch: 3883, train precision: 0.956333, train loss: 21.886589, valid precision: 0.845200, valid loss: 99.274215
epoch: 3884, train precision: 0.954756, train loss: 22.375171, valid precision: 0.840000, valid loss: 99.611132
epoch: 3885, train precision: 0.956644, train loss: 21.481116, valid precision: 0.848400, valid loss: 96.968572
epoch: 3886, train precision: 0.959800, train loss: 20.564876, valid precision: 0.843200, valid loss: 98.710069
epoch: 3887, train precision: 0.957911, train loss: 21.664292, valid precision: 0.845200, valid loss: 99.216239
epoch: 3888, train precision: 0.957978, train loss: 21.159611, valid precision: 0.845800, valid loss: 94.567538
epoch: 3889, train precision: 0.957333, train loss: 21.195640, valid precision: 0.841800, valid loss: 98.261535
epoch: 3890, train precision: 0.954378, train loss: 21.916402, valid precision: 0.842200, valid loss: 97.418625
epoch: 3891, train precision: 0.957933, train loss: 20.661626, valid precision: 0.841400, valid loss: 98.093778
epoch: 3892, train precision: 0.952111, train loss: 22.703159, valid precision: 0.838200, valid loss: 95.306901
epoch: 3893, train precision: 0.950867, train loss: 23.799356, valid precision: 0.837800, valid loss: 103.872402
epoch: 3894, train precision: 0.952644, train loss: 22.981195, valid precision: 0.835200, valid loss: 104.696935
epoch: 3895, train precision: 0.957933, train loss: 21.096371, valid precision: 0.844000, valid loss: 95.065096
epoch: 3896, train precision: 0.956889, train loss: 21.232352, valid precision: 0.842800, valid loss: 101.434754
epoch: 3897, train precision: 0.956756, train loss: 21.395430, valid precision: 0.839400, valid loss: 101.443331
epoch: 3898, train precision: 0.955022, train loss: 22.245325, valid precision: 0.838400, valid loss: 92.019510
epoch: 3899, train precision: 0.959756, train loss: 20.647932, valid precision: 0.850400, valid loss: 92.208485
epoch: 3900, train precision: 0.958867, train loss: 21.106848, valid precision: 0.844000, valid loss: 93.813193
epoch: 3901, train precision: 0.958733, train loss: 20.748204, valid precision: 0.842800, valid loss: 98.523408
epoch: 3902, train precision: 0.954200, train loss: 22.508990, valid precision: 0.848000, valid loss: 95.328019
epoch: 3903, train precision: 0.951578, train loss: 23.446465, valid precision: 0.845600, valid loss: 99.908134
epoch: 3904, train precision: 0.960600, train loss: 20.103937, valid precision: 0.844000, valid loss: 101.114324
epoch: 3905, train precision: 0.956356, train loss: 21.367522, valid precision: 0.841400, valid loss: 106.974112
epoch: 3906, train precision: 0.956533, train loss: 21.936732, valid precision: 0.843400, valid loss: 101.895557
epoch: 3907, train precision: 0.955178, train loss: 22.064098, valid precision: 0.845600, valid loss: 94.072215
epoch: 3908, train precision: 0.953556, train loss: 23.274813, valid precision: 0.839600, valid loss: 91.319859
epoch: 3909, train precision: 0.957200, train loss: 21.118142, valid precision: 0.846200, valid loss: 100.591250
epoch: 3910, train precision: 0.955222, train loss: 21.743761, valid precision: 0.845200, valid loss: 101.380543
epoch: 3911, train precision: 0.958889, train loss: 20.105595, valid precision: 0.844000, valid loss: 103.322917
epoch: 3912, train precision: 0.952222, train loss: 23.084727, valid precision: 0.840600, valid loss: 100.359492
epoch: 3913, train precision: 0.958578, train loss: 20.642202, valid precision: 0.845600, valid loss: 103.520026
epoch: 3914, train precision: 0.957733, train loss: 21.392718, valid precision: 0.838200, valid loss: 102.895009
epoch: 3915, train precision: 0.959844, train loss: 20.230991, valid precision: 0.850800, valid loss: 94.628990
epoch: 3916, train precision: 0.957311, train loss: 20.690944, valid precision: 0.849400, valid loss: 98.282245
epoch: 3917, train precision: 0.951289, train loss: 23.529801, valid precision: 0.847400, valid loss: 98.229053
epoch: 3918, train precision: 0.955822, train loss: 21.579131, valid precision: 0.846200, valid loss: 102.127396
epoch: 3919, train precision: 0.953667, train loss: 23.260351, valid precision: 0.836200, valid loss: 98.332174
epoch: 3920, train precision: 0.958444, train loss: 20.638895, valid precision: 0.841200, valid loss: 99.140270
epoch: 3921, train precision: 0.957822, train loss: 20.600959, valid precision: 0.846200, valid loss: 95.844498
epoch: 3922, train precision: 0.957244, train loss: 21.008136, valid precision: 0.848000, valid loss: 96.784358
epoch: 3923, train precision: 0.954733, train loss: 21.854992, valid precision: 0.846200, valid loss: 95.659631
epoch: 3924, train precision: 0.958378, train loss: 21.017719, valid precision: 0.843600, valid loss: 99.606661
epoch: 3925, train precision: 0.956511, train loss: 21.390147, valid precision: 0.842600, valid loss: 95.815105
epoch: 3926, train precision: 0.951622, train loss: 23.030311, valid precision: 0.843200, valid loss: 99.390111
epoch: 3927, train precision: 0.955933, train loss: 22.463801, valid precision: 0.845200, valid loss: 95.257381
epoch: 3928, train precision: 0.956200, train loss: 21.865073, valid precision: 0.840400, valid loss: 95.268966
epoch: 3929, train precision: 0.953556, train loss: 22.665939, valid precision: 0.839200, valid loss: 100.466058
epoch: 3930, train precision: 0.956533, train loss: 21.412010, valid precision: 0.842400, valid loss: 98.468567
epoch: 3931, train precision: 0.955711, train loss: 21.666294, valid precision: 0.842000, valid loss: 101.461271
epoch: 3932, train precision: 0.955667, train loss: 21.793791, valid precision: 0.843800, valid loss: 93.152887
epoch: 3933, train precision: 0.960578, train loss: 19.871711, valid precision: 0.846000, valid loss: 98.753286
epoch: 3934, train precision: 0.955089, train loss: 21.530560, valid precision: 0.848200, valid loss: 94.964461
epoch: 3935, train precision: 0.958889, train loss: 20.379727, valid precision: 0.845800, valid loss: 95.014848
epoch: 3936, train precision: 0.953533, train loss: 22.955342, valid precision: 0.838000, valid loss: 96.714723
epoch: 3937, train precision: 0.956467, train loss: 21.318463, valid precision: 0.843600, valid loss: 101.115115
epoch: 3938, train precision: 0.954133, train loss: 22.583077, valid precision: 0.843400, valid loss: 105.400703
epoch: 3939, train precision: 0.955133, train loss: 21.980743, valid precision: 0.841600, valid loss: 97.148256
epoch: 3940, train precision: 0.957800, train loss: 20.909278, valid precision: 0.846600, valid loss: 103.146226
epoch: 3941, train precision: 0.960156, train loss: 20.906846, valid precision: 0.841200, valid loss: 96.072987
epoch: 3942, train precision: 0.956511, train loss: 21.467153, valid precision: 0.840800, valid loss: 94.507480
epoch: 3943, train precision: 0.953022, train loss: 22.957658, valid precision: 0.841000, valid loss: 98.493942
epoch: 3944, train precision: 0.951622, train loss: 23.217780, valid precision: 0.843200, valid loss: 93.362408
epoch: 3945, train precision: 0.951911, train loss: 23.839373, valid precision: 0.844400, valid loss: 88.659097
epoch: 3946, train precision: 0.959422, train loss: 20.497033, valid precision: 0.842200, valid loss: 95.406229
epoch: 3947, train precision: 0.954467, train loss: 22.219785, valid precision: 0.841600, valid loss: 94.993269
epoch: 3948, train precision: 0.958644, train loss: 20.706374, valid precision: 0.841600, valid loss: 92.521240
epoch: 3949, train precision: 0.957911, train loss: 20.454842, valid precision: 0.847000, valid loss: 96.999240
epoch: 3950, train precision: 0.959067, train loss: 20.253470, valid precision: 0.851000, valid loss: 94.503289
epoch: 3951, train precision: 0.954467, train loss: 21.823083, valid precision: 0.841200, valid loss: 99.829155
epoch: 3952, train precision: 0.953289, train loss: 22.749114, valid precision: 0.841200, valid loss: 97.160755
epoch: 3953, train precision: 0.955022, train loss: 22.086092, valid precision: 0.846800, valid loss: 98.338625
epoch: 3954, train precision: 0.956622, train loss: 21.917531, valid precision: 0.842400, valid loss: 97.370866
epoch: 3955, train precision: 0.956822, train loss: 22.108414, valid precision: 0.843600, valid loss: 96.717976
epoch: 3956, train precision: 0.958511, train loss: 20.790922, valid precision: 0.849000, valid loss: 93.052126
epoch: 3957, train precision: 0.954867, train loss: 21.828206, valid precision: 0.843600, valid loss: 98.912586
epoch: 3958, train precision: 0.955311, train loss: 21.965957, valid precision: 0.842400, valid loss: 93.422490
epoch: 3959, train precision: 0.953111, train loss: 22.923062, valid precision: 0.837200, valid loss: 93.470946
epoch: 3960, train precision: 0.958467, train loss: 21.643125, valid precision: 0.842800, valid loss: 96.183694
epoch: 3961, train precision: 0.952689, train loss: 22.776651, valid precision: 0.841000, valid loss: 97.128411
epoch: 3962, train precision: 0.954444, train loss: 22.703751, valid precision: 0.846000, valid loss: 97.032371
epoch: 3963, train precision: 0.954822, train loss: 21.727090, valid precision: 0.841400, valid loss: 97.046036
epoch: 3964, train precision: 0.955844, train loss: 21.671704, valid precision: 0.840200, valid loss: 93.444881
epoch: 3965, train precision: 0.956444, train loss: 21.461293, valid precision: 0.845800, valid loss: 93.523006
epoch: 3966, train precision: 0.959956, train loss: 20.421496, valid precision: 0.841800, valid loss: 94.014106
epoch: 3967, train precision: 0.943622, train loss: 25.360676, valid precision: 0.833600, valid loss: 92.356033
epoch: 3968, train precision: 0.957711, train loss: 21.097431, valid precision: 0.844600, valid loss: 93.611228
epoch: 3969, train precision: 0.953311, train loss: 22.310603, valid precision: 0.840600, valid loss: 100.730415
epoch: 3970, train precision: 0.953178, train loss: 22.815980, valid precision: 0.839800, valid loss: 105.663302
epoch: 3971, train precision: 0.953111, train loss: 22.990000, valid precision: 0.838000, valid loss: 101.010224
epoch: 3972, train precision: 0.954933, train loss: 21.866119, valid precision: 0.843400, valid loss: 94.786719
epoch: 3973, train precision: 0.956844, train loss: 21.337739, valid precision: 0.842400, valid loss: 100.236665
epoch: 3974, train precision: 0.955244, train loss: 21.746212, valid precision: 0.844800, valid loss: 97.067724
epoch: 3975, train precision: 0.960244, train loss: 20.174360, valid precision: 0.843600, valid loss: 97.889618
epoch: 3976, train precision: 0.958511, train loss: 20.561061, valid precision: 0.842800, valid loss: 100.082074
epoch: 3977, train precision: 0.956978, train loss: 21.382690, valid precision: 0.843800, valid loss: 99.473055
epoch: 3978, train precision: 0.957600, train loss: 20.899547, valid precision: 0.842000, valid loss: 99.364702
epoch: 3979, train precision: 0.955600, train loss: 22.150208, valid precision: 0.847000, valid loss: 99.747329
epoch: 3980, train precision: 0.948867, train loss: 24.036001, valid precision: 0.840200, valid loss: 97.845260
epoch: 3981, train precision: 0.949000, train loss: 23.934309, valid precision: 0.842000, valid loss: 94.259022
epoch: 3982, train precision: 0.958711, train loss: 21.071291, valid precision: 0.843000, valid loss: 98.748186
epoch: 3983, train precision: 0.959200, train loss: 20.644918, valid precision: 0.845600, valid loss: 96.136731
epoch: 3984, train precision: 0.957533, train loss: 21.962735, valid precision: 0.844800, valid loss: 91.724826
epoch: 3985, train precision: 0.954400, train loss: 22.491754, valid precision: 0.841200, valid loss: 97.404283
epoch: 3986, train precision: 0.954356, train loss: 22.186975, valid precision: 0.836400, valid loss: 92.502656
epoch: 3987, train precision: 0.958889, train loss: 20.177094, valid precision: 0.843800, valid loss: 96.929866
epoch: 3988, train precision: 0.955400, train loss: 22.030775, valid precision: 0.842800, valid loss: 99.487829
epoch: 3989, train precision: 0.958689, train loss: 20.797926, valid precision: 0.839200, valid loss: 98.388316
epoch: 3990, train precision: 0.955356, train loss: 21.745864, valid precision: 0.838200, valid loss: 99.975403
epoch: 3991, train precision: 0.952111, train loss: 23.309006, valid precision: 0.837400, valid loss: 99.315608
epoch: 3992, train precision: 0.953933, train loss: 22.218664, valid precision: 0.841800, valid loss: 100.805597
epoch: 3993, train precision: 0.960733, train loss: 20.142726, valid precision: 0.845600, valid loss: 94.763296
epoch: 3994, train precision: 0.955600, train loss: 21.710792, valid precision: 0.845400, valid loss: 95.237840
epoch: 3995, train precision: 0.960511, train loss: 20.082867, valid precision: 0.846600, valid loss: 97.564990
epoch: 3996, train precision: 0.957067, train loss: 21.140667, valid precision: 0.845400, valid loss: 102.441048
epoch: 3997, train precision: 0.957711, train loss: 21.283528, valid precision: 0.840800, valid loss: 104.283207
epoch: 3998, train precision: 0.953644, train loss: 22.980438, valid precision: 0.839000, valid loss: 94.764879
epoch: 3999, train precision: 0.957600, train loss: 21.069270, valid precision: 0.846400, valid loss: 98.223387
epoch: 4000, train precision: 0.956222, train loss: 21.790062, valid precision: 0.848200, valid loss: 95.689805
epoch: 4001, train precision: 0.955933, train loss: 21.314737, valid precision: 0.836800, valid loss: 101.297722
epoch: 4002, train precision: 0.954644, train loss: 22.451660, valid precision: 0.840000, valid loss: 100.668652
epoch: 4003, train precision: 0.955533, train loss: 21.585005, valid precision: 0.848200, valid loss: 99.297949
epoch: 4004, train precision: 0.956000, train loss: 21.399458, valid precision: 0.847600, valid loss: 99.221383
epoch: 4005, train precision: 0.951400, train loss: 22.844819, valid precision: 0.838800, valid loss: 98.670901
epoch: 4006, train precision: 0.950622, train loss: 24.290726, valid precision: 0.841200, valid loss: 89.512887
epoch: 4007, train precision: 0.954511, train loss: 22.427272, valid precision: 0.843200, valid loss: 99.427256
epoch: 4008, train precision: 0.956667, train loss: 21.492650, valid precision: 0.847600, valid loss: 101.563940
epoch: 4009, train precision: 0.955444, train loss: 21.899628, valid precision: 0.845800, valid loss: 90.287319
epoch: 4010, train precision: 0.957800, train loss: 20.821336, valid precision: 0.842800, valid loss: 104.733383
epoch: 4011, train precision: 0.957822, train loss: 20.750021, valid precision: 0.842000, valid loss: 98.661046
epoch: 4012, train precision: 0.954444, train loss: 22.167042, valid precision: 0.844000, valid loss: 96.704694
epoch: 4013, train precision: 0.956556, train loss: 21.860534, valid precision: 0.841800, valid loss: 94.237528
epoch: 4014, train precision: 0.955822, train loss: 21.107932, valid precision: 0.842000, valid loss: 107.814653
epoch: 4015, train precision: 0.958578, train loss: 20.638327, valid precision: 0.846800, valid loss: 94.591868
epoch: 4016, train precision: 0.956556, train loss: 21.069383, valid precision: 0.843200, valid loss: 104.739933
epoch: 4017, train precision: 0.953578, train loss: 21.910418, valid precision: 0.846200, valid loss: 95.787886
epoch: 4018, train precision: 0.955200, train loss: 21.914127, valid precision: 0.844200, valid loss: 93.665592
epoch: 4019, train precision: 0.957333, train loss: 20.616970, valid precision: 0.849800, valid loss: 93.717932
epoch: 4020, train precision: 0.957133, train loss: 21.221528, valid precision: 0.843600, valid loss: 96.841941
epoch: 4021, train precision: 0.956733, train loss: 21.617891, valid precision: 0.849400, valid loss: 101.833644
epoch: 4022, train precision: 0.952689, train loss: 22.871369, valid precision: 0.834000, valid loss: 97.202925
epoch: 4023, train precision: 0.959311, train loss: 20.825407, valid precision: 0.844600, valid loss: 98.386161
epoch: 4024, train precision: 0.957867, train loss: 20.911839, valid precision: 0.849000, valid loss: 94.325827
epoch: 4025, train precision: 0.957867, train loss: 20.978171, valid precision: 0.845600, valid loss: 97.974238
epoch: 4026, train precision: 0.953711, train loss: 22.405666, valid precision: 0.844200, valid loss: 95.450352
epoch: 4027, train precision: 0.956622, train loss: 21.256478, valid precision: 0.847200, valid loss: 99.496400
epoch: 4028, train precision: 0.955889, train loss: 21.759040, valid precision: 0.849400, valid loss: 94.645900
epoch: 4029, train precision: 0.956089, train loss: 20.797358, valid precision: 0.847200, valid loss: 99.527922
epoch: 4030, train precision: 0.948356, train loss: 24.247657, valid precision: 0.838800, valid loss: 97.398265
epoch: 4031, train precision: 0.955800, train loss: 22.241956, valid precision: 0.847000, valid loss: 94.616434
epoch: 4032, train precision: 0.955467, train loss: 21.481616, valid precision: 0.849600, valid loss: 96.840995
epoch: 4033, train precision: 0.951867, train loss: 23.104562, valid precision: 0.841600, valid loss: 100.887173
epoch: 4034, train precision: 0.953911, train loss: 22.275761, valid precision: 0.845200, valid loss: 105.322365
epoch: 4035, train precision: 0.955178, train loss: 21.830908, valid precision: 0.845600, valid loss: 90.318170
epoch: 4036, train precision: 0.956644, train loss: 21.481990, valid precision: 0.837000, valid loss: 98.516816
epoch: 4037, train precision: 0.953044, train loss: 22.866972, valid precision: 0.843200, valid loss: 101.157871
epoch: 4038, train precision: 0.957800, train loss: 21.195714, valid precision: 0.847600, valid loss: 102.484892
epoch: 4039, train precision: 0.957622, train loss: 21.204944, valid precision: 0.842600, valid loss: 96.784207
epoch: 4040, train precision: 0.956156, train loss: 21.549129, valid precision: 0.843800, valid loss: 95.631448
epoch: 4041, train precision: 0.955578, train loss: 21.631382, valid precision: 0.841000, valid loss: 97.349566
epoch: 4042, train precision: 0.954911, train loss: 21.747699, valid precision: 0.846400, valid loss: 96.872799
epoch: 4043, train precision: 0.955022, train loss: 22.056576, valid precision: 0.841400, valid loss: 99.802027
epoch: 4044, train precision: 0.953533, train loss: 22.638305, valid precision: 0.844600, valid loss: 95.717003
epoch: 4045, train precision: 0.957200, train loss: 21.011630, valid precision: 0.843800, valid loss: 104.227929
epoch: 4046, train precision: 0.951956, train loss: 23.113855, valid precision: 0.839600, valid loss: 104.158691
epoch: 4047, train precision: 0.953289, train loss: 21.977185, valid precision: 0.845200, valid loss: 95.425884
epoch: 4048, train precision: 0.959600, train loss: 20.840551, valid precision: 0.846400, valid loss: 106.818800
epoch: 4049, train precision: 0.954267, train loss: 22.824274, valid precision: 0.838800, valid loss: 96.158039
epoch: 4050, train precision: 0.953044, train loss: 22.503349, valid precision: 0.842600, valid loss: 99.733535
epoch: 4051, train precision: 0.958400, train loss: 20.941412, valid precision: 0.847000, valid loss: 100.211749
epoch: 4052, train precision: 0.953800, train loss: 22.389323, valid precision: 0.843800, valid loss: 98.944122
epoch: 4053, train precision: 0.957778, train loss: 21.110014, valid precision: 0.845200, valid loss: 98.876460
epoch: 4054, train precision: 0.952222, train loss: 23.426124, valid precision: 0.835600, valid loss: 102.077282
epoch: 4055, train precision: 0.954356, train loss: 21.751869, valid precision: 0.851200, valid loss: 98.866418
epoch: 4056, train precision: 0.956289, train loss: 22.007385, valid precision: 0.839400, valid loss: 95.870061
epoch: 4057, train precision: 0.952089, train loss: 23.036866, valid precision: 0.843600, valid loss: 104.744595
epoch: 4058, train precision: 0.960756, train loss: 20.005858, valid precision: 0.847600, valid loss: 99.534083
epoch: 4059, train precision: 0.956289, train loss: 21.662047, valid precision: 0.842400, valid loss: 102.752232
epoch: 4060, train precision: 0.955911, train loss: 21.773663, valid precision: 0.845400, valid loss: 102.091023
epoch: 4061, train precision: 0.958111, train loss: 20.526373, valid precision: 0.847600, valid loss: 104.543492
epoch: 4062, train precision: 0.958022, train loss: 20.884786, valid precision: 0.846400, valid loss: 98.686165
epoch: 4063, train precision: 0.956444, train loss: 21.630013, valid precision: 0.846000, valid loss: 94.250216
epoch: 4064, train precision: 0.953844, train loss: 22.003629, valid precision: 0.844600, valid loss: 105.027283
epoch: 4065, train precision: 0.957933, train loss: 20.692252, valid precision: 0.848200, valid loss: 95.887383
epoch: 4066, train precision: 0.951667, train loss: 24.006973, valid precision: 0.838200, valid loss: 110.846796
epoch: 4067, train precision: 0.957333, train loss: 20.901117, valid precision: 0.848000, valid loss: 102.293820
epoch: 4068, train precision: 0.960200, train loss: 19.902489, valid precision: 0.847600, valid loss: 97.177643
epoch: 4069, train precision: 0.953933, train loss: 22.576537, valid precision: 0.843800, valid loss: 97.551987
epoch: 4070, train precision: 0.954356, train loss: 21.962589, valid precision: 0.844200, valid loss: 98.618191
epoch: 4071, train precision: 0.960267, train loss: 19.935998, valid precision: 0.847800, valid loss: 98.279070
epoch: 4072, train precision: 0.955089, train loss: 21.783045, valid precision: 0.840600, valid loss: 94.716028
epoch: 4073, train precision: 0.957089, train loss: 21.514912, valid precision: 0.846400, valid loss: 96.193153
epoch: 4074, train precision: 0.955022, train loss: 22.053157, valid precision: 0.844000, valid loss: 104.668058
epoch: 4075, train precision: 0.957978, train loss: 20.954443, valid precision: 0.841000, valid loss: 95.008521
epoch: 4076, train precision: 0.954733, train loss: 21.738904, valid precision: 0.841000, valid loss: 97.842934
epoch: 4077, train precision: 0.953333, train loss: 22.545406, valid precision: 0.839000, valid loss: 102.660202
epoch: 4078, train precision: 0.952422, train loss: 23.306380, valid precision: 0.842200, valid loss: 94.181198
epoch: 4079, train precision: 0.956044, train loss: 21.963478, valid precision: 0.841800, valid loss: 92.693684
epoch: 4080, train precision: 0.953400, train loss: 22.730700, valid precision: 0.846200, valid loss: 95.564113
epoch: 4081, train precision: 0.957022, train loss: 21.472642, valid precision: 0.844600, valid loss: 100.440922
epoch: 4082, train precision: 0.953933, train loss: 22.562922, valid precision: 0.844200, valid loss: 98.004081
epoch: 4083, train precision: 0.949222, train loss: 23.326906, valid precision: 0.835600, valid loss: 103.365478
epoch: 4084, train precision: 0.956444, train loss: 21.478024, valid precision: 0.840800, valid loss: 100.416847
epoch: 4085, train precision: 0.951911, train loss: 23.373673, valid precision: 0.841400, valid loss: 98.263461
epoch: 4086, train precision: 0.956778, train loss: 21.241266, valid precision: 0.845800, valid loss: 92.508154
epoch: 4087, train precision: 0.952956, train loss: 22.213596, valid precision: 0.843400, valid loss: 98.842254
epoch: 4088, train precision: 0.957111, train loss: 21.459669, valid precision: 0.847800, valid loss: 92.620578
epoch: 4089, train precision: 0.958667, train loss: 20.351704, valid precision: 0.846800, valid loss: 95.352527
epoch: 4090, train precision: 0.957400, train loss: 20.672720, valid precision: 0.851200, valid loss: 96.907774
epoch: 4091, train precision: 0.955733, train loss: 21.483511, valid precision: 0.838200, valid loss: 98.472330
epoch: 4092, train precision: 0.957044, train loss: 21.390880, valid precision: 0.844200, valid loss: 89.477102
epoch: 4093, train precision: 0.957378, train loss: 20.807020, valid precision: 0.845800, valid loss: 96.859801
epoch: 4094, train precision: 0.957333, train loss: 21.033358, valid precision: 0.843800, valid loss: 97.425617
epoch: 4095, train precision: 0.956511, train loss: 21.311240, valid precision: 0.848400, valid loss: 95.328752
epoch: 4096, train precision: 0.953044, train loss: 22.211419, valid precision: 0.847200, valid loss: 92.097644
epoch: 4097, train precision: 0.959311, train loss: 20.276954, valid precision: 0.850800, valid loss: 90.788731
epoch: 4098, train precision: 0.955333, train loss: 21.795809, valid precision: 0.846800, valid loss: 87.537077
epoch: 4099, train precision: 0.954911, train loss: 21.538143, valid precision: 0.846200, valid loss: 99.120987
epoch: 4100, train precision: 0.954622, train loss: 22.305324, valid precision: 0.846000, valid loss: 104.372741
epoch: 4101, train precision: 0.953044, train loss: 22.217978, valid precision: 0.844400, valid loss: 104.024739
epoch: 4102, train precision: 0.953444, train loss: 22.147692, valid precision: 0.848000, valid loss: 101.548756
epoch: 4103, train precision: 0.958756, train loss: 20.141894, valid precision: 0.847400, valid loss: 89.878180
epoch: 4104, train precision: 0.960067, train loss: 19.971510, valid precision: 0.845600, valid loss: 97.200995
epoch: 4105, train precision: 0.954956, train loss: 21.865159, valid precision: 0.841000, valid loss: 101.759314
epoch: 4106, train precision: 0.958133, train loss: 20.623597, valid precision: 0.846400, valid loss: 96.530837
epoch: 4107, train precision: 0.957533, train loss: 21.082618, valid precision: 0.846800, valid loss: 100.059200
epoch: 4108, train precision: 0.958511, train loss: 20.931978, valid precision: 0.848400, valid loss: 89.331032
epoch: 4109, train precision: 0.956489, train loss: 21.495569, valid precision: 0.844200, valid loss: 91.390293
epoch: 4110, train precision: 0.955200, train loss: 21.749828, valid precision: 0.842400, valid loss: 102.741218
epoch: 4111, train precision: 0.957511, train loss: 21.116899, valid precision: 0.843800, valid loss: 93.038542
epoch: 4112, train precision: 0.956311, train loss: 21.015883, valid precision: 0.845200, valid loss: 93.890602
epoch: 4113, train precision: 0.961111, train loss: 19.790215, valid precision: 0.841200, valid loss: 94.278286
epoch: 4114, train precision: 0.959667, train loss: 20.567570, valid precision: 0.846400, valid loss: 98.679392
epoch: 4115, train precision: 0.957378, train loss: 21.680479, valid precision: 0.847600, valid loss: 92.846055
epoch: 4116, train precision: 0.957711, train loss: 21.269559, valid precision: 0.846200, valid loss: 94.766608
epoch: 4117, train precision: 0.960556, train loss: 20.310394, valid precision: 0.847000, valid loss: 90.673794
epoch: 4118, train precision: 0.961000, train loss: 19.880282, valid precision: 0.847600, valid loss: 94.212858
epoch: 4119, train precision: 0.955711, train loss: 21.651118, valid precision: 0.845200, valid loss: 97.593299
epoch: 4120, train precision: 0.958667, train loss: 20.845472, valid precision: 0.845000, valid loss: 95.128462
epoch: 4121, train precision: 0.948667, train loss: 24.378422, valid precision: 0.836600, valid loss: 97.025259
epoch: 4122, train precision: 0.955311, train loss: 21.827152, valid precision: 0.839200, valid loss: 95.711074
epoch: 4123, train precision: 0.958489, train loss: 20.650872, valid precision: 0.846000, valid loss: 101.176007
epoch: 4124, train precision: 0.959711, train loss: 19.750357, valid precision: 0.845000, valid loss: 97.739727
epoch: 4125, train precision: 0.955333, train loss: 21.577439, valid precision: 0.842600, valid loss: 96.540117
epoch: 4126, train precision: 0.956800, train loss: 21.679328, valid precision: 0.843200, valid loss: 92.906221
epoch: 4127, train precision: 0.954822, train loss: 21.893826, valid precision: 0.845000, valid loss: 91.016762
epoch: 4128, train precision: 0.953867, train loss: 21.963382, valid precision: 0.839400, valid loss: 104.295046
epoch: 4129, train precision: 0.957244, train loss: 21.276084, valid precision: 0.844000, valid loss: 98.662290
epoch: 4130, train precision: 0.957200, train loss: 20.668784, valid precision: 0.845200, valid loss: 98.475626
epoch: 4131, train precision: 0.958089, train loss: 20.773227, valid precision: 0.844600, valid loss: 98.325808
epoch: 4132, train precision: 0.958556, train loss: 20.686027, valid precision: 0.842200, valid loss: 96.076873
epoch: 4133, train precision: 0.951956, train loss: 22.859696, valid precision: 0.842400, valid loss: 105.702704
epoch: 4134, train precision: 0.953867, train loss: 22.423154, valid precision: 0.842600, valid loss: 99.000509
epoch: 4135, train precision: 0.962244, train loss: 19.246652, valid precision: 0.845600, valid loss: 96.012532
epoch: 4136, train precision: 0.957333, train loss: 20.350035, valid precision: 0.846600, valid loss: 101.230222
epoch: 4137, train precision: 0.959000, train loss: 20.198372, valid precision: 0.845400, valid loss: 100.669452
epoch: 4138, train precision: 0.953467, train loss: 22.316624, valid precision: 0.843200, valid loss: 100.933976
epoch: 4139, train precision: 0.957600, train loss: 21.228183, valid precision: 0.843800, valid loss: 96.345479
epoch: 4140, train precision: 0.954333, train loss: 21.696186, valid precision: 0.842400, valid loss: 99.115015
epoch: 4141, train precision: 0.958533, train loss: 20.412682, valid precision: 0.850200, valid loss: 97.667771
epoch: 4142, train precision: 0.958022, train loss: 20.605325, valid precision: 0.844600, valid loss: 101.546565
epoch: 4143, train precision: 0.951978, train loss: 22.895427, valid precision: 0.839800, valid loss: 97.130809
epoch: 4144, train precision: 0.953400, train loss: 22.254165, valid precision: 0.841400, valid loss: 102.880983
epoch: 4145, train precision: 0.950400, train loss: 23.657245, valid precision: 0.841600, valid loss: 93.448210
epoch: 4146, train precision: 0.958333, train loss: 20.750682, valid precision: 0.844800, valid loss: 99.676308
epoch: 4147, train precision: 0.956889, train loss: 21.342538, valid precision: 0.849000, valid loss: 99.183473
epoch: 4148, train precision: 0.951067, train loss: 23.495071, valid precision: 0.846800, valid loss: 100.274893
epoch: 4149, train precision: 0.953244, train loss: 23.013038, valid precision: 0.841200, valid loss: 99.618611
epoch: 4150, train precision: 0.958289, train loss: 20.472764, valid precision: 0.847400, valid loss: 101.693412
epoch: 4151, train precision: 0.956178, train loss: 21.433958, valid precision: 0.842400, valid loss: 101.398834
epoch: 4152, train precision: 0.959978, train loss: 19.953060, valid precision: 0.848800, valid loss: 97.947825
epoch: 4153, train precision: 0.955111, train loss: 21.109836, valid precision: 0.849200, valid loss: 92.782334
epoch: 4154, train precision: 0.957133, train loss: 20.624883, valid precision: 0.848200, valid loss: 94.030827
epoch: 4155, train precision: 0.955756, train loss: 21.608188, valid precision: 0.842000, valid loss: 104.768740
epoch: 4156, train precision: 0.953733, train loss: 21.704592, valid precision: 0.843200, valid loss: 96.981075
epoch: 4157, train precision: 0.952600, train loss: 23.276331, valid precision: 0.839400, valid loss: 101.764884
epoch: 4158, train precision: 0.961244, train loss: 19.252981, valid precision: 0.846800, valid loss: 100.225401
epoch: 4159, train precision: 0.956333, train loss: 21.614028, valid precision: 0.838000, valid loss: 106.327291
epoch: 4160, train precision: 0.955733, train loss: 21.493881, valid precision: 0.841400, valid loss: 99.953139
epoch: 4161, train precision: 0.952533, train loss: 22.572058, valid precision: 0.844200, valid loss: 100.961562
epoch: 4162, train precision: 0.952733, train loss: 23.164310, valid precision: 0.838000, valid loss: 97.221115
epoch: 4163, train precision: 0.958178, train loss: 20.469999, valid precision: 0.844600, valid loss: 98.608645
epoch: 4164, train precision: 0.953867, train loss: 22.153675, valid precision: 0.846400, valid loss: 94.971371
epoch: 4165, train precision: 0.956067, train loss: 21.967777, valid precision: 0.843800, valid loss: 91.044111
epoch: 4166, train precision: 0.954644, train loss: 22.122999, valid precision: 0.841200, valid loss: 94.342478
epoch: 4167, train precision: 0.957844, train loss: 20.990141, valid precision: 0.845000, valid loss: 90.022798
epoch: 4168, train precision: 0.954200, train loss: 22.529474, valid precision: 0.841400, valid loss: 104.365343
epoch: 4169, train precision: 0.954333, train loss: 22.161202, valid precision: 0.840200, valid loss: 98.954409
epoch: 4170, train precision: 0.955667, train loss: 21.892479, valid precision: 0.840600, valid loss: 98.576264
epoch: 4171, train precision: 0.956467, train loss: 21.335204, valid precision: 0.841600, valid loss: 99.735784
epoch: 4172, train precision: 0.960689, train loss: 19.802867, valid precision: 0.846600, valid loss: 95.591250
epoch: 4173, train precision: 0.950867, train loss: 23.123640, valid precision: 0.842400, valid loss: 96.694198
epoch: 4174, train precision: 0.959800, train loss: 20.135014, valid precision: 0.849400, valid loss: 96.166989
epoch: 4175, train precision: 0.957933, train loss: 20.985546, valid precision: 0.843200, valid loss: 104.121707
epoch: 4176, train precision: 0.957733, train loss: 20.766066, valid precision: 0.849600, valid loss: 99.693905
epoch: 4177, train precision: 0.959578, train loss: 20.084366, valid precision: 0.848000, valid loss: 94.917905
epoch: 4178, train precision: 0.959267, train loss: 19.977755, valid precision: 0.845000, valid loss: 103.150633
epoch: 4179, train precision: 0.957000, train loss: 21.054907, valid precision: 0.844200, valid loss: 96.353273
epoch: 4180, train precision: 0.960133, train loss: 20.163124, valid precision: 0.843200, valid loss: 94.334855
epoch: 4181, train precision: 0.955533, train loss: 21.738523, valid precision: 0.843800, valid loss: 101.717796
epoch: 4182, train precision: 0.956067, train loss: 21.235913, valid precision: 0.846000, valid loss: 104.141724
epoch: 4183, train precision: 0.956156, train loss: 21.436301, valid precision: 0.841600, valid loss: 98.114156
epoch: 4184, train precision: 0.957289, train loss: 20.987298, valid precision: 0.844600, valid loss: 97.051992
epoch: 4185, train precision: 0.948956, train loss: 24.690525, valid precision: 0.837800, valid loss: 108.683881
epoch: 4186, train precision: 0.953489, train loss: 22.145794, valid precision: 0.846200, valid loss: 100.662933
epoch: 4187, train precision: 0.958111, train loss: 20.958042, valid precision: 0.848800, valid loss: 97.051693
epoch: 4188, train precision: 0.958778, train loss: 20.354238, valid precision: 0.848600, valid loss: 98.931447
epoch: 4189, train precision: 0.956200, train loss: 21.829063, valid precision: 0.843000, valid loss: 102.482618
epoch: 4190, train precision: 0.953156, train loss: 22.428320, valid precision: 0.845000, valid loss: 97.457669
epoch: 4191, train precision: 0.955444, train loss: 21.567162, valid precision: 0.844000, valid loss: 97.097713
epoch: 4192, train precision: 0.950711, train loss: 22.574139, valid precision: 0.846400, valid loss: 98.777599
epoch: 4193, train precision: 0.956933, train loss: 21.726739, valid precision: 0.842600, valid loss: 102.727694
epoch: 4194, train precision: 0.956378, train loss: 21.353927, valid precision: 0.845000, valid loss: 101.210707
epoch: 4195, train precision: 0.958889, train loss: 20.661647, valid precision: 0.843000, valid loss: 103.556076
epoch: 4196, train precision: 0.956311, train loss: 21.490228, valid precision: 0.847600, valid loss: 94.667947
epoch: 4197, train precision: 0.953644, train loss: 22.183132, valid precision: 0.839400, valid loss: 97.956314
epoch: 4198, train precision: 0.961444, train loss: 19.225779, valid precision: 0.853800, valid loss: 99.790886
epoch: 4199, train precision: 0.954067, train loss: 22.346587, valid precision: 0.845000, valid loss: 97.678957
epoch: 4200, train precision: 0.952511, train loss: 22.684413, valid precision: 0.844800, valid loss: 97.701128
epoch: 4201, train precision: 0.953444, train loss: 22.312512, valid precision: 0.850400, valid loss: 94.752490
epoch: 4202, train precision: 0.953244, train loss: 22.112795, valid precision: 0.844600, valid loss: 97.830233
epoch: 4203, train precision: 0.955289, train loss: 21.941045, valid precision: 0.846000, valid loss: 96.695565
epoch: 4204, train precision: 0.956800, train loss: 21.480395, valid precision: 0.838000, valid loss: 96.039478
epoch: 4205, train precision: 0.952244, train loss: 23.548180, valid precision: 0.839000, valid loss: 90.259996
epoch: 4206, train precision: 0.958089, train loss: 20.548783, valid precision: 0.847200, valid loss: 100.646959
epoch: 4207, train precision: 0.950067, train loss: 23.633995, valid precision: 0.847000, valid loss: 89.591818
epoch: 4208, train precision: 0.956956, train loss: 20.977378, valid precision: 0.846000, valid loss: 97.671081
epoch: 4209, train precision: 0.960689, train loss: 19.879222, valid precision: 0.850600, valid loss: 95.522267
epoch: 4210, train precision: 0.954622, train loss: 22.025029, valid precision: 0.844200, valid loss: 94.219064
epoch: 4211, train precision: 0.958044, train loss: 20.745211, valid precision: 0.848200, valid loss: 103.488579
epoch: 4212, train precision: 0.955244, train loss: 21.756989, valid precision: 0.848800, valid loss: 94.874079
epoch: 4213, train precision: 0.953333, train loss: 22.347178, valid precision: 0.841600, valid loss: 94.596637
epoch: 4214, train precision: 0.959044, train loss: 20.688428, valid precision: 0.848600, valid loss: 98.465497
epoch: 4215, train precision: 0.958889, train loss: 20.387105, valid precision: 0.850800, valid loss: 99.728351
epoch: 4216, train precision: 0.951600, train loss: 22.757515, valid precision: 0.841600, valid loss: 95.401487
epoch: 4217, train precision: 0.955356, train loss: 21.660565, valid precision: 0.842000, valid loss: 102.310077
epoch: 4218, train precision: 0.955689, train loss: 21.569693, valid precision: 0.842000, valid loss: 97.492709
epoch: 4219, train precision: 0.956800, train loss: 21.120403, valid precision: 0.841200, valid loss: 104.004290
epoch: 4220, train precision: 0.960756, train loss: 19.575031, valid precision: 0.850200, valid loss: 97.469597
epoch: 4221, train precision: 0.954689, train loss: 21.394410, valid precision: 0.843400, valid loss: 92.578147
epoch: 4222, train precision: 0.951022, train loss: 23.778184, valid precision: 0.842800, valid loss: 89.058904
epoch: 4223, train precision: 0.953867, train loss: 22.170555, valid precision: 0.836400, valid loss: 93.395854
epoch: 4224, train precision: 0.952733, train loss: 22.286026, valid precision: 0.839200, valid loss: 95.011918
epoch: 4225, train precision: 0.951000, train loss: 23.141943, valid precision: 0.843400, valid loss: 98.782994
epoch: 4226, train precision: 0.950622, train loss: 23.303313, valid precision: 0.843400, valid loss: 99.379180
epoch: 4227, train precision: 0.955178, train loss: 21.931795, valid precision: 0.846000, valid loss: 93.181635
epoch: 4228, train precision: 0.958778, train loss: 20.132823, valid precision: 0.846200, valid loss: 97.309636
epoch: 4229, train precision: 0.958044, train loss: 20.356588, valid precision: 0.846600, valid loss: 99.053679
epoch: 4230, train precision: 0.958044, train loss: 20.706986, valid precision: 0.843400, valid loss: 94.946847
epoch: 4231, train precision: 0.949778, train loss: 23.748383, valid precision: 0.837600, valid loss: 103.830872
epoch: 4232, train precision: 0.953667, train loss: 22.430558, valid precision: 0.838600, valid loss: 95.405086
epoch: 4233, train precision: 0.954089, train loss: 22.433270, valid precision: 0.844200, valid loss: 95.365641
epoch: 4234, train precision: 0.957844, train loss: 21.266466, valid precision: 0.846800, valid loss: 95.410929
epoch: 4235, train precision: 0.959200, train loss: 20.149634, valid precision: 0.845200, valid loss: 98.623542
epoch: 4236, train precision: 0.960644, train loss: 19.652198, valid precision: 0.851000, valid loss: 96.407768
epoch: 4237, train precision: 0.958822, train loss: 20.294736, valid precision: 0.844000, valid loss: 94.432579
epoch: 4238, train precision: 0.957511, train loss: 20.825521, valid precision: 0.847800, valid loss: 99.700887
epoch: 4239, train precision: 0.953178, train loss: 22.091091, valid precision: 0.847000, valid loss: 99.226443
epoch: 4240, train precision: 0.959267, train loss: 20.310071, valid precision: 0.846000, valid loss: 98.576284
epoch: 4241, train precision: 0.954689, train loss: 22.150580, valid precision: 0.841400, valid loss: 94.491550
epoch: 4242, train precision: 0.950444, train loss: 23.473732, valid precision: 0.838800, valid loss: 103.048237
epoch: 4243, train precision: 0.956689, train loss: 21.281781, valid precision: 0.847600, valid loss: 95.845950
epoch: 4244, train precision: 0.955956, train loss: 21.235945, valid precision: 0.843000, valid loss: 108.610583
epoch: 4245, train precision: 0.953600, train loss: 22.665692, valid precision: 0.840400, valid loss: 98.538047
epoch: 4246, train precision: 0.954489, train loss: 21.660960, valid precision: 0.845800, valid loss: 98.034201
epoch: 4247, train precision: 0.956333, train loss: 20.492480, valid precision: 0.848800, valid loss: 99.095368
epoch: 4248, train precision: 0.958000, train loss: 20.506097, valid precision: 0.845600, valid loss: 90.383403
epoch: 4249, train precision: 0.955933, train loss: 21.642677, valid precision: 0.846600, valid loss: 95.404786
epoch: 4250, train precision: 0.951467, train loss: 23.039922, valid precision: 0.845800, valid loss: 97.731187
epoch: 4251, train precision: 0.951444, train loss: 23.161119, valid precision: 0.847000, valid loss: 87.298183
epoch: 4252, train precision: 0.951022, train loss: 22.886054, valid precision: 0.849200, valid loss: 97.009399
epoch: 4253, train precision: 0.957756, train loss: 21.120019, valid precision: 0.850400, valid loss: 96.782468
epoch: 4254, train precision: 0.955111, train loss: 21.803228, valid precision: 0.844200, valid loss: 95.796633
epoch: 4255, train precision: 0.959133, train loss: 20.444852, valid precision: 0.843400, valid loss: 93.764162
epoch: 4256, train precision: 0.952467, train loss: 22.578326, valid precision: 0.846800, valid loss: 93.025205
epoch: 4257, train precision: 0.952244, train loss: 23.063852, valid precision: 0.841600, valid loss: 99.058564
epoch: 4258, train precision: 0.957289, train loss: 21.013358, valid precision: 0.845200, valid loss: 98.108259
epoch: 4259, train precision: 0.958756, train loss: 20.175355, valid precision: 0.851200, valid loss: 92.970343
epoch: 4260, train precision: 0.959822, train loss: 19.917860, valid precision: 0.848000, valid loss: 93.971930
epoch: 4261, train precision: 0.958733, train loss: 20.390049, valid precision: 0.844400, valid loss: 93.395026
epoch: 4262, train precision: 0.953756, train loss: 22.732296, valid precision: 0.843200, valid loss: 107.677009
epoch: 4263, train precision: 0.952467, train loss: 22.454981, valid precision: 0.843800, valid loss: 97.702433
epoch: 4264, train precision: 0.959244, train loss: 20.045879, valid precision: 0.851200, valid loss: 92.107404
epoch: 4265, train precision: 0.960000, train loss: 20.135784, valid precision: 0.849600, valid loss: 92.940493
epoch: 4266, train precision: 0.957289, train loss: 20.426311, valid precision: 0.847400, valid loss: 95.702236
epoch: 4267, train precision: 0.953778, train loss: 22.392381, valid precision: 0.846200, valid loss: 91.755092
epoch: 4268, train precision: 0.941311, train loss: 27.722694, valid precision: 0.834600, valid loss: 97.356207
epoch: 4269, train precision: 0.958556, train loss: 20.607772, valid precision: 0.849200, valid loss: 89.085039
epoch: 4270, train precision: 0.955511, train loss: 21.450894, valid precision: 0.850200, valid loss: 95.170770
epoch: 4271, train precision: 0.953267, train loss: 21.873519, valid precision: 0.841000, valid loss: 94.416690
epoch: 4272, train precision: 0.956533, train loss: 21.548300, valid precision: 0.848600, valid loss: 92.574497
epoch: 4273, train precision: 0.954822, train loss: 22.170982, valid precision: 0.847000, valid loss: 102.686213
epoch: 4274, train precision: 0.953356, train loss: 22.819263, valid precision: 0.840000, valid loss: 99.435361
epoch: 4275, train precision: 0.956511, train loss: 20.864249, valid precision: 0.844600, valid loss: 95.369245
epoch: 4276, train precision: 0.951000, train loss: 22.976484, valid precision: 0.842400, valid loss: 92.580227
epoch: 4277, train precision: 0.957311, train loss: 20.801144, valid precision: 0.845400, valid loss: 99.635008
epoch: 4278, train precision: 0.961244, train loss: 19.494702, valid precision: 0.847000, valid loss: 96.658579
epoch: 4279, train precision: 0.955133, train loss: 21.395106, valid precision: 0.847400, valid loss: 97.400521
epoch: 4280, train precision: 0.956244, train loss: 21.556535, valid precision: 0.847800, valid loss: 99.623642
epoch: 4281, train precision: 0.948822, train loss: 24.085109, valid precision: 0.845400, valid loss: 92.742858
epoch: 4282, train precision: 0.953222, train loss: 22.331202, valid precision: 0.848400, valid loss: 92.089034
epoch: 4283, train precision: 0.958711, train loss: 20.394007, valid precision: 0.848600, valid loss: 95.740990
epoch: 4284, train precision: 0.954733, train loss: 21.591476, valid precision: 0.844400, valid loss: 98.960269
epoch: 4285, train precision: 0.953356, train loss: 22.081870, valid precision: 0.845000, valid loss: 96.121155
epoch: 4286, train precision: 0.959311, train loss: 20.331330, valid precision: 0.848800, valid loss: 94.190290
epoch: 4287, train precision: 0.953822, train loss: 22.176980, valid precision: 0.837600, valid loss: 96.202831
epoch: 4288, train precision: 0.951089, train loss: 23.036513, valid precision: 0.843400, valid loss: 106.038392
epoch: 4289, train precision: 0.957467, train loss: 20.363662, valid precision: 0.847200, valid loss: 95.435323
epoch: 4290, train precision: 0.949800, train loss: 23.235108, valid precision: 0.840800, valid loss: 104.306682
epoch: 4291, train precision: 0.955222, train loss: 21.573143, valid precision: 0.843800, valid loss: 97.011106
epoch: 4292, train precision: 0.961444, train loss: 19.569215, valid precision: 0.854400, valid loss: 93.321155
epoch: 4293, train precision: 0.955533, train loss: 21.456099, valid precision: 0.847800, valid loss: 95.263346
epoch: 4294, train precision: 0.960489, train loss: 20.025344, valid precision: 0.843200, valid loss: 102.944131
epoch: 4295, train precision: 0.955933, train loss: 21.533681, valid precision: 0.843800, valid loss: 104.076864
epoch: 4296, train precision: 0.958444, train loss: 20.916827, valid precision: 0.847600, valid loss: 89.516372
epoch: 4297, train precision: 0.956822, train loss: 20.991459, valid precision: 0.844000, valid loss: 104.275027
epoch: 4298, train precision: 0.955556, train loss: 21.209503, valid precision: 0.846400, valid loss: 99.837872
epoch: 4299, train precision: 0.952489, train loss: 22.585852, valid precision: 0.837000, valid loss: 103.677578
epoch: 4300, train precision: 0.960467, train loss: 19.955340, valid precision: 0.846200, valid loss: 92.460579
epoch: 4301, train precision: 0.959156, train loss: 20.150247, valid precision: 0.846200, valid loss: 105.115180
epoch: 4302, train precision: 0.956222, train loss: 21.187748, valid precision: 0.845600, valid loss: 95.974974
epoch: 4303, train precision: 0.956156, train loss: 21.216797, valid precision: 0.845800, valid loss: 97.047695
epoch: 4304, train precision: 0.957267, train loss: 20.931306, valid precision: 0.843400, valid loss: 102.399175
epoch: 4305, train precision: 0.951022, train loss: 23.187390, valid precision: 0.843200, valid loss: 101.968698
epoch: 4306, train precision: 0.954844, train loss: 21.355519, valid precision: 0.840600, valid loss: 97.872440
epoch: 4307, train precision: 0.952133, train loss: 22.207107, valid precision: 0.849400, valid loss: 100.253622
epoch: 4308, train precision: 0.960756, train loss: 19.720856, valid precision: 0.848400, valid loss: 103.048827
epoch: 4309, train precision: 0.961667, train loss: 19.448378, valid precision: 0.852800, valid loss: 97.317591
epoch: 4310, train precision: 0.958133, train loss: 20.535693, valid precision: 0.849200, valid loss: 96.951735
epoch: 4311, train precision: 0.958711, train loss: 20.246796, valid precision: 0.851400, valid loss: 94.166326
epoch: 4312, train precision: 0.951111, train loss: 23.403757, valid precision: 0.844400, valid loss: 96.615656
epoch: 4313, train precision: 0.956822, train loss: 20.929535, valid precision: 0.842400, valid loss: 96.668900
epoch: 4314, train precision: 0.957444, train loss: 20.417057, valid precision: 0.847400, valid loss: 95.645295
epoch: 4315, train precision: 0.952244, train loss: 23.354708, valid precision: 0.840400, valid loss: 94.309688
epoch: 4316, train precision: 0.951067, train loss: 23.312706, valid precision: 0.843200, valid loss: 90.736033
epoch: 4317, train precision: 0.957400, train loss: 21.467268, valid precision: 0.847200, valid loss: 98.000497
epoch: 4318, train precision: 0.957867, train loss: 20.948575, valid precision: 0.845200, valid loss: 93.302731
epoch: 4319, train precision: 0.955089, train loss: 21.674020, valid precision: 0.840600, valid loss: 98.286377
epoch: 4320, train precision: 0.954133, train loss: 21.801548, valid precision: 0.846800, valid loss: 99.986999
epoch: 4321, train precision: 0.956911, train loss: 20.584791, valid precision: 0.852200, valid loss: 103.323065
epoch: 4322, train precision: 0.957133, train loss: 20.068976, valid precision: 0.844600, valid loss: 94.888288
epoch: 4323, train precision: 0.956067, train loss: 20.907571, valid precision: 0.844800, valid loss: 99.289564
epoch: 4324, train precision: 0.963000, train loss: 19.031626, valid precision: 0.848600, valid loss: 96.534155
epoch: 4325, train precision: 0.961244, train loss: 19.189947, valid precision: 0.847600, valid loss: 97.706242
epoch: 4326, train precision: 0.956844, train loss: 20.704420, valid precision: 0.843000, valid loss: 96.010051
epoch: 4327, train precision: 0.956844, train loss: 20.871033, valid precision: 0.847200, valid loss: 93.842855
epoch: 4328, train precision: 0.960022, train loss: 20.103064, valid precision: 0.849200, valid loss: 96.351364
epoch: 4329, train precision: 0.957978, train loss: 20.868934, valid precision: 0.843800, valid loss: 93.390144
epoch: 4330, train precision: 0.953822, train loss: 21.742167, valid precision: 0.839400, valid loss: 95.643054
epoch: 4331, train precision: 0.959222, train loss: 20.118181, valid precision: 0.849600, valid loss: 93.122179
epoch: 4332, train precision: 0.954911, train loss: 22.071156, valid precision: 0.841000, valid loss: 90.843160
epoch: 4333, train precision: 0.956556, train loss: 21.014137, valid precision: 0.844800, valid loss: 93.353116
epoch: 4334, train precision: 0.957489, train loss: 20.615567, valid precision: 0.849200, valid loss: 93.558619
epoch: 4335, train precision: 0.954022, train loss: 22.157623, valid precision: 0.844200, valid loss: 100.908421
epoch: 4336, train precision: 0.949933, train loss: 23.732020, valid precision: 0.836800, valid loss: 103.847142
epoch: 4337, train precision: 0.959267, train loss: 20.241648, valid precision: 0.845200, valid loss: 92.071863
epoch: 4338, train precision: 0.957089, train loss: 20.736299, valid precision: 0.839800, valid loss: 94.860773
epoch: 4339, train precision: 0.945911, train loss: 25.269854, valid precision: 0.835000, valid loss: 101.628892
epoch: 4340, train precision: 0.959511, train loss: 20.194193, valid precision: 0.843400, valid loss: 101.287109
epoch: 4341, train precision: 0.959711, train loss: 19.826006, valid precision: 0.844400, valid loss: 96.710816
epoch: 4342, train precision: 0.954844, train loss: 21.157767, valid precision: 0.848000, valid loss: 98.378051
epoch: 4343, train precision: 0.957956, train loss: 20.594007, valid precision: 0.844600, valid loss: 98.374283
epoch: 4344, train precision: 0.957933, train loss: 20.533996, valid precision: 0.845600, valid loss: 98.880838
epoch: 4345, train precision: 0.959133, train loss: 19.779791, valid precision: 0.847600, valid loss: 93.970959
epoch: 4346, train precision: 0.959000, train loss: 20.262054, valid precision: 0.842200, valid loss: 99.069255
epoch: 4347, train precision: 0.955333, train loss: 21.658746, valid precision: 0.848600, valid loss: 94.404518
epoch: 4348, train precision: 0.959822, train loss: 19.602679, valid precision: 0.848400, valid loss: 97.678585
epoch: 4349, train precision: 0.954844, train loss: 21.953541, valid precision: 0.845000, valid loss: 101.685724
epoch: 4350, train precision: 0.959156, train loss: 19.949152, valid precision: 0.841600, valid loss: 103.076492
epoch: 4351, train precision: 0.957467, train loss: 20.219113, valid precision: 0.844400, valid loss: 97.657125
epoch: 4352, train precision: 0.949933, train loss: 23.652889, valid precision: 0.842800, valid loss: 91.921978
epoch: 4353, train precision: 0.956689, train loss: 20.715344, valid precision: 0.843200, valid loss: 98.341287
epoch: 4354, train precision: 0.950044, train loss: 24.217248, valid precision: 0.844800, valid loss: 109.109029
epoch: 4355, train precision: 0.956533, train loss: 21.359313, valid precision: 0.843600, valid loss: 100.040378
epoch: 4356, train precision: 0.958711, train loss: 20.416119, valid precision: 0.847000, valid loss: 98.890099
epoch: 4357, train precision: 0.955511, train loss: 21.585530, valid precision: 0.843400, valid loss: 93.321061
epoch: 4358, train precision: 0.960667, train loss: 19.646442, valid precision: 0.845200, valid loss: 99.524653
epoch: 4359, train precision: 0.955444, train loss: 21.624061, valid precision: 0.840600, valid loss: 102.271442
epoch: 4360, train precision: 0.956578, train loss: 21.030774, valid precision: 0.844600, valid loss: 97.319396
epoch: 4361, train precision: 0.955311, train loss: 21.587601, valid precision: 0.846200, valid loss: 98.281667
epoch: 4362, train precision: 0.959844, train loss: 19.910428, valid precision: 0.841000, valid loss: 101.413312
epoch: 4363, train precision: 0.957289, train loss: 20.824342, valid precision: 0.847000, valid loss: 103.304311
epoch: 4364, train precision: 0.955289, train loss: 21.741102, valid precision: 0.845000, valid loss: 97.913320
epoch: 4365, train precision: 0.958244, train loss: 20.562671, valid precision: 0.852400, valid loss: 91.336891
epoch: 4366, train precision: 0.956956, train loss: 20.768867, valid precision: 0.845400, valid loss: 96.059035
epoch: 4367, train precision: 0.952200, train loss: 22.679633, valid precision: 0.845000, valid loss: 90.488548
epoch: 4368, train precision: 0.953267, train loss: 22.509729, valid precision: 0.845000, valid loss: 94.717727
epoch: 4369, train precision: 0.954933, train loss: 21.572673, valid precision: 0.846200, valid loss: 97.608916
epoch: 4370, train precision: 0.957333, train loss: 20.574489, valid precision: 0.852800, valid loss: 99.892216
epoch: 4371, train precision: 0.954711, train loss: 21.936736, valid precision: 0.844400, valid loss: 101.044728
epoch: 4372, train precision: 0.952978, train loss: 22.188147, valid precision: 0.836200, valid loss: 100.354950
epoch: 4373, train precision: 0.958222, train loss: 20.635435, valid precision: 0.848400, valid loss: 95.552890
epoch: 4374, train precision: 0.958200, train loss: 20.692695, valid precision: 0.847200, valid loss: 99.260573
epoch: 4375, train precision: 0.958711, train loss: 20.182898, valid precision: 0.851000, valid loss: 91.876570
epoch: 4376, train precision: 0.947067, train loss: 24.704482, valid precision: 0.837000, valid loss: 103.604957
epoch: 4377, train precision: 0.951800, train loss: 22.682720, valid precision: 0.837200, valid loss: 99.404559
epoch: 4378, train precision: 0.956333, train loss: 21.194764, valid precision: 0.841800, valid loss: 100.106294
epoch: 4379, train precision: 0.950089, train loss: 23.511176, valid precision: 0.839000, valid loss: 112.586664
epoch: 4380, train precision: 0.959267, train loss: 19.713717, valid precision: 0.844600, valid loss: 94.437171
epoch: 4381, train precision: 0.955400, train loss: 21.364284, valid precision: 0.847400, valid loss: 93.760808
epoch: 4382, train precision: 0.954600, train loss: 21.912383, valid precision: 0.843400, valid loss: 96.902140
epoch: 4383, train precision: 0.958511, train loss: 20.340777, valid precision: 0.840400, valid loss: 103.137921
epoch: 4384, train precision: 0.954644, train loss: 21.986584, valid precision: 0.843600, valid loss: 96.626668
epoch: 4385, train precision: 0.960111, train loss: 19.870588, valid precision: 0.847200, valid loss: 95.787786
epoch: 4386, train precision: 0.958422, train loss: 20.438550, valid precision: 0.842400, valid loss: 96.835026
epoch: 4387, train precision: 0.955178, train loss: 21.604985, valid precision: 0.843200, valid loss: 101.746813
epoch: 4388, train precision: 0.955467, train loss: 21.281259, valid precision: 0.843800, valid loss: 99.902937
epoch: 4389, train precision: 0.951733, train loss: 23.337781, valid precision: 0.839800, valid loss: 94.328594
epoch: 4390, train precision: 0.950889, train loss: 23.270964, valid precision: 0.844000, valid loss: 97.120164
epoch: 4391, train precision: 0.957356, train loss: 20.564996, valid precision: 0.846800, valid loss: 89.230520
epoch: 4392, train precision: 0.955444, train loss: 21.130496, valid precision: 0.843800, valid loss: 95.891448
epoch: 4393, train precision: 0.959200, train loss: 20.459147, valid precision: 0.846600, valid loss: 95.687478
epoch: 4394, train precision: 0.954378, train loss: 21.921140, valid precision: 0.841000, valid loss: 92.616221
epoch: 4395, train precision: 0.956556, train loss: 21.406012, valid precision: 0.841400, valid loss: 96.934011
epoch: 4396, train precision: 0.957644, train loss: 20.892607, valid precision: 0.843200, valid loss: 92.523556
epoch: 4397, train precision: 0.948778, train loss: 24.002936, valid precision: 0.841000, valid loss: 105.729658
epoch: 4398, train precision: 0.960156, train loss: 20.281244, valid precision: 0.845000, valid loss: 99.176826
epoch: 4399, train precision: 0.956889, train loss: 20.870437, valid precision: 0.841400, valid loss: 104.102401
epoch: 4400, train precision: 0.956489, train loss: 21.426313, valid precision: 0.847600, valid loss: 95.165472
epoch: 4401, train precision: 0.955711, train loss: 21.411256, valid precision: 0.842200, valid loss: 102.197457
epoch: 4402, train precision: 0.953778, train loss: 22.110657, valid precision: 0.838800, valid loss: 100.427753
epoch: 4403, train precision: 0.952422, train loss: 22.695921, valid precision: 0.840400, valid loss: 103.760952
epoch: 4404, train precision: 0.959044, train loss: 20.451860, valid precision: 0.847000, valid loss: 96.676340
epoch: 4405, train precision: 0.957222, train loss: 20.910295, valid precision: 0.845400, valid loss: 94.772702
epoch: 4406, train precision: 0.951289, train loss: 22.860496, valid precision: 0.843000, valid loss: 98.723257
epoch: 4407, train precision: 0.955244, train loss: 21.347385, valid precision: 0.838200, valid loss: 96.215610
epoch: 4408, train precision: 0.957511, train loss: 20.417430, valid precision: 0.838400, valid loss: 103.400593
epoch: 4409, train precision: 0.957511, train loss: 20.918645, valid precision: 0.851200, valid loss: 90.030249
epoch: 4410, train precision: 0.959267, train loss: 19.939556, valid precision: 0.850600, valid loss: 89.647742
epoch: 4411, train precision: 0.953644, train loss: 21.583705, valid precision: 0.838600, valid loss: 93.345849
epoch: 4412, train precision: 0.956822, train loss: 20.915294, valid precision: 0.850200, valid loss: 93.219173
epoch: 4413, train precision: 0.953222, train loss: 21.649277, valid precision: 0.840400, valid loss: 96.347319
epoch: 4414, train precision: 0.954556, train loss: 21.804236, valid precision: 0.839000, valid loss: 97.063617
epoch: 4415, train precision: 0.952400, train loss: 22.922798, valid precision: 0.840000, valid loss: 99.977930
epoch: 4416, train precision: 0.957267, train loss: 20.392442, valid precision: 0.843800, valid loss: 100.436933
epoch: 4417, train precision: 0.961911, train loss: 18.542270, valid precision: 0.845400, valid loss: 99.205090
epoch: 4418, train precision: 0.957978, train loss: 20.622585, valid precision: 0.846800, valid loss: 98.348585
epoch: 4419, train precision: 0.958000, train loss: 20.974260, valid precision: 0.847000, valid loss: 93.631334
epoch: 4420, train precision: 0.956978, train loss: 20.804113, valid precision: 0.844400, valid loss: 92.423664
epoch: 4421, train precision: 0.951822, train loss: 22.629537, valid precision: 0.841000, valid loss: 96.734718
epoch: 4422, train precision: 0.960089, train loss: 19.631662, valid precision: 0.844400, valid loss: 107.428954
epoch: 4423, train precision: 0.957689, train loss: 20.516841, valid precision: 0.843800, valid loss: 97.969179
epoch: 4424, train precision: 0.956622, train loss: 21.219546, valid precision: 0.844600, valid loss: 101.543793
epoch: 4425, train precision: 0.959467, train loss: 19.748231, valid precision: 0.838800, valid loss: 96.771161
epoch: 4426, train precision: 0.960200, train loss: 19.545020, valid precision: 0.841000, valid loss: 97.977950
epoch: 4427, train precision: 0.957711, train loss: 20.488118, valid precision: 0.844200, valid loss: 102.493097
epoch: 4428, train precision: 0.951156, train loss: 23.067350, valid precision: 0.842800, valid loss: 98.779267
epoch: 4429, train precision: 0.957244, train loss: 20.945769, valid precision: 0.842000, valid loss: 99.936804
epoch: 4430, train precision: 0.953756, train loss: 22.505109, valid precision: 0.845600, valid loss: 94.263270
epoch: 4431, train precision: 0.958800, train loss: 21.026036, valid precision: 0.845400, valid loss: 89.619104
epoch: 4432, train precision: 0.952822, train loss: 22.797299, valid precision: 0.842400, valid loss: 89.707887
epoch: 4433, train precision: 0.960533, train loss: 19.431335, valid precision: 0.851000, valid loss: 99.766077
epoch: 4434, train precision: 0.957000, train loss: 20.794531, valid precision: 0.848800, valid loss: 96.493024
epoch: 4435, train precision: 0.954644, train loss: 21.901574, valid precision: 0.841600, valid loss: 103.653107
epoch: 4436, train precision: 0.952444, train loss: 21.942447, valid precision: 0.841200, valid loss: 97.809182
epoch: 4437, train precision: 0.960578, train loss: 19.597028, valid precision: 0.847800, valid loss: 94.702545
epoch: 4438, train precision: 0.957222, train loss: 21.239954, valid precision: 0.846400, valid loss: 98.531074
epoch: 4439, train precision: 0.956067, train loss: 21.371456, valid precision: 0.841000, valid loss: 98.435640
epoch: 4440, train precision: 0.954956, train loss: 21.415962, valid precision: 0.837600, valid loss: 100.796332
epoch: 4441, train precision: 0.948311, train loss: 25.219823, valid precision: 0.840600, valid loss: 106.986859
epoch: 4442, train precision: 0.957222, train loss: 20.833454, valid precision: 0.843200, valid loss: 100.607429
epoch: 4443, train precision: 0.956911, train loss: 21.191685, valid precision: 0.840600, valid loss: 96.677112
epoch: 4444, train precision: 0.956156, train loss: 21.747369, valid precision: 0.841400, valid loss: 93.546387
epoch: 4445, train precision: 0.945444, train loss: 25.614675, valid precision: 0.839000, valid loss: 102.893577
epoch: 4446, train precision: 0.958467, train loss: 20.341130, valid precision: 0.842000, valid loss: 98.420963
epoch: 4447, train precision: 0.957467, train loss: 20.804606, valid precision: 0.845600, valid loss: 99.236688
epoch: 4448, train precision: 0.956200, train loss: 21.879512, valid precision: 0.840600, valid loss: 92.532724
epoch: 4449, train precision: 0.956244, train loss: 21.048348, valid precision: 0.842200, valid loss: 98.789470
epoch: 4450, train precision: 0.954000, train loss: 22.312058, valid precision: 0.839200, valid loss: 105.122828
epoch: 4451, train precision: 0.959022, train loss: 20.001542, valid precision: 0.842000, valid loss: 100.960476
epoch: 4452, train precision: 0.958333, train loss: 20.699646, valid precision: 0.846200, valid loss: 96.309688
epoch: 4453, train precision: 0.954822, train loss: 21.914628, valid precision: 0.844600, valid loss: 97.042574
epoch: 4454, train precision: 0.959000, train loss: 20.049075, valid precision: 0.847800, valid loss: 100.852201
epoch: 4455, train precision: 0.959000, train loss: 19.912838, valid precision: 0.844600, valid loss: 101.210371
epoch: 4456, train precision: 0.954867, train loss: 21.865119, valid precision: 0.846000, valid loss: 95.359109
epoch: 4457, train precision: 0.955022, train loss: 21.841960, valid precision: 0.848600, valid loss: 95.552576
epoch: 4458, train precision: 0.954089, train loss: 22.257730, valid precision: 0.841000, valid loss: 101.754893
epoch: 4459, train precision: 0.958311, train loss: 19.957880, valid precision: 0.846000, valid loss: 93.238296
epoch: 4460, train precision: 0.952822, train loss: 22.320100, valid precision: 0.843200, valid loss: 103.058230
epoch: 4461, train precision: 0.959667, train loss: 19.363496, valid precision: 0.846800, valid loss: 97.899050
epoch: 4462, train precision: 0.955333, train loss: 20.858908, valid precision: 0.844800, valid loss: 97.393312
epoch: 4463, train precision: 0.956733, train loss: 20.715192, valid precision: 0.838200, valid loss: 97.047266
epoch: 4464, train precision: 0.959778, train loss: 19.714160, valid precision: 0.846400, valid loss: 96.570992
epoch: 4465, train precision: 0.955133, train loss: 21.311046, valid precision: 0.840600, valid loss: 97.543158
epoch: 4466, train precision: 0.956667, train loss: 21.133590, valid precision: 0.842200, valid loss: 101.118660
epoch: 4467, train precision: 0.959267, train loss: 20.388244, valid precision: 0.843600, valid loss: 94.622792
epoch: 4468, train precision: 0.957444, train loss: 20.742225, valid precision: 0.846800, valid loss: 95.269900
epoch: 4469, train precision: 0.958044, train loss: 20.384794, valid precision: 0.848800, valid loss: 95.216813
epoch: 4470, train precision: 0.958933, train loss: 20.223742, valid precision: 0.850600, valid loss: 98.691707
epoch: 4471, train precision: 0.959800, train loss: 19.755255, valid precision: 0.845600, valid loss: 90.198772
epoch: 4472, train precision: 0.953222, train loss: 22.607230, valid precision: 0.842800, valid loss: 97.332046
epoch: 4473, train precision: 0.957022, train loss: 21.028725, valid precision: 0.848800, valid loss: 94.416808
epoch: 4474, train precision: 0.959556, train loss: 20.155738, valid precision: 0.845200, valid loss: 94.976709
epoch: 4475, train precision: 0.959933, train loss: 19.572271, valid precision: 0.846600, valid loss: 92.288929
epoch: 4476, train precision: 0.957578, train loss: 20.543495, valid precision: 0.849400, valid loss: 101.335079
epoch: 4477, train precision: 0.952333, train loss: 22.886136, valid precision: 0.842800, valid loss: 89.433116
epoch: 4478, train precision: 0.956533, train loss: 21.193927, valid precision: 0.846000, valid loss: 96.556715
epoch: 4479, train precision: 0.952422, train loss: 22.075457, valid precision: 0.847800, valid loss: 94.080490
epoch: 4480, train precision: 0.959800, train loss: 19.612176, valid precision: 0.851000, valid loss: 98.061833
epoch: 4481, train precision: 0.951822, train loss: 23.008565, valid precision: 0.845600, valid loss: 95.213919
epoch: 4482, train precision: 0.958111, train loss: 20.545928, valid precision: 0.847200, valid loss: 101.471219
epoch: 4483, train precision: 0.953556, train loss: 22.541661, valid precision: 0.845200, valid loss: 97.317285
epoch: 4484, train precision: 0.959689, train loss: 19.880574, valid precision: 0.844600, valid loss: 91.724593
epoch: 4485, train precision: 0.957378, train loss: 20.759683, valid precision: 0.850000, valid loss: 96.014577
epoch: 4486, train precision: 0.960022, train loss: 19.337349, valid precision: 0.850200, valid loss: 98.363093
epoch: 4487, train precision: 0.955933, train loss: 20.801281, valid precision: 0.847800, valid loss: 99.589173
epoch: 4488, train precision: 0.956244, train loss: 20.611236, valid precision: 0.842800, valid loss: 97.521450
epoch: 4489, train precision: 0.956889, train loss: 20.637538, valid precision: 0.846600, valid loss: 94.781754
epoch: 4490, train precision: 0.958156, train loss: 20.432579, valid precision: 0.841800, valid loss: 96.018165
epoch: 4491, train precision: 0.960333, train loss: 19.574690, valid precision: 0.847400, valid loss: 90.195507
epoch: 4492, train precision: 0.959133, train loss: 20.379193, valid precision: 0.846400, valid loss: 97.694050
epoch: 4493, train precision: 0.959578, train loss: 20.032045, valid precision: 0.850000, valid loss: 97.148155
epoch: 4494, train precision: 0.956444, train loss: 21.109519, valid precision: 0.847200, valid loss: 94.469389
epoch: 4495, train precision: 0.958800, train loss: 20.360062, valid precision: 0.849200, valid loss: 101.724532
epoch: 4496, train precision: 0.958533, train loss: 20.464959, valid precision: 0.850000, valid loss: 97.010430
epoch: 4497, train precision: 0.962156, train loss: 18.757830, valid precision: 0.846200, valid loss: 91.286690
epoch: 4498, train precision: 0.955356, train loss: 21.784146, valid precision: 0.841000, valid loss: 97.329710
epoch: 4499, train precision: 0.953044, train loss: 22.020025, valid precision: 0.848000, valid loss: 95.413146
epoch: 4500, train precision: 0.957800, train loss: 20.769118, valid precision: 0.846600, valid loss: 96.589224
epoch: 4501, train precision: 0.956378, train loss: 21.144616, valid precision: 0.841000, valid loss: 99.950320
epoch: 4502, train precision: 0.960867, train loss: 19.248441, valid precision: 0.850400, valid loss: 96.512494
epoch: 4503, train precision: 0.952800, train loss: 22.205112, valid precision: 0.836800, valid loss: 104.998807
epoch: 4504, train precision: 0.955200, train loss: 21.059480, valid precision: 0.843000, valid loss: 96.250056
epoch: 4505, train precision: 0.955978, train loss: 21.183885, valid precision: 0.848200, valid loss: 102.521022
epoch: 4506, train precision: 0.956822, train loss: 20.668603, valid precision: 0.843600, valid loss: 99.404305
epoch: 4507, train precision: 0.955422, train loss: 21.529214, valid precision: 0.850800, valid loss: 98.238447
epoch: 4508, train precision: 0.953378, train loss: 22.524969, valid precision: 0.844000, valid loss: 88.317776
epoch: 4509, train precision: 0.960222, train loss: 20.082337, valid precision: 0.844600, valid loss: 95.162173
epoch: 4510, train precision: 0.954822, train loss: 21.906031, valid precision: 0.844000, valid loss: 96.827993
epoch: 4511, train precision: 0.955067, train loss: 21.399012, valid precision: 0.843400, valid loss: 97.439202
epoch: 4512, train precision: 0.957356, train loss: 20.695348, valid precision: 0.848000, valid loss: 99.345408
epoch: 4513, train precision: 0.950978, train loss: 23.156930, valid precision: 0.843400, valid loss: 97.368641
epoch: 4514, train precision: 0.961400, train loss: 19.303979, valid precision: 0.848800, valid loss: 98.218841
epoch: 4515, train precision: 0.959689, train loss: 19.811371, valid precision: 0.842000, valid loss: 96.531363
epoch: 4516, train precision: 0.957267, train loss: 20.334507, valid precision: 0.841600, valid loss: 94.636270
epoch: 4517, train precision: 0.955978, train loss: 21.054349, valid precision: 0.838800, valid loss: 93.650116
epoch: 4518, train precision: 0.960467, train loss: 19.658336, valid precision: 0.848200, valid loss: 99.912587
epoch: 4519, train precision: 0.958044, train loss: 20.227433, valid precision: 0.851600, valid loss: 98.508819
epoch: 4520, train precision: 0.954022, train loss: 21.581033, valid precision: 0.840800, valid loss: 94.360616
epoch: 4521, train precision: 0.958822, train loss: 20.130744, valid precision: 0.846400, valid loss: 94.816779
epoch: 4522, train precision: 0.957044, train loss: 20.621290, valid precision: 0.839600, valid loss: 101.605240
epoch: 4523, train precision: 0.961378, train loss: 19.068948, valid precision: 0.846200, valid loss: 92.618974
epoch: 4524, train precision: 0.955956, train loss: 21.157199, valid precision: 0.845400, valid loss: 103.995190
epoch: 4525, train precision: 0.956178, train loss: 21.338999, valid precision: 0.844800, valid loss: 100.434375
epoch: 4526, train precision: 0.960200, train loss: 19.317061, valid precision: 0.850400, valid loss: 93.167001
epoch: 4527, train precision: 0.950022, train loss: 23.097445, valid precision: 0.843600, valid loss: 101.437062
epoch: 4528, train precision: 0.959511, train loss: 19.911402, valid precision: 0.846200, valid loss: 93.602078
epoch: 4529, train precision: 0.954644, train loss: 21.490567, valid precision: 0.847000, valid loss: 95.649506
epoch: 4530, train precision: 0.955733, train loss: 21.557056, valid precision: 0.843400, valid loss: 97.053488
epoch: 4531, train precision: 0.949222, train loss: 24.436477, valid precision: 0.833600, valid loss: 107.478415
epoch: 4532, train precision: 0.959733, train loss: 20.042406, valid precision: 0.841200, valid loss: 96.338714
epoch: 4533, train precision: 0.953956, train loss: 22.455996, valid precision: 0.844200, valid loss: 93.769248
epoch: 4534, train precision: 0.952489, train loss: 22.317907, valid precision: 0.842000, valid loss: 98.352680
epoch: 4535, train precision: 0.958467, train loss: 20.217377, valid precision: 0.847600, valid loss: 97.830171
epoch: 4536, train precision: 0.955867, train loss: 21.207485, valid precision: 0.846800, valid loss: 98.570998
epoch: 4537, train precision: 0.953711, train loss: 21.620829, valid precision: 0.840600, valid loss: 96.852338
epoch: 4538, train precision: 0.955867, train loss: 21.349299, valid precision: 0.844600, valid loss: 94.438382
epoch: 4539, train precision: 0.958556, train loss: 20.365691, valid precision: 0.841800, valid loss: 96.071000
epoch: 4540, train precision: 0.957133, train loss: 20.704701, valid precision: 0.840000, valid loss: 95.191295
epoch: 4541, train precision: 0.959489, train loss: 19.981449, valid precision: 0.848600, valid loss: 95.261764
epoch: 4542, train precision: 0.962333, train loss: 18.804006, valid precision: 0.841800, valid loss: 96.432391
epoch: 4543, train precision: 0.955822, train loss: 21.159085, valid precision: 0.843400, valid loss: 103.151180
epoch: 4544, train precision: 0.958756, train loss: 19.904406, valid precision: 0.848200, valid loss: 93.744897
epoch: 4545, train precision: 0.957756, train loss: 20.517801, valid precision: 0.844600, valid loss: 95.192376
epoch: 4546, train precision: 0.961889, train loss: 18.846188, valid precision: 0.846800, valid loss: 101.366963
epoch: 4547, train precision: 0.945711, train loss: 25.145235, valid precision: 0.838000, valid loss: 98.930480
epoch: 4548, train precision: 0.955933, train loss: 21.071661, valid precision: 0.844800, valid loss: 100.557817
epoch: 4549, train precision: 0.958933, train loss: 20.229593, valid precision: 0.844000, valid loss: 96.694853
epoch: 4550, train precision: 0.960244, train loss: 19.775120, valid precision: 0.846200, valid loss: 96.368814
epoch: 4551, train precision: 0.958422, train loss: 20.543599, valid precision: 0.843800, valid loss: 100.663578
epoch: 4552, train precision: 0.952156, train loss: 22.782315, valid precision: 0.837800, valid loss: 106.382425
epoch: 4553, train precision: 0.959489, train loss: 19.839841, valid precision: 0.849400, valid loss: 99.711777
epoch: 4554, train precision: 0.956400, train loss: 21.630089, valid precision: 0.841800, valid loss: 97.077107
epoch: 4555, train precision: 0.953289, train loss: 22.198301, valid precision: 0.841600, valid loss: 100.031363
epoch: 4556, train precision: 0.961444, train loss: 19.118961, valid precision: 0.847000, valid loss: 96.186600
epoch: 4557, train precision: 0.956644, train loss: 21.238324, valid precision: 0.843000, valid loss: 101.480432
epoch: 4558, train precision: 0.951667, train loss: 22.736579, valid precision: 0.839000, valid loss: 99.159849
epoch: 4559, train precision: 0.957267, train loss: 20.842919, valid precision: 0.847000, valid loss: 95.355908
epoch: 4560, train precision: 0.954933, train loss: 21.641964, valid precision: 0.843600, valid loss: 101.292379
epoch: 4561, train precision: 0.960733, train loss: 19.517040, valid precision: 0.851000, valid loss: 96.218268
epoch: 4562, train precision: 0.960956, train loss: 19.586853, valid precision: 0.846000, valid loss: 93.208153
epoch: 4563, train precision: 0.958178, train loss: 20.161864, valid precision: 0.841000, valid loss: 102.812299
epoch: 4564, train precision: 0.958400, train loss: 20.862243, valid precision: 0.844600, valid loss: 94.111134
epoch: 4565, train precision: 0.959667, train loss: 20.435098, valid precision: 0.842800, valid loss: 97.941516
epoch: 4566, train precision: 0.958578, train loss: 20.403913, valid precision: 0.847800, valid loss: 102.609290
epoch: 4567, train precision: 0.951889, train loss: 22.843061, valid precision: 0.840400, valid loss: 92.660963
epoch: 4568, train precision: 0.958844, train loss: 20.127394, valid precision: 0.839000, valid loss: 98.114891
epoch: 4569, train precision: 0.953778, train loss: 22.297675, valid precision: 0.843200, valid loss: 105.477085
epoch: 4570, train precision: 0.957133, train loss: 20.356189, valid precision: 0.844600, valid loss: 99.607528
epoch: 4571, train precision: 0.955578, train loss: 21.052293, valid precision: 0.842800, valid loss: 94.678831
epoch: 4572, train precision: 0.959067, train loss: 19.634600, valid precision: 0.846800, valid loss: 94.344682
epoch: 4573, train precision: 0.955644, train loss: 20.651308, valid precision: 0.841800, valid loss: 94.933516
epoch: 4574, train precision: 0.951622, train loss: 23.211839, valid precision: 0.841600, valid loss: 95.867079
epoch: 4575, train precision: 0.955289, train loss: 21.669547, valid precision: 0.849000, valid loss: 97.588056
epoch: 4576, train precision: 0.957644, train loss: 19.949732, valid precision: 0.843800, valid loss: 93.813755
epoch: 4577, train precision: 0.950889, train loss: 22.314594, valid precision: 0.841000, valid loss: 92.935128
epoch: 4578, train precision: 0.960800, train loss: 19.908091, valid precision: 0.847800, valid loss: 97.193917
epoch: 4579, train precision: 0.958956, train loss: 19.952594, valid precision: 0.841000, valid loss: 100.266756
epoch: 4580, train precision: 0.956756, train loss: 20.858853, valid precision: 0.845000, valid loss: 96.866559
epoch: 4581, train precision: 0.957067, train loss: 20.702125, valid precision: 0.843200, valid loss: 99.433279
epoch: 4582, train precision: 0.958156, train loss: 20.786439, valid precision: 0.839600, valid loss: 97.611615
epoch: 4583, train precision: 0.949822, train loss: 23.709624, valid precision: 0.832400, valid loss: 104.361373
epoch: 4584, train precision: 0.958911, train loss: 20.003731, valid precision: 0.843800, valid loss: 95.697500
epoch: 4585, train precision: 0.960178, train loss: 19.476788, valid precision: 0.846600, valid loss: 103.122307
epoch: 4586, train precision: 0.958800, train loss: 19.804350, valid precision: 0.845600, valid loss: 98.000715
epoch: 4587, train precision: 0.949667, train loss: 23.235337, valid precision: 0.842600, valid loss: 102.580765
epoch: 4588, train precision: 0.954400, train loss: 22.293614, valid precision: 0.841200, valid loss: 97.092605
epoch: 4589, train precision: 0.955689, train loss: 20.880151, valid precision: 0.841000, valid loss: 102.140925
epoch: 4590, train precision: 0.958711, train loss: 19.713029, valid precision: 0.846200, valid loss: 99.252750
epoch: 4591, train precision: 0.955756, train loss: 21.338613, valid precision: 0.844400, valid loss: 102.438276
epoch: 4592, train precision: 0.958289, train loss: 20.078257, valid precision: 0.838400, valid loss: 96.543071
epoch: 4593, train precision: 0.959289, train loss: 19.595831, valid precision: 0.845200, valid loss: 99.492713
epoch: 4594, train precision: 0.960000, train loss: 19.642130, valid precision: 0.850000, valid loss: 98.251968
epoch: 4595, train precision: 0.956933, train loss: 20.322932, valid precision: 0.842800, valid loss: 95.361657
epoch: 4596, train precision: 0.959333, train loss: 19.779148, valid precision: 0.849200, valid loss: 95.928068
epoch: 4597, train precision: 0.956733, train loss: 20.740114, valid precision: 0.843400, valid loss: 96.874009
epoch: 4598, train precision: 0.958422, train loss: 20.232831, valid precision: 0.848200, valid loss: 94.835370
epoch: 4599, train precision: 0.957422, train loss: 20.590483, valid precision: 0.843000, valid loss: 103.599113
epoch: 4600, train precision: 0.960956, train loss: 19.503701, valid precision: 0.847200, valid loss: 99.697602
epoch: 4601, train precision: 0.956533, train loss: 21.058663, valid precision: 0.838200, valid loss: 103.866933
epoch: 4602, train precision: 0.958911, train loss: 20.621007, valid precision: 0.840000, valid loss: 95.734114
epoch: 4603, train precision: 0.957689, train loss: 20.549785, valid precision: 0.843800, valid loss: 99.173705
epoch: 4604, train precision: 0.956267, train loss: 20.775764, valid precision: 0.844400, valid loss: 105.077157
epoch: 4605, train precision: 0.957311, train loss: 20.553969, valid precision: 0.843000, valid loss: 104.629447
epoch: 4606, train precision: 0.957422, train loss: 20.602551, valid precision: 0.847000, valid loss: 95.259661
epoch: 4607, train precision: 0.958667, train loss: 19.828340, valid precision: 0.846600, valid loss: 94.949088
epoch: 4608, train precision: 0.959489, train loss: 19.574242, valid precision: 0.846400, valid loss: 98.674732
epoch: 4609, train precision: 0.957400, train loss: 20.485546, valid precision: 0.840600, valid loss: 100.674066
epoch: 4610, train precision: 0.956133, train loss: 20.998729, valid precision: 0.835800, valid loss: 105.647865
epoch: 4611, train precision: 0.955956, train loss: 21.273921, valid precision: 0.840000, valid loss: 107.092515
epoch: 4612, train precision: 0.956200, train loss: 21.048244, valid precision: 0.842200, valid loss: 96.552604
epoch: 4613, train precision: 0.958400, train loss: 20.315106, valid precision: 0.843200, valid loss: 90.007876
epoch: 4614, train precision: 0.955022, train loss: 21.219732, valid precision: 0.839000, valid loss: 99.489299
epoch: 4615, train precision: 0.956489, train loss: 20.806412, valid precision: 0.839200, valid loss: 101.330782
epoch: 4616, train precision: 0.956267, train loss: 20.900105, valid precision: 0.842400, valid loss: 105.563527
epoch: 4617, train precision: 0.958400, train loss: 20.135039, valid precision: 0.842800, valid loss: 100.784286
epoch: 4618, train precision: 0.959400, train loss: 19.555175, valid precision: 0.847000, valid loss: 100.141144
epoch: 4619, train precision: 0.955422, train loss: 21.236664, valid precision: 0.840000, valid loss: 102.447822
epoch: 4620, train precision: 0.953200, train loss: 21.718080, valid precision: 0.840200, valid loss: 105.286621
epoch: 4621, train precision: 0.958133, train loss: 20.348495, valid precision: 0.841200, valid loss: 99.733721
epoch: 4622, train precision: 0.956933, train loss: 20.577826, valid precision: 0.844800, valid loss: 106.103996
epoch: 4623, train precision: 0.955533, train loss: 21.322919, valid precision: 0.839400, valid loss: 103.953671
epoch: 4624, train precision: 0.958133, train loss: 20.456601, valid precision: 0.842200, valid loss: 99.827953
epoch: 4625, train precision: 0.958756, train loss: 20.691755, valid precision: 0.842800, valid loss: 109.542012
epoch: 4626, train precision: 0.960844, train loss: 19.652425, valid precision: 0.845200, valid loss: 100.620720
epoch: 4627, train precision: 0.955133, train loss: 21.329499, valid precision: 0.839200, valid loss: 96.610443
epoch: 4628, train precision: 0.953822, train loss: 21.749372, valid precision: 0.843400, valid loss: 101.085445
epoch: 4629, train precision: 0.957089, train loss: 21.276016, valid precision: 0.842400, valid loss: 101.909275
epoch: 4630, train precision: 0.957711, train loss: 20.355869, valid precision: 0.841600, valid loss: 97.437715
epoch: 4631, train precision: 0.954733, train loss: 22.162277, valid precision: 0.838600, valid loss: 101.427917
epoch: 4632, train precision: 0.955844, train loss: 21.047879, valid precision: 0.846200, valid loss: 107.990965
epoch: 4633, train precision: 0.954178, train loss: 21.699849, valid precision: 0.842400, valid loss: 99.124833
epoch: 4634, train precision: 0.957200, train loss: 20.803962, valid precision: 0.841400, valid loss: 101.652045
epoch: 4635, train precision: 0.953444, train loss: 21.563658, valid precision: 0.841600, valid loss: 100.209604
epoch: 4636, train precision: 0.960200, train loss: 20.011774, valid precision: 0.843200, valid loss: 96.143414
epoch: 4637, train precision: 0.953333, train loss: 22.469907, valid precision: 0.837600, valid loss: 102.087159
epoch: 4638, train precision: 0.957978, train loss: 20.066960, valid precision: 0.843000, valid loss: 99.172815
epoch: 4639, train precision: 0.956889, train loss: 20.447346, valid precision: 0.842400, valid loss: 101.118714
epoch: 4640, train precision: 0.953911, train loss: 22.224916, valid precision: 0.841800, valid loss: 98.028932
epoch: 4641, train precision: 0.955400, train loss: 21.161801, valid precision: 0.846400, valid loss: 99.204640
epoch: 4642, train precision: 0.957978, train loss: 20.962867, valid precision: 0.841800, valid loss: 108.895759
epoch: 4643, train precision: 0.956667, train loss: 20.467678, valid precision: 0.845800, valid loss: 105.271813
epoch: 4644, train precision: 0.950689, train loss: 23.184300, valid precision: 0.835600, valid loss: 105.712222
epoch: 4645, train precision: 0.959178, train loss: 19.756670, valid precision: 0.842800, valid loss: 105.765460
epoch: 4646, train precision: 0.957089, train loss: 20.894224, valid precision: 0.844000, valid loss: 96.438040
epoch: 4647, train precision: 0.959511, train loss: 19.870785, valid precision: 0.837000, valid loss: 93.813902
epoch: 4648, train precision: 0.958533, train loss: 20.184908, valid precision: 0.843800, valid loss: 102.191032
epoch: 4649, train precision: 0.956911, train loss: 20.861323, valid precision: 0.842600, valid loss: 103.626251
epoch: 4650, train precision: 0.958978, train loss: 19.786726, valid precision: 0.840600, valid loss: 107.260614
epoch: 4651, train precision: 0.954867, train loss: 21.690228, valid precision: 0.840800, valid loss: 98.364718
epoch: 4652, train precision: 0.954311, train loss: 21.669529, valid precision: 0.842000, valid loss: 102.660695
epoch: 4653, train precision: 0.956422, train loss: 20.748397, valid precision: 0.843600, valid loss: 98.434470
epoch: 4654, train precision: 0.954533, train loss: 21.632715, valid precision: 0.843400, valid loss: 103.130286
epoch: 4655, train precision: 0.958467, train loss: 19.777684, valid precision: 0.845800, valid loss: 107.225607
epoch: 4656, train precision: 0.959244, train loss: 19.924884, valid precision: 0.845800, valid loss: 97.612394
epoch: 4657, train precision: 0.958733, train loss: 20.464849, valid precision: 0.845400, valid loss: 95.833848
epoch: 4658, train precision: 0.959378, train loss: 19.816976, valid precision: 0.844400, valid loss: 100.882633
epoch: 4659, train precision: 0.954067, train loss: 21.779710, valid precision: 0.840800, valid loss: 102.641364
epoch: 4660, train precision: 0.955511, train loss: 21.097863, valid precision: 0.843200, valid loss: 96.494743
epoch: 4661, train precision: 0.954733, train loss: 21.228622, valid precision: 0.844400, valid loss: 102.539173
epoch: 4662, train precision: 0.954778, train loss: 21.427358, valid precision: 0.839000, valid loss: 99.177506
epoch: 4663, train precision: 0.953711, train loss: 21.884594, valid precision: 0.840200, valid loss: 104.060736
epoch: 4664, train precision: 0.957778, train loss: 20.217379, valid precision: 0.840000, valid loss: 99.538965
epoch: 4665, train precision: 0.959311, train loss: 20.173154, valid precision: 0.847000, valid loss: 99.856181
epoch: 4666, train precision: 0.955667, train loss: 21.022358, valid precision: 0.838200, valid loss: 96.556536
epoch: 4667, train precision: 0.958933, train loss: 19.898232, valid precision: 0.844200, valid loss: 100.234787
epoch: 4668, train precision: 0.959067, train loss: 19.948785, valid precision: 0.839200, valid loss: 95.270881
epoch: 4669, train precision: 0.960889, train loss: 19.158672, valid precision: 0.847000, valid loss: 99.248219
epoch: 4670, train precision: 0.957000, train loss: 20.803029, valid precision: 0.840800, valid loss: 98.070804
epoch: 4671, train precision: 0.954956, train loss: 21.225502, valid precision: 0.843800, valid loss: 98.066498
epoch: 4672, train precision: 0.953289, train loss: 22.145346, valid precision: 0.841000, valid loss: 102.435715
epoch: 4673, train precision: 0.959756, train loss: 19.607236, valid precision: 0.841800, valid loss: 107.139509
epoch: 4674, train precision: 0.956533, train loss: 20.925316, valid precision: 0.836200, valid loss: 103.397883
epoch: 4675, train precision: 0.956489, train loss: 20.696010, valid precision: 0.840400, valid loss: 103.509028
epoch: 4676, train precision: 0.954733, train loss: 21.377863, valid precision: 0.843200, valid loss: 98.843081
epoch: 4677, train precision: 0.956644, train loss: 20.950928, valid precision: 0.845800, valid loss: 95.349695
epoch: 4678, train precision: 0.953489, train loss: 21.964557, valid precision: 0.835600, valid loss: 106.259158
epoch: 4679, train precision: 0.957200, train loss: 20.657763, valid precision: 0.846600, valid loss: 98.310892
epoch: 4680, train precision: 0.961244, train loss: 19.116309, valid precision: 0.842600, valid loss: 100.590303
epoch: 4681, train precision: 0.954667, train loss: 21.738118, valid precision: 0.840000, valid loss: 108.487891
epoch: 4682, train precision: 0.957689, train loss: 20.836556, valid precision: 0.840600, valid loss: 101.814576
epoch: 4683, train precision: 0.956089, train loss: 21.013153, valid precision: 0.839400, valid loss: 102.048781
epoch: 4684, train precision: 0.958622, train loss: 20.000894, valid precision: 0.846400, valid loss: 94.875969
epoch: 4685, train precision: 0.958422, train loss: 20.166750, valid precision: 0.841000, valid loss: 105.560782
epoch: 4686, train precision: 0.962644, train loss: 18.708904, valid precision: 0.847600, valid loss: 98.370593
epoch: 4687, train precision: 0.957111, train loss: 20.836424, valid precision: 0.839400, valid loss: 102.314977
epoch: 4688, train precision: 0.954244, train loss: 21.348102, valid precision: 0.840800, valid loss: 106.922362
epoch: 4689, train precision: 0.957444, train loss: 20.446669, valid precision: 0.838400, valid loss: 102.407555
epoch: 4690, train precision: 0.959911, train loss: 19.721183, valid precision: 0.844800, valid loss: 100.913490
epoch: 4691, train precision: 0.956022, train loss: 21.325451, valid precision: 0.839800, valid loss: 103.881628
epoch: 4692, train precision: 0.956467, train loss: 20.709923, valid precision: 0.845800, valid loss: 102.670795
epoch: 4693, train precision: 0.961000, train loss: 19.464502, valid precision: 0.845000, valid loss: 103.205573
epoch: 4694, train precision: 0.957644, train loss: 20.096685, valid precision: 0.835200, valid loss: 99.286760
epoch: 4695, train precision: 0.960933, train loss: 19.242051, valid precision: 0.845200, valid loss: 102.194888
epoch: 4696, train precision: 0.951289, train loss: 22.482369, valid precision: 0.843800, valid loss: 103.903464
epoch: 4697, train precision: 0.957511, train loss: 20.441483, valid precision: 0.838600, valid loss: 101.294205
epoch: 4698, train precision: 0.954800, train loss: 21.550340, valid precision: 0.841000, valid loss: 106.632561
epoch: 4699, train precision: 0.956889, train loss: 20.656394, valid precision: 0.842200, valid loss: 96.607982
epoch: 4700, train precision: 0.958000, train loss: 20.193153, valid precision: 0.841200, valid loss: 95.049647
epoch: 4701, train precision: 0.957111, train loss: 20.783797, valid precision: 0.840200, valid loss: 98.318409
epoch: 4702, train precision: 0.957422, train loss: 20.371446, valid precision: 0.842400, valid loss: 102.492854
epoch: 4703, train precision: 0.954711, train loss: 21.776688, valid precision: 0.842400, valid loss: 100.222851
epoch: 4704, train precision: 0.956444, train loss: 20.867712, valid precision: 0.838200, valid loss: 97.900229
epoch: 4705, train precision: 0.959022, train loss: 20.202767, valid precision: 0.846000, valid loss: 100.555398
epoch: 4706, train precision: 0.957378, train loss: 20.413993, valid precision: 0.838800, valid loss: 99.903191
epoch: 4707, train precision: 0.964400, train loss: 18.452210, valid precision: 0.846200, valid loss: 95.477551
epoch: 4708, train precision: 0.959489, train loss: 19.487347, valid precision: 0.845200, valid loss: 96.770492
epoch: 4709, train precision: 0.951133, train loss: 22.571319, valid precision: 0.838400, valid loss: 103.652371
epoch: 4710, train precision: 0.955778, train loss: 20.439706, valid precision: 0.847600, valid loss: 102.785058
epoch: 4711, train precision: 0.958156, train loss: 20.285069, valid precision: 0.844000, valid loss: 99.209000
epoch: 4712, train precision: 0.956556, train loss: 20.178886, valid precision: 0.841200, valid loss: 99.320891
epoch: 4713, train precision: 0.957111, train loss: 20.125605, valid precision: 0.839600, valid loss: 101.887272
epoch: 4714, train precision: 0.959667, train loss: 19.832156, valid precision: 0.842800, valid loss: 102.858686
epoch: 4715, train precision: 0.957044, train loss: 20.493443, valid precision: 0.846800, valid loss: 101.367514
epoch: 4716, train precision: 0.958444, train loss: 19.916938, valid precision: 0.837600, valid loss: 100.028097
epoch: 4717, train precision: 0.957000, train loss: 21.106183, valid precision: 0.843600, valid loss: 99.509387
epoch: 4718, train precision: 0.962200, train loss: 18.609716, valid precision: 0.843800, valid loss: 98.133365
epoch: 4719, train precision: 0.960844, train loss: 19.379862, valid precision: 0.844000, valid loss: 105.650558
epoch: 4720, train precision: 0.961600, train loss: 19.210562, valid precision: 0.837800, valid loss: 101.730115
epoch: 4721, train precision: 0.957622, train loss: 20.438470, valid precision: 0.838800, valid loss: 92.673673
epoch: 4722, train precision: 0.960444, train loss: 19.345208, valid precision: 0.846800, valid loss: 98.582525
epoch: 4723, train precision: 0.957644, train loss: 20.265102, valid precision: 0.841200, valid loss: 102.357809
epoch: 4724, train precision: 0.955622, train loss: 20.430090, valid precision: 0.842200, valid loss: 108.367141
epoch: 4725, train precision: 0.958289, train loss: 20.036400, valid precision: 0.845600, valid loss: 96.451111
epoch: 4726, train precision: 0.952000, train loss: 22.143704, valid precision: 0.839400, valid loss: 106.497711
epoch: 4727, train precision: 0.957089, train loss: 20.638616, valid precision: 0.842000, valid loss: 96.789515
epoch: 4728, train precision: 0.953978, train loss: 22.020936, valid precision: 0.842000, valid loss: 97.002912
epoch: 4729, train precision: 0.954089, train loss: 21.644629, valid precision: 0.843000, valid loss: 102.714239
epoch: 4730, train precision: 0.959556, train loss: 19.527474, valid precision: 0.845200, valid loss: 102.476673
epoch: 4731, train precision: 0.960933, train loss: 19.385813, valid precision: 0.842200, valid loss: 97.981464
epoch: 4732, train precision: 0.960311, train loss: 19.596104, valid precision: 0.843800, valid loss: 104.107104
epoch: 4733, train precision: 0.959400, train loss: 19.482423, valid precision: 0.844000, valid loss: 99.619204
epoch: 4734, train precision: 0.956333, train loss: 20.591185, valid precision: 0.844600, valid loss: 101.330544
epoch: 4735, train precision: 0.958289, train loss: 20.269069, valid precision: 0.841200, valid loss: 96.134241
epoch: 4736, train precision: 0.963867, train loss: 17.986038, valid precision: 0.848200, valid loss: 100.431957
epoch: 4737, train precision: 0.955689, train loss: 21.165803, valid precision: 0.842400, valid loss: 103.104782
epoch: 4738, train precision: 0.957800, train loss: 19.961417, valid precision: 0.844400, valid loss: 100.509396
epoch: 4739, train precision: 0.955800, train loss: 21.177124, valid precision: 0.839800, valid loss: 100.913183
epoch: 4740, train precision: 0.960444, train loss: 19.609621, valid precision: 0.843200, valid loss: 100.613608
epoch: 4741, train precision: 0.957756, train loss: 20.336292, valid precision: 0.842800, valid loss: 99.213725
epoch: 4742, train precision: 0.960578, train loss: 19.147799, valid precision: 0.846200, valid loss: 103.106599
epoch: 4743, train precision: 0.955022, train loss: 21.098186, valid precision: 0.839200, valid loss: 103.081166
epoch: 4744, train precision: 0.956422, train loss: 20.791297, valid precision: 0.844000, valid loss: 104.960777
epoch: 4745, train precision: 0.957533, train loss: 20.091933, valid precision: 0.844600, valid loss: 104.337140
epoch: 4746, train precision: 0.956489, train loss: 21.271686, valid precision: 0.840600, valid loss: 102.408126
epoch: 4747, train precision: 0.961178, train loss: 19.540926, valid precision: 0.846800, valid loss: 102.845053
epoch: 4748, train precision: 0.952511, train loss: 22.029538, valid precision: 0.839800, valid loss: 102.145612
epoch: 4749, train precision: 0.958444, train loss: 20.129346, valid precision: 0.848400, valid loss: 100.114159
epoch: 4750, train precision: 0.954533, train loss: 21.366521, valid precision: 0.839400, valid loss: 100.304460
epoch: 4751, train precision: 0.962467, train loss: 18.746870, valid precision: 0.841000, valid loss: 110.554277
epoch: 4752, train precision: 0.957956, train loss: 20.998519, valid precision: 0.836000, valid loss: 98.691134
epoch: 4753, train precision: 0.956067, train loss: 20.750450, valid precision: 0.838800, valid loss: 99.444022
epoch: 4754, train precision: 0.958711, train loss: 19.691701, valid precision: 0.845600, valid loss: 99.632948
epoch: 4755, train precision: 0.958978, train loss: 20.075007, valid precision: 0.844800, valid loss: 100.484490
epoch: 4756, train precision: 0.963867, train loss: 18.169693, valid precision: 0.845800, valid loss: 99.387377
epoch: 4757, train precision: 0.959511, train loss: 20.026798, valid precision: 0.848400, valid loss: 97.648409
epoch: 4758, train precision: 0.954867, train loss: 21.616157, valid precision: 0.841200, valid loss: 98.991560
epoch: 4759, train precision: 0.957867, train loss: 19.944790, valid precision: 0.842400, valid loss: 101.768407
epoch: 4760, train precision: 0.960356, train loss: 18.966394, valid precision: 0.842600, valid loss: 101.350583
epoch: 4761, train precision: 0.955600, train loss: 20.872424, valid precision: 0.840200, valid loss: 100.817461
epoch: 4762, train precision: 0.958889, train loss: 20.266136, valid precision: 0.844400, valid loss: 95.909428
epoch: 4763, train precision: 0.956778, train loss: 21.030418, valid precision: 0.839000, valid loss: 108.261425
epoch: 4764, train precision: 0.959244, train loss: 19.698763, valid precision: 0.843400, valid loss: 103.999005
epoch: 4765, train precision: 0.957444, train loss: 20.036252, valid precision: 0.843400, valid loss: 102.967512
epoch: 4766, train precision: 0.955889, train loss: 21.277844, valid precision: 0.842400, valid loss: 94.517779
epoch: 4767, train precision: 0.954667, train loss: 21.399312, valid precision: 0.843600, valid loss: 100.932662
epoch: 4768, train precision: 0.956067, train loss: 20.356588, valid precision: 0.844000, valid loss: 104.157069
epoch: 4769, train precision: 0.960867, train loss: 19.344661, valid precision: 0.842000, valid loss: 96.178533
epoch: 4770, train precision: 0.960222, train loss: 19.536862, valid precision: 0.848200, valid loss: 98.277929
epoch: 4771, train precision: 0.957000, train loss: 20.804144, valid precision: 0.843800, valid loss: 97.383507
epoch: 4772, train precision: 0.959778, train loss: 19.820319, valid precision: 0.848800, valid loss: 108.451696
epoch: 4773, train precision: 0.958356, train loss: 20.122021, valid precision: 0.844200, valid loss: 102.031314
epoch: 4774, train precision: 0.957822, train loss: 20.338920, valid precision: 0.838600, valid loss: 96.882420
epoch: 4775, train precision: 0.961156, train loss: 19.229601, valid precision: 0.844200, valid loss: 98.954929
epoch: 4776, train precision: 0.956156, train loss: 21.183531, valid precision: 0.843800, valid loss: 103.577746
epoch: 4777, train precision: 0.952178, train loss: 22.831760, valid precision: 0.837200, valid loss: 107.705255
epoch: 4778, train precision: 0.958733, train loss: 19.739293, valid precision: 0.839800, valid loss: 97.349524
epoch: 4779, train precision: 0.956511, train loss: 20.709838, valid precision: 0.841200, valid loss: 101.300288
epoch: 4780, train precision: 0.955333, train loss: 21.375548, valid precision: 0.840400, valid loss: 106.326713
epoch: 4781, train precision: 0.958267, train loss: 20.652270, valid precision: 0.846400, valid loss: 95.235043
epoch: 4782, train precision: 0.957978, train loss: 20.206482, valid precision: 0.838200, valid loss: 99.927193
epoch: 4783, train precision: 0.954533, train loss: 21.666610, valid precision: 0.844600, valid loss: 103.255885
epoch: 4784, train precision: 0.957022, train loss: 20.345798, valid precision: 0.839000, valid loss: 99.396747
epoch: 4785, train precision: 0.960644, train loss: 19.241862, valid precision: 0.850400, valid loss: 102.466295
epoch: 4786, train precision: 0.956400, train loss: 20.834395, valid precision: 0.844000, valid loss: 101.648237
epoch: 4787, train precision: 0.958311, train loss: 20.203900, valid precision: 0.840800, valid loss: 101.736079
epoch: 4788, train precision: 0.955222, train loss: 21.601178, valid precision: 0.840000, valid loss: 105.765601
epoch: 4789, train precision: 0.954333, train loss: 21.395549, valid precision: 0.838600, valid loss: 106.772776
epoch: 4790, train precision: 0.959667, train loss: 19.735574, valid precision: 0.842200, valid loss: 99.611748
epoch: 4791, train precision: 0.962067, train loss: 18.747065, valid precision: 0.849400, valid loss: 99.468489
epoch: 4792, train precision: 0.957978, train loss: 20.278711, valid precision: 0.845800, valid loss: 97.284676
epoch: 4793, train precision: 0.960378, train loss: 19.409945, valid precision: 0.847600, valid loss: 98.107612
epoch: 4794, train precision: 0.963511, train loss: 18.138255, valid precision: 0.841200, valid loss: 99.324563
epoch: 4795, train precision: 0.955333, train loss: 21.304955, valid precision: 0.840000, valid loss: 97.966794
epoch: 4796, train precision: 0.953533, train loss: 21.733103, valid precision: 0.840800, valid loss: 99.360407
epoch: 4797, train precision: 0.955756, train loss: 21.777137, valid precision: 0.843000, valid loss: 102.103040
epoch: 4798, train precision: 0.957800, train loss: 20.342315, valid precision: 0.843200, valid loss: 97.041611
epoch: 4799, train precision: 0.956244, train loss: 20.830467, valid precision: 0.843000, valid loss: 97.999162
epoch: 4800, train precision: 0.958711, train loss: 20.065840, valid precision: 0.844000, valid loss: 96.013598
epoch: 4801, train precision: 0.957044, train loss: 21.145977, valid precision: 0.844600, valid loss: 93.653472
epoch: 4802, train precision: 0.955622, train loss: 21.101495, valid precision: 0.838000, valid loss: 97.518918
epoch: 4803, train precision: 0.953644, train loss: 21.799780, valid precision: 0.841000, valid loss: 94.322091
epoch: 4804, train precision: 0.956467, train loss: 20.507067, valid precision: 0.839200, valid loss: 110.097525
epoch: 4805, train precision: 0.957822, train loss: 20.297942, valid precision: 0.842400, valid loss: 101.111399
epoch: 4806, train precision: 0.955089, train loss: 21.192281, valid precision: 0.840400, valid loss: 101.667200
epoch: 4807, train precision: 0.959133, train loss: 20.157545, valid precision: 0.839200, valid loss: 97.874257
epoch: 4808, train precision: 0.955311, train loss: 21.076147, valid precision: 0.841800, valid loss: 97.624561
epoch: 4809, train precision: 0.957022, train loss: 20.888616, valid precision: 0.841200, valid loss: 101.180489
epoch: 4810, train precision: 0.959267, train loss: 19.876583, valid precision: 0.842400, valid loss: 102.173390
epoch: 4811, train precision: 0.957556, train loss: 20.361614, valid precision: 0.849400, valid loss: 102.699011
epoch: 4812, train precision: 0.950667, train loss: 22.800473, valid precision: 0.838200, valid loss: 104.928307
epoch: 4813, train precision: 0.957022, train loss: 20.817875, valid precision: 0.844000, valid loss: 103.501861
epoch: 4814, train precision: 0.953911, train loss: 22.008173, valid precision: 0.838600, valid loss: 104.325475
epoch: 4815, train precision: 0.958044, train loss: 20.373817, valid precision: 0.845200, valid loss: 91.804921
epoch: 4816, train precision: 0.957133, train loss: 20.740503, valid precision: 0.843400, valid loss: 98.081674
epoch: 4817, train precision: 0.962356, train loss: 18.526984, valid precision: 0.845600, valid loss: 93.326830
epoch: 4818, train precision: 0.959089, train loss: 19.905039, valid precision: 0.842600, valid loss: 98.187339
epoch: 4819, train precision: 0.957311, train loss: 20.072936, valid precision: 0.842800, valid loss: 98.483102
epoch: 4820, train precision: 0.959178, train loss: 20.200502, valid precision: 0.842200, valid loss: 107.747422
epoch: 4821, train precision: 0.958000, train loss: 20.149547, valid precision: 0.850600, valid loss: 98.251402
epoch: 4822, train precision: 0.955267, train loss: 21.091269, valid precision: 0.842600, valid loss: 100.711776
epoch: 4823, train precision: 0.952578, train loss: 22.472468, valid precision: 0.837600, valid loss: 101.516775
epoch: 4824, train precision: 0.954622, train loss: 21.305634, valid precision: 0.839000, valid loss: 98.347401
epoch: 4825, train precision: 0.958889, train loss: 19.838292, valid precision: 0.842600, valid loss: 100.051989
epoch: 4826, train precision: 0.960422, train loss: 19.098387, valid precision: 0.846800, valid loss: 99.952434
epoch: 4827, train precision: 0.954333, train loss: 21.659222, valid precision: 0.849200, valid loss: 100.873074
epoch: 4828, train precision: 0.957289, train loss: 20.512918, valid precision: 0.843600, valid loss: 97.690848
epoch: 4829, train precision: 0.956511, train loss: 21.233539, valid precision: 0.839000, valid loss: 108.409478
epoch: 4830, train precision: 0.953000, train loss: 21.531240, valid precision: 0.842600, valid loss: 101.876368
epoch: 4831, train precision: 0.955311, train loss: 21.310915, valid precision: 0.839800, valid loss: 104.538151
epoch: 4832, train precision: 0.957844, train loss: 20.057432, valid precision: 0.841200, valid loss: 99.409619
epoch: 4833, train precision: 0.957844, train loss: 20.477516, valid precision: 0.843200, valid loss: 98.637700
epoch: 4834, train precision: 0.959267, train loss: 19.990684, valid precision: 0.845200, valid loss: 104.643770
epoch: 4835, train precision: 0.958644, train loss: 20.240433, valid precision: 0.847400, valid loss: 98.386523
epoch: 4836, train precision: 0.961489, train loss: 18.765461, valid precision: 0.847000, valid loss: 97.426114
epoch: 4837, train precision: 0.958600, train loss: 20.149799, valid precision: 0.849600, valid loss: 95.993723
epoch: 4838, train precision: 0.960422, train loss: 19.356435, valid precision: 0.840200, valid loss: 99.702203
epoch: 4839, train precision: 0.956267, train loss: 21.372786, valid precision: 0.847800, valid loss: 92.808305
epoch: 4840, train precision: 0.958733, train loss: 19.757466, valid precision: 0.845200, valid loss: 100.381649
epoch: 4841, train precision: 0.952533, train loss: 22.424027, valid precision: 0.839000, valid loss: 105.703555
epoch: 4842, train precision: 0.957489, train loss: 21.046611, valid precision: 0.843800, valid loss: 103.303768
epoch: 4843, train precision: 0.953378, train loss: 21.940148, valid precision: 0.845200, valid loss: 101.261919
epoch: 4844, train precision: 0.961000, train loss: 18.994678, valid precision: 0.843400, valid loss: 102.530151
epoch: 4845, train precision: 0.958978, train loss: 19.748133, valid precision: 0.847200, valid loss: 99.184685
epoch: 4846, train precision: 0.960178, train loss: 19.403951, valid precision: 0.848600, valid loss: 99.834779
epoch: 4847, train precision: 0.954978, train loss: 20.877630, valid precision: 0.843400, valid loss: 95.412834
epoch: 4848, train precision: 0.958711, train loss: 19.982013, valid precision: 0.847000, valid loss: 93.237606
epoch: 4849, train precision: 0.959178, train loss: 19.551354, valid precision: 0.845400, valid loss: 104.289409
epoch: 4850, train precision: 0.955089, train loss: 21.521211, valid precision: 0.843800, valid loss: 97.276212
epoch: 4851, train precision: 0.960511, train loss: 18.879473, valid precision: 0.848400, valid loss: 98.155531
epoch: 4852, train precision: 0.956400, train loss: 21.141777, valid precision: 0.843200, valid loss: 97.003825
epoch: 4853, train precision: 0.958800, train loss: 20.477910, valid precision: 0.847600, valid loss: 98.868007
epoch: 4854, train precision: 0.960822, train loss: 19.455408, valid precision: 0.849000, valid loss: 95.819099
epoch: 4855, train precision: 0.958667, train loss: 19.976086, valid precision: 0.844800, valid loss: 108.394337
epoch: 4856, train precision: 0.955311, train loss: 20.923084, valid precision: 0.845200, valid loss: 93.739079
epoch: 4857, train precision: 0.960978, train loss: 18.903837, valid precision: 0.844600, valid loss: 104.615044
epoch: 4858, train precision: 0.955667, train loss: 20.905114, valid precision: 0.843600, valid loss: 103.764678
epoch: 4859, train precision: 0.957911, train loss: 20.363896, valid precision: 0.842200, valid loss: 100.749374
epoch: 4860, train precision: 0.960289, train loss: 20.045870, valid precision: 0.844800, valid loss: 94.226562
epoch: 4861, train precision: 0.960311, train loss: 19.614658, valid precision: 0.848200, valid loss: 99.722040
epoch: 4862, train precision: 0.955267, train loss: 21.532346, valid precision: 0.843200, valid loss: 101.578236
epoch: 4863, train precision: 0.960067, train loss: 19.160589, valid precision: 0.846600, valid loss: 99.214026
epoch: 4864, train precision: 0.957711, train loss: 20.598934, valid precision: 0.844000, valid loss: 100.072832
epoch: 4865, train precision: 0.955956, train loss: 21.360960, valid precision: 0.842200, valid loss: 107.258770
epoch: 4866, train precision: 0.957222, train loss: 20.293763, valid precision: 0.848600, valid loss: 101.598561
epoch: 4867, train precision: 0.956244, train loss: 21.077531, valid precision: 0.841400, valid loss: 101.918676
epoch: 4868, train precision: 0.952644, train loss: 21.970118, valid precision: 0.843000, valid loss: 103.521028
epoch: 4869, train precision: 0.961044, train loss: 19.619871, valid precision: 0.849800, valid loss: 100.961806
epoch: 4870, train precision: 0.958978, train loss: 19.471597, valid precision: 0.844800, valid loss: 97.124648
epoch: 4871, train precision: 0.958956, train loss: 19.757430, valid precision: 0.844600, valid loss: 102.826864
epoch: 4872, train precision: 0.960756, train loss: 19.149068, valid precision: 0.850000, valid loss: 98.308847
epoch: 4873, train precision: 0.958778, train loss: 19.979837, valid precision: 0.843000, valid loss: 104.326427
epoch: 4874, train precision: 0.959933, train loss: 19.697741, valid precision: 0.847400, valid loss: 99.611461
epoch: 4875, train precision: 0.958800, train loss: 19.842124, valid precision: 0.847200, valid loss: 93.152487
epoch: 4876, train precision: 0.954889, train loss: 21.519312, valid precision: 0.844800, valid loss: 101.389842
epoch: 4877, train precision: 0.960356, train loss: 19.553930, valid precision: 0.847600, valid loss: 92.092463
epoch: 4878, train precision: 0.957844, train loss: 20.566041, valid precision: 0.845400, valid loss: 102.513159
epoch: 4879, train precision: 0.955600, train loss: 21.015259, valid precision: 0.846600, valid loss: 100.978761
epoch: 4880, train precision: 0.958578, train loss: 20.126511, valid precision: 0.850000, valid loss: 99.182239
epoch: 4881, train precision: 0.951600, train loss: 22.832798, valid precision: 0.841000, valid loss: 100.785851
epoch: 4882, train precision: 0.960556, train loss: 19.299067, valid precision: 0.847200, valid loss: 95.660020
epoch: 4883, train precision: 0.959733, train loss: 19.459774, valid precision: 0.848200, valid loss: 101.290285
epoch: 4884, train precision: 0.951733, train loss: 22.680437, valid precision: 0.841400, valid loss: 99.389337
epoch: 4885, train precision: 0.963600, train loss: 18.246523, valid precision: 0.846000, valid loss: 99.571290
epoch: 4886, train precision: 0.949267, train loss: 23.242672, valid precision: 0.839800, valid loss: 97.797546
epoch: 4887, train precision: 0.958333, train loss: 19.721981, valid precision: 0.844400, valid loss: 101.256185
epoch: 4888, train precision: 0.961133, train loss: 18.814170, valid precision: 0.854200, valid loss: 101.924451
epoch: 4889, train precision: 0.955156, train loss: 21.206268, valid precision: 0.841800, valid loss: 98.272379
epoch: 4890, train precision: 0.957711, train loss: 20.646142, valid precision: 0.851600, valid loss: 100.484229
epoch: 4891, train precision: 0.960378, train loss: 19.322709, valid precision: 0.851400, valid loss: 99.818042
epoch: 4892, train precision: 0.958489, train loss: 19.977417, valid precision: 0.843400, valid loss: 98.976168
epoch: 4893, train precision: 0.952822, train loss: 22.275298, valid precision: 0.845800, valid loss: 92.863730
epoch: 4894, train precision: 0.957800, train loss: 20.201038, valid precision: 0.846200, valid loss: 98.006005
epoch: 4895, train precision: 0.955200, train loss: 21.487052, valid precision: 0.845000, valid loss: 99.198034
epoch: 4896, train precision: 0.957600, train loss: 20.116077, valid precision: 0.843800, valid loss: 101.281477
epoch: 4897, train precision: 0.953733, train loss: 21.823944, valid precision: 0.838200, valid loss: 95.665168
epoch: 4898, train precision: 0.956911, train loss: 20.525892, valid precision: 0.842200, valid loss: 97.702926
epoch: 4899, train precision: 0.963489, train loss: 18.210335, valid precision: 0.849800, valid loss: 96.214720
epoch: 4900, train precision: 0.957333, train loss: 20.513560, valid precision: 0.845800, valid loss: 98.931166
epoch: 4901, train precision: 0.961378, train loss: 18.917740, valid precision: 0.848800, valid loss: 94.066938
epoch: 4902, train precision: 0.955267, train loss: 21.564794, valid precision: 0.843800, valid loss: 100.240256
epoch: 4903, train precision: 0.957044, train loss: 20.893507, valid precision: 0.846400, valid loss: 92.291280
epoch: 4904, train precision: 0.953933, train loss: 21.534157, valid precision: 0.845000, valid loss: 100.117364
epoch: 4905, train precision: 0.957111, train loss: 20.815986, valid precision: 0.846800, valid loss: 96.576259
epoch: 4906, train precision: 0.950933, train loss: 23.083920, valid precision: 0.839200, valid loss: 101.250183
epoch: 4907, train precision: 0.960356, train loss: 19.314578, valid precision: 0.846200, valid loss: 95.638800
epoch: 4908, train precision: 0.956267, train loss: 20.368252, valid precision: 0.840200, valid loss: 104.724169
epoch: 4909, train precision: 0.951444, train loss: 23.167104, valid precision: 0.838000, valid loss: 106.420494
epoch: 4910, train precision: 0.958400, train loss: 19.942613, valid precision: 0.843800, valid loss: 96.888662
epoch: 4911, train precision: 0.956378, train loss: 20.953681, valid precision: 0.839800, valid loss: 103.254618
epoch: 4912, train precision: 0.958289, train loss: 19.937798, valid precision: 0.847800, valid loss: 98.479006
epoch: 4913, train precision: 0.953889, train loss: 21.602461, valid precision: 0.841000, valid loss: 100.968391
epoch: 4914, train precision: 0.957556, train loss: 20.705759, valid precision: 0.842000, valid loss: 103.632987
epoch: 4915, train precision: 0.959356, train loss: 19.597952, valid precision: 0.845000, valid loss: 96.346186
epoch: 4916, train precision: 0.956644, train loss: 20.499421, valid precision: 0.850000, valid loss: 98.651795
epoch: 4917, train precision: 0.956556, train loss: 20.984649, valid precision: 0.843000, valid loss: 98.360382
epoch: 4918, train precision: 0.957822, train loss: 20.283717, valid precision: 0.846800, valid loss: 102.613798
epoch: 4919, train precision: 0.956533, train loss: 20.599204, valid precision: 0.844200, valid loss: 98.913529
epoch: 4920, train precision: 0.959422, train loss: 20.103140, valid precision: 0.847800, valid loss: 96.685580
epoch: 4921, train precision: 0.959844, train loss: 19.047098, valid precision: 0.845600, valid loss: 100.447473
epoch: 4922, train precision: 0.959267, train loss: 19.628117, valid precision: 0.845000, valid loss: 96.986678
epoch: 4923, train precision: 0.959089, train loss: 19.955401, valid precision: 0.844600, valid loss: 95.819033
epoch: 4924, train precision: 0.957889, train loss: 20.310354, valid precision: 0.841000, valid loss: 95.261152
epoch: 4925, train precision: 0.961356, train loss: 18.855621, valid precision: 0.846800, valid loss: 97.131438
epoch: 4926, train precision: 0.958444, train loss: 20.315530, valid precision: 0.841200, valid loss: 103.394935
epoch: 4927, train precision: 0.959467, train loss: 19.674371, valid precision: 0.845800, valid loss: 96.599222
epoch: 4928, train precision: 0.960400, train loss: 19.232310, valid precision: 0.847000, valid loss: 101.976607
epoch: 4929, train precision: 0.958556, train loss: 19.897722, valid precision: 0.843600, valid loss: 99.411100
epoch: 4930, train precision: 0.960333, train loss: 19.456650, valid precision: 0.841200, valid loss: 102.574289
epoch: 4931, train precision: 0.958533, train loss: 20.361991, valid precision: 0.848600, valid loss: 101.363962
epoch: 4932, train precision: 0.957444, train loss: 21.007844, valid precision: 0.845600, valid loss: 94.910495
epoch: 4933, train precision: 0.958889, train loss: 19.858941, valid precision: 0.847200, valid loss: 100.410843
epoch: 4934, train precision: 0.958911, train loss: 19.853309, valid precision: 0.842600, valid loss: 97.084978
epoch: 4935, train precision: 0.960222, train loss: 18.963883, valid precision: 0.848200, valid loss: 99.799485
epoch: 4936, train precision: 0.954733, train loss: 21.007595, valid precision: 0.839800, valid loss: 96.073225
epoch: 4937, train precision: 0.959022, train loss: 19.801503, valid precision: 0.842200, valid loss: 96.232805
epoch: 4938, train precision: 0.956578, train loss: 20.764104, valid precision: 0.849400, valid loss: 99.927875
epoch: 4939, train precision: 0.959000, train loss: 19.994622, valid precision: 0.851200, valid loss: 106.278073
epoch: 4940, train precision: 0.956178, train loss: 20.869287, valid precision: 0.845600, valid loss: 99.728343
epoch: 4941, train precision: 0.955378, train loss: 21.160440, valid precision: 0.840600, valid loss: 101.634841
epoch: 4942, train precision: 0.961511, train loss: 19.148140, valid precision: 0.849400, valid loss: 99.219653
epoch: 4943, train precision: 0.960689, train loss: 18.536044, valid precision: 0.847200, valid loss: 101.990488
epoch: 4944, train precision: 0.958333, train loss: 20.258523, valid precision: 0.842000, valid loss: 96.882221
epoch: 4945, train precision: 0.955133, train loss: 21.850627, valid precision: 0.839400, valid loss: 102.900647
epoch: 4946, train precision: 0.953489, train loss: 21.900276, valid precision: 0.842200, valid loss: 99.971821
epoch: 4947, train precision: 0.958400, train loss: 19.778339, valid precision: 0.845600, valid loss: 99.799931
epoch: 4948, train precision: 0.955133, train loss: 21.440984, valid precision: 0.839200, valid loss: 94.267008
epoch: 4949, train precision: 0.961333, train loss: 18.895103, valid precision: 0.848000, valid loss: 102.051580
epoch: 4950, train precision: 0.955356, train loss: 21.179155, valid precision: 0.841400, valid loss: 99.335659
epoch: 4951, train precision: 0.959822, train loss: 19.587764, valid precision: 0.842400, valid loss: 101.798117
epoch: 4952, train precision: 0.955044, train loss: 21.724429, valid precision: 0.838400, valid loss: 100.726785
epoch: 4953, train precision: 0.955444, train loss: 21.547889, valid precision: 0.837000, valid loss: 106.728318
epoch: 4954, train precision: 0.959978, train loss: 19.443786, valid precision: 0.844800, valid loss: 97.819914
epoch: 4955, train precision: 0.958867, train loss: 19.981660, valid precision: 0.843600, valid loss: 99.921403
epoch: 4956, train precision: 0.954511, train loss: 22.036498, valid precision: 0.844800, valid loss: 97.857261
epoch: 4957, train precision: 0.955356, train loss: 20.973083, valid precision: 0.840600, valid loss: 100.925865
epoch: 4958, train precision: 0.951111, train loss: 23.121034, valid precision: 0.841000, valid loss: 103.718774
epoch: 4959, train precision: 0.956022, train loss: 20.952697, valid precision: 0.847000, valid loss: 96.653175
epoch: 4960, train precision: 0.960867, train loss: 18.979509, valid precision: 0.855800, valid loss: 93.914412
epoch: 4961, train precision: 0.952311, train loss: 22.166720, valid precision: 0.843000, valid loss: 98.367153
epoch: 4962, train precision: 0.958800, train loss: 19.933801, valid precision: 0.846400, valid loss: 97.804488
epoch: 4963, train precision: 0.957800, train loss: 20.530961, valid precision: 0.846200, valid loss: 101.910066
epoch: 4964, train precision: 0.960556, train loss: 19.093192, valid precision: 0.849600, valid loss: 98.229524
epoch: 4965, train precision: 0.957311, train loss: 20.389566, valid precision: 0.843400, valid loss: 98.261983
epoch: 4966, train precision: 0.954978, train loss: 20.815248, valid precision: 0.845000, valid loss: 105.197726
epoch: 4967, train precision: 0.959378, train loss: 19.770275, valid precision: 0.853200, valid loss: 98.983852
epoch: 4968, train precision: 0.952867, train loss: 21.578917, valid precision: 0.844600, valid loss: 106.627762
epoch: 4969, train precision: 0.956956, train loss: 20.799114, valid precision: 0.844000, valid loss: 98.321460
epoch: 4970, train precision: 0.956467, train loss: 21.420612, valid precision: 0.837400, valid loss: 99.822151
epoch: 4971, train precision: 0.960311, train loss: 19.046161, valid precision: 0.851600, valid loss: 104.423248
epoch: 4972, train precision: 0.957889, train loss: 19.743476, valid precision: 0.846600, valid loss: 101.885876
epoch: 4973, train precision: 0.956933, train loss: 20.979138, valid precision: 0.837800, valid loss: 100.614271
epoch: 4974, train precision: 0.956644, train loss: 20.680787, valid precision: 0.847600, valid loss: 96.657734
epoch: 4975, train precision: 0.952867, train loss: 22.438444, valid precision: 0.846000, valid loss: 99.935003
epoch: 4976, train precision: 0.963978, train loss: 18.040139, valid precision: 0.848800, valid loss: 105.953622
epoch: 4977, train precision: 0.957689, train loss: 20.551739, valid precision: 0.845200, valid loss: 105.697669
epoch: 4978, train precision: 0.960978, train loss: 18.828395, valid precision: 0.852600, valid loss: 100.713864
epoch: 4979, train precision: 0.958978, train loss: 19.606045, valid precision: 0.851000, valid loss: 100.579099
epoch: 4980, train precision: 0.959267, train loss: 20.062906, valid precision: 0.847600, valid loss: 97.537896
epoch: 4981, train precision: 0.960156, train loss: 19.717545, valid precision: 0.848400, valid loss: 96.311770
epoch: 4982, train precision: 0.955778, train loss: 20.728262, valid precision: 0.844400, valid loss: 100.447419
epoch: 4983, train precision: 0.954689, train loss: 21.506554, valid precision: 0.845000, valid loss: 100.954978
epoch: 4984, train precision: 0.957844, train loss: 20.600332, valid precision: 0.843400, valid loss: 100.120536
epoch: 4985, train precision: 0.960644, train loss: 19.168402, valid precision: 0.852800, valid loss: 96.809291
epoch: 4986, train precision: 0.957067, train loss: 20.705668, valid precision: 0.848200, valid loss: 95.546055
epoch: 4987, train precision: 0.955111, train loss: 21.242550, valid precision: 0.840800, valid loss: 102.110750
epoch: 4988, train precision: 0.955600, train loss: 21.119939, valid precision: 0.843800, valid loss: 95.749955
epoch: 4989, train precision: 0.958422, train loss: 20.371593, valid precision: 0.845600, valid loss: 96.551463
epoch: 4990, train precision: 0.960333, train loss: 19.369576, valid precision: 0.844800, valid loss: 110.593758
epoch: 4991, train precision: 0.957111, train loss: 20.486203, valid precision: 0.845000, valid loss: 95.152320
epoch: 4992, train precision: 0.956200, train loss: 21.124508, valid precision: 0.847400, valid loss: 96.094359
epoch: 4993, train precision: 0.958689, train loss: 20.128383, valid precision: 0.848000, valid loss: 93.780597
epoch: 4994, train precision: 0.950000, train loss: 23.190258, valid precision: 0.840000, valid loss: 97.747340
epoch: 4995, train precision: 0.958000, train loss: 20.239566, valid precision: 0.842800, valid loss: 99.325036
epoch: 4996, train precision: 0.957422, train loss: 20.821057, valid precision: 0.841600, valid loss: 107.433265
epoch: 4997, train precision: 0.956978, train loss: 20.862583, valid precision: 0.838600, valid loss: 100.335647
epoch: 4998, train precision: 0.961267, train loss: 18.850494, valid precision: 0.846400, valid loss: 99.638897
epoch: 4999, train precision: 0.956911, train loss: 20.980628, valid precision: 0.845200, valid loss: 91.553149
epoch: 5000, train precision: 0.957089, train loss: 20.133788, valid precision: 0.850200, valid loss: 98.538978
