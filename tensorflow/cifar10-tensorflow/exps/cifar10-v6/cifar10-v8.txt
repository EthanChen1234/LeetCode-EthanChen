nohup: ignoring input
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:82:00.0
Total memory: 11.90GiB
Free memory: 5.98GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:82:00.0)
epoch: 0, train precision: 0.583200, train loss: 174.030037, valid precision: 0.602800, valid loss: 169.157844
epoch: 1, train precision: 0.684444, train loss: 135.991619, valid precision: 0.699600, valid loss: 133.025722
epoch: 2, train precision: 0.722422, train loss: 116.684536, valid precision: 0.719600, valid loss: 115.901657
epoch: 3, train precision: 0.756956, train loss: 101.575049, valid precision: 0.738800, valid loss: 103.556228
epoch: 4, train precision: 0.775156, train loss: 92.564421, valid precision: 0.757200, valid loss: 96.121571
epoch: 5, train precision: 0.791644, train loss: 84.890026, valid precision: 0.769200, valid loss: 90.308193
epoch: 6, train precision: 0.814200, train loss: 76.840530, valid precision: 0.777800, valid loss: 84.617818
epoch: 7, train precision: 0.819022, train loss: 74.054612, valid precision: 0.784400, valid loss: 82.528885
epoch: 8, train precision: 0.828356, train loss: 69.800765, valid precision: 0.794600, valid loss: 79.327030
epoch: 9, train precision: 0.835711, train loss: 66.509251, valid precision: 0.795400, valid loss: 78.407600
epoch: 10, train precision: 0.846889, train loss: 61.435148, valid precision: 0.800400, valid loss: 75.524656
epoch: 11, train precision: 0.859822, train loss: 57.784052, valid precision: 0.806600, valid loss: 72.505251
epoch: 12, train precision: 0.861844, train loss: 56.459213, valid precision: 0.808800, valid loss: 72.476587
epoch: 13, train precision: 0.868022, train loss: 54.248814, valid precision: 0.819200, valid loss: 70.180975
epoch: 14, train precision: 0.876978, train loss: 51.276663, valid precision: 0.821200, valid loss: 67.991215
epoch: 15, train precision: 0.879911, train loss: 49.627559, valid precision: 0.819400, valid loss: 67.662220
epoch: 16, train precision: 0.884956, train loss: 47.715615, valid precision: 0.824200, valid loss: 66.621309
epoch: 17, train precision: 0.891956, train loss: 45.594215, valid precision: 0.828800, valid loss: 65.172685
epoch: 18, train precision: 0.899111, train loss: 42.989158, valid precision: 0.833600, valid loss: 64.068843
epoch: 19, train precision: 0.891156, train loss: 44.861587, valid precision: 0.834000, valid loss: 64.608989
epoch: 20, train precision: 0.902111, train loss: 41.346836, valid precision: 0.830200, valid loss: 63.882432
epoch: 21, train precision: 0.910689, train loss: 38.942393, valid precision: 0.834600, valid loss: 62.600049
epoch: 22, train precision: 0.914578, train loss: 37.206321, valid precision: 0.836400, valid loss: 61.229335
epoch: 23, train precision: 0.915667, train loss: 36.857873, valid precision: 0.835200, valid loss: 62.471356
epoch: 24, train precision: 0.919556, train loss: 35.135296, valid precision: 0.836800, valid loss: 62.006264
epoch: 25, train precision: 0.923156, train loss: 34.144634, valid precision: 0.842000, valid loss: 60.644364
epoch: 26, train precision: 0.924533, train loss: 33.304951, valid precision: 0.841600, valid loss: 61.454562
epoch: 27, train precision: 0.930556, train loss: 31.430455, valid precision: 0.839200, valid loss: 61.190892
epoch: 28, train precision: 0.934933, train loss: 30.554332, valid precision: 0.842000, valid loss: 60.444318
epoch: 29, train precision: 0.935467, train loss: 29.723697, valid precision: 0.840800, valid loss: 60.229125
epoch: 30, train precision: 0.935267, train loss: 29.409835, valid precision: 0.840800, valid loss: 60.404025
epoch: 31, train precision: 0.936689, train loss: 28.843688, valid precision: 0.845600, valid loss: 60.288583
epoch: 32, train precision: 0.938956, train loss: 28.243795, valid precision: 0.844400, valid loss: 61.253162
epoch: 33, train precision: 0.941800, train loss: 27.170289, valid precision: 0.850000, valid loss: 59.403201
epoch: 34, train precision: 0.944911, train loss: 26.472815, valid precision: 0.850400, valid loss: 58.545593
epoch: 35, train precision: 0.949000, train loss: 25.328085, valid precision: 0.846600, valid loss: 59.261945
epoch: 36, train precision: 0.947333, train loss: 25.304437, valid precision: 0.845400, valid loss: 59.259243
epoch: 37, train precision: 0.953156, train loss: 23.767910, valid precision: 0.847600, valid loss: 58.795342
epoch: 38, train precision: 0.952800, train loss: 23.757836, valid precision: 0.853400, valid loss: 57.738347
epoch: 39, train precision: 0.950622, train loss: 24.120362, valid precision: 0.849200, valid loss: 59.414680
epoch: 40, train precision: 0.957289, train loss: 22.136175, valid precision: 0.848200, valid loss: 60.015559
epoch: 41, train precision: 0.956689, train loss: 22.500596, valid precision: 0.852000, valid loss: 58.917166
epoch: 42, train precision: 0.957178, train loss: 22.120274, valid precision: 0.850400, valid loss: 58.766849
epoch: 43, train precision: 0.960044, train loss: 21.160231, valid precision: 0.854400, valid loss: 59.436591
epoch: 44, train precision: 0.959200, train loss: 21.276558, valid precision: 0.854600, valid loss: 59.805664
epoch: 45, train precision: 0.961333, train loss: 20.581896, valid precision: 0.851800, valid loss: 60.062036
epoch: 46, train precision: 0.964622, train loss: 19.721770, valid precision: 0.852600, valid loss: 58.168113
epoch: 47, train precision: 0.963111, train loss: 19.977226, valid precision: 0.850200, valid loss: 60.837423
epoch: 48, train precision: 0.963200, train loss: 19.725029, valid precision: 0.851000, valid loss: 58.891405
epoch: 49, train precision: 0.965022, train loss: 19.331694, valid precision: 0.857000, valid loss: 59.807070
epoch: 50, train precision: 0.967133, train loss: 18.431203, valid precision: 0.853000, valid loss: 58.780901
epoch: 51, train precision: 0.969844, train loss: 17.661503, valid precision: 0.857400, valid loss: 59.201718
epoch: 52, train precision: 0.967311, train loss: 18.409732, valid precision: 0.859000, valid loss: 58.451528
epoch: 53, train precision: 0.969178, train loss: 17.766843, valid precision: 0.856400, valid loss: 60.051901
epoch: 54, train precision: 0.968378, train loss: 17.944961, valid precision: 0.849200, valid loss: 60.889006
epoch: 55, train precision: 0.965978, train loss: 18.439777, valid precision: 0.851600, valid loss: 61.906871
epoch: 56, train precision: 0.970578, train loss: 17.161829, valid precision: 0.851800, valid loss: 60.631296
epoch: 57, train precision: 0.973778, train loss: 16.220602, valid precision: 0.858000, valid loss: 58.716204
epoch: 58, train precision: 0.973333, train loss: 16.228066, valid precision: 0.858800, valid loss: 59.413608
epoch: 59, train precision: 0.973867, train loss: 16.044380, valid precision: 0.855600, valid loss: 59.512894
epoch: 60, train precision: 0.971733, train loss: 16.650579, valid precision: 0.856200, valid loss: 60.414707
epoch: 61, train precision: 0.971711, train loss: 16.764852, valid precision: 0.852800, valid loss: 61.760955
epoch: 62, train precision: 0.974044, train loss: 15.941109, valid precision: 0.856600, valid loss: 60.289901
epoch: 63, train precision: 0.973578, train loss: 15.737313, valid precision: 0.858600, valid loss: 61.300482
epoch: 64, train precision: 0.974778, train loss: 15.658617, valid precision: 0.861000, valid loss: 59.430651
epoch: 65, train precision: 0.975556, train loss: 15.300264, valid precision: 0.861800, valid loss: 58.944158
epoch: 66, train precision: 0.977467, train loss: 14.442898, valid precision: 0.860600, valid loss: 59.163416
epoch: 67, train precision: 0.978000, train loss: 14.599665, valid precision: 0.861600, valid loss: 60.559533
epoch: 68, train precision: 0.976667, train loss: 14.722483, valid precision: 0.856800, valid loss: 61.034261
epoch: 69, train precision: 0.979911, train loss: 13.947281, valid precision: 0.858400, valid loss: 61.604581
epoch: 70, train precision: 0.978067, train loss: 14.484016, valid precision: 0.856200, valid loss: 61.517098
epoch: 71, train precision: 0.978622, train loss: 14.205404, valid precision: 0.860600, valid loss: 60.921827
epoch: 72, train precision: 0.982311, train loss: 13.329949, valid precision: 0.861200, valid loss: 58.953428
epoch: 73, train precision: 0.980578, train loss: 13.763269, valid precision: 0.861400, valid loss: 61.388816
epoch: 74, train precision: 0.980444, train loss: 13.718836, valid precision: 0.862000, valid loss: 61.544448
epoch: 75, train precision: 0.979467, train loss: 13.789138, valid precision: 0.857800, valid loss: 62.579557
epoch: 76, train precision: 0.982378, train loss: 12.933474, valid precision: 0.859400, valid loss: 63.032454
epoch: 77, train precision: 0.984933, train loss: 12.432973, valid precision: 0.858800, valid loss: 62.236350
epoch: 78, train precision: 0.981333, train loss: 13.298206, valid precision: 0.852200, valid loss: 63.312793
epoch: 79, train precision: 0.980000, train loss: 13.752781, valid precision: 0.858200, valid loss: 61.624108
epoch: 80, train precision: 0.981867, train loss: 12.940643, valid precision: 0.858600, valid loss: 60.959463
epoch: 81, train precision: 0.983711, train loss: 12.303381, valid precision: 0.860000, valid loss: 60.476413
epoch: 82, train precision: 0.984333, train loss: 12.226083, valid precision: 0.858800, valid loss: 61.051383
epoch: 83, train precision: 0.984200, train loss: 12.246658, valid precision: 0.860000, valid loss: 61.970597
epoch: 84, train precision: 0.981956, train loss: 12.803619, valid precision: 0.861600, valid loss: 62.788090
epoch: 85, train precision: 0.984356, train loss: 12.267968, valid precision: 0.853400, valid loss: 63.512264
epoch: 86, train precision: 0.984022, train loss: 12.492416, valid precision: 0.855600, valid loss: 63.157302
epoch: 87, train precision: 0.984756, train loss: 12.134236, valid precision: 0.859000, valid loss: 63.150186
epoch: 88, train precision: 0.986067, train loss: 11.934658, valid precision: 0.859000, valid loss: 63.783546
epoch: 89, train precision: 0.984200, train loss: 12.103503, valid precision: 0.857800, valid loss: 63.609587
epoch: 90, train precision: 0.982533, train loss: 12.681183, valid precision: 0.859600, valid loss: 63.117338
epoch: 91, train precision: 0.987311, train loss: 11.425482, valid precision: 0.861400, valid loss: 63.146136
epoch: 92, train precision: 0.985356, train loss: 11.968832, valid precision: 0.856600, valid loss: 64.285806
epoch: 93, train precision: 0.985244, train loss: 11.884259, valid precision: 0.858600, valid loss: 63.552732
epoch: 94, train precision: 0.986911, train loss: 11.341709, valid precision: 0.862400, valid loss: 61.312276
epoch: 95, train precision: 0.985578, train loss: 11.695862, valid precision: 0.858400, valid loss: 66.018744
epoch: 96, train precision: 0.987444, train loss: 11.205381, valid precision: 0.865600, valid loss: 62.492425
epoch: 97, train precision: 0.986756, train loss: 11.305319, valid precision: 0.860000, valid loss: 64.914736
epoch: 98, train precision: 0.986311, train loss: 11.380982, valid precision: 0.861600, valid loss: 65.165162
epoch: 99, train precision: 0.989089, train loss: 10.774545, valid precision: 0.862200, valid loss: 65.546420
epoch: 100, train precision: 0.986933, train loss: 11.278372, valid precision: 0.859400, valid loss: 65.942257
epoch: 101, train precision: 0.987000, train loss: 11.402270, valid precision: 0.856800, valid loss: 64.741045
epoch: 102, train precision: 0.986111, train loss: 11.567414, valid precision: 0.855000, valid loss: 65.494290
epoch: 103, train precision: 0.985800, train loss: 11.739780, valid precision: 0.856000, valid loss: 67.238055
epoch: 104, train precision: 0.987644, train loss: 11.189313, valid precision: 0.860800, valid loss: 64.588722
epoch: 105, train precision: 0.989200, train loss: 10.670520, valid precision: 0.858000, valid loss: 65.560630
epoch: 106, train precision: 0.989911, train loss: 10.508483, valid precision: 0.856600, valid loss: 65.352204
epoch: 107, train precision: 0.989022, train loss: 10.743110, valid precision: 0.864600, valid loss: 65.455451
epoch: 108, train precision: 0.988889, train loss: 10.677625, valid precision: 0.864200, valid loss: 64.624177
epoch: 109, train precision: 0.988333, train loss: 11.009128, valid precision: 0.859800, valid loss: 66.565896
epoch: 110, train precision: 0.988000, train loss: 11.119428, valid precision: 0.857000, valid loss: 68.139023
epoch: 111, train precision: 0.987667, train loss: 10.915479, valid precision: 0.859800, valid loss: 66.110967
epoch: 112, train precision: 0.986933, train loss: 11.249185, valid precision: 0.857000, valid loss: 68.435752
epoch: 113, train precision: 0.989022, train loss: 10.694493, valid precision: 0.853400, valid loss: 68.834388
epoch: 114, train precision: 0.989867, train loss: 10.589465, valid precision: 0.856200, valid loss: 66.018075
epoch: 115, train precision: 0.990356, train loss: 10.302444, valid precision: 0.860400, valid loss: 65.983035
epoch: 116, train precision: 0.987689, train loss: 11.052419, valid precision: 0.852200, valid loss: 69.425310
epoch: 117, train precision: 0.989178, train loss: 10.643950, valid precision: 0.862000, valid loss: 67.701499
epoch: 118, train precision: 0.988533, train loss: 10.823401, valid precision: 0.863200, valid loss: 68.398545
epoch: 119, train precision: 0.988622, train loss: 10.951084, valid precision: 0.861400, valid loss: 68.858926
epoch: 120, train precision: 0.989933, train loss: 10.433171, valid precision: 0.861400, valid loss: 67.840547
epoch: 121, train precision: 0.990933, train loss: 10.424907, valid precision: 0.862000, valid loss: 66.734739
epoch: 122, train precision: 0.989911, train loss: 10.552677, valid precision: 0.865800, valid loss: 66.490881
epoch: 123, train precision: 0.990067, train loss: 10.379613, valid precision: 0.863600, valid loss: 67.341816
epoch: 124, train precision: 0.990933, train loss: 10.127452, valid precision: 0.863800, valid loss: 65.978305
epoch: 125, train precision: 0.989889, train loss: 10.473555, valid precision: 0.865800, valid loss: 65.154984
epoch: 126, train precision: 0.989244, train loss: 10.714194, valid precision: 0.857600, valid loss: 68.040307
epoch: 127, train precision: 0.990533, train loss: 10.261587, valid precision: 0.860000, valid loss: 67.637845
epoch: 128, train precision: 0.990844, train loss: 10.244749, valid precision: 0.860800, valid loss: 67.539117
epoch: 129, train precision: 0.991667, train loss: 10.117521, valid precision: 0.859800, valid loss: 67.464591
epoch: 130, train precision: 0.990867, train loss: 10.176468, valid precision: 0.863600, valid loss: 67.903243
epoch: 131, train precision: 0.988978, train loss: 10.751785, valid precision: 0.860600, valid loss: 69.156513
epoch: 132, train precision: 0.991489, train loss: 10.035956, valid precision: 0.863800, valid loss: 68.445959
epoch: 133, train precision: 0.990356, train loss: 10.460263, valid precision: 0.863600, valid loss: 70.916963
epoch: 134, train precision: 0.989978, train loss: 10.296199, valid precision: 0.862400, valid loss: 69.475032
epoch: 135, train precision: 0.991444, train loss: 10.123102, valid precision: 0.864000, valid loss: 68.639086
epoch: 136, train precision: 0.992289, train loss: 9.957464, valid precision: 0.864600, valid loss: 67.857377
epoch: 137, train precision: 0.992756, train loss: 9.710760, valid precision: 0.866000, valid loss: 66.433216
epoch: 138, train precision: 0.991400, train loss: 9.963957, valid precision: 0.869400, valid loss: 67.852672
epoch: 139, train precision: 0.992400, train loss: 9.921752, valid precision: 0.865600, valid loss: 68.507585
epoch: 140, train precision: 0.991778, train loss: 10.062313, valid precision: 0.865800, valid loss: 69.041711
epoch: 141, train precision: 0.991600, train loss: 10.265069, valid precision: 0.869600, valid loss: 67.877154
epoch: 142, train precision: 0.991422, train loss: 10.293852, valid precision: 0.867000, valid loss: 68.505018
epoch: 143, train precision: 0.991378, train loss: 10.162609, valid precision: 0.866200, valid loss: 67.882776
epoch: 144, train precision: 0.991667, train loss: 10.180427, valid precision: 0.861000, valid loss: 70.612042
epoch: 145, train precision: 0.992044, train loss: 10.048881, valid precision: 0.863800, valid loss: 68.525830
epoch: 146, train precision: 0.991844, train loss: 10.199048, valid precision: 0.865600, valid loss: 69.210232
epoch: 147, train precision: 0.992156, train loss: 10.088832, valid precision: 0.862200, valid loss: 69.350788
epoch: 148, train precision: 0.991222, train loss: 10.263708, valid precision: 0.865800, valid loss: 69.240787
epoch: 149, train precision: 0.993622, train loss: 9.691870, valid precision: 0.865800, valid loss: 69.283696
epoch: 150, train precision: 0.991556, train loss: 10.219185, valid precision: 0.857200, valid loss: 71.392423
epoch: 151, train precision: 0.992289, train loss: 10.069131, valid precision: 0.866000, valid loss: 70.269289
epoch: 152, train precision: 0.991867, train loss: 10.028972, valid precision: 0.865800, valid loss: 69.486744
epoch: 153, train precision: 0.993289, train loss: 9.777287, valid precision: 0.867200, valid loss: 68.940526
epoch: 154, train precision: 0.993667, train loss: 9.598330, valid precision: 0.863000, valid loss: 69.563958
epoch: 155, train precision: 0.992867, train loss: 9.859400, valid precision: 0.863800, valid loss: 70.078601
epoch: 156, train precision: 0.993156, train loss: 9.778702, valid precision: 0.865200, valid loss: 69.416048
epoch: 157, train precision: 0.991533, train loss: 10.150653, valid precision: 0.859400, valid loss: 72.194079
epoch: 158, train precision: 0.991400, train loss: 10.149594, valid precision: 0.858800, valid loss: 72.729836
epoch: 159, train precision: 0.993222, train loss: 9.756358, valid precision: 0.866200, valid loss: 71.772867
epoch: 160, train precision: 0.993511, train loss: 9.755873, valid precision: 0.857200, valid loss: 70.768199
epoch: 161, train precision: 0.993711, train loss: 9.734681, valid precision: 0.862400, valid loss: 70.619384
epoch: 162, train precision: 0.992844, train loss: 9.891685, valid precision: 0.861000, valid loss: 72.305168
epoch: 163, train precision: 0.993600, train loss: 9.609403, valid precision: 0.867000, valid loss: 72.782470
epoch: 164, train precision: 0.992867, train loss: 9.904699, valid precision: 0.864000, valid loss: 71.646783
epoch: 165, train precision: 0.992489, train loss: 10.041148, valid precision: 0.861600, valid loss: 73.668994
epoch: 166, train precision: 0.993400, train loss: 9.868396, valid precision: 0.866600, valid loss: 71.641706
epoch: 167, train precision: 0.992800, train loss: 10.185684, valid precision: 0.862800, valid loss: 71.532737
epoch: 168, train precision: 0.992956, train loss: 10.013496, valid precision: 0.865200, valid loss: 72.583511
epoch: 169, train precision: 0.993467, train loss: 9.868586, valid precision: 0.862200, valid loss: 72.205432
epoch: 170, train precision: 0.993333, train loss: 9.921862, valid precision: 0.863400, valid loss: 72.594368
epoch: 171, train precision: 0.993533, train loss: 9.788799, valid precision: 0.866800, valid loss: 69.524932
epoch: 172, train precision: 0.991467, train loss: 10.535994, valid precision: 0.865600, valid loss: 70.334450
epoch: 173, train precision: 0.992556, train loss: 10.151985, valid precision: 0.862400, valid loss: 71.473656
epoch: 174, train precision: 0.993311, train loss: 9.988293, valid precision: 0.864400, valid loss: 71.645983
epoch: 175, train precision: 0.992489, train loss: 10.106217, valid precision: 0.863800, valid loss: 72.121355
epoch: 176, train precision: 0.993933, train loss: 9.884217, valid precision: 0.865600, valid loss: 70.176027
epoch: 177, train precision: 0.994533, train loss: 9.530913, valid precision: 0.865000, valid loss: 70.508691
epoch: 178, train precision: 0.989733, train loss: 11.103423, valid precision: 0.863000, valid loss: 71.747942
epoch: 179, train precision: 0.993289, train loss: 9.973303, valid precision: 0.866000, valid loss: 72.080076
epoch: 180, train precision: 0.994689, train loss: 9.629545, valid precision: 0.866600, valid loss: 71.375167
epoch: 181, train precision: 0.993644, train loss: 9.809752, valid precision: 0.865000, valid loss: 72.707655
epoch: 182, train precision: 0.994089, train loss: 9.732482, valid precision: 0.869400, valid loss: 70.738505
epoch: 183, train precision: 0.994444, train loss: 9.575261, valid precision: 0.862600, valid loss: 73.035900
epoch: 184, train precision: 0.993356, train loss: 9.921196, valid precision: 0.865000, valid loss: 71.696240
epoch: 185, train precision: 0.993933, train loss: 9.941345, valid precision: 0.864400, valid loss: 71.296524
epoch: 186, train precision: 0.993533, train loss: 9.985416, valid precision: 0.869800, valid loss: 72.312314
epoch: 187, train precision: 0.993844, train loss: 9.955238, valid precision: 0.868600, valid loss: 72.077559
epoch: 188, train precision: 0.994644, train loss: 9.744384, valid precision: 0.868800, valid loss: 69.354796
epoch: 189, train precision: 0.994156, train loss: 9.923850, valid precision: 0.862000, valid loss: 72.054165
epoch: 190, train precision: 0.995156, train loss: 9.627218, valid precision: 0.866000, valid loss: 72.748923
epoch: 191, train precision: 0.994600, train loss: 9.617018, valid precision: 0.866600, valid loss: 73.851001
epoch: 192, train precision: 0.994267, train loss: 9.793872, valid precision: 0.867200, valid loss: 71.875300
epoch: 193, train precision: 0.994622, train loss: 9.781416, valid precision: 0.866400, valid loss: 73.011322
epoch: 194, train precision: 0.994556, train loss: 9.685005, valid precision: 0.864800, valid loss: 73.642615
epoch: 195, train precision: 0.994289, train loss: 9.756522, valid precision: 0.870200, valid loss: 72.581889
epoch: 196, train precision: 0.994067, train loss: 9.938703, valid precision: 0.868800, valid loss: 73.246737
epoch: 197, train precision: 0.994800, train loss: 9.780530, valid precision: 0.872200, valid loss: 71.675151
epoch: 198, train precision: 0.995711, train loss: 9.497117, valid precision: 0.870000, valid loss: 72.078295
epoch: 199, train precision: 0.995133, train loss: 9.665219, valid precision: 0.868600, valid loss: 73.955858
epoch: 200, train precision: 0.993756, train loss: 9.979069, valid precision: 0.867800, valid loss: 74.604483
epoch: 201, train precision: 0.993511, train loss: 10.161379, valid precision: 0.862600, valid loss: 75.251151
epoch: 202, train precision: 0.993822, train loss: 10.028854, valid precision: 0.867800, valid loss: 74.324927
epoch: 203, train precision: 0.994956, train loss: 9.649933, valid precision: 0.868000, valid loss: 74.768427
epoch: 204, train precision: 0.994556, train loss: 9.787972, valid precision: 0.867200, valid loss: 73.695667
epoch: 205, train precision: 0.994378, train loss: 10.006325, valid precision: 0.869000, valid loss: 75.014765
epoch: 206, train precision: 0.993311, train loss: 10.130086, valid precision: 0.866200, valid loss: 76.487011
epoch: 207, train precision: 0.994933, train loss: 9.701280, valid precision: 0.862800, valid loss: 75.245983
epoch: 208, train precision: 0.995200, train loss: 9.697530, valid precision: 0.865400, valid loss: 75.852139
epoch: 209, train precision: 0.994622, train loss: 9.889766, valid precision: 0.862800, valid loss: 74.974610
epoch: 210, train precision: 0.993778, train loss: 10.269089, valid precision: 0.867200, valid loss: 74.695017
epoch: 211, train precision: 0.994467, train loss: 9.975732, valid precision: 0.866200, valid loss: 73.708525
epoch: 212, train precision: 0.995778, train loss: 9.540778, valid precision: 0.869200, valid loss: 72.913904
epoch: 213, train precision: 0.995244, train loss: 9.738964, valid precision: 0.867800, valid loss: 74.580149
epoch: 214, train precision: 0.995311, train loss: 9.691740, valid precision: 0.866800, valid loss: 76.966901
epoch: 215, train precision: 0.994689, train loss: 9.857945, valid precision: 0.872000, valid loss: 74.094470
epoch: 216, train precision: 0.994756, train loss: 9.972774, valid precision: 0.861600, valid loss: 76.865828
epoch: 217, train precision: 0.994733, train loss: 9.829048, valid precision: 0.864000, valid loss: 77.250058
epoch: 218, train precision: 0.994689, train loss: 9.893484, valid precision: 0.859800, valid loss: 76.170741
epoch: 219, train precision: 0.994600, train loss: 9.954562, valid precision: 0.867800, valid loss: 77.209341
epoch: 220, train precision: 0.994178, train loss: 10.090924, valid precision: 0.862400, valid loss: 77.402259
epoch: 221, train precision: 0.994311, train loss: 10.175160, valid precision: 0.865000, valid loss: 76.611065
epoch: 222, train precision: 0.995867, train loss: 9.689401, valid precision: 0.868800, valid loss: 78.556125
epoch: 223, train precision: 0.995422, train loss: 9.847505, valid precision: 0.868600, valid loss: 76.628549
epoch: 224, train precision: 0.993733, train loss: 10.257489, valid precision: 0.867800, valid loss: 77.710290
epoch: 225, train precision: 0.995378, train loss: 9.817852, valid precision: 0.866400, valid loss: 76.590330
epoch: 226, train precision: 0.996622, train loss: 9.462816, valid precision: 0.866200, valid loss: 76.946165
epoch: 227, train precision: 0.996733, train loss: 9.373483, valid precision: 0.863400, valid loss: 75.671088
epoch: 228, train precision: 0.995556, train loss: 9.767833, valid precision: 0.864400, valid loss: 76.781959
epoch: 229, train precision: 0.995600, train loss: 9.799798, valid precision: 0.869400, valid loss: 76.604171
epoch: 230, train precision: 0.995467, train loss: 9.844821, valid precision: 0.863600, valid loss: 76.552474
epoch: 231, train precision: 0.996000, train loss: 9.661262, valid precision: 0.865200, valid loss: 76.245837
epoch: 232, train precision: 0.994911, train loss: 10.058433, valid precision: 0.867600, valid loss: 76.399263
epoch: 233, train precision: 0.994933, train loss: 10.198006, valid precision: 0.865800, valid loss: 77.276104
epoch: 234, train precision: 0.994533, train loss: 10.015394, valid precision: 0.868200, valid loss: 76.265485
epoch: 235, train precision: 0.996156, train loss: 9.670140, valid precision: 0.868200, valid loss: 74.766662
epoch: 236, train precision: 0.995400, train loss: 9.817619, valid precision: 0.867400, valid loss: 77.481298
epoch: 237, train precision: 0.995889, train loss: 9.872451, valid precision: 0.863600, valid loss: 77.275854
epoch: 238, train precision: 0.995933, train loss: 9.680343, valid precision: 0.867600, valid loss: 73.995260
epoch: 239, train precision: 0.995978, train loss: 9.734041, valid precision: 0.865400, valid loss: 76.683549
epoch: 240, train precision: 0.995756, train loss: 9.755290, valid precision: 0.865600, valid loss: 76.611946
epoch: 241, train precision: 0.995267, train loss: 10.041429, valid precision: 0.862800, valid loss: 78.703185
epoch: 242, train precision: 0.995733, train loss: 9.932237, valid precision: 0.870000, valid loss: 79.118457
epoch: 243, train precision: 0.995689, train loss: 9.865906, valid precision: 0.867800, valid loss: 78.144704
epoch: 244, train precision: 0.995711, train loss: 9.923783, valid precision: 0.868200, valid loss: 78.778943
epoch: 245, train precision: 0.996467, train loss: 9.604428, valid precision: 0.869000, valid loss: 77.896420
epoch: 246, train precision: 0.996178, train loss: 9.800570, valid precision: 0.873000, valid loss: 75.529587
epoch: 247, train precision: 0.995956, train loss: 9.810830, valid precision: 0.871000, valid loss: 77.180531
epoch: 248, train precision: 0.994978, train loss: 10.250843, valid precision: 0.866200, valid loss: 79.700541
epoch: 249, train precision: 0.995489, train loss: 9.988773, valid precision: 0.871200, valid loss: 78.213967
epoch: 250, train precision: 0.995956, train loss: 9.779694, valid precision: 0.867400, valid loss: 78.205738
epoch: 251, train precision: 0.996489, train loss: 9.851559, valid precision: 0.869000, valid loss: 77.158210
epoch: 252, train precision: 0.995711, train loss: 9.885810, valid precision: 0.863400, valid loss: 78.907075
epoch: 253, train precision: 0.996422, train loss: 9.786027, valid precision: 0.868400, valid loss: 76.720069
epoch: 254, train precision: 0.995889, train loss: 9.876094, valid precision: 0.866400, valid loss: 78.318709
epoch: 255, train precision: 0.995733, train loss: 9.969213, valid precision: 0.868800, valid loss: 77.976230
epoch: 256, train precision: 0.996356, train loss: 9.740072, valid precision: 0.871400, valid loss: 77.361786
epoch: 257, train precision: 0.996178, train loss: 9.792436, valid precision: 0.870200, valid loss: 78.828493
epoch: 258, train precision: 0.996467, train loss: 9.740195, valid precision: 0.869000, valid loss: 77.978105
epoch: 259, train precision: 0.995800, train loss: 10.065671, valid precision: 0.864800, valid loss: 78.537728
epoch: 260, train precision: 0.995733, train loss: 9.944479, valid precision: 0.865400, valid loss: 79.616983
epoch: 261, train precision: 0.994667, train loss: 10.344220, valid precision: 0.863000, valid loss: 80.830634
epoch: 262, train precision: 0.996911, train loss: 9.683888, valid precision: 0.868000, valid loss: 79.909288
epoch: 263, train precision: 0.995511, train loss: 10.082454, valid precision: 0.867800, valid loss: 78.312202
epoch: 264, train precision: 0.995800, train loss: 9.966351, valid precision: 0.873400, valid loss: 79.400126
epoch: 265, train precision: 0.997022, train loss: 9.617180, valid precision: 0.872400, valid loss: 78.056065
epoch: 266, train precision: 0.995644, train loss: 10.122959, valid precision: 0.876000, valid loss: 77.740796
epoch: 267, train precision: 0.995800, train loss: 10.123853, valid precision: 0.869400, valid loss: 79.851243
epoch: 268, train precision: 0.997311, train loss: 9.601465, valid precision: 0.866800, valid loss: 77.888237
epoch: 269, train precision: 0.996711, train loss: 9.754814, valid precision: 0.869800, valid loss: 78.598114
epoch: 270, train precision: 0.995978, train loss: 9.975979, valid precision: 0.868800, valid loss: 78.931508
epoch: 271, train precision: 0.996378, train loss: 10.036546, valid precision: 0.871800, valid loss: 78.596607
epoch: 272, train precision: 0.997022, train loss: 9.752799, valid precision: 0.869000, valid loss: 79.218908
epoch: 273, train precision: 0.996067, train loss: 10.048137, valid precision: 0.868600, valid loss: 80.430381
epoch: 274, train precision: 0.996667, train loss: 9.817299, valid precision: 0.869400, valid loss: 78.028900
epoch: 275, train precision: 0.996244, train loss: 9.845062, valid precision: 0.868400, valid loss: 79.223402
epoch: 276, train precision: 0.995667, train loss: 10.143764, valid precision: 0.869000, valid loss: 79.081307
epoch: 277, train precision: 0.995778, train loss: 10.232056, valid precision: 0.873000, valid loss: 77.472169
epoch: 278, train precision: 0.997067, train loss: 9.758234, valid precision: 0.866000, valid loss: 79.727620
epoch: 279, train precision: 0.996711, train loss: 9.937326, valid precision: 0.867600, valid loss: 77.480557
epoch: 280, train precision: 0.996756, train loss: 9.876485, valid precision: 0.865000, valid loss: 78.901774
epoch: 281, train precision: 0.996089, train loss: 10.033035, valid precision: 0.867000, valid loss: 78.825090
epoch: 282, train precision: 0.996333, train loss: 9.973801, valid precision: 0.870200, valid loss: 76.872397
epoch: 283, train precision: 0.996600, train loss: 9.901202, valid precision: 0.870600, valid loss: 77.761185
epoch: 284, train precision: 0.996533, train loss: 9.976218, valid precision: 0.867400, valid loss: 79.687055
epoch: 285, train precision: 0.996289, train loss: 10.031634, valid precision: 0.870000, valid loss: 77.206108
epoch: 286, train precision: 0.996889, train loss: 9.955272, valid precision: 0.870400, valid loss: 77.128273
epoch: 287, train precision: 0.995933, train loss: 10.196328, valid precision: 0.866400, valid loss: 78.783165
epoch: 288, train precision: 0.996511, train loss: 10.074766, valid precision: 0.868400, valid loss: 79.601532
epoch: 289, train precision: 0.996844, train loss: 9.960316, valid precision: 0.871000, valid loss: 79.126118
epoch: 290, train precision: 0.996378, train loss: 10.139972, valid precision: 0.866800, valid loss: 79.826071
epoch: 291, train precision: 0.996333, train loss: 10.100384, valid precision: 0.864600, valid loss: 78.540442
epoch: 292, train precision: 0.997244, train loss: 9.834886, valid precision: 0.868000, valid loss: 78.319228
epoch: 293, train precision: 0.997000, train loss: 9.926170, valid precision: 0.870000, valid loss: 78.458681
epoch: 294, train precision: 0.995533, train loss: 10.324918, valid precision: 0.865000, valid loss: 78.845804
epoch: 295, train precision: 0.997222, train loss: 9.855493, valid precision: 0.863600, valid loss: 78.901004
epoch: 296, train precision: 0.996689, train loss: 10.059848, valid precision: 0.870800, valid loss: 75.916759
epoch: 297, train precision: 0.996244, train loss: 10.097521, valid precision: 0.866600, valid loss: 80.017680
epoch: 298, train precision: 0.996222, train loss: 10.162842, valid precision: 0.866000, valid loss: 80.905612
epoch: 299, train precision: 0.996200, train loss: 10.105697, valid precision: 0.869200, valid loss: 78.563683
epoch: 300, train precision: 0.995511, train loss: 10.392533, valid precision: 0.865600, valid loss: 81.615259
epoch: 301, train precision: 0.996267, train loss: 10.097467, valid precision: 0.866400, valid loss: 79.076674
epoch: 302, train precision: 0.996267, train loss: 10.144321, valid precision: 0.865000, valid loss: 80.017413
epoch: 303, train precision: 0.996600, train loss: 10.129952, valid precision: 0.869200, valid loss: 78.081176
epoch: 304, train precision: 0.997089, train loss: 9.952043, valid precision: 0.866800, valid loss: 78.413156
epoch: 305, train precision: 0.996067, train loss: 10.251673, valid precision: 0.867000, valid loss: 78.913109
epoch: 306, train precision: 0.997444, train loss: 9.946683, valid precision: 0.870200, valid loss: 76.629225
epoch: 307, train precision: 0.997022, train loss: 10.039409, valid precision: 0.872000, valid loss: 78.285569
epoch: 308, train precision: 0.996711, train loss: 10.016937, valid precision: 0.869400, valid loss: 76.899739
epoch: 309, train precision: 0.996800, train loss: 10.051467, valid precision: 0.871000, valid loss: 77.254511
epoch: 310, train precision: 0.996044, train loss: 10.258679, valid precision: 0.869800, valid loss: 78.324620
epoch: 311, train precision: 0.996867, train loss: 10.088226, valid precision: 0.868800, valid loss: 78.308715
epoch: 312, train precision: 0.997533, train loss: 9.884015, valid precision: 0.872400, valid loss: 77.444805
epoch: 313, train precision: 0.996467, train loss: 10.226569, valid precision: 0.868000, valid loss: 77.169481
epoch: 314, train precision: 0.997244, train loss: 9.974503, valid precision: 0.869800, valid loss: 76.929029
epoch: 315, train precision: 0.997844, train loss: 9.782958, valid precision: 0.867800, valid loss: 78.847248
epoch: 316, train precision: 0.996933, train loss: 10.051841, valid precision: 0.869000, valid loss: 79.190029
epoch: 317, train precision: 0.996600, train loss: 10.205415, valid precision: 0.866200, valid loss: 79.427821
epoch: 318, train precision: 0.997156, train loss: 10.035905, valid precision: 0.864400, valid loss: 80.787572
epoch: 319, train precision: 0.997289, train loss: 9.905899, valid precision: 0.869400, valid loss: 80.496350
epoch: 320, train precision: 0.996000, train loss: 10.412187, valid precision: 0.871000, valid loss: 79.655226
epoch: 321, train precision: 0.995978, train loss: 10.401656, valid precision: 0.871800, valid loss: 79.253630
epoch: 322, train precision: 0.997400, train loss: 9.927550, valid precision: 0.868000, valid loss: 78.686297
epoch: 323, train precision: 0.996489, train loss: 10.237125, valid precision: 0.875600, valid loss: 78.637286
epoch: 324, train precision: 0.996511, train loss: 10.210631, valid precision: 0.866000, valid loss: 81.455047
epoch: 325, train precision: 0.996644, train loss: 10.269640, valid precision: 0.863600, valid loss: 81.263501
epoch: 326, train precision: 0.997556, train loss: 9.997481, valid precision: 0.869800, valid loss: 80.658742
epoch: 327, train precision: 0.996200, train loss: 10.367195, valid precision: 0.868400, valid loss: 81.550968
epoch: 328, train precision: 0.996356, train loss: 10.196352, valid precision: 0.866400, valid loss: 80.738743
epoch: 329, train precision: 0.996400, train loss: 10.262272, valid precision: 0.864800, valid loss: 80.798061
epoch: 330, train precision: 0.996111, train loss: 10.432174, valid precision: 0.867400, valid loss: 81.881318
epoch: 331, train precision: 0.996778, train loss: 10.244848, valid precision: 0.870200, valid loss: 80.933013
epoch: 332, train precision: 0.996156, train loss: 10.523403, valid precision: 0.868600, valid loss: 82.750909
epoch: 333, train precision: 0.996600, train loss: 10.281926, valid precision: 0.870600, valid loss: 80.248978
epoch: 334, train precision: 0.996800, train loss: 10.241813, valid precision: 0.869200, valid loss: 79.644927
epoch: 335, train precision: 0.997511, train loss: 10.046467, valid precision: 0.870000, valid loss: 81.762227
epoch: 336, train precision: 0.997311, train loss: 10.080347, valid precision: 0.867000, valid loss: 82.217191
epoch: 337, train precision: 0.997133, train loss: 10.190154, valid precision: 0.862200, valid loss: 83.769448
epoch: 338, train precision: 0.997400, train loss: 10.050938, valid precision: 0.868800, valid loss: 80.915448
epoch: 339, train precision: 0.997600, train loss: 9.988896, valid precision: 0.870600, valid loss: 79.797315
epoch: 340, train precision: 0.997022, train loss: 10.179596, valid precision: 0.867800, valid loss: 82.230249
epoch: 341, train precision: 0.997556, train loss: 10.002426, valid precision: 0.868000, valid loss: 79.228323
epoch: 342, train precision: 0.997556, train loss: 10.099262, valid precision: 0.871800, valid loss: 79.208880
epoch: 343, train precision: 0.996000, train loss: 10.472512, valid precision: 0.867000, valid loss: 80.996403
epoch: 344, train precision: 0.996889, train loss: 10.201566, valid precision: 0.870600, valid loss: 79.740388
epoch: 345, train precision: 0.997444, train loss: 10.196862, valid precision: 0.866800, valid loss: 81.620246
epoch: 346, train precision: 0.996089, train loss: 10.454013, valid precision: 0.867400, valid loss: 81.137903
epoch: 347, train precision: 0.997556, train loss: 10.045109, valid precision: 0.869400, valid loss: 79.695630
epoch: 348, train precision: 0.996933, train loss: 10.305225, valid precision: 0.870800, valid loss: 80.605292
epoch: 349, train precision: 0.996311, train loss: 10.466926, valid precision: 0.864800, valid loss: 83.945738
epoch: 350, train precision: 0.997044, train loss: 10.207336, valid precision: 0.867400, valid loss: 81.149631
epoch: 351, train precision: 0.997356, train loss: 10.137895, valid precision: 0.870000, valid loss: 80.670557
epoch: 352, train precision: 0.997511, train loss: 10.051419, valid precision: 0.872200, valid loss: 80.264680
epoch: 353, train precision: 0.997356, train loss: 10.124818, valid precision: 0.873600, valid loss: 80.907352
epoch: 354, train precision: 0.997311, train loss: 10.226749, valid precision: 0.873600, valid loss: 82.373590
epoch: 355, train precision: 0.996133, train loss: 10.576578, valid precision: 0.867200, valid loss: 82.639721
epoch: 356, train precision: 0.996622, train loss: 10.256633, valid precision: 0.871000, valid loss: 81.522309
epoch: 357, train precision: 0.996889, train loss: 10.270677, valid precision: 0.870000, valid loss: 82.045999
epoch: 358, train precision: 0.997844, train loss: 9.967699, valid precision: 0.869000, valid loss: 80.861071
epoch: 359, train precision: 0.997600, train loss: 10.093194, valid precision: 0.873000, valid loss: 80.279244
epoch: 360, train precision: 0.996844, train loss: 10.233917, valid precision: 0.869600, valid loss: 80.951875
epoch: 361, train precision: 0.997222, train loss: 10.204137, valid precision: 0.866400, valid loss: 82.604042
epoch: 362, train precision: 0.996200, train loss: 10.566797, valid precision: 0.865200, valid loss: 85.170750
epoch: 363, train precision: 0.997133, train loss: 10.399044, valid precision: 0.866800, valid loss: 83.070105
epoch: 364, train precision: 0.996756, train loss: 10.332653, valid precision: 0.871400, valid loss: 81.471542
epoch: 365, train precision: 0.997244, train loss: 10.281318, valid precision: 0.870000, valid loss: 83.741069
epoch: 366, train precision: 0.996911, train loss: 10.319120, valid precision: 0.866600, valid loss: 83.976270
epoch: 367, train precision: 0.996933, train loss: 10.239493, valid precision: 0.870200, valid loss: 82.688001
epoch: 368, train precision: 0.995889, train loss: 10.664896, valid precision: 0.869200, valid loss: 83.126169
epoch: 369, train precision: 0.996422, train loss: 10.456959, valid precision: 0.865800, valid loss: 83.671681
epoch: 370, train precision: 0.998267, train loss: 10.002350, valid precision: 0.871200, valid loss: 81.404444
epoch: 371, train precision: 0.997289, train loss: 10.291558, valid precision: 0.870600, valid loss: 81.539939
epoch: 372, train precision: 0.998133, train loss: 10.019800, valid precision: 0.872600, valid loss: 80.463961
epoch: 373, train precision: 0.996800, train loss: 10.392720, valid precision: 0.867800, valid loss: 81.433505
epoch: 374, train precision: 0.996911, train loss: 10.364234, valid precision: 0.871000, valid loss: 81.258811
epoch: 375, train precision: 0.997822, train loss: 10.125259, valid precision: 0.873400, valid loss: 79.939376
epoch: 376, train precision: 0.996933, train loss: 10.389574, valid precision: 0.866400, valid loss: 82.645105
epoch: 377, train precision: 0.997311, train loss: 10.324883, valid precision: 0.870400, valid loss: 80.710446
epoch: 378, train precision: 0.997667, train loss: 10.226801, valid precision: 0.870200, valid loss: 81.630109
epoch: 379, train precision: 0.997444, train loss: 10.182856, valid precision: 0.869400, valid loss: 81.808957
epoch: 380, train precision: 0.997933, train loss: 10.157636, valid precision: 0.870400, valid loss: 81.697123
epoch: 381, train precision: 0.997356, train loss: 10.277837, valid precision: 0.872400, valid loss: 82.147093
epoch: 382, train precision: 0.997467, train loss: 10.328244, valid precision: 0.868600, valid loss: 82.378021
epoch: 383, train precision: 0.996822, train loss: 10.420152, valid precision: 0.869200, valid loss: 83.578580
epoch: 384, train precision: 0.996800, train loss: 10.418854, valid precision: 0.864200, valid loss: 83.212479
epoch: 385, train precision: 0.996844, train loss: 10.464686, valid precision: 0.869000, valid loss: 83.122938
epoch: 386, train precision: 0.997400, train loss: 10.263027, valid precision: 0.868400, valid loss: 83.801441
epoch: 387, train precision: 0.998200, train loss: 10.104324, valid precision: 0.871600, valid loss: 80.546650
epoch: 388, train precision: 0.997511, train loss: 10.329313, valid precision: 0.871400, valid loss: 81.475702
epoch: 389, train precision: 0.997756, train loss: 10.259670, valid precision: 0.873200, valid loss: 81.946646
epoch: 390, train precision: 0.996222, train loss: 10.768651, valid precision: 0.866400, valid loss: 85.073492
epoch: 391, train precision: 0.997022, train loss: 10.459077, valid precision: 0.873600, valid loss: 81.326227
epoch: 392, train precision: 0.997133, train loss: 10.448001, valid precision: 0.869400, valid loss: 83.098073
epoch: 393, train precision: 0.997400, train loss: 10.402209, valid precision: 0.869200, valid loss: 83.053360
epoch: 394, train precision: 0.997244, train loss: 10.359833, valid precision: 0.867600, valid loss: 84.478287
epoch: 395, train precision: 0.997578, train loss: 10.315735, valid precision: 0.872600, valid loss: 81.232283
epoch: 396, train precision: 0.997533, train loss: 10.308802, valid precision: 0.870400, valid loss: 81.651558
epoch: 397, train precision: 0.997422, train loss: 10.329472, valid precision: 0.872800, valid loss: 81.699107
epoch: 398, train precision: 0.997356, train loss: 10.387127, valid precision: 0.868400, valid loss: 81.776050
epoch: 399, train precision: 0.997067, train loss: 10.483575, valid precision: 0.871600, valid loss: 83.725432
epoch: 400, train precision: 0.997156, train loss: 10.305720, valid precision: 0.865800, valid loss: 82.534076
epoch: 401, train precision: 0.997444, train loss: 10.375264, valid precision: 0.870000, valid loss: 82.588291
epoch: 402, train precision: 0.997067, train loss: 10.285843, valid precision: 0.871000, valid loss: 82.801619
epoch: 403, train precision: 0.997844, train loss: 10.218674, valid precision: 0.864800, valid loss: 83.632127
epoch: 404, train precision: 0.997711, train loss: 10.258185, valid precision: 0.871800, valid loss: 80.961016
epoch: 405, train precision: 0.997511, train loss: 10.416942, valid precision: 0.871000, valid loss: 82.013171
epoch: 406, train precision: 0.996933, train loss: 10.564848, valid precision: 0.868800, valid loss: 81.664411
epoch: 407, train precision: 0.997800, train loss: 10.251023, valid precision: 0.871000, valid loss: 80.021976
epoch: 408, train precision: 0.997622, train loss: 10.319002, valid precision: 0.869200, valid loss: 81.125405
epoch: 409, train precision: 0.997156, train loss: 10.510002, valid precision: 0.872800, valid loss: 81.432597
epoch: 410, train precision: 0.997667, train loss: 10.353991, valid precision: 0.870400, valid loss: 78.967794
epoch: 411, train precision: 0.997156, train loss: 10.430114, valid precision: 0.869200, valid loss: 80.701958
epoch: 412, train precision: 0.997422, train loss: 10.326561, valid precision: 0.872000, valid loss: 81.305405
epoch: 413, train precision: 0.997444, train loss: 10.407436, valid precision: 0.871600, valid loss: 82.524900
epoch: 414, train precision: 0.997756, train loss: 10.285467, valid precision: 0.871200, valid loss: 80.932802
epoch: 415, train precision: 0.997622, train loss: 10.279707, valid precision: 0.872200, valid loss: 80.683146
epoch: 416, train precision: 0.996978, train loss: 10.500368, valid precision: 0.867600, valid loss: 82.335988
epoch: 417, train precision: 0.996822, train loss: 10.560155, valid precision: 0.872800, valid loss: 80.931334
epoch: 418, train precision: 0.997578, train loss: 10.334545, valid precision: 0.875800, valid loss: 79.694859
epoch: 419, train precision: 0.996800, train loss: 10.560266, valid precision: 0.868000, valid loss: 83.329002
epoch: 420, train precision: 0.997556, train loss: 10.369393, valid precision: 0.872600, valid loss: 81.473364
epoch: 421, train precision: 0.998289, train loss: 10.161742, valid precision: 0.873400, valid loss: 80.979993
epoch: 422, train precision: 0.997356, train loss: 10.442649, valid precision: 0.872000, valid loss: 80.797109
epoch: 423, train precision: 0.997978, train loss: 10.303908, valid precision: 0.871400, valid loss: 79.823192
epoch: 424, train precision: 0.997511, train loss: 10.358254, valid precision: 0.870600, valid loss: 81.520386
epoch: 425, train precision: 0.998000, train loss: 10.232461, valid precision: 0.873600, valid loss: 83.872938
epoch: 426, train precision: 0.997556, train loss: 10.393521, valid precision: 0.873800, valid loss: 82.286900
epoch: 427, train precision: 0.997333, train loss: 10.451451, valid precision: 0.869200, valid loss: 82.515713
epoch: 428, train precision: 0.997311, train loss: 10.489521, valid precision: 0.876200, valid loss: 81.890502
epoch: 429, train precision: 0.997311, train loss: 10.499692, valid precision: 0.869400, valid loss: 82.996156
epoch: 430, train precision: 0.997733, train loss: 10.332726, valid precision: 0.873800, valid loss: 82.873525
epoch: 431, train precision: 0.997711, train loss: 10.305711, valid precision: 0.871600, valid loss: 82.793889
epoch: 432, train precision: 0.997289, train loss: 10.504533, valid precision: 0.871000, valid loss: 84.307670
epoch: 433, train precision: 0.996889, train loss: 10.496939, valid precision: 0.870600, valid loss: 84.640294
epoch: 434, train precision: 0.997467, train loss: 10.431350, valid precision: 0.872600, valid loss: 83.669773
epoch: 435, train precision: 0.998089, train loss: 10.274668, valid precision: 0.873400, valid loss: 80.775049
epoch: 436, train precision: 0.997867, train loss: 10.376234, valid precision: 0.871200, valid loss: 82.633954
epoch: 437, train precision: 0.997156, train loss: 10.585770, valid precision: 0.871200, valid loss: 81.960243
epoch: 438, train precision: 0.997422, train loss: 10.462843, valid precision: 0.874200, valid loss: 83.584701
epoch: 439, train precision: 0.998244, train loss: 10.309228, valid precision: 0.872000, valid loss: 82.147200
epoch: 440, train precision: 0.997511, train loss: 10.466661, valid precision: 0.871200, valid loss: 82.990550
epoch: 441, train precision: 0.998489, train loss: 10.267319, valid precision: 0.872800, valid loss: 81.355906
epoch: 442, train precision: 0.997511, train loss: 10.557632, valid precision: 0.874800, valid loss: 81.589889
epoch: 443, train precision: 0.997378, train loss: 10.517432, valid precision: 0.872800, valid loss: 82.386267
epoch: 444, train precision: 0.997778, train loss: 10.416509, valid precision: 0.872600, valid loss: 82.354054
epoch: 445, train precision: 0.997667, train loss: 10.530046, valid precision: 0.872000, valid loss: 81.486902
epoch: 446, train precision: 0.996356, train loss: 10.899555, valid precision: 0.870200, valid loss: 84.945074
epoch: 447, train precision: 0.998311, train loss: 10.235251, valid precision: 0.870000, valid loss: 81.820487
epoch: 448, train precision: 0.997267, train loss: 10.596421, valid precision: 0.873600, valid loss: 81.498697
epoch: 449, train precision: 0.997533, train loss: 10.463772, valid precision: 0.877800, valid loss: 83.299457
epoch: 450, train precision: 0.997422, train loss: 10.549785, valid precision: 0.868800, valid loss: 82.878356
epoch: 451, train precision: 0.997178, train loss: 10.600316, valid precision: 0.867600, valid loss: 84.577739
epoch: 452, train precision: 0.997533, train loss: 10.509193, valid precision: 0.872000, valid loss: 83.296813
epoch: 453, train precision: 0.997933, train loss: 10.475148, valid precision: 0.871400, valid loss: 82.673546
epoch: 454, train precision: 0.997844, train loss: 10.405799, valid precision: 0.870600, valid loss: 84.468256
epoch: 455, train precision: 0.997667, train loss: 10.501477, valid precision: 0.870800, valid loss: 83.617719
epoch: 456, train precision: 0.997956, train loss: 10.403519, valid precision: 0.866400, valid loss: 83.346161
epoch: 457, train precision: 0.997778, train loss: 10.425009, valid precision: 0.871200, valid loss: 81.417442
epoch: 458, train precision: 0.997600, train loss: 10.470622, valid precision: 0.872600, valid loss: 82.238273
epoch: 459, train precision: 0.997911, train loss: 10.380298, valid precision: 0.869800, valid loss: 83.535689
epoch: 460, train precision: 0.997822, train loss: 10.415357, valid precision: 0.874600, valid loss: 82.381856
epoch: 461, train precision: 0.997311, train loss: 10.620150, valid precision: 0.867200, valid loss: 83.380084
epoch: 462, train precision: 0.997756, train loss: 10.439271, valid precision: 0.872400, valid loss: 81.477567
epoch: 463, train precision: 0.997733, train loss: 10.453386, valid precision: 0.872000, valid loss: 81.474474
epoch: 464, train precision: 0.997844, train loss: 10.461038, valid precision: 0.870800, valid loss: 83.785226
epoch: 465, train precision: 0.997422, train loss: 10.566082, valid precision: 0.873600, valid loss: 82.519939
epoch: 466, train precision: 0.997822, train loss: 10.491911, valid precision: 0.872000, valid loss: 83.860238
epoch: 467, train precision: 0.997689, train loss: 10.574970, valid precision: 0.865600, valid loss: 82.658713
epoch: 468, train precision: 0.998022, train loss: 10.458177, valid precision: 0.875200, valid loss: 79.885558
epoch: 469, train precision: 0.997756, train loss: 10.518076, valid precision: 0.870400, valid loss: 82.067452
epoch: 470, train precision: 0.997378, train loss: 10.658465, valid precision: 0.869400, valid loss: 81.762299
epoch: 471, train precision: 0.998022, train loss: 10.456698, valid precision: 0.868200, valid loss: 81.796406
epoch: 472, train precision: 0.997800, train loss: 10.459613, valid precision: 0.872400, valid loss: 82.181032
epoch: 473, train precision: 0.997644, train loss: 10.540280, valid precision: 0.869000, valid loss: 82.328144
epoch: 474, train precision: 0.997400, train loss: 10.705124, valid precision: 0.866000, valid loss: 83.780403
epoch: 475, train precision: 0.997689, train loss: 10.472784, valid precision: 0.868400, valid loss: 83.351293
epoch: 476, train precision: 0.998022, train loss: 10.533542, valid precision: 0.869400, valid loss: 84.858401
epoch: 477, train precision: 0.998044, train loss: 10.429349, valid precision: 0.868800, valid loss: 81.087685
epoch: 478, train precision: 0.998089, train loss: 10.390802, valid precision: 0.871600, valid loss: 81.703763
epoch: 479, train precision: 0.998111, train loss: 10.429850, valid precision: 0.872400, valid loss: 82.301461
epoch: 480, train precision: 0.997667, train loss: 10.557671, valid precision: 0.872200, valid loss: 81.271906
epoch: 481, train precision: 0.997711, train loss: 10.533442, valid precision: 0.872000, valid loss: 82.825760
epoch: 482, train precision: 0.997356, train loss: 10.623549, valid precision: 0.871600, valid loss: 82.040012
epoch: 483, train precision: 0.997822, train loss: 10.422045, valid precision: 0.872000, valid loss: 82.569009
epoch: 484, train precision: 0.997933, train loss: 10.506886, valid precision: 0.872400, valid loss: 82.044453
epoch: 485, train precision: 0.997444, train loss: 10.579582, valid precision: 0.871400, valid loss: 83.133572
epoch: 486, train precision: 0.998000, train loss: 10.494964, valid precision: 0.876000, valid loss: 81.127286
epoch: 487, train precision: 0.997644, train loss: 10.552140, valid precision: 0.874800, valid loss: 81.909485
epoch: 488, train precision: 0.998356, train loss: 10.422904, valid precision: 0.877000, valid loss: 81.123445
epoch: 489, train precision: 0.997578, train loss: 10.557081, valid precision: 0.873200, valid loss: 82.949138
epoch: 490, train precision: 0.997378, train loss: 10.620007, valid precision: 0.875400, valid loss: 84.007579
epoch: 491, train precision: 0.998311, train loss: 10.470248, valid precision: 0.869200, valid loss: 84.798148
epoch: 492, train precision: 0.997800, train loss: 10.490302, valid precision: 0.870000, valid loss: 81.461287
epoch: 493, train precision: 0.998111, train loss: 10.471722, valid precision: 0.872600, valid loss: 82.582192
epoch: 494, train precision: 0.997689, train loss: 10.487739, valid precision: 0.873800, valid loss: 83.617180
epoch: 495, train precision: 0.997533, train loss: 10.621755, valid precision: 0.875800, valid loss: 83.392709
epoch: 496, train precision: 0.997422, train loss: 10.739821, valid precision: 0.872400, valid loss: 82.998339
epoch: 497, train precision: 0.997533, train loss: 10.683635, valid precision: 0.872200, valid loss: 81.997808
epoch: 498, train precision: 0.998111, train loss: 10.536513, valid precision: 0.872600, valid loss: 83.113829
epoch: 499, train precision: 0.997333, train loss: 10.780039, valid precision: 0.875400, valid loss: 81.089518
epoch: 500, train precision: 0.997511, train loss: 10.591372, valid precision: 0.872400, valid loss: 84.035453
epoch: 501, train precision: 0.997578, train loss: 10.682139, valid precision: 0.871400, valid loss: 80.978436
epoch: 502, train precision: 0.997644, train loss: 10.615922, valid precision: 0.874200, valid loss: 82.823991
epoch: 503, train precision: 0.998222, train loss: 10.440548, valid precision: 0.873600, valid loss: 81.930462
epoch: 504, train precision: 0.997622, train loss: 10.504303, valid precision: 0.873800, valid loss: 83.089031
epoch: 505, train precision: 0.997467, train loss: 10.614277, valid precision: 0.868800, valid loss: 82.690100
epoch: 506, train precision: 0.997733, train loss: 10.601959, valid precision: 0.869000, valid loss: 81.969995
epoch: 507, train precision: 0.997956, train loss: 10.457834, valid precision: 0.866600, valid loss: 84.448728
epoch: 508, train precision: 0.997311, train loss: 10.775356, valid precision: 0.869200, valid loss: 83.293664
epoch: 509, train precision: 0.997556, train loss: 10.652951, valid precision: 0.870800, valid loss: 83.664825
epoch: 510, train precision: 0.997911, train loss: 10.535360, valid precision: 0.869800, valid loss: 82.849357
epoch: 511, train precision: 0.998267, train loss: 10.447349, valid precision: 0.865200, valid loss: 83.058059
epoch: 512, train precision: 0.998533, train loss: 10.417454, valid precision: 0.875600, valid loss: 82.678907
epoch: 513, train precision: 0.998178, train loss: 10.505131, valid precision: 0.871200, valid loss: 81.361984
epoch: 514, train precision: 0.997089, train loss: 10.762903, valid precision: 0.869800, valid loss: 84.594287
epoch: 515, train precision: 0.997711, train loss: 10.656392, valid precision: 0.867400, valid loss: 83.726075
epoch: 516, train precision: 0.998089, train loss: 10.531148, valid precision: 0.873200, valid loss: 83.640633
epoch: 517, train precision: 0.997356, train loss: 10.676317, valid precision: 0.874800, valid loss: 83.076441
epoch: 518, train precision: 0.997533, train loss: 10.588289, valid precision: 0.872600, valid loss: 81.739383
epoch: 519, train precision: 0.998511, train loss: 10.360518, valid precision: 0.876200, valid loss: 80.723903
epoch: 520, train precision: 0.998022, train loss: 10.535420, valid precision: 0.873400, valid loss: 81.767171
epoch: 521, train precision: 0.998378, train loss: 10.412466, valid precision: 0.874400, valid loss: 81.719743
epoch: 522, train precision: 0.998178, train loss: 10.410492, valid precision: 0.873000, valid loss: 84.198024
epoch: 523, train precision: 0.997822, train loss: 10.599057, valid precision: 0.872000, valid loss: 81.464767
epoch: 524, train precision: 0.998133, train loss: 10.579348, valid precision: 0.868400, valid loss: 82.583487
epoch: 525, train precision: 0.997911, train loss: 10.598149, valid precision: 0.869800, valid loss: 84.244827
epoch: 526, train precision: 0.997556, train loss: 10.718721, valid precision: 0.871800, valid loss: 83.968931
epoch: 527, train precision: 0.998244, train loss: 10.532243, valid precision: 0.870400, valid loss: 82.758554
epoch: 528, train precision: 0.998133, train loss: 10.475612, valid precision: 0.874000, valid loss: 83.501624
epoch: 529, train precision: 0.997911, train loss: 10.547222, valid precision: 0.871200, valid loss: 83.335309
epoch: 530, train precision: 0.997933, train loss: 10.618099, valid precision: 0.872800, valid loss: 83.517561
epoch: 531, train precision: 0.997422, train loss: 10.723305, valid precision: 0.877000, valid loss: 84.334516
epoch: 532, train precision: 0.998467, train loss: 10.443434, valid precision: 0.875600, valid loss: 80.828193
epoch: 533, train precision: 0.998067, train loss: 10.563514, valid precision: 0.871200, valid loss: 83.877703
epoch: 534, train precision: 0.998622, train loss: 10.364232, valid precision: 0.878200, valid loss: 82.995276
epoch: 535, train precision: 0.998356, train loss: 10.551456, valid precision: 0.870200, valid loss: 84.321705
epoch: 536, train precision: 0.997911, train loss: 10.635022, valid precision: 0.876600, valid loss: 83.665549
epoch: 537, train precision: 0.997200, train loss: 10.771690, valid precision: 0.866000, valid loss: 85.012006
epoch: 538, train precision: 0.998244, train loss: 10.427394, valid precision: 0.873200, valid loss: 82.690570
epoch: 539, train precision: 0.998044, train loss: 10.644731, valid precision: 0.874600, valid loss: 82.396500
epoch: 540, train precision: 0.998289, train loss: 10.516183, valid precision: 0.872600, valid loss: 81.792346
epoch: 541, train precision: 0.998467, train loss: 10.500657, valid precision: 0.872600, valid loss: 82.147584
epoch: 542, train precision: 0.997644, train loss: 10.756000, valid precision: 0.869000, valid loss: 82.891022
epoch: 543, train precision: 0.998000, train loss: 10.582327, valid precision: 0.873800, valid loss: 81.235596
epoch: 544, train precision: 0.998156, train loss: 10.628539, valid precision: 0.871400, valid loss: 82.437675
epoch: 545, train precision: 0.997222, train loss: 10.857956, valid precision: 0.873400, valid loss: 83.583411
epoch: 546, train precision: 0.997733, train loss: 10.621534, valid precision: 0.870800, valid loss: 83.281746
epoch: 547, train precision: 0.997489, train loss: 10.756554, valid precision: 0.872600, valid loss: 81.506870
epoch: 548, train precision: 0.998133, train loss: 10.603562, valid precision: 0.875400, valid loss: 83.134093
epoch: 549, train precision: 0.998778, train loss: 10.368266, valid precision: 0.876800, valid loss: 80.396978
epoch: 550, train precision: 0.997578, train loss: 10.787648, valid precision: 0.872000, valid loss: 84.207924
epoch: 551, train precision: 0.997867, train loss: 10.672765, valid precision: 0.873600, valid loss: 82.196275
epoch: 552, train precision: 0.997800, train loss: 10.677050, valid precision: 0.868600, valid loss: 83.320854
epoch: 553, train precision: 0.997156, train loss: 10.900975, valid precision: 0.872800, valid loss: 84.830062
epoch: 554, train precision: 0.998289, train loss: 10.519387, valid precision: 0.874800, valid loss: 81.581254
epoch: 555, train precision: 0.998044, train loss: 10.585766, valid precision: 0.871400, valid loss: 83.999120
epoch: 556, train precision: 0.998289, train loss: 10.594714, valid precision: 0.874600, valid loss: 84.025524
epoch: 557, train precision: 0.998489, train loss: 10.523476, valid precision: 0.873400, valid loss: 85.095266
epoch: 558, train precision: 0.997889, train loss: 10.618601, valid precision: 0.873000, valid loss: 82.978303
epoch: 559, train precision: 0.997933, train loss: 10.626144, valid precision: 0.870600, valid loss: 82.619776
epoch: 560, train precision: 0.998022, train loss: 10.664105, valid precision: 0.873400, valid loss: 83.173043
epoch: 561, train precision: 0.998222, train loss: 10.537463, valid precision: 0.873800, valid loss: 81.503129
epoch: 562, train precision: 0.998400, train loss: 10.504413, valid precision: 0.874600, valid loss: 81.281417
epoch: 563, train precision: 0.998444, train loss: 10.436143, valid precision: 0.876600, valid loss: 83.110359
epoch: 564, train precision: 0.998000, train loss: 10.567082, valid precision: 0.876200, valid loss: 81.280998
epoch: 565, train precision: 0.998022, train loss: 10.580355, valid precision: 0.876200, valid loss: 81.297753
epoch: 566, train precision: 0.997800, train loss: 10.672182, valid precision: 0.872000, valid loss: 81.853075
epoch: 567, train precision: 0.998311, train loss: 10.600713, valid precision: 0.874000, valid loss: 82.778298
epoch: 568, train precision: 0.998156, train loss: 10.559267, valid precision: 0.872600, valid loss: 84.426035
epoch: 569, train precision: 0.997867, train loss: 10.635773, valid precision: 0.877400, valid loss: 81.810793
epoch: 570, train precision: 0.998311, train loss: 10.497221, valid precision: 0.874400, valid loss: 81.354430
epoch: 571, train precision: 0.998333, train loss: 10.633396, valid precision: 0.873000, valid loss: 83.033397
epoch: 572, train precision: 0.998200, train loss: 10.592403, valid precision: 0.880000, valid loss: 80.836154
epoch: 573, train precision: 0.998289, train loss: 10.518059, valid precision: 0.870800, valid loss: 84.547079
epoch: 574, train precision: 0.998022, train loss: 10.628757, valid precision: 0.871600, valid loss: 83.359662
epoch: 575, train precision: 0.997800, train loss: 10.677184, valid precision: 0.872400, valid loss: 82.275309
epoch: 576, train precision: 0.997756, train loss: 10.717300, valid precision: 0.869000, valid loss: 84.346077
epoch: 577, train precision: 0.998044, train loss: 10.625275, valid precision: 0.873000, valid loss: 82.974816
epoch: 578, train precision: 0.998222, train loss: 10.543884, valid precision: 0.876000, valid loss: 82.443879
epoch: 579, train precision: 0.996978, train loss: 10.959929, valid precision: 0.873600, valid loss: 86.100084
epoch: 580, train precision: 0.998311, train loss: 10.598790, valid precision: 0.872600, valid loss: 83.206280
epoch: 581, train precision: 0.998089, train loss: 10.597680, valid precision: 0.877000, valid loss: 83.669018
epoch: 582, train precision: 0.997933, train loss: 10.721998, valid precision: 0.876000, valid loss: 83.627600
epoch: 583, train precision: 0.997489, train loss: 10.857203, valid precision: 0.873200, valid loss: 82.699389
epoch: 584, train precision: 0.998200, train loss: 10.561700, valid precision: 0.875000, valid loss: 81.133057
epoch: 585, train precision: 0.998422, train loss: 10.519812, valid precision: 0.877600, valid loss: 81.290597
epoch: 586, train precision: 0.998133, train loss: 10.675218, valid precision: 0.876400, valid loss: 81.444246
epoch: 587, train precision: 0.997511, train loss: 10.860771, valid precision: 0.872600, valid loss: 82.770438
epoch: 588, train precision: 0.997911, train loss: 10.734857, valid precision: 0.877800, valid loss: 82.554270
epoch: 589, train precision: 0.998578, train loss: 10.471301, valid precision: 0.879000, valid loss: 81.409777
epoch: 590, train precision: 0.998267, train loss: 10.615726, valid precision: 0.874400, valid loss: 83.434454
epoch: 591, train precision: 0.998244, train loss: 10.685522, valid precision: 0.869800, valid loss: 82.252237
epoch: 592, train precision: 0.998378, train loss: 10.562051, valid precision: 0.875800, valid loss: 81.858167
epoch: 593, train precision: 0.998400, train loss: 10.575990, valid precision: 0.873400, valid loss: 82.245827
epoch: 594, train precision: 0.998311, train loss: 10.559709, valid precision: 0.876600, valid loss: 80.050009
epoch: 595, train precision: 0.997600, train loss: 10.800903, valid precision: 0.876200, valid loss: 82.984498
epoch: 596, train precision: 0.998333, train loss: 10.642783, valid precision: 0.868800, valid loss: 85.047262
epoch: 597, train precision: 0.998556, train loss: 10.542723, valid precision: 0.874400, valid loss: 83.194895
epoch: 598, train precision: 0.998089, train loss: 10.649251, valid precision: 0.873600, valid loss: 81.783918
epoch: 599, train precision: 0.997689, train loss: 10.731166, valid precision: 0.875200, valid loss: 82.340708
epoch: 600, train precision: 0.997156, train loss: 10.918592, valid precision: 0.868400, valid loss: 87.321567
epoch: 601, train precision: 0.998467, train loss: 10.584139, valid precision: 0.875200, valid loss: 83.263222
epoch: 602, train precision: 0.998067, train loss: 10.621274, valid precision: 0.873800, valid loss: 81.708493
epoch: 603, train precision: 0.998022, train loss: 10.618054, valid precision: 0.871400, valid loss: 84.084888
epoch: 604, train precision: 0.997978, train loss: 10.718955, valid precision: 0.875400, valid loss: 82.964693
epoch: 605, train precision: 0.997978, train loss: 10.743297, valid precision: 0.873000, valid loss: 83.028360
epoch: 606, train precision: 0.998667, train loss: 10.465584, valid precision: 0.874000, valid loss: 83.132090
epoch: 607, train precision: 0.998356, train loss: 10.571880, valid precision: 0.874000, valid loss: 83.427634
epoch: 608, train precision: 0.998111, train loss: 10.783847, valid precision: 0.878800, valid loss: 81.089969
epoch: 609, train precision: 0.998067, train loss: 10.667086, valid precision: 0.874600, valid loss: 83.805542
epoch: 610, train precision: 0.997711, train loss: 10.840873, valid precision: 0.874200, valid loss: 84.703680
epoch: 611, train precision: 0.998289, train loss: 10.616417, valid precision: 0.877600, valid loss: 82.092281
epoch: 612, train precision: 0.998756, train loss: 10.487972, valid precision: 0.874200, valid loss: 83.041758
epoch: 613, train precision: 0.998311, train loss: 10.648649, valid precision: 0.871200, valid loss: 82.558511
epoch: 614, train precision: 0.997733, train loss: 10.770045, valid precision: 0.873200, valid loss: 82.958303
epoch: 615, train precision: 0.997600, train loss: 10.804016, valid precision: 0.870200, valid loss: 86.508179
epoch: 616, train precision: 0.997778, train loss: 10.714530, valid precision: 0.875600, valid loss: 82.883996
epoch: 617, train precision: 0.997822, train loss: 10.825115, valid precision: 0.874800, valid loss: 84.801418
epoch: 618, train precision: 0.998400, train loss: 10.593014, valid precision: 0.875000, valid loss: 83.009208
epoch: 619, train precision: 0.998111, train loss: 10.644010, valid precision: 0.871400, valid loss: 84.247625
epoch: 620, train precision: 0.998444, train loss: 10.562613, valid precision: 0.874600, valid loss: 84.356120
epoch: 621, train precision: 0.998378, train loss: 10.546011, valid precision: 0.877800, valid loss: 82.025121
epoch: 622, train precision: 0.998222, train loss: 10.644751, valid precision: 0.875000, valid loss: 84.143267
epoch: 623, train precision: 0.998378, train loss: 10.608794, valid precision: 0.876400, valid loss: 83.623620
epoch: 624, train precision: 0.998511, train loss: 10.562708, valid precision: 0.874000, valid loss: 83.406970
epoch: 625, train precision: 0.998333, train loss: 10.552291, valid precision: 0.875800, valid loss: 82.114757
epoch: 626, train precision: 0.998422, train loss: 10.576512, valid precision: 0.874800, valid loss: 84.658661
epoch: 627, train precision: 0.998311, train loss: 10.602805, valid precision: 0.876800, valid loss: 83.756372
epoch: 628, train precision: 0.998333, train loss: 10.646588, valid precision: 0.877200, valid loss: 83.605308
epoch: 629, train precision: 0.998222, train loss: 10.687546, valid precision: 0.875600, valid loss: 84.282569
epoch: 630, train precision: 0.998356, train loss: 10.663768, valid precision: 0.876000, valid loss: 82.855633
epoch: 631, train precision: 0.997689, train loss: 10.803155, valid precision: 0.877000, valid loss: 84.848410
epoch: 632, train precision: 0.997844, train loss: 10.740649, valid precision: 0.875600, valid loss: 85.191430
epoch: 633, train precision: 0.998578, train loss: 10.578595, valid precision: 0.873000, valid loss: 83.851031
epoch: 634, train precision: 0.997711, train loss: 10.857465, valid precision: 0.874000, valid loss: 85.892493
epoch: 635, train precision: 0.998311, train loss: 10.660821, valid precision: 0.876800, valid loss: 84.250947
epoch: 636, train precision: 0.997600, train loss: 10.872877, valid precision: 0.872800, valid loss: 84.764389
epoch: 637, train precision: 0.998133, train loss: 10.611879, valid precision: 0.876000, valid loss: 83.623901
epoch: 638, train precision: 0.998378, train loss: 10.631176, valid precision: 0.876600, valid loss: 83.977668
epoch: 639, train precision: 0.998444, train loss: 10.626084, valid precision: 0.879400, valid loss: 84.250052
epoch: 640, train precision: 0.998289, train loss: 10.653587, valid precision: 0.874600, valid loss: 83.661579
epoch: 641, train precision: 0.998667, train loss: 10.469193, valid precision: 0.876800, valid loss: 83.551202
epoch: 642, train precision: 0.998311, train loss: 10.673060, valid precision: 0.874400, valid loss: 86.783299
epoch: 643, train precision: 0.997733, train loss: 10.778000, valid precision: 0.871800, valid loss: 86.001091
epoch: 644, train precision: 0.998933, train loss: 10.533126, valid precision: 0.876800, valid loss: 84.054110
epoch: 645, train precision: 0.998178, train loss: 10.749484, valid precision: 0.876200, valid loss: 83.971042
epoch: 646, train precision: 0.998444, train loss: 10.710437, valid precision: 0.877000, valid loss: 82.763116
epoch: 647, train precision: 0.997956, train loss: 10.675802, valid precision: 0.872200, valid loss: 86.566251
epoch: 648, train precision: 0.998178, train loss: 10.731968, valid precision: 0.876000, valid loss: 83.199251
epoch: 649, train precision: 0.998400, train loss: 10.606865, valid precision: 0.874400, valid loss: 82.377307
epoch: 650, train precision: 0.997911, train loss: 10.804787, valid precision: 0.874600, valid loss: 86.218913
epoch: 651, train precision: 0.998644, train loss: 10.645925, valid precision: 0.877000, valid loss: 84.066568
epoch: 652, train precision: 0.998356, train loss: 10.708124, valid precision: 0.868800, valid loss: 86.179789
epoch: 653, train precision: 0.998778, train loss: 10.544539, valid precision: 0.878000, valid loss: 81.800185
epoch: 654, train precision: 0.998822, train loss: 10.544171, valid precision: 0.873600, valid loss: 83.279067
epoch: 655, train precision: 0.998156, train loss: 10.677036, valid precision: 0.877400, valid loss: 83.111549
epoch: 656, train precision: 0.998400, train loss: 10.614982, valid precision: 0.874200, valid loss: 83.451080
epoch: 657, train precision: 0.998289, train loss: 10.635838, valid precision: 0.877000, valid loss: 82.587332
epoch: 658, train precision: 0.998933, train loss: 10.482749, valid precision: 0.875200, valid loss: 83.051632
epoch: 659, train precision: 0.998422, train loss: 10.610168, valid precision: 0.877200, valid loss: 83.063342
epoch: 660, train precision: 0.997422, train loss: 10.944184, valid precision: 0.875600, valid loss: 83.958068
epoch: 661, train precision: 0.998333, train loss: 10.713698, valid precision: 0.874000, valid loss: 83.620760
epoch: 662, train precision: 0.997978, train loss: 10.802946, valid precision: 0.876800, valid loss: 85.608964
epoch: 663, train precision: 0.998511, train loss: 10.607172, valid precision: 0.877400, valid loss: 84.182853
epoch: 664, train precision: 0.998267, train loss: 10.686814, valid precision: 0.876200, valid loss: 85.763282
epoch: 665, train precision: 0.997644, train loss: 10.894557, valid precision: 0.875400, valid loss: 86.484635
epoch: 666, train precision: 0.998556, train loss: 10.599976, valid precision: 0.877800, valid loss: 85.633284
epoch: 667, train precision: 0.998556, train loss: 10.636740, valid precision: 0.873800, valid loss: 85.372337
epoch: 668, train precision: 0.997867, train loss: 10.834166, valid precision: 0.871200, valid loss: 87.202183
epoch: 669, train precision: 0.998333, train loss: 10.634422, valid precision: 0.874000, valid loss: 85.454296
epoch: 670, train precision: 0.997578, train loss: 10.918252, valid precision: 0.872400, valid loss: 85.990156
epoch: 671, train precision: 0.998644, train loss: 10.600848, valid precision: 0.874000, valid loss: 85.629676
epoch: 672, train precision: 0.998444, train loss: 10.578409, valid precision: 0.872000, valid loss: 86.060937
epoch: 673, train precision: 0.997822, train loss: 10.810413, valid precision: 0.873400, valid loss: 85.826562
epoch: 674, train precision: 0.998644, train loss: 10.652189, valid precision: 0.872000, valid loss: 83.891457
epoch: 675, train precision: 0.998867, train loss: 10.544439, valid precision: 0.872600, valid loss: 84.308411
epoch: 676, train precision: 0.997933, train loss: 10.766916, valid precision: 0.873600, valid loss: 85.709636
epoch: 677, train precision: 0.997956, train loss: 10.710868, valid precision: 0.875800, valid loss: 86.054596
epoch: 678, train precision: 0.998667, train loss: 10.628924, valid precision: 0.877400, valid loss: 85.516533
epoch: 679, train precision: 0.998356, train loss: 10.713711, valid precision: 0.875600, valid loss: 85.377003
epoch: 680, train precision: 0.998644, train loss: 10.585639, valid precision: 0.875600, valid loss: 84.523351
epoch: 681, train precision: 0.997889, train loss: 10.808552, valid precision: 0.873800, valid loss: 85.358781
epoch: 682, train precision: 0.998600, train loss: 10.628323, valid precision: 0.878600, valid loss: 84.636285
epoch: 683, train precision: 0.998244, train loss: 10.727884, valid precision: 0.877000, valid loss: 86.096622
epoch: 684, train precision: 0.998489, train loss: 10.700141, valid precision: 0.873400, valid loss: 84.062301
epoch: 685, train precision: 0.998489, train loss: 10.621623, valid precision: 0.875000, valid loss: 84.995561
epoch: 686, train precision: 0.998244, train loss: 10.682084, valid precision: 0.880400, valid loss: 84.983350
epoch: 687, train precision: 0.997911, train loss: 10.816715, valid precision: 0.878200, valid loss: 82.340993
epoch: 688, train precision: 0.998156, train loss: 10.744558, valid precision: 0.878000, valid loss: 83.640564
epoch: 689, train precision: 0.998178, train loss: 10.722664, valid precision: 0.880000, valid loss: 82.785224
epoch: 690, train precision: 0.998578, train loss: 10.627446, valid precision: 0.878400, valid loss: 83.431028
epoch: 691, train precision: 0.998356, train loss: 10.711689, valid precision: 0.874800, valid loss: 84.034648
epoch: 692, train precision: 0.998222, train loss: 10.736319, valid precision: 0.877600, valid loss: 83.401097
epoch: 693, train precision: 0.998711, train loss: 10.626332, valid precision: 0.878400, valid loss: 83.745321
epoch: 694, train precision: 0.998489, train loss: 10.651868, valid precision: 0.877600, valid loss: 83.599645
epoch: 695, train precision: 0.998444, train loss: 10.677372, valid precision: 0.877800, valid loss: 82.609935
epoch: 696, train precision: 0.998311, train loss: 10.740352, valid precision: 0.879600, valid loss: 82.699165
epoch: 697, train precision: 0.998289, train loss: 10.701191, valid precision: 0.874400, valid loss: 84.100098
epoch: 698, train precision: 0.998400, train loss: 10.727758, valid precision: 0.875600, valid loss: 83.419914
epoch: 699, train precision: 0.998400, train loss: 10.724475, valid precision: 0.872600, valid loss: 85.353598
epoch: 700, train precision: 0.998578, train loss: 10.706614, valid precision: 0.878800, valid loss: 84.969426
epoch: 701, train precision: 0.998644, train loss: 10.599296, valid precision: 0.878200, valid loss: 84.014501
epoch: 702, train precision: 0.998200, train loss: 10.694126, valid precision: 0.875800, valid loss: 85.229436
epoch: 703, train precision: 0.997867, train loss: 10.803542, valid precision: 0.874400, valid loss: 85.681896
epoch: 704, train precision: 0.998422, train loss: 10.686006, valid precision: 0.877400, valid loss: 84.256864
epoch: 705, train precision: 0.998578, train loss: 10.685265, valid precision: 0.874600, valid loss: 85.131598
epoch: 706, train precision: 0.998244, train loss: 10.675499, valid precision: 0.882800, valid loss: 85.786116
epoch: 707, train precision: 0.998089, train loss: 10.755384, valid precision: 0.876000, valid loss: 82.704581
epoch: 708, train precision: 0.998800, train loss: 10.600529, valid precision: 0.876800, valid loss: 85.636070
epoch: 709, train precision: 0.998556, train loss: 10.571374, valid precision: 0.876400, valid loss: 84.819151
epoch: 710, train precision: 0.998356, train loss: 10.711174, valid precision: 0.876000, valid loss: 83.883109
epoch: 711, train precision: 0.998133, train loss: 10.757115, valid precision: 0.877000, valid loss: 84.508375
epoch: 712, train precision: 0.997956, train loss: 10.792186, valid precision: 0.876800, valid loss: 85.865602
epoch: 713, train precision: 0.998711, train loss: 10.559693, valid precision: 0.875000, valid loss: 84.069981
epoch: 714, train precision: 0.998378, train loss: 10.687607, valid precision: 0.878600, valid loss: 83.457866
epoch: 715, train precision: 0.998333, train loss: 10.791688, valid precision: 0.874200, valid loss: 82.637947
epoch: 716, train precision: 0.998511, train loss: 10.676188, valid precision: 0.874800, valid loss: 82.888932
epoch: 717, train precision: 0.997867, train loss: 10.837525, valid precision: 0.872800, valid loss: 85.135383
epoch: 718, train precision: 0.998756, train loss: 10.698400, valid precision: 0.872800, valid loss: 82.785365
epoch: 719, train precision: 0.998533, train loss: 10.694238, valid precision: 0.872600, valid loss: 84.194417
epoch: 720, train precision: 0.998044, train loss: 10.832854, valid precision: 0.876000, valid loss: 85.076360
epoch: 721, train precision: 0.998556, train loss: 10.643595, valid precision: 0.877600, valid loss: 86.154799
epoch: 722, train precision: 0.998644, train loss: 10.627717, valid precision: 0.876600, valid loss: 85.447462
epoch: 723, train precision: 0.998800, train loss: 10.594179, valid precision: 0.876800, valid loss: 86.248864
epoch: 724, train precision: 0.998578, train loss: 10.750001, valid precision: 0.874400, valid loss: 85.742088
epoch: 725, train precision: 0.998178, train loss: 10.774101, valid precision: 0.877800, valid loss: 84.332647
epoch: 726, train precision: 0.998178, train loss: 10.785735, valid precision: 0.869200, valid loss: 88.801551
epoch: 727, train precision: 0.998778, train loss: 10.632004, valid precision: 0.873600, valid loss: 87.185721
epoch: 728, train precision: 0.998444, train loss: 10.712342, valid precision: 0.874200, valid loss: 86.253190
epoch: 729, train precision: 0.997956, train loss: 10.868613, valid precision: 0.872000, valid loss: 87.512273
epoch: 730, train precision: 0.998178, train loss: 10.856673, valid precision: 0.873400, valid loss: 86.277939
epoch: 731, train precision: 0.997933, train loss: 10.842223, valid precision: 0.869200, valid loss: 86.318125
epoch: 732, train precision: 0.998933, train loss: 10.561728, valid precision: 0.874600, valid loss: 83.114776
epoch: 733, train precision: 0.998311, train loss: 10.757389, valid precision: 0.878600, valid loss: 85.137074
epoch: 734, train precision: 0.997667, train loss: 10.851902, valid precision: 0.871800, valid loss: 86.528826
epoch: 735, train precision: 0.998378, train loss: 10.691869, valid precision: 0.872400, valid loss: 85.567678
epoch: 736, train precision: 0.998578, train loss: 10.706198, valid precision: 0.873200, valid loss: 84.778748
epoch: 737, train precision: 0.998689, train loss: 10.641003, valid precision: 0.876400, valid loss: 85.943912
epoch: 738, train precision: 0.998067, train loss: 10.769446, valid precision: 0.871200, valid loss: 86.395817
epoch: 739, train precision: 0.998511, train loss: 10.719074, valid precision: 0.867200, valid loss: 86.940598
epoch: 740, train precision: 0.998467, train loss: 10.716002, valid precision: 0.869200, valid loss: 86.004740
epoch: 741, train precision: 0.998222, train loss: 10.782034, valid precision: 0.872400, valid loss: 85.991360
epoch: 742, train precision: 0.998400, train loss: 10.698723, valid precision: 0.870800, valid loss: 85.937120
epoch: 743, train precision: 0.998378, train loss: 10.647877, valid precision: 0.871600, valid loss: 84.928355
epoch: 744, train precision: 0.998267, train loss: 10.717544, valid precision: 0.879200, valid loss: 84.161270
epoch: 745, train precision: 0.998200, train loss: 10.812019, valid precision: 0.875400, valid loss: 83.612982
epoch: 746, train precision: 0.997911, train loss: 10.865044, valid precision: 0.875000, valid loss: 85.970967
epoch: 747, train precision: 0.998778, train loss: 10.639452, valid precision: 0.875400, valid loss: 84.809160
epoch: 748, train precision: 0.998844, train loss: 10.621018, valid precision: 0.877200, valid loss: 84.694923
epoch: 749, train precision: 0.998911, train loss: 10.538855, valid precision: 0.873400, valid loss: 86.935738
epoch: 750, train precision: 0.998400, train loss: 10.723089, valid precision: 0.878200, valid loss: 86.474634
epoch: 751, train precision: 0.998067, train loss: 10.835412, valid precision: 0.871200, valid loss: 90.605980
epoch: 752, train precision: 0.998511, train loss: 10.655953, valid precision: 0.873800, valid loss: 88.590157
epoch: 753, train precision: 0.998378, train loss: 10.711757, valid precision: 0.873800, valid loss: 87.124303
epoch: 754, train precision: 0.998022, train loss: 10.730270, valid precision: 0.874800, valid loss: 87.544123
epoch: 755, train precision: 0.998244, train loss: 10.817102, valid precision: 0.873800, valid loss: 88.280490
epoch: 756, train precision: 0.998489, train loss: 10.751637, valid precision: 0.871200, valid loss: 86.786912
epoch: 757, train precision: 0.998489, train loss: 10.773994, valid precision: 0.871400, valid loss: 88.660235
epoch: 758, train precision: 0.997533, train loss: 11.001096, valid precision: 0.870600, valid loss: 88.200999
epoch: 759, train precision: 0.998044, train loss: 10.783482, valid precision: 0.870800, valid loss: 87.229150
epoch: 760, train precision: 0.998578, train loss: 10.715766, valid precision: 0.877400, valid loss: 86.714889
epoch: 761, train precision: 0.998533, train loss: 10.769036, valid precision: 0.873000, valid loss: 86.838817
epoch: 762, train precision: 0.998644, train loss: 10.663548, valid precision: 0.876800, valid loss: 87.837242
epoch: 763, train precision: 0.998644, train loss: 10.670521, valid precision: 0.870400, valid loss: 86.626666
epoch: 764, train precision: 0.998333, train loss: 10.754992, valid precision: 0.872200, valid loss: 85.970499
epoch: 765, train precision: 0.998222, train loss: 10.842855, valid precision: 0.875000, valid loss: 84.238886
epoch: 766, train precision: 0.998400, train loss: 10.745764, valid precision: 0.873400, valid loss: 85.992463
epoch: 767, train precision: 0.998956, train loss: 10.590790, valid precision: 0.873800, valid loss: 87.412505
epoch: 768, train precision: 0.998467, train loss: 10.690031, valid precision: 0.876400, valid loss: 85.809986
epoch: 769, train precision: 0.998133, train loss: 10.844198, valid precision: 0.877000, valid loss: 85.909163
epoch: 770, train precision: 0.998422, train loss: 10.690487, valid precision: 0.879600, valid loss: 84.066775
epoch: 771, train precision: 0.998289, train loss: 10.848077, valid precision: 0.878600, valid loss: 85.643485
epoch: 772, train precision: 0.998422, train loss: 10.740297, valid precision: 0.880000, valid loss: 84.229115
epoch: 773, train precision: 0.998489, train loss: 10.722820, valid precision: 0.877000, valid loss: 85.992570
epoch: 774, train precision: 0.998622, train loss: 10.716677, valid precision: 0.877000, valid loss: 83.720635
epoch: 775, train precision: 0.998422, train loss: 10.727547, valid precision: 0.870800, valid loss: 86.437782
epoch: 776, train precision: 0.998844, train loss: 10.639961, valid precision: 0.875800, valid loss: 85.668009
epoch: 777, train precision: 0.998556, train loss: 10.703127, valid precision: 0.875400, valid loss: 84.402159
epoch: 778, train precision: 0.998689, train loss: 10.579102, valid precision: 0.876400, valid loss: 86.362796
epoch: 779, train precision: 0.998689, train loss: 10.731079, valid precision: 0.872800, valid loss: 89.453441
epoch: 780, train precision: 0.998000, train loss: 10.841753, valid precision: 0.875800, valid loss: 86.571739
epoch: 781, train precision: 0.998200, train loss: 10.831874, valid precision: 0.873400, valid loss: 87.257452
epoch: 782, train precision: 0.998667, train loss: 10.713297, valid precision: 0.876200, valid loss: 86.578661
epoch: 783, train precision: 0.998489, train loss: 10.695810, valid precision: 0.874400, valid loss: 85.183963
epoch: 784, train precision: 0.998644, train loss: 10.685959, valid precision: 0.874400, valid loss: 86.133624
epoch: 785, train precision: 0.998378, train loss: 10.804768, valid precision: 0.870800, valid loss: 85.693297
epoch: 786, train precision: 0.998311, train loss: 10.774584, valid precision: 0.875200, valid loss: 84.259596
epoch: 787, train precision: 0.998533, train loss: 10.702171, valid precision: 0.873800, valid loss: 85.178712
epoch: 788, train precision: 0.998467, train loss: 10.729036, valid precision: 0.871000, valid loss: 87.426258
epoch: 789, train precision: 0.998044, train loss: 10.856781, valid precision: 0.874000, valid loss: 88.798024
epoch: 790, train precision: 0.998311, train loss: 10.760747, valid precision: 0.872200, valid loss: 88.537299
epoch: 791, train precision: 0.998711, train loss: 10.656943, valid precision: 0.869800, valid loss: 88.812668
epoch: 792, train precision: 0.998244, train loss: 10.822808, valid precision: 0.874600, valid loss: 87.453290
epoch: 793, train precision: 0.998600, train loss: 10.705252, valid precision: 0.873800, valid loss: 86.171990
epoch: 794, train precision: 0.998400, train loss: 10.798652, valid precision: 0.871800, valid loss: 87.835499
epoch: 795, train precision: 0.998222, train loss: 10.788702, valid precision: 0.877800, valid loss: 86.110002
epoch: 796, train precision: 0.998356, train loss: 10.811681, valid precision: 0.870200, valid loss: 85.194607
epoch: 797, train precision: 0.998600, train loss: 10.661118, valid precision: 0.873600, valid loss: 85.173087
epoch: 798, train precision: 0.998533, train loss: 10.716500, valid precision: 0.871600, valid loss: 87.563881
epoch: 799, train precision: 0.998133, train loss: 10.905592, valid precision: 0.872000, valid loss: 87.759438
epoch: 800, train precision: 0.998333, train loss: 10.853407, valid precision: 0.874000, valid loss: 86.944479
epoch: 801, train precision: 0.998533, train loss: 10.732992, valid precision: 0.872800, valid loss: 85.495029
epoch: 802, train precision: 0.998422, train loss: 10.734406, valid precision: 0.873200, valid loss: 86.834368
epoch: 803, train precision: 0.998311, train loss: 10.864396, valid precision: 0.872600, valid loss: 86.865234
epoch: 804, train precision: 0.998333, train loss: 10.801993, valid precision: 0.872400, valid loss: 87.593260
epoch: 805, train precision: 0.998489, train loss: 10.821877, valid precision: 0.872600, valid loss: 88.555344
epoch: 806, train precision: 0.998400, train loss: 10.815981, valid precision: 0.868600, valid loss: 88.448763
epoch: 807, train precision: 0.998000, train loss: 10.815136, valid precision: 0.874400, valid loss: 87.763693
epoch: 808, train precision: 0.998156, train loss: 10.885636, valid precision: 0.869400, valid loss: 88.226749
epoch: 809, train precision: 0.998222, train loss: 10.842380, valid precision: 0.868600, valid loss: 88.695702
epoch: 810, train precision: 0.998667, train loss: 10.713373, valid precision: 0.871800, valid loss: 87.141660
epoch: 811, train precision: 0.998556, train loss: 10.675410, valid precision: 0.868800, valid loss: 90.024640
epoch: 812, train precision: 0.998222, train loss: 10.797314, valid precision: 0.871000, valid loss: 87.409709
epoch: 813, train precision: 0.998267, train loss: 10.806289, valid precision: 0.874000, valid loss: 84.573645
epoch: 814, train precision: 0.998400, train loss: 10.731128, valid precision: 0.875400, valid loss: 87.299554
epoch: 815, train precision: 0.998756, train loss: 10.636400, valid precision: 0.880800, valid loss: 86.532529
epoch: 816, train precision: 0.998489, train loss: 10.732001, valid precision: 0.874200, valid loss: 86.280792
epoch: 817, train precision: 0.998800, train loss: 10.677877, valid precision: 0.874400, valid loss: 85.818924
epoch: 818, train precision: 0.998622, train loss: 10.645047, valid precision: 0.871200, valid loss: 86.901366
epoch: 819, train precision: 0.998244, train loss: 10.767239, valid precision: 0.872000, valid loss: 88.320199
epoch: 820, train precision: 0.998378, train loss: 10.847376, valid precision: 0.874200, valid loss: 86.793564
epoch: 821, train precision: 0.998289, train loss: 10.839025, valid precision: 0.874800, valid loss: 88.018494
epoch: 822, train precision: 0.998600, train loss: 10.728049, valid precision: 0.873000, valid loss: 89.412056
epoch: 823, train precision: 0.998067, train loss: 10.851705, valid precision: 0.872600, valid loss: 86.707258
epoch: 824, train precision: 0.998422, train loss: 10.733191, valid precision: 0.875600, valid loss: 87.383471
epoch: 825, train precision: 0.997511, train loss: 11.074893, valid precision: 0.870800, valid loss: 88.715822
epoch: 826, train precision: 0.998622, train loss: 10.772510, valid precision: 0.874800, valid loss: 85.983860
epoch: 827, train precision: 0.998533, train loss: 10.760494, valid precision: 0.874200, valid loss: 88.381947
epoch: 828, train precision: 0.998267, train loss: 10.843520, valid precision: 0.874800, valid loss: 89.369912
epoch: 829, train precision: 0.998800, train loss: 10.654355, valid precision: 0.874200, valid loss: 87.902050
epoch: 830, train precision: 0.998356, train loss: 10.810785, valid precision: 0.872400, valid loss: 87.841438
epoch: 831, train precision: 0.998733, train loss: 10.690443, valid precision: 0.871800, valid loss: 88.264470
epoch: 832, train precision: 0.998711, train loss: 10.735372, valid precision: 0.868400, valid loss: 90.253911
epoch: 833, train precision: 0.998467, train loss: 10.809831, valid precision: 0.873600, valid loss: 91.920357
epoch: 834, train precision: 0.998556, train loss: 10.708018, valid precision: 0.873000, valid loss: 87.537845
epoch: 835, train precision: 0.998378, train loss: 10.754177, valid precision: 0.871200, valid loss: 89.981728
epoch: 836, train precision: 0.998222, train loss: 10.886300, valid precision: 0.872000, valid loss: 89.785258
epoch: 837, train precision: 0.998978, train loss: 10.648146, valid precision: 0.873800, valid loss: 87.401588
epoch: 838, train precision: 0.998444, train loss: 10.802773, valid precision: 0.872600, valid loss: 88.988028
epoch: 839, train precision: 0.998111, train loss: 10.937706, valid precision: 0.872800, valid loss: 90.251343
epoch: 840, train precision: 0.998311, train loss: 10.829888, valid precision: 0.872600, valid loss: 89.219512
epoch: 841, train precision: 0.998267, train loss: 10.891881, valid precision: 0.870800, valid loss: 87.636406
epoch: 842, train precision: 0.998244, train loss: 10.810825, valid precision: 0.870600, valid loss: 90.262137
epoch: 843, train precision: 0.997733, train loss: 10.941792, valid precision: 0.871000, valid loss: 89.890980
epoch: 844, train precision: 0.998778, train loss: 10.649436, valid precision: 0.874800, valid loss: 88.605288
epoch: 845, train precision: 0.998622, train loss: 10.701766, valid precision: 0.875200, valid loss: 88.463413
epoch: 846, train precision: 0.998956, train loss: 10.598352, valid precision: 0.874000, valid loss: 87.948499
epoch: 847, train precision: 0.998533, train loss: 10.753804, valid precision: 0.872200, valid loss: 89.236986
epoch: 848, train precision: 0.998689, train loss: 10.664933, valid precision: 0.875600, valid loss: 87.888493
epoch: 849, train precision: 0.998667, train loss: 10.733976, valid precision: 0.874000, valid loss: 91.029204
epoch: 850, train precision: 0.998333, train loss: 10.755364, valid precision: 0.870800, valid loss: 89.049899
epoch: 851, train precision: 0.998511, train loss: 10.717204, valid precision: 0.870200, valid loss: 91.362434
epoch: 852, train precision: 0.998778, train loss: 10.636630, valid precision: 0.877000, valid loss: 88.516507
epoch: 853, train precision: 0.998467, train loss: 10.784312, valid precision: 0.871000, valid loss: 89.079871
epoch: 854, train precision: 0.998467, train loss: 10.760405, valid precision: 0.868000, valid loss: 90.074291
epoch: 855, train precision: 0.998444, train loss: 10.759704, valid precision: 0.868200, valid loss: 91.051076
epoch: 856, train precision: 0.998578, train loss: 10.713768, valid precision: 0.872000, valid loss: 87.713128
epoch: 857, train precision: 0.997822, train loss: 11.010829, valid precision: 0.868600, valid loss: 90.043379
epoch: 858, train precision: 0.998422, train loss: 10.890265, valid precision: 0.871800, valid loss: 87.808510
epoch: 859, train precision: 0.998311, train loss: 10.906476, valid precision: 0.872800, valid loss: 88.982665
epoch: 860, train precision: 0.998622, train loss: 10.720556, valid precision: 0.872800, valid loss: 87.670753
epoch: 861, train precision: 0.998200, train loss: 10.785668, valid precision: 0.872600, valid loss: 88.432965
epoch: 862, train precision: 0.998267, train loss: 10.860232, valid precision: 0.867400, valid loss: 91.663124
epoch: 863, train precision: 0.997956, train loss: 10.857425, valid precision: 0.868000, valid loss: 89.161981
epoch: 864, train precision: 0.998511, train loss: 10.808258, valid precision: 0.872000, valid loss: 90.739474
epoch: 865, train precision: 0.998511, train loss: 10.738029, valid precision: 0.870800, valid loss: 88.368024
epoch: 866, train precision: 0.998489, train loss: 10.810527, valid precision: 0.871800, valid loss: 90.922609
epoch: 867, train precision: 0.999156, train loss: 10.618357, valid precision: 0.871200, valid loss: 88.485804
epoch: 868, train precision: 0.998089, train loss: 10.962776, valid precision: 0.866200, valid loss: 90.484446
epoch: 869, train precision: 0.998511, train loss: 10.751442, valid precision: 0.871800, valid loss: 89.957568
epoch: 870, train precision: 0.998222, train loss: 10.860567, valid precision: 0.871000, valid loss: 90.554820
epoch: 871, train precision: 0.998600, train loss: 10.756277, valid precision: 0.873600, valid loss: 90.198832
epoch: 872, train precision: 0.998089, train loss: 10.879679, valid precision: 0.872000, valid loss: 87.910683
epoch: 873, train precision: 0.998667, train loss: 10.783236, valid precision: 0.872600, valid loss: 86.281320
epoch: 874, train precision: 0.998467, train loss: 10.760630, valid precision: 0.871200, valid loss: 86.170206
epoch: 875, train precision: 0.998533, train loss: 10.803295, valid precision: 0.872600, valid loss: 85.236862
epoch: 876, train precision: 0.998822, train loss: 10.726264, valid precision: 0.874200, valid loss: 87.054995
epoch: 877, train precision: 0.998111, train loss: 10.900291, valid precision: 0.872600, valid loss: 88.750717
epoch: 878, train precision: 0.997956, train loss: 10.963728, valid precision: 0.874400, valid loss: 87.539241
epoch: 879, train precision: 0.997844, train loss: 10.994437, valid precision: 0.873800, valid loss: 86.974332
epoch: 880, train precision: 0.998578, train loss: 10.809398, valid precision: 0.871200, valid loss: 88.234579
epoch: 881, train precision: 0.998178, train loss: 10.810450, valid precision: 0.872800, valid loss: 87.386668
epoch: 882, train precision: 0.998556, train loss: 10.782682, valid precision: 0.872000, valid loss: 87.530348
epoch: 883, train precision: 0.998911, train loss: 10.697146, valid precision: 0.877800, valid loss: 86.343767
epoch: 884, train precision: 0.998867, train loss: 10.731320, valid precision: 0.875000, valid loss: 87.244423
epoch: 885, train precision: 0.998733, train loss: 10.716100, valid precision: 0.873600, valid loss: 87.163130
epoch: 886, train precision: 0.998556, train loss: 10.743647, valid precision: 0.875800, valid loss: 86.555045
epoch: 887, train precision: 0.998689, train loss: 10.729183, valid precision: 0.874000, valid loss: 87.047256
epoch: 888, train precision: 0.998200, train loss: 10.844215, valid precision: 0.876200, valid loss: 86.270494
epoch: 889, train precision: 0.998689, train loss: 10.773852, valid precision: 0.872800, valid loss: 88.305036
epoch: 890, train precision: 0.998667, train loss: 10.741679, valid precision: 0.872200, valid loss: 87.084099
epoch: 891, train precision: 0.998422, train loss: 10.863183, valid precision: 0.876200, valid loss: 86.665041
epoch: 892, train precision: 0.998644, train loss: 10.663738, valid precision: 0.871200, valid loss: 86.737531
epoch: 893, train precision: 0.998333, train loss: 10.841032, valid precision: 0.874600, valid loss: 88.425189
epoch: 894, train precision: 0.998822, train loss: 10.716701, valid precision: 0.876800, valid loss: 86.402119
epoch: 895, train precision: 0.999111, train loss: 10.607611, valid precision: 0.875600, valid loss: 87.355603
epoch: 896, train precision: 0.998511, train loss: 10.831694, valid precision: 0.873800, valid loss: 86.668682
epoch: 897, train precision: 0.998756, train loss: 10.683299, valid precision: 0.875600, valid loss: 87.241166
epoch: 898, train precision: 0.998533, train loss: 10.783770, valid precision: 0.877400, valid loss: 87.803069
epoch: 899, train precision: 0.998511, train loss: 10.740348, valid precision: 0.877600, valid loss: 86.479870
epoch: 900, train precision: 0.998111, train loss: 10.838590, valid precision: 0.876200, valid loss: 88.002809
epoch: 901, train precision: 0.998667, train loss: 10.769669, valid precision: 0.880200, valid loss: 86.530048
epoch: 902, train precision: 0.998578, train loss: 10.752629, valid precision: 0.877600, valid loss: 87.144597
epoch: 903, train precision: 0.998778, train loss: 10.743751, valid precision: 0.876600, valid loss: 88.685405
epoch: 904, train precision: 0.998022, train loss: 10.973685, valid precision: 0.876400, valid loss: 89.270495
epoch: 905, train precision: 0.997800, train loss: 10.990957, valid precision: 0.875000, valid loss: 89.373395
epoch: 906, train precision: 0.998400, train loss: 10.794490, valid precision: 0.872600, valid loss: 89.366535
epoch: 907, train precision: 0.998600, train loss: 10.713014, valid precision: 0.873000, valid loss: 88.218353
epoch: 908, train precision: 0.997956, train loss: 10.915133, valid precision: 0.873400, valid loss: 89.062670
epoch: 909, train precision: 0.998289, train loss: 10.780977, valid precision: 0.873200, valid loss: 87.836454
epoch: 910, train precision: 0.998111, train loss: 10.853676, valid precision: 0.871600, valid loss: 89.717225
epoch: 911, train precision: 0.998778, train loss: 10.739035, valid precision: 0.875200, valid loss: 87.555580
epoch: 912, train precision: 0.998756, train loss: 10.758086, valid precision: 0.873600, valid loss: 88.862159
epoch: 913, train precision: 0.998444, train loss: 10.831850, valid precision: 0.874600, valid loss: 85.687444
epoch: 914, train precision: 0.999111, train loss: 10.588514, valid precision: 0.872600, valid loss: 87.199060
epoch: 915, train precision: 0.998378, train loss: 10.855086, valid precision: 0.875000, valid loss: 85.562203
epoch: 916, train precision: 0.998489, train loss: 10.877093, valid precision: 0.875600, valid loss: 86.879178
epoch: 917, train precision: 0.998378, train loss: 10.821526, valid precision: 0.875400, valid loss: 84.836105
epoch: 918, train precision: 0.998356, train loss: 10.836916, valid precision: 0.876200, valid loss: 86.731064
epoch: 919, train precision: 0.998622, train loss: 10.735292, valid precision: 0.876000, valid loss: 86.302425
epoch: 920, train precision: 0.998644, train loss: 10.745490, valid precision: 0.872600, valid loss: 88.743324
epoch: 921, train precision: 0.998889, train loss: 10.652640, valid precision: 0.874000, valid loss: 89.355423
epoch: 922, train precision: 0.998889, train loss: 10.695566, valid precision: 0.873000, valid loss: 86.761432
epoch: 923, train precision: 0.998956, train loss: 10.669843, valid precision: 0.872200, valid loss: 85.778416
epoch: 924, train precision: 0.998600, train loss: 10.691331, valid precision: 0.875800, valid loss: 85.197638
epoch: 925, train precision: 0.998467, train loss: 10.769473, valid precision: 0.873400, valid loss: 87.970335
epoch: 926, train precision: 0.998689, train loss: 10.724045, valid precision: 0.872400, valid loss: 88.815735
epoch: 927, train precision: 0.998711, train loss: 10.711299, valid precision: 0.876800, valid loss: 88.867587
epoch: 928, train precision: 0.998578, train loss: 10.719795, valid precision: 0.875200, valid loss: 86.404031
epoch: 929, train precision: 0.998644, train loss: 10.752188, valid precision: 0.873400, valid loss: 89.215418
epoch: 930, train precision: 0.998511, train loss: 10.768705, valid precision: 0.875400, valid loss: 86.030835
epoch: 931, train precision: 0.998556, train loss: 10.780522, valid precision: 0.873600, valid loss: 86.477290
epoch: 932, train precision: 0.998622, train loss: 10.711536, valid precision: 0.870200, valid loss: 89.818991
epoch: 933, train precision: 0.998289, train loss: 10.830127, valid precision: 0.872400, valid loss: 89.560265
epoch: 934, train precision: 0.998578, train loss: 10.707227, valid precision: 0.876200, valid loss: 90.724172
epoch: 935, train precision: 0.998511, train loss: 10.760896, valid precision: 0.871600, valid loss: 90.191139
epoch: 936, train precision: 0.998689, train loss: 10.749361, valid precision: 0.869600, valid loss: 89.541517
epoch: 937, train precision: 0.998689, train loss: 10.770706, valid precision: 0.872600, valid loss: 89.815699
epoch: 938, train precision: 0.998533, train loss: 10.750769, valid precision: 0.871800, valid loss: 90.357020
epoch: 939, train precision: 0.998067, train loss: 10.894169, valid precision: 0.870400, valid loss: 90.658073
epoch: 940, train precision: 0.998644, train loss: 10.782857, valid precision: 0.874800, valid loss: 89.018237
epoch: 941, train precision: 0.998733, train loss: 10.667437, valid precision: 0.874200, valid loss: 90.784426
epoch: 942, train precision: 0.998400, train loss: 10.833048, valid precision: 0.870800, valid loss: 91.338936
epoch: 943, train precision: 0.998133, train loss: 10.898290, valid precision: 0.871000, valid loss: 92.482576
epoch: 944, train precision: 0.998889, train loss: 10.644130, valid precision: 0.875800, valid loss: 89.533797
epoch: 945, train precision: 0.998444, train loss: 10.843493, valid precision: 0.872400, valid loss: 88.640899
epoch: 946, train precision: 0.998333, train loss: 10.778414, valid precision: 0.870400, valid loss: 91.016468
epoch: 947, train precision: 0.998867, train loss: 10.662564, valid precision: 0.870800, valid loss: 87.966553
epoch: 948, train precision: 0.998800, train loss: 10.698458, valid precision: 0.872600, valid loss: 88.123996
epoch: 949, train precision: 0.998956, train loss: 10.625422, valid precision: 0.870400, valid loss: 90.505014
epoch: 950, train precision: 0.998733, train loss: 10.726130, valid precision: 0.877000, valid loss: 88.124016
epoch: 951, train precision: 0.998556, train loss: 10.759514, valid precision: 0.874400, valid loss: 88.470203
epoch: 952, train precision: 0.998511, train loss: 10.714355, valid precision: 0.875000, valid loss: 89.292663
epoch: 953, train precision: 0.998356, train loss: 10.830283, valid precision: 0.872000, valid loss: 89.096216
epoch: 954, train precision: 0.998467, train loss: 10.807169, valid precision: 0.871800, valid loss: 89.089071
epoch: 955, train precision: 0.998222, train loss: 10.906235, valid precision: 0.869800, valid loss: 91.188231
epoch: 956, train precision: 0.998889, train loss: 10.702786, valid precision: 0.877600, valid loss: 87.026199
epoch: 957, train precision: 0.998822, train loss: 10.692041, valid precision: 0.878200, valid loss: 85.323185
epoch: 958, train precision: 0.998756, train loss: 10.750651, valid precision: 0.873600, valid loss: 86.535642
epoch: 959, train precision: 0.998267, train loss: 10.844104, valid precision: 0.872800, valid loss: 90.112786
epoch: 960, train precision: 0.998800, train loss: 10.678890, valid precision: 0.878600, valid loss: 85.860788
epoch: 961, train precision: 0.998533, train loss: 10.781581, valid precision: 0.873400, valid loss: 88.566519
epoch: 962, train precision: 0.998867, train loss: 10.696239, valid precision: 0.874600, valid loss: 87.966506
epoch: 963, train precision: 0.998444, train loss: 10.802731, valid precision: 0.872000, valid loss: 87.610679
epoch: 964, train precision: 0.998333, train loss: 10.790579, valid precision: 0.874000, valid loss: 85.560540
epoch: 965, train precision: 0.998133, train loss: 10.804445, valid precision: 0.872800, valid loss: 88.202241
epoch: 966, train precision: 0.998600, train loss: 10.761508, valid precision: 0.872400, valid loss: 88.477015
epoch: 967, train precision: 0.998089, train loss: 10.930783, valid precision: 0.873800, valid loss: 90.243634
epoch: 968, train precision: 0.998667, train loss: 10.741367, valid precision: 0.876200, valid loss: 87.037439
epoch: 969, train precision: 0.998378, train loss: 10.819308, valid precision: 0.872000, valid loss: 88.108248
epoch: 970, train precision: 0.998556, train loss: 10.757479, valid precision: 0.873400, valid loss: 88.202573
epoch: 971, train precision: 0.998578, train loss: 10.809487, valid precision: 0.869400, valid loss: 91.478691
epoch: 972, train precision: 0.998378, train loss: 10.736812, valid precision: 0.870400, valid loss: 89.147197
epoch: 973, train precision: 0.998733, train loss: 10.729898, valid precision: 0.872200, valid loss: 88.851756
epoch: 974, train precision: 0.998600, train loss: 10.825236, valid precision: 0.867600, valid loss: 91.485967
epoch: 975, train precision: 0.998667, train loss: 10.800414, valid precision: 0.872200, valid loss: 88.875426
epoch: 976, train precision: 0.998556, train loss: 10.813633, valid precision: 0.867200, valid loss: 90.237753
epoch: 977, train precision: 0.998667, train loss: 10.734039, valid precision: 0.871200, valid loss: 91.184846
epoch: 978, train precision: 0.998622, train loss: 10.831568, valid precision: 0.871800, valid loss: 89.737042
epoch: 979, train precision: 0.998400, train loss: 10.843368, valid precision: 0.871800, valid loss: 90.933198
epoch: 980, train precision: 0.998933, train loss: 10.645401, valid precision: 0.874400, valid loss: 90.796504
epoch: 981, train precision: 0.998689, train loss: 10.669000, valid precision: 0.873000, valid loss: 90.178903
epoch: 982, train precision: 0.998711, train loss: 10.667974, valid precision: 0.870800, valid loss: 91.390178
epoch: 983, train precision: 0.998578, train loss: 10.754707, valid precision: 0.873000, valid loss: 89.758005
epoch: 984, train precision: 0.998556, train loss: 10.732441, valid precision: 0.871200, valid loss: 91.031522
epoch: 985, train precision: 0.998778, train loss: 10.737133, valid precision: 0.868800, valid loss: 91.211841
epoch: 986, train precision: 0.998444, train loss: 10.860119, valid precision: 0.866600, valid loss: 92.661098
epoch: 987, train precision: 0.998578, train loss: 10.790567, valid precision: 0.869600, valid loss: 91.234927
epoch: 988, train precision: 0.998867, train loss: 10.660540, valid precision: 0.869200, valid loss: 91.488316
epoch: 989, train precision: 0.998644, train loss: 10.766399, valid precision: 0.868800, valid loss: 90.108797
epoch: 990, train precision: 0.998556, train loss: 10.722073, valid precision: 0.871200, valid loss: 89.586462
epoch: 991, train precision: 0.998667, train loss: 10.772730, valid precision: 0.871600, valid loss: 89.231460
epoch: 992, train precision: 0.998889, train loss: 10.736600, valid precision: 0.869000, valid loss: 88.292364
epoch: 993, train precision: 0.998911, train loss: 10.664996, valid precision: 0.869800, valid loss: 90.725846
epoch: 994, train precision: 0.998756, train loss: 10.744858, valid precision: 0.868000, valid loss: 89.092298
epoch: 995, train precision: 0.998622, train loss: 10.726269, valid precision: 0.868000, valid loss: 90.914363
epoch: 996, train precision: 0.998467, train loss: 10.846556, valid precision: 0.873600, valid loss: 89.600765
epoch: 997, train precision: 0.998311, train loss: 10.910049, valid precision: 0.873400, valid loss: 89.108628
epoch: 998, train precision: 0.998622, train loss: 10.758715, valid precision: 0.870400, valid loss: 89.330223
epoch: 999, train precision: 0.998667, train loss: 10.728182, valid precision: 0.873600, valid loss: 88.140496
epoch: 1000, train precision: 0.997267, train loss: 11.196806, valid precision: 0.869800, valid loss: 89.510886
epoch: 1001, train precision: 0.998911, train loss: 10.697470, valid precision: 0.874200, valid loss: 88.368654
epoch: 1002, train precision: 0.998822, train loss: 10.685271, valid precision: 0.874200, valid loss: 87.246649
epoch: 1003, train precision: 0.998089, train loss: 10.811418, valid precision: 0.874000, valid loss: 89.725833
epoch: 1004, train precision: 0.998867, train loss: 10.746875, valid precision: 0.872400, valid loss: 89.370369
epoch: 1005, train precision: 0.998711, train loss: 10.665088, valid precision: 0.873600, valid loss: 88.052866
epoch: 1006, train precision: 0.998978, train loss: 10.729724, valid precision: 0.873400, valid loss: 88.797548
epoch: 1007, train precision: 0.998644, train loss: 10.709983, valid precision: 0.874400, valid loss: 89.197882
epoch: 1008, train precision: 0.998933, train loss: 10.689747, valid precision: 0.874000, valid loss: 89.324929
epoch: 1009, train precision: 0.998733, train loss: 10.720672, valid precision: 0.875400, valid loss: 86.749999
epoch: 1010, train precision: 0.998889, train loss: 10.677385, valid precision: 0.873800, valid loss: 90.775879
epoch: 1011, train precision: 0.998200, train loss: 10.952018, valid precision: 0.869400, valid loss: 91.008186
epoch: 1012, train precision: 0.998756, train loss: 10.696982, valid precision: 0.871400, valid loss: 92.245004
epoch: 1013, train precision: 0.998111, train loss: 10.949631, valid precision: 0.870400, valid loss: 90.881159
epoch: 1014, train precision: 0.998889, train loss: 10.703631, valid precision: 0.872200, valid loss: 91.399410
epoch: 1015, train precision: 0.998289, train loss: 10.879352, valid precision: 0.871400, valid loss: 91.002551
epoch: 1016, train precision: 0.998711, train loss: 10.750505, valid precision: 0.875400, valid loss: 89.775533
epoch: 1017, train precision: 0.998933, train loss: 10.617529, valid precision: 0.874800, valid loss: 93.724011
epoch: 1018, train precision: 0.998511, train loss: 10.809930, valid precision: 0.868600, valid loss: 93.074671
epoch: 1019, train precision: 0.998267, train loss: 10.813534, valid precision: 0.873200, valid loss: 90.873279
epoch: 1020, train precision: 0.998244, train loss: 10.924395, valid precision: 0.870400, valid loss: 91.338066
epoch: 1021, train precision: 0.998333, train loss: 10.928386, valid precision: 0.868200, valid loss: 90.452759
epoch: 1022, train precision: 0.998156, train loss: 10.872862, valid precision: 0.872800, valid loss: 89.945378
epoch: 1023, train precision: 0.998644, train loss: 10.823218, valid precision: 0.874400, valid loss: 89.492167
epoch: 1024, train precision: 0.998867, train loss: 10.733361, valid precision: 0.876200, valid loss: 89.745055
epoch: 1025, train precision: 0.998556, train loss: 10.856288, valid precision: 0.874600, valid loss: 89.453403
epoch: 1026, train precision: 0.998422, train loss: 10.863474, valid precision: 0.867600, valid loss: 93.488152
epoch: 1027, train precision: 0.998333, train loss: 10.862491, valid precision: 0.872600, valid loss: 91.275551
epoch: 1028, train precision: 0.998822, train loss: 10.784021, valid precision: 0.871600, valid loss: 88.996256
epoch: 1029, train precision: 0.998778, train loss: 10.723304, valid precision: 0.871400, valid loss: 88.955561
epoch: 1030, train precision: 0.998400, train loss: 10.828439, valid precision: 0.868000, valid loss: 90.929029
epoch: 1031, train precision: 0.998800, train loss: 10.751576, valid precision: 0.868800, valid loss: 91.080706
epoch: 1032, train precision: 0.998756, train loss: 10.731879, valid precision: 0.871000, valid loss: 91.010395
epoch: 1033, train precision: 0.998022, train loss: 10.927532, valid precision: 0.872600, valid loss: 92.931969
epoch: 1034, train precision: 0.999111, train loss: 10.611678, valid precision: 0.875200, valid loss: 89.862582
epoch: 1035, train precision: 0.998822, train loss: 10.754588, valid precision: 0.874400, valid loss: 88.826408
epoch: 1036, train precision: 0.998867, train loss: 10.740076, valid precision: 0.873600, valid loss: 88.894925
epoch: 1037, train precision: 0.998422, train loss: 10.799594, valid precision: 0.874400, valid loss: 90.405204
epoch: 1038, train precision: 0.998644, train loss: 10.812286, valid precision: 0.875200, valid loss: 88.029759
epoch: 1039, train precision: 0.998400, train loss: 10.830178, valid precision: 0.870600, valid loss: 90.985392
epoch: 1040, train precision: 0.998156, train loss: 10.939394, valid precision: 0.872200, valid loss: 91.309524
epoch: 1041, train precision: 0.998822, train loss: 10.663848, valid precision: 0.873600, valid loss: 91.868291
epoch: 1042, train precision: 0.998244, train loss: 10.868572, valid precision: 0.870800, valid loss: 92.318434
epoch: 1043, train precision: 0.998756, train loss: 10.728920, valid precision: 0.874000, valid loss: 92.301020
epoch: 1044, train precision: 0.998600, train loss: 10.884237, valid precision: 0.870600, valid loss: 92.202235
epoch: 1045, train precision: 0.998778, train loss: 10.729988, valid precision: 0.869400, valid loss: 91.781625
epoch: 1046, train precision: 0.998578, train loss: 10.796860, valid precision: 0.871400, valid loss: 92.135769
epoch: 1047, train precision: 0.998578, train loss: 10.854575, valid precision: 0.871400, valid loss: 90.152675
epoch: 1048, train precision: 0.998444, train loss: 10.753033, valid precision: 0.872200, valid loss: 89.926457
epoch: 1049, train precision: 0.998933, train loss: 10.713876, valid precision: 0.871800, valid loss: 90.262446
epoch: 1050, train precision: 0.998200, train loss: 10.871202, valid precision: 0.871800, valid loss: 88.353661
epoch: 1051, train precision: 0.998822, train loss: 10.691118, valid precision: 0.871800, valid loss: 91.339674
epoch: 1052, train precision: 0.998711, train loss: 10.726850, valid precision: 0.873200, valid loss: 91.794428
epoch: 1053, train precision: 0.998511, train loss: 10.810118, valid precision: 0.874400, valid loss: 88.609396
epoch: 1054, train precision: 0.998933, train loss: 10.693158, valid precision: 0.874600, valid loss: 88.987602
epoch: 1055, train precision: 0.998644, train loss: 10.796528, valid precision: 0.878800, valid loss: 89.820949
epoch: 1056, train precision: 0.998022, train loss: 10.936374, valid precision: 0.870600, valid loss: 90.985932
epoch: 1057, train precision: 0.999089, train loss: 10.626675, valid precision: 0.875000, valid loss: 88.458525
epoch: 1058, train precision: 0.998511, train loss: 10.888642, valid precision: 0.874000, valid loss: 88.828786
epoch: 1059, train precision: 0.998444, train loss: 10.817456, valid precision: 0.874400, valid loss: 89.389210
epoch: 1060, train precision: 0.999111, train loss: 10.584861, valid precision: 0.872200, valid loss: 89.492695
epoch: 1061, train precision: 0.998667, train loss: 10.765007, valid precision: 0.876200, valid loss: 86.898466
epoch: 1062, train precision: 0.998911, train loss: 10.681552, valid precision: 0.872400, valid loss: 89.972286
epoch: 1063, train precision: 0.998400, train loss: 10.853088, valid precision: 0.874600, valid loss: 89.950898
epoch: 1064, train precision: 0.998889, train loss: 10.733587, valid precision: 0.875000, valid loss: 90.914630
epoch: 1065, train precision: 0.998800, train loss: 10.700791, valid precision: 0.871200, valid loss: 88.762435
epoch: 1066, train precision: 0.998067, train loss: 10.893530, valid precision: 0.869800, valid loss: 92.071121
epoch: 1067, train precision: 0.998378, train loss: 10.828622, valid precision: 0.872600, valid loss: 91.178524
epoch: 1068, train precision: 0.998556, train loss: 10.781501, valid precision: 0.871600, valid loss: 90.899914
epoch: 1069, train precision: 0.999178, train loss: 10.697790, valid precision: 0.869200, valid loss: 89.407663
epoch: 1070, train precision: 0.999044, train loss: 10.659596, valid precision: 0.867400, valid loss: 90.115060
epoch: 1071, train precision: 0.998733, train loss: 10.759007, valid precision: 0.875200, valid loss: 87.678261
epoch: 1072, train precision: 0.998711, train loss: 10.731503, valid precision: 0.873200, valid loss: 91.626716
epoch: 1073, train precision: 0.998689, train loss: 10.708500, valid precision: 0.872400, valid loss: 91.506961
epoch: 1074, train precision: 0.998533, train loss: 10.811938, valid precision: 0.870000, valid loss: 90.488342
epoch: 1075, train precision: 0.998956, train loss: 10.655646, valid precision: 0.873200, valid loss: 91.410058
epoch: 1076, train precision: 0.998756, train loss: 10.781385, valid precision: 0.874600, valid loss: 90.338583
epoch: 1077, train precision: 0.998622, train loss: 10.772130, valid precision: 0.868800, valid loss: 91.296180
epoch: 1078, train precision: 0.998756, train loss: 10.760802, valid precision: 0.870200, valid loss: 91.798890
epoch: 1079, train precision: 0.998511, train loss: 10.866328, valid precision: 0.872000, valid loss: 91.585959
epoch: 1080, train precision: 0.998556, train loss: 10.807586, valid precision: 0.872800, valid loss: 89.338246
epoch: 1081, train precision: 0.998622, train loss: 10.782428, valid precision: 0.871600, valid loss: 90.702241
epoch: 1082, train precision: 0.998422, train loss: 10.829541, valid precision: 0.869000, valid loss: 90.781121
epoch: 1083, train precision: 0.999000, train loss: 10.672215, valid precision: 0.871800, valid loss: 90.973313
epoch: 1084, train precision: 0.998689, train loss: 10.743785, valid precision: 0.871400, valid loss: 91.566433
epoch: 1085, train precision: 0.998467, train loss: 10.839634, valid precision: 0.867600, valid loss: 91.875412
epoch: 1086, train precision: 0.998467, train loss: 10.833425, valid precision: 0.870000, valid loss: 89.721491
epoch: 1087, train precision: 0.998267, train loss: 10.910962, valid precision: 0.869000, valid loss: 89.908068
epoch: 1088, train precision: 0.998756, train loss: 10.757622, valid precision: 0.870400, valid loss: 90.992743
epoch: 1089, train precision: 0.998956, train loss: 10.679543, valid precision: 0.870000, valid loss: 89.929361
epoch: 1090, train precision: 0.999044, train loss: 10.621089, valid precision: 0.868000, valid loss: 90.446293
epoch: 1091, train precision: 0.998444, train loss: 10.866065, valid precision: 0.872000, valid loss: 89.051887
epoch: 1092, train precision: 0.998711, train loss: 10.786018, valid precision: 0.866000, valid loss: 89.704361
epoch: 1093, train precision: 0.998778, train loss: 10.724217, valid precision: 0.871400, valid loss: 88.902899
epoch: 1094, train precision: 0.998978, train loss: 10.651077, valid precision: 0.868400, valid loss: 91.984362
epoch: 1095, train precision: 0.998778, train loss: 10.686118, valid precision: 0.868200, valid loss: 90.383684
epoch: 1096, train precision: 0.998822, train loss: 10.743391, valid precision: 0.872000, valid loss: 89.200588
epoch: 1097, train precision: 0.998378, train loss: 10.863811, valid precision: 0.870800, valid loss: 88.067370
epoch: 1098, train precision: 0.998600, train loss: 10.809907, valid precision: 0.870000, valid loss: 90.807594
epoch: 1099, train precision: 0.998756, train loss: 10.753842, valid precision: 0.874600, valid loss: 88.348042
epoch: 1100, train precision: 0.998889, train loss: 10.733963, valid precision: 0.870600, valid loss: 90.359102
epoch: 1101, train precision: 0.998889, train loss: 10.738402, valid precision: 0.871800, valid loss: 90.329931
epoch: 1102, train precision: 0.998622, train loss: 10.782954, valid precision: 0.872400, valid loss: 91.087524
epoch: 1103, train precision: 0.998844, train loss: 10.747937, valid precision: 0.873800, valid loss: 85.755314
epoch: 1104, train precision: 0.998756, train loss: 10.754290, valid precision: 0.872800, valid loss: 87.869859
epoch: 1105, train precision: 0.998178, train loss: 10.962231, valid precision: 0.871200, valid loss: 90.422648
epoch: 1106, train precision: 0.998867, train loss: 10.664120, valid precision: 0.870400, valid loss: 89.826399
epoch: 1107, train precision: 0.998156, train loss: 10.980940, valid precision: 0.873800, valid loss: 90.674084
epoch: 1108, train precision: 0.999067, train loss: 10.667143, valid precision: 0.873000, valid loss: 89.277239
epoch: 1109, train precision: 0.998756, train loss: 10.751777, valid precision: 0.872000, valid loss: 89.453789
epoch: 1110, train precision: 0.998711, train loss: 10.744306, valid precision: 0.873200, valid loss: 90.651546
epoch: 1111, train precision: 0.998444, train loss: 10.842471, valid precision: 0.877600, valid loss: 87.803457
epoch: 1112, train precision: 0.998622, train loss: 10.790915, valid precision: 0.869400, valid loss: 90.081603
epoch: 1113, train precision: 0.998733, train loss: 10.793929, valid precision: 0.871200, valid loss: 88.713230
epoch: 1114, train precision: 0.998933, train loss: 10.737024, valid precision: 0.871800, valid loss: 91.532608
epoch: 1115, train precision: 0.997956, train loss: 10.974698, valid precision: 0.872200, valid loss: 90.817253
epoch: 1116, train precision: 0.998600, train loss: 10.804135, valid precision: 0.873800, valid loss: 89.654717
epoch: 1117, train precision: 0.998978, train loss: 10.705705, valid precision: 0.873800, valid loss: 90.630347
epoch: 1118, train precision: 0.998444, train loss: 10.908232, valid precision: 0.870600, valid loss: 91.477732
epoch: 1119, train precision: 0.998333, train loss: 10.852577, valid precision: 0.870200, valid loss: 92.415540
epoch: 1120, train precision: 0.998889, train loss: 10.701223, valid precision: 0.872600, valid loss: 90.643775
epoch: 1121, train precision: 0.998711, train loss: 10.728863, valid precision: 0.874400, valid loss: 92.086141
epoch: 1122, train precision: 0.998733, train loss: 10.802636, valid precision: 0.876800, valid loss: 90.178945
epoch: 1123, train precision: 0.998667, train loss: 10.716012, valid precision: 0.874400, valid loss: 91.211947
epoch: 1124, train precision: 0.998911, train loss: 10.628654, valid precision: 0.877000, valid loss: 90.780015
epoch: 1125, train precision: 0.998733, train loss: 10.734744, valid precision: 0.874400, valid loss: 91.402650
epoch: 1126, train precision: 0.998800, train loss: 10.719918, valid precision: 0.870600, valid loss: 89.664908
epoch: 1127, train precision: 0.998400, train loss: 10.831704, valid precision: 0.870000, valid loss: 92.374853
epoch: 1128, train precision: 0.999022, train loss: 10.670991, valid precision: 0.875400, valid loss: 90.268187
epoch: 1129, train precision: 0.998733, train loss: 10.731150, valid precision: 0.879800, valid loss: 89.768423
epoch: 1130, train precision: 0.998889, train loss: 10.715228, valid precision: 0.877200, valid loss: 89.417880
epoch: 1131, train precision: 0.998933, train loss: 10.716212, valid precision: 0.877800, valid loss: 88.803630
epoch: 1132, train precision: 0.998911, train loss: 10.672978, valid precision: 0.874200, valid loss: 89.354342
epoch: 1133, train precision: 0.998111, train loss: 10.869044, valid precision: 0.873000, valid loss: 90.591180
epoch: 1134, train precision: 0.999067, train loss: 10.691539, valid precision: 0.875000, valid loss: 92.272872
epoch: 1135, train precision: 0.998600, train loss: 10.781156, valid precision: 0.871000, valid loss: 88.826692
epoch: 1136, train precision: 0.998511, train loss: 10.864384, valid precision: 0.875600, valid loss: 89.362487
epoch: 1137, train precision: 0.998667, train loss: 10.769623, valid precision: 0.872000, valid loss: 91.367282
epoch: 1138, train precision: 0.999222, train loss: 10.641682, valid precision: 0.870800, valid loss: 91.885295
epoch: 1139, train precision: 0.998133, train loss: 10.916426, valid precision: 0.872400, valid loss: 89.845885
epoch: 1140, train precision: 0.998867, train loss: 10.735025, valid precision: 0.872200, valid loss: 90.514037
epoch: 1141, train precision: 0.998867, train loss: 10.709179, valid precision: 0.873800, valid loss: 89.747457
epoch: 1142, train precision: 0.998533, train loss: 10.808064, valid precision: 0.874600, valid loss: 89.178427
epoch: 1143, train precision: 0.998689, train loss: 10.838610, valid precision: 0.871600, valid loss: 92.315559
epoch: 1144, train precision: 0.998867, train loss: 10.716986, valid precision: 0.874400, valid loss: 89.910110
epoch: 1145, train precision: 0.999067, train loss: 10.719597, valid precision: 0.873600, valid loss: 88.707842
epoch: 1146, train precision: 0.998644, train loss: 10.788252, valid precision: 0.871200, valid loss: 87.947892
epoch: 1147, train precision: 0.998378, train loss: 10.853954, valid precision: 0.871800, valid loss: 87.284115
epoch: 1148, train precision: 0.998178, train loss: 10.935729, valid precision: 0.869800, valid loss: 86.615279
epoch: 1149, train precision: 0.998800, train loss: 10.739359, valid precision: 0.875400, valid loss: 86.238827
epoch: 1150, train precision: 0.999067, train loss: 10.671935, valid precision: 0.873800, valid loss: 87.879934
epoch: 1151, train precision: 0.998600, train loss: 10.818815, valid precision: 0.872600, valid loss: 88.134861
epoch: 1152, train precision: 0.998578, train loss: 10.751143, valid precision: 0.873800, valid loss: 90.061740
epoch: 1153, train precision: 0.998756, train loss: 10.728425, valid precision: 0.873200, valid loss: 87.915927
epoch: 1154, train precision: 0.998933, train loss: 10.684138, valid precision: 0.870400, valid loss: 87.547013
epoch: 1155, train precision: 0.999067, train loss: 10.703089, valid precision: 0.872800, valid loss: 88.972152
epoch: 1156, train precision: 0.998956, train loss: 10.694924, valid precision: 0.873200, valid loss: 86.981859
epoch: 1157, train precision: 0.998844, train loss: 10.699620, valid precision: 0.873600, valid loss: 88.949876
epoch: 1158, train precision: 0.998333, train loss: 10.926632, valid precision: 0.878000, valid loss: 87.971905
epoch: 1159, train precision: 0.998711, train loss: 10.758260, valid precision: 0.874800, valid loss: 89.904084
epoch: 1160, train precision: 0.998844, train loss: 10.768782, valid precision: 0.874600, valid loss: 91.439086
epoch: 1161, train precision: 0.998378, train loss: 10.821279, valid precision: 0.875600, valid loss: 90.524135
epoch: 1162, train precision: 0.998444, train loss: 10.807033, valid precision: 0.874800, valid loss: 88.950106
epoch: 1163, train precision: 0.998533, train loss: 10.825818, valid precision: 0.872800, valid loss: 90.622904
epoch: 1164, train precision: 0.998889, train loss: 10.695492, valid precision: 0.874800, valid loss: 87.807897
epoch: 1165, train precision: 0.998822, train loss: 10.764499, valid precision: 0.874600, valid loss: 89.496242
epoch: 1166, train precision: 0.998511, train loss: 10.856339, valid precision: 0.873600, valid loss: 89.310396
epoch: 1167, train precision: 0.998844, train loss: 10.727451, valid precision: 0.878200, valid loss: 87.397844
epoch: 1168, train precision: 0.998622, train loss: 10.774364, valid precision: 0.875200, valid loss: 89.590686
epoch: 1169, train precision: 0.998644, train loss: 10.777184, valid precision: 0.871200, valid loss: 90.279798
epoch: 1170, train precision: 0.999111, train loss: 10.683044, valid precision: 0.874600, valid loss: 88.866517
epoch: 1171, train precision: 0.998178, train loss: 10.920865, valid precision: 0.880200, valid loss: 87.815482
epoch: 1172, train precision: 0.998889, train loss: 10.677714, valid precision: 0.878800, valid loss: 89.481340
epoch: 1173, train precision: 0.998911, train loss: 10.666263, valid precision: 0.879000, valid loss: 88.636369
epoch: 1174, train precision: 0.998778, train loss: 10.743261, valid precision: 0.877200, valid loss: 89.414634
epoch: 1175, train precision: 0.998556, train loss: 10.774157, valid precision: 0.874800, valid loss: 90.079304
epoch: 1176, train precision: 0.998378, train loss: 10.856019, valid precision: 0.876200, valid loss: 89.787360
epoch: 1177, train precision: 0.998778, train loss: 10.761045, valid precision: 0.878800, valid loss: 89.137215
epoch: 1178, train precision: 0.998733, train loss: 10.725690, valid precision: 0.875600, valid loss: 89.516809
epoch: 1179, train precision: 0.998400, train loss: 10.827596, valid precision: 0.878800, valid loss: 88.319547
epoch: 1180, train precision: 0.999178, train loss: 10.592592, valid precision: 0.879800, valid loss: 87.417741
epoch: 1181, train precision: 0.998667, train loss: 10.709071, valid precision: 0.875200, valid loss: 88.483432
epoch: 1182, train precision: 0.998756, train loss: 10.726435, valid precision: 0.879400, valid loss: 88.231656
epoch: 1183, train precision: 0.998956, train loss: 10.703296, valid precision: 0.876200, valid loss: 88.021091
epoch: 1184, train precision: 0.998844, train loss: 10.751727, valid precision: 0.876400, valid loss: 88.694229
epoch: 1185, train precision: 0.998933, train loss: 10.685057, valid precision: 0.876400, valid loss: 86.294432
epoch: 1186, train precision: 0.998933, train loss: 10.731768, valid precision: 0.877000, valid loss: 86.626586
epoch: 1187, train precision: 0.998711, train loss: 10.739786, valid precision: 0.879400, valid loss: 86.853033
epoch: 1188, train precision: 0.998622, train loss: 10.839616, valid precision: 0.876600, valid loss: 88.182785
epoch: 1189, train precision: 0.998533, train loss: 10.881887, valid precision: 0.875800, valid loss: 88.610702
epoch: 1190, train precision: 0.998644, train loss: 10.796698, valid precision: 0.878800, valid loss: 86.940264
epoch: 1191, train precision: 0.998578, train loss: 10.722032, valid precision: 0.878000, valid loss: 87.879359
epoch: 1192, train precision: 0.998822, train loss: 10.693575, valid precision: 0.879000, valid loss: 87.587185
epoch: 1193, train precision: 0.998489, train loss: 10.850105, valid precision: 0.876000, valid loss: 88.008562
epoch: 1194, train precision: 0.998511, train loss: 10.779153, valid precision: 0.877200, valid loss: 87.724318
epoch: 1195, train precision: 0.998511, train loss: 10.871399, valid precision: 0.875800, valid loss: 89.476045
epoch: 1196, train precision: 0.998511, train loss: 10.795118, valid precision: 0.877400, valid loss: 87.564678
epoch: 1197, train precision: 0.998200, train loss: 10.877968, valid precision: 0.875600, valid loss: 89.702665
epoch: 1198, train precision: 0.998800, train loss: 10.767860, valid precision: 0.869800, valid loss: 90.051685
epoch: 1199, train precision: 0.998844, train loss: 10.766960, valid precision: 0.874600, valid loss: 89.187134
epoch: 1200, train precision: 0.998489, train loss: 10.815710, valid precision: 0.874400, valid loss: 87.569452
epoch: 1201, train precision: 0.998800, train loss: 10.736729, valid precision: 0.876600, valid loss: 89.405972
epoch: 1202, train precision: 0.998911, train loss: 10.788273, valid precision: 0.872600, valid loss: 90.290359
epoch: 1203, train precision: 0.998578, train loss: 10.790533, valid precision: 0.872800, valid loss: 89.297486
epoch: 1204, train precision: 0.998089, train loss: 11.025142, valid precision: 0.867200, valid loss: 92.216485
epoch: 1205, train precision: 0.998689, train loss: 10.791323, valid precision: 0.872200, valid loss: 89.660460
epoch: 1206, train precision: 0.998844, train loss: 10.701106, valid precision: 0.872600, valid loss: 89.099596
epoch: 1207, train precision: 0.998889, train loss: 10.706284, valid precision: 0.872400, valid loss: 91.317415
epoch: 1208, train precision: 0.998622, train loss: 10.720924, valid precision: 0.876400, valid loss: 90.732765
epoch: 1209, train precision: 0.998622, train loss: 10.816123, valid precision: 0.874200, valid loss: 90.905703
epoch: 1210, train precision: 0.998733, train loss: 10.718463, valid precision: 0.875400, valid loss: 91.439715
epoch: 1211, train precision: 0.998867, train loss: 10.725730, valid precision: 0.873000, valid loss: 90.496102
epoch: 1212, train precision: 0.998644, train loss: 10.790561, valid precision: 0.872600, valid loss: 90.033469
epoch: 1213, train precision: 0.998800, train loss: 10.729732, valid precision: 0.880000, valid loss: 88.621353
epoch: 1214, train precision: 0.998533, train loss: 10.754867, valid precision: 0.875400, valid loss: 88.729375
epoch: 1215, train precision: 0.998778, train loss: 10.714915, valid precision: 0.877000, valid loss: 91.995523
epoch: 1216, train precision: 0.998533, train loss: 10.802625, valid precision: 0.873600, valid loss: 91.495743
epoch: 1217, train precision: 0.998778, train loss: 10.712840, valid precision: 0.875600, valid loss: 90.890621
epoch: 1218, train precision: 0.999067, train loss: 10.624460, valid precision: 0.876600, valid loss: 91.379207
epoch: 1219, train precision: 0.998933, train loss: 10.669082, valid precision: 0.871800, valid loss: 91.898255
epoch: 1220, train precision: 0.998244, train loss: 10.943612, valid precision: 0.876200, valid loss: 90.507066
epoch: 1221, train precision: 0.998222, train loss: 10.855738, valid precision: 0.875000, valid loss: 89.852694
epoch: 1222, train precision: 0.998911, train loss: 10.697959, valid precision: 0.874400, valid loss: 89.252444
epoch: 1223, train precision: 0.998956, train loss: 10.712912, valid precision: 0.874000, valid loss: 89.443999
epoch: 1224, train precision: 0.998778, train loss: 10.657139, valid precision: 0.876200, valid loss: 89.600035
epoch: 1225, train precision: 0.998844, train loss: 10.743240, valid precision: 0.876200, valid loss: 88.336007
epoch: 1226, train precision: 0.998956, train loss: 10.730747, valid precision: 0.879200, valid loss: 89.169821
epoch: 1227, train precision: 0.998844, train loss: 10.760150, valid precision: 0.873800, valid loss: 88.316076
epoch: 1228, train precision: 0.998822, train loss: 10.725199, valid precision: 0.874200, valid loss: 88.275901
epoch: 1229, train precision: 0.998867, train loss: 10.727038, valid precision: 0.875800, valid loss: 88.166432
epoch: 1230, train precision: 0.998711, train loss: 10.697824, valid precision: 0.878800, valid loss: 88.489092
epoch: 1231, train precision: 0.998667, train loss: 10.851938, valid precision: 0.876000, valid loss: 90.654534
epoch: 1232, train precision: 0.998667, train loss: 10.854187, valid precision: 0.874400, valid loss: 88.751205
epoch: 1233, train precision: 0.999044, train loss: 10.644371, valid precision: 0.875400, valid loss: 88.334109
epoch: 1234, train precision: 0.998911, train loss: 10.710629, valid precision: 0.874000, valid loss: 89.769056
epoch: 1235, train precision: 0.998800, train loss: 10.778452, valid precision: 0.872200, valid loss: 89.469132
epoch: 1236, train precision: 0.998844, train loss: 10.686066, valid precision: 0.872600, valid loss: 87.553683
epoch: 1237, train precision: 0.999133, train loss: 10.595781, valid precision: 0.875600, valid loss: 87.377460
epoch: 1238, train precision: 0.999067, train loss: 10.705409, valid precision: 0.874200, valid loss: 88.162608
epoch: 1239, train precision: 0.998800, train loss: 10.718095, valid precision: 0.874200, valid loss: 90.445390
epoch: 1240, train precision: 0.998978, train loss: 10.682059, valid precision: 0.876800, valid loss: 88.289759
epoch: 1241, train precision: 0.998578, train loss: 10.733750, valid precision: 0.878200, valid loss: 87.089476
epoch: 1242, train precision: 0.998711, train loss: 10.739133, valid precision: 0.875200, valid loss: 88.725075
epoch: 1243, train precision: 0.998578, train loss: 10.809495, valid precision: 0.875000, valid loss: 90.261396
epoch: 1244, train precision: 0.998733, train loss: 10.713273, valid precision: 0.871600, valid loss: 89.388907
epoch: 1245, train precision: 0.998733, train loss: 10.785430, valid precision: 0.874600, valid loss: 89.878384
epoch: 1246, train precision: 0.998889, train loss: 10.733197, valid precision: 0.875200, valid loss: 89.257212
epoch: 1247, train precision: 0.998756, train loss: 10.783888, valid precision: 0.869600, valid loss: 88.522141
epoch: 1248, train precision: 0.998933, train loss: 10.764812, valid precision: 0.873200, valid loss: 87.548247
epoch: 1249, train precision: 0.998622, train loss: 10.722051, valid precision: 0.871800, valid loss: 89.283601
epoch: 1250, train precision: 0.998733, train loss: 10.726984, valid precision: 0.873600, valid loss: 89.807846
epoch: 1251, train precision: 0.998800, train loss: 10.737857, valid precision: 0.872600, valid loss: 91.525749
epoch: 1252, train precision: 0.999089, train loss: 10.605911, valid precision: 0.875000, valid loss: 88.965099
epoch: 1253, train precision: 0.998800, train loss: 10.676185, valid precision: 0.879400, valid loss: 89.170896
epoch: 1254, train precision: 0.998867, train loss: 10.732804, valid precision: 0.874200, valid loss: 89.613857
epoch: 1255, train precision: 0.998600, train loss: 10.790092, valid precision: 0.872000, valid loss: 91.642963
epoch: 1256, train precision: 0.998867, train loss: 10.691485, valid precision: 0.870200, valid loss: 90.300819
epoch: 1257, train precision: 0.998911, train loss: 10.695491, valid precision: 0.874600, valid loss: 89.194334
epoch: 1258, train precision: 0.998511, train loss: 10.853869, valid precision: 0.870800, valid loss: 91.794865
epoch: 1259, train precision: 0.998911, train loss: 10.750459, valid precision: 0.878600, valid loss: 88.155899
epoch: 1260, train precision: 0.999044, train loss: 10.644418, valid precision: 0.871600, valid loss: 89.876922
epoch: 1261, train precision: 0.998378, train loss: 10.809990, valid precision: 0.876000, valid loss: 90.693947
epoch: 1262, train precision: 0.999111, train loss: 10.641849, valid precision: 0.872600, valid loss: 89.285682
epoch: 1263, train precision: 0.998689, train loss: 10.773382, valid precision: 0.866400, valid loss: 92.661057
epoch: 1264, train precision: 0.998622, train loss: 10.811573, valid precision: 0.875400, valid loss: 89.399419
epoch: 1265, train precision: 0.998644, train loss: 10.779684, valid precision: 0.872800, valid loss: 92.697228
epoch: 1266, train precision: 0.998667, train loss: 10.824276, valid precision: 0.872000, valid loss: 92.418376
epoch: 1267, train precision: 0.998444, train loss: 10.881828, valid precision: 0.875000, valid loss: 92.734566
epoch: 1268, train precision: 0.998822, train loss: 10.753853, valid precision: 0.876400, valid loss: 89.096378
epoch: 1269, train precision: 0.998800, train loss: 10.813746, valid precision: 0.873800, valid loss: 89.715502
epoch: 1270, train precision: 0.998422, train loss: 10.939815, valid precision: 0.874000, valid loss: 90.969803
epoch: 1271, train precision: 0.999000, train loss: 10.711558, valid precision: 0.876400, valid loss: 90.624305
epoch: 1272, train precision: 0.999089, train loss: 10.727171, valid precision: 0.873400, valid loss: 89.837434
epoch: 1273, train precision: 0.998844, train loss: 10.712214, valid precision: 0.871600, valid loss: 90.428026
epoch: 1274, train precision: 0.997844, train loss: 10.965587, valid precision: 0.873400, valid loss: 90.077917
epoch: 1275, train precision: 0.998756, train loss: 10.794393, valid precision: 0.876600, valid loss: 89.057342
epoch: 1276, train precision: 0.998667, train loss: 10.837543, valid precision: 0.875200, valid loss: 91.754599
epoch: 1277, train precision: 0.998889, train loss: 10.697831, valid precision: 0.875000, valid loss: 89.196728
epoch: 1278, train precision: 0.998333, train loss: 10.979041, valid precision: 0.870600, valid loss: 90.072390
epoch: 1279, train precision: 0.998844, train loss: 10.661092, valid precision: 0.874600, valid loss: 89.339015
epoch: 1280, train precision: 0.998778, train loss: 10.693623, valid precision: 0.873800, valid loss: 88.964084
epoch: 1281, train precision: 0.998622, train loss: 10.831386, valid precision: 0.869400, valid loss: 89.146932
epoch: 1282, train precision: 0.998511, train loss: 10.791053, valid precision: 0.875000, valid loss: 88.911443
epoch: 1283, train precision: 0.998044, train loss: 10.888298, valid precision: 0.870000, valid loss: 91.412479
epoch: 1284, train precision: 0.998711, train loss: 10.762104, valid precision: 0.872600, valid loss: 89.339710
epoch: 1285, train precision: 0.998578, train loss: 10.749090, valid precision: 0.872800, valid loss: 90.130277
epoch: 1286, train precision: 0.998556, train loss: 10.765312, valid precision: 0.872000, valid loss: 89.076139
epoch: 1287, train precision: 0.998911, train loss: 10.691897, valid precision: 0.872400, valid loss: 89.649103
epoch: 1288, train precision: 0.998800, train loss: 10.736760, valid precision: 0.873200, valid loss: 88.798676
epoch: 1289, train precision: 0.998289, train loss: 10.902857, valid precision: 0.871600, valid loss: 89.775431
epoch: 1290, train precision: 0.999000, train loss: 10.641270, valid precision: 0.876400, valid loss: 88.146879
epoch: 1291, train precision: 0.998889, train loss: 10.714116, valid precision: 0.877200, valid loss: 85.702038
epoch: 1292, train precision: 0.998511, train loss: 10.804209, valid precision: 0.874800, valid loss: 90.095776
epoch: 1293, train precision: 0.998644, train loss: 10.720202, valid precision: 0.873800, valid loss: 88.117523
epoch: 1294, train precision: 0.998933, train loss: 10.681995, valid precision: 0.874000, valid loss: 88.574097
epoch: 1295, train precision: 0.998711, train loss: 10.795382, valid precision: 0.872800, valid loss: 89.087120
epoch: 1296, train precision: 0.998822, train loss: 10.735897, valid precision: 0.875600, valid loss: 90.845940
epoch: 1297, train precision: 0.998822, train loss: 10.731723, valid precision: 0.869200, valid loss: 91.148337
epoch: 1298, train precision: 0.998689, train loss: 10.768404, valid precision: 0.872200, valid loss: 90.828843
epoch: 1299, train precision: 0.999133, train loss: 10.594179, valid precision: 0.875000, valid loss: 89.409586
epoch: 1300, train precision: 0.998489, train loss: 10.848065, valid precision: 0.871000, valid loss: 91.952434
epoch: 1301, train precision: 0.998956, train loss: 10.619412, valid precision: 0.874200, valid loss: 90.837595
epoch: 1302, train precision: 0.998822, train loss: 10.705337, valid precision: 0.872400, valid loss: 92.094141
epoch: 1303, train precision: 0.998400, train loss: 10.933235, valid precision: 0.874800, valid loss: 90.868642
epoch: 1304, train precision: 0.998667, train loss: 10.799734, valid precision: 0.871800, valid loss: 92.103111
epoch: 1305, train precision: 0.998778, train loss: 10.701393, valid precision: 0.876800, valid loss: 91.080234
epoch: 1306, train precision: 0.998689, train loss: 10.734438, valid precision: 0.875400, valid loss: 93.067814
epoch: 1307, train precision: 0.998956, train loss: 10.731470, valid precision: 0.874200, valid loss: 92.676465
epoch: 1308, train precision: 0.998867, train loss: 10.633732, valid precision: 0.874800, valid loss: 91.916845
epoch: 1309, train precision: 0.998867, train loss: 10.743061, valid precision: 0.872400, valid loss: 94.037060
epoch: 1310, train precision: 0.998800, train loss: 10.708389, valid precision: 0.872000, valid loss: 90.650770
epoch: 1311, train precision: 0.998644, train loss: 10.727090, valid precision: 0.872400, valid loss: 91.328518
epoch: 1312, train precision: 0.998800, train loss: 10.721710, valid precision: 0.872200, valid loss: 91.953400
epoch: 1313, train precision: 0.998822, train loss: 10.690735, valid precision: 0.873000, valid loss: 89.379102
epoch: 1314, train precision: 0.998933, train loss: 10.702592, valid precision: 0.873600, valid loss: 88.994600
epoch: 1315, train precision: 0.998689, train loss: 10.686645, valid precision: 0.875400, valid loss: 89.202415
epoch: 1316, train precision: 0.998844, train loss: 10.686076, valid precision: 0.872400, valid loss: 91.791393
epoch: 1317, train precision: 0.998933, train loss: 10.708541, valid precision: 0.877400, valid loss: 89.424375
epoch: 1318, train precision: 0.998311, train loss: 10.930050, valid precision: 0.872400, valid loss: 90.359992
epoch: 1319, train precision: 0.999133, train loss: 10.625265, valid precision: 0.874200, valid loss: 91.517489
epoch: 1320, train precision: 0.998022, train loss: 10.888697, valid precision: 0.867600, valid loss: 92.527335
epoch: 1321, train precision: 0.998600, train loss: 10.762108, valid precision: 0.871800, valid loss: 90.362518
epoch: 1322, train precision: 0.998867, train loss: 10.694206, valid precision: 0.869000, valid loss: 93.203885
epoch: 1323, train precision: 0.998289, train loss: 10.869117, valid precision: 0.872800, valid loss: 92.623775
epoch: 1324, train precision: 0.998000, train loss: 10.888789, valid precision: 0.870800, valid loss: 90.459947
epoch: 1325, train precision: 0.999089, train loss: 10.646274, valid precision: 0.870800, valid loss: 91.327692
epoch: 1326, train precision: 0.998733, train loss: 10.740951, valid precision: 0.872400, valid loss: 92.351626
epoch: 1327, train precision: 0.998600, train loss: 10.764727, valid precision: 0.870200, valid loss: 91.184313
epoch: 1328, train precision: 0.998600, train loss: 10.801199, valid precision: 0.874600, valid loss: 86.787944
epoch: 1329, train precision: 0.998533, train loss: 10.854946, valid precision: 0.875200, valid loss: 88.835024
epoch: 1330, train precision: 0.998756, train loss: 10.722592, valid precision: 0.872400, valid loss: 87.855847
epoch: 1331, train precision: 0.998556, train loss: 10.781471, valid precision: 0.873800, valid loss: 90.221608
epoch: 1332, train precision: 0.998756, train loss: 10.749089, valid precision: 0.871600, valid loss: 88.857035
epoch: 1333, train precision: 0.998756, train loss: 10.785487, valid precision: 0.870000, valid loss: 89.434312
epoch: 1334, train precision: 0.999089, train loss: 10.657744, valid precision: 0.874200, valid loss: 90.617809
epoch: 1335, train precision: 0.998956, train loss: 10.709343, valid precision: 0.876600, valid loss: 89.714612
epoch: 1336, train precision: 0.998644, train loss: 10.770566, valid precision: 0.876400, valid loss: 89.537257
epoch: 1337, train precision: 0.998933, train loss: 10.680694, valid precision: 0.875400, valid loss: 88.247901
epoch: 1338, train precision: 0.999156, train loss: 10.608792, valid precision: 0.875600, valid loss: 88.107770
epoch: 1339, train precision: 0.998667, train loss: 10.801699, valid precision: 0.877200, valid loss: 88.376065
epoch: 1340, train precision: 0.998600, train loss: 10.774754, valid precision: 0.877600, valid loss: 89.806233
epoch: 1341, train precision: 0.998422, train loss: 10.961859, valid precision: 0.871800, valid loss: 88.038279
epoch: 1342, train precision: 0.998756, train loss: 10.712226, valid precision: 0.875200, valid loss: 88.784031
epoch: 1343, train precision: 0.998933, train loss: 10.628090, valid precision: 0.875600, valid loss: 90.763554
epoch: 1344, train precision: 0.998978, train loss: 10.631160, valid precision: 0.876800, valid loss: 88.514362
epoch: 1345, train precision: 0.998800, train loss: 10.742607, valid precision: 0.871600, valid loss: 91.415565
epoch: 1346, train precision: 0.998711, train loss: 10.751298, valid precision: 0.872600, valid loss: 92.676031
epoch: 1347, train precision: 0.998711, train loss: 10.752711, valid precision: 0.873800, valid loss: 91.926856
epoch: 1348, train precision: 0.998622, train loss: 10.808475, valid precision: 0.874800, valid loss: 89.012519
epoch: 1349, train precision: 0.999044, train loss: 10.608348, valid precision: 0.873600, valid loss: 92.293119
epoch: 1350, train precision: 0.999111, train loss: 10.605846, valid precision: 0.871600, valid loss: 92.162477
epoch: 1351, train precision: 0.998622, train loss: 10.689782, valid precision: 0.873600, valid loss: 91.203548
epoch: 1352, train precision: 0.998711, train loss: 10.722000, valid precision: 0.870600, valid loss: 93.884074
epoch: 1353, train precision: 0.998667, train loss: 10.757376, valid precision: 0.871800, valid loss: 90.631604
epoch: 1354, train precision: 0.998644, train loss: 10.728784, valid precision: 0.871800, valid loss: 93.313072
epoch: 1355, train precision: 0.998711, train loss: 10.771940, valid precision: 0.873400, valid loss: 91.390057
epoch: 1356, train precision: 0.998511, train loss: 10.822202, valid precision: 0.873800, valid loss: 93.620215
epoch: 1357, train precision: 0.998578, train loss: 10.730707, valid precision: 0.871000, valid loss: 91.274893
epoch: 1358, train precision: 0.998889, train loss: 10.750729, valid precision: 0.872000, valid loss: 91.879770
epoch: 1359, train precision: 0.998867, train loss: 10.694854, valid precision: 0.869800, valid loss: 90.256945
epoch: 1360, train precision: 0.999156, train loss: 10.625626, valid precision: 0.875400, valid loss: 91.110439
epoch: 1361, train precision: 0.998111, train loss: 10.928590, valid precision: 0.869000, valid loss: 92.144730
epoch: 1362, train precision: 0.999200, train loss: 10.556839, valid precision: 0.873600, valid loss: 93.658184
epoch: 1363, train precision: 0.999200, train loss: 10.641574, valid precision: 0.872200, valid loss: 91.042686
epoch: 1364, train precision: 0.998689, train loss: 10.727347, valid precision: 0.866800, valid loss: 93.356351
epoch: 1365, train precision: 0.999289, train loss: 10.549962, valid precision: 0.876000, valid loss: 89.503604
epoch: 1366, train precision: 0.999200, train loss: 10.588101, valid precision: 0.873800, valid loss: 89.504557
epoch: 1367, train precision: 0.999022, train loss: 10.663552, valid precision: 0.874200, valid loss: 88.536602
epoch: 1368, train precision: 0.998711, train loss: 10.716195, valid precision: 0.874000, valid loss: 91.363910
epoch: 1369, train precision: 0.998578, train loss: 10.755064, valid precision: 0.873600, valid loss: 90.529882
epoch: 1370, train precision: 0.999044, train loss: 10.655015, valid precision: 0.873800, valid loss: 93.518343
epoch: 1371, train precision: 0.998533, train loss: 10.804384, valid precision: 0.874400, valid loss: 90.405179
epoch: 1372, train precision: 0.998889, train loss: 10.720093, valid precision: 0.875000, valid loss: 90.848617
epoch: 1373, train precision: 0.998911, train loss: 10.705923, valid precision: 0.875200, valid loss: 91.242322
epoch: 1374, train precision: 0.998422, train loss: 10.864937, valid precision: 0.872200, valid loss: 93.424155
epoch: 1375, train precision: 0.999022, train loss: 10.675148, valid precision: 0.873600, valid loss: 93.072239
epoch: 1376, train precision: 0.998356, train loss: 10.843834, valid precision: 0.868600, valid loss: 93.759570
epoch: 1377, train precision: 0.998822, train loss: 10.706953, valid precision: 0.874000, valid loss: 90.301071
epoch: 1378, train precision: 0.998578, train loss: 10.840076, valid precision: 0.871800, valid loss: 91.249097
epoch: 1379, train precision: 0.998911, train loss: 10.688815, valid precision: 0.872000, valid loss: 92.070198
epoch: 1380, train precision: 0.999156, train loss: 10.639457, valid precision: 0.876200, valid loss: 88.805987
epoch: 1381, train precision: 0.998800, train loss: 10.725999, valid precision: 0.870400, valid loss: 91.769970
epoch: 1382, train precision: 0.998778, train loss: 10.703705, valid precision: 0.870000, valid loss: 91.596475
epoch: 1383, train precision: 0.998978, train loss: 10.660798, valid precision: 0.874800, valid loss: 89.655020
epoch: 1384, train precision: 0.998933, train loss: 10.684894, valid precision: 0.869200, valid loss: 90.818674
epoch: 1385, train precision: 0.998778, train loss: 10.763737, valid precision: 0.873200, valid loss: 90.561481
epoch: 1386, train precision: 0.998667, train loss: 10.693109, valid precision: 0.873600, valid loss: 89.300462
epoch: 1387, train precision: 0.998867, train loss: 10.731777, valid precision: 0.871400, valid loss: 91.602505
epoch: 1388, train precision: 0.998533, train loss: 10.778293, valid precision: 0.871600, valid loss: 91.614266
epoch: 1389, train precision: 0.998800, train loss: 10.697746, valid precision: 0.873200, valid loss: 90.747843
epoch: 1390, train precision: 0.998756, train loss: 10.680230, valid precision: 0.876600, valid loss: 90.564808
epoch: 1391, train precision: 0.998644, train loss: 10.726838, valid precision: 0.873600, valid loss: 90.180790
epoch: 1392, train precision: 0.998889, train loss: 10.649912, valid precision: 0.878400, valid loss: 88.465964
epoch: 1393, train precision: 0.998867, train loss: 10.666372, valid precision: 0.879000, valid loss: 90.377383
epoch: 1394, train precision: 0.998844, train loss: 10.680762, valid precision: 0.873400, valid loss: 90.671919
epoch: 1395, train precision: 0.998600, train loss: 10.720933, valid precision: 0.873200, valid loss: 89.253708
epoch: 1396, train precision: 0.998800, train loss: 10.710228, valid precision: 0.875400, valid loss: 90.477539
epoch: 1397, train precision: 0.999311, train loss: 10.597916, valid precision: 0.873600, valid loss: 89.763580
epoch: 1398, train precision: 0.998911, train loss: 10.740884, valid precision: 0.875400, valid loss: 89.972211
epoch: 1399, train precision: 0.998822, train loss: 10.693211, valid precision: 0.876000, valid loss: 91.716678
epoch: 1400, train precision: 0.998911, train loss: 10.699303, valid precision: 0.869200, valid loss: 91.084188
epoch: 1401, train precision: 0.999000, train loss: 10.707738, valid precision: 0.872600, valid loss: 90.295881
epoch: 1402, train precision: 0.998800, train loss: 10.676643, valid precision: 0.871800, valid loss: 91.597078
epoch: 1403, train precision: 0.999178, train loss: 10.627137, valid precision: 0.871800, valid loss: 92.309650
epoch: 1404, train precision: 0.998689, train loss: 10.774640, valid precision: 0.873600, valid loss: 90.623936
epoch: 1405, train precision: 0.998578, train loss: 10.744400, valid precision: 0.872800, valid loss: 90.565664
epoch: 1406, train precision: 0.998822, train loss: 10.674858, valid precision: 0.875000, valid loss: 91.860879
epoch: 1407, train precision: 0.998844, train loss: 10.650307, valid precision: 0.873000, valid loss: 91.816608
epoch: 1408, train precision: 0.998756, train loss: 10.754348, valid precision: 0.875400, valid loss: 91.101797
epoch: 1409, train precision: 0.998156, train loss: 10.918612, valid precision: 0.869200, valid loss: 92.273906
epoch: 1410, train precision: 0.998711, train loss: 10.673747, valid precision: 0.873600, valid loss: 93.179083
epoch: 1411, train precision: 0.998600, train loss: 10.822362, valid precision: 0.868800, valid loss: 94.113834
epoch: 1412, train precision: 0.998756, train loss: 10.759685, valid precision: 0.868400, valid loss: 92.479509
epoch: 1413, train precision: 0.998622, train loss: 10.729167, valid precision: 0.872000, valid loss: 90.250093
epoch: 1414, train precision: 0.999044, train loss: 10.690298, valid precision: 0.871000, valid loss: 90.921007
epoch: 1415, train precision: 0.999133, train loss: 10.672728, valid precision: 0.869400, valid loss: 92.074244
epoch: 1416, train precision: 0.998733, train loss: 10.706191, valid precision: 0.870600, valid loss: 94.128235
epoch: 1417, train precision: 0.998711, train loss: 10.729481, valid precision: 0.869600, valid loss: 94.342312
epoch: 1418, train precision: 0.998622, train loss: 10.791708, valid precision: 0.872800, valid loss: 92.915416
epoch: 1419, train precision: 0.998933, train loss: 10.692583, valid precision: 0.872800, valid loss: 90.692087
epoch: 1420, train precision: 0.998711, train loss: 10.704089, valid precision: 0.874600, valid loss: 92.382575
epoch: 1421, train precision: 0.998467, train loss: 10.835138, valid precision: 0.870800, valid loss: 92.330905
epoch: 1422, train precision: 0.998911, train loss: 10.705826, valid precision: 0.870000, valid loss: 92.930234
epoch: 1423, train precision: 0.998644, train loss: 10.761174, valid precision: 0.875600, valid loss: 93.006856
epoch: 1424, train precision: 0.998689, train loss: 10.815426, valid precision: 0.874200, valid loss: 94.181633
epoch: 1425, train precision: 0.999089, train loss: 10.658542, valid precision: 0.873000, valid loss: 93.471390
epoch: 1426, train precision: 0.998778, train loss: 10.755999, valid precision: 0.875400, valid loss: 91.492650
epoch: 1427, train precision: 0.998867, train loss: 10.692377, valid precision: 0.872800, valid loss: 91.858057
epoch: 1428, train precision: 0.998600, train loss: 10.764943, valid precision: 0.872200, valid loss: 90.481207
epoch: 1429, train precision: 0.999089, train loss: 10.626979, valid precision: 0.874800, valid loss: 89.951173
epoch: 1430, train precision: 0.998556, train loss: 10.799524, valid precision: 0.873800, valid loss: 89.722708
epoch: 1431, train precision: 0.998800, train loss: 10.736611, valid precision: 0.874000, valid loss: 88.830274
epoch: 1432, train precision: 0.998800, train loss: 10.796411, valid precision: 0.872200, valid loss: 91.044677
epoch: 1433, train precision: 0.998844, train loss: 10.729635, valid precision: 0.871600, valid loss: 91.004780
epoch: 1434, train precision: 0.998311, train loss: 10.845932, valid precision: 0.873800, valid loss: 90.869433
epoch: 1435, train precision: 0.999089, train loss: 10.684264, valid precision: 0.874800, valid loss: 88.092233
epoch: 1436, train precision: 0.998711, train loss: 10.788436, valid precision: 0.871800, valid loss: 92.677999
epoch: 1437, train precision: 0.998867, train loss: 10.715994, valid precision: 0.870800, valid loss: 92.540902
epoch: 1438, train precision: 0.998667, train loss: 10.752046, valid precision: 0.871200, valid loss: 93.541300
epoch: 1439, train precision: 0.998778, train loss: 10.780308, valid precision: 0.876400, valid loss: 90.624546
epoch: 1440, train precision: 0.998600, train loss: 10.731769, valid precision: 0.868800, valid loss: 91.825991
epoch: 1441, train precision: 0.998889, train loss: 10.667751, valid precision: 0.874200, valid loss: 92.511760
epoch: 1442, train precision: 0.998711, train loss: 10.741219, valid precision: 0.876200, valid loss: 91.291247
epoch: 1443, train precision: 0.998311, train loss: 10.822935, valid precision: 0.876000, valid loss: 92.721366
epoch: 1444, train precision: 0.998889, train loss: 10.587031, valid precision: 0.877200, valid loss: 90.818240
epoch: 1445, train precision: 0.998756, train loss: 10.749388, valid precision: 0.874200, valid loss: 92.170690
epoch: 1446, train precision: 0.998644, train loss: 10.747432, valid precision: 0.869600, valid loss: 93.665334
epoch: 1447, train precision: 0.999000, train loss: 10.679488, valid precision: 0.875800, valid loss: 92.075869
epoch: 1448, train precision: 0.998689, train loss: 10.772122, valid precision: 0.874400, valid loss: 92.631059
epoch: 1449, train precision: 0.998822, train loss: 10.707633, valid precision: 0.869400, valid loss: 93.510777
epoch: 1450, train precision: 0.998844, train loss: 10.675373, valid precision: 0.872000, valid loss: 91.672667
epoch: 1451, train precision: 0.998956, train loss: 10.677294, valid precision: 0.878200, valid loss: 90.226309
epoch: 1452, train precision: 0.998800, train loss: 10.654058, valid precision: 0.878200, valid loss: 91.041879
epoch: 1453, train precision: 0.999000, train loss: 10.670580, valid precision: 0.876400, valid loss: 90.944760
epoch: 1454, train precision: 0.999067, train loss: 10.632829, valid precision: 0.874200, valid loss: 91.513370
epoch: 1455, train precision: 0.999000, train loss: 10.620895, valid precision: 0.876800, valid loss: 90.993593
epoch: 1456, train precision: 0.998533, train loss: 10.767145, valid precision: 0.877200, valid loss: 89.984615
epoch: 1457, train precision: 0.999022, train loss: 10.725147, valid precision: 0.872400, valid loss: 92.126150
epoch: 1458, train precision: 0.998911, train loss: 10.644402, valid precision: 0.879800, valid loss: 88.025616
epoch: 1459, train precision: 0.998867, train loss: 10.751207, valid precision: 0.874600, valid loss: 89.878180
epoch: 1460, train precision: 0.998578, train loss: 10.782066, valid precision: 0.871800, valid loss: 91.063945
epoch: 1461, train precision: 0.998756, train loss: 10.720128, valid precision: 0.877800, valid loss: 89.982366
epoch: 1462, train precision: 0.999067, train loss: 10.656087, valid precision: 0.875000, valid loss: 88.634444
epoch: 1463, train precision: 0.998378, train loss: 10.808534, valid precision: 0.873000, valid loss: 91.093634
epoch: 1464, train precision: 0.998756, train loss: 10.735111, valid precision: 0.874800, valid loss: 87.662855
epoch: 1465, train precision: 0.998800, train loss: 10.704875, valid precision: 0.873600, valid loss: 89.913563
epoch: 1466, train precision: 0.998889, train loss: 10.695902, valid precision: 0.877400, valid loss: 87.790521
epoch: 1467, train precision: 0.998889, train loss: 10.716614, valid precision: 0.876400, valid loss: 88.097009
epoch: 1468, train precision: 0.998556, train loss: 10.843624, valid precision: 0.879000, valid loss: 88.300732
epoch: 1469, train precision: 0.998556, train loss: 10.774272, valid precision: 0.875400, valid loss: 89.255149
epoch: 1470, train precision: 0.998756, train loss: 10.693887, valid precision: 0.875000, valid loss: 91.791934
epoch: 1471, train precision: 0.998489, train loss: 10.791324, valid precision: 0.878400, valid loss: 91.587617
epoch: 1472, train precision: 0.998356, train loss: 10.893294, valid precision: 0.869800, valid loss: 93.226996
epoch: 1473, train precision: 0.999178, train loss: 10.603120, valid precision: 0.875800, valid loss: 90.095706
epoch: 1474, train precision: 0.998578, train loss: 10.781118, valid precision: 0.878800, valid loss: 91.224949
epoch: 1475, train precision: 0.998978, train loss: 10.681443, valid precision: 0.872800, valid loss: 91.957706
epoch: 1476, train precision: 0.998511, train loss: 10.744930, valid precision: 0.870200, valid loss: 91.195044
epoch: 1477, train precision: 0.998889, train loss: 10.693243, valid precision: 0.868200, valid loss: 94.639313
epoch: 1478, train precision: 0.998889, train loss: 10.692076, valid precision: 0.869800, valid loss: 93.429493
epoch: 1479, train precision: 0.998911, train loss: 10.706166, valid precision: 0.871400, valid loss: 93.048019
epoch: 1480, train precision: 0.998933, train loss: 10.662556, valid precision: 0.869000, valid loss: 93.222054
epoch: 1481, train precision: 0.998689, train loss: 10.752945, valid precision: 0.869200, valid loss: 92.123411
epoch: 1482, train precision: 0.998644, train loss: 10.769869, valid precision: 0.869800, valid loss: 95.086685
epoch: 1483, train precision: 0.998956, train loss: 10.689111, valid precision: 0.878800, valid loss: 90.576194
epoch: 1484, train precision: 0.999111, train loss: 10.658005, valid precision: 0.874200, valid loss: 89.483374
epoch: 1485, train precision: 0.998844, train loss: 10.690493, valid precision: 0.875200, valid loss: 89.178499
epoch: 1486, train precision: 0.998933, train loss: 10.634026, valid precision: 0.877200, valid loss: 87.667966
epoch: 1487, train precision: 0.998556, train loss: 10.787192, valid precision: 0.875200, valid loss: 90.121313
epoch: 1488, train precision: 0.998778, train loss: 10.727950, valid precision: 0.874600, valid loss: 87.687121
epoch: 1489, train precision: 0.998444, train loss: 10.794960, valid precision: 0.875400, valid loss: 89.688784
epoch: 1490, train precision: 0.998978, train loss: 10.740159, valid precision: 0.875600, valid loss: 89.856365
epoch: 1491, train precision: 0.998978, train loss: 10.645869, valid precision: 0.873600, valid loss: 91.143826
epoch: 1492, train precision: 0.998756, train loss: 10.679265, valid precision: 0.873200, valid loss: 93.223036
epoch: 1493, train precision: 0.998600, train loss: 10.792885, valid precision: 0.874800, valid loss: 90.748576
epoch: 1494, train precision: 0.999133, train loss: 10.639927, valid precision: 0.874600, valid loss: 93.195816
epoch: 1495, train precision: 0.998889, train loss: 10.710761, valid precision: 0.875000, valid loss: 91.742785
epoch: 1496, train precision: 0.998756, train loss: 10.685674, valid precision: 0.874600, valid loss: 92.584516
epoch: 1497, train precision: 0.998978, train loss: 10.654454, valid precision: 0.877800, valid loss: 92.787071
epoch: 1498, train precision: 0.998667, train loss: 10.757195, valid precision: 0.876600, valid loss: 92.654423
epoch: 1499, train precision: 0.998644, train loss: 10.773874, valid precision: 0.879200, valid loss: 90.702440
epoch: 1500, train precision: 0.998800, train loss: 10.671203, valid precision: 0.879800, valid loss: 91.070224
epoch: 1501, train precision: 0.998689, train loss: 10.780606, valid precision: 0.875600, valid loss: 91.399132
epoch: 1502, train precision: 0.998733, train loss: 10.691076, valid precision: 0.874200, valid loss: 91.510071
epoch: 1503, train precision: 0.999089, train loss: 10.651776, valid precision: 0.874600, valid loss: 92.081450
epoch: 1504, train precision: 0.998556, train loss: 10.830867, valid precision: 0.875400, valid loss: 92.483032
epoch: 1505, train precision: 0.998556, train loss: 10.772604, valid precision: 0.877000, valid loss: 89.314172
epoch: 1506, train precision: 0.999067, train loss: 10.608074, valid precision: 0.873800, valid loss: 93.578352
epoch: 1507, train precision: 0.999022, train loss: 10.628435, valid precision: 0.873600, valid loss: 94.106673
epoch: 1508, train precision: 0.999000, train loss: 10.633816, valid precision: 0.873200, valid loss: 91.952642
epoch: 1509, train precision: 0.999067, train loss: 10.676002, valid precision: 0.874800, valid loss: 92.012810
epoch: 1510, train precision: 0.998911, train loss: 10.684106, valid precision: 0.873600, valid loss: 92.891185
epoch: 1511, train precision: 0.998689, train loss: 10.767457, valid precision: 0.874200, valid loss: 89.895808
epoch: 1512, train precision: 0.998844, train loss: 10.707946, valid precision: 0.876200, valid loss: 89.466254
epoch: 1513, train precision: 0.998844, train loss: 10.711543, valid precision: 0.878000, valid loss: 88.934475
epoch: 1514, train precision: 0.998978, train loss: 10.666832, valid precision: 0.876000, valid loss: 91.634837
epoch: 1515, train precision: 0.998800, train loss: 10.691930, valid precision: 0.876800, valid loss: 90.523316
epoch: 1516, train precision: 0.999044, train loss: 10.673702, valid precision: 0.879800, valid loss: 87.593149
epoch: 1517, train precision: 0.998844, train loss: 10.711878, valid precision: 0.874200, valid loss: 90.279462
epoch: 1518, train precision: 0.998822, train loss: 10.723734, valid precision: 0.877000, valid loss: 91.465466
epoch: 1519, train precision: 0.998756, train loss: 10.736206, valid precision: 0.877600, valid loss: 91.981904
epoch: 1520, train precision: 0.998622, train loss: 10.755691, valid precision: 0.870000, valid loss: 94.008755
epoch: 1521, train precision: 0.999000, train loss: 10.641331, valid precision: 0.874600, valid loss: 92.899201
epoch: 1522, train precision: 0.998822, train loss: 10.650219, valid precision: 0.872600, valid loss: 94.446797
epoch: 1523, train precision: 0.998711, train loss: 10.785001, valid precision: 0.875800, valid loss: 92.758853
epoch: 1524, train precision: 0.999022, train loss: 10.652866, valid precision: 0.873000, valid loss: 92.205973
epoch: 1525, train precision: 0.998533, train loss: 10.814911, valid precision: 0.874200, valid loss: 91.510072
epoch: 1526, train precision: 0.998933, train loss: 10.672014, valid precision: 0.874400, valid loss: 91.033431
epoch: 1527, train precision: 0.998956, train loss: 10.625899, valid precision: 0.873600, valid loss: 90.863110
epoch: 1528, train precision: 0.998311, train loss: 10.896594, valid precision: 0.876400, valid loss: 91.080854
epoch: 1529, train precision: 0.998400, train loss: 10.857865, valid precision: 0.875400, valid loss: 89.242724
epoch: 1530, train precision: 0.999133, train loss: 10.674618, valid precision: 0.871600, valid loss: 90.184434
epoch: 1531, train precision: 0.999000, train loss: 10.654415, valid precision: 0.874000, valid loss: 91.932569
epoch: 1532, train precision: 0.998689, train loss: 10.695154, valid precision: 0.877200, valid loss: 89.840567
epoch: 1533, train precision: 0.998578, train loss: 10.827319, valid precision: 0.872400, valid loss: 91.839516
epoch: 1534, train precision: 0.998644, train loss: 10.789172, valid precision: 0.874400, valid loss: 91.638845
epoch: 1535, train precision: 0.998489, train loss: 10.790931, valid precision: 0.873200, valid loss: 91.404739
epoch: 1536, train precision: 0.999244, train loss: 10.561246, valid precision: 0.873000, valid loss: 92.038085
epoch: 1537, train precision: 0.998778, train loss: 10.724290, valid precision: 0.873600, valid loss: 92.535433
epoch: 1538, train precision: 0.998711, train loss: 10.672449, valid precision: 0.874400, valid loss: 89.839623
epoch: 1539, train precision: 0.998933, train loss: 10.742747, valid precision: 0.875800, valid loss: 89.498851
epoch: 1540, train precision: 0.998533, train loss: 10.805069, valid precision: 0.872800, valid loss: 90.001683
epoch: 1541, train precision: 0.999289, train loss: 10.591900, valid precision: 0.873600, valid loss: 93.108836
epoch: 1542, train precision: 0.998844, train loss: 10.714242, valid precision: 0.874400, valid loss: 90.642995
epoch: 1543, train precision: 0.999089, train loss: 10.684951, valid precision: 0.876000, valid loss: 92.280968
epoch: 1544, train precision: 0.998800, train loss: 10.720980, valid precision: 0.877200, valid loss: 91.181439
epoch: 1545, train precision: 0.998511, train loss: 10.789243, valid precision: 0.873400, valid loss: 91.173346
epoch: 1546, train precision: 0.998667, train loss: 10.760057, valid precision: 0.877400, valid loss: 88.526738
epoch: 1547, train precision: 0.998711, train loss: 10.751755, valid precision: 0.879000, valid loss: 88.859604
epoch: 1548, train precision: 0.999022, train loss: 10.643652, valid precision: 0.880600, valid loss: 87.944378
epoch: 1549, train precision: 0.998933, train loss: 10.664795, valid precision: 0.880000, valid loss: 88.519401
epoch: 1550, train precision: 0.998844, train loss: 10.673640, valid precision: 0.878200, valid loss: 89.806019
epoch: 1551, train precision: 0.999000, train loss: 10.622983, valid precision: 0.877600, valid loss: 88.673504
epoch: 1552, train precision: 0.998756, train loss: 10.691672, valid precision: 0.873400, valid loss: 92.339514
epoch: 1553, train precision: 0.998378, train loss: 10.802017, valid precision: 0.876800, valid loss: 91.913048
epoch: 1554, train precision: 0.998422, train loss: 10.832245, valid precision: 0.879200, valid loss: 89.622636
epoch: 1555, train precision: 0.999022, train loss: 10.684071, valid precision: 0.877600, valid loss: 90.180068
epoch: 1556, train precision: 0.999267, train loss: 10.618981, valid precision: 0.880000, valid loss: 89.429635
epoch: 1557, train precision: 0.998956, train loss: 10.622097, valid precision: 0.876200, valid loss: 92.261796
epoch: 1558, train precision: 0.998933, train loss: 10.665470, valid precision: 0.881000, valid loss: 89.294817
epoch: 1559, train precision: 0.998667, train loss: 10.690019, valid precision: 0.874000, valid loss: 91.257055
epoch: 1560, train precision: 0.998556, train loss: 10.736745, valid precision: 0.877800, valid loss: 91.147454
epoch: 1561, train precision: 0.998956, train loss: 10.632656, valid precision: 0.876800, valid loss: 92.908672
epoch: 1562, train precision: 0.998689, train loss: 10.913205, valid precision: 0.875000, valid loss: 90.383325
epoch: 1563, train precision: 0.998889, train loss: 10.707828, valid precision: 0.879800, valid loss: 89.402746
epoch: 1564, train precision: 0.998889, train loss: 10.645017, valid precision: 0.879000, valid loss: 89.947661
epoch: 1565, train precision: 0.999156, train loss: 10.609836, valid precision: 0.876000, valid loss: 90.400625
epoch: 1566, train precision: 0.999111, train loss: 10.647292, valid precision: 0.873800, valid loss: 89.909319
epoch: 1567, train precision: 0.998889, train loss: 10.665814, valid precision: 0.877200, valid loss: 89.314521
epoch: 1568, train precision: 0.998867, train loss: 10.705967, valid precision: 0.879600, valid loss: 90.099782
epoch: 1569, train precision: 0.998622, train loss: 10.811804, valid precision: 0.876000, valid loss: 90.025786
epoch: 1570, train precision: 0.999156, train loss: 10.578160, valid precision: 0.877000, valid loss: 89.264932
epoch: 1571, train precision: 0.998711, train loss: 10.709807, valid precision: 0.878200, valid loss: 92.167060
epoch: 1572, train precision: 0.998867, train loss: 10.707180, valid precision: 0.872400, valid loss: 92.792500
epoch: 1573, train precision: 0.999000, train loss: 10.632683, valid precision: 0.877800, valid loss: 89.334699
epoch: 1574, train precision: 0.998911, train loss: 10.707857, valid precision: 0.879000, valid loss: 87.291892
epoch: 1575, train precision: 0.998933, train loss: 10.642606, valid precision: 0.876600, valid loss: 89.006994
epoch: 1576, train precision: 0.998778, train loss: 10.681493, valid precision: 0.874600, valid loss: 89.289225
epoch: 1577, train precision: 0.999044, train loss: 10.634346, valid precision: 0.877800, valid loss: 88.697023
epoch: 1578, train precision: 0.999067, train loss: 10.587859, valid precision: 0.874800, valid loss: 89.367849
epoch: 1579, train precision: 0.998667, train loss: 10.768100, valid precision: 0.879400, valid loss: 87.937314
epoch: 1580, train precision: 0.998778, train loss: 10.718952, valid precision: 0.876600, valid loss: 89.004464
epoch: 1581, train precision: 0.998578, train loss: 10.774678, valid precision: 0.876600, valid loss: 90.892200
epoch: 1582, train precision: 0.998889, train loss: 10.709899, valid precision: 0.875800, valid loss: 89.290864
epoch: 1583, train precision: 0.998511, train loss: 10.821696, valid precision: 0.870800, valid loss: 92.443442
epoch: 1584, train precision: 0.999022, train loss: 10.649010, valid precision: 0.874600, valid loss: 92.534307
epoch: 1585, train precision: 0.998667, train loss: 10.735305, valid precision: 0.874600, valid loss: 89.692715
epoch: 1586, train precision: 0.999067, train loss: 10.630019, valid precision: 0.874600, valid loss: 89.361163
epoch: 1587, train precision: 0.998756, train loss: 10.690383, valid precision: 0.873600, valid loss: 90.016249
epoch: 1588, train precision: 0.998800, train loss: 10.709633, valid precision: 0.876200, valid loss: 88.044980
epoch: 1589, train precision: 0.998578, train loss: 10.755599, valid precision: 0.876000, valid loss: 90.818684
epoch: 1590, train precision: 0.998911, train loss: 10.654059, valid precision: 0.879200, valid loss: 90.607439
epoch: 1591, train precision: 0.998978, train loss: 10.619967, valid precision: 0.875600, valid loss: 89.905766
epoch: 1592, train precision: 0.999044, train loss: 10.620804, valid precision: 0.875200, valid loss: 90.347969
epoch: 1593, train precision: 0.998933, train loss: 10.665653, valid precision: 0.875200, valid loss: 89.623936
epoch: 1594, train precision: 0.999044, train loss: 10.649495, valid precision: 0.876200, valid loss: 90.470203
epoch: 1595, train precision: 0.998756, train loss: 10.657910, valid precision: 0.873800, valid loss: 91.490027
epoch: 1596, train precision: 0.998622, train loss: 10.721073, valid precision: 0.875200, valid loss: 92.882902
epoch: 1597, train precision: 0.998400, train loss: 10.818580, valid precision: 0.875800, valid loss: 93.665958
epoch: 1598, train precision: 0.998756, train loss: 10.661550, valid precision: 0.871200, valid loss: 93.037058
epoch: 1599, train precision: 0.998844, train loss: 10.673867, valid precision: 0.876000, valid loss: 92.168513
epoch: 1600, train precision: 0.998956, train loss: 10.595240, valid precision: 0.873800, valid loss: 92.070933
epoch: 1601, train precision: 0.998978, train loss: 10.640799, valid precision: 0.874400, valid loss: 95.650688
epoch: 1602, train precision: 0.998600, train loss: 10.790846, valid precision: 0.872200, valid loss: 93.514333
epoch: 1603, train precision: 0.999289, train loss: 10.532632, valid precision: 0.876400, valid loss: 92.162698
epoch: 1604, train precision: 0.998378, train loss: 10.795571, valid precision: 0.873200, valid loss: 93.935707
epoch: 1605, train precision: 0.999044, train loss: 10.680077, valid precision: 0.878600, valid loss: 92.400063
epoch: 1606, train precision: 0.999022, train loss: 10.690196, valid precision: 0.879600, valid loss: 91.358976
epoch: 1607, train precision: 0.998978, train loss: 10.669554, valid precision: 0.877800, valid loss: 91.988575
epoch: 1608, train precision: 0.999067, train loss: 10.627643, valid precision: 0.877200, valid loss: 89.895570
epoch: 1609, train precision: 0.998978, train loss: 10.604898, valid precision: 0.880800, valid loss: 89.699531
epoch: 1610, train precision: 0.998867, train loss: 10.621772, valid precision: 0.875400, valid loss: 92.269171
epoch: 1611, train precision: 0.998889, train loss: 10.701947, valid precision: 0.878400, valid loss: 91.062817
epoch: 1612, train precision: 0.998978, train loss: 10.584923, valid precision: 0.878400, valid loss: 92.002172
epoch: 1613, train precision: 0.998844, train loss: 10.754137, valid precision: 0.876400, valid loss: 93.229808
epoch: 1614, train precision: 0.998733, train loss: 10.727749, valid precision: 0.874600, valid loss: 91.427155
epoch: 1615, train precision: 0.999089, train loss: 10.616312, valid precision: 0.877800, valid loss: 89.483374
epoch: 1616, train precision: 0.999044, train loss: 10.631594, valid precision: 0.877000, valid loss: 90.051171
epoch: 1617, train precision: 0.999244, train loss: 10.604282, valid precision: 0.872400, valid loss: 90.645937
epoch: 1618, train precision: 0.999067, train loss: 10.638023, valid precision: 0.875800, valid loss: 89.338864
epoch: 1619, train precision: 0.999089, train loss: 10.595640, valid precision: 0.878000, valid loss: 90.340878
epoch: 1620, train precision: 0.998533, train loss: 10.829281, valid precision: 0.875000, valid loss: 93.257150
epoch: 1621, train precision: 0.998867, train loss: 10.645381, valid precision: 0.876600, valid loss: 88.497767
epoch: 1622, train precision: 0.998844, train loss: 10.667831, valid precision: 0.877800, valid loss: 90.854042
epoch: 1623, train precision: 0.998267, train loss: 10.824056, valid precision: 0.878600, valid loss: 90.518103
epoch: 1624, train precision: 0.998956, train loss: 10.633132, valid precision: 0.877400, valid loss: 88.402682
epoch: 1625, train precision: 0.998644, train loss: 10.765532, valid precision: 0.877800, valid loss: 92.114002
epoch: 1626, train precision: 0.998800, train loss: 10.694070, valid precision: 0.876400, valid loss: 92.211561
epoch: 1627, train precision: 0.999133, train loss: 10.611129, valid precision: 0.880400, valid loss: 88.850703
epoch: 1628, train precision: 0.998644, train loss: 10.811442, valid precision: 0.878600, valid loss: 90.740366
epoch: 1629, train precision: 0.998822, train loss: 10.668984, valid precision: 0.878800, valid loss: 88.866186
epoch: 1630, train precision: 0.998644, train loss: 10.738302, valid precision: 0.878200, valid loss: 89.393015
epoch: 1631, train precision: 0.999178, train loss: 10.586889, valid precision: 0.879800, valid loss: 88.182844
epoch: 1632, train precision: 0.998311, train loss: 10.866406, valid precision: 0.876800, valid loss: 89.019426
epoch: 1633, train precision: 0.998667, train loss: 10.758303, valid precision: 0.877400, valid loss: 87.638185
epoch: 1634, train precision: 0.998422, train loss: 10.806302, valid precision: 0.879000, valid loss: 89.758564
epoch: 1635, train precision: 0.998956, train loss: 10.676580, valid precision: 0.878600, valid loss: 86.934874
epoch: 1636, train precision: 0.999156, train loss: 10.605983, valid precision: 0.881200, valid loss: 88.183067
epoch: 1637, train precision: 0.998956, train loss: 10.664248, valid precision: 0.877800, valid loss: 88.431633
epoch: 1638, train precision: 0.998911, train loss: 10.717111, valid precision: 0.877400, valid loss: 89.615680
epoch: 1639, train precision: 0.998978, train loss: 10.653389, valid precision: 0.879000, valid loss: 87.146446
epoch: 1640, train precision: 0.998956, train loss: 10.654965, valid precision: 0.875200, valid loss: 89.226464
epoch: 1641, train precision: 0.998733, train loss: 10.716666, valid precision: 0.874200, valid loss: 88.922594
epoch: 1642, train precision: 0.998822, train loss: 10.636624, valid precision: 0.879200, valid loss: 89.217909
epoch: 1643, train precision: 0.998067, train loss: 10.841187, valid precision: 0.876200, valid loss: 91.996475
epoch: 1644, train precision: 0.999022, train loss: 10.653668, valid precision: 0.878000, valid loss: 90.496720
epoch: 1645, train precision: 0.998489, train loss: 10.814733, valid precision: 0.882400, valid loss: 89.568600
epoch: 1646, train precision: 0.998933, train loss: 10.687362, valid precision: 0.875400, valid loss: 90.593909
epoch: 1647, train precision: 0.998911, train loss: 10.690056, valid precision: 0.881000, valid loss: 90.378339
epoch: 1648, train precision: 0.998133, train loss: 10.859727, valid precision: 0.875000, valid loss: 93.369016
epoch: 1649, train precision: 0.998867, train loss: 10.645029, valid precision: 0.879200, valid loss: 89.845302
epoch: 1650, train precision: 0.998267, train loss: 10.902521, valid precision: 0.870200, valid loss: 89.898272
epoch: 1651, train precision: 0.998889, train loss: 10.655203, valid precision: 0.875000, valid loss: 89.151957
epoch: 1652, train precision: 0.998733, train loss: 10.697130, valid precision: 0.873400, valid loss: 89.019653
epoch: 1653, train precision: 0.999089, train loss: 10.525170, valid precision: 0.876200, valid loss: 91.449040
epoch: 1654, train precision: 0.998733, train loss: 10.742861, valid precision: 0.874400, valid loss: 92.127112
epoch: 1655, train precision: 0.998489, train loss: 10.842809, valid precision: 0.874000, valid loss: 93.724892
epoch: 1656, train precision: 0.998867, train loss: 10.627478, valid precision: 0.876000, valid loss: 90.054918
epoch: 1657, train precision: 0.998067, train loss: 10.990628, valid precision: 0.872200, valid loss: 91.677546
epoch: 1658, train precision: 0.998978, train loss: 10.697665, valid precision: 0.877000, valid loss: 90.299167
epoch: 1659, train precision: 0.998800, train loss: 10.705626, valid precision: 0.875000, valid loss: 92.712336
epoch: 1660, train precision: 0.998933, train loss: 10.642396, valid precision: 0.878400, valid loss: 91.387009
epoch: 1661, train precision: 0.998711, train loss: 10.659773, valid precision: 0.878000, valid loss: 89.469297
epoch: 1662, train precision: 0.998244, train loss: 10.833486, valid precision: 0.872800, valid loss: 93.283068
epoch: 1663, train precision: 0.998778, train loss: 10.705989, valid precision: 0.874800, valid loss: 89.230470
epoch: 1664, train precision: 0.999156, train loss: 10.597873, valid precision: 0.878200, valid loss: 89.317620
epoch: 1665, train precision: 0.998267, train loss: 10.913037, valid precision: 0.874400, valid loss: 90.835286
epoch: 1666, train precision: 0.998556, train loss: 10.705081, valid precision: 0.874200, valid loss: 92.543772
epoch: 1667, train precision: 0.998622, train loss: 10.718427, valid precision: 0.875200, valid loss: 90.744524
epoch: 1668, train precision: 0.998467, train loss: 10.742917, valid precision: 0.874400, valid loss: 93.304072
epoch: 1669, train precision: 0.998667, train loss: 10.674946, valid precision: 0.876000, valid loss: 93.367932
epoch: 1670, train precision: 0.998978, train loss: 10.627664, valid precision: 0.874400, valid loss: 90.784165
epoch: 1671, train precision: 0.998978, train loss: 10.627361, valid precision: 0.873200, valid loss: 89.758007
epoch: 1672, train precision: 0.999267, train loss: 10.555782, valid precision: 0.874000, valid loss: 92.204053
epoch: 1673, train precision: 0.998822, train loss: 10.641287, valid precision: 0.877400, valid loss: 90.298451
epoch: 1674, train precision: 0.998933, train loss: 10.624484, valid precision: 0.879600, valid loss: 89.190283
epoch: 1675, train precision: 0.999111, train loss: 10.640542, valid precision: 0.879400, valid loss: 88.924013
epoch: 1676, train precision: 0.998689, train loss: 10.775327, valid precision: 0.875400, valid loss: 89.622758
epoch: 1677, train precision: 0.998667, train loss: 10.715941, valid precision: 0.879800, valid loss: 88.034476
epoch: 1678, train precision: 0.999000, train loss: 10.589531, valid precision: 0.875400, valid loss: 90.758755
epoch: 1679, train precision: 0.998800, train loss: 10.674688, valid precision: 0.874000, valid loss: 91.006542
epoch: 1680, train precision: 0.998444, train loss: 10.832924, valid precision: 0.874200, valid loss: 90.844820
epoch: 1681, train precision: 0.998889, train loss: 10.638413, valid precision: 0.876200, valid loss: 88.787023
epoch: 1682, train precision: 0.999044, train loss: 10.696009, valid precision: 0.876000, valid loss: 87.958968
epoch: 1683, train precision: 0.998889, train loss: 10.656646, valid precision: 0.876000, valid loss: 90.005772
epoch: 1684, train precision: 0.998733, train loss: 10.716072, valid precision: 0.873200, valid loss: 88.980318
epoch: 1685, train precision: 0.998933, train loss: 10.652142, valid precision: 0.874000, valid loss: 88.089435
epoch: 1686, train precision: 0.998933, train loss: 10.608675, valid precision: 0.878400, valid loss: 88.054862
epoch: 1687, train precision: 0.998889, train loss: 10.689629, valid precision: 0.870200, valid loss: 92.661056
epoch: 1688, train precision: 0.998933, train loss: 10.619384, valid precision: 0.870200, valid loss: 93.008925
epoch: 1689, train precision: 0.998844, train loss: 10.616258, valid precision: 0.873200, valid loss: 91.080478
epoch: 1690, train precision: 0.999067, train loss: 10.630459, valid precision: 0.872400, valid loss: 90.497079
epoch: 1691, train precision: 0.998844, train loss: 10.622922, valid precision: 0.880000, valid loss: 90.274372
epoch: 1692, train precision: 0.999022, train loss: 10.595511, valid precision: 0.876000, valid loss: 90.401524
epoch: 1693, train precision: 0.998889, train loss: 10.676074, valid precision: 0.879000, valid loss: 89.736798
epoch: 1694, train precision: 0.998689, train loss: 10.716799, valid precision: 0.876200, valid loss: 91.856067
epoch: 1695, train precision: 0.998689, train loss: 10.692204, valid precision: 0.875600, valid loss: 89.766808
epoch: 1696, train precision: 0.999111, train loss: 10.589446, valid precision: 0.871800, valid loss: 93.499245
epoch: 1697, train precision: 0.998578, train loss: 10.706547, valid precision: 0.870800, valid loss: 91.151242
epoch: 1698, train precision: 0.998711, train loss: 10.735800, valid precision: 0.872000, valid loss: 90.825388
epoch: 1699, train precision: 0.999111, train loss: 10.609052, valid precision: 0.876200, valid loss: 90.309481
epoch: 1700, train precision: 0.999089, train loss: 10.581953, valid precision: 0.875000, valid loss: 89.752889
epoch: 1701, train precision: 0.998956, train loss: 10.627254, valid precision: 0.873600, valid loss: 92.413585
epoch: 1702, train precision: 0.998844, train loss: 10.682761, valid precision: 0.870600, valid loss: 92.450427
epoch: 1703, train precision: 0.998600, train loss: 10.735100, valid precision: 0.870000, valid loss: 92.961691
epoch: 1704, train precision: 0.998533, train loss: 10.714654, valid precision: 0.877000, valid loss: 89.730669
epoch: 1705, train precision: 0.998756, train loss: 10.676873, valid precision: 0.878000, valid loss: 90.943389
epoch: 1706, train precision: 0.999200, train loss: 10.548251, valid precision: 0.873600, valid loss: 91.781643
epoch: 1707, train precision: 0.999178, train loss: 10.546712, valid precision: 0.874800, valid loss: 92.155632
epoch: 1708, train precision: 0.998778, train loss: 10.637330, valid precision: 0.875200, valid loss: 93.340994
epoch: 1709, train precision: 0.998844, train loss: 10.643273, valid precision: 0.876200, valid loss: 92.334121
epoch: 1710, train precision: 0.998956, train loss: 10.647343, valid precision: 0.873600, valid loss: 91.605881
epoch: 1711, train precision: 0.998889, train loss: 10.609110, valid precision: 0.875200, valid loss: 91.239993
epoch: 1712, train precision: 0.998711, train loss: 10.697677, valid precision: 0.875600, valid loss: 90.449318
epoch: 1713, train precision: 0.998911, train loss: 10.620275, valid precision: 0.877800, valid loss: 90.011137
epoch: 1714, train precision: 0.998800, train loss: 10.621937, valid precision: 0.876600, valid loss: 92.086714
epoch: 1715, train precision: 0.998844, train loss: 10.683215, valid precision: 0.878200, valid loss: 90.949476
epoch: 1716, train precision: 0.999111, train loss: 10.601105, valid precision: 0.877400, valid loss: 90.860056
epoch: 1717, train precision: 0.998289, train loss: 10.764279, valid precision: 0.873000, valid loss: 93.093350
epoch: 1718, train precision: 0.999156, train loss: 10.574278, valid precision: 0.876800, valid loss: 90.571813
epoch: 1719, train precision: 0.999200, train loss: 10.562356, valid precision: 0.879400, valid loss: 88.977411
epoch: 1720, train precision: 0.998978, train loss: 10.599839, valid precision: 0.875400, valid loss: 90.597097
epoch: 1721, train precision: 0.999022, train loss: 10.605383, valid precision: 0.877000, valid loss: 90.756070
epoch: 1722, train precision: 0.998644, train loss: 10.692508, valid precision: 0.874000, valid loss: 92.215232
epoch: 1723, train precision: 0.998756, train loss: 10.700911, valid precision: 0.875600, valid loss: 91.963076
epoch: 1724, train precision: 0.999067, train loss: 10.630426, valid precision: 0.879200, valid loss: 91.978928
epoch: 1725, train precision: 0.998333, train loss: 10.805271, valid precision: 0.873400, valid loss: 95.824378
epoch: 1726, train precision: 0.998889, train loss: 10.568655, valid precision: 0.877200, valid loss: 93.697271
epoch: 1727, train precision: 0.998911, train loss: 10.670769, valid precision: 0.870400, valid loss: 95.854829
epoch: 1728, train precision: 0.998933, train loss: 10.574751, valid precision: 0.876600, valid loss: 93.969826
epoch: 1729, train precision: 0.999111, train loss: 10.565485, valid precision: 0.873800, valid loss: 93.891453
epoch: 1730, train precision: 0.998533, train loss: 10.769416, valid precision: 0.871200, valid loss: 93.269576
epoch: 1731, train precision: 0.998911, train loss: 10.616497, valid precision: 0.873400, valid loss: 93.821987
epoch: 1732, train precision: 0.998822, train loss: 10.619917, valid precision: 0.872400, valid loss: 94.192691
epoch: 1733, train precision: 0.998822, train loss: 10.699022, valid precision: 0.875400, valid loss: 92.598766
epoch: 1734, train precision: 0.998600, train loss: 10.713863, valid precision: 0.876800, valid loss: 91.778993
epoch: 1735, train precision: 0.998889, train loss: 10.636594, valid precision: 0.875000, valid loss: 92.685092
epoch: 1736, train precision: 0.999244, train loss: 10.565496, valid precision: 0.872200, valid loss: 95.266799
epoch: 1737, train precision: 0.999022, train loss: 10.626913, valid precision: 0.871600, valid loss: 93.147942
epoch: 1738, train precision: 0.998822, train loss: 10.641946, valid precision: 0.875200, valid loss: 94.460272
epoch: 1739, train precision: 0.998089, train loss: 10.788849, valid precision: 0.872200, valid loss: 95.519533
epoch: 1740, train precision: 0.999067, train loss: 10.565220, valid precision: 0.872800, valid loss: 94.279433
epoch: 1741, train precision: 0.998756, train loss: 10.699204, valid precision: 0.871800, valid loss: 95.564742
epoch: 1742, train precision: 0.998711, train loss: 10.632932, valid precision: 0.872000, valid loss: 97.023969
epoch: 1743, train precision: 0.999000, train loss: 10.547186, valid precision: 0.874800, valid loss: 93.299093
epoch: 1744, train precision: 0.998556, train loss: 10.733704, valid precision: 0.874200, valid loss: 94.913466
epoch: 1745, train precision: 0.998733, train loss: 10.689825, valid precision: 0.873000, valid loss: 95.149086
epoch: 1746, train precision: 0.999067, train loss: 10.569449, valid precision: 0.876600, valid loss: 93.736621
epoch: 1747, train precision: 0.998889, train loss: 10.624125, valid precision: 0.873000, valid loss: 97.035984
epoch: 1748, train precision: 0.998111, train loss: 10.880500, valid precision: 0.871600, valid loss: 98.889709
epoch: 1749, train precision: 0.998844, train loss: 10.603798, valid precision: 0.874000, valid loss: 93.449415
epoch: 1750, train precision: 0.999000, train loss: 10.653922, valid precision: 0.873000, valid loss: 92.097582
epoch: 1751, train precision: 0.999044, train loss: 10.624992, valid precision: 0.873600, valid loss: 93.969369
epoch: 1752, train precision: 0.998889, train loss: 10.629192, valid precision: 0.876000, valid loss: 93.068749
epoch: 1753, train precision: 0.998733, train loss: 10.666372, valid precision: 0.872200, valid loss: 94.826802
epoch: 1754, train precision: 0.998956, train loss: 10.649315, valid precision: 0.875400, valid loss: 93.431653
epoch: 1755, train precision: 0.998844, train loss: 10.634395, valid precision: 0.876400, valid loss: 95.656662
epoch: 1756, train precision: 0.998889, train loss: 10.595267, valid precision: 0.871400, valid loss: 93.976040
epoch: 1757, train precision: 0.998933, train loss: 10.592382, valid precision: 0.875400, valid loss: 93.788664
epoch: 1758, train precision: 0.999178, train loss: 10.603705, valid precision: 0.875600, valid loss: 95.596516
epoch: 1759, train precision: 0.998933, train loss: 10.643533, valid precision: 0.872800, valid loss: 94.096225
epoch: 1760, train precision: 0.998444, train loss: 10.791781, valid precision: 0.868000, valid loss: 95.356982
epoch: 1761, train precision: 0.999044, train loss: 10.613801, valid precision: 0.876000, valid loss: 92.524019
epoch: 1762, train precision: 0.998867, train loss: 10.603044, valid precision: 0.873600, valid loss: 92.906410
epoch: 1763, train precision: 0.998800, train loss: 10.637625, valid precision: 0.876600, valid loss: 91.054816
epoch: 1764, train precision: 0.998800, train loss: 10.679071, valid precision: 0.874200, valid loss: 91.300979
epoch: 1765, train precision: 0.998978, train loss: 10.585210, valid precision: 0.878000, valid loss: 91.948533
epoch: 1766, train precision: 0.998578, train loss: 10.767699, valid precision: 0.873600, valid loss: 91.079538
epoch: 1767, train precision: 0.998844, train loss: 10.679838, valid precision: 0.875400, valid loss: 91.706448
epoch: 1768, train precision: 0.998956, train loss: 10.605226, valid precision: 0.873400, valid loss: 92.568220
epoch: 1769, train precision: 0.998778, train loss: 10.625937, valid precision: 0.872200, valid loss: 92.391320
epoch: 1770, train precision: 0.998489, train loss: 10.735118, valid precision: 0.873400, valid loss: 92.844037
epoch: 1771, train precision: 0.998622, train loss: 10.673146, valid precision: 0.875800, valid loss: 91.152338
epoch: 1772, train precision: 0.998467, train loss: 10.729116, valid precision: 0.873200, valid loss: 92.380480
epoch: 1773, train precision: 0.999067, train loss: 10.650538, valid precision: 0.875800, valid loss: 94.567154
epoch: 1774, train precision: 0.998600, train loss: 10.720703, valid precision: 0.874400, valid loss: 92.531456
epoch: 1775, train precision: 0.998889, train loss: 10.638661, valid precision: 0.879200, valid loss: 92.504360
epoch: 1776, train precision: 0.998889, train loss: 10.641732, valid precision: 0.878000, valid loss: 92.609436
epoch: 1777, train precision: 0.998933, train loss: 10.639940, valid precision: 0.869400, valid loss: 94.246480
epoch: 1778, train precision: 0.998956, train loss: 10.609101, valid precision: 0.875600, valid loss: 93.872459
epoch: 1779, train precision: 0.999044, train loss: 10.556906, valid precision: 0.875200, valid loss: 94.075861
epoch: 1780, train precision: 0.998444, train loss: 10.746829, valid precision: 0.877200, valid loss: 93.299213
epoch: 1781, train precision: 0.999067, train loss: 10.583857, valid precision: 0.873600, valid loss: 95.559599
epoch: 1782, train precision: 0.999067, train loss: 10.590796, valid precision: 0.874600, valid loss: 94.448018
epoch: 1783, train precision: 0.998822, train loss: 10.683123, valid precision: 0.875400, valid loss: 96.101002
epoch: 1784, train precision: 0.998867, train loss: 10.621496, valid precision: 0.876400, valid loss: 94.880490
epoch: 1785, train precision: 0.999022, train loss: 10.566858, valid precision: 0.874600, valid loss: 93.885224
epoch: 1786, train precision: 0.998911, train loss: 10.629758, valid precision: 0.874200, valid loss: 95.397200
epoch: 1787, train precision: 0.998378, train loss: 10.754457, valid precision: 0.875000, valid loss: 94.247035
epoch: 1788, train precision: 0.998956, train loss: 10.625441, valid precision: 0.876400, valid loss: 93.289486
epoch: 1789, train precision: 0.998889, train loss: 10.612373, valid precision: 0.875000, valid loss: 95.034088
epoch: 1790, train precision: 0.998844, train loss: 10.597333, valid precision: 0.875800, valid loss: 92.676700
epoch: 1791, train precision: 0.998600, train loss: 10.812628, valid precision: 0.875200, valid loss: 91.982188
epoch: 1792, train precision: 0.999089, train loss: 10.593183, valid precision: 0.874200, valid loss: 93.241322
epoch: 1793, train precision: 0.998933, train loss: 10.663444, valid precision: 0.876000, valid loss: 91.044085
epoch: 1794, train precision: 0.999000, train loss: 10.571874, valid precision: 0.875000, valid loss: 91.015561
epoch: 1795, train precision: 0.998889, train loss: 10.638991, valid precision: 0.874400, valid loss: 92.699908
epoch: 1796, train precision: 0.998622, train loss: 10.674707, valid precision: 0.873600, valid loss: 92.633665
epoch: 1797, train precision: 0.998844, train loss: 10.636263, valid precision: 0.876600, valid loss: 90.822972
epoch: 1798, train precision: 0.998556, train loss: 10.743160, valid precision: 0.865800, valid loss: 94.488002
epoch: 1799, train precision: 0.998889, train loss: 10.636631, valid precision: 0.872200, valid loss: 91.266485
epoch: 1800, train precision: 0.998578, train loss: 10.757472, valid precision: 0.873600, valid loss: 92.821804
epoch: 1801, train precision: 0.999289, train loss: 10.517888, valid precision: 0.870600, valid loss: 95.239582
epoch: 1802, train precision: 0.998356, train loss: 10.820368, valid precision: 0.871200, valid loss: 95.537837
epoch: 1803, train precision: 0.998867, train loss: 10.613222, valid precision: 0.873800, valid loss: 92.881354
epoch: 1804, train precision: 0.999000, train loss: 10.626814, valid precision: 0.871600, valid loss: 93.707241
epoch: 1805, train precision: 0.998533, train loss: 10.776311, valid precision: 0.871600, valid loss: 93.558111
epoch: 1806, train precision: 0.998489, train loss: 10.731274, valid precision: 0.872800, valid loss: 95.895422
epoch: 1807, train precision: 0.999089, train loss: 10.544650, valid precision: 0.874000, valid loss: 91.453283
epoch: 1808, train precision: 0.998933, train loss: 10.663217, valid precision: 0.868800, valid loss: 94.717840
epoch: 1809, train precision: 0.998956, train loss: 10.606986, valid precision: 0.876200, valid loss: 93.124899
epoch: 1810, train precision: 0.998733, train loss: 10.650342, valid precision: 0.875400, valid loss: 92.411366
epoch: 1811, train precision: 0.998844, train loss: 10.696664, valid precision: 0.871400, valid loss: 92.313372
epoch: 1812, train precision: 0.998400, train loss: 10.751932, valid precision: 0.873200, valid loss: 92.756299
epoch: 1813, train precision: 0.998756, train loss: 10.687878, valid precision: 0.872600, valid loss: 90.090324
epoch: 1814, train precision: 0.998689, train loss: 10.751156, valid precision: 0.875400, valid loss: 91.062874
epoch: 1815, train precision: 0.998889, train loss: 10.595360, valid precision: 0.873000, valid loss: 91.893391
epoch: 1816, train precision: 0.998489, train loss: 10.736681, valid precision: 0.876000, valid loss: 91.759219
epoch: 1817, train precision: 0.999022, train loss: 10.575905, valid precision: 0.876400, valid loss: 90.807265
epoch: 1818, train precision: 0.998933, train loss: 10.591890, valid precision: 0.874200, valid loss: 91.393051
epoch: 1819, train precision: 0.999133, train loss: 10.517055, valid precision: 0.872800, valid loss: 90.856688
epoch: 1820, train precision: 0.999022, train loss: 10.608364, valid precision: 0.872800, valid loss: 93.777454
epoch: 1821, train precision: 0.999022, train loss: 10.560463, valid precision: 0.874600, valid loss: 92.501515
epoch: 1822, train precision: 0.999089, train loss: 10.601705, valid precision: 0.875200, valid loss: 93.163764
epoch: 1823, train precision: 0.998800, train loss: 10.652573, valid precision: 0.875600, valid loss: 93.130681
epoch: 1824, train precision: 0.998844, train loss: 10.699187, valid precision: 0.875600, valid loss: 92.319329
epoch: 1825, train precision: 0.999089, train loss: 10.539919, valid precision: 0.873800, valid loss: 92.491998
epoch: 1826, train precision: 0.998044, train loss: 10.824987, valid precision: 0.876000, valid loss: 93.064651
epoch: 1827, train precision: 0.999178, train loss: 10.506513, valid precision: 0.876200, valid loss: 93.884212
epoch: 1828, train precision: 0.998889, train loss: 10.645003, valid precision: 0.878600, valid loss: 92.152490
epoch: 1829, train precision: 0.998911, train loss: 10.541810, valid precision: 0.877600, valid loss: 92.846844
epoch: 1830, train precision: 0.998311, train loss: 10.861595, valid precision: 0.873800, valid loss: 91.634480
epoch: 1831, train precision: 0.998867, train loss: 10.619305, valid precision: 0.878400, valid loss: 89.957544
epoch: 1832, train precision: 0.998911, train loss: 10.620876, valid precision: 0.875400, valid loss: 90.915493
epoch: 1833, train precision: 0.999022, train loss: 10.638891, valid precision: 0.873800, valid loss: 91.912757
epoch: 1834, train precision: 0.999000, train loss: 10.642158, valid precision: 0.875800, valid loss: 90.235037
epoch: 1835, train precision: 0.998711, train loss: 10.687951, valid precision: 0.872600, valid loss: 92.306674
epoch: 1836, train precision: 0.998644, train loss: 10.654939, valid precision: 0.875200, valid loss: 93.602975
epoch: 1837, train precision: 0.999044, train loss: 10.598703, valid precision: 0.873400, valid loss: 92.603131
epoch: 1838, train precision: 0.999089, train loss: 10.622362, valid precision: 0.872800, valid loss: 92.248296
epoch: 1839, train precision: 0.998978, train loss: 10.593648, valid precision: 0.875200, valid loss: 93.270507
epoch: 1840, train precision: 0.999089, train loss: 10.564706, valid precision: 0.877200, valid loss: 91.904803
epoch: 1841, train precision: 0.998733, train loss: 10.619911, valid precision: 0.875600, valid loss: 92.983814
epoch: 1842, train precision: 0.998822, train loss: 10.645322, valid precision: 0.875800, valid loss: 92.909516
epoch: 1843, train precision: 0.998778, train loss: 10.649334, valid precision: 0.878000, valid loss: 92.648873
epoch: 1844, train precision: 0.998889, train loss: 10.609029, valid precision: 0.875200, valid loss: 95.972028
epoch: 1845, train precision: 0.998889, train loss: 10.553408, valid precision: 0.877000, valid loss: 93.158991
epoch: 1846, train precision: 0.999244, train loss: 10.522400, valid precision: 0.876000, valid loss: 92.801140
epoch: 1847, train precision: 0.999200, train loss: 10.560887, valid precision: 0.876600, valid loss: 93.589779
epoch: 1848, train precision: 0.998933, train loss: 10.641705, valid precision: 0.876200, valid loss: 93.726508
epoch: 1849, train precision: 0.998844, train loss: 10.670560, valid precision: 0.877400, valid loss: 91.846877
epoch: 1850, train precision: 0.998422, train loss: 10.788378, valid precision: 0.876400, valid loss: 92.081543
epoch: 1851, train precision: 0.998867, train loss: 10.591069, valid precision: 0.874800, valid loss: 92.854649
epoch: 1852, train precision: 0.998556, train loss: 10.656391, valid precision: 0.871800, valid loss: 92.350831
epoch: 1853, train precision: 0.998867, train loss: 10.654668, valid precision: 0.872400, valid loss: 92.951820
epoch: 1854, train precision: 0.998778, train loss: 10.661440, valid precision: 0.869400, valid loss: 93.534717
epoch: 1855, train precision: 0.999067, train loss: 10.561958, valid precision: 0.875800, valid loss: 92.857936
epoch: 1856, train precision: 0.998644, train loss: 10.770751, valid precision: 0.872200, valid loss: 94.908275
epoch: 1857, train precision: 0.998822, train loss: 10.664251, valid precision: 0.878000, valid loss: 92.829217
epoch: 1858, train precision: 0.998600, train loss: 10.757226, valid precision: 0.870400, valid loss: 94.957502
epoch: 1859, train precision: 0.998644, train loss: 10.678427, valid precision: 0.874000, valid loss: 94.103253
epoch: 1860, train precision: 0.998778, train loss: 10.659616, valid precision: 0.876600, valid loss: 91.709962
epoch: 1861, train precision: 0.998711, train loss: 10.656990, valid precision: 0.875800, valid loss: 93.904636
epoch: 1862, train precision: 0.999000, train loss: 10.599003, valid precision: 0.875000, valid loss: 91.504146
epoch: 1863, train precision: 0.998533, train loss: 10.728767, valid precision: 0.874600, valid loss: 91.972331
epoch: 1864, train precision: 0.998933, train loss: 10.559099, valid precision: 0.877000, valid loss: 89.228128
epoch: 1865, train precision: 0.998778, train loss: 10.711461, valid precision: 0.876400, valid loss: 90.308455
epoch: 1866, train precision: 0.999067, train loss: 10.555283, valid precision: 0.879200, valid loss: 87.274543
epoch: 1867, train precision: 0.998644, train loss: 10.681540, valid precision: 0.877600, valid loss: 90.017142
epoch: 1868, train precision: 0.998622, train loss: 10.693373, valid precision: 0.877600, valid loss: 91.892925
epoch: 1869, train precision: 0.998733, train loss: 10.690058, valid precision: 0.880800, valid loss: 88.201255
epoch: 1870, train precision: 0.998956, train loss: 10.655109, valid precision: 0.873600, valid loss: 91.163302
epoch: 1871, train precision: 0.999133, train loss: 10.558161, valid precision: 0.878800, valid loss: 89.207075
epoch: 1872, train precision: 0.998956, train loss: 10.636186, valid precision: 0.877000, valid loss: 91.693322
epoch: 1873, train precision: 0.999022, train loss: 10.537025, valid precision: 0.875800, valid loss: 90.880790
epoch: 1874, train precision: 0.998667, train loss: 10.749196, valid precision: 0.874200, valid loss: 92.392741
epoch: 1875, train precision: 0.998911, train loss: 10.623067, valid precision: 0.877000, valid loss: 94.248599
epoch: 1876, train precision: 0.998711, train loss: 10.697197, valid precision: 0.875800, valid loss: 92.292878
epoch: 1877, train precision: 0.998889, train loss: 10.610246, valid precision: 0.874600, valid loss: 91.499858
epoch: 1878, train precision: 0.999089, train loss: 10.602123, valid precision: 0.875600, valid loss: 91.889404
epoch: 1879, train precision: 0.998644, train loss: 10.626571, valid precision: 0.875000, valid loss: 91.938535
epoch: 1880, train precision: 0.998822, train loss: 10.712999, valid precision: 0.873800, valid loss: 92.797562
epoch: 1881, train precision: 0.998622, train loss: 10.668187, valid precision: 0.879200, valid loss: 93.929296
epoch: 1882, train precision: 0.998444, train loss: 10.818121, valid precision: 0.878200, valid loss: 93.224800
epoch: 1883, train precision: 0.998867, train loss: 10.631357, valid precision: 0.876400, valid loss: 94.406488
epoch: 1884, train precision: 0.998933, train loss: 10.630561, valid precision: 0.872600, valid loss: 93.083389
epoch: 1885, train precision: 0.998911, train loss: 10.618034, valid precision: 0.875800, valid loss: 92.278998
epoch: 1886, train precision: 0.998689, train loss: 10.627275, valid precision: 0.875600, valid loss: 93.856902
epoch: 1887, train precision: 0.998444, train loss: 10.726185, valid precision: 0.876800, valid loss: 94.344032
epoch: 1888, train precision: 0.999022, train loss: 10.574590, valid precision: 0.876400, valid loss: 93.407292
epoch: 1889, train precision: 0.998733, train loss: 10.673887, valid precision: 0.877600, valid loss: 91.560151
epoch: 1890, train precision: 0.999089, train loss: 10.545116, valid precision: 0.873400, valid loss: 94.062976
epoch: 1891, train precision: 0.998733, train loss: 10.704400, valid precision: 0.872200, valid loss: 94.134222
epoch: 1892, train precision: 0.998756, train loss: 10.642632, valid precision: 0.876200, valid loss: 95.274805
epoch: 1893, train precision: 0.998800, train loss: 10.624048, valid precision: 0.872600, valid loss: 91.267522
epoch: 1894, train precision: 0.998689, train loss: 10.650750, valid precision: 0.876000, valid loss: 91.270708
epoch: 1895, train precision: 0.998733, train loss: 10.671782, valid precision: 0.873200, valid loss: 92.478503
epoch: 1896, train precision: 0.998778, train loss: 10.621615, valid precision: 0.876000, valid loss: 91.580510
epoch: 1897, train precision: 0.998978, train loss: 10.559964, valid precision: 0.879800, valid loss: 94.144906
epoch: 1898, train precision: 0.999067, train loss: 10.612027, valid precision: 0.874600, valid loss: 94.414457
epoch: 1899, train precision: 0.999022, train loss: 10.616459, valid precision: 0.878000, valid loss: 92.328125
epoch: 1900, train precision: 0.998844, train loss: 10.585502, valid precision: 0.877200, valid loss: 91.741884
epoch: 1901, train precision: 0.998889, train loss: 10.675266, valid precision: 0.878600, valid loss: 92.259098
epoch: 1902, train precision: 0.999333, train loss: 10.493963, valid precision: 0.879800, valid loss: 91.706460
epoch: 1903, train precision: 0.999022, train loss: 10.618118, valid precision: 0.875200, valid loss: 90.976268
epoch: 1904, train precision: 0.998622, train loss: 10.710667, valid precision: 0.874000, valid loss: 92.924364
epoch: 1905, train precision: 0.998311, train loss: 10.827118, valid precision: 0.870400, valid loss: 94.319223
epoch: 1906, train precision: 0.999156, train loss: 10.483848, valid precision: 0.875600, valid loss: 92.884022
epoch: 1907, train precision: 0.998978, train loss: 10.574726, valid precision: 0.874000, valid loss: 93.117207
epoch: 1908, train precision: 0.998978, train loss: 10.594956, valid precision: 0.878200, valid loss: 92.501410
epoch: 1909, train precision: 0.998956, train loss: 10.495587, valid precision: 0.871000, valid loss: 94.177508
epoch: 1910, train precision: 0.998533, train loss: 10.734448, valid precision: 0.872200, valid loss: 95.739431
epoch: 1911, train precision: 0.999089, train loss: 10.568483, valid precision: 0.871200, valid loss: 93.423745
epoch: 1912, train precision: 0.998733, train loss: 10.726100, valid precision: 0.873000, valid loss: 96.043920
epoch: 1913, train precision: 0.999067, train loss: 10.526286, valid precision: 0.874200, valid loss: 93.861633
epoch: 1914, train precision: 0.999022, train loss: 10.564528, valid precision: 0.873400, valid loss: 90.432422
epoch: 1915, train precision: 0.998911, train loss: 10.599623, valid precision: 0.876000, valid loss: 92.325309
epoch: 1916, train precision: 0.998644, train loss: 10.630396, valid precision: 0.872600, valid loss: 95.116427
epoch: 1917, train precision: 0.999111, train loss: 10.554313, valid precision: 0.875000, valid loss: 94.336457
epoch: 1918, train precision: 0.998889, train loss: 10.609147, valid precision: 0.869200, valid loss: 92.347043
epoch: 1919, train precision: 0.999044, train loss: 10.547712, valid precision: 0.876400, valid loss: 91.506034
epoch: 1920, train precision: 0.998933, train loss: 10.578411, valid precision: 0.874800, valid loss: 93.262672
epoch: 1921, train precision: 0.998889, train loss: 10.626806, valid precision: 0.875800, valid loss: 92.279055
epoch: 1922, train precision: 0.998644, train loss: 10.637208, valid precision: 0.878400, valid loss: 93.879041
epoch: 1923, train precision: 0.998689, train loss: 10.596625, valid precision: 0.873800, valid loss: 93.547153
epoch: 1924, train precision: 0.998444, train loss: 10.749649, valid precision: 0.876800, valid loss: 94.165146
epoch: 1925, train precision: 0.998933, train loss: 10.564484, valid precision: 0.872600, valid loss: 93.161363
epoch: 1926, train precision: 0.998956, train loss: 10.599359, valid precision: 0.870800, valid loss: 91.725385
epoch: 1927, train precision: 0.999200, train loss: 10.500583, valid precision: 0.878800, valid loss: 91.618676
epoch: 1928, train precision: 0.999044, train loss: 10.574962, valid precision: 0.873200, valid loss: 94.241917
epoch: 1929, train precision: 0.998756, train loss: 10.621136, valid precision: 0.874000, valid loss: 95.192215
epoch: 1930, train precision: 0.999000, train loss: 10.609961, valid precision: 0.873600, valid loss: 95.967035
epoch: 1931, train precision: 0.998911, train loss: 10.615844, valid precision: 0.868800, valid loss: 93.971490
epoch: 1932, train precision: 0.998622, train loss: 10.674744, valid precision: 0.874200, valid loss: 93.345036
epoch: 1933, train precision: 0.999200, train loss: 10.549009, valid precision: 0.874200, valid loss: 92.558040
epoch: 1934, train precision: 0.998667, train loss: 10.679354, valid precision: 0.875200, valid loss: 92.516288
epoch: 1935, train precision: 0.999022, train loss: 10.609099, valid precision: 0.870400, valid loss: 93.685822
epoch: 1936, train precision: 0.998867, train loss: 10.586480, valid precision: 0.875800, valid loss: 97.505431
epoch: 1937, train precision: 0.998933, train loss: 10.623272, valid precision: 0.878800, valid loss: 93.752333
epoch: 1938, train precision: 0.999222, train loss: 10.491184, valid precision: 0.874200, valid loss: 94.756701
epoch: 1939, train precision: 0.998356, train loss: 10.765618, valid precision: 0.871400, valid loss: 96.583616
epoch: 1940, train precision: 0.998933, train loss: 10.569192, valid precision: 0.874400, valid loss: 94.585217
epoch: 1941, train precision: 0.998889, train loss: 10.667124, valid precision: 0.873400, valid loss: 95.432390
epoch: 1942, train precision: 0.999156, train loss: 10.588085, valid precision: 0.874800, valid loss: 96.118482
epoch: 1943, train precision: 0.998978, train loss: 10.575704, valid precision: 0.871600, valid loss: 94.538406
epoch: 1944, train precision: 0.998689, train loss: 10.642482, valid precision: 0.876600, valid loss: 95.205442
epoch: 1945, train precision: 0.999133, train loss: 10.494597, valid precision: 0.875000, valid loss: 95.039325
epoch: 1946, train precision: 0.999133, train loss: 10.514494, valid precision: 0.877000, valid loss: 93.100244
epoch: 1947, train precision: 0.998711, train loss: 10.633343, valid precision: 0.876000, valid loss: 95.612451
epoch: 1948, train precision: 0.998844, train loss: 10.608528, valid precision: 0.874800, valid loss: 95.248070
epoch: 1949, train precision: 0.998489, train loss: 10.705195, valid precision: 0.873600, valid loss: 94.664241
epoch: 1950, train precision: 0.998889, train loss: 10.588630, valid precision: 0.875200, valid loss: 92.211568
epoch: 1951, train precision: 0.998933, train loss: 10.610083, valid precision: 0.876600, valid loss: 92.498819
epoch: 1952, train precision: 0.999044, train loss: 10.560177, valid precision: 0.876000, valid loss: 93.629951
epoch: 1953, train precision: 0.998867, train loss: 10.585706, valid precision: 0.875200, valid loss: 92.178033
epoch: 1954, train precision: 0.999133, train loss: 10.459995, valid precision: 0.876400, valid loss: 93.453275
epoch: 1955, train precision: 0.998622, train loss: 10.714750, valid precision: 0.876800, valid loss: 94.610985
epoch: 1956, train precision: 0.999244, train loss: 10.487807, valid precision: 0.875400, valid loss: 90.982384
epoch: 1957, train precision: 0.998733, train loss: 10.635502, valid precision: 0.877600, valid loss: 90.629185
epoch: 1958, train precision: 0.998711, train loss: 10.728548, valid precision: 0.873000, valid loss: 91.985418
epoch: 1959, train precision: 0.999000, train loss: 10.532778, valid precision: 0.878000, valid loss: 93.826786
epoch: 1960, train precision: 0.998956, train loss: 10.519475, valid precision: 0.877200, valid loss: 93.992306
epoch: 1961, train precision: 0.998844, train loss: 10.560702, valid precision: 0.874600, valid loss: 93.024767
epoch: 1962, train precision: 0.999133, train loss: 10.525443, valid precision: 0.878200, valid loss: 94.664606
epoch: 1963, train precision: 0.998733, train loss: 10.648176, valid precision: 0.875600, valid loss: 95.847403
epoch: 1964, train precision: 0.998867, train loss: 10.614758, valid precision: 0.873200, valid loss: 94.245497
epoch: 1965, train precision: 0.999000, train loss: 10.612214, valid precision: 0.877600, valid loss: 92.785527
epoch: 1966, train precision: 0.999111, train loss: 10.543458, valid precision: 0.873400, valid loss: 92.596016
epoch: 1967, train precision: 0.999000, train loss: 10.614998, valid precision: 0.875000, valid loss: 93.368776
epoch: 1968, train precision: 0.999244, train loss: 10.529277, valid precision: 0.871200, valid loss: 95.232053
epoch: 1969, train precision: 0.998844, train loss: 10.562217, valid precision: 0.874800, valid loss: 94.653878
epoch: 1970, train precision: 0.999311, train loss: 10.468027, valid precision: 0.874400, valid loss: 92.489166
epoch: 1971, train precision: 0.998800, train loss: 10.589478, valid precision: 0.874400, valid loss: 94.950921
epoch: 1972, train precision: 0.998556, train loss: 10.685598, valid precision: 0.870600, valid loss: 95.523111
epoch: 1973, train precision: 0.998867, train loss: 10.566223, valid precision: 0.868000, valid loss: 97.210683
epoch: 1974, train precision: 0.998889, train loss: 10.649139, valid precision: 0.874400, valid loss: 94.898373
epoch: 1975, train precision: 0.998978, train loss: 10.608454, valid precision: 0.875600, valid loss: 92.292232
epoch: 1976, train precision: 0.998756, train loss: 10.587262, valid precision: 0.876000, valid loss: 93.384836
epoch: 1977, train precision: 0.998800, train loss: 10.623261, valid precision: 0.876200, valid loss: 91.890035
epoch: 1978, train precision: 0.999022, train loss: 10.563705, valid precision: 0.875000, valid loss: 92.800473
epoch: 1979, train precision: 0.999133, train loss: 10.523516, valid precision: 0.869800, valid loss: 94.482880
epoch: 1980, train precision: 0.998689, train loss: 10.667590, valid precision: 0.870800, valid loss: 94.011647
epoch: 1981, train precision: 0.999044, train loss: 10.554028, valid precision: 0.876200, valid loss: 94.713218
epoch: 1982, train precision: 0.998844, train loss: 10.617123, valid precision: 0.875400, valid loss: 95.854591
epoch: 1983, train precision: 0.999089, train loss: 10.504021, valid precision: 0.871000, valid loss: 94.646382
epoch: 1984, train precision: 0.999178, train loss: 10.508862, valid precision: 0.873000, valid loss: 92.862018
epoch: 1985, train precision: 0.998756, train loss: 10.563175, valid precision: 0.874800, valid loss: 92.897709
epoch: 1986, train precision: 0.998978, train loss: 10.551783, valid precision: 0.875600, valid loss: 93.509236
epoch: 1987, train precision: 0.998489, train loss: 10.721807, valid precision: 0.876400, valid loss: 94.381199
epoch: 1988, train precision: 0.998889, train loss: 10.576521, valid precision: 0.875400, valid loss: 95.813665
epoch: 1989, train precision: 0.998889, train loss: 10.566593, valid precision: 0.874000, valid loss: 93.532458
epoch: 1990, train precision: 0.998956, train loss: 10.529274, valid precision: 0.875600, valid loss: 93.152058
epoch: 1991, train precision: 0.998822, train loss: 10.652494, valid precision: 0.875600, valid loss: 95.025498
epoch: 1992, train precision: 0.998689, train loss: 10.675433, valid precision: 0.873400, valid loss: 94.181540
epoch: 1993, train precision: 0.999067, train loss: 10.512599, valid precision: 0.876200, valid loss: 93.817576
epoch: 1994, train precision: 0.998689, train loss: 10.663560, valid precision: 0.870800, valid loss: 96.001077
epoch: 1995, train precision: 0.998867, train loss: 10.550989, valid precision: 0.875000, valid loss: 94.166753
epoch: 1996, train precision: 0.998933, train loss: 10.618510, valid precision: 0.873600, valid loss: 95.257150
epoch: 1997, train precision: 0.998933, train loss: 10.545780, valid precision: 0.874600, valid loss: 96.449284
epoch: 1998, train precision: 0.999067, train loss: 10.571850, valid precision: 0.874200, valid loss: 94.949677
epoch: 1999, train precision: 0.998889, train loss: 10.572803, valid precision: 0.875000, valid loss: 95.093233
epoch: 2000, train precision: 0.999133, train loss: 10.530123, valid precision: 0.873400, valid loss: 95.734364
epoch: 2001, train precision: 0.999000, train loss: 10.558382, valid precision: 0.878200, valid loss: 94.085889
epoch: 2002, train precision: 0.998978, train loss: 10.530324, valid precision: 0.876000, valid loss: 95.936442
epoch: 2003, train precision: 0.999156, train loss: 10.521278, valid precision: 0.873600, valid loss: 96.326459
epoch: 2004, train precision: 0.998778, train loss: 10.584179, valid precision: 0.875600, valid loss: 95.452819
epoch: 2005, train precision: 0.998822, train loss: 10.535622, valid precision: 0.875600, valid loss: 95.626052
epoch: 2006, train precision: 0.999089, train loss: 10.539286, valid precision: 0.874800, valid loss: 96.811053
epoch: 2007, train precision: 0.999156, train loss: 10.561374, valid precision: 0.871200, valid loss: 98.012159
epoch: 2008, train precision: 0.998844, train loss: 10.642624, valid precision: 0.874000, valid loss: 94.344157
epoch: 2009, train precision: 0.999000, train loss: 10.498383, valid precision: 0.872000, valid loss: 94.000414
epoch: 2010, train precision: 0.998844, train loss: 10.573150, valid precision: 0.876200, valid loss: 93.805080
epoch: 2011, train precision: 0.999200, train loss: 10.563258, valid precision: 0.874000, valid loss: 92.266027
epoch: 2012, train precision: 0.998889, train loss: 10.657587, valid precision: 0.874200, valid loss: 92.827250
epoch: 2013, train precision: 0.998867, train loss: 10.580869, valid precision: 0.876400, valid loss: 92.620289
epoch: 2014, train precision: 0.998711, train loss: 10.587608, valid precision: 0.872600, valid loss: 92.689764
epoch: 2015, train precision: 0.998778, train loss: 10.626395, valid precision: 0.873600, valid loss: 93.241319
epoch: 2016, train precision: 0.998800, train loss: 10.691193, valid precision: 0.874800, valid loss: 90.194935
epoch: 2017, train precision: 0.998911, train loss: 10.563517, valid precision: 0.872000, valid loss: 93.771941
epoch: 2018, train precision: 0.998756, train loss: 10.600172, valid precision: 0.873000, valid loss: 94.829168
epoch: 2019, train precision: 0.998778, train loss: 10.588528, valid precision: 0.874600, valid loss: 94.345432
epoch: 2020, train precision: 0.998889, train loss: 10.562815, valid precision: 0.873000, valid loss: 95.060939
epoch: 2021, train precision: 0.998844, train loss: 10.610636, valid precision: 0.871200, valid loss: 95.204059
epoch: 2022, train precision: 0.999000, train loss: 10.522164, valid precision: 0.876600, valid loss: 93.626636
epoch: 2023, train precision: 0.998867, train loss: 10.648962, valid precision: 0.870600, valid loss: 93.559321
epoch: 2024, train precision: 0.999356, train loss: 10.457918, valid precision: 0.873800, valid loss: 93.613011
epoch: 2025, train precision: 0.998911, train loss: 10.539925, valid precision: 0.874000, valid loss: 94.144465
epoch: 2026, train precision: 0.998733, train loss: 10.601082, valid precision: 0.871400, valid loss: 98.159943
epoch: 2027, train precision: 0.998778, train loss: 10.614974, valid precision: 0.871800, valid loss: 99.265161
epoch: 2028, train precision: 0.998822, train loss: 10.594320, valid precision: 0.873400, valid loss: 96.646054
epoch: 2029, train precision: 0.998778, train loss: 10.606666, valid precision: 0.871600, valid loss: 95.605547
epoch: 2030, train precision: 0.998711, train loss: 10.653551, valid precision: 0.869000, valid loss: 97.525151
epoch: 2031, train precision: 0.998689, train loss: 10.628279, valid precision: 0.872000, valid loss: 94.701611
epoch: 2032, train precision: 0.998800, train loss: 10.590734, valid precision: 0.874400, valid loss: 93.443484
epoch: 2033, train precision: 0.998822, train loss: 10.622460, valid precision: 0.871000, valid loss: 94.650723
epoch: 2034, train precision: 0.999000, train loss: 10.536646, valid precision: 0.875000, valid loss: 95.388798
epoch: 2035, train precision: 0.998844, train loss: 10.621686, valid precision: 0.873000, valid loss: 97.049027
epoch: 2036, train precision: 0.999044, train loss: 10.531960, valid precision: 0.876200, valid loss: 93.161780
epoch: 2037, train precision: 0.999111, train loss: 10.507931, valid precision: 0.872800, valid loss: 95.737433
epoch: 2038, train precision: 0.999089, train loss: 10.490835, valid precision: 0.871400, valid loss: 95.119073
epoch: 2039, train precision: 0.999222, train loss: 10.437966, valid precision: 0.876400, valid loss: 94.363193
epoch: 2040, train precision: 0.999133, train loss: 10.483089, valid precision: 0.875200, valid loss: 93.666555
epoch: 2041, train precision: 0.998911, train loss: 10.584720, valid precision: 0.873200, valid loss: 95.415239
epoch: 2042, train precision: 0.998511, train loss: 10.644472, valid precision: 0.871000, valid loss: 97.695113
epoch: 2043, train precision: 0.998644, train loss: 10.689426, valid precision: 0.874200, valid loss: 95.167125
epoch: 2044, train precision: 0.998800, train loss: 10.585675, valid precision: 0.873600, valid loss: 94.920956
epoch: 2045, train precision: 0.998800, train loss: 10.599405, valid precision: 0.875800, valid loss: 95.213095
epoch: 2046, train precision: 0.998911, train loss: 10.616760, valid precision: 0.872600, valid loss: 95.277258
epoch: 2047, train precision: 0.997978, train loss: 10.847727, valid precision: 0.872600, valid loss: 96.613555
epoch: 2048, train precision: 0.998822, train loss: 10.589546, valid precision: 0.872400, valid loss: 94.852042
epoch: 2049, train precision: 0.999067, train loss: 10.552023, valid precision: 0.873200, valid loss: 94.330445
epoch: 2050, train precision: 0.999200, train loss: 10.478642, valid precision: 0.877400, valid loss: 92.570319
epoch: 2051, train precision: 0.999111, train loss: 10.553930, valid precision: 0.875400, valid loss: 93.463945
epoch: 2052, train precision: 0.998667, train loss: 10.701814, valid precision: 0.874600, valid loss: 94.537437
epoch: 2053, train precision: 0.999133, train loss: 10.537479, valid precision: 0.879000, valid loss: 94.758521
epoch: 2054, train precision: 0.999067, train loss: 10.535663, valid precision: 0.878600, valid loss: 91.737656
epoch: 2055, train precision: 0.999133, train loss: 10.544138, valid precision: 0.881200, valid loss: 88.861689
epoch: 2056, train precision: 0.998933, train loss: 10.567002, valid precision: 0.878400, valid loss: 93.224201
epoch: 2057, train precision: 0.999022, train loss: 10.515534, valid precision: 0.878200, valid loss: 94.257260
epoch: 2058, train precision: 0.998844, train loss: 10.510709, valid precision: 0.876800, valid loss: 92.692025
epoch: 2059, train precision: 0.998889, train loss: 10.561806, valid precision: 0.874400, valid loss: 92.794859
epoch: 2060, train precision: 0.998956, train loss: 10.587088, valid precision: 0.873000, valid loss: 95.095248
epoch: 2061, train precision: 0.999089, train loss: 10.556770, valid precision: 0.877800, valid loss: 91.969458
epoch: 2062, train precision: 0.998956, train loss: 10.531948, valid precision: 0.874800, valid loss: 93.687175
epoch: 2063, train precision: 0.999244, train loss: 10.493163, valid precision: 0.875200, valid loss: 92.636657
epoch: 2064, train precision: 0.998378, train loss: 10.715321, valid precision: 0.874600, valid loss: 94.298974
epoch: 2065, train precision: 0.998756, train loss: 10.637654, valid precision: 0.875400, valid loss: 93.600212
epoch: 2066, train precision: 0.998978, train loss: 10.561140, valid precision: 0.877800, valid loss: 90.258183
epoch: 2067, train precision: 0.999044, train loss: 10.507921, valid precision: 0.870800, valid loss: 91.958800
epoch: 2068, train precision: 0.998956, train loss: 10.567657, valid precision: 0.871000, valid loss: 93.583450
epoch: 2069, train precision: 0.999022, train loss: 10.579131, valid precision: 0.870800, valid loss: 92.050738
epoch: 2070, train precision: 0.998956, train loss: 10.529764, valid precision: 0.870200, valid loss: 92.332735
epoch: 2071, train precision: 0.999244, train loss: 10.483204, valid precision: 0.873600, valid loss: 91.837044
epoch: 2072, train precision: 0.999133, train loss: 10.535535, valid precision: 0.873800, valid loss: 91.668888
epoch: 2073, train precision: 0.998911, train loss: 10.562238, valid precision: 0.872000, valid loss: 93.379525
epoch: 2074, train precision: 0.998689, train loss: 10.635003, valid precision: 0.874800, valid loss: 93.465791
epoch: 2075, train precision: 0.998600, train loss: 10.640250, valid precision: 0.871200, valid loss: 94.225651
epoch: 2076, train precision: 0.998800, train loss: 10.605585, valid precision: 0.871200, valid loss: 93.826622
epoch: 2077, train precision: 0.999089, train loss: 10.505149, valid precision: 0.873000, valid loss: 91.526057
epoch: 2078, train precision: 0.998956, train loss: 10.602280, valid precision: 0.876200, valid loss: 93.384091
epoch: 2079, train precision: 0.998622, train loss: 10.676076, valid precision: 0.869200, valid loss: 95.621945
epoch: 2080, train precision: 0.998911, train loss: 10.564653, valid precision: 0.873800, valid loss: 94.666802
epoch: 2081, train precision: 0.999111, train loss: 10.479820, valid precision: 0.872800, valid loss: 95.264089
epoch: 2082, train precision: 0.999267, train loss: 10.529896, valid precision: 0.870600, valid loss: 95.349514
epoch: 2083, train precision: 0.998689, train loss: 10.619279, valid precision: 0.869200, valid loss: 99.745105
epoch: 2084, train precision: 0.999089, train loss: 10.510305, valid precision: 0.872400, valid loss: 96.500939
epoch: 2085, train precision: 0.999044, train loss: 10.523735, valid precision: 0.873000, valid loss: 96.180812
epoch: 2086, train precision: 0.999044, train loss: 10.534935, valid precision: 0.873200, valid loss: 93.804808
epoch: 2087, train precision: 0.998533, train loss: 10.641163, valid precision: 0.870000, valid loss: 96.821669
epoch: 2088, train precision: 0.999000, train loss: 10.567703, valid precision: 0.874600, valid loss: 94.559789
epoch: 2089, train precision: 0.999156, train loss: 10.488301, valid precision: 0.876000, valid loss: 93.159819
epoch: 2090, train precision: 0.998711, train loss: 10.652913, valid precision: 0.871400, valid loss: 95.441681
epoch: 2091, train precision: 0.998889, train loss: 10.531755, valid precision: 0.874000, valid loss: 94.500233
epoch: 2092, train precision: 0.998733, train loss: 10.574515, valid precision: 0.876000, valid loss: 91.758029
epoch: 2093, train precision: 0.998844, train loss: 10.608420, valid precision: 0.875400, valid loss: 94.888602
epoch: 2094, train precision: 0.999222, train loss: 10.463315, valid precision: 0.879200, valid loss: 92.557769
epoch: 2095, train precision: 0.998844, train loss: 10.551818, valid precision: 0.876800, valid loss: 93.466352
epoch: 2096, train precision: 0.999000, train loss: 10.531903, valid precision: 0.869000, valid loss: 94.995973
epoch: 2097, train precision: 0.998489, train loss: 10.796699, valid precision: 0.869600, valid loss: 96.687696
epoch: 2098, train precision: 0.998933, train loss: 10.519550, valid precision: 0.871800, valid loss: 94.419603
epoch: 2099, train precision: 0.998733, train loss: 10.691112, valid precision: 0.877400, valid loss: 92.081047
epoch: 2100, train precision: 0.998556, train loss: 10.656965, valid precision: 0.873200, valid loss: 95.711468
epoch: 2101, train precision: 0.998933, train loss: 10.543571, valid precision: 0.874000, valid loss: 94.079759
epoch: 2102, train precision: 0.998489, train loss: 10.725497, valid precision: 0.870400, valid loss: 93.929222
epoch: 2103, train precision: 0.998933, train loss: 10.620905, valid precision: 0.874000, valid loss: 92.031813
epoch: 2104, train precision: 0.998933, train loss: 10.534251, valid precision: 0.871200, valid loss: 95.613101
epoch: 2105, train precision: 0.999200, train loss: 10.469248, valid precision: 0.871800, valid loss: 95.926852
epoch: 2106, train precision: 0.998844, train loss: 10.565032, valid precision: 0.869800, valid loss: 97.331489
epoch: 2107, train precision: 0.998711, train loss: 10.606951, valid precision: 0.870400, valid loss: 97.270751
epoch: 2108, train precision: 0.999200, train loss: 10.515447, valid precision: 0.869400, valid loss: 95.782055
epoch: 2109, train precision: 0.998244, train loss: 10.727985, valid precision: 0.868200, valid loss: 99.438849
epoch: 2110, train precision: 0.998667, train loss: 10.611088, valid precision: 0.867600, valid loss: 98.344016
epoch: 2111, train precision: 0.998822, train loss: 10.584553, valid precision: 0.873200, valid loss: 97.898662
epoch: 2112, train precision: 0.998867, train loss: 10.567217, valid precision: 0.869400, valid loss: 96.719306
epoch: 2113, train precision: 0.998822, train loss: 10.623306, valid precision: 0.870400, valid loss: 96.321215
epoch: 2114, train precision: 0.998489, train loss: 10.629756, valid precision: 0.874800, valid loss: 95.634716
epoch: 2115, train precision: 0.999044, train loss: 10.570744, valid precision: 0.869200, valid loss: 97.103008
epoch: 2116, train precision: 0.999200, train loss: 10.478599, valid precision: 0.872000, valid loss: 93.207600
epoch: 2117, train precision: 0.999200, train loss: 10.485153, valid precision: 0.870000, valid loss: 93.747805
epoch: 2118, train precision: 0.999222, train loss: 10.520825, valid precision: 0.874400, valid loss: 94.179453
epoch: 2119, train precision: 0.998778, train loss: 10.615911, valid precision: 0.871400, valid loss: 96.725540
epoch: 2120, train precision: 0.998467, train loss: 10.674624, valid precision: 0.871000, valid loss: 95.593591
epoch: 2121, train precision: 0.999222, train loss: 10.479989, valid precision: 0.876000, valid loss: 94.726747
epoch: 2122, train precision: 0.998889, train loss: 10.579972, valid precision: 0.875400, valid loss: 96.227863
epoch: 2123, train precision: 0.998867, train loss: 10.576283, valid precision: 0.874800, valid loss: 92.601567
epoch: 2124, train precision: 0.998822, train loss: 10.587062, valid precision: 0.871600, valid loss: 95.730852
epoch: 2125, train precision: 0.998933, train loss: 10.562698, valid precision: 0.875000, valid loss: 94.184011
epoch: 2126, train precision: 0.998867, train loss: 10.597198, valid precision: 0.875600, valid loss: 93.573126
epoch: 2127, train precision: 0.999156, train loss: 10.514681, valid precision: 0.873000, valid loss: 94.968829
epoch: 2128, train precision: 0.998778, train loss: 10.626555, valid precision: 0.872800, valid loss: 94.533869
epoch: 2129, train precision: 0.999044, train loss: 10.491666, valid precision: 0.874800, valid loss: 93.867791
epoch: 2130, train precision: 0.999267, train loss: 10.543742, valid precision: 0.871400, valid loss: 93.405378
epoch: 2131, train precision: 0.998956, train loss: 10.578337, valid precision: 0.874800, valid loss: 93.062988
epoch: 2132, train precision: 0.998533, train loss: 10.687990, valid precision: 0.872400, valid loss: 95.284123
epoch: 2133, train precision: 0.999022, train loss: 10.531759, valid precision: 0.874400, valid loss: 94.297466
epoch: 2134, train precision: 0.998867, train loss: 10.571981, valid precision: 0.868400, valid loss: 97.352658
epoch: 2135, train precision: 0.999489, train loss: 10.373825, valid precision: 0.876800, valid loss: 95.177683
epoch: 2136, train precision: 0.999222, train loss: 10.458543, valid precision: 0.875800, valid loss: 93.449372
epoch: 2137, train precision: 0.999133, train loss: 10.523446, valid precision: 0.876400, valid loss: 93.607570
epoch: 2138, train precision: 0.998800, train loss: 10.543193, valid precision: 0.878800, valid loss: 92.351364
epoch: 2139, train precision: 0.998889, train loss: 10.541712, valid precision: 0.875000, valid loss: 94.153567
epoch: 2140, train precision: 0.999000, train loss: 10.507363, valid precision: 0.875200, valid loss: 94.655772
epoch: 2141, train precision: 0.999378, train loss: 10.401390, valid precision: 0.870200, valid loss: 94.937519
epoch: 2142, train precision: 0.998956, train loss: 10.547506, valid precision: 0.870200, valid loss: 96.580423
epoch: 2143, train precision: 0.998933, train loss: 10.589408, valid precision: 0.876000, valid loss: 94.206917
epoch: 2144, train precision: 0.998867, train loss: 10.562595, valid precision: 0.874200, valid loss: 92.030612
epoch: 2145, train precision: 0.999111, train loss: 10.539518, valid precision: 0.875200, valid loss: 92.873743
epoch: 2146, train precision: 0.998600, train loss: 10.734783, valid precision: 0.874000, valid loss: 93.827652
epoch: 2147, train precision: 0.998733, train loss: 10.638896, valid precision: 0.875200, valid loss: 91.484255
epoch: 2148, train precision: 0.999089, train loss: 10.531813, valid precision: 0.878400, valid loss: 91.967820
epoch: 2149, train precision: 0.999156, train loss: 10.454377, valid precision: 0.874200, valid loss: 94.059342
epoch: 2150, train precision: 0.998778, train loss: 10.607638, valid precision: 0.878600, valid loss: 92.949352
epoch: 2151, train precision: 0.998578, train loss: 10.622418, valid precision: 0.877600, valid loss: 95.765745
epoch: 2152, train precision: 0.999067, train loss: 10.495476, valid precision: 0.877000, valid loss: 93.316568
epoch: 2153, train precision: 0.999111, train loss: 10.541239, valid precision: 0.880800, valid loss: 92.163269
epoch: 2154, train precision: 0.999022, train loss: 10.521749, valid precision: 0.877800, valid loss: 90.708423
epoch: 2155, train precision: 0.999111, train loss: 10.521552, valid precision: 0.877600, valid loss: 91.398662
epoch: 2156, train precision: 0.999044, train loss: 10.523370, valid precision: 0.878200, valid loss: 90.722779
epoch: 2157, train precision: 0.999133, train loss: 10.507003, valid precision: 0.873200, valid loss: 93.646051
epoch: 2158, train precision: 0.998844, train loss: 10.611648, valid precision: 0.876600, valid loss: 91.955939
epoch: 2159, train precision: 0.998911, train loss: 10.557893, valid precision: 0.880000, valid loss: 93.502257
epoch: 2160, train precision: 0.999000, train loss: 10.484468, valid precision: 0.880800, valid loss: 93.046468
epoch: 2161, train precision: 0.999178, train loss: 10.461286, valid precision: 0.878400, valid loss: 91.638866
epoch: 2162, train precision: 0.999200, train loss: 10.441305, valid precision: 0.878800, valid loss: 93.254232
epoch: 2163, train precision: 0.998844, train loss: 10.538620, valid precision: 0.877400, valid loss: 94.496872
epoch: 2164, train precision: 0.998956, train loss: 10.525339, valid precision: 0.873000, valid loss: 95.136090
epoch: 2165, train precision: 0.998844, train loss: 10.577930, valid precision: 0.874000, valid loss: 96.426460
epoch: 2166, train precision: 0.999089, train loss: 10.447390, valid precision: 0.875200, valid loss: 94.991686
epoch: 2167, train precision: 0.999022, train loss: 10.499586, valid precision: 0.872600, valid loss: 97.399234
epoch: 2168, train precision: 0.998978, train loss: 10.524134, valid precision: 0.872400, valid loss: 97.370844
epoch: 2169, train precision: 0.998956, train loss: 10.519639, valid precision: 0.874200, valid loss: 93.938286
epoch: 2170, train precision: 0.998800, train loss: 10.590512, valid precision: 0.873200, valid loss: 95.673299
epoch: 2171, train precision: 0.998622, train loss: 10.612579, valid precision: 0.880000, valid loss: 93.460553
epoch: 2172, train precision: 0.998911, train loss: 10.508885, valid precision: 0.876200, valid loss: 94.099690
epoch: 2173, train precision: 0.998556, train loss: 10.684580, valid precision: 0.875600, valid loss: 94.836160
epoch: 2174, train precision: 0.999244, train loss: 10.483408, valid precision: 0.875200, valid loss: 92.964723
epoch: 2175, train precision: 0.998600, train loss: 10.606492, valid precision: 0.874600, valid loss: 92.293014
epoch: 2176, train precision: 0.999067, train loss: 10.557919, valid precision: 0.875400, valid loss: 92.237135
epoch: 2177, train precision: 0.999178, train loss: 10.481726, valid precision: 0.874000, valid loss: 92.783806
epoch: 2178, train precision: 0.999067, train loss: 10.521913, valid precision: 0.875800, valid loss: 90.790247
epoch: 2179, train precision: 0.999044, train loss: 10.542740, valid precision: 0.877400, valid loss: 91.498214
epoch: 2180, train precision: 0.998689, train loss: 10.540981, valid precision: 0.877400, valid loss: 93.765006
epoch: 2181, train precision: 0.998622, train loss: 10.618205, valid precision: 0.875400, valid loss: 94.874597
epoch: 2182, train precision: 0.998578, train loss: 10.626952, valid precision: 0.874800, valid loss: 94.630418
epoch: 2183, train precision: 0.998978, train loss: 10.537370, valid precision: 0.876800, valid loss: 95.444080
epoch: 2184, train precision: 0.998644, train loss: 10.597332, valid precision: 0.871800, valid loss: 96.094380
epoch: 2185, train precision: 0.998689, train loss: 10.579321, valid precision: 0.873400, valid loss: 95.385233
epoch: 2186, train precision: 0.998578, train loss: 10.583296, valid precision: 0.874600, valid loss: 95.474575
epoch: 2187, train precision: 0.999000, train loss: 10.466172, valid precision: 0.875200, valid loss: 92.899822
epoch: 2188, train precision: 0.999178, train loss: 10.485405, valid precision: 0.873600, valid loss: 94.661515
epoch: 2189, train precision: 0.999222, train loss: 10.495913, valid precision: 0.873800, valid loss: 94.184530
epoch: 2190, train precision: 0.998644, train loss: 10.631809, valid precision: 0.878000, valid loss: 94.743176
epoch: 2191, train precision: 0.999333, train loss: 10.378578, valid precision: 0.875800, valid loss: 95.466579
epoch: 2192, train precision: 0.999156, train loss: 10.435254, valid precision: 0.869600, valid loss: 95.311409
epoch: 2193, train precision: 0.998533, train loss: 10.594759, valid precision: 0.870600, valid loss: 97.768671
epoch: 2194, train precision: 0.999000, train loss: 10.530281, valid precision: 0.874000, valid loss: 97.064567
epoch: 2195, train precision: 0.999067, train loss: 10.504636, valid precision: 0.873200, valid loss: 95.588616
epoch: 2196, train precision: 0.998889, train loss: 10.570005, valid precision: 0.874200, valid loss: 95.430445
epoch: 2197, train precision: 0.999289, train loss: 10.432462, valid precision: 0.873000, valid loss: 96.833087
epoch: 2198, train precision: 0.998956, train loss: 10.488161, valid precision: 0.870000, valid loss: 96.883316
epoch: 2199, train precision: 0.999022, train loss: 10.476199, valid precision: 0.872600, valid loss: 96.512230
epoch: 2200, train precision: 0.999133, train loss: 10.441307, valid precision: 0.877000, valid loss: 95.514195
epoch: 2201, train precision: 0.999244, train loss: 10.383170, valid precision: 0.874000, valid loss: 94.775585
epoch: 2202, train precision: 0.999356, train loss: 10.432433, valid precision: 0.873800, valid loss: 93.255943
epoch: 2203, train precision: 0.999267, train loss: 10.412602, valid precision: 0.876400, valid loss: 94.397918
epoch: 2204, train precision: 0.998578, train loss: 10.598436, valid precision: 0.874600, valid loss: 94.385218
epoch: 2205, train precision: 0.999089, train loss: 10.476033, valid precision: 0.873400, valid loss: 93.019394
epoch: 2206, train precision: 0.998311, train loss: 10.670124, valid precision: 0.875800, valid loss: 93.133494
epoch: 2207, train precision: 0.999333, train loss: 10.409007, valid precision: 0.875800, valid loss: 92.838491
epoch: 2208, train precision: 0.999089, train loss: 10.502961, valid precision: 0.877000, valid loss: 95.785248
epoch: 2209, train precision: 0.998889, train loss: 10.541530, valid precision: 0.873000, valid loss: 93.363493
epoch: 2210, train precision: 0.998956, train loss: 10.564675, valid precision: 0.874800, valid loss: 93.712786
epoch: 2211, train precision: 0.998800, train loss: 10.545005, valid precision: 0.875800, valid loss: 91.230310
epoch: 2212, train precision: 0.998800, train loss: 10.595645, valid precision: 0.880000, valid loss: 90.601697
epoch: 2213, train precision: 0.998578, train loss: 10.668157, valid precision: 0.878600, valid loss: 91.779918
epoch: 2214, train precision: 0.998644, train loss: 10.659256, valid precision: 0.875200, valid loss: 93.506407
epoch: 2215, train precision: 0.999000, train loss: 10.492097, valid precision: 0.873000, valid loss: 95.041219
epoch: 2216, train precision: 0.999067, train loss: 10.460174, valid precision: 0.876400, valid loss: 94.391215
epoch: 2217, train precision: 0.998756, train loss: 10.538297, valid precision: 0.870200, valid loss: 94.635550
epoch: 2218, train precision: 0.998978, train loss: 10.526385, valid precision: 0.873200, valid loss: 92.907128
epoch: 2219, train precision: 0.998733, train loss: 10.566379, valid precision: 0.874200, valid loss: 92.666653
epoch: 2220, train precision: 0.999044, train loss: 10.484458, valid precision: 0.872400, valid loss: 93.397191
epoch: 2221, train precision: 0.998622, train loss: 10.588374, valid precision: 0.872200, valid loss: 96.326840
epoch: 2222, train precision: 0.999067, train loss: 10.521834, valid precision: 0.871800, valid loss: 95.735392
epoch: 2223, train precision: 0.999244, train loss: 10.426647, valid precision: 0.871400, valid loss: 94.353628
epoch: 2224, train precision: 0.998800, train loss: 10.576673, valid precision: 0.869200, valid loss: 96.443835
epoch: 2225, train precision: 0.999067, train loss: 10.470679, valid precision: 0.872200, valid loss: 94.442000
epoch: 2226, train precision: 0.999000, train loss: 10.498724, valid precision: 0.871600, valid loss: 96.626924
epoch: 2227, train precision: 0.998911, train loss: 10.525212, valid precision: 0.870000, valid loss: 95.885593
epoch: 2228, train precision: 0.999178, train loss: 10.436228, valid precision: 0.872000, valid loss: 95.185996
epoch: 2229, train precision: 0.998822, train loss: 10.573722, valid precision: 0.871000, valid loss: 95.831409
epoch: 2230, train precision: 0.999311, train loss: 10.419132, valid precision: 0.875800, valid loss: 94.413268
epoch: 2231, train precision: 0.998689, train loss: 10.595148, valid precision: 0.871800, valid loss: 94.446836
epoch: 2232, train precision: 0.998622, train loss: 10.630846, valid precision: 0.870400, valid loss: 100.394196
epoch: 2233, train precision: 0.999244, train loss: 10.440371, valid precision: 0.875400, valid loss: 96.043910
epoch: 2234, train precision: 0.998844, train loss: 10.587755, valid precision: 0.874200, valid loss: 95.834596
epoch: 2235, train precision: 0.999222, train loss: 10.369132, valid precision: 0.874200, valid loss: 95.812333
epoch: 2236, train precision: 0.999044, train loss: 10.480975, valid precision: 0.870200, valid loss: 96.666467
epoch: 2237, train precision: 0.998822, train loss: 10.566332, valid precision: 0.873400, valid loss: 96.007956
epoch: 2238, train precision: 0.998978, train loss: 10.512607, valid precision: 0.879800, valid loss: 93.944144
epoch: 2239, train precision: 0.998978, train loss: 10.521311, valid precision: 0.876000, valid loss: 94.964468
epoch: 2240, train precision: 0.998889, train loss: 10.557963, valid precision: 0.876600, valid loss: 93.593496
epoch: 2241, train precision: 0.998733, train loss: 10.605481, valid precision: 0.875400, valid loss: 92.122648
epoch: 2242, train precision: 0.999156, train loss: 10.432977, valid precision: 0.879800, valid loss: 90.855756
epoch: 2243, train precision: 0.998711, train loss: 10.616394, valid precision: 0.876600, valid loss: 92.992330
epoch: 2244, train precision: 0.999267, train loss: 10.419915, valid precision: 0.874800, valid loss: 93.339807
epoch: 2245, train precision: 0.998822, train loss: 10.591615, valid precision: 0.873400, valid loss: 95.330644
epoch: 2246, train precision: 0.999000, train loss: 10.520600, valid precision: 0.874400, valid loss: 94.146881
epoch: 2247, train precision: 0.998356, train loss: 10.689470, valid precision: 0.875800, valid loss: 95.412248
epoch: 2248, train precision: 0.998711, train loss: 10.528617, valid precision: 0.876600, valid loss: 96.505183
epoch: 2249, train precision: 0.998956, train loss: 10.516920, valid precision: 0.874800, valid loss: 97.393961
epoch: 2250, train precision: 0.999067, train loss: 10.468032, valid precision: 0.874600, valid loss: 97.497453
epoch: 2251, train precision: 0.998956, train loss: 10.480942, valid precision: 0.875600, valid loss: 96.045746
epoch: 2252, train precision: 0.998978, train loss: 10.514641, valid precision: 0.876600, valid loss: 94.789431
epoch: 2253, train precision: 0.998578, train loss: 10.561347, valid precision: 0.875000, valid loss: 95.161955
epoch: 2254, train precision: 0.999022, train loss: 10.469666, valid precision: 0.874800, valid loss: 94.671664
epoch: 2255, train precision: 0.999244, train loss: 10.523889, valid precision: 0.871200, valid loss: 91.940984
epoch: 2256, train precision: 0.998578, train loss: 10.626941, valid precision: 0.872800, valid loss: 96.577292
epoch: 2257, train precision: 0.999022, train loss: 10.508903, valid precision: 0.875200, valid loss: 94.109561
epoch: 2258, train precision: 0.999333, train loss: 10.438323, valid precision: 0.872600, valid loss: 95.423486
epoch: 2259, train precision: 0.999089, train loss: 10.466066, valid precision: 0.872000, valid loss: 94.648465
epoch: 2260, train precision: 0.998956, train loss: 10.543241, valid precision: 0.877200, valid loss: 93.858732
epoch: 2261, train precision: 0.998822, train loss: 10.518881, valid precision: 0.877000, valid loss: 94.214561
epoch: 2262, train precision: 0.998978, train loss: 10.526327, valid precision: 0.876800, valid loss: 92.909709
epoch: 2263, train precision: 0.998733, train loss: 10.602141, valid precision: 0.872200, valid loss: 94.788027
epoch: 2264, train precision: 0.999089, train loss: 10.490812, valid precision: 0.877200, valid loss: 93.219969
epoch: 2265, train precision: 0.999000, train loss: 10.500055, valid precision: 0.879400, valid loss: 92.806302
epoch: 2266, train precision: 0.999022, train loss: 10.501728, valid precision: 0.875600, valid loss: 93.204722
epoch: 2267, train precision: 0.999156, train loss: 10.421712, valid precision: 0.879400, valid loss: 93.272957
epoch: 2268, train precision: 0.998533, train loss: 10.598591, valid precision: 0.878600, valid loss: 93.773676
epoch: 2269, train precision: 0.999000, train loss: 10.500457, valid precision: 0.877800, valid loss: 92.626190
epoch: 2270, train precision: 0.998956, train loss: 10.508708, valid precision: 0.880000, valid loss: 93.650437
epoch: 2271, train precision: 0.999133, train loss: 10.495524, valid precision: 0.875000, valid loss: 94.123381
epoch: 2272, train precision: 0.998800, train loss: 10.535462, valid precision: 0.876200, valid loss: 93.444302
epoch: 2273, train precision: 0.998889, train loss: 10.511435, valid precision: 0.881400, valid loss: 93.921012
epoch: 2274, train precision: 0.998911, train loss: 10.573470, valid precision: 0.876000, valid loss: 92.314202
epoch: 2275, train precision: 0.998867, train loss: 10.552287, valid precision: 0.874200, valid loss: 93.710222
epoch: 2276, train precision: 0.999067, train loss: 10.436380, valid precision: 0.878400, valid loss: 93.325148
epoch: 2277, train precision: 0.999111, train loss: 10.508400, valid precision: 0.875800, valid loss: 93.997740
epoch: 2278, train precision: 0.999044, train loss: 10.457162, valid precision: 0.877400, valid loss: 93.417815
epoch: 2279, train precision: 0.998400, train loss: 10.677241, valid precision: 0.872600, valid loss: 95.610801
epoch: 2280, train precision: 0.998378, train loss: 10.675353, valid precision: 0.875200, valid loss: 93.930172
epoch: 2281, train precision: 0.999178, train loss: 10.485280, valid precision: 0.876400, valid loss: 93.819958
epoch: 2282, train precision: 0.999111, train loss: 10.469207, valid precision: 0.873800, valid loss: 92.862594
epoch: 2283, train precision: 0.999267, train loss: 10.404894, valid precision: 0.873200, valid loss: 92.190208
epoch: 2284, train precision: 0.999333, train loss: 10.409698, valid precision: 0.873600, valid loss: 94.621582
epoch: 2285, train precision: 0.999156, train loss: 10.451042, valid precision: 0.872200, valid loss: 96.801706
epoch: 2286, train precision: 0.999089, train loss: 10.439996, valid precision: 0.876400, valid loss: 93.709273
epoch: 2287, train precision: 0.998756, train loss: 10.580760, valid precision: 0.874400, valid loss: 94.524260
epoch: 2288, train precision: 0.999111, train loss: 10.443763, valid precision: 0.876200, valid loss: 95.991971
epoch: 2289, train precision: 0.999000, train loss: 10.468338, valid precision: 0.878800, valid loss: 95.914642
epoch: 2290, train precision: 0.999311, train loss: 10.418875, valid precision: 0.875200, valid loss: 93.997093
epoch: 2291, train precision: 0.998956, train loss: 10.459205, valid precision: 0.873200, valid loss: 95.293402
epoch: 2292, train precision: 0.999022, train loss: 10.437567, valid precision: 0.873400, valid loss: 96.592586
epoch: 2293, train precision: 0.999067, train loss: 10.426645, valid precision: 0.871200, valid loss: 95.199403
epoch: 2294, train precision: 0.998822, train loss: 10.536402, valid precision: 0.870000, valid loss: 98.009945
epoch: 2295, train precision: 0.998689, train loss: 10.565007, valid precision: 0.877400, valid loss: 95.470352
epoch: 2296, train precision: 0.998711, train loss: 10.599510, valid precision: 0.877000, valid loss: 94.138024
epoch: 2297, train precision: 0.998511, train loss: 10.680074, valid precision: 0.875000, valid loss: 93.349097
epoch: 2298, train precision: 0.998933, train loss: 10.496604, valid precision: 0.875400, valid loss: 93.799406
epoch: 2299, train precision: 0.999022, train loss: 10.509032, valid precision: 0.870400, valid loss: 95.267713
epoch: 2300, train precision: 0.999111, train loss: 10.433171, valid precision: 0.874400, valid loss: 93.788331
epoch: 2301, train precision: 0.998911, train loss: 10.463675, valid precision: 0.875400, valid loss: 93.490467
epoch: 2302, train precision: 0.999044, train loss: 10.487121, valid precision: 0.868800, valid loss: 94.894786
epoch: 2303, train precision: 0.999044, train loss: 10.489630, valid precision: 0.876600, valid loss: 90.495583
epoch: 2304, train precision: 0.999111, train loss: 10.512192, valid precision: 0.873000, valid loss: 95.560523
epoch: 2305, train precision: 0.999289, train loss: 10.451821, valid precision: 0.872000, valid loss: 93.731408
epoch: 2306, train precision: 0.999133, train loss: 10.395380, valid precision: 0.871600, valid loss: 97.624716
epoch: 2307, train precision: 0.998867, train loss: 10.562100, valid precision: 0.874200, valid loss: 95.393319
epoch: 2308, train precision: 0.999156, train loss: 10.395576, valid precision: 0.876400, valid loss: 94.954337
epoch: 2309, train precision: 0.998800, train loss: 10.553514, valid precision: 0.876800, valid loss: 93.826763
epoch: 2310, train precision: 0.999000, train loss: 10.428481, valid precision: 0.876600, valid loss: 94.217814
epoch: 2311, train precision: 0.999022, train loss: 10.471004, valid precision: 0.870800, valid loss: 96.723600
epoch: 2312, train precision: 0.998733, train loss: 10.541364, valid precision: 0.875400, valid loss: 92.858256
epoch: 2313, train precision: 0.999178, train loss: 10.402965, valid precision: 0.871600, valid loss: 95.161307
epoch: 2314, train precision: 0.999044, train loss: 10.458211, valid precision: 0.873600, valid loss: 95.006287
epoch: 2315, train precision: 0.998556, train loss: 10.599232, valid precision: 0.870200, valid loss: 95.681129
epoch: 2316, train precision: 0.999000, train loss: 10.516071, valid precision: 0.879200, valid loss: 93.059015
epoch: 2317, train precision: 0.998800, train loss: 10.471375, valid precision: 0.878200, valid loss: 92.398729
epoch: 2318, train precision: 0.999044, train loss: 10.448499, valid precision: 0.876800, valid loss: 91.680003
epoch: 2319, train precision: 0.998978, train loss: 10.500609, valid precision: 0.875000, valid loss: 93.184463
epoch: 2320, train precision: 0.998622, train loss: 10.535674, valid precision: 0.877600, valid loss: 94.974669
epoch: 2321, train precision: 0.998978, train loss: 10.481937, valid precision: 0.874200, valid loss: 95.958730
epoch: 2322, train precision: 0.998978, train loss: 10.535422, valid precision: 0.873400, valid loss: 93.294363
epoch: 2323, train precision: 0.998667, train loss: 10.552584, valid precision: 0.876400, valid loss: 95.897167
epoch: 2324, train precision: 0.999133, train loss: 10.445523, valid precision: 0.872400, valid loss: 94.695432
epoch: 2325, train precision: 0.998578, train loss: 10.590525, valid precision: 0.875000, valid loss: 93.170557
epoch: 2326, train precision: 0.998822, train loss: 10.580615, valid precision: 0.877000, valid loss: 93.411197
epoch: 2327, train precision: 0.999200, train loss: 10.460600, valid precision: 0.875400, valid loss: 93.028767
epoch: 2328, train precision: 0.999067, train loss: 10.461949, valid precision: 0.876800, valid loss: 95.340566
epoch: 2329, train precision: 0.999333, train loss: 10.325387, valid precision: 0.873800, valid loss: 96.379364
epoch: 2330, train precision: 0.999089, train loss: 10.503373, valid precision: 0.874200, valid loss: 92.950126
epoch: 2331, train precision: 0.999022, train loss: 10.471207, valid precision: 0.873200, valid loss: 93.544889
epoch: 2332, train precision: 0.998844, train loss: 10.550719, valid precision: 0.876400, valid loss: 92.723700
epoch: 2333, train precision: 0.999267, train loss: 10.426589, valid precision: 0.873800, valid loss: 91.931025
epoch: 2334, train precision: 0.998978, train loss: 10.458433, valid precision: 0.875000, valid loss: 89.779846
epoch: 2335, train precision: 0.999178, train loss: 10.408824, valid precision: 0.876200, valid loss: 91.893625
epoch: 2336, train precision: 0.998800, train loss: 10.493680, valid precision: 0.873600, valid loss: 91.749008
epoch: 2337, train precision: 0.998978, train loss: 10.445618, valid precision: 0.876400, valid loss: 91.364971
epoch: 2338, train precision: 0.998911, train loss: 10.495631, valid precision: 0.876400, valid loss: 91.823973
epoch: 2339, train precision: 0.998800, train loss: 10.572828, valid precision: 0.871200, valid loss: 93.772109
epoch: 2340, train precision: 0.998867, train loss: 10.561632, valid precision: 0.876000, valid loss: 91.816963
epoch: 2341, train precision: 0.998489, train loss: 10.690595, valid precision: 0.872400, valid loss: 91.825678
epoch: 2342, train precision: 0.999244, train loss: 10.414181, valid precision: 0.874800, valid loss: 90.022421
epoch: 2343, train precision: 0.999044, train loss: 10.511987, valid precision: 0.878600, valid loss: 92.406435
epoch: 2344, train precision: 0.998756, train loss: 10.553880, valid precision: 0.876200, valid loss: 93.453905
epoch: 2345, train precision: 0.999022, train loss: 10.477470, valid precision: 0.878200, valid loss: 90.400568
epoch: 2346, train precision: 0.999311, train loss: 10.420340, valid precision: 0.876000, valid loss: 93.025778
epoch: 2347, train precision: 0.998844, train loss: 10.582532, valid precision: 0.873400, valid loss: 93.524163
epoch: 2348, train precision: 0.998667, train loss: 10.571027, valid precision: 0.875000, valid loss: 91.999067
epoch: 2349, train precision: 0.998800, train loss: 10.529843, valid precision: 0.873800, valid loss: 94.492780
epoch: 2350, train precision: 0.999089, train loss: 10.467320, valid precision: 0.877200, valid loss: 90.966187
epoch: 2351, train precision: 0.998733, train loss: 10.575318, valid precision: 0.877400, valid loss: 92.836649
epoch: 2352, train precision: 0.998844, train loss: 10.486726, valid precision: 0.878400, valid loss: 89.775751
epoch: 2353, train precision: 0.999178, train loss: 10.427806, valid precision: 0.877800, valid loss: 91.207523
epoch: 2354, train precision: 0.998600, train loss: 10.575986, valid precision: 0.875600, valid loss: 91.787281
epoch: 2355, train precision: 0.998978, train loss: 10.486421, valid precision: 0.873800, valid loss: 90.544739
epoch: 2356, train precision: 0.999000, train loss: 10.452602, valid precision: 0.872200, valid loss: 91.945546
epoch: 2357, train precision: 0.999022, train loss: 10.479154, valid precision: 0.875800, valid loss: 93.210776
epoch: 2358, train precision: 0.999067, train loss: 10.451168, valid precision: 0.871800, valid loss: 92.098792
epoch: 2359, train precision: 0.998644, train loss: 10.522618, valid precision: 0.870000, valid loss: 89.171959
epoch: 2360, train precision: 0.998956, train loss: 10.537617, valid precision: 0.869200, valid loss: 92.697409
epoch: 2361, train precision: 0.999289, train loss: 10.450614, valid precision: 0.871800, valid loss: 91.505691
epoch: 2362, train precision: 0.999000, train loss: 10.438114, valid precision: 0.878200, valid loss: 90.414017
epoch: 2363, train precision: 0.998489, train loss: 10.610052, valid precision: 0.878600, valid loss: 91.515670
epoch: 2364, train precision: 0.999022, train loss: 10.426206, valid precision: 0.874400, valid loss: 92.594757
epoch: 2365, train precision: 0.999333, train loss: 10.396321, valid precision: 0.878800, valid loss: 90.399386
epoch: 2366, train precision: 0.998867, train loss: 10.518051, valid precision: 0.876800, valid loss: 91.804980
epoch: 2367, train precision: 0.998289, train loss: 10.707440, valid precision: 0.877800, valid loss: 91.174867
epoch: 2368, train precision: 0.998711, train loss: 10.566406, valid precision: 0.873800, valid loss: 91.670855
epoch: 2369, train precision: 0.999178, train loss: 10.420781, valid precision: 0.876000, valid loss: 89.604767
epoch: 2370, train precision: 0.998556, train loss: 10.610734, valid precision: 0.874000, valid loss: 95.090360
epoch: 2371, train precision: 0.999111, train loss: 10.513782, valid precision: 0.875400, valid loss: 95.114241
epoch: 2372, train precision: 0.998733, train loss: 10.533717, valid precision: 0.876000, valid loss: 91.567604
epoch: 2373, train precision: 0.998978, train loss: 10.476222, valid precision: 0.876800, valid loss: 91.381221
epoch: 2374, train precision: 0.998978, train loss: 10.561152, valid precision: 0.882000, valid loss: 91.710915
epoch: 2375, train precision: 0.999200, train loss: 10.432156, valid precision: 0.876200, valid loss: 94.480804
epoch: 2376, train precision: 0.998667, train loss: 10.567694, valid precision: 0.877200, valid loss: 94.658508
epoch: 2377, train precision: 0.998800, train loss: 10.512381, valid precision: 0.874800, valid loss: 94.341516
epoch: 2378, train precision: 0.999067, train loss: 10.466715, valid precision: 0.878400, valid loss: 93.441360
epoch: 2379, train precision: 0.999044, train loss: 10.473269, valid precision: 0.878000, valid loss: 92.350904
epoch: 2380, train precision: 0.999022, train loss: 10.455888, valid precision: 0.878200, valid loss: 91.482786
epoch: 2381, train precision: 0.999022, train loss: 10.411277, valid precision: 0.878600, valid loss: 89.495630
epoch: 2382, train precision: 0.998889, train loss: 10.517226, valid precision: 0.875800, valid loss: 91.624189
epoch: 2383, train precision: 0.999044, train loss: 10.435874, valid precision: 0.878600, valid loss: 88.490820
epoch: 2384, train precision: 0.998800, train loss: 10.579494, valid precision: 0.876600, valid loss: 92.604003
epoch: 2385, train precision: 0.999000, train loss: 10.455336, valid precision: 0.876200, valid loss: 91.950738
epoch: 2386, train precision: 0.998733, train loss: 10.535918, valid precision: 0.876000, valid loss: 92.300620
epoch: 2387, train precision: 0.999267, train loss: 10.354229, valid precision: 0.880200, valid loss: 90.410745
epoch: 2388, train precision: 0.998778, train loss: 10.518630, valid precision: 0.875800, valid loss: 92.387066
epoch: 2389, train precision: 0.999156, train loss: 10.470150, valid precision: 0.876800, valid loss: 91.721996
epoch: 2390, train precision: 0.998889, train loss: 10.485473, valid precision: 0.880000, valid loss: 91.635801
epoch: 2391, train precision: 0.998867, train loss: 10.539326, valid precision: 0.877000, valid loss: 91.350026
epoch: 2392, train precision: 0.998800, train loss: 10.516258, valid precision: 0.879800, valid loss: 88.482723
epoch: 2393, train precision: 0.999067, train loss: 10.464909, valid precision: 0.877600, valid loss: 89.296110
epoch: 2394, train precision: 0.999067, train loss: 10.412217, valid precision: 0.877800, valid loss: 89.900839
epoch: 2395, train precision: 0.999222, train loss: 10.401030, valid precision: 0.875800, valid loss: 91.764187
epoch: 2396, train precision: 0.998933, train loss: 10.488016, valid precision: 0.877200, valid loss: 91.473165
epoch: 2397, train precision: 0.998933, train loss: 10.495127, valid precision: 0.876200, valid loss: 93.595803
epoch: 2398, train precision: 0.999133, train loss: 10.412826, valid precision: 0.878200, valid loss: 91.405748
epoch: 2399, train precision: 0.999022, train loss: 10.437250, valid precision: 0.878800, valid loss: 93.102669
epoch: 2400, train precision: 0.998844, train loss: 10.531954, valid precision: 0.874200, valid loss: 94.652986
epoch: 2401, train precision: 0.999067, train loss: 10.470441, valid precision: 0.877800, valid loss: 92.562166
epoch: 2402, train precision: 0.998867, train loss: 10.517112, valid precision: 0.874800, valid loss: 92.494849
epoch: 2403, train precision: 0.999222, train loss: 10.426100, valid precision: 0.879400, valid loss: 93.852073
epoch: 2404, train precision: 0.999000, train loss: 10.531080, valid precision: 0.873400, valid loss: 91.807283
epoch: 2405, train precision: 0.998978, train loss: 10.504472, valid precision: 0.874800, valid loss: 91.728513
epoch: 2406, train precision: 0.998844, train loss: 10.581949, valid precision: 0.873600, valid loss: 93.686378
epoch: 2407, train precision: 0.999044, train loss: 10.397953, valid precision: 0.878600, valid loss: 92.977208
epoch: 2408, train precision: 0.998511, train loss: 10.650486, valid precision: 0.874000, valid loss: 94.367346
epoch: 2409, train precision: 0.998911, train loss: 10.476512, valid precision: 0.877200, valid loss: 92.329432
epoch: 2410, train precision: 0.999111, train loss: 10.416344, valid precision: 0.881200, valid loss: 90.689508
epoch: 2411, train precision: 0.999089, train loss: 10.405036, valid precision: 0.880200, valid loss: 93.366174
epoch: 2412, train precision: 0.998467, train loss: 10.556495, valid precision: 0.876200, valid loss: 91.696570
epoch: 2413, train precision: 0.999311, train loss: 10.429357, valid precision: 0.876600, valid loss: 91.769435
epoch: 2414, train precision: 0.999356, train loss: 10.383525, valid precision: 0.874800, valid loss: 94.069704
epoch: 2415, train precision: 0.998489, train loss: 10.643431, valid precision: 0.878000, valid loss: 94.980277
epoch: 2416, train precision: 0.999156, train loss: 10.395169, valid precision: 0.880200, valid loss: 91.676808
epoch: 2417, train precision: 0.998778, train loss: 10.525512, valid precision: 0.875600, valid loss: 97.170501
epoch: 2418, train precision: 0.998956, train loss: 10.455135, valid precision: 0.876200, valid loss: 94.465969
epoch: 2419, train precision: 0.998822, train loss: 10.470158, valid precision: 0.875200, valid loss: 96.924413
epoch: 2420, train precision: 0.999022, train loss: 10.446087, valid precision: 0.873800, valid loss: 92.656104
epoch: 2421, train precision: 0.999222, train loss: 10.396170, valid precision: 0.876400, valid loss: 95.329571
epoch: 2422, train precision: 0.998533, train loss: 10.625098, valid precision: 0.876200, valid loss: 95.559632
epoch: 2423, train precision: 0.998889, train loss: 10.512038, valid precision: 0.875800, valid loss: 92.149462
epoch: 2424, train precision: 0.999089, train loss: 10.408742, valid precision: 0.879600, valid loss: 93.519692
epoch: 2425, train precision: 0.998689, train loss: 10.558383, valid precision: 0.870400, valid loss: 92.311842
epoch: 2426, train precision: 0.998800, train loss: 10.527421, valid precision: 0.877600, valid loss: 92.212293
epoch: 2427, train precision: 0.999311, train loss: 10.430318, valid precision: 0.874000, valid loss: 93.726660
epoch: 2428, train precision: 0.999289, train loss: 10.406633, valid precision: 0.875800, valid loss: 95.513727
epoch: 2429, train precision: 0.999178, train loss: 10.453807, valid precision: 0.879000, valid loss: 91.882214
epoch: 2430, train precision: 0.999000, train loss: 10.529125, valid precision: 0.875800, valid loss: 93.026790
epoch: 2431, train precision: 0.998467, train loss: 10.551554, valid precision: 0.877600, valid loss: 93.612496
epoch: 2432, train precision: 0.998978, train loss: 10.477812, valid precision: 0.880800, valid loss: 90.700166
epoch: 2433, train precision: 0.998800, train loss: 10.460186, valid precision: 0.875800, valid loss: 92.316921
epoch: 2434, train precision: 0.999133, train loss: 10.441774, valid precision: 0.878600, valid loss: 91.239973
epoch: 2435, train precision: 0.998978, train loss: 10.484962, valid precision: 0.878000, valid loss: 92.633709
epoch: 2436, train precision: 0.998844, train loss: 10.497426, valid precision: 0.878000, valid loss: 92.451328
epoch: 2437, train precision: 0.998956, train loss: 10.491954, valid precision: 0.880000, valid loss: 92.403545
epoch: 2438, train precision: 0.999022, train loss: 10.474929, valid precision: 0.874400, valid loss: 94.226242
epoch: 2439, train precision: 0.999022, train loss: 10.451903, valid precision: 0.873000, valid loss: 95.780731
epoch: 2440, train precision: 0.999044, train loss: 10.414101, valid precision: 0.873000, valid loss: 93.160168
epoch: 2441, train precision: 0.998844, train loss: 10.537943, valid precision: 0.873600, valid loss: 92.981221
epoch: 2442, train precision: 0.998889, train loss: 10.458866, valid precision: 0.877200, valid loss: 93.294254
epoch: 2443, train precision: 0.999133, train loss: 10.404273, valid precision: 0.876600, valid loss: 95.946936
epoch: 2444, train precision: 0.998889, train loss: 10.467632, valid precision: 0.874600, valid loss: 95.653926
epoch: 2445, train precision: 0.999044, train loss: 10.423014, valid precision: 0.873600, valid loss: 94.858373
epoch: 2446, train precision: 0.998800, train loss: 10.555754, valid precision: 0.874600, valid loss: 95.832409
epoch: 2447, train precision: 0.999289, train loss: 10.392859, valid precision: 0.876200, valid loss: 95.355621
epoch: 2448, train precision: 0.998844, train loss: 10.491095, valid precision: 0.874200, valid loss: 96.745318
epoch: 2449, train precision: 0.998800, train loss: 10.506379, valid precision: 0.877400, valid loss: 94.200692
epoch: 2450, train precision: 0.999089, train loss: 10.396287, valid precision: 0.874600, valid loss: 96.921293
epoch: 2451, train precision: 0.998956, train loss: 10.454142, valid precision: 0.870200, valid loss: 95.214134
epoch: 2452, train precision: 0.998822, train loss: 10.524419, valid precision: 0.872800, valid loss: 95.457436
epoch: 2453, train precision: 0.998844, train loss: 10.513756, valid precision: 0.868000, valid loss: 95.825971
epoch: 2454, train precision: 0.998844, train loss: 10.502234, valid precision: 0.875200, valid loss: 93.290802
epoch: 2455, train precision: 0.998800, train loss: 10.581742, valid precision: 0.877000, valid loss: 92.276536
epoch: 2456, train precision: 0.998711, train loss: 10.549490, valid precision: 0.875000, valid loss: 93.755060
epoch: 2457, train precision: 0.998733, train loss: 10.487890, valid precision: 0.874200, valid loss: 96.062136
epoch: 2458, train precision: 0.999089, train loss: 10.439648, valid precision: 0.870800, valid loss: 97.681309
epoch: 2459, train precision: 0.998956, train loss: 10.443917, valid precision: 0.871400, valid loss: 96.416325
epoch: 2460, train precision: 0.998822, train loss: 10.488207, valid precision: 0.870000, valid loss: 94.755909
epoch: 2461, train precision: 0.998778, train loss: 10.552274, valid precision: 0.874200, valid loss: 95.875630
epoch: 2462, train precision: 0.999422, train loss: 10.342588, valid precision: 0.876400, valid loss: 96.323232
epoch: 2463, train precision: 0.998778, train loss: 10.569483, valid precision: 0.871800, valid loss: 97.603844
epoch: 2464, train precision: 0.999111, train loss: 10.405899, valid precision: 0.874000, valid loss: 95.637597
epoch: 2465, train precision: 0.998978, train loss: 10.487088, valid precision: 0.872000, valid loss: 95.938212
epoch: 2466, train precision: 0.998778, train loss: 10.521018, valid precision: 0.873200, valid loss: 93.432581
epoch: 2467, train precision: 0.998889, train loss: 10.480555, valid precision: 0.872600, valid loss: 96.585373
epoch: 2468, train precision: 0.999111, train loss: 10.441481, valid precision: 0.876000, valid loss: 96.151936
epoch: 2469, train precision: 0.999178, train loss: 10.419047, valid precision: 0.874800, valid loss: 96.202143
epoch: 2470, train precision: 0.998956, train loss: 10.470669, valid precision: 0.878800, valid loss: 96.655063
epoch: 2471, train precision: 0.998733, train loss: 10.527969, valid precision: 0.876600, valid loss: 96.703111
epoch: 2472, train precision: 0.999422, train loss: 10.346660, valid precision: 0.880200, valid loss: 92.820922
epoch: 2473, train precision: 0.998844, train loss: 10.469148, valid precision: 0.875000, valid loss: 94.932375
epoch: 2474, train precision: 0.999000, train loss: 10.517245, valid precision: 0.877600, valid loss: 95.996668
epoch: 2475, train precision: 0.999133, train loss: 10.398988, valid precision: 0.875400, valid loss: 94.225103
epoch: 2476, train precision: 0.999000, train loss: 10.448248, valid precision: 0.873800, valid loss: 95.299672
epoch: 2477, train precision: 0.999244, train loss: 10.402887, valid precision: 0.876400, valid loss: 95.600556
epoch: 2478, train precision: 0.998533, train loss: 10.531242, valid precision: 0.874200, valid loss: 95.990977
epoch: 2479, train precision: 0.999489, train loss: 10.330383, valid precision: 0.873800, valid loss: 94.652774
epoch: 2480, train precision: 0.999133, train loss: 10.435419, valid precision: 0.875200, valid loss: 97.717696
epoch: 2481, train precision: 0.998978, train loss: 10.462356, valid precision: 0.870800, valid loss: 97.008396
epoch: 2482, train precision: 0.999244, train loss: 10.399597, valid precision: 0.874600, valid loss: 99.952492
epoch: 2483, train precision: 0.998911, train loss: 10.495972, valid precision: 0.875600, valid loss: 97.924190
epoch: 2484, train precision: 0.999067, train loss: 10.421494, valid precision: 0.877800, valid loss: 95.863752
epoch: 2485, train precision: 0.999311, train loss: 10.371277, valid precision: 0.874800, valid loss: 95.183274
epoch: 2486, train precision: 0.998733, train loss: 10.579142, valid precision: 0.873600, valid loss: 98.085622
epoch: 2487, train precision: 0.998933, train loss: 10.432144, valid precision: 0.872600, valid loss: 95.448178
epoch: 2488, train precision: 0.999289, train loss: 10.380966, valid precision: 0.873400, valid loss: 97.265479
epoch: 2489, train precision: 0.999022, train loss: 10.371378, valid precision: 0.874600, valid loss: 98.040599
epoch: 2490, train precision: 0.999022, train loss: 10.445973, valid precision: 0.874200, valid loss: 99.367436
epoch: 2491, train precision: 0.998978, train loss: 10.463853, valid precision: 0.874800, valid loss: 96.360479
epoch: 2492, train precision: 0.998778, train loss: 10.582683, valid precision: 0.874000, valid loss: 98.480215
epoch: 2493, train precision: 0.998800, train loss: 10.462548, valid precision: 0.871200, valid loss: 98.348189
epoch: 2494, train precision: 0.998867, train loss: 10.517063, valid precision: 0.870600, valid loss: 94.904921
epoch: 2495, train precision: 0.999044, train loss: 10.386931, valid precision: 0.876000, valid loss: 97.015897
epoch: 2496, train precision: 0.998711, train loss: 10.540841, valid precision: 0.872600, valid loss: 96.508039
epoch: 2497, train precision: 0.999200, train loss: 10.391880, valid precision: 0.875400, valid loss: 95.181214
epoch: 2498, train precision: 0.999133, train loss: 10.406762, valid precision: 0.871000, valid loss: 97.598742
epoch: 2499, train precision: 0.999044, train loss: 10.444907, valid precision: 0.872000, valid loss: 96.127493
epoch: 2500, train precision: 0.999022, train loss: 10.444819, valid precision: 0.871600, valid loss: 94.445922
epoch: 2501, train precision: 0.999000, train loss: 10.463989, valid precision: 0.873400, valid loss: 96.208518
epoch: 2502, train precision: 0.999200, train loss: 10.399222, valid precision: 0.877000, valid loss: 95.746707
epoch: 2503, train precision: 0.999222, train loss: 10.379614, valid precision: 0.873400, valid loss: 96.589726
epoch: 2504, train precision: 0.999222, train loss: 10.396312, valid precision: 0.871400, valid loss: 94.787509
epoch: 2505, train precision: 0.999111, train loss: 10.389522, valid precision: 0.874800, valid loss: 95.294964
epoch: 2506, train precision: 0.998489, train loss: 10.568733, valid precision: 0.878000, valid loss: 94.944189
epoch: 2507, train precision: 0.999133, train loss: 10.410030, valid precision: 0.880400, valid loss: 90.888449
epoch: 2508, train precision: 0.999156, train loss: 10.408563, valid precision: 0.874600, valid loss: 93.577918
epoch: 2509, train precision: 0.999067, train loss: 10.517244, valid precision: 0.874200, valid loss: 96.177196
epoch: 2510, train precision: 0.999133, train loss: 10.431321, valid precision: 0.870400, valid loss: 95.810939
epoch: 2511, train precision: 0.998600, train loss: 10.532448, valid precision: 0.872000, valid loss: 96.671291
epoch: 2512, train precision: 0.999133, train loss: 10.373214, valid precision: 0.871800, valid loss: 94.973970
epoch: 2513, train precision: 0.998822, train loss: 10.506556, valid precision: 0.872000, valid loss: 95.128527
epoch: 2514, train precision: 0.998733, train loss: 10.505544, valid precision: 0.878400, valid loss: 94.044243
epoch: 2515, train precision: 0.998911, train loss: 10.513584, valid precision: 0.875600, valid loss: 94.787959
epoch: 2516, train precision: 0.998756, train loss: 10.492093, valid precision: 0.876600, valid loss: 95.095313
epoch: 2517, train precision: 0.998889, train loss: 10.425877, valid precision: 0.876400, valid loss: 94.975513
epoch: 2518, train precision: 0.999222, train loss: 10.411067, valid precision: 0.873400, valid loss: 95.066538
epoch: 2519, train precision: 0.998867, train loss: 10.506538, valid precision: 0.872600, valid loss: 96.206254
epoch: 2520, train precision: 0.999111, train loss: 10.377737, valid precision: 0.877000, valid loss: 94.934276
epoch: 2521, train precision: 0.998756, train loss: 10.499100, valid precision: 0.872200, valid loss: 97.742601
epoch: 2522, train precision: 0.998267, train loss: 10.638012, valid precision: 0.872600, valid loss: 96.003765
epoch: 2523, train precision: 0.998867, train loss: 10.431412, valid precision: 0.876600, valid loss: 97.649465
epoch: 2524, train precision: 0.999111, train loss: 10.399527, valid precision: 0.872800, valid loss: 96.802407
epoch: 2525, train precision: 0.999000, train loss: 10.445415, valid precision: 0.872200, valid loss: 97.082659
epoch: 2526, train precision: 0.998756, train loss: 10.483214, valid precision: 0.874200, valid loss: 98.472328
epoch: 2527, train precision: 0.999044, train loss: 10.444480, valid precision: 0.873600, valid loss: 97.223959
epoch: 2528, train precision: 0.998444, train loss: 10.602673, valid precision: 0.870600, valid loss: 100.356093
epoch: 2529, train precision: 0.998956, train loss: 10.457922, valid precision: 0.872800, valid loss: 97.790394
epoch: 2530, train precision: 0.999156, train loss: 10.466857, valid precision: 0.874400, valid loss: 95.037717
epoch: 2531, train precision: 0.999089, train loss: 10.401703, valid precision: 0.872600, valid loss: 95.793235
epoch: 2532, train precision: 0.998889, train loss: 10.521913, valid precision: 0.870600, valid loss: 98.443396
epoch: 2533, train precision: 0.998978, train loss: 10.422556, valid precision: 0.874400, valid loss: 96.344815
epoch: 2534, train precision: 0.998933, train loss: 10.410551, valid precision: 0.876200, valid loss: 96.026545
epoch: 2535, train precision: 0.999178, train loss: 10.375341, valid precision: 0.875200, valid loss: 95.431506
epoch: 2536, train precision: 0.999133, train loss: 10.420599, valid precision: 0.877200, valid loss: 95.478197
epoch: 2537, train precision: 0.998933, train loss: 10.431874, valid precision: 0.875000, valid loss: 95.425043
epoch: 2538, train precision: 0.999111, train loss: 10.460694, valid precision: 0.877000, valid loss: 95.496072
epoch: 2539, train precision: 0.999489, train loss: 10.371955, valid precision: 0.874800, valid loss: 93.801063
epoch: 2540, train precision: 0.999200, train loss: 10.397624, valid precision: 0.875200, valid loss: 95.000418
epoch: 2541, train precision: 0.998822, train loss: 10.427316, valid precision: 0.873200, valid loss: 94.291036
epoch: 2542, train precision: 0.998933, train loss: 10.454252, valid precision: 0.873800, valid loss: 94.669913
epoch: 2543, train precision: 0.998800, train loss: 10.507228, valid precision: 0.874600, valid loss: 93.424316
epoch: 2544, train precision: 0.998422, train loss: 10.566609, valid precision: 0.877200, valid loss: 93.873056
epoch: 2545, train precision: 0.998778, train loss: 10.539885, valid precision: 0.877400, valid loss: 93.278506
epoch: 2546, train precision: 0.999022, train loss: 10.425948, valid precision: 0.879000, valid loss: 94.414851
epoch: 2547, train precision: 0.998956, train loss: 10.452387, valid precision: 0.878600, valid loss: 95.382475
epoch: 2548, train precision: 0.999067, train loss: 10.450657, valid precision: 0.875200, valid loss: 94.512460
epoch: 2549, train precision: 0.998844, train loss: 10.506802, valid precision: 0.877800, valid loss: 94.100021
epoch: 2550, train precision: 0.999022, train loss: 10.438987, valid precision: 0.877400, valid loss: 94.857756
epoch: 2551, train precision: 0.998933, train loss: 10.440706, valid precision: 0.876400, valid loss: 96.891769
epoch: 2552, train precision: 0.998644, train loss: 10.556451, valid precision: 0.872000, valid loss: 98.015819
epoch: 2553, train precision: 0.999089, train loss: 10.443523, valid precision: 0.876000, valid loss: 96.960424
epoch: 2554, train precision: 0.998933, train loss: 10.464559, valid precision: 0.873000, valid loss: 97.902915
epoch: 2555, train precision: 0.999000, train loss: 10.447832, valid precision: 0.872600, valid loss: 98.401617
epoch: 2556, train precision: 0.999178, train loss: 10.344983, valid precision: 0.871200, valid loss: 98.802935
epoch: 2557, train precision: 0.998711, train loss: 10.450742, valid precision: 0.877400, valid loss: 98.992092
epoch: 2558, train precision: 0.998733, train loss: 10.505640, valid precision: 0.869600, valid loss: 95.913102
epoch: 2559, train precision: 0.998822, train loss: 10.570851, valid precision: 0.875600, valid loss: 96.930284
epoch: 2560, train precision: 0.999044, train loss: 10.436752, valid precision: 0.874800, valid loss: 95.402033
epoch: 2561, train precision: 0.999222, train loss: 10.375905, valid precision: 0.874600, valid loss: 96.952440
epoch: 2562, train precision: 0.998956, train loss: 10.446372, valid precision: 0.871800, valid loss: 95.253377
epoch: 2563, train precision: 0.998578, train loss: 10.591949, valid precision: 0.873000, valid loss: 95.567494
epoch: 2564, train precision: 0.999111, train loss: 10.384630, valid precision: 0.874200, valid loss: 94.257792
epoch: 2565, train precision: 0.998978, train loss: 10.444072, valid precision: 0.876400, valid loss: 93.206116
epoch: 2566, train precision: 0.999178, train loss: 10.395810, valid precision: 0.875400, valid loss: 93.399037
epoch: 2567, train precision: 0.998778, train loss: 10.517287, valid precision: 0.875000, valid loss: 94.114683
epoch: 2568, train precision: 0.999089, train loss: 10.458070, valid precision: 0.871800, valid loss: 96.804659
epoch: 2569, train precision: 0.998667, train loss: 10.518868, valid precision: 0.869400, valid loss: 98.187122
epoch: 2570, train precision: 0.999311, train loss: 10.360326, valid precision: 0.871600, valid loss: 98.633079
epoch: 2571, train precision: 0.998889, train loss: 10.419060, valid precision: 0.873400, valid loss: 99.125539
epoch: 2572, train precision: 0.998844, train loss: 10.466189, valid precision: 0.872800, valid loss: 97.605718
epoch: 2573, train precision: 0.999156, train loss: 10.381701, valid precision: 0.876800, valid loss: 95.630944
epoch: 2574, train precision: 0.999067, train loss: 10.397235, valid precision: 0.875200, valid loss: 97.549774
epoch: 2575, train precision: 0.999533, train loss: 10.321012, valid precision: 0.874600, valid loss: 96.279942
epoch: 2576, train precision: 0.999156, train loss: 10.361245, valid precision: 0.875800, valid loss: 97.204375
epoch: 2577, train precision: 0.999067, train loss: 10.422026, valid precision: 0.875000, valid loss: 100.121363
epoch: 2578, train precision: 0.998800, train loss: 10.484639, valid precision: 0.871000, valid loss: 98.775858
epoch: 2579, train precision: 0.999222, train loss: 10.406985, valid precision: 0.870600, valid loss: 95.959479
epoch: 2580, train precision: 0.998667, train loss: 10.463220, valid precision: 0.875000, valid loss: 96.065970
epoch: 2581, train precision: 0.999444, train loss: 10.310033, valid precision: 0.874000, valid loss: 95.817185
epoch: 2582, train precision: 0.998756, train loss: 10.514813, valid precision: 0.873600, valid loss: 98.423759
epoch: 2583, train precision: 0.999133, train loss: 10.409720, valid precision: 0.873200, valid loss: 96.823876
epoch: 2584, train precision: 0.999044, train loss: 10.408116, valid precision: 0.875800, valid loss: 97.117685
epoch: 2585, train precision: 0.999156, train loss: 10.357279, valid precision: 0.873600, valid loss: 97.590193
epoch: 2586, train precision: 0.998733, train loss: 10.562193, valid precision: 0.868000, valid loss: 98.562456
epoch: 2587, train precision: 0.999022, train loss: 10.404361, valid precision: 0.875600, valid loss: 96.437232
epoch: 2588, train precision: 0.998756, train loss: 10.476772, valid precision: 0.870200, valid loss: 97.849329
epoch: 2589, train precision: 0.999067, train loss: 10.416880, valid precision: 0.875000, valid loss: 99.609751
epoch: 2590, train precision: 0.999089, train loss: 10.420229, valid precision: 0.871400, valid loss: 97.644375
epoch: 2591, train precision: 0.998978, train loss: 10.427315, valid precision: 0.875200, valid loss: 97.520045
epoch: 2592, train precision: 0.999156, train loss: 10.387400, valid precision: 0.871000, valid loss: 97.269843
epoch: 2593, train precision: 0.999178, train loss: 10.461451, valid precision: 0.870600, valid loss: 95.601331
epoch: 2594, train precision: 0.998822, train loss: 10.463574, valid precision: 0.877200, valid loss: 95.330829
epoch: 2595, train precision: 0.999178, train loss: 10.379096, valid precision: 0.875400, valid loss: 95.534236
epoch: 2596, train precision: 0.998867, train loss: 10.487627, valid precision: 0.875200, valid loss: 98.370738
epoch: 2597, train precision: 0.999044, train loss: 10.444936, valid precision: 0.870400, valid loss: 97.317165
epoch: 2598, train precision: 0.998800, train loss: 10.482291, valid precision: 0.874400, valid loss: 97.742890
epoch: 2599, train precision: 0.998489, train loss: 10.617997, valid precision: 0.870400, valid loss: 97.144255
epoch: 2600, train precision: 0.999067, train loss: 10.391834, valid precision: 0.878000, valid loss: 95.135690
epoch: 2601, train precision: 0.999133, train loss: 10.412376, valid precision: 0.874600, valid loss: 95.294495
epoch: 2602, train precision: 0.998911, train loss: 10.410315, valid precision: 0.876000, valid loss: 93.381075
epoch: 2603, train precision: 0.999200, train loss: 10.423254, valid precision: 0.874400, valid loss: 93.635921
epoch: 2604, train precision: 0.999200, train loss: 10.427093, valid precision: 0.875000, valid loss: 91.409707
epoch: 2605, train precision: 0.999133, train loss: 10.432416, valid precision: 0.878600, valid loss: 92.052682
epoch: 2606, train precision: 0.998956, train loss: 10.460005, valid precision: 0.877000, valid loss: 93.443769
epoch: 2607, train precision: 0.998933, train loss: 10.500050, valid precision: 0.876800, valid loss: 92.855940
epoch: 2608, train precision: 0.999000, train loss: 10.364947, valid precision: 0.871800, valid loss: 95.050896
epoch: 2609, train precision: 0.998911, train loss: 10.537643, valid precision: 0.871600, valid loss: 94.596816
epoch: 2610, train precision: 0.998689, train loss: 10.577627, valid precision: 0.872800, valid loss: 96.360889
epoch: 2611, train precision: 0.999044, train loss: 10.358191, valid precision: 0.875000, valid loss: 94.986718
epoch: 2612, train precision: 0.998333, train loss: 10.665303, valid precision: 0.872800, valid loss: 99.434362
epoch: 2613, train precision: 0.999222, train loss: 10.382940, valid precision: 0.875000, valid loss: 94.925511
epoch: 2614, train precision: 0.998911, train loss: 10.424697, valid precision: 0.874400, valid loss: 93.242184
epoch: 2615, train precision: 0.999311, train loss: 10.355950, valid precision: 0.878200, valid loss: 92.413545
epoch: 2616, train precision: 0.999133, train loss: 10.396864, valid precision: 0.875800, valid loss: 93.593777
epoch: 2617, train precision: 0.999111, train loss: 10.380118, valid precision: 0.875000, valid loss: 96.278124
epoch: 2618, train precision: 0.998889, train loss: 10.490099, valid precision: 0.872200, valid loss: 96.279470
epoch: 2619, train precision: 0.999111, train loss: 10.390004, valid precision: 0.871200, valid loss: 95.915221
epoch: 2620, train precision: 0.998511, train loss: 10.596273, valid precision: 0.873600, valid loss: 95.004442
epoch: 2621, train precision: 0.998956, train loss: 10.416674, valid precision: 0.874000, valid loss: 91.156639
epoch: 2622, train precision: 0.999067, train loss: 10.422684, valid precision: 0.874000, valid loss: 95.069576
epoch: 2623, train precision: 0.998844, train loss: 10.439963, valid precision: 0.875400, valid loss: 94.824990
epoch: 2624, train precision: 0.999044, train loss: 10.465530, valid precision: 0.879800, valid loss: 94.205477
epoch: 2625, train precision: 0.999311, train loss: 10.372957, valid precision: 0.875800, valid loss: 93.731720
epoch: 2626, train precision: 0.998889, train loss: 10.446287, valid precision: 0.872800, valid loss: 95.826730
epoch: 2627, train precision: 0.998867, train loss: 10.480718, valid precision: 0.874000, valid loss: 95.363507
epoch: 2628, train precision: 0.998978, train loss: 10.456539, valid precision: 0.875000, valid loss: 94.811243
epoch: 2629, train precision: 0.999067, train loss: 10.383255, valid precision: 0.869200, valid loss: 95.275028
epoch: 2630, train precision: 0.999178, train loss: 10.402211, valid precision: 0.873800, valid loss: 98.022057
epoch: 2631, train precision: 0.999222, train loss: 10.370341, valid precision: 0.878600, valid loss: 94.029274
epoch: 2632, train precision: 0.999222, train loss: 10.355841, valid precision: 0.879800, valid loss: 96.746353
epoch: 2633, train precision: 0.998533, train loss: 10.512279, valid precision: 0.874000, valid loss: 96.655189
epoch: 2634, train precision: 0.999000, train loss: 10.408494, valid precision: 0.876800, valid loss: 95.560383
epoch: 2635, train precision: 0.998644, train loss: 10.483225, valid precision: 0.876200, valid loss: 94.680737
epoch: 2636, train precision: 0.999067, train loss: 10.442164, valid precision: 0.875800, valid loss: 91.505456
epoch: 2637, train precision: 0.998844, train loss: 10.508671, valid precision: 0.875800, valid loss: 94.159365
epoch: 2638, train precision: 0.999022, train loss: 10.435079, valid precision: 0.873200, valid loss: 93.324992
epoch: 2639, train precision: 0.999133, train loss: 10.380118, valid precision: 0.877400, valid loss: 93.532120
epoch: 2640, train precision: 0.999200, train loss: 10.321087, valid precision: 0.876200, valid loss: 92.582657
epoch: 2641, train precision: 0.999267, train loss: 10.376853, valid precision: 0.875200, valid loss: 91.917969
epoch: 2642, train precision: 0.999111, train loss: 10.343449, valid precision: 0.876200, valid loss: 92.585081
epoch: 2643, train precision: 0.998933, train loss: 10.412887, valid precision: 0.875400, valid loss: 92.661237
epoch: 2644, train precision: 0.998889, train loss: 10.459185, valid precision: 0.874400, valid loss: 96.254012
epoch: 2645, train precision: 0.998844, train loss: 10.539992, valid precision: 0.873200, valid loss: 94.927849
epoch: 2646, train precision: 0.999200, train loss: 10.380406, valid precision: 0.873400, valid loss: 96.483330
epoch: 2647, train precision: 0.998844, train loss: 10.482213, valid precision: 0.870600, valid loss: 97.744335
epoch: 2648, train precision: 0.998867, train loss: 10.538053, valid precision: 0.870200, valid loss: 97.066839
epoch: 2649, train precision: 0.998889, train loss: 10.422653, valid precision: 0.871000, valid loss: 95.952904
epoch: 2650, train precision: 0.999022, train loss: 10.482545, valid precision: 0.872400, valid loss: 95.892848
epoch: 2651, train precision: 0.999022, train loss: 10.423092, valid precision: 0.876000, valid loss: 94.091282
epoch: 2652, train precision: 0.998800, train loss: 10.498459, valid precision: 0.874200, valid loss: 93.875185
epoch: 2653, train precision: 0.999067, train loss: 10.405399, valid precision: 0.871200, valid loss: 96.486951
epoch: 2654, train precision: 0.998933, train loss: 10.375115, valid precision: 0.874800, valid loss: 96.107488
epoch: 2655, train precision: 0.999333, train loss: 10.348919, valid precision: 0.874400, valid loss: 94.721219
epoch: 2656, train precision: 0.998533, train loss: 10.502252, valid precision: 0.872600, valid loss: 95.840017
epoch: 2657, train precision: 0.998800, train loss: 10.482858, valid precision: 0.874200, valid loss: 96.157637
epoch: 2658, train precision: 0.999156, train loss: 10.417871, valid precision: 0.884000, valid loss: 92.632112
epoch: 2659, train precision: 0.998844, train loss: 10.402736, valid precision: 0.874800, valid loss: 96.966697
epoch: 2660, train precision: 0.998778, train loss: 10.544337, valid precision: 0.877600, valid loss: 93.241910
epoch: 2661, train precision: 0.999200, train loss: 10.387171, valid precision: 0.877200, valid loss: 93.948892
epoch: 2662, train precision: 0.998978, train loss: 10.399591, valid precision: 0.874800, valid loss: 94.888300
epoch: 2663, train precision: 0.999000, train loss: 10.442462, valid precision: 0.874800, valid loss: 96.059540
epoch: 2664, train precision: 0.998778, train loss: 10.511947, valid precision: 0.876200, valid loss: 92.964421
epoch: 2665, train precision: 0.998889, train loss: 10.421140, valid precision: 0.872000, valid loss: 95.310811
epoch: 2666, train precision: 0.998822, train loss: 10.550487, valid precision: 0.873200, valid loss: 96.728482
epoch: 2667, train precision: 0.998489, train loss: 10.560667, valid precision: 0.876400, valid loss: 93.416584
epoch: 2668, train precision: 0.998911, train loss: 10.435597, valid precision: 0.876000, valid loss: 95.065893
epoch: 2669, train precision: 0.999133, train loss: 10.369595, valid precision: 0.875200, valid loss: 95.433886
epoch: 2670, train precision: 0.999133, train loss: 10.402360, valid precision: 0.871000, valid loss: 96.967043
epoch: 2671, train precision: 0.998800, train loss: 10.489932, valid precision: 0.877800, valid loss: 96.759856
epoch: 2672, train precision: 0.998533, train loss: 10.581482, valid precision: 0.870600, valid loss: 99.415585
epoch: 2673, train precision: 0.998889, train loss: 10.473625, valid precision: 0.875200, valid loss: 97.434848
epoch: 2674, train precision: 0.998911, train loss: 10.417605, valid precision: 0.872800, valid loss: 95.306602
epoch: 2675, train precision: 0.998911, train loss: 10.439712, valid precision: 0.877200, valid loss: 94.086940
epoch: 2676, train precision: 0.999000, train loss: 10.382521, valid precision: 0.875000, valid loss: 96.465516
epoch: 2677, train precision: 0.998956, train loss: 10.423968, valid precision: 0.872600, valid loss: 95.236583
epoch: 2678, train precision: 0.998778, train loss: 10.507175, valid precision: 0.877400, valid loss: 93.695344
epoch: 2679, train precision: 0.999111, train loss: 10.378887, valid precision: 0.879600, valid loss: 92.609097
epoch: 2680, train precision: 0.998733, train loss: 10.470479, valid precision: 0.875000, valid loss: 93.860160
epoch: 2681, train precision: 0.999089, train loss: 10.366333, valid precision: 0.875400, valid loss: 97.511134
epoch: 2682, train precision: 0.999244, train loss: 10.371025, valid precision: 0.875000, valid loss: 94.495259
epoch: 2683, train precision: 0.998822, train loss: 10.514788, valid precision: 0.878200, valid loss: 91.398497
epoch: 2684, train precision: 0.999178, train loss: 10.388087, valid precision: 0.873600, valid loss: 95.494467
epoch: 2685, train precision: 0.999111, train loss: 10.382531, valid precision: 0.877000, valid loss: 94.743265
epoch: 2686, train precision: 0.998911, train loss: 10.410170, valid precision: 0.881400, valid loss: 93.572984
epoch: 2687, train precision: 0.998733, train loss: 10.494136, valid precision: 0.875000, valid loss: 95.460530
epoch: 2688, train precision: 0.998911, train loss: 10.444594, valid precision: 0.873200, valid loss: 94.722200
epoch: 2689, train precision: 0.999067, train loss: 10.393274, valid precision: 0.876600, valid loss: 94.434562
epoch: 2690, train precision: 0.999000, train loss: 10.361752, valid precision: 0.872400, valid loss: 96.164876
epoch: 2691, train precision: 0.999289, train loss: 10.328538, valid precision: 0.876600, valid loss: 94.334813
epoch: 2692, train precision: 0.999022, train loss: 10.418689, valid precision: 0.872400, valid loss: 94.912170
epoch: 2693, train precision: 0.998800, train loss: 10.488809, valid precision: 0.871400, valid loss: 95.036372
epoch: 2694, train precision: 0.999067, train loss: 10.368141, valid precision: 0.871600, valid loss: 93.703222
epoch: 2695, train precision: 0.998956, train loss: 10.433491, valid precision: 0.875200, valid loss: 93.277011
epoch: 2696, train precision: 0.998956, train loss: 10.371063, valid precision: 0.877200, valid loss: 92.661833
epoch: 2697, train precision: 0.999156, train loss: 10.375913, valid precision: 0.873400, valid loss: 93.975246
epoch: 2698, train precision: 0.999156, train loss: 10.348492, valid precision: 0.873200, valid loss: 95.031358
epoch: 2699, train precision: 0.999133, train loss: 10.343334, valid precision: 0.877600, valid loss: 93.278925
epoch: 2700, train precision: 0.998667, train loss: 10.531029, valid precision: 0.872800, valid loss: 92.188833
epoch: 2701, train precision: 0.999178, train loss: 10.350362, valid precision: 0.875800, valid loss: 93.413381
epoch: 2702, train precision: 0.998667, train loss: 10.514213, valid precision: 0.875800, valid loss: 95.713998
epoch: 2703, train precision: 0.998933, train loss: 10.424480, valid precision: 0.871000, valid loss: 94.192074
epoch: 2704, train precision: 0.998489, train loss: 10.534948, valid precision: 0.871600, valid loss: 94.438912
epoch: 2705, train precision: 0.998911, train loss: 10.445089, valid precision: 0.874800, valid loss: 93.166707
epoch: 2706, train precision: 0.999089, train loss: 10.391519, valid precision: 0.878200, valid loss: 93.670493
epoch: 2707, train precision: 0.999133, train loss: 10.332825, valid precision: 0.873400, valid loss: 93.209247
epoch: 2708, train precision: 0.999111, train loss: 10.351958, valid precision: 0.876600, valid loss: 93.564211
epoch: 2709, train precision: 0.998511, train loss: 10.524098, valid precision: 0.877600, valid loss: 93.685693
epoch: 2710, train precision: 0.998733, train loss: 10.514956, valid precision: 0.877800, valid loss: 94.105758
epoch: 2711, train precision: 0.998978, train loss: 10.359550, valid precision: 0.877600, valid loss: 93.886320
epoch: 2712, train precision: 0.999044, train loss: 10.395671, valid precision: 0.873600, valid loss: 94.777694
epoch: 2713, train precision: 0.998933, train loss: 10.382086, valid precision: 0.877400, valid loss: 93.367425
epoch: 2714, train precision: 0.999067, train loss: 10.400307, valid precision: 0.875000, valid loss: 92.670272
epoch: 2715, train precision: 0.999289, train loss: 10.365407, valid precision: 0.877600, valid loss: 92.941169
epoch: 2716, train precision: 0.998533, train loss: 10.530049, valid precision: 0.874200, valid loss: 93.174993
epoch: 2717, train precision: 0.998889, train loss: 10.479643, valid precision: 0.874600, valid loss: 94.084292
epoch: 2718, train precision: 0.998267, train loss: 10.667736, valid precision: 0.871600, valid loss: 96.863593
epoch: 2719, train precision: 0.998733, train loss: 10.462755, valid precision: 0.874800, valid loss: 96.144624
epoch: 2720, train precision: 0.998800, train loss: 10.443397, valid precision: 0.877200, valid loss: 95.001134
epoch: 2721, train precision: 0.999133, train loss: 10.380086, valid precision: 0.877400, valid loss: 94.946170
epoch: 2722, train precision: 0.999222, train loss: 10.375894, valid precision: 0.873200, valid loss: 96.377864
epoch: 2723, train precision: 0.999044, train loss: 10.382731, valid precision: 0.875000, valid loss: 94.727567
epoch: 2724, train precision: 0.999133, train loss: 10.373028, valid precision: 0.875000, valid loss: 93.438173
epoch: 2725, train precision: 0.998911, train loss: 10.478154, valid precision: 0.875400, valid loss: 95.087510
epoch: 2726, train precision: 0.998689, train loss: 10.520003, valid precision: 0.880000, valid loss: 93.133712
epoch: 2727, train precision: 0.999200, train loss: 10.371589, valid precision: 0.875000, valid loss: 94.104684
epoch: 2728, train precision: 0.999022, train loss: 10.408890, valid precision: 0.879000, valid loss: 92.639959
epoch: 2729, train precision: 0.999156, train loss: 10.316190, valid precision: 0.879600, valid loss: 95.251626
epoch: 2730, train precision: 0.998689, train loss: 10.556874, valid precision: 0.876200, valid loss: 93.574432
epoch: 2731, train precision: 0.998933, train loss: 10.441301, valid precision: 0.872400, valid loss: 93.778897
epoch: 2732, train precision: 0.999356, train loss: 10.359071, valid precision: 0.879000, valid loss: 90.929263
epoch: 2733, train precision: 0.999222, train loss: 10.378933, valid precision: 0.876200, valid loss: 93.848419
epoch: 2734, train precision: 0.998844, train loss: 10.472528, valid precision: 0.875800, valid loss: 95.505456
epoch: 2735, train precision: 0.998422, train loss: 10.566840, valid precision: 0.873000, valid loss: 96.021777
epoch: 2736, train precision: 0.999111, train loss: 10.376839, valid precision: 0.875400, valid loss: 94.693463
epoch: 2737, train precision: 0.998867, train loss: 10.433487, valid precision: 0.874000, valid loss: 96.003378
epoch: 2738, train precision: 0.999311, train loss: 10.330841, valid precision: 0.874600, valid loss: 93.654690
epoch: 2739, train precision: 0.998578, train loss: 10.535029, valid precision: 0.875400, valid loss: 96.092385
epoch: 2740, train precision: 0.999333, train loss: 10.300620, valid precision: 0.873200, valid loss: 94.409514
epoch: 2741, train precision: 0.999267, train loss: 10.322830, valid precision: 0.878600, valid loss: 93.108845
epoch: 2742, train precision: 0.998667, train loss: 10.500235, valid precision: 0.875000, valid loss: 97.283161
epoch: 2743, train precision: 0.999133, train loss: 10.327896, valid precision: 0.872200, valid loss: 97.195296
epoch: 2744, train precision: 0.998600, train loss: 10.535834, valid precision: 0.874000, valid loss: 95.268583
epoch: 2745, train precision: 0.999022, train loss: 10.359762, valid precision: 0.879000, valid loss: 94.680436
epoch: 2746, train precision: 0.999156, train loss: 10.351636, valid precision: 0.875200, valid loss: 93.807691
epoch: 2747, train precision: 0.999000, train loss: 10.402361, valid precision: 0.876000, valid loss: 94.021742
epoch: 2748, train precision: 0.998933, train loss: 10.422220, valid precision: 0.871400, valid loss: 93.272397
epoch: 2749, train precision: 0.999289, train loss: 10.307014, valid precision: 0.874000, valid loss: 94.342797
epoch: 2750, train precision: 0.999222, train loss: 10.320686, valid precision: 0.878800, valid loss: 93.738096
epoch: 2751, train precision: 0.999200, train loss: 10.379617, valid precision: 0.871800, valid loss: 93.083353
epoch: 2752, train precision: 0.999067, train loss: 10.360404, valid precision: 0.874400, valid loss: 95.219659
epoch: 2753, train precision: 0.998911, train loss: 10.400020, valid precision: 0.872000, valid loss: 96.577774
epoch: 2754, train precision: 0.998933, train loss: 10.443781, valid precision: 0.874800, valid loss: 94.748129
epoch: 2755, train precision: 0.998889, train loss: 10.448879, valid precision: 0.874000, valid loss: 95.402904
epoch: 2756, train precision: 0.998778, train loss: 10.507382, valid precision: 0.874400, valid loss: 96.089148
epoch: 2757, train precision: 0.999067, train loss: 10.366957, valid precision: 0.872400, valid loss: 95.672694
epoch: 2758, train precision: 0.999022, train loss: 10.384212, valid precision: 0.873600, valid loss: 98.340129
epoch: 2759, train precision: 0.999133, train loss: 10.354483, valid precision: 0.873600, valid loss: 97.151293
epoch: 2760, train precision: 0.998622, train loss: 10.575778, valid precision: 0.873800, valid loss: 98.532436
epoch: 2761, train precision: 0.998778, train loss: 10.525755, valid precision: 0.875600, valid loss: 96.152514
epoch: 2762, train precision: 0.998889, train loss: 10.446412, valid precision: 0.875200, valid loss: 97.065998
epoch: 2763, train precision: 0.998889, train loss: 10.439815, valid precision: 0.879200, valid loss: 96.731097
epoch: 2764, train precision: 0.999356, train loss: 10.294542, valid precision: 0.877600, valid loss: 96.330740
epoch: 2765, train precision: 0.998911, train loss: 10.417336, valid precision: 0.875800, valid loss: 95.216965
epoch: 2766, train precision: 0.999000, train loss: 10.415636, valid precision: 0.872600, valid loss: 95.019607
epoch: 2767, train precision: 0.999156, train loss: 10.369296, valid precision: 0.870000, valid loss: 96.493271
epoch: 2768, train precision: 0.998933, train loss: 10.394515, valid precision: 0.872000, valid loss: 94.075338
epoch: 2769, train precision: 0.998889, train loss: 10.456634, valid precision: 0.872600, valid loss: 96.896909
epoch: 2770, train precision: 0.999044, train loss: 10.383422, valid precision: 0.872000, valid loss: 96.700858
epoch: 2771, train precision: 0.999133, train loss: 10.303834, valid precision: 0.875200, valid loss: 97.224012
epoch: 2772, train precision: 0.998822, train loss: 10.476520, valid precision: 0.872600, valid loss: 96.901517
epoch: 2773, train precision: 0.999067, train loss: 10.358540, valid precision: 0.880400, valid loss: 95.917948
epoch: 2774, train precision: 0.998511, train loss: 10.539597, valid precision: 0.871400, valid loss: 94.809548
epoch: 2775, train precision: 0.999156, train loss: 10.347649, valid precision: 0.874600, valid loss: 97.217689
epoch: 2776, train precision: 0.998933, train loss: 10.469766, valid precision: 0.871800, valid loss: 96.766312
epoch: 2777, train precision: 0.999422, train loss: 10.295197, valid precision: 0.870600, valid loss: 95.420997
epoch: 2778, train precision: 0.999200, train loss: 10.374052, valid precision: 0.871800, valid loss: 95.873235
epoch: 2779, train precision: 0.999267, train loss: 10.331583, valid precision: 0.872200, valid loss: 97.128844
epoch: 2780, train precision: 0.999267, train loss: 10.315388, valid precision: 0.875200, valid loss: 97.130916
epoch: 2781, train precision: 0.998956, train loss: 10.356467, valid precision: 0.871400, valid loss: 95.810727
epoch: 2782, train precision: 0.999044, train loss: 10.361843, valid precision: 0.876200, valid loss: 93.056890
epoch: 2783, train precision: 0.998867, train loss: 10.411732, valid precision: 0.870800, valid loss: 96.494985
epoch: 2784, train precision: 0.999022, train loss: 10.363066, valid precision: 0.874000, valid loss: 95.588503
epoch: 2785, train precision: 0.998556, train loss: 10.535424, valid precision: 0.873400, valid loss: 98.272612
epoch: 2786, train precision: 0.999022, train loss: 10.383433, valid precision: 0.870800, valid loss: 97.064937
epoch: 2787, train precision: 0.999289, train loss: 10.300427, valid precision: 0.873000, valid loss: 98.398670
epoch: 2788, train precision: 0.998778, train loss: 10.437428, valid precision: 0.870200, valid loss: 97.475862
epoch: 2789, train precision: 0.998644, train loss: 10.500808, valid precision: 0.874200, valid loss: 96.756885
epoch: 2790, train precision: 0.999067, train loss: 10.345596, valid precision: 0.872600, valid loss: 97.393469
epoch: 2791, train precision: 0.998689, train loss: 10.531780, valid precision: 0.871000, valid loss: 97.245150
epoch: 2792, train precision: 0.998733, train loss: 10.485465, valid precision: 0.874200, valid loss: 94.859027
epoch: 2793, train precision: 0.999111, train loss: 10.333194, valid precision: 0.870400, valid loss: 96.990396
epoch: 2794, train precision: 0.999111, train loss: 10.365285, valid precision: 0.869600, valid loss: 98.693908
epoch: 2795, train precision: 0.999000, train loss: 10.418664, valid precision: 0.872400, valid loss: 95.389513
epoch: 2796, train precision: 0.998822, train loss: 10.491183, valid precision: 0.869400, valid loss: 97.545427
epoch: 2797, train precision: 0.999422, train loss: 10.335768, valid precision: 0.873200, valid loss: 95.887402
epoch: 2798, train precision: 0.998711, train loss: 10.517677, valid precision: 0.871000, valid loss: 97.193522
epoch: 2799, train precision: 0.998622, train loss: 10.525840, valid precision: 0.869800, valid loss: 97.141891
epoch: 2800, train precision: 0.998956, train loss: 10.404147, valid precision: 0.869800, valid loss: 96.163283
epoch: 2801, train precision: 0.998800, train loss: 10.461254, valid precision: 0.871600, valid loss: 95.713915
epoch: 2802, train precision: 0.998933, train loss: 10.399937, valid precision: 0.872400, valid loss: 95.064777
epoch: 2803, train precision: 0.999200, train loss: 10.359664, valid precision: 0.873200, valid loss: 98.665330
epoch: 2804, train precision: 0.998711, train loss: 10.483669, valid precision: 0.868000, valid loss: 100.489324
epoch: 2805, train precision: 0.999244, train loss: 10.356821, valid precision: 0.871200, valid loss: 97.139310
epoch: 2806, train precision: 0.999044, train loss: 10.385931, valid precision: 0.876400, valid loss: 96.536685
epoch: 2807, train precision: 0.999222, train loss: 10.314940, valid precision: 0.874200, valid loss: 96.713738
epoch: 2808, train precision: 0.999156, train loss: 10.412096, valid precision: 0.870600, valid loss: 99.033613
epoch: 2809, train precision: 0.998933, train loss: 10.406764, valid precision: 0.870400, valid loss: 100.268419
epoch: 2810, train precision: 0.999000, train loss: 10.385346, valid precision: 0.871400, valid loss: 98.582538
epoch: 2811, train precision: 0.998889, train loss: 10.481264, valid precision: 0.870000, valid loss: 96.668173
epoch: 2812, train precision: 0.999200, train loss: 10.322454, valid precision: 0.872200, valid loss: 95.872300
epoch: 2813, train precision: 0.999000, train loss: 10.403139, valid precision: 0.870400, valid loss: 96.314624
epoch: 2814, train precision: 0.999156, train loss: 10.326124, valid precision: 0.871600, valid loss: 96.864264
epoch: 2815, train precision: 0.998911, train loss: 10.444087, valid precision: 0.869200, valid loss: 96.126958
epoch: 2816, train precision: 0.998889, train loss: 10.433493, valid precision: 0.872200, valid loss: 97.491950
epoch: 2817, train precision: 0.999044, train loss: 10.448803, valid precision: 0.869000, valid loss: 98.051290
epoch: 2818, train precision: 0.998756, train loss: 10.447296, valid precision: 0.869000, valid loss: 96.139934
epoch: 2819, train precision: 0.998756, train loss: 10.481359, valid precision: 0.873600, valid loss: 94.581339
epoch: 2820, train precision: 0.999156, train loss: 10.331355, valid precision: 0.874400, valid loss: 96.714613
epoch: 2821, train precision: 0.999111, train loss: 10.317011, valid precision: 0.871400, valid loss: 98.279017
epoch: 2822, train precision: 0.998844, train loss: 10.391638, valid precision: 0.872600, valid loss: 98.168512
epoch: 2823, train precision: 0.998444, train loss: 10.560994, valid precision: 0.874200, valid loss: 96.154070
epoch: 2824, train precision: 0.998644, train loss: 10.504656, valid precision: 0.873800, valid loss: 96.607316
epoch: 2825, train precision: 0.999067, train loss: 10.434892, valid precision: 0.872600, valid loss: 97.062712
epoch: 2826, train precision: 0.998933, train loss: 10.449897, valid precision: 0.871400, valid loss: 97.877534
epoch: 2827, train precision: 0.998933, train loss: 10.323955, valid precision: 0.875000, valid loss: 97.110294
epoch: 2828, train precision: 0.998689, train loss: 10.531249, valid precision: 0.873000, valid loss: 95.221638
epoch: 2829, train precision: 0.999178, train loss: 10.345836, valid precision: 0.876200, valid loss: 93.546266
epoch: 2830, train precision: 0.999111, train loss: 10.374970, valid precision: 0.873600, valid loss: 95.528928
epoch: 2831, train precision: 0.999067, train loss: 10.404031, valid precision: 0.873200, valid loss: 97.712639
epoch: 2832, train precision: 0.999000, train loss: 10.356519, valid precision: 0.876400, valid loss: 94.866102
epoch: 2833, train precision: 0.999200, train loss: 10.319137, valid precision: 0.870600, valid loss: 96.865986
epoch: 2834, train precision: 0.998956, train loss: 10.381878, valid precision: 0.871600, valid loss: 94.815100
epoch: 2835, train precision: 0.999178, train loss: 10.341333, valid precision: 0.872600, valid loss: 95.398593
epoch: 2836, train precision: 0.999111, train loss: 10.402622, valid precision: 0.874600, valid loss: 95.637990
epoch: 2837, train precision: 0.998867, train loss: 10.426035, valid precision: 0.873800, valid loss: 92.808025
epoch: 2838, train precision: 0.998978, train loss: 10.359811, valid precision: 0.875200, valid loss: 92.499611
epoch: 2839, train precision: 0.998800, train loss: 10.459277, valid precision: 0.876200, valid loss: 95.411552
epoch: 2840, train precision: 0.999133, train loss: 10.354963, valid precision: 0.876600, valid loss: 94.777115
epoch: 2841, train precision: 0.998844, train loss: 10.441973, valid precision: 0.869600, valid loss: 97.312690
epoch: 2842, train precision: 0.998733, train loss: 10.469549, valid precision: 0.870000, valid loss: 98.037083
epoch: 2843, train precision: 0.999178, train loss: 10.379719, valid precision: 0.877200, valid loss: 95.549768
epoch: 2844, train precision: 0.998778, train loss: 10.427179, valid precision: 0.878400, valid loss: 96.776276
epoch: 2845, train precision: 0.998778, train loss: 10.414765, valid precision: 0.875600, valid loss: 95.379240
epoch: 2846, train precision: 0.998778, train loss: 10.430605, valid precision: 0.877400, valid loss: 94.958467
epoch: 2847, train precision: 0.998844, train loss: 10.488201, valid precision: 0.874600, valid loss: 94.292548
epoch: 2848, train precision: 0.998911, train loss: 10.406391, valid precision: 0.878000, valid loss: 96.257598
epoch: 2849, train precision: 0.999089, train loss: 10.339287, valid precision: 0.875000, valid loss: 96.867510
epoch: 2850, train precision: 0.999267, train loss: 10.344823, valid precision: 0.873800, valid loss: 97.654564
epoch: 2851, train precision: 0.999022, train loss: 10.374768, valid precision: 0.877000, valid loss: 95.165641
epoch: 2852, train precision: 0.999044, train loss: 10.342591, valid precision: 0.872600, valid loss: 97.483767
epoch: 2853, train precision: 0.998667, train loss: 10.485272, valid precision: 0.874000, valid loss: 99.021640
epoch: 2854, train precision: 0.999222, train loss: 10.317360, valid precision: 0.874200, valid loss: 97.535151
epoch: 2855, train precision: 0.998933, train loss: 10.387198, valid precision: 0.872600, valid loss: 99.078522
epoch: 2856, train precision: 0.999111, train loss: 10.343031, valid precision: 0.872600, valid loss: 97.394791
epoch: 2857, train precision: 0.999067, train loss: 10.367781, valid precision: 0.874000, valid loss: 97.867522
epoch: 2858, train precision: 0.999222, train loss: 10.307216, valid precision: 0.876200, valid loss: 96.904028
epoch: 2859, train precision: 0.998578, train loss: 10.561989, valid precision: 0.874200, valid loss: 98.176193
epoch: 2860, train precision: 0.998778, train loss: 10.424532, valid precision: 0.870400, valid loss: 102.050602
epoch: 2861, train precision: 0.998822, train loss: 10.358879, valid precision: 0.876200, valid loss: 95.867099
epoch: 2862, train precision: 0.999200, train loss: 10.290601, valid precision: 0.873800, valid loss: 96.136434
epoch: 2863, train precision: 0.999067, train loss: 10.292976, valid precision: 0.877800, valid loss: 97.689054
epoch: 2864, train precision: 0.999356, train loss: 10.292148, valid precision: 0.875600, valid loss: 96.659306
epoch: 2865, train precision: 0.999000, train loss: 10.341040, valid precision: 0.879400, valid loss: 98.312757
epoch: 2866, train precision: 0.998733, train loss: 10.468383, valid precision: 0.874800, valid loss: 98.897651
epoch: 2867, train precision: 0.999244, train loss: 10.360507, valid precision: 0.873800, valid loss: 97.425280
epoch: 2868, train precision: 0.999067, train loss: 10.384978, valid precision: 0.873000, valid loss: 99.287628
epoch: 2869, train precision: 0.998889, train loss: 10.421276, valid precision: 0.874400, valid loss: 97.392361
epoch: 2870, train precision: 0.999200, train loss: 10.323907, valid precision: 0.870200, valid loss: 95.803285
epoch: 2871, train precision: 0.998800, train loss: 10.407829, valid precision: 0.874800, valid loss: 95.842594
epoch: 2872, train precision: 0.999111, train loss: 10.382188, valid precision: 0.873000, valid loss: 96.224786
epoch: 2873, train precision: 0.999000, train loss: 10.394205, valid precision: 0.871600, valid loss: 98.875947
epoch: 2874, train precision: 0.999333, train loss: 10.287467, valid precision: 0.871600, valid loss: 96.283611
epoch: 2875, train precision: 0.999000, train loss: 10.360739, valid precision: 0.869600, valid loss: 98.740257
epoch: 2876, train precision: 0.998511, train loss: 10.475011, valid precision: 0.873000, valid loss: 98.466390
epoch: 2877, train precision: 0.999022, train loss: 10.358250, valid precision: 0.869800, valid loss: 98.694081
epoch: 2878, train precision: 0.998711, train loss: 10.509284, valid precision: 0.866400, valid loss: 98.975398
epoch: 2879, train precision: 0.998667, train loss: 10.458535, valid precision: 0.873200, valid loss: 97.528921
epoch: 2880, train precision: 0.999178, train loss: 10.344641, valid precision: 0.875400, valid loss: 97.399620
epoch: 2881, train precision: 0.998844, train loss: 10.382474, valid precision: 0.873200, valid loss: 96.378068
epoch: 2882, train precision: 0.999067, train loss: 10.340726, valid precision: 0.873400, valid loss: 97.775911
epoch: 2883, train precision: 0.999022, train loss: 10.383788, valid precision: 0.873200, valid loss: 96.683070
epoch: 2884, train precision: 0.999222, train loss: 10.305865, valid precision: 0.876200, valid loss: 96.140011
epoch: 2885, train precision: 0.999200, train loss: 10.277227, valid precision: 0.873600, valid loss: 100.303223
epoch: 2886, train precision: 0.998667, train loss: 10.440113, valid precision: 0.870800, valid loss: 98.869224
epoch: 2887, train precision: 0.998578, train loss: 10.473600, valid precision: 0.871000, valid loss: 96.586122
epoch: 2888, train precision: 0.998800, train loss: 10.414762, valid precision: 0.868400, valid loss: 100.477191
epoch: 2889, train precision: 0.998756, train loss: 10.456666, valid precision: 0.870800, valid loss: 98.713816
epoch: 2890, train precision: 0.999178, train loss: 10.323785, valid precision: 0.874200, valid loss: 99.717537
epoch: 2891, train precision: 0.999000, train loss: 10.378616, valid precision: 0.876400, valid loss: 97.399809
epoch: 2892, train precision: 0.998933, train loss: 10.344224, valid precision: 0.868600, valid loss: 98.730967
epoch: 2893, train precision: 0.998911, train loss: 10.396820, valid precision: 0.872600, valid loss: 96.951593
epoch: 2894, train precision: 0.998978, train loss: 10.378335, valid precision: 0.873000, valid loss: 99.598750
epoch: 2895, train precision: 0.998822, train loss: 10.417027, valid precision: 0.874600, valid loss: 97.775968
epoch: 2896, train precision: 0.998756, train loss: 10.385574, valid precision: 0.873600, valid loss: 98.166066
epoch: 2897, train precision: 0.998556, train loss: 10.481214, valid precision: 0.877200, valid loss: 98.507337
epoch: 2898, train precision: 0.998978, train loss: 10.388177, valid precision: 0.875200, valid loss: 99.856252
epoch: 2899, train precision: 0.999133, train loss: 10.359224, valid precision: 0.869200, valid loss: 100.941082
epoch: 2900, train precision: 0.998622, train loss: 10.556045, valid precision: 0.872400, valid loss: 99.865331
epoch: 2901, train precision: 0.999289, train loss: 10.272502, valid precision: 0.873200, valid loss: 99.418507
epoch: 2902, train precision: 0.999089, train loss: 10.321489, valid precision: 0.869200, valid loss: 100.219731
epoch: 2903, train precision: 0.999178, train loss: 10.336221, valid precision: 0.868400, valid loss: 102.038615
epoch: 2904, train precision: 0.998978, train loss: 10.370868, valid precision: 0.874200, valid loss: 99.500574
epoch: 2905, train precision: 0.998378, train loss: 10.509644, valid precision: 0.871000, valid loss: 100.032234
epoch: 2906, train precision: 0.998933, train loss: 10.392276, valid precision: 0.871200, valid loss: 100.637439
epoch: 2907, train precision: 0.998978, train loss: 10.328379, valid precision: 0.874200, valid loss: 100.240332
epoch: 2908, train precision: 0.999000, train loss: 10.343422, valid precision: 0.865800, valid loss: 100.234693
epoch: 2909, train precision: 0.999133, train loss: 10.269373, valid precision: 0.871800, valid loss: 97.779189
epoch: 2910, train precision: 0.999111, train loss: 10.332682, valid precision: 0.872000, valid loss: 98.057218
epoch: 2911, train precision: 0.999067, train loss: 10.334795, valid precision: 0.871200, valid loss: 97.421982
epoch: 2912, train precision: 0.998867, train loss: 10.361145, valid precision: 0.874800, valid loss: 98.341663
epoch: 2913, train precision: 0.999222, train loss: 10.274012, valid precision: 0.870400, valid loss: 99.946353
epoch: 2914, train precision: 0.998578, train loss: 10.480708, valid precision: 0.872600, valid loss: 99.435853
epoch: 2915, train precision: 0.999000, train loss: 10.385176, valid precision: 0.873000, valid loss: 96.635341
epoch: 2916, train precision: 0.999067, train loss: 10.308431, valid precision: 0.876000, valid loss: 96.550555
epoch: 2917, train precision: 0.999022, train loss: 10.347413, valid precision: 0.874000, valid loss: 96.913258
epoch: 2918, train precision: 0.999267, train loss: 10.310789, valid precision: 0.873800, valid loss: 98.179777
epoch: 2919, train precision: 0.999200, train loss: 10.372833, valid precision: 0.870200, valid loss: 98.414021
epoch: 2920, train precision: 0.999133, train loss: 10.371673, valid precision: 0.874000, valid loss: 99.526459
epoch: 2921, train precision: 0.999133, train loss: 10.283383, valid precision: 0.868200, valid loss: 100.023082
epoch: 2922, train precision: 0.999222, train loss: 10.324367, valid precision: 0.868200, valid loss: 100.630954
epoch: 2923, train precision: 0.998867, train loss: 10.386584, valid precision: 0.871200, valid loss: 101.082546
epoch: 2924, train precision: 0.998956, train loss: 10.369103, valid precision: 0.873000, valid loss: 97.758155
epoch: 2925, train precision: 0.999022, train loss: 10.371961, valid precision: 0.871800, valid loss: 95.644053
epoch: 2926, train precision: 0.998978, train loss: 10.394577, valid precision: 0.868800, valid loss: 99.126863
epoch: 2927, train precision: 0.998800, train loss: 10.388666, valid precision: 0.872800, valid loss: 95.908449
epoch: 2928, train precision: 0.999378, train loss: 10.240755, valid precision: 0.874200, valid loss: 98.492337
epoch: 2929, train precision: 0.999178, train loss: 10.323324, valid precision: 0.874200, valid loss: 95.807560
epoch: 2930, train precision: 0.998889, train loss: 10.411537, valid precision: 0.873600, valid loss: 99.007193
epoch: 2931, train precision: 0.998978, train loss: 10.353543, valid precision: 0.874200, valid loss: 95.675875
epoch: 2932, train precision: 0.998867, train loss: 10.416261, valid precision: 0.874000, valid loss: 97.209551
epoch: 2933, train precision: 0.998733, train loss: 10.430926, valid precision: 0.870200, valid loss: 97.445326
epoch: 2934, train precision: 0.999000, train loss: 10.365242, valid precision: 0.874600, valid loss: 96.167133
epoch: 2935, train precision: 0.999178, train loss: 10.318625, valid precision: 0.874000, valid loss: 96.085123
epoch: 2936, train precision: 0.998733, train loss: 10.452556, valid precision: 0.871800, valid loss: 100.141466
epoch: 2937, train precision: 0.998644, train loss: 10.488389, valid precision: 0.872800, valid loss: 96.895749
epoch: 2938, train precision: 0.998956, train loss: 10.409489, valid precision: 0.872800, valid loss: 98.798889
epoch: 2939, train precision: 0.999311, train loss: 10.286701, valid precision: 0.871200, valid loss: 99.552058
epoch: 2940, train precision: 0.998933, train loss: 10.398934, valid precision: 0.872000, valid loss: 98.793783
epoch: 2941, train precision: 0.999222, train loss: 10.305300, valid precision: 0.872600, valid loss: 96.399518
epoch: 2942, train precision: 0.999067, train loss: 10.364078, valid precision: 0.873200, valid loss: 96.726294
epoch: 2943, train precision: 0.998578, train loss: 10.524110, valid precision: 0.868800, valid loss: 99.355902
epoch: 2944, train precision: 0.998889, train loss: 10.386944, valid precision: 0.868200, valid loss: 99.055177
epoch: 2945, train precision: 0.998933, train loss: 10.389724, valid precision: 0.871800, valid loss: 96.909147
epoch: 2946, train precision: 0.998689, train loss: 10.381815, valid precision: 0.868000, valid loss: 100.375277
epoch: 2947, train precision: 0.998644, train loss: 10.446305, valid precision: 0.871400, valid loss: 99.422372
epoch: 2948, train precision: 0.999267, train loss: 10.279315, valid precision: 0.870400, valid loss: 99.013314
epoch: 2949, train precision: 0.999022, train loss: 10.331083, valid precision: 0.871000, valid loss: 99.190717
epoch: 2950, train precision: 0.998778, train loss: 10.443652, valid precision: 0.873200, valid loss: 99.143303
epoch: 2951, train precision: 0.999089, train loss: 10.375519, valid precision: 0.871200, valid loss: 97.180463
epoch: 2952, train precision: 0.998933, train loss: 10.406512, valid precision: 0.874200, valid loss: 97.854596
epoch: 2953, train precision: 0.999067, train loss: 10.333533, valid precision: 0.873400, valid loss: 99.606301
epoch: 2954, train precision: 0.998933, train loss: 10.365650, valid precision: 0.870800, valid loss: 100.815444
epoch: 2955, train precision: 0.998822, train loss: 10.520530, valid precision: 0.876800, valid loss: 99.047770
epoch: 2956, train precision: 0.999267, train loss: 10.313666, valid precision: 0.875600, valid loss: 96.210842
epoch: 2957, train precision: 0.999000, train loss: 10.469123, valid precision: 0.872200, valid loss: 96.176663
epoch: 2958, train precision: 0.999133, train loss: 10.283231, valid precision: 0.877400, valid loss: 96.126256
epoch: 2959, train precision: 0.998933, train loss: 10.359138, valid precision: 0.873000, valid loss: 97.544545
epoch: 2960, train precision: 0.998911, train loss: 10.405701, valid precision: 0.869800, valid loss: 99.455974
epoch: 2961, train precision: 0.998689, train loss: 10.479689, valid precision: 0.877400, valid loss: 96.518952
epoch: 2962, train precision: 0.998822, train loss: 10.461928, valid precision: 0.872000, valid loss: 95.558644
epoch: 2963, train precision: 0.998978, train loss: 10.384755, valid precision: 0.875200, valid loss: 95.555724
epoch: 2964, train precision: 0.998889, train loss: 10.386730, valid precision: 0.874000, valid loss: 95.387721
epoch: 2965, train precision: 0.999267, train loss: 10.290474, valid precision: 0.875600, valid loss: 94.951142
epoch: 2966, train precision: 0.999089, train loss: 10.317674, valid precision: 0.876800, valid loss: 97.837709
epoch: 2967, train precision: 0.998756, train loss: 10.388813, valid precision: 0.874400, valid loss: 98.780999
epoch: 2968, train precision: 0.999222, train loss: 10.313264, valid precision: 0.878000, valid loss: 93.708216
epoch: 2969, train precision: 0.999000, train loss: 10.385008, valid precision: 0.876200, valid loss: 95.409257
epoch: 2970, train precision: 0.999222, train loss: 10.273816, valid precision: 0.871800, valid loss: 95.848223
epoch: 2971, train precision: 0.999022, train loss: 10.389933, valid precision: 0.876600, valid loss: 93.798918
epoch: 2972, train precision: 0.999289, train loss: 10.257616, valid precision: 0.874200, valid loss: 95.486337
epoch: 2973, train precision: 0.999022, train loss: 10.408060, valid precision: 0.872400, valid loss: 94.899971
epoch: 2974, train precision: 0.999244, train loss: 10.315403, valid precision: 0.876000, valid loss: 95.979151
epoch: 2975, train precision: 0.999067, train loss: 10.395568, valid precision: 0.877200, valid loss: 96.575427
epoch: 2976, train precision: 0.998822, train loss: 10.453371, valid precision: 0.870200, valid loss: 96.866017
epoch: 2977, train precision: 0.999222, train loss: 10.292170, valid precision: 0.875200, valid loss: 95.062471
epoch: 2978, train precision: 0.998911, train loss: 10.342820, valid precision: 0.874600, valid loss: 95.286174
epoch: 2979, train precision: 0.999111, train loss: 10.386191, valid precision: 0.876000, valid loss: 96.402334
epoch: 2980, train precision: 0.999289, train loss: 10.273235, valid precision: 0.877000, valid loss: 95.395174
epoch: 2981, train precision: 0.999111, train loss: 10.396669, valid precision: 0.875400, valid loss: 94.836983
epoch: 2982, train precision: 0.999044, train loss: 10.398337, valid precision: 0.873200, valid loss: 99.705247
epoch: 2983, train precision: 0.999200, train loss: 10.272186, valid precision: 0.873000, valid loss: 96.771178
epoch: 2984, train precision: 0.999222, train loss: 10.312472, valid precision: 0.873400, valid loss: 98.123132
epoch: 2985, train precision: 0.998822, train loss: 10.412910, valid precision: 0.874800, valid loss: 95.814696
epoch: 2986, train precision: 0.998756, train loss: 10.417806, valid precision: 0.873800, valid loss: 100.409192
epoch: 2987, train precision: 0.999356, train loss: 10.250500, valid precision: 0.872400, valid loss: 97.768496
epoch: 2988, train precision: 0.999178, train loss: 10.314101, valid precision: 0.875400, valid loss: 95.979981
epoch: 2989, train precision: 0.998800, train loss: 10.368790, valid precision: 0.871800, valid loss: 96.946871
epoch: 2990, train precision: 0.999244, train loss: 10.245506, valid precision: 0.868200, valid loss: 98.938102
epoch: 2991, train precision: 0.999244, train loss: 10.255464, valid precision: 0.871600, valid loss: 100.026906
epoch: 2992, train precision: 0.998578, train loss: 10.458696, valid precision: 0.869800, valid loss: 100.486239
epoch: 2993, train precision: 0.999111, train loss: 10.342607, valid precision: 0.872200, valid loss: 97.807850
epoch: 2994, train precision: 0.998622, train loss: 10.469830, valid precision: 0.869000, valid loss: 100.121167
epoch: 2995, train precision: 0.998867, train loss: 10.452297, valid precision: 0.873600, valid loss: 94.704212
epoch: 2996, train precision: 0.998778, train loss: 10.436497, valid precision: 0.873000, valid loss: 100.417923
epoch: 2997, train precision: 0.998467, train loss: 10.473733, valid precision: 0.871800, valid loss: 98.674582
epoch: 2998, train precision: 0.999133, train loss: 10.257928, valid precision: 0.874200, valid loss: 97.297703
epoch: 2999, train precision: 0.998867, train loss: 10.437822, valid precision: 0.878600, valid loss: 96.858636
epoch: 3000, train precision: 0.999200, train loss: 10.318547, valid precision: 0.875800, valid loss: 96.857849
epoch: 3001, train precision: 0.999222, train loss: 10.301828, valid precision: 0.876600, valid loss: 98.475905
epoch: 3002, train precision: 0.998422, train loss: 10.491764, valid precision: 0.875200, valid loss: 101.155871
epoch: 3003, train precision: 0.999244, train loss: 10.299825, valid precision: 0.876000, valid loss: 97.371662
epoch: 3004, train precision: 0.999067, train loss: 10.340021, valid precision: 0.872200, valid loss: 98.388018
epoch: 3005, train precision: 0.999067, train loss: 10.320083, valid precision: 0.872200, valid loss: 100.932980
epoch: 3006, train precision: 0.999244, train loss: 10.300725, valid precision: 0.875800, valid loss: 98.345181
epoch: 3007, train precision: 0.999311, train loss: 10.268964, valid precision: 0.874600, valid loss: 98.143027
epoch: 3008, train precision: 0.998689, train loss: 10.421427, valid precision: 0.873400, valid loss: 96.989324
epoch: 3009, train precision: 0.999022, train loss: 10.348320, valid precision: 0.878800, valid loss: 93.967874
epoch: 3010, train precision: 0.998778, train loss: 10.373241, valid precision: 0.874800, valid loss: 98.990088
epoch: 3011, train precision: 0.998911, train loss: 10.425618, valid precision: 0.869200, valid loss: 97.736660
epoch: 3012, train precision: 0.998889, train loss: 10.354789, valid precision: 0.871000, valid loss: 98.576638
epoch: 3013, train precision: 0.999156, train loss: 10.271645, valid precision: 0.873800, valid loss: 97.696822
epoch: 3014, train precision: 0.999089, train loss: 10.346197, valid precision: 0.876400, valid loss: 98.481038
epoch: 3015, train precision: 0.999000, train loss: 10.325363, valid precision: 0.873800, valid loss: 99.201165
epoch: 3016, train precision: 0.998800, train loss: 10.434158, valid precision: 0.875400, valid loss: 96.470835
epoch: 3017, train precision: 0.998667, train loss: 10.448436, valid precision: 0.872000, valid loss: 97.467203
epoch: 3018, train precision: 0.999178, train loss: 10.319533, valid precision: 0.874600, valid loss: 98.639286
epoch: 3019, train precision: 0.998889, train loss: 10.405159, valid precision: 0.873600, valid loss: 97.292630
epoch: 3020, train precision: 0.998933, train loss: 10.339586, valid precision: 0.871400, valid loss: 99.075417
epoch: 3021, train precision: 0.999178, train loss: 10.294611, valid precision: 0.871600, valid loss: 98.522085
epoch: 3022, train precision: 0.998778, train loss: 10.318285, valid precision: 0.870000, valid loss: 99.842317
epoch: 3023, train precision: 0.998956, train loss: 10.417704, valid precision: 0.875800, valid loss: 99.218834
epoch: 3024, train precision: 0.999156, train loss: 10.336310, valid precision: 0.873800, valid loss: 97.373327
epoch: 3025, train precision: 0.999089, train loss: 10.383725, valid precision: 0.869200, valid loss: 99.368348
epoch: 3026, train precision: 0.999067, train loss: 10.299577, valid precision: 0.873400, valid loss: 100.675051
epoch: 3027, train precision: 0.998889, train loss: 10.364857, valid precision: 0.868600, valid loss: 101.339060
epoch: 3028, train precision: 0.999111, train loss: 10.287763, valid precision: 0.871000, valid loss: 99.735105
epoch: 3029, train precision: 0.998822, train loss: 10.391375, valid precision: 0.873400, valid loss: 100.510393
epoch: 3030, train precision: 0.999111, train loss: 10.292592, valid precision: 0.875000, valid loss: 99.353644
epoch: 3031, train precision: 0.999267, train loss: 10.288252, valid precision: 0.874600, valid loss: 99.544902
epoch: 3032, train precision: 0.999089, train loss: 10.313969, valid precision: 0.873400, valid loss: 99.341964
epoch: 3033, train precision: 0.998822, train loss: 10.417972, valid precision: 0.870800, valid loss: 99.312003
epoch: 3034, train precision: 0.998822, train loss: 10.350959, valid precision: 0.873400, valid loss: 98.381010
epoch: 3035, train precision: 0.999044, train loss: 10.350676, valid precision: 0.872200, valid loss: 97.801529
epoch: 3036, train precision: 0.999400, train loss: 10.291851, valid precision: 0.871800, valid loss: 95.903673
epoch: 3037, train precision: 0.998978, train loss: 10.382442, valid precision: 0.872800, valid loss: 97.394638
epoch: 3038, train precision: 0.998822, train loss: 10.372449, valid precision: 0.873600, valid loss: 96.732361
epoch: 3039, train precision: 0.998844, train loss: 10.405078, valid precision: 0.871800, valid loss: 97.846173
epoch: 3040, train precision: 0.998889, train loss: 10.447949, valid precision: 0.874400, valid loss: 98.278035
epoch: 3041, train precision: 0.998978, train loss: 10.333862, valid precision: 0.877600, valid loss: 97.096926
epoch: 3042, train precision: 0.998822, train loss: 10.471997, valid precision: 0.879200, valid loss: 97.778400
epoch: 3043, train precision: 0.999089, train loss: 10.305647, valid precision: 0.875000, valid loss: 100.765335
epoch: 3044, train precision: 0.998889, train loss: 10.336480, valid precision: 0.875600, valid loss: 100.109300
epoch: 3045, train precision: 0.999022, train loss: 10.310945, valid precision: 0.879600, valid loss: 100.136774
epoch: 3046, train precision: 0.998978, train loss: 10.433115, valid precision: 0.873200, valid loss: 98.807513
epoch: 3047, train precision: 0.999022, train loss: 10.314392, valid precision: 0.873400, valid loss: 99.013157
epoch: 3048, train precision: 0.998956, train loss: 10.326305, valid precision: 0.874200, valid loss: 100.838857
epoch: 3049, train precision: 0.998933, train loss: 10.370180, valid precision: 0.871200, valid loss: 99.053209
epoch: 3050, train precision: 0.999267, train loss: 10.264964, valid precision: 0.872600, valid loss: 99.478807
epoch: 3051, train precision: 0.998933, train loss: 10.403106, valid precision: 0.872600, valid loss: 99.468403
epoch: 3052, train precision: 0.999244, train loss: 10.277154, valid precision: 0.871600, valid loss: 98.125909
epoch: 3053, train precision: 0.999200, train loss: 10.333778, valid precision: 0.870800, valid loss: 97.800303
epoch: 3054, train precision: 0.998889, train loss: 10.360983, valid precision: 0.872400, valid loss: 100.019773
epoch: 3055, train precision: 0.998933, train loss: 10.444357, valid precision: 0.872000, valid loss: 97.080207
epoch: 3056, train precision: 0.999178, train loss: 10.325138, valid precision: 0.872000, valid loss: 98.136436
epoch: 3057, train precision: 0.999133, train loss: 10.299091, valid precision: 0.877200, valid loss: 97.014223
epoch: 3058, train precision: 0.999044, train loss: 10.330241, valid precision: 0.871400, valid loss: 98.137840
epoch: 3059, train precision: 0.999178, train loss: 10.273578, valid precision: 0.872800, valid loss: 97.841257
epoch: 3060, train precision: 0.998956, train loss: 10.343659, valid precision: 0.871800, valid loss: 101.125633
epoch: 3061, train precision: 0.999333, train loss: 10.223935, valid precision: 0.876200, valid loss: 100.008383
epoch: 3062, train precision: 0.999444, train loss: 10.185027, valid precision: 0.873600, valid loss: 100.218736
epoch: 3063, train precision: 0.998867, train loss: 10.360593, valid precision: 0.871000, valid loss: 98.765478
epoch: 3064, train precision: 0.999133, train loss: 10.285573, valid precision: 0.872800, valid loss: 98.945061
epoch: 3065, train precision: 0.999067, train loss: 10.319007, valid precision: 0.874000, valid loss: 100.876834
epoch: 3066, train precision: 0.998933, train loss: 10.389657, valid precision: 0.869600, valid loss: 99.049062
epoch: 3067, train precision: 0.998911, train loss: 10.396974, valid precision: 0.872800, valid loss: 98.607613
epoch: 3068, train precision: 0.999089, train loss: 10.306090, valid precision: 0.873000, valid loss: 97.773608
epoch: 3069, train precision: 0.998867, train loss: 10.369010, valid precision: 0.870800, valid loss: 99.458375
epoch: 3070, train precision: 0.998889, train loss: 10.391702, valid precision: 0.870200, valid loss: 99.745814
epoch: 3071, train precision: 0.999200, train loss: 10.330095, valid precision: 0.873400, valid loss: 99.273772
epoch: 3072, train precision: 0.999111, train loss: 10.303984, valid precision: 0.871200, valid loss: 99.313972
epoch: 3073, train precision: 0.998978, train loss: 10.384864, valid precision: 0.867600, valid loss: 100.774192
epoch: 3074, train precision: 0.998756, train loss: 10.425426, valid precision: 0.867200, valid loss: 99.269321
epoch: 3075, train precision: 0.999222, train loss: 10.241341, valid precision: 0.873200, valid loss: 97.016351
epoch: 3076, train precision: 0.999200, train loss: 10.321261, valid precision: 0.869000, valid loss: 98.036332
epoch: 3077, train precision: 0.999111, train loss: 10.344187, valid precision: 0.865400, valid loss: 100.669050
epoch: 3078, train precision: 0.999089, train loss: 10.272390, valid precision: 0.869800, valid loss: 99.341481
epoch: 3079, train precision: 0.998578, train loss: 10.431207, valid precision: 0.873800, valid loss: 101.320025
epoch: 3080, train precision: 0.998933, train loss: 10.346240, valid precision: 0.874600, valid loss: 97.552170
epoch: 3081, train precision: 0.998911, train loss: 10.416270, valid precision: 0.872600, valid loss: 99.428324
epoch: 3082, train precision: 0.999111, train loss: 10.263718, valid precision: 0.873200, valid loss: 99.352362
epoch: 3083, train precision: 0.999133, train loss: 10.306695, valid precision: 0.875200, valid loss: 99.253608
epoch: 3084, train precision: 0.999022, train loss: 10.326451, valid precision: 0.876600, valid loss: 100.217405
epoch: 3085, train precision: 0.999178, train loss: 10.292771, valid precision: 0.872000, valid loss: 98.645365
epoch: 3086, train precision: 0.999156, train loss: 10.278375, valid precision: 0.873000, valid loss: 98.450053
epoch: 3087, train precision: 0.999067, train loss: 10.305305, valid precision: 0.872800, valid loss: 97.511069
epoch: 3088, train precision: 0.998933, train loss: 10.337189, valid precision: 0.869600, valid loss: 98.607107
epoch: 3089, train precision: 0.998778, train loss: 10.339092, valid precision: 0.874200, valid loss: 98.500081
epoch: 3090, train precision: 0.998978, train loss: 10.317373, valid precision: 0.870000, valid loss: 100.570219
epoch: 3091, train precision: 0.998778, train loss: 10.337377, valid precision: 0.874600, valid loss: 101.096248
epoch: 3092, train precision: 0.998889, train loss: 10.420237, valid precision: 0.870600, valid loss: 99.134421
epoch: 3093, train precision: 0.999111, train loss: 10.291380, valid precision: 0.872600, valid loss: 98.117823
epoch: 3094, train precision: 0.999156, train loss: 10.256672, valid precision: 0.870800, valid loss: 99.931193
epoch: 3095, train precision: 0.998733, train loss: 10.435056, valid precision: 0.870800, valid loss: 101.058389
epoch: 3096, train precision: 0.998556, train loss: 10.493973, valid precision: 0.872200, valid loss: 99.170379
epoch: 3097, train precision: 0.999044, train loss: 10.297168, valid precision: 0.872200, valid loss: 98.640945
epoch: 3098, train precision: 0.998978, train loss: 10.356620, valid precision: 0.872200, valid loss: 95.999355
epoch: 3099, train precision: 0.998978, train loss: 10.375344, valid precision: 0.871400, valid loss: 96.876752
epoch: 3100, train precision: 0.998333, train loss: 10.585843, valid precision: 0.870600, valid loss: 99.319331
epoch: 3101, train precision: 0.998689, train loss: 10.413172, valid precision: 0.872200, valid loss: 99.112699
epoch: 3102, train precision: 0.999333, train loss: 10.271979, valid precision: 0.871800, valid loss: 97.835333
epoch: 3103, train precision: 0.998911, train loss: 10.360147, valid precision: 0.877000, valid loss: 98.619501
epoch: 3104, train precision: 0.999022, train loss: 10.319867, valid precision: 0.872000, valid loss: 100.071971
epoch: 3105, train precision: 0.999178, train loss: 10.293651, valid precision: 0.872600, valid loss: 101.435083
epoch: 3106, train precision: 0.999244, train loss: 10.299831, valid precision: 0.874400, valid loss: 99.630117
epoch: 3107, train precision: 0.999267, train loss: 10.245873, valid precision: 0.873600, valid loss: 98.415063
epoch: 3108, train precision: 0.998778, train loss: 10.404798, valid precision: 0.871400, valid loss: 99.380906
epoch: 3109, train precision: 0.999200, train loss: 10.269395, valid precision: 0.871000, valid loss: 98.857774
epoch: 3110, train precision: 0.999000, train loss: 10.333459, valid precision: 0.873000, valid loss: 96.924814
epoch: 3111, train precision: 0.999156, train loss: 10.273310, valid precision: 0.876000, valid loss: 97.275940
epoch: 3112, train precision: 0.998867, train loss: 10.433846, valid precision: 0.876000, valid loss: 98.923056
epoch: 3113, train precision: 0.999044, train loss: 10.345165, valid precision: 0.874600, valid loss: 99.096299
epoch: 3114, train precision: 0.999089, train loss: 10.316781, valid precision: 0.873600, valid loss: 99.928927
epoch: 3115, train precision: 0.999222, train loss: 10.243120, valid precision: 0.872200, valid loss: 96.399367
epoch: 3116, train precision: 0.999178, train loss: 10.318121, valid precision: 0.875200, valid loss: 96.633436
epoch: 3117, train precision: 0.999222, train loss: 10.298627, valid precision: 0.873800, valid loss: 98.548621
epoch: 3118, train precision: 0.998844, train loss: 10.378710, valid precision: 0.871000, valid loss: 100.768063
epoch: 3119, train precision: 0.999267, train loss: 10.299363, valid precision: 0.872800, valid loss: 98.102423
epoch: 3120, train precision: 0.998956, train loss: 10.356885, valid precision: 0.870000, valid loss: 99.148320
epoch: 3121, train precision: 0.998667, train loss: 10.381166, valid precision: 0.873000, valid loss: 96.471494
epoch: 3122, train precision: 0.998644, train loss: 10.425770, valid precision: 0.872800, valid loss: 96.559439
epoch: 3123, train precision: 0.999089, train loss: 10.297564, valid precision: 0.876000, valid loss: 94.176454
epoch: 3124, train precision: 0.998511, train loss: 10.464174, valid precision: 0.870000, valid loss: 95.494513
epoch: 3125, train precision: 0.999089, train loss: 10.342854, valid precision: 0.871000, valid loss: 97.992891
epoch: 3126, train precision: 0.998511, train loss: 10.444444, valid precision: 0.872600, valid loss: 96.121558
epoch: 3127, train precision: 0.999267, train loss: 10.263942, valid precision: 0.878800, valid loss: 98.262911
epoch: 3128, train precision: 0.999156, train loss: 10.273394, valid precision: 0.878000, valid loss: 97.646259
epoch: 3129, train precision: 0.998956, train loss: 10.315834, valid precision: 0.874400, valid loss: 98.633280
epoch: 3130, train precision: 0.999156, train loss: 10.267416, valid precision: 0.873400, valid loss: 100.233600
epoch: 3131, train precision: 0.999000, train loss: 10.275770, valid precision: 0.870600, valid loss: 101.143730
epoch: 3132, train precision: 0.998556, train loss: 10.463087, valid precision: 0.868400, valid loss: 100.090310
epoch: 3133, train precision: 0.998867, train loss: 10.366579, valid precision: 0.872000, valid loss: 96.290485
epoch: 3134, train precision: 0.998622, train loss: 10.452159, valid precision: 0.870400, valid loss: 99.212855
epoch: 3135, train precision: 0.998889, train loss: 10.367808, valid precision: 0.872800, valid loss: 97.601807
epoch: 3136, train precision: 0.998911, train loss: 10.342772, valid precision: 0.875400, valid loss: 97.007636
epoch: 3137, train precision: 0.999178, train loss: 10.241988, valid precision: 0.878600, valid loss: 96.870005
epoch: 3138, train precision: 0.999000, train loss: 10.331870, valid precision: 0.875000, valid loss: 96.258229
epoch: 3139, train precision: 0.998911, train loss: 10.320624, valid precision: 0.875000, valid loss: 98.293312
epoch: 3140, train precision: 0.999000, train loss: 10.321848, valid precision: 0.876400, valid loss: 97.062674
epoch: 3141, train precision: 0.999289, train loss: 10.220406, valid precision: 0.874400, valid loss: 97.479023
epoch: 3142, train precision: 0.998933, train loss: 10.364106, valid precision: 0.876800, valid loss: 97.304809
epoch: 3143, train precision: 0.999111, train loss: 10.290747, valid precision: 0.872600, valid loss: 95.970604
epoch: 3144, train precision: 0.999089, train loss: 10.281424, valid precision: 0.877000, valid loss: 97.671972
epoch: 3145, train precision: 0.998711, train loss: 10.411808, valid precision: 0.876000, valid loss: 99.893238
epoch: 3146, train precision: 0.999067, train loss: 10.300592, valid precision: 0.876200, valid loss: 98.881848
epoch: 3147, train precision: 0.999333, train loss: 10.265740, valid precision: 0.875000, valid loss: 98.106515
epoch: 3148, train precision: 0.998822, train loss: 10.381541, valid precision: 0.876200, valid loss: 97.565437
epoch: 3149, train precision: 0.998911, train loss: 10.298930, valid precision: 0.878400, valid loss: 96.394437
epoch: 3150, train precision: 0.998933, train loss: 10.322894, valid precision: 0.877400, valid loss: 95.303075
epoch: 3151, train precision: 0.998956, train loss: 10.305095, valid precision: 0.876000, valid loss: 94.231071
epoch: 3152, train precision: 0.998867, train loss: 10.374948, valid precision: 0.875800, valid loss: 96.918587
epoch: 3153, train precision: 0.999000, train loss: 10.318458, valid precision: 0.878400, valid loss: 96.616074
epoch: 3154, train precision: 0.999067, train loss: 10.301199, valid precision: 0.877400, valid loss: 99.460705
epoch: 3155, train precision: 0.999133, train loss: 10.286364, valid precision: 0.877400, valid loss: 97.450401
epoch: 3156, train precision: 0.998956, train loss: 10.308896, valid precision: 0.873000, valid loss: 98.605919
epoch: 3157, train precision: 0.999022, train loss: 10.350711, valid precision: 0.873600, valid loss: 100.527737
epoch: 3158, train precision: 0.999267, train loss: 10.214897, valid precision: 0.875000, valid loss: 96.205940
epoch: 3159, train precision: 0.999200, train loss: 10.239515, valid precision: 0.871800, valid loss: 97.596712
epoch: 3160, train precision: 0.998778, train loss: 10.376678, valid precision: 0.873800, valid loss: 101.127824
epoch: 3161, train precision: 0.998978, train loss: 10.301958, valid precision: 0.877400, valid loss: 100.093508
epoch: 3162, train precision: 0.999067, train loss: 10.306060, valid precision: 0.870600, valid loss: 100.910663
epoch: 3163, train precision: 0.999156, train loss: 10.256655, valid precision: 0.871600, valid loss: 100.118632
epoch: 3164, train precision: 0.999222, train loss: 10.314384, valid precision: 0.874000, valid loss: 99.099452
epoch: 3165, train precision: 0.999000, train loss: 10.341639, valid precision: 0.872800, valid loss: 98.971064
epoch: 3166, train precision: 0.999289, train loss: 10.283773, valid precision: 0.875200, valid loss: 99.312597
epoch: 3167, train precision: 0.999156, train loss: 10.266017, valid precision: 0.876400, valid loss: 95.672033
epoch: 3168, train precision: 0.998844, train loss: 10.305971, valid precision: 0.877000, valid loss: 96.974434
epoch: 3169, train precision: 0.998933, train loss: 10.328858, valid precision: 0.877200, valid loss: 97.779325
epoch: 3170, train precision: 0.999089, train loss: 10.279093, valid precision: 0.876400, valid loss: 96.384071
epoch: 3171, train precision: 0.999111, train loss: 10.314857, valid precision: 0.870000, valid loss: 98.679491
epoch: 3172, train precision: 0.999222, train loss: 10.291925, valid precision: 0.871800, valid loss: 96.248857
epoch: 3173, train precision: 0.999244, train loss: 10.306690, valid precision: 0.875200, valid loss: 99.307669
epoch: 3174, train precision: 0.998933, train loss: 10.358390, valid precision: 0.874800, valid loss: 96.379332
epoch: 3175, train precision: 0.999267, train loss: 10.284081, valid precision: 0.872000, valid loss: 97.750329
epoch: 3176, train precision: 0.999089, train loss: 10.294046, valid precision: 0.868200, valid loss: 97.301571
epoch: 3177, train precision: 0.999333, train loss: 10.226911, valid precision: 0.874000, valid loss: 95.627130
epoch: 3178, train precision: 0.999044, train loss: 10.310808, valid precision: 0.869400, valid loss: 96.557386
epoch: 3179, train precision: 0.998933, train loss: 10.315331, valid precision: 0.871600, valid loss: 97.015573
epoch: 3180, train precision: 0.998800, train loss: 10.335233, valid precision: 0.873000, valid loss: 99.097170
epoch: 3181, train precision: 0.998978, train loss: 10.368951, valid precision: 0.870800, valid loss: 99.963402
epoch: 3182, train precision: 0.999133, train loss: 10.229656, valid precision: 0.872800, valid loss: 95.253245
epoch: 3183, train precision: 0.998867, train loss: 10.336536, valid precision: 0.873000, valid loss: 95.869743
epoch: 3184, train precision: 0.998622, train loss: 10.438537, valid precision: 0.870600, valid loss: 99.662593
epoch: 3185, train precision: 0.999067, train loss: 10.362657, valid precision: 0.871400, valid loss: 98.032913
epoch: 3186, train precision: 0.998644, train loss: 10.370696, valid precision: 0.871400, valid loss: 98.239244
epoch: 3187, train precision: 0.998889, train loss: 10.383449, valid precision: 0.871200, valid loss: 97.758622
epoch: 3188, train precision: 0.998600, train loss: 10.421797, valid precision: 0.868200, valid loss: 99.059805
epoch: 3189, train precision: 0.999200, train loss: 10.273180, valid precision: 0.871400, valid loss: 95.946842
epoch: 3190, train precision: 0.998844, train loss: 10.317699, valid precision: 0.874800, valid loss: 94.646785
epoch: 3191, train precision: 0.998889, train loss: 10.380632, valid precision: 0.874800, valid loss: 95.681251
epoch: 3192, train precision: 0.999000, train loss: 10.338581, valid precision: 0.874000, valid loss: 95.109467
epoch: 3193, train precision: 0.999000, train loss: 10.258751, valid precision: 0.875400, valid loss: 96.606084
epoch: 3194, train precision: 0.998756, train loss: 10.380857, valid precision: 0.873200, valid loss: 95.975062
epoch: 3195, train precision: 0.998222, train loss: 10.542817, valid precision: 0.877200, valid loss: 95.211950
epoch: 3196, train precision: 0.999178, train loss: 10.305910, valid precision: 0.874400, valid loss: 95.252035
epoch: 3197, train precision: 0.999044, train loss: 10.305135, valid precision: 0.873800, valid loss: 95.690418
epoch: 3198, train precision: 0.998956, train loss: 10.372066, valid precision: 0.874800, valid loss: 94.934017
epoch: 3199, train precision: 0.999044, train loss: 10.337486, valid precision: 0.873400, valid loss: 97.121084
epoch: 3200, train precision: 0.998956, train loss: 10.325106, valid precision: 0.875000, valid loss: 97.556155
epoch: 3201, train precision: 0.998867, train loss: 10.376158, valid precision: 0.875000, valid loss: 95.483004
epoch: 3202, train precision: 0.999111, train loss: 10.196384, valid precision: 0.873800, valid loss: 94.468480
epoch: 3203, train precision: 0.999222, train loss: 10.225284, valid precision: 0.876400, valid loss: 93.850336
epoch: 3204, train precision: 0.998644, train loss: 10.455971, valid precision: 0.869600, valid loss: 97.835333
epoch: 3205, train precision: 0.999289, train loss: 10.233432, valid precision: 0.872800, valid loss: 97.105803
epoch: 3206, train precision: 0.998578, train loss: 10.406529, valid precision: 0.872600, valid loss: 99.765662
epoch: 3207, train precision: 0.999000, train loss: 10.276681, valid precision: 0.874400, valid loss: 96.159045
epoch: 3208, train precision: 0.998622, train loss: 10.405860, valid precision: 0.879600, valid loss: 97.283249
epoch: 3209, train precision: 0.999044, train loss: 10.284423, valid precision: 0.874400, valid loss: 98.142404
epoch: 3210, train precision: 0.998889, train loss: 10.325720, valid precision: 0.874000, valid loss: 96.311978
epoch: 3211, train precision: 0.998733, train loss: 10.414159, valid precision: 0.874600, valid loss: 96.018686
epoch: 3212, train precision: 0.999089, train loss: 10.325999, valid precision: 0.873200, valid loss: 96.622349
epoch: 3213, train precision: 0.998778, train loss: 10.356207, valid precision: 0.873600, valid loss: 98.437643
epoch: 3214, train precision: 0.999200, train loss: 10.304604, valid precision: 0.872000, valid loss: 95.623202
epoch: 3215, train precision: 0.999000, train loss: 10.338098, valid precision: 0.875200, valid loss: 95.966654
epoch: 3216, train precision: 0.999267, train loss: 10.232858, valid precision: 0.878600, valid loss: 96.373209
epoch: 3217, train precision: 0.999022, train loss: 10.320325, valid precision: 0.874000, valid loss: 97.374707
epoch: 3218, train precision: 0.998644, train loss: 10.393079, valid precision: 0.870800, valid loss: 97.242379
epoch: 3219, train precision: 0.998978, train loss: 10.297450, valid precision: 0.875400, valid loss: 95.004143
epoch: 3220, train precision: 0.999111, train loss: 10.306150, valid precision: 0.876600, valid loss: 94.224789
epoch: 3221, train precision: 0.999267, train loss: 10.241473, valid precision: 0.879200, valid loss: 94.579039
epoch: 3222, train precision: 0.998756, train loss: 10.450820, valid precision: 0.873800, valid loss: 95.902739
epoch: 3223, train precision: 0.999044, train loss: 10.318281, valid precision: 0.871000, valid loss: 93.533103
epoch: 3224, train precision: 0.999156, train loss: 10.254932, valid precision: 0.874000, valid loss: 96.557193
epoch: 3225, train precision: 0.999000, train loss: 10.285672, valid precision: 0.876600, valid loss: 94.283263
epoch: 3226, train precision: 0.998978, train loss: 10.280331, valid precision: 0.874800, valid loss: 96.980290
epoch: 3227, train precision: 0.998733, train loss: 10.338054, valid precision: 0.870000, valid loss: 99.151217
epoch: 3228, train precision: 0.999200, train loss: 10.209259, valid precision: 0.871000, valid loss: 100.491928
epoch: 3229, train precision: 0.999333, train loss: 10.234716, valid precision: 0.875400, valid loss: 97.143021
epoch: 3230, train precision: 0.999222, train loss: 10.311808, valid precision: 0.870000, valid loss: 100.013813
epoch: 3231, train precision: 0.999111, train loss: 10.256657, valid precision: 0.871800, valid loss: 99.448157
epoch: 3232, train precision: 0.998800, train loss: 10.342202, valid precision: 0.874200, valid loss: 101.233046
epoch: 3233, train precision: 0.999222, train loss: 10.273327, valid precision: 0.876800, valid loss: 97.936609
epoch: 3234, train precision: 0.998889, train loss: 10.323920, valid precision: 0.874400, valid loss: 98.893172
epoch: 3235, train precision: 0.999222, train loss: 10.216069, valid precision: 0.872000, valid loss: 100.892728
epoch: 3236, train precision: 0.998644, train loss: 10.354000, valid precision: 0.869800, valid loss: 99.757421
epoch: 3237, train precision: 0.999222, train loss: 10.258717, valid precision: 0.876600, valid loss: 99.184731
epoch: 3238, train precision: 0.998822, train loss: 10.333329, valid precision: 0.870400, valid loss: 102.418591
epoch: 3239, train precision: 0.999022, train loss: 10.240811, valid precision: 0.874000, valid loss: 99.276393
epoch: 3240, train precision: 0.998711, train loss: 10.392256, valid precision: 0.868800, valid loss: 100.585394
epoch: 3241, train precision: 0.999133, train loss: 10.239702, valid precision: 0.872600, valid loss: 97.108819
epoch: 3242, train precision: 0.998711, train loss: 10.402782, valid precision: 0.870400, valid loss: 99.471820
epoch: 3243, train precision: 0.999467, train loss: 10.207275, valid precision: 0.870800, valid loss: 97.241172
epoch: 3244, train precision: 0.998978, train loss: 10.330719, valid precision: 0.871200, valid loss: 99.997268
epoch: 3245, train precision: 0.999111, train loss: 10.284658, valid precision: 0.871200, valid loss: 98.551830
epoch: 3246, train precision: 0.998733, train loss: 10.377729, valid precision: 0.869800, valid loss: 99.204514
epoch: 3247, train precision: 0.999244, train loss: 10.245540, valid precision: 0.871000, valid loss: 97.839972
epoch: 3248, train precision: 0.999089, train loss: 10.219632, valid precision: 0.874400, valid loss: 99.216054
epoch: 3249, train precision: 0.999133, train loss: 10.271585, valid precision: 0.874600, valid loss: 100.826537
epoch: 3250, train precision: 0.998756, train loss: 10.390602, valid precision: 0.875000, valid loss: 100.186865
epoch: 3251, train precision: 0.998889, train loss: 10.351658, valid precision: 0.876800, valid loss: 96.987792
epoch: 3252, train precision: 0.999222, train loss: 10.145170, valid precision: 0.874000, valid loss: 97.662240
epoch: 3253, train precision: 0.999356, train loss: 10.187796, valid precision: 0.871600, valid loss: 98.495205
epoch: 3254, train precision: 0.999178, train loss: 10.240267, valid precision: 0.872200, valid loss: 98.345700
epoch: 3255, train precision: 0.999022, train loss: 10.285021, valid precision: 0.872800, valid loss: 100.911912
epoch: 3256, train precision: 0.998778, train loss: 10.361184, valid precision: 0.875200, valid loss: 97.789342
epoch: 3257, train precision: 0.999022, train loss: 10.254910, valid precision: 0.874000, valid loss: 99.753401
epoch: 3258, train precision: 0.998844, train loss: 10.284172, valid precision: 0.875400, valid loss: 99.261140
epoch: 3259, train precision: 0.998956, train loss: 10.251439, valid precision: 0.872200, valid loss: 100.453585
epoch: 3260, train precision: 0.999067, train loss: 10.211947, valid precision: 0.874200, valid loss: 100.711448
epoch: 3261, train precision: 0.998578, train loss: 10.360509, valid precision: 0.870200, valid loss: 103.023694
epoch: 3262, train precision: 0.999044, train loss: 10.295307, valid precision: 0.871200, valid loss: 100.181349
epoch: 3263, train precision: 0.998844, train loss: 10.332801, valid precision: 0.872000, valid loss: 100.539616
epoch: 3264, train precision: 0.998911, train loss: 10.271713, valid precision: 0.871600, valid loss: 100.461167
epoch: 3265, train precision: 0.998844, train loss: 10.294218, valid precision: 0.871800, valid loss: 101.189316
epoch: 3266, train precision: 0.998844, train loss: 10.270282, valid precision: 0.874800, valid loss: 102.835751
epoch: 3267, train precision: 0.998867, train loss: 10.333704, valid precision: 0.872600, valid loss: 102.065480
epoch: 3268, train precision: 0.998978, train loss: 10.305387, valid precision: 0.873400, valid loss: 101.736049
epoch: 3269, train precision: 0.999222, train loss: 10.261218, valid precision: 0.874000, valid loss: 100.530533
epoch: 3270, train precision: 0.999044, train loss: 10.249746, valid precision: 0.875600, valid loss: 99.190810
epoch: 3271, train precision: 0.999222, train loss: 10.141403, valid precision: 0.875000, valid loss: 99.943263
epoch: 3272, train precision: 0.998956, train loss: 10.350713, valid precision: 0.876000, valid loss: 99.034141
epoch: 3273, train precision: 0.998867, train loss: 10.280415, valid precision: 0.879200, valid loss: 97.895211
epoch: 3274, train precision: 0.999156, train loss: 10.241698, valid precision: 0.874000, valid loss: 98.676190
epoch: 3275, train precision: 0.999133, train loss: 10.265051, valid precision: 0.875800, valid loss: 97.116775
epoch: 3276, train precision: 0.998622, train loss: 10.410535, valid precision: 0.873000, valid loss: 99.862475
epoch: 3277, train precision: 0.998911, train loss: 10.289100, valid precision: 0.873000, valid loss: 99.052560
epoch: 3278, train precision: 0.999333, train loss: 10.210991, valid precision: 0.873800, valid loss: 99.835058
epoch: 3279, train precision: 0.999533, train loss: 10.181292, valid precision: 0.876800, valid loss: 98.964227
epoch: 3280, train precision: 0.998622, train loss: 10.354551, valid precision: 0.872200, valid loss: 96.279204
epoch: 3281, train precision: 0.999200, train loss: 10.190829, valid precision: 0.874200, valid loss: 97.891686
epoch: 3282, train precision: 0.999000, train loss: 10.298830, valid precision: 0.871800, valid loss: 98.279965
epoch: 3283, train precision: 0.999133, train loss: 10.237187, valid precision: 0.874200, valid loss: 97.789841
epoch: 3284, train precision: 0.999200, train loss: 10.294644, valid precision: 0.869200, valid loss: 100.014594
epoch: 3285, train precision: 0.999267, train loss: 10.193496, valid precision: 0.870200, valid loss: 102.054160
epoch: 3286, train precision: 0.998778, train loss: 10.400621, valid precision: 0.872000, valid loss: 100.702498
epoch: 3287, train precision: 0.999022, train loss: 10.306903, valid precision: 0.872400, valid loss: 100.207660
epoch: 3288, train precision: 0.998756, train loss: 10.377973, valid precision: 0.872600, valid loss: 99.643631
epoch: 3289, train precision: 0.999089, train loss: 10.265405, valid precision: 0.872600, valid loss: 99.562270
epoch: 3290, train precision: 0.999200, train loss: 10.263433, valid precision: 0.872600, valid loss: 98.438763
epoch: 3291, train precision: 0.998689, train loss: 10.356475, valid precision: 0.874200, valid loss: 98.543246
epoch: 3292, train precision: 0.999111, train loss: 10.228390, valid precision: 0.872800, valid loss: 97.467272
epoch: 3293, train precision: 0.999422, train loss: 10.188593, valid precision: 0.875400, valid loss: 98.756907
epoch: 3294, train precision: 0.998978, train loss: 10.336123, valid precision: 0.872400, valid loss: 100.079906
epoch: 3295, train precision: 0.998822, train loss: 10.354669, valid precision: 0.871200, valid loss: 99.176489
epoch: 3296, train precision: 0.998667, train loss: 10.431100, valid precision: 0.869800, valid loss: 102.180518
epoch: 3297, train precision: 0.998822, train loss: 10.302896, valid precision: 0.872600, valid loss: 99.728589
epoch: 3298, train precision: 0.998911, train loss: 10.311407, valid precision: 0.867400, valid loss: 100.595747
epoch: 3299, train precision: 0.998889, train loss: 10.287844, valid precision: 0.870000, valid loss: 100.679953
epoch: 3300, train precision: 0.999333, train loss: 10.212608, valid precision: 0.871800, valid loss: 98.877151
epoch: 3301, train precision: 0.998222, train loss: 10.504734, valid precision: 0.868400, valid loss: 101.731733
epoch: 3302, train precision: 0.999200, train loss: 10.243369, valid precision: 0.872600, valid loss: 99.379271
epoch: 3303, train precision: 0.999178, train loss: 10.266279, valid precision: 0.872400, valid loss: 98.881387
epoch: 3304, train precision: 0.999067, train loss: 10.237748, valid precision: 0.875200, valid loss: 99.219059
epoch: 3305, train precision: 0.998978, train loss: 10.300962, valid precision: 0.872200, valid loss: 98.592750
epoch: 3306, train precision: 0.999333, train loss: 10.220678, valid precision: 0.869600, valid loss: 101.728529
epoch: 3307, train precision: 0.999444, train loss: 10.218536, valid precision: 0.872800, valid loss: 99.430268
epoch: 3308, train precision: 0.999156, train loss: 10.255378, valid precision: 0.872400, valid loss: 98.627155
epoch: 3309, train precision: 0.998844, train loss: 10.267153, valid precision: 0.869600, valid loss: 100.275286
epoch: 3310, train precision: 0.998556, train loss: 10.417104, valid precision: 0.873200, valid loss: 98.564353
epoch: 3311, train precision: 0.998778, train loss: 10.310817, valid precision: 0.872400, valid loss: 97.998494
epoch: 3312, train precision: 0.998400, train loss: 10.471948, valid precision: 0.872800, valid loss: 96.557227
epoch: 3313, train precision: 0.998889, train loss: 10.264664, valid precision: 0.872600, valid loss: 96.498058
epoch: 3314, train precision: 0.998444, train loss: 10.477360, valid precision: 0.871000, valid loss: 98.588328
epoch: 3315, train precision: 0.998889, train loss: 10.308439, valid precision: 0.870200, valid loss: 99.674978
epoch: 3316, train precision: 0.998822, train loss: 10.339406, valid precision: 0.873800, valid loss: 96.952130
epoch: 3317, train precision: 0.998911, train loss: 10.356259, valid precision: 0.875600, valid loss: 95.657752
epoch: 3318, train precision: 0.998889, train loss: 10.299147, valid precision: 0.876200, valid loss: 98.498728
epoch: 3319, train precision: 0.999156, train loss: 10.209214, valid precision: 0.876200, valid loss: 95.955296
epoch: 3320, train precision: 0.998689, train loss: 10.349861, valid precision: 0.872000, valid loss: 99.221644
epoch: 3321, train precision: 0.999089, train loss: 10.313800, valid precision: 0.873000, valid loss: 95.598686
epoch: 3322, train precision: 0.999311, train loss: 10.158052, valid precision: 0.871800, valid loss: 98.317548
epoch: 3323, train precision: 0.998689, train loss: 10.309773, valid precision: 0.873800, valid loss: 97.187058
epoch: 3324, train precision: 0.998956, train loss: 10.343380, valid precision: 0.873200, valid loss: 96.823925
epoch: 3325, train precision: 0.999000, train loss: 10.326801, valid precision: 0.870800, valid loss: 97.504098
epoch: 3326, train precision: 0.999222, train loss: 10.216338, valid precision: 0.869800, valid loss: 100.427524
epoch: 3327, train precision: 0.999044, train loss: 10.243686, valid precision: 0.872200, valid loss: 99.088568
epoch: 3328, train precision: 0.998578, train loss: 10.388140, valid precision: 0.869600, valid loss: 100.349083
epoch: 3329, train precision: 0.999111, train loss: 10.207903, valid precision: 0.868800, valid loss: 100.917225
epoch: 3330, train precision: 0.998689, train loss: 10.310052, valid precision: 0.872600, valid loss: 100.755387
epoch: 3331, train precision: 0.999156, train loss: 10.257207, valid precision: 0.874400, valid loss: 95.303125
epoch: 3332, train precision: 0.998933, train loss: 10.278969, valid precision: 0.871000, valid loss: 99.808947
epoch: 3333, train precision: 0.999178, train loss: 10.209240, valid precision: 0.873200, valid loss: 96.542862
epoch: 3334, train precision: 0.999111, train loss: 10.252630, valid precision: 0.874200, valid loss: 98.746103
epoch: 3335, train precision: 0.998778, train loss: 10.314455, valid precision: 0.874200, valid loss: 99.249008
epoch: 3336, train precision: 0.999244, train loss: 10.217042, valid precision: 0.872600, valid loss: 95.249041
epoch: 3337, train precision: 0.999111, train loss: 10.221941, valid precision: 0.873400, valid loss: 97.167987
epoch: 3338, train precision: 0.998756, train loss: 10.346409, valid precision: 0.876600, valid loss: 95.585358
epoch: 3339, train precision: 0.999044, train loss: 10.250218, valid precision: 0.880800, valid loss: 96.255974
epoch: 3340, train precision: 0.999267, train loss: 10.207455, valid precision: 0.877600, valid loss: 96.864235
epoch: 3341, train precision: 0.999156, train loss: 10.239892, valid precision: 0.876200, valid loss: 99.210146
epoch: 3342, train precision: 0.999156, train loss: 10.242017, valid precision: 0.875400, valid loss: 96.877615
epoch: 3343, train precision: 0.999244, train loss: 10.214124, valid precision: 0.870000, valid loss: 99.664640
epoch: 3344, train precision: 0.999022, train loss: 10.381469, valid precision: 0.872200, valid loss: 101.403612
epoch: 3345, train precision: 0.999156, train loss: 10.238731, valid precision: 0.873800, valid loss: 95.674367
epoch: 3346, train precision: 0.999200, train loss: 10.198651, valid precision: 0.873200, valid loss: 98.257283
epoch: 3347, train precision: 0.999222, train loss: 10.240789, valid precision: 0.870400, valid loss: 99.817014
epoch: 3348, train precision: 0.999244, train loss: 10.198602, valid precision: 0.876600, valid loss: 98.697528
epoch: 3349, train precision: 0.999000, train loss: 10.280425, valid precision: 0.875000, valid loss: 96.306959
epoch: 3350, train precision: 0.998956, train loss: 10.288461, valid precision: 0.873800, valid loss: 99.418043
epoch: 3351, train precision: 0.998956, train loss: 10.302809, valid precision: 0.872800, valid loss: 100.988551
epoch: 3352, train precision: 0.999022, train loss: 10.245222, valid precision: 0.875000, valid loss: 96.993420
epoch: 3353, train precision: 0.998667, train loss: 10.403073, valid precision: 0.872800, valid loss: 97.556354
epoch: 3354, train precision: 0.998556, train loss: 10.406181, valid precision: 0.874400, valid loss: 97.404502
epoch: 3355, train precision: 0.999156, train loss: 10.265368, valid precision: 0.873800, valid loss: 98.352754
epoch: 3356, train precision: 0.999422, train loss: 10.192147, valid precision: 0.874000, valid loss: 96.903360
epoch: 3357, train precision: 0.999378, train loss: 10.174705, valid precision: 0.875400, valid loss: 94.099608
epoch: 3358, train precision: 0.999000, train loss: 10.263796, valid precision: 0.877800, valid loss: 96.186880
epoch: 3359, train precision: 0.999133, train loss: 10.215475, valid precision: 0.875000, valid loss: 96.287046
epoch: 3360, train precision: 0.999000, train loss: 10.259261, valid precision: 0.874800, valid loss: 96.380231
epoch: 3361, train precision: 0.999000, train loss: 10.291641, valid precision: 0.877800, valid loss: 95.782650
epoch: 3362, train precision: 0.999178, train loss: 10.212181, valid precision: 0.875600, valid loss: 94.940609
epoch: 3363, train precision: 0.999422, train loss: 10.208472, valid precision: 0.878200, valid loss: 93.799388
epoch: 3364, train precision: 0.999111, train loss: 10.304360, valid precision: 0.873000, valid loss: 96.192425
epoch: 3365, train precision: 0.998911, train loss: 10.275691, valid precision: 0.874000, valid loss: 96.706668
epoch: 3366, train precision: 0.999133, train loss: 10.240462, valid precision: 0.879400, valid loss: 97.418131
epoch: 3367, train precision: 0.998889, train loss: 10.337468, valid precision: 0.876600, valid loss: 98.023113
epoch: 3368, train precision: 0.999156, train loss: 10.222375, valid precision: 0.873400, valid loss: 99.979578
epoch: 3369, train precision: 0.999267, train loss: 10.191742, valid precision: 0.874400, valid loss: 99.757715
epoch: 3370, train precision: 0.999133, train loss: 10.192118, valid precision: 0.874200, valid loss: 97.595749
epoch: 3371, train precision: 0.999267, train loss: 10.259980, valid precision: 0.874800, valid loss: 96.705522
epoch: 3372, train precision: 0.998978, train loss: 10.304928, valid precision: 0.871800, valid loss: 97.953656
epoch: 3373, train precision: 0.999222, train loss: 10.230466, valid precision: 0.874200, valid loss: 95.707581
epoch: 3374, train precision: 0.998778, train loss: 10.324486, valid precision: 0.877200, valid loss: 97.242319
epoch: 3375, train precision: 0.999444, train loss: 10.149123, valid precision: 0.873800, valid loss: 96.429454
epoch: 3376, train precision: 0.999000, train loss: 10.257659, valid precision: 0.872800, valid loss: 97.885876
epoch: 3377, train precision: 0.998689, train loss: 10.348934, valid precision: 0.875000, valid loss: 97.744589
epoch: 3378, train precision: 0.998778, train loss: 10.351657, valid precision: 0.873200, valid loss: 98.060672
epoch: 3379, train precision: 0.999089, train loss: 10.279940, valid precision: 0.871400, valid loss: 98.490780
epoch: 3380, train precision: 0.999267, train loss: 10.202159, valid precision: 0.872400, valid loss: 97.548249
epoch: 3381, train precision: 0.999178, train loss: 10.242553, valid precision: 0.872600, valid loss: 97.492174
epoch: 3382, train precision: 0.999022, train loss: 10.334006, valid precision: 0.868200, valid loss: 98.825971
epoch: 3383, train precision: 0.999022, train loss: 10.259211, valid precision: 0.875600, valid loss: 96.927099
epoch: 3384, train precision: 0.998778, train loss: 10.287947, valid precision: 0.877600, valid loss: 96.219726
epoch: 3385, train precision: 0.999133, train loss: 10.238008, valid precision: 0.874200, valid loss: 99.609436
epoch: 3386, train precision: 0.999400, train loss: 10.174438, valid precision: 0.873600, valid loss: 96.939556
epoch: 3387, train precision: 0.999222, train loss: 10.224835, valid precision: 0.869800, valid loss: 96.797539
epoch: 3388, train precision: 0.999222, train loss: 10.232037, valid precision: 0.872800, valid loss: 97.751699
epoch: 3389, train precision: 0.998622, train loss: 10.475540, valid precision: 0.872400, valid loss: 97.537489
epoch: 3390, train precision: 0.999267, train loss: 10.196628, valid precision: 0.874400, valid loss: 96.294662
epoch: 3391, train precision: 0.998600, train loss: 10.428154, valid precision: 0.876200, valid loss: 98.891496
epoch: 3392, train precision: 0.999178, train loss: 10.257953, valid precision: 0.876800, valid loss: 96.437016
epoch: 3393, train precision: 0.999200, train loss: 10.210716, valid precision: 0.876400, valid loss: 99.836790
epoch: 3394, train precision: 0.998889, train loss: 10.312798, valid precision: 0.873800, valid loss: 99.432335
epoch: 3395, train precision: 0.999089, train loss: 10.241018, valid precision: 0.873800, valid loss: 99.494479
epoch: 3396, train precision: 0.999156, train loss: 10.279720, valid precision: 0.872400, valid loss: 100.614994
epoch: 3397, train precision: 0.999067, train loss: 10.230470, valid precision: 0.875000, valid loss: 96.820014
epoch: 3398, train precision: 0.999400, train loss: 10.165437, valid precision: 0.876600, valid loss: 97.934284
epoch: 3399, train precision: 0.998911, train loss: 10.307731, valid precision: 0.877600, valid loss: 96.145076
epoch: 3400, train precision: 0.999044, train loss: 10.224474, valid precision: 0.874800, valid loss: 96.029720
epoch: 3401, train precision: 0.999200, train loss: 10.205368, valid precision: 0.873200, valid loss: 97.839858
epoch: 3402, train precision: 0.998733, train loss: 10.372991, valid precision: 0.875400, valid loss: 100.386105
epoch: 3403, train precision: 0.999222, train loss: 10.237576, valid precision: 0.873000, valid loss: 98.202700
epoch: 3404, train precision: 0.999200, train loss: 10.242771, valid precision: 0.876200, valid loss: 97.577604
epoch: 3405, train precision: 0.998978, train loss: 10.296860, valid precision: 0.878800, valid loss: 95.002679
epoch: 3406, train precision: 0.999044, train loss: 10.262518, valid precision: 0.874200, valid loss: 95.172277
epoch: 3407, train precision: 0.999067, train loss: 10.293290, valid precision: 0.876400, valid loss: 95.686366
epoch: 3408, train precision: 0.998600, train loss: 10.362127, valid precision: 0.875000, valid loss: 97.873631
epoch: 3409, train precision: 0.999133, train loss: 10.195846, valid precision: 0.876600, valid loss: 98.086703
epoch: 3410, train precision: 0.998756, train loss: 10.372815, valid precision: 0.872800, valid loss: 99.866183
epoch: 3411, train precision: 0.998667, train loss: 10.475029, valid precision: 0.877000, valid loss: 99.498186
epoch: 3412, train precision: 0.998800, train loss: 10.321937, valid precision: 0.871400, valid loss: 98.421245
epoch: 3413, train precision: 0.999089, train loss: 10.291452, valid precision: 0.879200, valid loss: 95.913166
epoch: 3414, train precision: 0.999022, train loss: 10.287676, valid precision: 0.874400, valid loss: 97.663983
epoch: 3415, train precision: 0.998800, train loss: 10.437883, valid precision: 0.872000, valid loss: 98.242397
epoch: 3416, train precision: 0.999111, train loss: 10.262637, valid precision: 0.872200, valid loss: 98.390270
epoch: 3417, train precision: 0.998867, train loss: 10.339527, valid precision: 0.872800, valid loss: 98.171103
epoch: 3418, train precision: 0.999089, train loss: 10.321150, valid precision: 0.876600, valid loss: 97.696024
epoch: 3419, train precision: 0.999156, train loss: 10.317410, valid precision: 0.874600, valid loss: 98.086301
epoch: 3420, train precision: 0.999111, train loss: 10.268532, valid precision: 0.871000, valid loss: 100.338344
epoch: 3421, train precision: 0.999356, train loss: 10.163679, valid precision: 0.872400, valid loss: 97.639725
epoch: 3422, train precision: 0.998867, train loss: 10.296343, valid precision: 0.876000, valid loss: 96.053677
epoch: 3423, train precision: 0.999378, train loss: 10.187415, valid precision: 0.874000, valid loss: 97.132046
epoch: 3424, train precision: 0.998778, train loss: 10.371517, valid precision: 0.878200, valid loss: 97.897589
epoch: 3425, train precision: 0.999089, train loss: 10.229659, valid precision: 0.873200, valid loss: 95.562588
epoch: 3426, train precision: 0.999467, train loss: 10.178146, valid precision: 0.873400, valid loss: 98.333653
epoch: 3427, train precision: 0.999200, train loss: 10.206882, valid precision: 0.873800, valid loss: 99.772337
epoch: 3428, train precision: 0.999178, train loss: 10.247088, valid precision: 0.875400, valid loss: 100.636876
epoch: 3429, train precision: 0.998822, train loss: 10.339485, valid precision: 0.872000, valid loss: 99.087106
epoch: 3430, train precision: 0.998867, train loss: 10.308449, valid precision: 0.875800, valid loss: 99.357156
epoch: 3431, train precision: 0.999200, train loss: 10.255082, valid precision: 0.875600, valid loss: 96.615583
epoch: 3432, train precision: 0.998978, train loss: 10.294834, valid precision: 0.878000, valid loss: 96.509887
epoch: 3433, train precision: 0.999200, train loss: 10.254200, valid precision: 0.875800, valid loss: 97.719734
epoch: 3434, train precision: 0.999000, train loss: 10.311658, valid precision: 0.879400, valid loss: 96.818365
epoch: 3435, train precision: 0.999000, train loss: 10.317461, valid precision: 0.877400, valid loss: 97.271198
epoch: 3436, train precision: 0.999489, train loss: 10.135844, valid precision: 0.874200, valid loss: 95.681641
epoch: 3437, train precision: 0.999178, train loss: 10.226842, valid precision: 0.881000, valid loss: 97.420719
epoch: 3438, train precision: 0.998733, train loss: 10.360659, valid precision: 0.876200, valid loss: 95.483716
epoch: 3439, train precision: 0.999156, train loss: 10.261872, valid precision: 0.879200, valid loss: 94.419335
epoch: 3440, train precision: 0.998756, train loss: 10.325208, valid precision: 0.878400, valid loss: 97.174689
epoch: 3441, train precision: 0.998800, train loss: 10.278591, valid precision: 0.875000, valid loss: 98.014337
epoch: 3442, train precision: 0.998689, train loss: 10.376943, valid precision: 0.876400, valid loss: 96.554072
epoch: 3443, train precision: 0.999111, train loss: 10.265365, valid precision: 0.873000, valid loss: 99.736416
epoch: 3444, train precision: 0.999111, train loss: 10.234617, valid precision: 0.878000, valid loss: 95.721487
epoch: 3445, train precision: 0.999067, train loss: 10.236385, valid precision: 0.877200, valid loss: 97.130596
epoch: 3446, train precision: 0.998756, train loss: 10.352118, valid precision: 0.879200, valid loss: 95.020980
epoch: 3447, train precision: 0.998711, train loss: 10.332924, valid precision: 0.874800, valid loss: 97.516720
epoch: 3448, train precision: 0.998756, train loss: 10.315975, valid precision: 0.878400, valid loss: 97.420070
epoch: 3449, train precision: 0.999133, train loss: 10.248580, valid precision: 0.876800, valid loss: 95.611546
epoch: 3450, train precision: 0.999200, train loss: 10.155849, valid precision: 0.878800, valid loss: 97.037792
epoch: 3451, train precision: 0.998844, train loss: 10.262146, valid precision: 0.878200, valid loss: 95.700541
epoch: 3452, train precision: 0.999222, train loss: 10.254562, valid precision: 0.873400, valid loss: 96.935693
epoch: 3453, train precision: 0.999356, train loss: 10.211983, valid precision: 0.870800, valid loss: 96.592922
epoch: 3454, train precision: 0.999267, train loss: 10.175928, valid precision: 0.875600, valid loss: 95.338184
epoch: 3455, train precision: 0.998733, train loss: 10.383546, valid precision: 0.875400, valid loss: 97.898258
epoch: 3456, train precision: 0.999089, train loss: 10.260194, valid precision: 0.873200, valid loss: 96.553301
epoch: 3457, train precision: 0.999333, train loss: 10.171701, valid precision: 0.872000, valid loss: 99.750308
epoch: 3458, train precision: 0.999067, train loss: 10.232098, valid precision: 0.873200, valid loss: 97.798965
epoch: 3459, train precision: 0.998556, train loss: 10.354763, valid precision: 0.874600, valid loss: 98.784405
epoch: 3460, train precision: 0.999400, train loss: 10.140477, valid precision: 0.875400, valid loss: 98.860737
epoch: 3461, train precision: 0.998511, train loss: 10.420036, valid precision: 0.872400, valid loss: 101.958536
epoch: 3462, train precision: 0.999067, train loss: 10.209530, valid precision: 0.873400, valid loss: 102.183077
epoch: 3463, train precision: 0.999267, train loss: 10.240873, valid precision: 0.874000, valid loss: 99.844917
epoch: 3464, train precision: 0.999000, train loss: 10.263329, valid precision: 0.876000, valid loss: 99.374314
epoch: 3465, train precision: 0.999178, train loss: 10.186700, valid precision: 0.872800, valid loss: 100.854262
epoch: 3466, train precision: 0.999111, train loss: 10.202479, valid precision: 0.873200, valid loss: 98.944499
epoch: 3467, train precision: 0.998644, train loss: 10.355518, valid precision: 0.871000, valid loss: 97.482546
epoch: 3468, train precision: 0.999067, train loss: 10.259681, valid precision: 0.872200, valid loss: 100.395157
epoch: 3469, train precision: 0.998911, train loss: 10.311045, valid precision: 0.872800, valid loss: 96.871369
epoch: 3470, train precision: 0.999311, train loss: 10.205485, valid precision: 0.867400, valid loss: 97.792913
epoch: 3471, train precision: 0.999200, train loss: 10.236828, valid precision: 0.869800, valid loss: 101.206884
epoch: 3472, train precision: 0.999244, train loss: 10.226696, valid precision: 0.867400, valid loss: 100.162587
epoch: 3473, train precision: 0.999444, train loss: 10.140755, valid precision: 0.870800, valid loss: 98.901769
epoch: 3474, train precision: 0.998756, train loss: 10.323183, valid precision: 0.871200, valid loss: 99.268277
epoch: 3475, train precision: 0.999111, train loss: 10.193123, valid precision: 0.871800, valid loss: 99.747593
epoch: 3476, train precision: 0.999400, train loss: 10.115399, valid precision: 0.874200, valid loss: 97.239725
epoch: 3477, train precision: 0.998933, train loss: 10.240910, valid precision: 0.873400, valid loss: 97.545621
epoch: 3478, train precision: 0.999111, train loss: 10.255983, valid precision: 0.870400, valid loss: 97.700440
epoch: 3479, train precision: 0.998711, train loss: 10.357461, valid precision: 0.869000, valid loss: 98.142262
epoch: 3480, train precision: 0.998911, train loss: 10.306916, valid precision: 0.876600, valid loss: 98.579141
epoch: 3481, train precision: 0.999000, train loss: 10.287205, valid precision: 0.876400, valid loss: 98.373350
epoch: 3482, train precision: 0.999178, train loss: 10.200175, valid precision: 0.875400, valid loss: 98.612579
epoch: 3483, train precision: 0.998867, train loss: 10.241360, valid precision: 0.876200, valid loss: 98.757772
epoch: 3484, train precision: 0.999333, train loss: 10.152530, valid precision: 0.870800, valid loss: 100.375064
epoch: 3485, train precision: 0.998800, train loss: 10.404090, valid precision: 0.875800, valid loss: 99.092409
epoch: 3486, train precision: 0.999022, train loss: 10.259757, valid precision: 0.876000, valid loss: 99.404808
epoch: 3487, train precision: 0.999000, train loss: 10.218921, valid precision: 0.873000, valid loss: 98.180408
epoch: 3488, train precision: 0.998756, train loss: 10.255881, valid precision: 0.875200, valid loss: 98.667155
epoch: 3489, train precision: 0.999178, train loss: 10.205379, valid precision: 0.875400, valid loss: 99.318423
epoch: 3490, train precision: 0.998644, train loss: 10.334120, valid precision: 0.875600, valid loss: 100.002642
epoch: 3491, train precision: 0.999200, train loss: 10.220303, valid precision: 0.875000, valid loss: 98.154383
epoch: 3492, train precision: 0.999133, train loss: 10.222434, valid precision: 0.872200, valid loss: 100.977388
epoch: 3493, train precision: 0.999000, train loss: 10.234889, valid precision: 0.872000, valid loss: 100.277751
epoch: 3494, train precision: 0.999000, train loss: 10.232526, valid precision: 0.873200, valid loss: 99.126371
epoch: 3495, train precision: 0.998956, train loss: 10.289646, valid precision: 0.877600, valid loss: 98.576951
epoch: 3496, train precision: 0.999178, train loss: 10.216333, valid precision: 0.877000, valid loss: 97.709239
epoch: 3497, train precision: 0.999000, train loss: 10.276686, valid precision: 0.872200, valid loss: 99.759939
epoch: 3498, train precision: 0.999200, train loss: 10.168599, valid precision: 0.873800, valid loss: 99.931748
epoch: 3499, train precision: 0.999200, train loss: 10.225826, valid precision: 0.875200, valid loss: 101.192239
epoch: 3500, train precision: 0.999178, train loss: 10.179876, valid precision: 0.874600, valid loss: 98.306367
epoch: 3501, train precision: 0.998556, train loss: 10.483088, valid precision: 0.874400, valid loss: 97.056546
epoch: 3502, train precision: 0.999178, train loss: 10.259071, valid precision: 0.874400, valid loss: 96.706533
epoch: 3503, train precision: 0.998667, train loss: 10.379217, valid precision: 0.877000, valid loss: 96.897066
epoch: 3504, train precision: 0.998867, train loss: 10.246010, valid precision: 0.874400, valid loss: 99.089927
epoch: 3505, train precision: 0.999022, train loss: 10.214061, valid precision: 0.874200, valid loss: 96.746038
epoch: 3506, train precision: 0.999267, train loss: 10.123961, valid precision: 0.879200, valid loss: 95.642553
epoch: 3507, train precision: 0.999000, train loss: 10.272437, valid precision: 0.872600, valid loss: 100.441933
epoch: 3508, train precision: 0.998911, train loss: 10.281613, valid precision: 0.873400, valid loss: 97.394126
epoch: 3509, train precision: 0.999244, train loss: 10.193964, valid precision: 0.872400, valid loss: 97.834136
epoch: 3510, train precision: 0.998956, train loss: 10.284350, valid precision: 0.876400, valid loss: 95.590416
epoch: 3511, train precision: 0.999022, train loss: 10.190632, valid precision: 0.874200, valid loss: 95.478672
epoch: 3512, train precision: 0.998733, train loss: 10.265885, valid precision: 0.873000, valid loss: 95.029509
epoch: 3513, train precision: 0.999244, train loss: 10.200691, valid precision: 0.875000, valid loss: 95.400189
epoch: 3514, train precision: 0.999244, train loss: 10.173746, valid precision: 0.875800, valid loss: 95.731390
epoch: 3515, train precision: 0.999067, train loss: 10.241228, valid precision: 0.877200, valid loss: 96.417882
epoch: 3516, train precision: 0.998622, train loss: 10.394547, valid precision: 0.873600, valid loss: 97.193051
epoch: 3517, train precision: 0.998956, train loss: 10.294518, valid precision: 0.874800, valid loss: 96.055251
epoch: 3518, train precision: 0.999222, train loss: 10.138128, valid precision: 0.874400, valid loss: 97.032063
epoch: 3519, train precision: 0.999156, train loss: 10.188979, valid precision: 0.874600, valid loss: 97.233646
epoch: 3520, train precision: 0.999267, train loss: 10.161015, valid precision: 0.874800, valid loss: 98.900734
epoch: 3521, train precision: 0.999222, train loss: 10.157112, valid precision: 0.876400, valid loss: 96.426631
epoch: 3522, train precision: 0.999133, train loss: 10.260522, valid precision: 0.876800, valid loss: 96.173844
epoch: 3523, train precision: 0.999222, train loss: 10.161452, valid precision: 0.878200, valid loss: 96.986600
epoch: 3524, train precision: 0.998933, train loss: 10.260040, valid precision: 0.875000, valid loss: 95.651737
epoch: 3525, train precision: 0.998978, train loss: 10.219802, valid precision: 0.876400, valid loss: 95.638560
epoch: 3526, train precision: 0.999044, train loss: 10.218230, valid precision: 0.881200, valid loss: 93.305215
epoch: 3527, train precision: 0.999222, train loss: 10.172400, valid precision: 0.877800, valid loss: 92.465752
epoch: 3528, train precision: 0.999467, train loss: 10.113573, valid precision: 0.878400, valid loss: 94.602271
epoch: 3529, train precision: 0.999267, train loss: 10.167250, valid precision: 0.877200, valid loss: 93.440829
epoch: 3530, train precision: 0.999067, train loss: 10.210653, valid precision: 0.874600, valid loss: 95.724020
epoch: 3531, train precision: 0.998578, train loss: 10.306305, valid precision: 0.873600, valid loss: 97.266514
epoch: 3532, train precision: 0.999222, train loss: 10.162188, valid precision: 0.876800, valid loss: 96.478477
epoch: 3533, train precision: 0.999156, train loss: 10.208435, valid precision: 0.876800, valid loss: 92.211526
epoch: 3534, train precision: 0.999200, train loss: 10.159082, valid precision: 0.877000, valid loss: 93.335054
epoch: 3535, train precision: 0.999067, train loss: 10.158333, valid precision: 0.877800, valid loss: 94.799103
epoch: 3536, train precision: 0.999067, train loss: 10.284345, valid precision: 0.875000, valid loss: 93.393268
epoch: 3537, train precision: 0.999089, train loss: 10.197838, valid precision: 0.879800, valid loss: 97.232845
epoch: 3538, train precision: 0.999400, train loss: 10.158911, valid precision: 0.873400, valid loss: 96.496370
epoch: 3539, train precision: 0.999133, train loss: 10.247950, valid precision: 0.873400, valid loss: 96.737045
epoch: 3540, train precision: 0.998822, train loss: 10.335903, valid precision: 0.870800, valid loss: 96.808833
epoch: 3541, train precision: 0.998911, train loss: 10.261337, valid precision: 0.877000, valid loss: 95.993706
epoch: 3542, train precision: 0.999000, train loss: 10.257566, valid precision: 0.875200, valid loss: 94.527617
epoch: 3543, train precision: 0.999444, train loss: 10.120893, valid precision: 0.874400, valid loss: 96.021993
epoch: 3544, train precision: 0.998711, train loss: 10.266089, valid precision: 0.873600, valid loss: 96.202128
epoch: 3545, train precision: 0.999133, train loss: 10.210676, valid precision: 0.873200, valid loss: 96.994668
epoch: 3546, train precision: 0.999156, train loss: 10.190788, valid precision: 0.880200, valid loss: 95.657451
epoch: 3547, train precision: 0.999022, train loss: 10.248287, valid precision: 0.876600, valid loss: 96.636546
epoch: 3548, train precision: 0.999044, train loss: 10.248533, valid precision: 0.875200, valid loss: 94.909895
epoch: 3549, train precision: 0.999289, train loss: 10.188762, valid precision: 0.874600, valid loss: 96.459544
epoch: 3550, train precision: 0.999400, train loss: 10.170336, valid precision: 0.879400, valid loss: 95.212659
epoch: 3551, train precision: 0.998933, train loss: 10.271992, valid precision: 0.875200, valid loss: 97.012658
epoch: 3552, train precision: 0.998889, train loss: 10.243716, valid precision: 0.876800, valid loss: 96.394681
epoch: 3553, train precision: 0.999200, train loss: 10.207948, valid precision: 0.875800, valid loss: 93.637324
epoch: 3554, train precision: 0.999044, train loss: 10.194444, valid precision: 0.878200, valid loss: 95.361687
epoch: 3555, train precision: 0.999089, train loss: 10.216442, valid precision: 0.874400, valid loss: 96.498770
epoch: 3556, train precision: 0.999067, train loss: 10.226128, valid precision: 0.878000, valid loss: 95.090518
epoch: 3557, train precision: 0.998889, train loss: 10.270274, valid precision: 0.875000, valid loss: 98.592660
epoch: 3558, train precision: 0.998778, train loss: 10.303943, valid precision: 0.877200, valid loss: 97.714537
epoch: 3559, train precision: 0.999000, train loss: 10.172511, valid precision: 0.878200, valid loss: 96.312717
epoch: 3560, train precision: 0.999378, train loss: 10.093193, valid precision: 0.877200, valid loss: 95.453932
epoch: 3561, train precision: 0.999000, train loss: 10.190704, valid precision: 0.878600, valid loss: 95.951275
epoch: 3562, train precision: 0.999178, train loss: 10.222128, valid precision: 0.879200, valid loss: 96.605417
epoch: 3563, train precision: 0.998867, train loss: 10.261085, valid precision: 0.876400, valid loss: 96.147239
epoch: 3564, train precision: 0.999244, train loss: 10.163878, valid precision: 0.877600, valid loss: 95.415079
epoch: 3565, train precision: 0.998956, train loss: 10.215287, valid precision: 0.878000, valid loss: 94.061876
epoch: 3566, train precision: 0.999111, train loss: 10.184715, valid precision: 0.881800, valid loss: 95.158266
epoch: 3567, train precision: 0.998867, train loss: 10.279392, valid precision: 0.875600, valid loss: 96.479725
epoch: 3568, train precision: 0.999067, train loss: 10.232636, valid precision: 0.877400, valid loss: 96.628121
epoch: 3569, train precision: 0.999044, train loss: 10.227895, valid precision: 0.881800, valid loss: 95.770305
epoch: 3570, train precision: 0.999022, train loss: 10.259150, valid precision: 0.879000, valid loss: 97.588881
epoch: 3571, train precision: 0.998600, train loss: 10.318490, valid precision: 0.878000, valid loss: 96.637613
epoch: 3572, train precision: 0.998889, train loss: 10.252399, valid precision: 0.875400, valid loss: 95.728046
epoch: 3573, train precision: 0.999089, train loss: 10.164936, valid precision: 0.876600, valid loss: 96.610178
epoch: 3574, train precision: 0.998867, train loss: 10.239813, valid precision: 0.875200, valid loss: 98.365979
epoch: 3575, train precision: 0.998533, train loss: 10.357869, valid precision: 0.870200, valid loss: 100.078997
epoch: 3576, train precision: 0.999244, train loss: 10.208220, valid precision: 0.875800, valid loss: 95.326137
epoch: 3577, train precision: 0.998933, train loss: 10.224680, valid precision: 0.878200, valid loss: 94.866059
epoch: 3578, train precision: 0.998689, train loss: 10.301991, valid precision: 0.878200, valid loss: 95.807290
epoch: 3579, train precision: 0.999022, train loss: 10.266378, valid precision: 0.877200, valid loss: 97.779011
epoch: 3580, train precision: 0.998978, train loss: 10.230665, valid precision: 0.878400, valid loss: 94.583646
epoch: 3581, train precision: 0.998933, train loss: 10.230129, valid precision: 0.879000, valid loss: 94.983520
epoch: 3582, train precision: 0.998933, train loss: 10.265343, valid precision: 0.874200, valid loss: 98.050150
epoch: 3583, train precision: 0.999022, train loss: 10.209526, valid precision: 0.868800, valid loss: 100.064032
epoch: 3584, train precision: 0.999000, train loss: 10.238720, valid precision: 0.870800, valid loss: 99.280889
epoch: 3585, train precision: 0.998778, train loss: 10.337634, valid precision: 0.869200, valid loss: 98.622326
epoch: 3586, train precision: 0.999156, train loss: 10.211674, valid precision: 0.872200, valid loss: 99.992295
epoch: 3587, train precision: 0.998756, train loss: 10.322453, valid precision: 0.872800, valid loss: 98.279048
epoch: 3588, train precision: 0.999133, train loss: 10.179120, valid precision: 0.875800, valid loss: 98.811203
epoch: 3589, train precision: 0.998822, train loss: 10.292661, valid precision: 0.871600, valid loss: 100.690361
epoch: 3590, train precision: 0.999311, train loss: 10.147634, valid precision: 0.872800, valid loss: 98.932232
epoch: 3591, train precision: 0.999200, train loss: 10.190736, valid precision: 0.874000, valid loss: 96.994492
epoch: 3592, train precision: 0.999622, train loss: 10.102050, valid precision: 0.875200, valid loss: 95.703069
epoch: 3593, train precision: 0.999089, train loss: 10.202029, valid precision: 0.879400, valid loss: 97.235226
epoch: 3594, train precision: 0.998822, train loss: 10.287547, valid precision: 0.870800, valid loss: 100.175774
epoch: 3595, train precision: 0.999244, train loss: 10.182509, valid precision: 0.872400, valid loss: 98.855519
epoch: 3596, train precision: 0.999289, train loss: 10.184574, valid precision: 0.874600, valid loss: 97.607727
epoch: 3597, train precision: 0.999311, train loss: 10.118586, valid precision: 0.874000, valid loss: 100.858671
epoch: 3598, train precision: 0.999133, train loss: 10.178467, valid precision: 0.875600, valid loss: 98.007601
epoch: 3599, train precision: 0.999222, train loss: 10.185359, valid precision: 0.873000, valid loss: 97.768127
epoch: 3600, train precision: 0.999022, train loss: 10.192337, valid precision: 0.877000, valid loss: 98.343807
epoch: 3601, train precision: 0.998644, train loss: 10.265054, valid precision: 0.872400, valid loss: 98.339485
epoch: 3602, train precision: 0.999267, train loss: 10.160223, valid precision: 0.874600, valid loss: 97.322558
epoch: 3603, train precision: 0.999044, train loss: 10.239174, valid precision: 0.873600, valid loss: 96.910965
epoch: 3604, train precision: 0.999200, train loss: 10.156098, valid precision: 0.875800, valid loss: 97.076141
epoch: 3605, train precision: 0.999400, train loss: 10.135749, valid precision: 0.872200, valid loss: 99.461732
epoch: 3606, train precision: 0.999178, train loss: 10.161242, valid precision: 0.874600, valid loss: 98.051720
epoch: 3607, train precision: 0.999000, train loss: 10.236066, valid precision: 0.873800, valid loss: 101.649291
epoch: 3608, train precision: 0.998622, train loss: 10.345348, valid precision: 0.872600, valid loss: 99.507262
epoch: 3609, train precision: 0.998556, train loss: 10.302083, valid precision: 0.875800, valid loss: 99.978538
epoch: 3610, train precision: 0.999244, train loss: 10.175468, valid precision: 0.877800, valid loss: 97.052822
epoch: 3611, train precision: 0.999511, train loss: 10.072374, valid precision: 0.879000, valid loss: 95.080621
epoch: 3612, train precision: 0.999156, train loss: 10.213209, valid precision: 0.876200, valid loss: 96.975287
epoch: 3613, train precision: 0.999244, train loss: 10.147213, valid precision: 0.878000, valid loss: 97.014680
epoch: 3614, train precision: 0.999067, train loss: 10.212189, valid precision: 0.877000, valid loss: 95.595622
epoch: 3615, train precision: 0.998978, train loss: 10.187910, valid precision: 0.874400, valid loss: 99.247042
epoch: 3616, train precision: 0.999156, train loss: 10.178557, valid precision: 0.876400, valid loss: 99.167783
epoch: 3617, train precision: 0.999289, train loss: 10.082163, valid precision: 0.874800, valid loss: 98.718950
epoch: 3618, train precision: 0.999156, train loss: 10.174581, valid precision: 0.875800, valid loss: 97.990110
epoch: 3619, train precision: 0.999000, train loss: 10.195474, valid precision: 0.875200, valid loss: 97.722330
epoch: 3620, train precision: 0.998933, train loss: 10.193025, valid precision: 0.881800, valid loss: 96.874581
epoch: 3621, train precision: 0.998778, train loss: 10.263424, valid precision: 0.876000, valid loss: 98.279595
epoch: 3622, train precision: 0.998911, train loss: 10.246141, valid precision: 0.873600, valid loss: 99.027167
epoch: 3623, train precision: 0.999044, train loss: 10.239416, valid precision: 0.873600, valid loss: 97.579492
epoch: 3624, train precision: 0.998400, train loss: 10.401331, valid precision: 0.872800, valid loss: 97.536233
epoch: 3625, train precision: 0.999111, train loss: 10.186829, valid precision: 0.875400, valid loss: 98.707099
epoch: 3626, train precision: 0.999156, train loss: 10.255083, valid precision: 0.871200, valid loss: 99.824166
epoch: 3627, train precision: 0.999022, train loss: 10.154775, valid precision: 0.874200, valid loss: 99.904090
epoch: 3628, train precision: 0.999044, train loss: 10.180372, valid precision: 0.877400, valid loss: 99.523327
epoch: 3629, train precision: 0.998889, train loss: 10.230507, valid precision: 0.876000, valid loss: 97.676681
epoch: 3630, train precision: 0.999156, train loss: 10.217796, valid precision: 0.877600, valid loss: 96.581228
epoch: 3631, train precision: 0.999089, train loss: 10.201955, valid precision: 0.876000, valid loss: 96.161928
epoch: 3632, train precision: 0.999111, train loss: 10.214659, valid precision: 0.875000, valid loss: 99.307632
epoch: 3633, train precision: 0.998733, train loss: 10.249608, valid precision: 0.876200, valid loss: 96.294116
epoch: 3634, train precision: 0.999289, train loss: 10.127115, valid precision: 0.877400, valid loss: 99.196131
epoch: 3635, train precision: 0.999178, train loss: 10.183417, valid precision: 0.874400, valid loss: 99.050076
epoch: 3636, train precision: 0.998689, train loss: 10.330143, valid precision: 0.873600, valid loss: 97.842327
epoch: 3637, train precision: 0.999111, train loss: 10.148437, valid precision: 0.874200, valid loss: 102.801240
epoch: 3638, train precision: 0.999222, train loss: 10.145787, valid precision: 0.876800, valid loss: 99.507556
epoch: 3639, train precision: 0.999244, train loss: 10.117348, valid precision: 0.874200, valid loss: 100.929639
epoch: 3640, train precision: 0.998822, train loss: 10.332366, valid precision: 0.871600, valid loss: 99.163911
epoch: 3641, train precision: 0.998622, train loss: 10.322608, valid precision: 0.873800, valid loss: 99.294305
epoch: 3642, train precision: 0.998978, train loss: 10.236941, valid precision: 0.874200, valid loss: 99.500824
epoch: 3643, train precision: 0.999022, train loss: 10.226388, valid precision: 0.875400, valid loss: 100.018368
epoch: 3644, train precision: 0.998911, train loss: 10.266406, valid precision: 0.881200, valid loss: 98.302868
epoch: 3645, train precision: 0.999267, train loss: 10.161428, valid precision: 0.878800, valid loss: 99.407302
epoch: 3646, train precision: 0.999133, train loss: 10.214446, valid precision: 0.874200, valid loss: 100.974868
epoch: 3647, train precision: 0.998733, train loss: 10.285661, valid precision: 0.876800, valid loss: 99.317845
epoch: 3648, train precision: 0.999356, train loss: 10.079148, valid precision: 0.876400, valid loss: 98.135703
epoch: 3649, train precision: 0.998778, train loss: 10.277054, valid precision: 0.876200, valid loss: 97.897644
epoch: 3650, train precision: 0.999067, train loss: 10.201329, valid precision: 0.876800, valid loss: 98.493290
epoch: 3651, train precision: 0.999267, train loss: 10.202128, valid precision: 0.877600, valid loss: 97.457407
epoch: 3652, train precision: 0.999333, train loss: 10.125527, valid precision: 0.879600, valid loss: 96.740225
epoch: 3653, train precision: 0.998911, train loss: 10.296207, valid precision: 0.877200, valid loss: 98.887475
epoch: 3654, train precision: 0.999111, train loss: 10.183368, valid precision: 0.878600, valid loss: 98.742465
epoch: 3655, train precision: 0.999200, train loss: 10.139105, valid precision: 0.878600, valid loss: 97.813394
epoch: 3656, train precision: 0.998600, train loss: 10.312138, valid precision: 0.878800, valid loss: 99.665535
epoch: 3657, train precision: 0.999133, train loss: 10.234483, valid precision: 0.880000, valid loss: 100.535858
epoch: 3658, train precision: 0.998911, train loss: 10.213087, valid precision: 0.876600, valid loss: 99.650578
epoch: 3659, train precision: 0.999000, train loss: 10.217974, valid precision: 0.876400, valid loss: 96.351548
epoch: 3660, train precision: 0.999178, train loss: 10.154891, valid precision: 0.877200, valid loss: 95.626103
epoch: 3661, train precision: 0.999200, train loss: 10.164060, valid precision: 0.880000, valid loss: 97.414066
epoch: 3662, train precision: 0.999156, train loss: 10.197357, valid precision: 0.875600, valid loss: 97.465850
epoch: 3663, train precision: 0.998733, train loss: 10.369965, valid precision: 0.878000, valid loss: 98.312552
epoch: 3664, train precision: 0.998978, train loss: 10.173481, valid precision: 0.875000, valid loss: 98.209335
epoch: 3665, train precision: 0.999111, train loss: 10.220500, valid precision: 0.875800, valid loss: 98.263954
epoch: 3666, train precision: 0.999289, train loss: 10.167100, valid precision: 0.886200, valid loss: 98.972803
epoch: 3667, train precision: 0.999356, train loss: 10.127398, valid precision: 0.876000, valid loss: 96.052852
epoch: 3668, train precision: 0.999267, train loss: 10.183728, valid precision: 0.879000, valid loss: 95.528311
epoch: 3669, train precision: 0.999333, train loss: 10.162528, valid precision: 0.876400, valid loss: 99.108458
epoch: 3670, train precision: 0.998956, train loss: 10.201251, valid precision: 0.876000, valid loss: 97.701169
epoch: 3671, train precision: 0.999133, train loss: 10.203465, valid precision: 0.878600, valid loss: 97.694743
epoch: 3672, train precision: 0.999156, train loss: 10.138897, valid precision: 0.876800, valid loss: 98.672153
epoch: 3673, train precision: 0.998978, train loss: 10.242677, valid precision: 0.874400, valid loss: 97.466880
epoch: 3674, train precision: 0.999333, train loss: 10.130870, valid precision: 0.879000, valid loss: 96.600788
epoch: 3675, train precision: 0.999133, train loss: 10.206559, valid precision: 0.877800, valid loss: 99.224256
epoch: 3676, train precision: 0.999178, train loss: 10.168841, valid precision: 0.875600, valid loss: 98.709559
epoch: 3677, train precision: 0.999378, train loss: 10.120631, valid precision: 0.877800, valid loss: 98.172962
epoch: 3678, train precision: 0.999444, train loss: 10.148922, valid precision: 0.873200, valid loss: 100.246677
epoch: 3679, train precision: 0.999000, train loss: 10.250775, valid precision: 0.877400, valid loss: 97.056803
epoch: 3680, train precision: 0.998889, train loss: 10.247438, valid precision: 0.872800, valid loss: 100.615644
epoch: 3681, train precision: 0.999000, train loss: 10.283914, valid precision: 0.880400, valid loss: 96.424200
epoch: 3682, train precision: 0.999111, train loss: 10.180604, valid precision: 0.876600, valid loss: 97.614907
epoch: 3683, train precision: 0.999244, train loss: 10.189380, valid precision: 0.878400, valid loss: 98.014640
epoch: 3684, train precision: 0.999067, train loss: 10.237366, valid precision: 0.875400, valid loss: 95.829379
epoch: 3685, train precision: 0.999311, train loss: 10.187634, valid precision: 0.879400, valid loss: 93.763540
epoch: 3686, train precision: 0.999044, train loss: 10.219762, valid precision: 0.876000, valid loss: 96.944996
epoch: 3687, train precision: 0.999067, train loss: 10.156538, valid precision: 0.874000, valid loss: 97.850774
epoch: 3688, train precision: 0.999111, train loss: 10.195972, valid precision: 0.874800, valid loss: 94.768235
epoch: 3689, train precision: 0.999022, train loss: 10.215100, valid precision: 0.875800, valid loss: 96.241882
epoch: 3690, train precision: 0.998689, train loss: 10.375560, valid precision: 0.872600, valid loss: 95.723585
epoch: 3691, train precision: 0.999178, train loss: 10.189548, valid precision: 0.878200, valid loss: 97.409032
epoch: 3692, train precision: 0.998867, train loss: 10.278968, valid precision: 0.876800, valid loss: 98.290216
epoch: 3693, train precision: 0.999156, train loss: 10.253050, valid precision: 0.876400, valid loss: 96.810042
epoch: 3694, train precision: 0.998756, train loss: 10.341207, valid precision: 0.876600, valid loss: 96.929249
epoch: 3695, train precision: 0.999000, train loss: 10.206345, valid precision: 0.877000, valid loss: 96.106045
epoch: 3696, train precision: 0.999244, train loss: 10.160634, valid precision: 0.874600, valid loss: 95.879346
epoch: 3697, train precision: 0.999022, train loss: 10.261237, valid precision: 0.877600, valid loss: 94.220705
epoch: 3698, train precision: 0.998867, train loss: 10.274509, valid precision: 0.872400, valid loss: 96.446430
epoch: 3699, train precision: 0.999244, train loss: 10.193009, valid precision: 0.873400, valid loss: 96.893631
epoch: 3700, train precision: 0.998978, train loss: 10.240360, valid precision: 0.870400, valid loss: 98.357816
epoch: 3701, train precision: 0.999267, train loss: 10.194832, valid precision: 0.874800, valid loss: 95.967503
epoch: 3702, train precision: 0.999133, train loss: 10.147692, valid precision: 0.875200, valid loss: 94.962455
epoch: 3703, train precision: 0.999111, train loss: 10.183009, valid precision: 0.875000, valid loss: 95.167811
epoch: 3704, train precision: 0.999400, train loss: 10.098770, valid precision: 0.874800, valid loss: 95.475810
epoch: 3705, train precision: 0.998711, train loss: 10.264323, valid precision: 0.871600, valid loss: 96.656477
epoch: 3706, train precision: 0.998867, train loss: 10.234776, valid precision: 0.872000, valid loss: 96.365733
epoch: 3707, train precision: 0.999022, train loss: 10.241911, valid precision: 0.880800, valid loss: 93.414780
epoch: 3708, train precision: 0.999111, train loss: 10.163951, valid precision: 0.878200, valid loss: 97.105830
epoch: 3709, train precision: 0.999267, train loss: 10.123903, valid precision: 0.875400, valid loss: 101.063625
epoch: 3710, train precision: 0.998933, train loss: 10.223819, valid precision: 0.874600, valid loss: 99.576720
epoch: 3711, train precision: 0.998933, train loss: 10.214458, valid precision: 0.877000, valid loss: 98.773434
epoch: 3712, train precision: 0.999178, train loss: 10.201757, valid precision: 0.878600, valid loss: 98.144845
epoch: 3713, train precision: 0.999133, train loss: 10.180481, valid precision: 0.877600, valid loss: 98.100378
epoch: 3714, train precision: 0.999022, train loss: 10.189233, valid precision: 0.873600, valid loss: 99.399071
epoch: 3715, train precision: 0.999178, train loss: 10.187647, valid precision: 0.873600, valid loss: 99.438555
epoch: 3716, train precision: 0.999156, train loss: 10.131660, valid precision: 0.872800, valid loss: 97.964051
epoch: 3717, train precision: 0.998556, train loss: 10.414376, valid precision: 0.876200, valid loss: 97.720695
epoch: 3718, train precision: 0.998778, train loss: 10.292315, valid precision: 0.874000, valid loss: 98.155044
epoch: 3719, train precision: 0.999267, train loss: 10.158530, valid precision: 0.874800, valid loss: 98.887290
epoch: 3720, train precision: 0.999067, train loss: 10.216718, valid precision: 0.873200, valid loss: 99.646101
epoch: 3721, train precision: 0.999333, train loss: 10.100642, valid precision: 0.877800, valid loss: 95.266738
epoch: 3722, train precision: 0.999178, train loss: 10.169362, valid precision: 0.872000, valid loss: 97.071533
epoch: 3723, train precision: 0.998867, train loss: 10.320734, valid precision: 0.875400, valid loss: 95.808636
epoch: 3724, train precision: 0.999222, train loss: 10.168498, valid precision: 0.876200, valid loss: 96.461745
epoch: 3725, train precision: 0.999067, train loss: 10.175999, valid precision: 0.877600, valid loss: 98.631818
epoch: 3726, train precision: 0.999089, train loss: 10.162531, valid precision: 0.874200, valid loss: 99.933646
epoch: 3727, train precision: 0.998356, train loss: 10.412641, valid precision: 0.871400, valid loss: 102.496104
epoch: 3728, train precision: 0.999044, train loss: 10.186544, valid precision: 0.877400, valid loss: 99.441849
epoch: 3729, train precision: 0.998911, train loss: 10.169603, valid precision: 0.872800, valid loss: 99.233463
epoch: 3730, train precision: 0.998822, train loss: 10.307548, valid precision: 0.874800, valid loss: 98.254400
epoch: 3731, train precision: 0.999156, train loss: 10.181249, valid precision: 0.876400, valid loss: 98.070094
epoch: 3732, train precision: 0.999244, train loss: 10.164776, valid precision: 0.871600, valid loss: 98.999284
epoch: 3733, train precision: 0.999222, train loss: 10.154769, valid precision: 0.871200, valid loss: 99.174686
epoch: 3734, train precision: 0.999044, train loss: 10.249149, valid precision: 0.873600, valid loss: 97.306650
epoch: 3735, train precision: 0.999244, train loss: 10.116579, valid precision: 0.876000, valid loss: 97.817387
epoch: 3736, train precision: 0.998733, train loss: 10.300533, valid precision: 0.878200, valid loss: 96.341997
epoch: 3737, train precision: 0.998911, train loss: 10.216323, valid precision: 0.870600, valid loss: 98.029266
epoch: 3738, train precision: 0.998867, train loss: 10.314335, valid precision: 0.870200, valid loss: 100.637836
epoch: 3739, train precision: 0.999178, train loss: 10.243401, valid precision: 0.876200, valid loss: 97.456524
epoch: 3740, train precision: 0.998733, train loss: 10.276226, valid precision: 0.875200, valid loss: 97.790676
epoch: 3741, train precision: 0.998822, train loss: 10.302528, valid precision: 0.874200, valid loss: 99.348300
epoch: 3742, train precision: 0.999378, train loss: 10.119487, valid precision: 0.879800, valid loss: 96.477187
epoch: 3743, train precision: 0.999000, train loss: 10.269990, valid precision: 0.875400, valid loss: 97.950815
epoch: 3744, train precision: 0.998956, train loss: 10.247392, valid precision: 0.876600, valid loss: 97.376704
epoch: 3745, train precision: 0.999267, train loss: 10.173700, valid precision: 0.877400, valid loss: 97.665998
epoch: 3746, train precision: 0.999200, train loss: 10.211342, valid precision: 0.876400, valid loss: 96.833582
epoch: 3747, train precision: 0.999244, train loss: 10.121267, valid precision: 0.874200, valid loss: 99.157564
epoch: 3748, train precision: 0.998844, train loss: 10.301724, valid precision: 0.878400, valid loss: 99.262646
epoch: 3749, train precision: 0.999133, train loss: 10.184850, valid precision: 0.873400, valid loss: 98.575099
epoch: 3750, train precision: 0.999267, train loss: 10.171868, valid precision: 0.878200, valid loss: 98.330213
epoch: 3751, train precision: 0.999178, train loss: 10.166207, valid precision: 0.876400, valid loss: 98.347827
epoch: 3752, train precision: 0.999311, train loss: 10.112459, valid precision: 0.875400, valid loss: 98.285616
epoch: 3753, train precision: 0.999156, train loss: 10.158228, valid precision: 0.876200, valid loss: 98.480128
epoch: 3754, train precision: 0.998889, train loss: 10.280476, valid precision: 0.872200, valid loss: 100.443759
epoch: 3755, train precision: 0.999178, train loss: 10.156472, valid precision: 0.876400, valid loss: 98.489599
epoch: 3756, train precision: 0.999378, train loss: 10.052442, valid precision: 0.878000, valid loss: 97.944665
epoch: 3757, train precision: 0.999333, train loss: 10.190750, valid precision: 0.873000, valid loss: 100.499421
epoch: 3758, train precision: 0.998800, train loss: 10.274479, valid precision: 0.873800, valid loss: 96.137829
epoch: 3759, train precision: 0.999200, train loss: 10.164886, valid precision: 0.878200, valid loss: 96.892942
epoch: 3760, train precision: 0.999044, train loss: 10.165839, valid precision: 0.881200, valid loss: 95.697424
epoch: 3761, train precision: 0.999178, train loss: 10.157889, valid precision: 0.872000, valid loss: 98.605428
epoch: 3762, train precision: 0.999133, train loss: 10.145795, valid precision: 0.875400, valid loss: 96.314428
epoch: 3763, train precision: 0.999222, train loss: 10.189779, valid precision: 0.873200, valid loss: 96.210641
epoch: 3764, train precision: 0.999156, train loss: 10.199002, valid precision: 0.874200, valid loss: 96.746759
epoch: 3765, train precision: 0.998956, train loss: 10.255295, valid precision: 0.871200, valid loss: 97.446703
epoch: 3766, train precision: 0.998756, train loss: 10.324166, valid precision: 0.873600, valid loss: 95.026048
epoch: 3767, train precision: 0.999378, train loss: 10.103319, valid precision: 0.878200, valid loss: 94.273221
epoch: 3768, train precision: 0.999089, train loss: 10.174430, valid precision: 0.877600, valid loss: 97.264532
epoch: 3769, train precision: 0.998956, train loss: 10.242819, valid precision: 0.879400, valid loss: 94.106877
epoch: 3770, train precision: 0.999178, train loss: 10.187153, valid precision: 0.881200, valid loss: 95.672369
epoch: 3771, train precision: 0.999200, train loss: 10.092247, valid precision: 0.874400, valid loss: 99.092802
epoch: 3772, train precision: 0.999133, train loss: 10.190491, valid precision: 0.877200, valid loss: 98.513434
epoch: 3773, train precision: 0.998822, train loss: 10.287292, valid precision: 0.874800, valid loss: 96.896916
epoch: 3774, train precision: 0.999200, train loss: 10.120528, valid precision: 0.874800, valid loss: 96.155120
epoch: 3775, train precision: 0.998933, train loss: 10.175545, valid precision: 0.877800, valid loss: 96.205588
epoch: 3776, train precision: 0.999000, train loss: 10.207038, valid precision: 0.873400, valid loss: 100.342111
epoch: 3777, train precision: 0.998800, train loss: 10.263937, valid precision: 0.873800, valid loss: 99.478680
epoch: 3778, train precision: 0.999244, train loss: 10.169333, valid precision: 0.875000, valid loss: 98.242408
epoch: 3779, train precision: 0.999111, train loss: 10.208186, valid precision: 0.877200, valid loss: 96.213981
epoch: 3780, train precision: 0.999089, train loss: 10.218463, valid precision: 0.875000, valid loss: 98.108771
epoch: 3781, train precision: 0.999044, train loss: 10.172226, valid precision: 0.878000, valid loss: 95.699934
epoch: 3782, train precision: 0.999044, train loss: 10.152171, valid precision: 0.877200, valid loss: 97.344837
epoch: 3783, train precision: 0.999044, train loss: 10.154137, valid precision: 0.877000, valid loss: 99.409983
epoch: 3784, train precision: 0.999289, train loss: 10.134112, valid precision: 0.878000, valid loss: 100.034614
epoch: 3785, train precision: 0.998889, train loss: 10.216014, valid precision: 0.872600, valid loss: 101.204031
epoch: 3786, train precision: 0.999089, train loss: 10.210260, valid precision: 0.877600, valid loss: 96.094363
epoch: 3787, train precision: 0.998889, train loss: 10.200748, valid precision: 0.876200, valid loss: 98.024695
epoch: 3788, train precision: 0.998778, train loss: 10.239903, valid precision: 0.876400, valid loss: 98.424279
epoch: 3789, train precision: 0.999311, train loss: 10.140775, valid precision: 0.876000, valid loss: 95.787396
epoch: 3790, train precision: 0.999133, train loss: 10.132007, valid precision: 0.875600, valid loss: 97.344535
epoch: 3791, train precision: 0.999133, train loss: 10.164869, valid precision: 0.875000, valid loss: 95.284816
epoch: 3792, train precision: 0.998867, train loss: 10.220111, valid precision: 0.874600, valid loss: 98.197912
epoch: 3793, train precision: 0.998933, train loss: 10.247311, valid precision: 0.874000, valid loss: 95.375504
epoch: 3794, train precision: 0.998978, train loss: 10.187997, valid precision: 0.873400, valid loss: 94.528072
epoch: 3795, train precision: 0.998933, train loss: 10.187062, valid precision: 0.875000, valid loss: 97.091103
epoch: 3796, train precision: 0.999044, train loss: 10.187316, valid precision: 0.875400, valid loss: 97.920243
epoch: 3797, train precision: 0.999156, train loss: 10.154358, valid precision: 0.872800, valid loss: 99.396819
epoch: 3798, train precision: 0.999200, train loss: 10.099109, valid precision: 0.874000, valid loss: 97.817093
epoch: 3799, train precision: 0.999044, train loss: 10.198606, valid precision: 0.875400, valid loss: 101.596338
epoch: 3800, train precision: 0.998956, train loss: 10.181867, valid precision: 0.874800, valid loss: 97.136736
epoch: 3801, train precision: 0.999089, train loss: 10.189139, valid precision: 0.877000, valid loss: 95.508140
epoch: 3802, train precision: 0.998956, train loss: 10.211557, valid precision: 0.872600, valid loss: 98.820100
epoch: 3803, train precision: 0.998622, train loss: 10.272485, valid precision: 0.870000, valid loss: 101.347657
epoch: 3804, train precision: 0.998867, train loss: 10.286175, valid precision: 0.873200, valid loss: 99.018200
epoch: 3805, train precision: 0.999022, train loss: 10.159250, valid precision: 0.875400, valid loss: 100.333457
epoch: 3806, train precision: 0.999089, train loss: 10.151139, valid precision: 0.870200, valid loss: 99.040392
epoch: 3807, train precision: 0.999133, train loss: 10.182531, valid precision: 0.871600, valid loss: 98.583677
epoch: 3808, train precision: 0.999044, train loss: 10.178021, valid precision: 0.874000, valid loss: 98.049646
epoch: 3809, train precision: 0.999156, train loss: 10.147195, valid precision: 0.872000, valid loss: 99.062807
epoch: 3810, train precision: 0.999378, train loss: 10.106650, valid precision: 0.869800, valid loss: 98.764753
epoch: 3811, train precision: 0.999089, train loss: 10.230283, valid precision: 0.867400, valid loss: 102.068389
epoch: 3812, train precision: 0.998844, train loss: 10.172760, valid precision: 0.869400, valid loss: 101.600939
epoch: 3813, train precision: 0.999089, train loss: 10.204710, valid precision: 0.870000, valid loss: 101.149307
epoch: 3814, train precision: 0.999178, train loss: 10.173851, valid precision: 0.872200, valid loss: 101.118636
epoch: 3815, train precision: 0.999022, train loss: 10.228820, valid precision: 0.871600, valid loss: 100.186086
epoch: 3816, train precision: 0.999556, train loss: 9.999754, valid precision: 0.872400, valid loss: 100.410237
epoch: 3817, train precision: 0.999178, train loss: 10.142666, valid precision: 0.874000, valid loss: 99.969993
epoch: 3818, train precision: 0.999178, train loss: 10.092918, valid precision: 0.874800, valid loss: 100.611308
epoch: 3819, train precision: 0.998911, train loss: 10.235258, valid precision: 0.873200, valid loss: 99.140919
epoch: 3820, train precision: 0.999044, train loss: 10.171288, valid precision: 0.872800, valid loss: 100.738745
epoch: 3821, train precision: 0.998978, train loss: 10.124569, valid precision: 0.873600, valid loss: 101.814255
epoch: 3822, train precision: 0.999200, train loss: 10.136279, valid precision: 0.873000, valid loss: 100.962512
epoch: 3823, train precision: 0.999044, train loss: 10.181429, valid precision: 0.872000, valid loss: 102.876282
epoch: 3824, train precision: 0.998578, train loss: 10.324819, valid precision: 0.870000, valid loss: 98.851513
epoch: 3825, train precision: 0.998889, train loss: 10.276192, valid precision: 0.871400, valid loss: 100.412963
epoch: 3826, train precision: 0.999133, train loss: 10.169524, valid precision: 0.870600, valid loss: 96.830637
epoch: 3827, train precision: 0.999089, train loss: 10.212433, valid precision: 0.874200, valid loss: 96.828526
epoch: 3828, train precision: 0.999111, train loss: 10.168648, valid precision: 0.872000, valid loss: 97.387461
epoch: 3829, train precision: 0.999311, train loss: 10.101309, valid precision: 0.871200, valid loss: 98.061226
epoch: 3830, train precision: 0.999133, train loss: 10.184612, valid precision: 0.873800, valid loss: 97.568859
epoch: 3831, train precision: 0.999222, train loss: 10.191428, valid precision: 0.875600, valid loss: 95.889830
epoch: 3832, train precision: 0.999244, train loss: 10.157761, valid precision: 0.871200, valid loss: 93.778193
epoch: 3833, train precision: 0.999222, train loss: 10.155013, valid precision: 0.876600, valid loss: 98.257367
epoch: 3834, train precision: 0.999200, train loss: 10.119882, valid precision: 0.875000, valid loss: 96.686534
epoch: 3835, train precision: 0.999000, train loss: 10.212800, valid precision: 0.875400, valid loss: 97.445496
epoch: 3836, train precision: 0.998956, train loss: 10.220962, valid precision: 0.871000, valid loss: 98.978617
epoch: 3837, train precision: 0.999000, train loss: 10.260180, valid precision: 0.877200, valid loss: 97.936509
epoch: 3838, train precision: 0.999178, train loss: 10.161688, valid precision: 0.873800, valid loss: 96.648537
epoch: 3839, train precision: 0.999200, train loss: 10.182620, valid precision: 0.876600, valid loss: 96.524364
epoch: 3840, train precision: 0.999178, train loss: 10.190069, valid precision: 0.873800, valid loss: 96.877923
epoch: 3841, train precision: 0.999089, train loss: 10.128503, valid precision: 0.879200, valid loss: 98.629514
epoch: 3842, train precision: 0.999356, train loss: 10.064027, valid precision: 0.876200, valid loss: 99.657165
epoch: 3843, train precision: 0.999133, train loss: 10.157232, valid precision: 0.874200, valid loss: 100.915891
epoch: 3844, train precision: 0.999089, train loss: 10.173944, valid precision: 0.875200, valid loss: 99.955704
epoch: 3845, train precision: 0.999089, train loss: 10.156325, valid precision: 0.875800, valid loss: 99.079665
epoch: 3846, train precision: 0.999111, train loss: 10.190276, valid precision: 0.871400, valid loss: 99.882489
epoch: 3847, train precision: 0.998533, train loss: 10.350868, valid precision: 0.876600, valid loss: 100.165673
epoch: 3848, train precision: 0.999178, train loss: 10.151167, valid precision: 0.874400, valid loss: 101.147614
epoch: 3849, train precision: 0.998956, train loss: 10.212092, valid precision: 0.872800, valid loss: 99.187187
epoch: 3850, train precision: 0.999111, train loss: 10.145709, valid precision: 0.875200, valid loss: 98.883877
epoch: 3851, train precision: 0.998956, train loss: 10.205238, valid precision: 0.873800, valid loss: 100.623983
epoch: 3852, train precision: 0.999244, train loss: 10.140687, valid precision: 0.875200, valid loss: 100.678529
epoch: 3853, train precision: 0.999178, train loss: 10.123377, valid precision: 0.871200, valid loss: 100.466440
epoch: 3854, train precision: 0.999067, train loss: 10.191679, valid precision: 0.872400, valid loss: 99.019573
epoch: 3855, train precision: 0.999022, train loss: 10.183629, valid precision: 0.873000, valid loss: 100.865376
epoch: 3856, train precision: 0.998867, train loss: 10.228466, valid precision: 0.871400, valid loss: 102.741941
epoch: 3857, train precision: 0.999289, train loss: 10.161254, valid precision: 0.874400, valid loss: 98.151041
epoch: 3858, train precision: 0.999267, train loss: 10.105025, valid precision: 0.876000, valid loss: 99.969079
epoch: 3859, train precision: 0.999111, train loss: 10.175915, valid precision: 0.873800, valid loss: 101.266056
epoch: 3860, train precision: 0.998844, train loss: 10.203757, valid precision: 0.870000, valid loss: 103.366583
epoch: 3861, train precision: 0.999044, train loss: 10.171824, valid precision: 0.872800, valid loss: 100.826437
epoch: 3862, train precision: 0.999000, train loss: 10.227532, valid precision: 0.871200, valid loss: 102.778778
epoch: 3863, train precision: 0.999356, train loss: 10.100077, valid precision: 0.875000, valid loss: 103.673925
epoch: 3864, train precision: 0.999000, train loss: 10.165967, valid precision: 0.877400, valid loss: 98.978522
epoch: 3865, train precision: 0.999378, train loss: 10.058208, valid precision: 0.871800, valid loss: 102.260485
epoch: 3866, train precision: 0.998889, train loss: 10.250824, valid precision: 0.869600, valid loss: 104.294660
epoch: 3867, train precision: 0.999044, train loss: 10.189028, valid precision: 0.868800, valid loss: 99.967331
epoch: 3868, train precision: 0.999044, train loss: 10.183287, valid precision: 0.872600, valid loss: 102.611679
epoch: 3869, train precision: 0.999000, train loss: 10.179757, valid precision: 0.876400, valid loss: 101.900170
epoch: 3870, train precision: 0.999333, train loss: 10.101040, valid precision: 0.871600, valid loss: 101.752900
epoch: 3871, train precision: 0.998867, train loss: 10.230040, valid precision: 0.869600, valid loss: 102.923285
epoch: 3872, train precision: 0.998667, train loss: 10.253975, valid precision: 0.875200, valid loss: 101.434265
epoch: 3873, train precision: 0.999178, train loss: 10.113046, valid precision: 0.874000, valid loss: 103.222961
epoch: 3874, train precision: 0.999244, train loss: 10.139037, valid precision: 0.871400, valid loss: 104.157362
epoch: 3875, train precision: 0.999089, train loss: 10.136825, valid precision: 0.875200, valid loss: 102.274514
epoch: 3876, train precision: 0.998844, train loss: 10.261559, valid precision: 0.872200, valid loss: 101.861669
epoch: 3877, train precision: 0.999378, train loss: 10.022585, valid precision: 0.871400, valid loss: 100.010475
epoch: 3878, train precision: 0.998689, train loss: 10.299717, valid precision: 0.870200, valid loss: 101.765641
epoch: 3879, train precision: 0.999156, train loss: 10.121676, valid precision: 0.872600, valid loss: 100.979829
epoch: 3880, train precision: 0.999111, train loss: 10.152097, valid precision: 0.874400, valid loss: 100.301736
epoch: 3881, train precision: 0.999289, train loss: 10.106951, valid precision: 0.872400, valid loss: 101.597627
epoch: 3882, train precision: 0.999111, train loss: 10.135192, valid precision: 0.870200, valid loss: 101.975653
epoch: 3883, train precision: 0.999067, train loss: 10.185007, valid precision: 0.868000, valid loss: 101.363210
epoch: 3884, train precision: 0.998667, train loss: 10.293976, valid precision: 0.872200, valid loss: 100.505899
epoch: 3885, train precision: 0.998911, train loss: 10.240109, valid precision: 0.873600, valid loss: 101.097724
epoch: 3886, train precision: 0.999067, train loss: 10.167945, valid precision: 0.875600, valid loss: 99.537181
epoch: 3887, train precision: 0.999289, train loss: 10.094300, valid precision: 0.873800, valid loss: 99.557399
epoch: 3888, train precision: 0.999067, train loss: 10.221257, valid precision: 0.871400, valid loss: 98.769207
epoch: 3889, train precision: 0.998867, train loss: 10.172573, valid precision: 0.870600, valid loss: 97.979814
epoch: 3890, train precision: 0.999067, train loss: 10.188039, valid precision: 0.871800, valid loss: 97.654901
epoch: 3891, train precision: 0.999156, train loss: 10.148112, valid precision: 0.872200, valid loss: 100.862553
epoch: 3892, train precision: 0.999178, train loss: 10.144969, valid precision: 0.872400, valid loss: 99.661562
epoch: 3893, train precision: 0.998800, train loss: 10.289922, valid precision: 0.873200, valid loss: 97.974659
epoch: 3894, train precision: 0.999356, train loss: 10.098237, valid precision: 0.874200, valid loss: 97.860995
epoch: 3895, train precision: 0.999311, train loss: 10.081778, valid precision: 0.875000, valid loss: 97.459730
epoch: 3896, train precision: 0.998911, train loss: 10.241906, valid precision: 0.874800, valid loss: 99.112252
epoch: 3897, train precision: 0.999311, train loss: 10.092805, valid precision: 0.877000, valid loss: 98.324823
epoch: 3898, train precision: 0.999267, train loss: 10.089464, valid precision: 0.874200, valid loss: 97.690901
epoch: 3899, train precision: 0.999111, train loss: 10.175671, valid precision: 0.874200, valid loss: 100.889508
epoch: 3900, train precision: 0.999267, train loss: 10.094923, valid precision: 0.872000, valid loss: 96.611879
epoch: 3901, train precision: 0.999289, train loss: 10.100671, valid precision: 0.872600, valid loss: 99.631209
epoch: 3902, train precision: 0.998422, train loss: 10.316430, valid precision: 0.875000, valid loss: 102.283513
epoch: 3903, train precision: 0.999289, train loss: 10.144644, valid precision: 0.874400, valid loss: 97.901007
epoch: 3904, train precision: 0.999289, train loss: 10.119640, valid precision: 0.873000, valid loss: 97.902450
epoch: 3905, train precision: 0.999267, train loss: 10.051103, valid precision: 0.876200, valid loss: 98.574432
epoch: 3906, train precision: 0.999044, train loss: 10.154274, valid precision: 0.876600, valid loss: 99.572107
epoch: 3907, train precision: 0.998778, train loss: 10.310353, valid precision: 0.874400, valid loss: 98.774753
epoch: 3908, train precision: 0.999133, train loss: 10.133594, valid precision: 0.876400, valid loss: 97.205291
epoch: 3909, train precision: 0.998556, train loss: 10.297452, valid precision: 0.873000, valid loss: 99.364221
epoch: 3910, train precision: 0.999289, train loss: 10.093874, valid precision: 0.873600, valid loss: 99.930420
epoch: 3911, train precision: 0.998911, train loss: 10.183843, valid precision: 0.872000, valid loss: 100.390360
epoch: 3912, train precision: 0.998933, train loss: 10.214671, valid precision: 0.868800, valid loss: 101.601019
epoch: 3913, train precision: 0.999022, train loss: 10.158943, valid precision: 0.877400, valid loss: 100.050881
epoch: 3914, train precision: 0.999289, train loss: 10.108801, valid precision: 0.871200, valid loss: 101.566101
epoch: 3915, train precision: 0.999244, train loss: 10.133693, valid precision: 0.871200, valid loss: 99.619707
epoch: 3916, train precision: 0.999000, train loss: 10.205430, valid precision: 0.878200, valid loss: 100.786130
epoch: 3917, train precision: 0.998800, train loss: 10.218868, valid precision: 0.874400, valid loss: 100.425621
epoch: 3918, train precision: 0.999133, train loss: 10.130435, valid precision: 0.876000, valid loss: 96.276735
epoch: 3919, train precision: 0.998956, train loss: 10.188080, valid precision: 0.877800, valid loss: 96.628388
epoch: 3920, train precision: 0.999133, train loss: 10.155229, valid precision: 0.871400, valid loss: 99.707503
epoch: 3921, train precision: 0.998956, train loss: 10.203544, valid precision: 0.876400, valid loss: 98.695587
epoch: 3922, train precision: 0.998933, train loss: 10.208033, valid precision: 0.876200, valid loss: 101.224188
epoch: 3923, train precision: 0.999378, train loss: 10.073338, valid precision: 0.881400, valid loss: 100.250345
epoch: 3924, train precision: 0.999311, train loss: 10.051762, valid precision: 0.873800, valid loss: 99.885511
epoch: 3925, train precision: 0.999222, train loss: 10.109617, valid precision: 0.874800, valid loss: 99.240436
epoch: 3926, train precision: 0.999289, train loss: 10.105969, valid precision: 0.873600, valid loss: 97.772229
epoch: 3927, train precision: 0.999022, train loss: 10.149354, valid precision: 0.874800, valid loss: 99.016800
epoch: 3928, train precision: 0.999111, train loss: 10.145116, valid precision: 0.875400, valid loss: 97.063574
epoch: 3929, train precision: 0.999089, train loss: 10.149958, valid precision: 0.878000, valid loss: 96.646389
epoch: 3930, train precision: 0.999111, train loss: 10.116093, valid precision: 0.875200, valid loss: 99.904147
epoch: 3931, train precision: 0.999400, train loss: 10.099164, valid precision: 0.876000, valid loss: 98.464535
epoch: 3932, train precision: 0.999400, train loss: 10.073435, valid precision: 0.877200, valid loss: 99.025897
epoch: 3933, train precision: 0.999044, train loss: 10.160026, valid precision: 0.873400, valid loss: 100.071656
epoch: 3934, train precision: 0.999333, train loss: 10.039162, valid precision: 0.875400, valid loss: 100.468331
epoch: 3935, train precision: 0.999067, train loss: 10.140226, valid precision: 0.872000, valid loss: 99.591098
epoch: 3936, train precision: 0.998956, train loss: 10.182431, valid precision: 0.870600, valid loss: 101.206415
epoch: 3937, train precision: 0.999333, train loss: 10.045456, valid precision: 0.875000, valid loss: 100.190856
epoch: 3938, train precision: 0.999267, train loss: 10.132782, valid precision: 0.874000, valid loss: 98.989596
epoch: 3939, train precision: 0.999156, train loss: 10.116615, valid precision: 0.875000, valid loss: 99.999858
epoch: 3940, train precision: 0.999289, train loss: 10.095294, valid precision: 0.874200, valid loss: 98.940413
epoch: 3941, train precision: 0.999067, train loss: 10.140318, valid precision: 0.868600, valid loss: 102.633766
epoch: 3942, train precision: 0.998711, train loss: 10.239668, valid precision: 0.867000, valid loss: 103.955669
epoch: 3943, train precision: 0.999089, train loss: 10.138441, valid precision: 0.875600, valid loss: 99.997500
epoch: 3944, train precision: 0.999089, train loss: 10.142917, valid precision: 0.873000, valid loss: 100.236317
epoch: 3945, train precision: 0.998911, train loss: 10.151924, valid precision: 0.875000, valid loss: 100.384516
epoch: 3946, train precision: 0.999400, train loss: 10.044709, valid precision: 0.874000, valid loss: 99.852419
epoch: 3947, train precision: 0.999022, train loss: 10.139841, valid precision: 0.875600, valid loss: 100.583143
epoch: 3948, train precision: 0.998667, train loss: 10.233380, valid precision: 0.874600, valid loss: 102.644246
epoch: 3949, train precision: 0.998933, train loss: 10.236249, valid precision: 0.870000, valid loss: 98.986464
epoch: 3950, train precision: 0.999222, train loss: 10.039624, valid precision: 0.873200, valid loss: 101.128226
epoch: 3951, train precision: 0.998978, train loss: 10.165212, valid precision: 0.873800, valid loss: 100.943706
epoch: 3952, train precision: 0.999311, train loss: 10.085871, valid precision: 0.875400, valid loss: 100.999796
epoch: 3953, train precision: 0.999311, train loss: 10.091385, valid precision: 0.869400, valid loss: 101.573325
epoch: 3954, train precision: 0.998889, train loss: 10.181209, valid precision: 0.874000, valid loss: 101.415631
epoch: 3955, train precision: 0.998778, train loss: 10.270379, valid precision: 0.871200, valid loss: 101.722424
epoch: 3956, train precision: 0.998978, train loss: 10.144808, valid precision: 0.872400, valid loss: 101.954272
epoch: 3957, train precision: 0.999289, train loss: 10.155025, valid precision: 0.871200, valid loss: 100.132603
epoch: 3958, train precision: 0.999067, train loss: 10.126867, valid precision: 0.877400, valid loss: 101.024889
epoch: 3959, train precision: 0.998800, train loss: 10.178459, valid precision: 0.874400, valid loss: 101.588150
epoch: 3960, train precision: 0.998822, train loss: 10.222432, valid precision: 0.875400, valid loss: 99.880657
epoch: 3961, train precision: 0.998711, train loss: 10.264492, valid precision: 0.873000, valid loss: 101.159837
epoch: 3962, train precision: 0.999200, train loss: 10.112813, valid precision: 0.875000, valid loss: 103.188238
epoch: 3963, train precision: 0.999311, train loss: 10.086092, valid precision: 0.871200, valid loss: 103.180432
epoch: 3964, train precision: 0.998956, train loss: 10.215438, valid precision: 0.869800, valid loss: 102.297894
epoch: 3965, train precision: 0.999067, train loss: 10.118303, valid precision: 0.870000, valid loss: 102.374132
epoch: 3966, train precision: 0.999178, train loss: 10.119669, valid precision: 0.875200, valid loss: 101.538193
epoch: 3967, train precision: 0.998489, train loss: 10.285923, valid precision: 0.871600, valid loss: 101.625655
epoch: 3968, train precision: 0.999244, train loss: 10.128172, valid precision: 0.871600, valid loss: 102.523551
epoch: 3969, train precision: 0.999133, train loss: 10.111616, valid precision: 0.874800, valid loss: 102.135102
epoch: 3970, train precision: 0.998600, train loss: 10.299577, valid precision: 0.867400, valid loss: 105.582294
epoch: 3971, train precision: 0.998778, train loss: 10.224267, valid precision: 0.872400, valid loss: 101.650967
epoch: 3972, train precision: 0.999133, train loss: 10.064247, valid precision: 0.874600, valid loss: 100.493178
epoch: 3973, train precision: 0.999111, train loss: 10.095805, valid precision: 0.874000, valid loss: 100.812132
epoch: 3974, train precision: 0.998889, train loss: 10.189906, valid precision: 0.873200, valid loss: 103.871805
epoch: 3975, train precision: 0.999089, train loss: 10.169385, valid precision: 0.875400, valid loss: 99.430078
epoch: 3976, train precision: 0.998933, train loss: 10.192903, valid precision: 0.874800, valid loss: 98.780552
epoch: 3977, train precision: 0.998911, train loss: 10.182233, valid precision: 0.874800, valid loss: 103.873873
epoch: 3978, train precision: 0.999000, train loss: 10.159616, valid precision: 0.873800, valid loss: 101.254950
epoch: 3979, train precision: 0.999089, train loss: 10.134437, valid precision: 0.874800, valid loss: 102.751479
epoch: 3980, train precision: 0.998978, train loss: 10.213653, valid precision: 0.871000, valid loss: 101.053518
epoch: 3981, train precision: 0.999311, train loss: 10.092415, valid precision: 0.874400, valid loss: 102.983019
epoch: 3982, train precision: 0.999111, train loss: 10.113432, valid precision: 0.871200, valid loss: 103.344191
epoch: 3983, train precision: 0.999089, train loss: 10.148181, valid precision: 0.872200, valid loss: 102.886928
epoch: 3984, train precision: 0.999067, train loss: 10.176670, valid precision: 0.873800, valid loss: 99.766029
epoch: 3985, train precision: 0.999133, train loss: 10.090621, valid precision: 0.874400, valid loss: 100.730467
epoch: 3986, train precision: 0.999022, train loss: 10.158214, valid precision: 0.874800, valid loss: 99.664119
epoch: 3987, train precision: 0.999022, train loss: 10.160752, valid precision: 0.875400, valid loss: 98.931419
epoch: 3988, train precision: 0.999156, train loss: 10.130536, valid precision: 0.875000, valid loss: 99.604096
epoch: 3989, train precision: 0.999067, train loss: 10.142925, valid precision: 0.876400, valid loss: 98.255078
epoch: 3990, train precision: 0.999156, train loss: 10.131554, valid precision: 0.872600, valid loss: 98.077120
epoch: 3991, train precision: 0.999244, train loss: 10.088800, valid precision: 0.875000, valid loss: 98.787238
epoch: 3992, train precision: 0.998711, train loss: 10.241957, valid precision: 0.870200, valid loss: 102.891293
epoch: 3993, train precision: 0.999289, train loss: 10.120601, valid precision: 0.870600, valid loss: 99.822819
epoch: 3994, train precision: 0.999022, train loss: 10.177654, valid precision: 0.872600, valid loss: 99.797498
epoch: 3995, train precision: 0.999044, train loss: 10.179436, valid precision: 0.876200, valid loss: 97.438640
epoch: 3996, train precision: 0.999067, train loss: 10.122876, valid precision: 0.876000, valid loss: 101.775160
epoch: 3997, train precision: 0.999067, train loss: 10.154486, valid precision: 0.871800, valid loss: 99.898402
epoch: 3998, train precision: 0.998911, train loss: 10.149802, valid precision: 0.870600, valid loss: 100.730438
epoch: 3999, train precision: 0.998889, train loss: 10.219765, valid precision: 0.875600, valid loss: 100.519853
epoch: 4000, train precision: 0.999067, train loss: 10.101211, valid precision: 0.873000, valid loss: 100.433602
epoch: 4001, train precision: 0.999089, train loss: 10.143278, valid precision: 0.873000, valid loss: 101.375654
epoch: 4002, train precision: 0.999156, train loss: 10.122034, valid precision: 0.873400, valid loss: 97.473894
epoch: 4003, train precision: 0.998911, train loss: 10.155252, valid precision: 0.877400, valid loss: 98.793509
epoch: 4004, train precision: 0.998844, train loss: 10.188744, valid precision: 0.874800, valid loss: 100.250018
epoch: 4005, train precision: 0.999000, train loss: 10.114760, valid precision: 0.872600, valid loss: 101.429213
epoch: 4006, train precision: 0.999156, train loss: 10.088593, valid precision: 0.874400, valid loss: 99.245794
epoch: 4007, train precision: 0.998978, train loss: 10.148744, valid precision: 0.876800, valid loss: 95.918396
epoch: 4008, train precision: 0.999111, train loss: 10.128890, valid precision: 0.872200, valid loss: 100.107785
epoch: 4009, train precision: 0.999089, train loss: 10.188400, valid precision: 0.874200, valid loss: 99.552278
epoch: 4010, train precision: 0.999044, train loss: 10.186418, valid precision: 0.872400, valid loss: 99.615484
epoch: 4011, train precision: 0.999089, train loss: 10.143796, valid precision: 0.876600, valid loss: 98.865260
epoch: 4012, train precision: 0.999333, train loss: 10.032880, valid precision: 0.878600, valid loss: 97.338721
epoch: 4013, train precision: 0.999200, train loss: 10.119325, valid precision: 0.874000, valid loss: 94.080563
epoch: 4014, train precision: 0.998689, train loss: 10.283217, valid precision: 0.874200, valid loss: 98.693303
epoch: 4015, train precision: 0.999000, train loss: 10.187938, valid precision: 0.874600, valid loss: 98.435752
epoch: 4016, train precision: 0.999244, train loss: 10.104560, valid precision: 0.875800, valid loss: 98.002004
epoch: 4017, train precision: 0.999089, train loss: 10.162550, valid precision: 0.874600, valid loss: 97.644442
epoch: 4018, train precision: 0.999067, train loss: 10.144729, valid precision: 0.874600, valid loss: 97.688666
epoch: 4019, train precision: 0.999022, train loss: 10.168366, valid precision: 0.874800, valid loss: 101.272391
epoch: 4020, train precision: 0.999067, train loss: 10.160976, valid precision: 0.871600, valid loss: 102.313012
epoch: 4021, train precision: 0.999022, train loss: 10.175457, valid precision: 0.870200, valid loss: 100.047390
epoch: 4022, train precision: 0.998467, train loss: 10.326584, valid precision: 0.871600, valid loss: 99.894769
epoch: 4023, train precision: 0.999111, train loss: 10.122786, valid precision: 0.869800, valid loss: 101.573060
epoch: 4024, train precision: 0.998844, train loss: 10.195102, valid precision: 0.869400, valid loss: 100.509471
epoch: 4025, train precision: 0.998822, train loss: 10.234463, valid precision: 0.866200, valid loss: 102.489908
epoch: 4026, train precision: 0.998933, train loss: 10.256143, valid precision: 0.868600, valid loss: 101.314598
epoch: 4027, train precision: 0.999067, train loss: 10.117968, valid precision: 0.869800, valid loss: 98.052773
epoch: 4028, train precision: 0.998778, train loss: 10.224090, valid precision: 0.872600, valid loss: 102.143949
epoch: 4029, train precision: 0.999133, train loss: 10.125729, valid precision: 0.873600, valid loss: 99.609852
epoch: 4030, train precision: 0.999178, train loss: 10.082771, valid precision: 0.871800, valid loss: 97.561360
epoch: 4031, train precision: 0.999000, train loss: 10.101684, valid precision: 0.873000, valid loss: 97.678680
epoch: 4032, train precision: 0.999044, train loss: 10.119514, valid precision: 0.875600, valid loss: 98.926034
epoch: 4033, train precision: 0.998956, train loss: 10.195411, valid precision: 0.876200, valid loss: 96.190743
epoch: 4034, train precision: 0.998756, train loss: 10.208400, valid precision: 0.876000, valid loss: 101.449356
epoch: 4035, train precision: 0.999378, train loss: 10.053493, valid precision: 0.875800, valid loss: 97.246994
epoch: 4036, train precision: 0.998844, train loss: 10.159224, valid precision: 0.874400, valid loss: 98.270405
epoch: 4037, train precision: 0.999133, train loss: 10.094260, valid precision: 0.876600, valid loss: 97.805570
epoch: 4038, train precision: 0.998978, train loss: 10.145991, valid precision: 0.873800, valid loss: 99.306415
epoch: 4039, train precision: 0.999400, train loss: 10.078795, valid precision: 0.875000, valid loss: 97.692926
epoch: 4040, train precision: 0.998844, train loss: 10.173390, valid precision: 0.876400, valid loss: 98.403312
epoch: 4041, train precision: 0.999333, train loss: 10.106972, valid precision: 0.870800, valid loss: 98.775522
epoch: 4042, train precision: 0.999089, train loss: 10.105664, valid precision: 0.870000, valid loss: 99.834828
epoch: 4043, train precision: 0.999133, train loss: 10.081995, valid precision: 0.872400, valid loss: 98.704350
epoch: 4044, train precision: 0.999311, train loss: 10.084668, valid precision: 0.873400, valid loss: 98.728459
epoch: 4045, train precision: 0.999022, train loss: 10.152676, valid precision: 0.875000, valid loss: 96.997899
epoch: 4046, train precision: 0.999044, train loss: 10.169956, valid precision: 0.878000, valid loss: 98.659108
epoch: 4047, train precision: 0.999200, train loss: 10.084128, valid precision: 0.873800, valid loss: 97.428431
epoch: 4048, train precision: 0.998911, train loss: 10.128055, valid precision: 0.870400, valid loss: 99.791801
epoch: 4049, train precision: 0.999222, train loss: 10.098555, valid precision: 0.873800, valid loss: 99.760560
epoch: 4050, train precision: 0.998711, train loss: 10.278176, valid precision: 0.876800, valid loss: 100.331735
epoch: 4051, train precision: 0.999156, train loss: 10.072938, valid precision: 0.875800, valid loss: 98.045253
epoch: 4052, train precision: 0.999111, train loss: 10.124868, valid precision: 0.873800, valid loss: 98.968532
epoch: 4053, train precision: 0.999022, train loss: 10.139690, valid precision: 0.874600, valid loss: 99.643512
epoch: 4054, train precision: 0.998867, train loss: 10.176117, valid precision: 0.876600, valid loss: 98.194390
epoch: 4055, train precision: 0.999178, train loss: 10.109769, valid precision: 0.873800, valid loss: 100.460004
epoch: 4056, train precision: 0.998800, train loss: 10.216066, valid precision: 0.873800, valid loss: 99.150737
epoch: 4057, train precision: 0.998956, train loss: 10.127712, valid precision: 0.874200, valid loss: 97.115196
epoch: 4058, train precision: 0.999089, train loss: 10.124005, valid precision: 0.873000, valid loss: 96.639785
epoch: 4059, train precision: 0.998956, train loss: 10.155145, valid precision: 0.873800, valid loss: 99.863357
epoch: 4060, train precision: 0.999200, train loss: 10.089429, valid precision: 0.870600, valid loss: 98.758092
epoch: 4061, train precision: 0.999044, train loss: 10.139144, valid precision: 0.876000, valid loss: 93.739226
epoch: 4062, train precision: 0.999022, train loss: 10.139128, valid precision: 0.873800, valid loss: 99.577974
epoch: 4063, train precision: 0.999378, train loss: 10.048718, valid precision: 0.874800, valid loss: 100.185001
epoch: 4064, train precision: 0.999200, train loss: 10.128119, valid precision: 0.874400, valid loss: 98.176432
epoch: 4065, train precision: 0.998867, train loss: 10.207883, valid precision: 0.873800, valid loss: 99.389996
epoch: 4066, train precision: 0.999222, train loss: 10.062301, valid precision: 0.871000, valid loss: 100.163948
epoch: 4067, train precision: 0.998911, train loss: 10.230401, valid precision: 0.868200, valid loss: 101.846067
epoch: 4068, train precision: 0.999289, train loss: 10.052721, valid precision: 0.873600, valid loss: 97.540002
epoch: 4069, train precision: 0.999267, train loss: 10.003112, valid precision: 0.874800, valid loss: 100.760373
epoch: 4070, train precision: 0.998644, train loss: 10.227080, valid precision: 0.876800, valid loss: 97.694741
epoch: 4071, train precision: 0.998644, train loss: 10.235274, valid precision: 0.873200, valid loss: 99.986568
epoch: 4072, train precision: 0.998733, train loss: 10.226094, valid precision: 0.873800, valid loss: 98.048366
epoch: 4073, train precision: 0.999111, train loss: 10.137087, valid precision: 0.872400, valid loss: 98.351457
epoch: 4074, train precision: 0.998978, train loss: 10.155769, valid precision: 0.868000, valid loss: 102.699159
epoch: 4075, train precision: 0.999178, train loss: 10.112930, valid precision: 0.871800, valid loss: 99.981851
epoch: 4076, train precision: 0.999000, train loss: 10.115958, valid precision: 0.869000, valid loss: 101.513697
epoch: 4077, train precision: 0.999044, train loss: 10.142421, valid precision: 0.867200, valid loss: 103.420489
epoch: 4078, train precision: 0.999244, train loss: 10.057751, valid precision: 0.872400, valid loss: 99.440314
epoch: 4079, train precision: 0.999333, train loss: 10.105538, valid precision: 0.873400, valid loss: 99.780502
epoch: 4080, train precision: 0.998733, train loss: 10.298068, valid precision: 0.868800, valid loss: 104.982001
epoch: 4081, train precision: 0.999422, train loss: 10.031119, valid precision: 0.872600, valid loss: 97.770109
epoch: 4082, train precision: 0.999244, train loss: 10.128685, valid precision: 0.867400, valid loss: 100.770565
epoch: 4083, train precision: 0.999244, train loss: 10.065217, valid precision: 0.870000, valid loss: 101.056573
epoch: 4084, train precision: 0.999044, train loss: 10.140312, valid precision: 0.871400, valid loss: 100.368172
epoch: 4085, train precision: 0.999244, train loss: 10.107712, valid precision: 0.872400, valid loss: 98.899686
epoch: 4086, train precision: 0.998867, train loss: 10.177790, valid precision: 0.872400, valid loss: 100.002504
epoch: 4087, train precision: 0.999156, train loss: 10.054820, valid precision: 0.875000, valid loss: 101.465926
epoch: 4088, train precision: 0.999044, train loss: 10.158902, valid precision: 0.872800, valid loss: 100.726720
epoch: 4089, train precision: 0.999222, train loss: 10.046555, valid precision: 0.873800, valid loss: 99.479176
epoch: 4090, train precision: 0.999000, train loss: 10.151304, valid precision: 0.868400, valid loss: 100.041643
epoch: 4091, train precision: 0.999044, train loss: 10.162348, valid precision: 0.866600, valid loss: 98.773153
epoch: 4092, train precision: 0.999356, train loss: 10.043373, valid precision: 0.875000, valid loss: 98.850087
epoch: 4093, train precision: 0.999200, train loss: 10.057139, valid precision: 0.871800, valid loss: 100.959594
epoch: 4094, train precision: 0.999022, train loss: 10.091411, valid precision: 0.871800, valid loss: 100.088356
epoch: 4095, train precision: 0.999267, train loss: 10.057453, valid precision: 0.874000, valid loss: 98.400498
epoch: 4096, train precision: 0.999156, train loss: 10.098958, valid precision: 0.871200, valid loss: 99.057635
epoch: 4097, train precision: 0.999111, train loss: 10.122143, valid precision: 0.868600, valid loss: 101.018416
epoch: 4098, train precision: 0.999156, train loss: 10.111790, valid precision: 0.872200, valid loss: 98.916973
epoch: 4099, train precision: 0.999244, train loss: 10.118029, valid precision: 0.871400, valid loss: 99.482586
epoch: 4100, train precision: 0.999289, train loss: 10.060420, valid precision: 0.869800, valid loss: 99.504054
epoch: 4101, train precision: 0.999156, train loss: 10.113057, valid precision: 0.869200, valid loss: 101.660977
epoch: 4102, train precision: 0.999133, train loss: 10.135129, valid precision: 0.872000, valid loss: 99.561987
epoch: 4103, train precision: 0.999378, train loss: 10.046983, valid precision: 0.872400, valid loss: 101.277067
epoch: 4104, train precision: 0.999356, train loss: 10.078116, valid precision: 0.872800, valid loss: 98.543985
epoch: 4105, train precision: 0.999067, train loss: 10.110635, valid precision: 0.871800, valid loss: 101.441950
epoch: 4106, train precision: 0.998978, train loss: 10.158233, valid precision: 0.873200, valid loss: 100.948646
epoch: 4107, train precision: 0.998911, train loss: 10.147917, valid precision: 0.872800, valid loss: 100.280067
epoch: 4108, train precision: 0.999178, train loss: 10.114782, valid precision: 0.871800, valid loss: 102.490464
epoch: 4109, train precision: 0.999333, train loss: 10.066348, valid precision: 0.875000, valid loss: 101.985202
epoch: 4110, train precision: 0.999000, train loss: 10.149858, valid precision: 0.872400, valid loss: 102.509877
epoch: 4111, train precision: 0.998956, train loss: 10.188242, valid precision: 0.876000, valid loss: 101.566142
epoch: 4112, train precision: 0.998844, train loss: 10.186368, valid precision: 0.872200, valid loss: 101.901845
epoch: 4113, train precision: 0.999000, train loss: 10.179813, valid precision: 0.871400, valid loss: 102.586240
epoch: 4114, train precision: 0.998867, train loss: 10.148453, valid precision: 0.871600, valid loss: 98.271487
epoch: 4115, train precision: 0.998978, train loss: 10.206410, valid precision: 0.872000, valid loss: 99.032888
epoch: 4116, train precision: 0.999067, train loss: 10.106586, valid precision: 0.871400, valid loss: 102.348696
epoch: 4117, train precision: 0.998644, train loss: 10.253406, valid precision: 0.869600, valid loss: 98.610976
epoch: 4118, train precision: 0.999378, train loss: 10.081579, valid precision: 0.872000, valid loss: 99.679515
epoch: 4119, train precision: 0.999578, train loss: 9.941999, valid precision: 0.871200, valid loss: 101.099456
epoch: 4120, train precision: 0.999067, train loss: 10.123961, valid precision: 0.865800, valid loss: 106.029527
epoch: 4121, train precision: 0.998956, train loss: 10.155731, valid precision: 0.870800, valid loss: 103.345566
epoch: 4122, train precision: 0.998978, train loss: 10.134972, valid precision: 0.866400, valid loss: 102.172239
epoch: 4123, train precision: 0.998889, train loss: 10.191068, valid precision: 0.869200, valid loss: 101.410010
epoch: 4124, train precision: 0.999044, train loss: 10.177195, valid precision: 0.869600, valid loss: 100.346304
epoch: 4125, train precision: 0.999311, train loss: 10.064633, valid precision: 0.873400, valid loss: 100.039399
epoch: 4126, train precision: 0.999067, train loss: 10.112161, valid precision: 0.873800, valid loss: 101.953727
epoch: 4127, train precision: 0.998733, train loss: 10.246927, valid precision: 0.867000, valid loss: 102.624263
epoch: 4128, train precision: 0.999400, train loss: 10.052592, valid precision: 0.872800, valid loss: 99.886421
epoch: 4129, train precision: 0.998911, train loss: 10.144071, valid precision: 0.869000, valid loss: 99.438224
epoch: 4130, train precision: 0.999133, train loss: 10.136865, valid precision: 0.872200, valid loss: 98.709375
epoch: 4131, train precision: 0.999600, train loss: 10.021225, valid precision: 0.873600, valid loss: 98.799364
epoch: 4132, train precision: 0.999289, train loss: 10.044779, valid precision: 0.874200, valid loss: 98.236501
epoch: 4133, train precision: 0.998889, train loss: 10.176077, valid precision: 0.868600, valid loss: 99.597192
epoch: 4134, train precision: 0.999178, train loss: 10.050594, valid precision: 0.873400, valid loss: 100.137436
epoch: 4135, train precision: 0.999311, train loss: 10.015173, valid precision: 0.874800, valid loss: 100.263525
epoch: 4136, train precision: 0.999000, train loss: 10.154773, valid precision: 0.867400, valid loss: 100.672703
epoch: 4137, train precision: 0.998800, train loss: 10.169996, valid precision: 0.870800, valid loss: 101.786582
epoch: 4138, train precision: 0.999111, train loss: 10.081716, valid precision: 0.868800, valid loss: 101.266047
epoch: 4139, train precision: 0.998911, train loss: 10.183503, valid precision: 0.872600, valid loss: 101.310419
epoch: 4140, train precision: 0.998956, train loss: 10.172443, valid precision: 0.867200, valid loss: 104.161222
epoch: 4141, train precision: 0.999044, train loss: 10.119801, valid precision: 0.869600, valid loss: 102.669493
epoch: 4142, train precision: 0.999044, train loss: 10.120875, valid precision: 0.871000, valid loss: 100.380618
epoch: 4143, train precision: 0.999311, train loss: 10.094815, valid precision: 0.870200, valid loss: 101.546267
epoch: 4144, train precision: 0.999289, train loss: 10.115236, valid precision: 0.869200, valid loss: 103.585827
epoch: 4145, train precision: 0.999000, train loss: 10.092703, valid precision: 0.871600, valid loss: 99.195397
epoch: 4146, train precision: 0.999267, train loss: 10.078764, valid precision: 0.874600, valid loss: 99.696502
epoch: 4147, train precision: 0.999111, train loss: 10.093394, valid precision: 0.874800, valid loss: 103.023377
epoch: 4148, train precision: 0.998956, train loss: 10.163009, valid precision: 0.875000, valid loss: 102.179851
epoch: 4149, train precision: 0.999222, train loss: 10.082717, valid precision: 0.875000, valid loss: 99.921871
epoch: 4150, train precision: 0.998933, train loss: 10.191762, valid precision: 0.877000, valid loss: 101.127394
epoch: 4151, train precision: 0.999089, train loss: 10.126939, valid precision: 0.874000, valid loss: 99.840984
epoch: 4152, train precision: 0.998822, train loss: 10.208486, valid precision: 0.874600, valid loss: 102.213549
epoch: 4153, train precision: 0.998956, train loss: 10.115445, valid precision: 0.867600, valid loss: 103.773566
epoch: 4154, train precision: 0.998978, train loss: 10.135108, valid precision: 0.869000, valid loss: 102.872041
epoch: 4155, train precision: 0.998911, train loss: 10.195252, valid precision: 0.872800, valid loss: 103.627282
epoch: 4156, train precision: 0.999133, train loss: 10.115547, valid precision: 0.873600, valid loss: 100.337006
epoch: 4157, train precision: 0.999111, train loss: 10.116078, valid precision: 0.875800, valid loss: 98.167055
epoch: 4158, train precision: 0.999222, train loss: 10.105682, valid precision: 0.874400, valid loss: 98.706122
epoch: 4159, train precision: 0.999000, train loss: 10.147819, valid precision: 0.875000, valid loss: 97.641064
epoch: 4160, train precision: 0.998911, train loss: 10.123793, valid precision: 0.872000, valid loss: 99.515476
epoch: 4161, train precision: 0.999133, train loss: 10.070955, valid precision: 0.877600, valid loss: 98.152741
epoch: 4162, train precision: 0.998756, train loss: 10.220821, valid precision: 0.876600, valid loss: 97.960260
epoch: 4163, train precision: 0.998667, train loss: 10.225800, valid precision: 0.873600, valid loss: 100.702711
epoch: 4164, train precision: 0.999000, train loss: 10.154265, valid precision: 0.876600, valid loss: 99.368171
epoch: 4165, train precision: 0.999022, train loss: 10.128090, valid precision: 0.876600, valid loss: 96.372942
epoch: 4166, train precision: 0.999244, train loss: 10.067295, valid precision: 0.875400, valid loss: 98.258479
epoch: 4167, train precision: 0.998889, train loss: 10.161731, valid precision: 0.875400, valid loss: 97.459486
epoch: 4168, train precision: 0.999156, train loss: 10.072191, valid precision: 0.874400, valid loss: 96.424588
epoch: 4169, train precision: 0.998911, train loss: 10.135395, valid precision: 0.873600, valid loss: 99.468848
epoch: 4170, train precision: 0.999222, train loss: 10.114221, valid precision: 0.870400, valid loss: 98.348138
epoch: 4171, train precision: 0.999378, train loss: 10.045872, valid precision: 0.875600, valid loss: 96.851025
epoch: 4172, train precision: 0.999444, train loss: 9.978395, valid precision: 0.874800, valid loss: 99.108788
epoch: 4173, train precision: 0.999356, train loss: 10.052052, valid precision: 0.878400, valid loss: 99.615457
epoch: 4174, train precision: 0.999222, train loss: 10.039607, valid precision: 0.873600, valid loss: 98.109060
epoch: 4175, train precision: 0.998911, train loss: 10.108733, valid precision: 0.868200, valid loss: 100.541780
epoch: 4176, train precision: 0.998978, train loss: 10.139115, valid precision: 0.871800, valid loss: 101.192544
epoch: 4177, train precision: 0.998822, train loss: 10.170003, valid precision: 0.873400, valid loss: 97.449182
epoch: 4178, train precision: 0.999089, train loss: 10.083370, valid precision: 0.874000, valid loss: 99.815602
epoch: 4179, train precision: 0.999311, train loss: 10.017563, valid precision: 0.874200, valid loss: 99.875488
epoch: 4180, train precision: 0.999533, train loss: 9.989552, valid precision: 0.875800, valid loss: 99.064458
epoch: 4181, train precision: 0.998956, train loss: 10.192372, valid precision: 0.874200, valid loss: 101.527384
epoch: 4182, train precision: 0.999044, train loss: 10.104704, valid precision: 0.873600, valid loss: 100.413685
epoch: 4183, train precision: 0.999156, train loss: 10.053939, valid precision: 0.876400, valid loss: 100.314993
epoch: 4184, train precision: 0.998667, train loss: 10.225042, valid precision: 0.873400, valid loss: 100.732252
epoch: 4185, train precision: 0.998933, train loss: 10.166850, valid precision: 0.876400, valid loss: 97.743017
epoch: 4186, train precision: 0.999222, train loss: 10.077503, valid precision: 0.874000, valid loss: 98.653229
epoch: 4187, train precision: 0.999200, train loss: 10.086547, valid precision: 0.877000, valid loss: 98.494685
epoch: 4188, train precision: 0.998778, train loss: 10.186060, valid precision: 0.872200, valid loss: 100.214040
epoch: 4189, train precision: 0.999022, train loss: 10.097524, valid precision: 0.874400, valid loss: 99.802532
epoch: 4190, train precision: 0.999000, train loss: 10.205350, valid precision: 0.873600, valid loss: 100.332966
epoch: 4191, train precision: 0.999289, train loss: 10.037758, valid precision: 0.875400, valid loss: 100.849769
epoch: 4192, train precision: 0.998933, train loss: 10.117116, valid precision: 0.873000, valid loss: 97.791573
epoch: 4193, train precision: 0.998933, train loss: 10.150097, valid precision: 0.873000, valid loss: 98.060508
epoch: 4194, train precision: 0.999200, train loss: 10.063772, valid precision: 0.874200, valid loss: 100.887356
epoch: 4195, train precision: 0.999200, train loss: 10.065104, valid precision: 0.875200, valid loss: 100.595093
epoch: 4196, train precision: 0.998978, train loss: 10.148729, valid precision: 0.868400, valid loss: 102.436137
epoch: 4197, train precision: 0.999244, train loss: 10.053016, valid precision: 0.870800, valid loss: 100.275772
epoch: 4198, train precision: 0.999222, train loss: 10.053729, valid precision: 0.871600, valid loss: 99.543009
epoch: 4199, train precision: 0.999133, train loss: 10.074591, valid precision: 0.871800, valid loss: 100.877336
epoch: 4200, train precision: 0.998600, train loss: 10.341221, valid precision: 0.871800, valid loss: 99.801352
epoch: 4201, train precision: 0.999156, train loss: 10.073664, valid precision: 0.870800, valid loss: 98.360414
epoch: 4202, train precision: 0.999111, train loss: 10.088435, valid precision: 0.870400, valid loss: 97.100340
epoch: 4203, train precision: 0.999133, train loss: 10.081454, valid precision: 0.876200, valid loss: 99.594374
epoch: 4204, train precision: 0.998800, train loss: 10.138451, valid precision: 0.873200, valid loss: 97.020664
epoch: 4205, train precision: 0.998822, train loss: 10.158609, valid precision: 0.871800, valid loss: 101.361191
epoch: 4206, train precision: 0.998844, train loss: 10.162135, valid precision: 0.876600, valid loss: 97.020352
epoch: 4207, train precision: 0.998889, train loss: 10.131913, valid precision: 0.871800, valid loss: 99.783967
epoch: 4208, train precision: 0.998800, train loss: 10.220254, valid precision: 0.873000, valid loss: 97.081541
epoch: 4209, train precision: 0.998956, train loss: 10.091476, valid precision: 0.877400, valid loss: 97.425509
epoch: 4210, train precision: 0.999111, train loss: 10.132564, valid precision: 0.870400, valid loss: 98.465899
epoch: 4211, train precision: 0.999311, train loss: 10.020829, valid precision: 0.875800, valid loss: 97.023906
epoch: 4212, train precision: 0.999067, train loss: 10.130048, valid precision: 0.871200, valid loss: 99.261031
epoch: 4213, train precision: 0.998978, train loss: 10.123382, valid precision: 0.868400, valid loss: 99.774575
epoch: 4214, train precision: 0.998978, train loss: 10.088553, valid precision: 0.872600, valid loss: 99.941659
epoch: 4215, train precision: 0.999133, train loss: 10.158748, valid precision: 0.872800, valid loss: 100.769520
epoch: 4216, train precision: 0.998711, train loss: 10.215713, valid precision: 0.869000, valid loss: 101.830030
epoch: 4217, train precision: 0.999067, train loss: 10.106559, valid precision: 0.871200, valid loss: 101.434423
epoch: 4218, train precision: 0.999022, train loss: 10.068827, valid precision: 0.867000, valid loss: 103.225671
epoch: 4219, train precision: 0.998556, train loss: 10.233077, valid precision: 0.865600, valid loss: 103.786993
epoch: 4220, train precision: 0.998644, train loss: 10.242229, valid precision: 0.870400, valid loss: 100.704387
epoch: 4221, train precision: 0.999000, train loss: 10.106477, valid precision: 0.870200, valid loss: 103.032848
epoch: 4222, train precision: 0.998756, train loss: 10.161274, valid precision: 0.871600, valid loss: 103.147340
epoch: 4223, train precision: 0.999044, train loss: 10.157532, valid precision: 0.870000, valid loss: 100.124835
epoch: 4224, train precision: 0.999044, train loss: 10.109639, valid precision: 0.870600, valid loss: 102.049601
epoch: 4225, train precision: 0.999311, train loss: 10.026267, valid precision: 0.870400, valid loss: 107.040145
epoch: 4226, train precision: 0.998956, train loss: 10.166779, valid precision: 0.867200, valid loss: 104.029847
epoch: 4227, train precision: 0.999333, train loss: 10.076795, valid precision: 0.870600, valid loss: 101.133238
epoch: 4228, train precision: 0.999267, train loss: 10.010362, valid precision: 0.872800, valid loss: 99.845059
epoch: 4229, train precision: 0.998933, train loss: 10.096625, valid precision: 0.875800, valid loss: 97.825191
epoch: 4230, train precision: 0.999556, train loss: 9.987818, valid precision: 0.871400, valid loss: 99.085787
epoch: 4231, train precision: 0.998222, train loss: 10.406161, valid precision: 0.875200, valid loss: 102.333909
epoch: 4232, train precision: 0.998778, train loss: 10.138147, valid precision: 0.874400, valid loss: 97.981703
epoch: 4233, train precision: 0.998956, train loss: 10.166235, valid precision: 0.872200, valid loss: 96.247509
epoch: 4234, train precision: 0.998800, train loss: 10.171638, valid precision: 0.873600, valid loss: 100.265264
epoch: 4235, train precision: 0.998889, train loss: 10.219576, valid precision: 0.874400, valid loss: 98.837060
epoch: 4236, train precision: 0.998867, train loss: 10.209863, valid precision: 0.871800, valid loss: 99.978430
epoch: 4237, train precision: 0.999267, train loss: 10.068999, valid precision: 0.865200, valid loss: 100.383154
epoch: 4238, train precision: 0.999200, train loss: 10.088628, valid precision: 0.871800, valid loss: 100.029300
epoch: 4239, train precision: 0.999333, train loss: 10.033837, valid precision: 0.872600, valid loss: 100.498638
epoch: 4240, train precision: 0.998978, train loss: 10.049182, valid precision: 0.872800, valid loss: 99.016106
epoch: 4241, train precision: 0.999244, train loss: 10.011340, valid precision: 0.871800, valid loss: 98.575362
epoch: 4242, train precision: 0.998800, train loss: 10.161926, valid precision: 0.873000, valid loss: 99.695856
epoch: 4243, train precision: 0.998867, train loss: 10.168521, valid precision: 0.873400, valid loss: 99.575034
epoch: 4244, train precision: 0.999422, train loss: 10.002867, valid precision: 0.868000, valid loss: 99.619335
epoch: 4245, train precision: 0.998844, train loss: 10.208135, valid precision: 0.869000, valid loss: 102.229899
epoch: 4246, train precision: 0.998978, train loss: 10.142244, valid precision: 0.866400, valid loss: 101.126762
epoch: 4247, train precision: 0.999111, train loss: 10.106536, valid precision: 0.872800, valid loss: 99.016619
epoch: 4248, train precision: 0.999244, train loss: 10.033603, valid precision: 0.873400, valid loss: 102.031579
epoch: 4249, train precision: 0.998289, train loss: 10.367442, valid precision: 0.870600, valid loss: 102.134605
epoch: 4250, train precision: 0.999044, train loss: 10.106481, valid precision: 0.870400, valid loss: 101.753383
epoch: 4251, train precision: 0.999333, train loss: 10.069239, valid precision: 0.870200, valid loss: 100.151202
epoch: 4252, train precision: 0.999311, train loss: 10.083020, valid precision: 0.870200, valid loss: 99.945243
epoch: 4253, train precision: 0.998867, train loss: 10.159426, valid precision: 0.872200, valid loss: 99.730499
epoch: 4254, train precision: 0.999156, train loss: 10.069184, valid precision: 0.873800, valid loss: 96.603346
epoch: 4255, train precision: 0.998400, train loss: 10.342992, valid precision: 0.874400, valid loss: 99.965404
epoch: 4256, train precision: 0.998533, train loss: 10.275835, valid precision: 0.870200, valid loss: 101.766978
epoch: 4257, train precision: 0.999289, train loss: 10.069969, valid precision: 0.873600, valid loss: 99.464723
epoch: 4258, train precision: 0.999200, train loss: 10.090543, valid precision: 0.872000, valid loss: 98.302250
epoch: 4259, train precision: 0.999333, train loss: 10.021232, valid precision: 0.876400, valid loss: 97.509063
epoch: 4260, train precision: 0.999156, train loss: 10.031697, valid precision: 0.878400, valid loss: 99.246161
epoch: 4261, train precision: 0.999178, train loss: 10.107748, valid precision: 0.876200, valid loss: 99.046639
epoch: 4262, train precision: 0.998978, train loss: 10.149249, valid precision: 0.869600, valid loss: 101.206308
epoch: 4263, train precision: 0.999267, train loss: 10.008071, valid precision: 0.876400, valid loss: 97.383951
epoch: 4264, train precision: 0.998667, train loss: 10.210982, valid precision: 0.872200, valid loss: 97.281234
epoch: 4265, train precision: 0.999178, train loss: 10.116963, valid precision: 0.873200, valid loss: 97.240722
epoch: 4266, train precision: 0.998933, train loss: 10.084535, valid precision: 0.873200, valid loss: 97.678346
epoch: 4267, train precision: 0.999289, train loss: 10.036710, valid precision: 0.876200, valid loss: 98.391782
epoch: 4268, train precision: 0.999311, train loss: 9.989709, valid precision: 0.873600, valid loss: 100.715746
epoch: 4269, train precision: 0.999267, train loss: 9.995997, valid precision: 0.876000, valid loss: 99.648384
epoch: 4270, train precision: 0.999289, train loss: 10.045201, valid precision: 0.873200, valid loss: 99.148673
epoch: 4271, train precision: 0.999356, train loss: 10.022983, valid precision: 0.873400, valid loss: 98.384006
epoch: 4272, train precision: 0.999178, train loss: 10.082018, valid precision: 0.868800, valid loss: 99.951209
epoch: 4273, train precision: 0.998667, train loss: 10.213503, valid precision: 0.872400, valid loss: 100.646858
epoch: 4274, train precision: 0.999222, train loss: 10.060951, valid precision: 0.873000, valid loss: 98.358661
epoch: 4275, train precision: 0.999133, train loss: 10.052987, valid precision: 0.874800, valid loss: 99.735436
epoch: 4276, train precision: 0.998844, train loss: 10.149699, valid precision: 0.872200, valid loss: 97.207929
epoch: 4277, train precision: 0.998933, train loss: 10.178533, valid precision: 0.876600, valid loss: 99.766333
epoch: 4278, train precision: 0.998978, train loss: 10.074068, valid precision: 0.878000, valid loss: 99.250853
epoch: 4279, train precision: 0.998778, train loss: 10.227807, valid precision: 0.870600, valid loss: 100.110598
epoch: 4280, train precision: 0.999089, train loss: 10.151467, valid precision: 0.874800, valid loss: 96.696810
epoch: 4281, train precision: 0.999244, train loss: 10.089923, valid precision: 0.875600, valid loss: 99.749191
epoch: 4282, train precision: 0.999378, train loss: 10.040039, valid precision: 0.874000, valid loss: 97.673867
epoch: 4283, train precision: 0.999222, train loss: 10.049236, valid precision: 0.871200, valid loss: 99.775988
epoch: 4284, train precision: 0.999022, train loss: 10.131368, valid precision: 0.872600, valid loss: 101.667595
epoch: 4285, train precision: 0.999356, train loss: 9.991785, valid precision: 0.872400, valid loss: 99.265423
epoch: 4286, train precision: 0.998600, train loss: 10.175435, valid precision: 0.868600, valid loss: 101.082045
epoch: 4287, train precision: 0.998978, train loss: 10.127050, valid precision: 0.874600, valid loss: 100.967893
epoch: 4288, train precision: 0.999244, train loss: 10.039079, valid precision: 0.872200, valid loss: 100.001543
epoch: 4289, train precision: 0.998822, train loss: 10.104860, valid precision: 0.870600, valid loss: 99.064122
epoch: 4290, train precision: 0.999178, train loss: 10.045375, valid precision: 0.875400, valid loss: 99.754213
epoch: 4291, train precision: 0.999022, train loss: 10.130065, valid precision: 0.871600, valid loss: 100.457245
epoch: 4292, train precision: 0.999178, train loss: 10.049140, valid precision: 0.870400, valid loss: 98.949850
epoch: 4293, train precision: 0.999000, train loss: 10.080792, valid precision: 0.872200, valid loss: 101.238935
epoch: 4294, train precision: 0.999156, train loss: 10.058685, valid precision: 0.873000, valid loss: 103.085547
epoch: 4295, train precision: 0.998867, train loss: 10.116618, valid precision: 0.868600, valid loss: 102.095598
epoch: 4296, train precision: 0.999511, train loss: 9.973397, valid precision: 0.868600, valid loss: 99.060332
epoch: 4297, train precision: 0.999022, train loss: 10.117722, valid precision: 0.873800, valid loss: 98.395664
epoch: 4298, train precision: 0.998667, train loss: 10.248882, valid precision: 0.874400, valid loss: 97.780326
epoch: 4299, train precision: 0.998711, train loss: 10.161713, valid precision: 0.872000, valid loss: 99.253563
epoch: 4300, train precision: 0.998800, train loss: 10.149308, valid precision: 0.865400, valid loss: 102.627156
epoch: 4301, train precision: 0.999089, train loss: 10.058476, valid precision: 0.873400, valid loss: 98.944370
epoch: 4302, train precision: 0.999089, train loss: 10.090948, valid precision: 0.874200, valid loss: 100.542340
epoch: 4303, train precision: 0.999044, train loss: 10.074395, valid precision: 0.876400, valid loss: 99.751376
epoch: 4304, train precision: 0.999178, train loss: 10.050078, valid precision: 0.872800, valid loss: 100.623206
epoch: 4305, train precision: 0.999044, train loss: 10.089705, valid precision: 0.870600, valid loss: 101.988126
epoch: 4306, train precision: 0.999222, train loss: 10.079701, valid precision: 0.874000, valid loss: 101.956883
epoch: 4307, train precision: 0.999467, train loss: 9.969490, valid precision: 0.876000, valid loss: 99.158601
epoch: 4308, train precision: 0.999067, train loss: 10.050941, valid precision: 0.875400, valid loss: 99.428435
epoch: 4309, train precision: 0.999067, train loss: 10.080209, valid precision: 0.876400, valid loss: 97.946293
epoch: 4310, train precision: 0.998511, train loss: 10.251365, valid precision: 0.872400, valid loss: 96.661929
epoch: 4311, train precision: 0.999156, train loss: 10.104641, valid precision: 0.874400, valid loss: 97.919174
epoch: 4312, train precision: 0.998978, train loss: 10.126050, valid precision: 0.872400, valid loss: 101.895986
epoch: 4313, train precision: 0.999356, train loss: 10.006474, valid precision: 0.875200, valid loss: 100.079534
epoch: 4314, train precision: 0.999000, train loss: 10.054943, valid precision: 0.873200, valid loss: 99.488147
epoch: 4315, train precision: 0.999022, train loss: 10.027737, valid precision: 0.873000, valid loss: 100.558370
epoch: 4316, train precision: 0.999200, train loss: 10.071387, valid precision: 0.875200, valid loss: 100.811853
epoch: 4317, train precision: 0.998622, train loss: 10.164327, valid precision: 0.873600, valid loss: 100.906991
epoch: 4318, train precision: 0.998889, train loss: 10.151684, valid precision: 0.873200, valid loss: 103.015617
epoch: 4319, train precision: 0.999178, train loss: 10.067470, valid precision: 0.875000, valid loss: 101.567113
epoch: 4320, train precision: 0.998333, train loss: 10.308063, valid precision: 0.875600, valid loss: 97.910407
epoch: 4321, train precision: 0.999156, train loss: 10.037672, valid precision: 0.872000, valid loss: 99.640804
epoch: 4322, train precision: 0.999356, train loss: 9.983748, valid precision: 0.871600, valid loss: 100.802378
epoch: 4323, train precision: 0.998956, train loss: 10.124447, valid precision: 0.869600, valid loss: 100.488776
epoch: 4324, train precision: 0.998956, train loss: 10.109042, valid precision: 0.872200, valid loss: 102.050386
epoch: 4325, train precision: 0.999044, train loss: 10.086106, valid precision: 0.873400, valid loss: 100.209676
epoch: 4326, train precision: 0.999000, train loss: 10.078712, valid precision: 0.871800, valid loss: 100.807234
epoch: 4327, train precision: 0.999044, train loss: 10.086512, valid precision: 0.870800, valid loss: 100.266100
epoch: 4328, train precision: 0.999267, train loss: 10.007959, valid precision: 0.873000, valid loss: 99.026355
epoch: 4329, train precision: 0.998844, train loss: 10.229903, valid precision: 0.872400, valid loss: 101.538026
epoch: 4330, train precision: 0.998778, train loss: 10.115273, valid precision: 0.875600, valid loss: 101.522640
epoch: 4331, train precision: 0.998689, train loss: 10.270887, valid precision: 0.873200, valid loss: 102.262675
epoch: 4332, train precision: 0.998933, train loss: 10.108408, valid precision: 0.874000, valid loss: 96.299177
epoch: 4333, train precision: 0.998911, train loss: 10.166470, valid precision: 0.875000, valid loss: 98.106291
epoch: 4334, train precision: 0.999156, train loss: 10.049508, valid precision: 0.875400, valid loss: 98.886467
epoch: 4335, train precision: 0.998800, train loss: 10.172825, valid precision: 0.874800, valid loss: 99.676381
epoch: 4336, train precision: 0.999044, train loss: 10.145281, valid precision: 0.875000, valid loss: 99.684828
epoch: 4337, train precision: 0.999000, train loss: 10.160640, valid precision: 0.874200, valid loss: 98.347603
epoch: 4338, train precision: 0.999244, train loss: 10.053943, valid precision: 0.871000, valid loss: 99.264678
epoch: 4339, train precision: 0.999267, train loss: 10.049264, valid precision: 0.873000, valid loss: 97.976423
epoch: 4340, train precision: 0.999022, train loss: 10.110493, valid precision: 0.876200, valid loss: 95.894420
epoch: 4341, train precision: 0.998422, train loss: 10.263140, valid precision: 0.871800, valid loss: 99.565309
epoch: 4342, train precision: 0.999356, train loss: 10.019794, valid precision: 0.876000, valid loss: 98.809654
epoch: 4343, train precision: 0.999222, train loss: 10.044070, valid precision: 0.869400, valid loss: 99.084474
epoch: 4344, train precision: 0.998711, train loss: 10.170015, valid precision: 0.876200, valid loss: 97.935018
epoch: 4345, train precision: 0.999067, train loss: 10.078121, valid precision: 0.874600, valid loss: 100.569179
epoch: 4346, train precision: 0.998689, train loss: 10.205526, valid precision: 0.872600, valid loss: 100.728715
epoch: 4347, train precision: 0.999000, train loss: 10.110639, valid precision: 0.876200, valid loss: 96.454842
epoch: 4348, train precision: 0.998889, train loss: 10.199971, valid precision: 0.875600, valid loss: 97.862968
epoch: 4349, train precision: 0.999133, train loss: 10.066364, valid precision: 0.876400, valid loss: 97.203690
epoch: 4350, train precision: 0.999067, train loss: 10.086305, valid precision: 0.875800, valid loss: 99.265926
epoch: 4351, train precision: 0.999022, train loss: 10.046682, valid precision: 0.877400, valid loss: 98.563524
epoch: 4352, train precision: 0.998556, train loss: 10.282408, valid precision: 0.875200, valid loss: 102.587959
epoch: 4353, train precision: 0.999000, train loss: 10.066864, valid precision: 0.875000, valid loss: 100.561303
epoch: 4354, train precision: 0.999133, train loss: 10.029199, valid precision: 0.876400, valid loss: 99.448906
epoch: 4355, train precision: 0.999222, train loss: 10.045420, valid precision: 0.874000, valid loss: 98.965251
epoch: 4356, train precision: 0.999000, train loss: 10.119351, valid precision: 0.875200, valid loss: 98.792301
epoch: 4357, train precision: 0.998978, train loss: 10.120751, valid precision: 0.873400, valid loss: 97.011808
epoch: 4358, train precision: 0.999089, train loss: 10.090585, valid precision: 0.873400, valid loss: 100.626964
epoch: 4359, train precision: 0.999178, train loss: 10.009346, valid precision: 0.874200, valid loss: 98.630577
epoch: 4360, train precision: 0.999178, train loss: 10.083563, valid precision: 0.878000, valid loss: 97.852282
epoch: 4361, train precision: 0.998778, train loss: 10.162354, valid precision: 0.871600, valid loss: 100.356066
epoch: 4362, train precision: 0.999400, train loss: 9.969621, valid precision: 0.878000, valid loss: 98.026043
epoch: 4363, train precision: 0.999178, train loss: 10.011053, valid precision: 0.876600, valid loss: 97.895108
epoch: 4364, train precision: 0.999267, train loss: 10.002848, valid precision: 0.875000, valid loss: 100.412640
epoch: 4365, train precision: 0.998956, train loss: 10.101107, valid precision: 0.876800, valid loss: 100.169244
epoch: 4366, train precision: 0.999133, train loss: 10.033598, valid precision: 0.878000, valid loss: 100.164615
epoch: 4367, train precision: 0.998889, train loss: 10.093168, valid precision: 0.877400, valid loss: 100.814220
epoch: 4368, train precision: 0.999111, train loss: 10.113389, valid precision: 0.874800, valid loss: 103.025504
epoch: 4369, train precision: 0.998822, train loss: 10.121215, valid precision: 0.873200, valid loss: 103.431040
epoch: 4370, train precision: 0.999356, train loss: 9.963893, valid precision: 0.873600, valid loss: 101.882111
epoch: 4371, train precision: 0.999200, train loss: 10.058291, valid precision: 0.879200, valid loss: 100.616178
epoch: 4372, train precision: 0.999156, train loss: 10.046546, valid precision: 0.873800, valid loss: 99.870814
epoch: 4373, train precision: 0.998933, train loss: 10.131320, valid precision: 0.871400, valid loss: 100.984942
epoch: 4374, train precision: 0.999156, train loss: 10.115243, valid precision: 0.874600, valid loss: 98.450692
epoch: 4375, train precision: 0.999222, train loss: 10.085454, valid precision: 0.872400, valid loss: 98.250710
epoch: 4376, train precision: 0.998956, train loss: 10.131846, valid precision: 0.873800, valid loss: 98.793109
epoch: 4377, train precision: 0.998978, train loss: 10.144270, valid precision: 0.873800, valid loss: 95.533333
epoch: 4378, train precision: 0.999267, train loss: 10.039341, valid precision: 0.871400, valid loss: 96.524452
epoch: 4379, train precision: 0.999356, train loss: 9.993406, valid precision: 0.874400, valid loss: 97.075787
epoch: 4380, train precision: 0.999244, train loss: 10.004988, valid precision: 0.874200, valid loss: 98.154746
epoch: 4381, train precision: 0.999133, train loss: 10.041328, valid precision: 0.874200, valid loss: 99.101278
epoch: 4382, train precision: 0.999311, train loss: 10.033837, valid precision: 0.872600, valid loss: 99.363658
epoch: 4383, train precision: 0.998844, train loss: 10.162494, valid precision: 0.870000, valid loss: 101.955080
epoch: 4384, train precision: 0.998978, train loss: 10.138473, valid precision: 0.876800, valid loss: 99.975396
epoch: 4385, train precision: 0.999000, train loss: 10.125911, valid precision: 0.871800, valid loss: 101.309630
epoch: 4386, train precision: 0.999156, train loss: 10.069579, valid precision: 0.872000, valid loss: 102.941416
epoch: 4387, train precision: 0.999200, train loss: 10.053340, valid precision: 0.870400, valid loss: 101.832841
epoch: 4388, train precision: 0.998867, train loss: 10.170491, valid precision: 0.871000, valid loss: 99.620483
epoch: 4389, train precision: 0.999133, train loss: 10.079386, valid precision: 0.870800, valid loss: 96.169397
epoch: 4390, train precision: 0.999111, train loss: 10.051212, valid precision: 0.873800, valid loss: 98.303760
epoch: 4391, train precision: 0.998622, train loss: 10.186929, valid precision: 0.869600, valid loss: 102.639611
epoch: 4392, train precision: 0.999244, train loss: 10.045788, valid precision: 0.873800, valid loss: 101.676911
epoch: 4393, train precision: 0.999133, train loss: 10.076115, valid precision: 0.872200, valid loss: 103.315929
epoch: 4394, train precision: 0.999067, train loss: 10.046266, valid precision: 0.865400, valid loss: 101.728885
epoch: 4395, train precision: 0.998956, train loss: 10.124157, valid precision: 0.868200, valid loss: 103.176905
epoch: 4396, train precision: 0.998756, train loss: 10.132246, valid precision: 0.869600, valid loss: 101.083873
epoch: 4397, train precision: 0.999267, train loss: 10.056834, valid precision: 0.874400, valid loss: 99.746221
epoch: 4398, train precision: 0.998822, train loss: 10.118022, valid precision: 0.876800, valid loss: 99.759081
epoch: 4399, train precision: 0.999244, train loss: 10.106972, valid precision: 0.876800, valid loss: 97.347411
epoch: 4400, train precision: 0.999089, train loss: 10.138739, valid precision: 0.872600, valid loss: 98.164721
epoch: 4401, train precision: 0.999067, train loss: 10.063247, valid precision: 0.875800, valid loss: 97.757176
epoch: 4402, train precision: 0.999289, train loss: 10.024444, valid precision: 0.874600, valid loss: 97.247657
epoch: 4403, train precision: 0.998667, train loss: 10.174023, valid precision: 0.874400, valid loss: 102.016624
epoch: 4404, train precision: 0.999000, train loss: 10.053791, valid precision: 0.878200, valid loss: 101.595114
epoch: 4405, train precision: 0.999067, train loss: 10.091316, valid precision: 0.873000, valid loss: 101.897664
epoch: 4406, train precision: 0.999111, train loss: 10.125656, valid precision: 0.873400, valid loss: 101.936947
epoch: 4407, train precision: 0.999044, train loss: 10.100975, valid precision: 0.875000, valid loss: 98.990831
epoch: 4408, train precision: 0.998889, train loss: 10.150166, valid precision: 0.873600, valid loss: 99.660370
epoch: 4409, train precision: 0.999089, train loss: 10.014596, valid precision: 0.872800, valid loss: 102.658840
epoch: 4410, train precision: 0.999244, train loss: 10.037500, valid precision: 0.876000, valid loss: 100.847658
epoch: 4411, train precision: 0.999067, train loss: 10.129578, valid precision: 0.876400, valid loss: 101.685188
epoch: 4412, train precision: 0.999111, train loss: 10.015383, valid precision: 0.873800, valid loss: 102.692518
epoch: 4413, train precision: 0.999044, train loss: 10.090571, valid precision: 0.874800, valid loss: 100.012997
epoch: 4414, train precision: 0.998778, train loss: 10.200183, valid precision: 0.872000, valid loss: 97.084299
epoch: 4415, train precision: 0.999222, train loss: 10.021175, valid precision: 0.878000, valid loss: 96.552363
epoch: 4416, train precision: 0.999133, train loss: 10.021736, valid precision: 0.875000, valid loss: 97.913982
epoch: 4417, train precision: 0.999244, train loss: 10.009658, valid precision: 0.872600, valid loss: 99.516178
epoch: 4418, train precision: 0.999156, train loss: 10.044370, valid precision: 0.870800, valid loss: 100.024981
epoch: 4419, train precision: 0.999222, train loss: 10.011389, valid precision: 0.870200, valid loss: 100.204494
epoch: 4420, train precision: 0.999133, train loss: 10.060070, valid precision: 0.873600, valid loss: 100.558214
epoch: 4421, train precision: 0.999133, train loss: 10.009015, valid precision: 0.870200, valid loss: 101.118770
epoch: 4422, train precision: 0.999089, train loss: 10.079911, valid precision: 0.876000, valid loss: 99.606876
epoch: 4423, train precision: 0.998911, train loss: 10.110463, valid precision: 0.871200, valid loss: 100.345322
epoch: 4424, train precision: 0.998956, train loss: 10.071569, valid precision: 0.872200, valid loss: 100.975506
epoch: 4425, train precision: 0.998867, train loss: 10.187079, valid precision: 0.872400, valid loss: 101.489586
epoch: 4426, train precision: 0.998822, train loss: 10.117197, valid precision: 0.868800, valid loss: 101.204394
epoch: 4427, train precision: 0.999089, train loss: 10.074015, valid precision: 0.873200, valid loss: 98.938670
epoch: 4428, train precision: 0.999089, train loss: 10.075902, valid precision: 0.872000, valid loss: 98.089623
epoch: 4429, train precision: 0.999067, train loss: 10.063690, valid precision: 0.871600, valid loss: 99.515748
epoch: 4430, train precision: 0.999022, train loss: 10.022227, valid precision: 0.869800, valid loss: 101.907975
epoch: 4431, train precision: 0.999400, train loss: 9.983784, valid precision: 0.869800, valid loss: 101.927741
epoch: 4432, train precision: 0.999133, train loss: 10.064528, valid precision: 0.870600, valid loss: 104.317835
epoch: 4433, train precision: 0.998822, train loss: 10.149807, valid precision: 0.870000, valid loss: 102.512053
epoch: 4434, train precision: 0.999200, train loss: 10.025020, valid precision: 0.873000, valid loss: 103.733963
epoch: 4435, train precision: 0.999133, train loss: 10.087192, valid precision: 0.874200, valid loss: 101.425411
epoch: 4436, train precision: 0.999178, train loss: 10.063383, valid precision: 0.874400, valid loss: 100.334725
epoch: 4437, train precision: 0.999000, train loss: 10.076878, valid precision: 0.873200, valid loss: 104.588887
epoch: 4438, train precision: 0.998978, train loss: 10.066139, valid precision: 0.870200, valid loss: 105.873747
epoch: 4439, train precision: 0.999244, train loss: 10.102440, valid precision: 0.872000, valid loss: 102.719503
epoch: 4440, train precision: 0.999022, train loss: 10.038096, valid precision: 0.869400, valid loss: 104.234128
epoch: 4441, train precision: 0.999067, train loss: 10.057554, valid precision: 0.869600, valid loss: 102.989443
epoch: 4442, train precision: 0.998889, train loss: 10.121236, valid precision: 0.872800, valid loss: 104.420762
epoch: 4443, train precision: 0.999089, train loss: 10.059434, valid precision: 0.867800, valid loss: 102.566962
epoch: 4444, train precision: 0.999333, train loss: 9.978059, valid precision: 0.874400, valid loss: 100.427482
epoch: 4445, train precision: 0.998956, train loss: 10.077456, valid precision: 0.874200, valid loss: 103.256473
epoch: 4446, train precision: 0.998778, train loss: 10.156033, valid precision: 0.869000, valid loss: 101.078125
epoch: 4447, train precision: 0.999333, train loss: 9.953337, valid precision: 0.872000, valid loss: 102.571421
epoch: 4448, train precision: 0.998889, train loss: 10.118122, valid precision: 0.871800, valid loss: 103.609861
epoch: 4449, train precision: 0.999289, train loss: 10.003285, valid precision: 0.868400, valid loss: 101.882186
epoch: 4450, train precision: 0.999222, train loss: 10.031934, valid precision: 0.866600, valid loss: 105.276620
epoch: 4451, train precision: 0.998733, train loss: 10.161475, valid precision: 0.872600, valid loss: 102.147668
epoch: 4452, train precision: 0.999156, train loss: 10.016191, valid precision: 0.868600, valid loss: 101.740169
epoch: 4453, train precision: 0.999311, train loss: 10.019266, valid precision: 0.872400, valid loss: 102.610075
epoch: 4454, train precision: 0.999067, train loss: 10.052753, valid precision: 0.869000, valid loss: 105.117318
epoch: 4455, train precision: 0.999267, train loss: 10.000423, valid precision: 0.872200, valid loss: 103.320712
epoch: 4456, train precision: 0.999178, train loss: 10.028074, valid precision: 0.873600, valid loss: 103.887065
epoch: 4457, train precision: 0.998867, train loss: 10.079154, valid precision: 0.870800, valid loss: 104.409794
epoch: 4458, train precision: 0.999200, train loss: 10.034597, valid precision: 0.871600, valid loss: 101.578609
epoch: 4459, train precision: 0.999178, train loss: 10.051006, valid precision: 0.876600, valid loss: 101.392994
epoch: 4460, train precision: 0.999156, train loss: 10.041150, valid precision: 0.872600, valid loss: 100.044417
epoch: 4461, train precision: 0.999111, train loss: 10.050608, valid precision: 0.872000, valid loss: 103.713989
epoch: 4462, train precision: 0.999156, train loss: 9.991213, valid precision: 0.875200, valid loss: 99.831538
epoch: 4463, train precision: 0.999133, train loss: 10.036625, valid precision: 0.872200, valid loss: 100.301152
epoch: 4464, train precision: 0.998733, train loss: 10.117902, valid precision: 0.870800, valid loss: 102.692420
epoch: 4465, train precision: 0.999111, train loss: 10.059283, valid precision: 0.871400, valid loss: 104.778496
epoch: 4466, train precision: 0.999067, train loss: 10.082515, valid precision: 0.871200, valid loss: 101.327198
epoch: 4467, train precision: 0.998822, train loss: 10.128298, valid precision: 0.872400, valid loss: 101.376164
epoch: 4468, train precision: 0.999333, train loss: 10.015824, valid precision: 0.873600, valid loss: 100.925625
epoch: 4469, train precision: 0.999133, train loss: 10.075916, valid precision: 0.873000, valid loss: 102.245308
epoch: 4470, train precision: 0.999178, train loss: 10.001024, valid precision: 0.875400, valid loss: 103.174885
epoch: 4471, train precision: 0.999311, train loss: 10.035944, valid precision: 0.876400, valid loss: 101.589326
epoch: 4472, train precision: 0.999244, train loss: 10.081318, valid precision: 0.873200, valid loss: 104.088006
epoch: 4473, train precision: 0.999222, train loss: 9.983455, valid precision: 0.876800, valid loss: 99.526860
epoch: 4474, train precision: 0.999333, train loss: 9.960843, valid precision: 0.876600, valid loss: 100.342983
epoch: 4475, train precision: 0.999044, train loss: 10.101446, valid precision: 0.877000, valid loss: 98.551253
epoch: 4476, train precision: 0.999156, train loss: 10.062516, valid precision: 0.877000, valid loss: 99.983281
epoch: 4477, train precision: 0.998644, train loss: 10.227971, valid precision: 0.874000, valid loss: 103.059266
epoch: 4478, train precision: 0.998844, train loss: 10.111303, valid precision: 0.872200, valid loss: 102.880342
epoch: 4479, train precision: 0.998711, train loss: 10.136929, valid precision: 0.871600, valid loss: 104.428464
epoch: 4480, train precision: 0.999022, train loss: 10.082860, valid precision: 0.871800, valid loss: 103.303296
epoch: 4481, train precision: 0.999133, train loss: 10.046403, valid precision: 0.873600, valid loss: 102.378976
epoch: 4482, train precision: 0.998689, train loss: 10.198113, valid precision: 0.869400, valid loss: 104.610077
epoch: 4483, train precision: 0.999000, train loss: 10.100567, valid precision: 0.870200, valid loss: 106.525666
epoch: 4484, train precision: 0.999289, train loss: 10.029894, valid precision: 0.873000, valid loss: 104.999071
epoch: 4485, train precision: 0.998644, train loss: 10.244546, valid precision: 0.877400, valid loss: 98.609549
epoch: 4486, train precision: 0.999333, train loss: 9.981804, valid precision: 0.873800, valid loss: 101.297317
epoch: 4487, train precision: 0.999067, train loss: 10.026264, valid precision: 0.877200, valid loss: 103.144885
epoch: 4488, train precision: 0.999156, train loss: 10.015487, valid precision: 0.876200, valid loss: 101.773810
epoch: 4489, train precision: 0.998867, train loss: 10.144380, valid precision: 0.874400, valid loss: 101.547006
epoch: 4490, train precision: 0.998933, train loss: 10.094284, valid precision: 0.875600, valid loss: 100.694729
epoch: 4491, train precision: 0.999000, train loss: 10.069940, valid precision: 0.873400, valid loss: 102.619830
epoch: 4492, train precision: 0.998889, train loss: 10.140906, valid precision: 0.876800, valid loss: 103.638860
epoch: 4493, train precision: 0.999067, train loss: 10.103393, valid precision: 0.874200, valid loss: 102.210891
epoch: 4494, train precision: 0.998844, train loss: 10.108924, valid precision: 0.879000, valid loss: 99.384649
epoch: 4495, train precision: 0.999089, train loss: 10.043947, valid precision: 0.877200, valid loss: 99.760246
epoch: 4496, train precision: 0.999067, train loss: 10.104667, valid precision: 0.876000, valid loss: 99.788822
epoch: 4497, train precision: 0.999000, train loss: 10.066231, valid precision: 0.875600, valid loss: 101.158395
epoch: 4498, train precision: 0.999111, train loss: 10.034105, valid precision: 0.874400, valid loss: 101.207823
epoch: 4499, train precision: 0.999133, train loss: 10.017026, valid precision: 0.876600, valid loss: 101.248262
epoch: 4500, train precision: 0.999133, train loss: 10.046912, valid precision: 0.871400, valid loss: 102.249045
epoch: 4501, train precision: 0.999000, train loss: 10.118883, valid precision: 0.873800, valid loss: 98.601073
epoch: 4502, train precision: 0.999200, train loss: 10.038960, valid precision: 0.878800, valid loss: 98.382949
epoch: 4503, train precision: 0.999333, train loss: 9.993242, valid precision: 0.878600, valid loss: 99.372117
epoch: 4504, train precision: 0.999156, train loss: 10.109620, valid precision: 0.871000, valid loss: 100.875256
epoch: 4505, train precision: 0.999133, train loss: 10.047970, valid precision: 0.870400, valid loss: 101.997392
epoch: 4506, train precision: 0.999289, train loss: 9.991728, valid precision: 0.878200, valid loss: 99.082936
epoch: 4507, train precision: 0.999067, train loss: 10.046614, valid precision: 0.874800, valid loss: 100.349581
epoch: 4508, train precision: 0.999022, train loss: 10.101614, valid precision: 0.881400, valid loss: 98.423849
epoch: 4509, train precision: 0.999089, train loss: 10.053549, valid precision: 0.879400, valid loss: 98.853222
epoch: 4510, train precision: 0.998800, train loss: 10.119121, valid precision: 0.876800, valid loss: 101.751174
epoch: 4511, train precision: 0.999378, train loss: 9.926339, valid precision: 0.876000, valid loss: 100.198212
epoch: 4512, train precision: 0.998933, train loss: 10.177269, valid precision: 0.873200, valid loss: 98.202222
epoch: 4513, train precision: 0.999289, train loss: 10.004939, valid precision: 0.876600, valid loss: 98.401116
epoch: 4514, train precision: 0.999311, train loss: 10.050356, valid precision: 0.878600, valid loss: 95.874303
epoch: 4515, train precision: 0.998889, train loss: 10.184652, valid precision: 0.872600, valid loss: 100.450086
epoch: 4516, train precision: 0.998800, train loss: 10.127915, valid precision: 0.875200, valid loss: 99.937513
epoch: 4517, train precision: 0.999133, train loss: 10.126208, valid precision: 0.874400, valid loss: 99.234908
epoch: 4518, train precision: 0.999000, train loss: 10.044930, valid precision: 0.875600, valid loss: 99.182344
epoch: 4519, train precision: 0.999178, train loss: 9.996448, valid precision: 0.877400, valid loss: 100.187835
epoch: 4520, train precision: 0.999289, train loss: 10.010810, valid precision: 0.877400, valid loss: 100.503727
epoch: 4521, train precision: 0.999333, train loss: 10.031955, valid precision: 0.874600, valid loss: 99.312920
epoch: 4522, train precision: 0.999267, train loss: 10.017274, valid precision: 0.871600, valid loss: 100.646005
epoch: 4523, train precision: 0.999000, train loss: 10.125729, valid precision: 0.876000, valid loss: 99.994580
epoch: 4524, train precision: 0.999222, train loss: 10.016220, valid precision: 0.875000, valid loss: 101.949938
epoch: 4525, train precision: 0.999022, train loss: 10.124421, valid precision: 0.868600, valid loss: 102.827988
epoch: 4526, train precision: 0.998867, train loss: 10.123458, valid precision: 0.874800, valid loss: 100.292059
epoch: 4527, train precision: 0.999267, train loss: 9.995207, valid precision: 0.875400, valid loss: 99.747082
epoch: 4528, train precision: 0.999089, train loss: 10.011356, valid precision: 0.878000, valid loss: 98.990088
epoch: 4529, train precision: 0.998933, train loss: 10.087404, valid precision: 0.875400, valid loss: 98.072621
epoch: 4530, train precision: 0.998889, train loss: 10.076139, valid precision: 0.878600, valid loss: 98.363161
epoch: 4531, train precision: 0.999133, train loss: 10.113706, valid precision: 0.880600, valid loss: 99.923497
epoch: 4532, train precision: 0.998778, train loss: 10.226870, valid precision: 0.875800, valid loss: 100.668473
epoch: 4533, train precision: 0.999067, train loss: 10.084256, valid precision: 0.876400, valid loss: 99.794628
epoch: 4534, train precision: 0.999200, train loss: 10.045456, valid precision: 0.876800, valid loss: 98.445593
epoch: 4535, train precision: 0.999222, train loss: 10.033879, valid precision: 0.877600, valid loss: 101.574456
epoch: 4536, train precision: 0.999267, train loss: 10.015640, valid precision: 0.879600, valid loss: 99.349273
epoch: 4537, train precision: 0.999444, train loss: 9.964822, valid precision: 0.880200, valid loss: 97.573014
epoch: 4538, train precision: 0.999133, train loss: 10.002921, valid precision: 0.876800, valid loss: 100.503651
epoch: 4539, train precision: 0.998733, train loss: 10.182096, valid precision: 0.877600, valid loss: 99.113370
epoch: 4540, train precision: 0.999022, train loss: 10.032874, valid precision: 0.878200, valid loss: 98.829387
epoch: 4541, train precision: 0.999089, train loss: 10.092644, valid precision: 0.878400, valid loss: 100.181686
epoch: 4542, train precision: 0.998822, train loss: 10.132182, valid precision: 0.876800, valid loss: 101.470384
epoch: 4543, train precision: 0.998711, train loss: 10.145879, valid precision: 0.875400, valid loss: 101.102908
epoch: 4544, train precision: 0.999400, train loss: 9.990878, valid precision: 0.874800, valid loss: 103.723088
epoch: 4545, train precision: 0.998956, train loss: 10.118996, valid precision: 0.876000, valid loss: 102.960463
epoch: 4546, train precision: 0.999089, train loss: 10.113236, valid precision: 0.875000, valid loss: 99.243013
epoch: 4547, train precision: 0.999333, train loss: 9.986218, valid precision: 0.871400, valid loss: 101.697099
epoch: 4548, train precision: 0.999133, train loss: 10.058505, valid precision: 0.874400, valid loss: 99.157042
epoch: 4549, train precision: 0.998889, train loss: 10.113197, valid precision: 0.875400, valid loss: 101.453963
epoch: 4550, train precision: 0.999289, train loss: 10.063371, valid precision: 0.875800, valid loss: 101.399272
epoch: 4551, train precision: 0.999089, train loss: 10.037383, valid precision: 0.880600, valid loss: 99.932698
epoch: 4552, train precision: 0.998778, train loss: 10.183882, valid precision: 0.874600, valid loss: 100.644174
epoch: 4553, train precision: 0.999156, train loss: 10.029840, valid precision: 0.877400, valid loss: 98.442058
epoch: 4554, train precision: 0.998956, train loss: 10.078766, valid precision: 0.879000, valid loss: 96.812665
epoch: 4555, train precision: 0.999178, train loss: 10.039355, valid precision: 0.874600, valid loss: 99.666184
epoch: 4556, train precision: 0.998800, train loss: 10.111871, valid precision: 0.875400, valid loss: 100.570422
epoch: 4557, train precision: 0.998978, train loss: 10.192807, valid precision: 0.871200, valid loss: 99.520760
epoch: 4558, train precision: 0.998756, train loss: 10.134694, valid precision: 0.875400, valid loss: 101.662867
epoch: 4559, train precision: 0.999244, train loss: 10.024077, valid precision: 0.876200, valid loss: 100.424742
epoch: 4560, train precision: 0.999022, train loss: 10.128414, valid precision: 0.874000, valid loss: 96.771047
epoch: 4561, train precision: 0.998867, train loss: 10.198678, valid precision: 0.876800, valid loss: 100.192398
epoch: 4562, train precision: 0.999200, train loss: 10.063805, valid precision: 0.876400, valid loss: 97.142010
epoch: 4563, train precision: 0.998822, train loss: 10.151215, valid precision: 0.875400, valid loss: 101.778741
epoch: 4564, train precision: 0.999022, train loss: 10.125816, valid precision: 0.879000, valid loss: 99.317110
epoch: 4565, train precision: 0.999089, train loss: 10.073992, valid precision: 0.876600, valid loss: 96.362090
epoch: 4566, train precision: 0.999378, train loss: 10.039404, valid precision: 0.875200, valid loss: 98.554364
epoch: 4567, train precision: 0.999333, train loss: 9.983154, valid precision: 0.874200, valid loss: 101.549053
epoch: 4568, train precision: 0.999133, train loss: 9.987508, valid precision: 0.872000, valid loss: 102.354843
epoch: 4569, train precision: 0.999178, train loss: 10.019363, valid precision: 0.875000, valid loss: 101.688209
epoch: 4570, train precision: 0.999000, train loss: 10.103771, valid precision: 0.874400, valid loss: 100.253493
epoch: 4571, train precision: 0.998933, train loss: 10.123452, valid precision: 0.866800, valid loss: 102.830697
epoch: 4572, train precision: 0.998889, train loss: 10.135090, valid precision: 0.869600, valid loss: 104.723953
epoch: 4573, train precision: 0.999133, train loss: 10.032886, valid precision: 0.872400, valid loss: 102.268811
epoch: 4574, train precision: 0.999244, train loss: 9.993437, valid precision: 0.876400, valid loss: 100.627176
epoch: 4575, train precision: 0.998689, train loss: 10.176777, valid precision: 0.871200, valid loss: 100.139537
epoch: 4576, train precision: 0.998844, train loss: 10.190626, valid precision: 0.876200, valid loss: 98.166855
epoch: 4577, train precision: 0.998889, train loss: 10.073858, valid precision: 0.872400, valid loss: 99.205416
epoch: 4578, train precision: 0.999178, train loss: 9.955488, valid precision: 0.877800, valid loss: 99.262459
epoch: 4579, train precision: 0.999200, train loss: 10.051118, valid precision: 0.878200, valid loss: 97.304179
epoch: 4580, train precision: 0.999000, train loss: 10.116587, valid precision: 0.873400, valid loss: 99.186245
epoch: 4581, train precision: 0.999422, train loss: 9.988405, valid precision: 0.874800, valid loss: 99.927556
epoch: 4582, train precision: 0.998711, train loss: 10.153879, valid precision: 0.876000, valid loss: 99.888324
epoch: 4583, train precision: 0.999067, train loss: 10.078580, valid precision: 0.874200, valid loss: 99.376742
epoch: 4584, train precision: 0.999000, train loss: 10.078082, valid precision: 0.872000, valid loss: 101.663485
epoch: 4585, train precision: 0.999022, train loss: 10.046471, valid precision: 0.871800, valid loss: 102.773628
epoch: 4586, train precision: 0.999156, train loss: 10.062188, valid precision: 0.870200, valid loss: 101.968678
epoch: 4587, train precision: 0.999156, train loss: 10.062444, valid precision: 0.874200, valid loss: 99.633830
epoch: 4588, train precision: 0.999156, train loss: 10.011643, valid precision: 0.877000, valid loss: 101.011758
epoch: 4589, train precision: 0.999067, train loss: 10.008976, valid precision: 0.874000, valid loss: 102.878743
epoch: 4590, train precision: 0.999156, train loss: 10.079717, valid precision: 0.874200, valid loss: 100.422922
epoch: 4591, train precision: 0.999022, train loss: 10.065793, valid precision: 0.869200, valid loss: 102.355011
epoch: 4592, train precision: 0.999356, train loss: 9.979749, valid precision: 0.871800, valid loss: 100.616415
epoch: 4593, train precision: 0.998911, train loss: 10.061816, valid precision: 0.875400, valid loss: 99.226750
epoch: 4594, train precision: 0.998933, train loss: 10.104383, valid precision: 0.873800, valid loss: 102.424514
epoch: 4595, train precision: 0.999244, train loss: 9.979205, valid precision: 0.874800, valid loss: 100.768679
epoch: 4596, train precision: 0.999156, train loss: 10.019169, valid precision: 0.871400, valid loss: 103.243675
epoch: 4597, train precision: 0.999022, train loss: 10.024609, valid precision: 0.870600, valid loss: 104.671704
epoch: 4598, train precision: 0.998889, train loss: 10.168197, valid precision: 0.875000, valid loss: 103.333512
epoch: 4599, train precision: 0.999022, train loss: 10.070938, valid precision: 0.871600, valid loss: 101.746604
epoch: 4600, train precision: 0.998756, train loss: 10.191647, valid precision: 0.874800, valid loss: 103.806541
epoch: 4601, train precision: 0.999089, train loss: 10.077113, valid precision: 0.873400, valid loss: 101.072072
epoch: 4602, train precision: 0.999156, train loss: 10.069942, valid precision: 0.870600, valid loss: 102.974270
epoch: 4603, train precision: 0.999044, train loss: 10.017467, valid precision: 0.872600, valid loss: 100.427111
epoch: 4604, train precision: 0.998867, train loss: 10.093841, valid precision: 0.871400, valid loss: 99.217853
epoch: 4605, train precision: 0.999044, train loss: 10.063819, valid precision: 0.876200, valid loss: 99.285948
epoch: 4606, train precision: 0.999089, train loss: 10.055230, valid precision: 0.873800, valid loss: 97.352587
epoch: 4607, train precision: 0.999022, train loss: 10.051798, valid precision: 0.874800, valid loss: 99.842028
epoch: 4608, train precision: 0.999089, train loss: 10.043432, valid precision: 0.876600, valid loss: 100.227576
epoch: 4609, train precision: 0.999089, train loss: 9.982624, valid precision: 0.874400, valid loss: 101.605534
epoch: 4610, train precision: 0.999111, train loss: 10.076078, valid precision: 0.873400, valid loss: 102.079387
epoch: 4611, train precision: 0.998956, train loss: 10.082784, valid precision: 0.875200, valid loss: 101.100377
epoch: 4612, train precision: 0.999111, train loss: 10.027482, valid precision: 0.875800, valid loss: 99.092943
epoch: 4613, train precision: 0.998911, train loss: 10.068970, valid precision: 0.875800, valid loss: 101.091906
epoch: 4614, train precision: 0.999200, train loss: 9.992667, valid precision: 0.874600, valid loss: 102.796134
epoch: 4615, train precision: 0.999000, train loss: 10.061115, valid precision: 0.876600, valid loss: 100.320561
epoch: 4616, train precision: 0.999089, train loss: 10.072199, valid precision: 0.872800, valid loss: 101.695183
epoch: 4617, train precision: 0.999200, train loss: 10.036377, valid precision: 0.871200, valid loss: 105.357871
epoch: 4618, train precision: 0.998911, train loss: 10.157512, valid precision: 0.871200, valid loss: 102.947307
epoch: 4619, train precision: 0.999289, train loss: 9.963013, valid precision: 0.875000, valid loss: 101.542862
epoch: 4620, train precision: 0.999333, train loss: 9.979629, valid precision: 0.878000, valid loss: 102.724037
epoch: 4621, train precision: 0.999244, train loss: 10.088267, valid precision: 0.871400, valid loss: 102.108290
epoch: 4622, train precision: 0.999200, train loss: 9.996193, valid precision: 0.871400, valid loss: 104.504804
epoch: 4623, train precision: 0.999133, train loss: 10.021879, valid precision: 0.878000, valid loss: 103.774998
epoch: 4624, train precision: 0.999556, train loss: 9.978970, valid precision: 0.877800, valid loss: 98.790737
epoch: 4625, train precision: 0.999178, train loss: 9.989593, valid precision: 0.877200, valid loss: 102.180146
epoch: 4626, train precision: 0.999111, train loss: 10.061163, valid precision: 0.870400, valid loss: 105.323865
epoch: 4627, train precision: 0.999178, train loss: 10.080972, valid precision: 0.872200, valid loss: 101.788059
epoch: 4628, train precision: 0.999400, train loss: 10.021321, valid precision: 0.876600, valid loss: 101.295477
epoch: 4629, train precision: 0.999156, train loss: 10.067463, valid precision: 0.876800, valid loss: 102.743136
epoch: 4630, train precision: 0.999333, train loss: 10.000109, valid precision: 0.874600, valid loss: 101.511914
epoch: 4631, train precision: 0.999178, train loss: 10.024000, valid precision: 0.874000, valid loss: 104.061201
epoch: 4632, train precision: 0.998800, train loss: 10.159070, valid precision: 0.875600, valid loss: 105.074573
epoch: 4633, train precision: 0.999067, train loss: 10.094038, valid precision: 0.875200, valid loss: 103.819632
epoch: 4634, train precision: 0.999356, train loss: 9.997599, valid precision: 0.878800, valid loss: 101.927427
epoch: 4635, train precision: 0.998800, train loss: 10.112546, valid precision: 0.876800, valid loss: 103.967500
epoch: 4636, train precision: 0.998800, train loss: 10.115700, valid precision: 0.878800, valid loss: 100.712739
epoch: 4637, train precision: 0.999067, train loss: 10.017410, valid precision: 0.878000, valid loss: 99.238214
epoch: 4638, train precision: 0.998978, train loss: 10.040671, valid precision: 0.875600, valid loss: 100.065889
epoch: 4639, train precision: 0.999289, train loss: 9.981317, valid precision: 0.874400, valid loss: 101.416049
epoch: 4640, train precision: 0.999156, train loss: 10.094368, valid precision: 0.873400, valid loss: 103.037255
epoch: 4641, train precision: 0.998778, train loss: 10.088708, valid precision: 0.874200, valid loss: 101.016181
epoch: 4642, train precision: 0.999089, train loss: 10.035169, valid precision: 0.873800, valid loss: 101.238755
epoch: 4643, train precision: 0.999200, train loss: 10.044018, valid precision: 0.872000, valid loss: 101.996009
epoch: 4644, train precision: 0.998933, train loss: 10.059383, valid precision: 0.874200, valid loss: 101.257274
epoch: 4645, train precision: 0.999044, train loss: 10.071396, valid precision: 0.872200, valid loss: 103.309742
epoch: 4646, train precision: 0.998956, train loss: 10.045169, valid precision: 0.873600, valid loss: 103.430069
epoch: 4647, train precision: 0.998689, train loss: 10.123906, valid precision: 0.874800, valid loss: 101.822814
epoch: 4648, train precision: 0.999200, train loss: 9.984150, valid precision: 0.877200, valid loss: 99.954166
epoch: 4649, train precision: 0.998756, train loss: 10.108793, valid precision: 0.871400, valid loss: 105.063349
epoch: 4650, train precision: 0.999311, train loss: 9.964740, valid precision: 0.869200, valid loss: 105.532212
epoch: 4651, train precision: 0.999111, train loss: 10.052895, valid precision: 0.869200, valid loss: 105.222513
epoch: 4652, train precision: 0.999178, train loss: 10.013299, valid precision: 0.870600, valid loss: 102.297058
epoch: 4653, train precision: 0.999022, train loss: 10.056946, valid precision: 0.871200, valid loss: 102.560460
epoch: 4654, train precision: 0.999044, train loss: 10.029491, valid precision: 0.873400, valid loss: 103.277013
epoch: 4655, train precision: 0.999222, train loss: 10.007757, valid precision: 0.872600, valid loss: 101.844194
epoch: 4656, train precision: 0.999067, train loss: 10.035639, valid precision: 0.871600, valid loss: 103.016728
epoch: 4657, train precision: 0.998978, train loss: 10.086311, valid precision: 0.873800, valid loss: 100.632020
epoch: 4658, train precision: 0.999289, train loss: 10.018178, valid precision: 0.872000, valid loss: 100.817789
epoch: 4659, train precision: 0.999156, train loss: 9.981504, valid precision: 0.871600, valid loss: 104.839543
epoch: 4660, train precision: 0.999267, train loss: 9.979269, valid precision: 0.871000, valid loss: 102.923941
epoch: 4661, train precision: 0.999178, train loss: 10.072721, valid precision: 0.866000, valid loss: 106.020023
epoch: 4662, train precision: 0.998844, train loss: 10.104512, valid precision: 0.864600, valid loss: 102.331072
epoch: 4663, train precision: 0.999022, train loss: 10.025233, valid precision: 0.869200, valid loss: 102.954920
epoch: 4664, train precision: 0.999311, train loss: 10.021581, valid precision: 0.872400, valid loss: 102.596962
epoch: 4665, train precision: 0.998733, train loss: 10.188571, valid precision: 0.865200, valid loss: 105.527912
epoch: 4666, train precision: 0.998822, train loss: 10.145998, valid precision: 0.868200, valid loss: 101.347643
epoch: 4667, train precision: 0.999222, train loss: 10.018689, valid precision: 0.871600, valid loss: 100.562736
epoch: 4668, train precision: 0.999133, train loss: 9.997965, valid precision: 0.874800, valid loss: 101.648862
epoch: 4669, train precision: 0.999022, train loss: 10.057273, valid precision: 0.869000, valid loss: 103.009809
epoch: 4670, train precision: 0.999489, train loss: 9.951623, valid precision: 0.875000, valid loss: 101.654385
epoch: 4671, train precision: 0.999044, train loss: 10.054359, valid precision: 0.874200, valid loss: 99.757369
epoch: 4672, train precision: 0.999356, train loss: 10.020452, valid precision: 0.874800, valid loss: 100.482371
epoch: 4673, train precision: 0.999222, train loss: 9.975255, valid precision: 0.870600, valid loss: 104.530119
epoch: 4674, train precision: 0.999222, train loss: 10.013261, valid precision: 0.869400, valid loss: 101.738639
epoch: 4675, train precision: 0.999378, train loss: 9.976750, valid precision: 0.871800, valid loss: 100.600775
epoch: 4676, train precision: 0.999111, train loss: 10.012171, valid precision: 0.874000, valid loss: 99.829877
epoch: 4677, train precision: 0.998867, train loss: 10.026811, valid precision: 0.873800, valid loss: 100.565190
epoch: 4678, train precision: 0.999200, train loss: 10.022419, valid precision: 0.866800, valid loss: 106.896251
epoch: 4679, train precision: 0.999022, train loss: 10.059389, valid precision: 0.871200, valid loss: 100.305724
epoch: 4680, train precision: 0.998689, train loss: 10.035047, valid precision: 0.874600, valid loss: 102.735012
epoch: 4681, train precision: 0.999378, train loss: 9.958200, valid precision: 0.876400, valid loss: 99.491874
epoch: 4682, train precision: 0.999156, train loss: 9.994229, valid precision: 0.873600, valid loss: 101.278867
epoch: 4683, train precision: 0.998844, train loss: 10.098569, valid precision: 0.877000, valid loss: 101.683155
epoch: 4684, train precision: 0.999000, train loss: 10.123673, valid precision: 0.874800, valid loss: 102.536426
epoch: 4685, train precision: 0.999578, train loss: 9.876374, valid precision: 0.874200, valid loss: 103.364326
epoch: 4686, train precision: 0.998889, train loss: 10.091479, valid precision: 0.874200, valid loss: 104.595426
epoch: 4687, train precision: 0.999089, train loss: 10.030125, valid precision: 0.873800, valid loss: 101.010696
epoch: 4688, train precision: 0.999178, train loss: 10.012072, valid precision: 0.874800, valid loss: 102.312917
epoch: 4689, train precision: 0.999222, train loss: 10.002580, valid precision: 0.873800, valid loss: 101.253855
epoch: 4690, train precision: 0.999356, train loss: 9.923216, valid precision: 0.874600, valid loss: 104.863005
epoch: 4691, train precision: 0.998622, train loss: 10.186571, valid precision: 0.873800, valid loss: 103.684975
epoch: 4692, train precision: 0.999200, train loss: 10.012446, valid precision: 0.873800, valid loss: 99.667473
epoch: 4693, train precision: 0.999400, train loss: 9.957872, valid precision: 0.874600, valid loss: 101.075732
epoch: 4694, train precision: 0.999244, train loss: 9.944332, valid precision: 0.873200, valid loss: 99.938934
epoch: 4695, train precision: 0.998867, train loss: 10.080201, valid precision: 0.873400, valid loss: 100.754932
epoch: 4696, train precision: 0.999022, train loss: 10.075226, valid precision: 0.873400, valid loss: 101.005346
epoch: 4697, train precision: 0.999089, train loss: 10.081879, valid precision: 0.873400, valid loss: 99.638406
epoch: 4698, train precision: 0.998800, train loss: 10.141520, valid precision: 0.873400, valid loss: 99.585508
epoch: 4699, train precision: 0.998933, train loss: 10.085560, valid precision: 0.873400, valid loss: 101.068908
epoch: 4700, train precision: 0.999356, train loss: 9.972342, valid precision: 0.875600, valid loss: 100.195467
epoch: 4701, train precision: 0.998933, train loss: 10.062075, valid precision: 0.876800, valid loss: 100.057794
epoch: 4702, train precision: 0.998867, train loss: 10.067374, valid precision: 0.875200, valid loss: 99.118400
epoch: 4703, train precision: 0.998956, train loss: 10.083863, valid precision: 0.873800, valid loss: 101.334775
epoch: 4704, train precision: 0.999311, train loss: 9.999134, valid precision: 0.875400, valid loss: 100.077002
epoch: 4705, train precision: 0.999000, train loss: 10.106499, valid precision: 0.875800, valid loss: 99.028431
epoch: 4706, train precision: 0.999244, train loss: 10.010061, valid precision: 0.874000, valid loss: 100.100045
epoch: 4707, train precision: 0.998933, train loss: 10.142480, valid precision: 0.874000, valid loss: 101.090364
epoch: 4708, train precision: 0.999089, train loss: 10.067574, valid precision: 0.874400, valid loss: 99.493687
epoch: 4709, train precision: 0.999289, train loss: 9.951102, valid precision: 0.874800, valid loss: 100.794675
epoch: 4710, train precision: 0.999000, train loss: 10.051971, valid precision: 0.873400, valid loss: 97.975144
epoch: 4711, train precision: 0.999267, train loss: 9.987213, valid precision: 0.872600, valid loss: 98.992488
epoch: 4712, train precision: 0.999133, train loss: 10.023271, valid precision: 0.875200, valid loss: 100.389473
epoch: 4713, train precision: 0.999089, train loss: 10.051685, valid precision: 0.873000, valid loss: 99.028057
epoch: 4714, train precision: 0.998689, train loss: 10.141059, valid precision: 0.870000, valid loss: 100.775337
epoch: 4715, train precision: 0.998956, train loss: 10.066880, valid precision: 0.874000, valid loss: 99.610932
epoch: 4716, train precision: 0.998689, train loss: 10.130396, valid precision: 0.873400, valid loss: 96.909530
epoch: 4717, train precision: 0.998778, train loss: 10.100485, valid precision: 0.871200, valid loss: 99.897423
epoch: 4718, train precision: 0.999089, train loss: 10.012405, valid precision: 0.870400, valid loss: 99.850198
epoch: 4719, train precision: 0.999267, train loss: 10.020285, valid precision: 0.878000, valid loss: 96.735100
epoch: 4720, train precision: 0.999289, train loss: 9.994483, valid precision: 0.875400, valid loss: 95.519793
epoch: 4721, train precision: 0.999178, train loss: 9.997716, valid precision: 0.873000, valid loss: 97.603448
epoch: 4722, train precision: 0.998778, train loss: 10.100509, valid precision: 0.876600, valid loss: 98.810770
epoch: 4723, train precision: 0.999222, train loss: 9.972294, valid precision: 0.876600, valid loss: 96.704953
epoch: 4724, train precision: 0.999089, train loss: 10.047725, valid precision: 0.875400, valid loss: 98.615571
epoch: 4725, train precision: 0.998822, train loss: 10.130078, valid precision: 0.877000, valid loss: 99.471211
epoch: 4726, train precision: 0.999044, train loss: 10.015132, valid precision: 0.874200, valid loss: 98.104985
epoch: 4727, train precision: 0.999111, train loss: 10.042723, valid precision: 0.878000, valid loss: 96.035079
epoch: 4728, train precision: 0.999133, train loss: 10.006377, valid precision: 0.878600, valid loss: 97.512925
epoch: 4729, train precision: 0.999022, train loss: 10.039653, valid precision: 0.875600, valid loss: 101.037235
epoch: 4730, train precision: 0.998822, train loss: 10.078916, valid precision: 0.870400, valid loss: 104.054619
epoch: 4731, train precision: 0.999133, train loss: 10.026564, valid precision: 0.874600, valid loss: 98.092489
epoch: 4732, train precision: 0.998933, train loss: 10.068178, valid precision: 0.875600, valid loss: 98.306106
epoch: 4733, train precision: 0.998756, train loss: 10.081271, valid precision: 0.877000, valid loss: 98.719226
epoch: 4734, train precision: 0.999067, train loss: 10.010626, valid precision: 0.876000, valid loss: 99.941795
epoch: 4735, train precision: 0.999111, train loss: 10.041940, valid precision: 0.876200, valid loss: 99.293331
epoch: 4736, train precision: 0.998933, train loss: 10.099449, valid precision: 0.870400, valid loss: 99.973669
epoch: 4737, train precision: 0.998933, train loss: 10.042765, valid precision: 0.870600, valid loss: 102.554836
epoch: 4738, train precision: 0.999133, train loss: 9.987971, valid precision: 0.874200, valid loss: 99.147048
epoch: 4739, train precision: 0.998778, train loss: 10.152039, valid precision: 0.867800, valid loss: 101.592683
epoch: 4740, train precision: 0.999289, train loss: 9.990426, valid precision: 0.873800, valid loss: 100.273166
epoch: 4741, train precision: 0.999067, train loss: 10.014936, valid precision: 0.874800, valid loss: 98.292342
epoch: 4742, train precision: 0.999000, train loss: 10.052878, valid precision: 0.868400, valid loss: 100.509438
epoch: 4743, train precision: 0.998644, train loss: 10.094831, valid precision: 0.871000, valid loss: 101.495598
epoch: 4744, train precision: 0.999156, train loss: 9.995143, valid precision: 0.873600, valid loss: 99.681684
epoch: 4745, train precision: 0.999178, train loss: 9.996154, valid precision: 0.872800, valid loss: 98.882736
epoch: 4746, train precision: 0.999022, train loss: 10.058898, valid precision: 0.869200, valid loss: 104.406595
epoch: 4747, train precision: 0.999289, train loss: 9.958874, valid precision: 0.872400, valid loss: 98.798668
epoch: 4748, train precision: 0.999200, train loss: 9.992168, valid precision: 0.872600, valid loss: 99.541765
epoch: 4749, train precision: 0.999333, train loss: 9.951991, valid precision: 0.874400, valid loss: 96.908539
epoch: 4750, train precision: 0.998667, train loss: 10.090916, valid precision: 0.876200, valid loss: 98.980920
epoch: 4751, train precision: 0.999378, train loss: 9.873460, valid precision: 0.875600, valid loss: 100.649562
epoch: 4752, train precision: 0.999089, train loss: 10.018993, valid precision: 0.867400, valid loss: 102.922736
epoch: 4753, train precision: 0.998889, train loss: 10.076336, valid precision: 0.863800, valid loss: 103.609808
epoch: 4754, train precision: 0.999289, train loss: 10.017165, valid precision: 0.872600, valid loss: 100.709908
epoch: 4755, train precision: 0.998822, train loss: 10.077550, valid precision: 0.872800, valid loss: 100.889723
epoch: 4756, train precision: 0.999022, train loss: 10.004994, valid precision: 0.869600, valid loss: 101.758224
epoch: 4757, train precision: 0.999378, train loss: 9.936421, valid precision: 0.869400, valid loss: 103.184125
epoch: 4758, train precision: 0.999089, train loss: 10.044551, valid precision: 0.868000, valid loss: 100.690200
epoch: 4759, train precision: 0.999133, train loss: 9.989455, valid precision: 0.872400, valid loss: 102.789844
epoch: 4760, train precision: 0.999311, train loss: 9.904581, valid precision: 0.867200, valid loss: 102.216649
epoch: 4761, train precision: 0.998778, train loss: 10.105543, valid precision: 0.874400, valid loss: 99.289769
epoch: 4762, train precision: 0.999267, train loss: 9.993767, valid precision: 0.873000, valid loss: 99.538230
epoch: 4763, train precision: 0.999000, train loss: 10.078328, valid precision: 0.873600, valid loss: 99.620196
epoch: 4764, train precision: 0.998911, train loss: 10.036454, valid precision: 0.871000, valid loss: 102.087837
epoch: 4765, train precision: 0.999489, train loss: 9.904588, valid precision: 0.873800, valid loss: 100.344866
epoch: 4766, train precision: 0.999156, train loss: 9.950209, valid precision: 0.875400, valid loss: 102.516736
epoch: 4767, train precision: 0.998867, train loss: 10.139458, valid precision: 0.873000, valid loss: 100.735221
epoch: 4768, train precision: 0.998867, train loss: 10.043777, valid precision: 0.871400, valid loss: 98.207906
epoch: 4769, train precision: 0.999089, train loss: 10.024480, valid precision: 0.872000, valid loss: 99.705333
epoch: 4770, train precision: 0.998756, train loss: 10.104345, valid precision: 0.872600, valid loss: 102.046419
epoch: 4771, train precision: 0.999244, train loss: 10.024299, valid precision: 0.874200, valid loss: 100.359426
epoch: 4772, train precision: 0.999289, train loss: 9.936893, valid precision: 0.876800, valid loss: 98.127218
epoch: 4773, train precision: 0.999089, train loss: 9.957620, valid precision: 0.875400, valid loss: 97.928174
epoch: 4774, train precision: 0.999111, train loss: 10.028653, valid precision: 0.871000, valid loss: 98.556790
epoch: 4775, train precision: 0.999289, train loss: 9.988912, valid precision: 0.873800, valid loss: 99.095220
epoch: 4776, train precision: 0.998422, train loss: 10.197898, valid precision: 0.871000, valid loss: 101.698452
epoch: 4777, train precision: 0.998844, train loss: 10.034941, valid precision: 0.872000, valid loss: 102.870453
epoch: 4778, train precision: 0.999222, train loss: 9.984166, valid precision: 0.868000, valid loss: 103.986833
epoch: 4779, train precision: 0.999200, train loss: 9.985047, valid precision: 0.875400, valid loss: 103.320111
epoch: 4780, train precision: 0.999267, train loss: 10.009877, valid precision: 0.874200, valid loss: 100.554099
epoch: 4781, train precision: 0.999267, train loss: 10.004716, valid precision: 0.873600, valid loss: 99.803217
epoch: 4782, train precision: 0.998844, train loss: 10.073677, valid precision: 0.870800, valid loss: 102.646591
epoch: 4783, train precision: 0.999156, train loss: 9.941576, valid precision: 0.871000, valid loss: 103.434504
epoch: 4784, train precision: 0.998800, train loss: 10.034154, valid precision: 0.872200, valid loss: 101.246483
epoch: 4785, train precision: 0.998467, train loss: 10.178193, valid precision: 0.875400, valid loss: 104.084909
epoch: 4786, train precision: 0.999244, train loss: 9.977661, valid precision: 0.874200, valid loss: 100.854431
epoch: 4787, train precision: 0.999044, train loss: 10.019321, valid precision: 0.873000, valid loss: 100.776309
epoch: 4788, train precision: 0.999067, train loss: 10.025704, valid precision: 0.873000, valid loss: 101.223056
epoch: 4789, train precision: 0.999267, train loss: 9.965676, valid precision: 0.870800, valid loss: 99.734198
epoch: 4790, train precision: 0.999267, train loss: 9.940523, valid precision: 0.871800, valid loss: 97.686125
epoch: 4791, train precision: 0.999311, train loss: 9.932437, valid precision: 0.879200, valid loss: 97.765448
epoch: 4792, train precision: 0.998778, train loss: 10.110485, valid precision: 0.875400, valid loss: 99.487567
epoch: 4793, train precision: 0.999267, train loss: 9.970879, valid precision: 0.878400, valid loss: 98.385782
epoch: 4794, train precision: 0.998933, train loss: 10.105452, valid precision: 0.871400, valid loss: 101.598132
epoch: 4795, train precision: 0.998844, train loss: 10.100858, valid precision: 0.873400, valid loss: 97.329851
epoch: 4796, train precision: 0.998867, train loss: 10.159584, valid precision: 0.874600, valid loss: 99.721378
epoch: 4797, train precision: 0.999200, train loss: 9.977627, valid precision: 0.875000, valid loss: 98.643498
epoch: 4798, train precision: 0.998978, train loss: 10.010531, valid precision: 0.873000, valid loss: 99.914911
epoch: 4799, train precision: 0.999400, train loss: 9.953577, valid precision: 0.871200, valid loss: 97.321598
epoch: 4800, train precision: 0.998956, train loss: 10.108699, valid precision: 0.873600, valid loss: 100.603448
epoch: 4801, train precision: 0.999044, train loss: 10.004378, valid precision: 0.874400, valid loss: 98.645933
epoch: 4802, train precision: 0.998711, train loss: 10.142433, valid precision: 0.875800, valid loss: 100.824315
epoch: 4803, train precision: 0.999044, train loss: 9.980099, valid precision: 0.873800, valid loss: 98.572819
epoch: 4804, train precision: 0.999156, train loss: 9.968790, valid precision: 0.877400, valid loss: 99.378010
epoch: 4805, train precision: 0.998911, train loss: 10.056597, valid precision: 0.872800, valid loss: 101.652213
epoch: 4806, train precision: 0.999133, train loss: 9.977998, valid precision: 0.873000, valid loss: 103.009838
epoch: 4807, train precision: 0.999067, train loss: 10.004387, valid precision: 0.876400, valid loss: 102.096667
epoch: 4808, train precision: 0.999067, train loss: 10.017420, valid precision: 0.875600, valid loss: 97.535012
epoch: 4809, train precision: 0.999289, train loss: 9.983276, valid precision: 0.873800, valid loss: 97.499204
epoch: 4810, train precision: 0.999067, train loss: 9.998962, valid precision: 0.875200, valid loss: 101.918692
epoch: 4811, train precision: 0.998933, train loss: 10.049984, valid precision: 0.872000, valid loss: 96.757628
epoch: 4812, train precision: 0.999200, train loss: 9.975784, valid precision: 0.877000, valid loss: 96.018901
epoch: 4813, train precision: 0.999067, train loss: 10.056018, valid precision: 0.872400, valid loss: 99.249482
epoch: 4814, train precision: 0.998956, train loss: 10.082880, valid precision: 0.874800, valid loss: 98.344749
epoch: 4815, train precision: 0.999044, train loss: 10.023193, valid precision: 0.876000, valid loss: 99.628760
epoch: 4816, train precision: 0.999311, train loss: 9.928626, valid precision: 0.873400, valid loss: 102.881807
epoch: 4817, train precision: 0.999311, train loss: 9.969162, valid precision: 0.869400, valid loss: 103.009398
epoch: 4818, train precision: 0.999156, train loss: 9.965684, valid precision: 0.875200, valid loss: 102.393225
epoch: 4819, train precision: 0.999067, train loss: 10.084198, valid precision: 0.874400, valid loss: 100.873675
epoch: 4820, train precision: 0.999311, train loss: 9.931680, valid precision: 0.874400, valid loss: 104.243553
epoch: 4821, train precision: 0.998600, train loss: 10.140225, valid precision: 0.869400, valid loss: 104.224612
epoch: 4822, train precision: 0.999111, train loss: 10.056589, valid precision: 0.873000, valid loss: 101.231303
epoch: 4823, train precision: 0.998933, train loss: 10.089194, valid precision: 0.866000, valid loss: 102.389989
epoch: 4824, train precision: 0.999244, train loss: 10.017621, valid precision: 0.869800, valid loss: 99.003414
epoch: 4825, train precision: 0.999378, train loss: 9.935552, valid precision: 0.874800, valid loss: 99.789725
epoch: 4826, train precision: 0.999267, train loss: 10.019710, valid precision: 0.873600, valid loss: 99.741588
epoch: 4827, train precision: 0.999111, train loss: 9.979679, valid precision: 0.873600, valid loss: 100.127802
epoch: 4828, train precision: 0.999133, train loss: 9.995384, valid precision: 0.870800, valid loss: 99.543963
epoch: 4829, train precision: 0.999044, train loss: 9.969451, valid precision: 0.875400, valid loss: 101.756404
epoch: 4830, train precision: 0.999222, train loss: 9.978288, valid precision: 0.878600, valid loss: 97.652760
epoch: 4831, train precision: 0.999022, train loss: 10.021334, valid precision: 0.875400, valid loss: 100.980369
epoch: 4832, train precision: 0.999156, train loss: 9.998685, valid precision: 0.871600, valid loss: 99.566850
epoch: 4833, train precision: 0.999156, train loss: 10.003792, valid precision: 0.874600, valid loss: 96.959522
epoch: 4834, train precision: 0.999244, train loss: 9.946186, valid precision: 0.875400, valid loss: 98.705484
epoch: 4835, train precision: 0.999089, train loss: 10.074457, valid precision: 0.872800, valid loss: 98.186944
epoch: 4836, train precision: 0.998956, train loss: 10.093866, valid precision: 0.869600, valid loss: 97.337775
epoch: 4837, train precision: 0.998956, train loss: 10.072476, valid precision: 0.876200, valid loss: 97.068676
epoch: 4838, train precision: 0.999156, train loss: 9.994211, valid precision: 0.872800, valid loss: 97.953821
epoch: 4839, train precision: 0.998844, train loss: 10.106747, valid precision: 0.871400, valid loss: 98.198508
epoch: 4840, train precision: 0.999089, train loss: 9.987226, valid precision: 0.873600, valid loss: 96.202419
epoch: 4841, train precision: 0.999267, train loss: 9.936821, valid precision: 0.872800, valid loss: 98.121442
epoch: 4842, train precision: 0.999022, train loss: 10.005419, valid precision: 0.872800, valid loss: 99.393498
epoch: 4843, train precision: 0.999156, train loss: 9.957032, valid precision: 0.872000, valid loss: 99.065710
epoch: 4844, train precision: 0.998733, train loss: 10.035583, valid precision: 0.872200, valid loss: 101.309622
epoch: 4845, train precision: 0.998756, train loss: 10.049217, valid precision: 0.870400, valid loss: 100.703568
epoch: 4846, train precision: 0.999133, train loss: 10.011808, valid precision: 0.873600, valid loss: 100.394196
epoch: 4847, train precision: 0.999200, train loss: 10.014921, valid precision: 0.870000, valid loss: 98.044357
epoch: 4848, train precision: 0.999133, train loss: 10.036415, valid precision: 0.872400, valid loss: 97.736957
epoch: 4849, train precision: 0.998933, train loss: 10.028957, valid precision: 0.869000, valid loss: 101.990855
epoch: 4850, train precision: 0.998956, train loss: 10.032802, valid precision: 0.871400, valid loss: 101.659721
epoch: 4851, train precision: 0.999111, train loss: 9.985909, valid precision: 0.875800, valid loss: 98.381440
epoch: 4852, train precision: 0.998956, train loss: 10.025666, valid precision: 0.871600, valid loss: 100.617572
epoch: 4853, train precision: 0.999089, train loss: 10.030786, valid precision: 0.871600, valid loss: 99.588918
epoch: 4854, train precision: 0.999311, train loss: 9.952868, valid precision: 0.877200, valid loss: 100.241084
epoch: 4855, train precision: 0.998933, train loss: 10.121636, valid precision: 0.870800, valid loss: 101.198961
epoch: 4856, train precision: 0.999022, train loss: 10.040386, valid precision: 0.873600, valid loss: 98.580275
epoch: 4857, train precision: 0.999089, train loss: 10.022119, valid precision: 0.873600, valid loss: 98.324084
epoch: 4858, train precision: 0.999111, train loss: 10.035557, valid precision: 0.873800, valid loss: 98.530261
epoch: 4859, train precision: 0.999244, train loss: 10.001054, valid precision: 0.865400, valid loss: 101.489659
epoch: 4860, train precision: 0.999089, train loss: 9.996121, valid precision: 0.875000, valid loss: 101.562976
epoch: 4861, train precision: 0.999178, train loss: 10.046776, valid precision: 0.873200, valid loss: 98.206710
epoch: 4862, train precision: 0.999022, train loss: 9.994174, valid precision: 0.871400, valid loss: 103.062361
epoch: 4863, train precision: 0.998911, train loss: 10.088759, valid precision: 0.871800, valid loss: 100.532578
epoch: 4864, train precision: 0.999067, train loss: 10.034811, valid precision: 0.874200, valid loss: 98.989764
epoch: 4865, train precision: 0.998978, train loss: 10.004389, valid precision: 0.874000, valid loss: 101.658337
epoch: 4866, train precision: 0.999244, train loss: 10.012555, valid precision: 0.870800, valid loss: 102.306126
epoch: 4867, train precision: 0.999222, train loss: 10.009140, valid precision: 0.878600, valid loss: 99.491773
epoch: 4868, train precision: 0.998911, train loss: 10.079755, valid precision: 0.874200, valid loss: 101.954045
epoch: 4869, train precision: 0.999178, train loss: 10.071277, valid precision: 0.876800, valid loss: 98.600420
epoch: 4870, train precision: 0.999244, train loss: 9.923726, valid precision: 0.878000, valid loss: 99.114497
epoch: 4871, train precision: 0.999067, train loss: 10.072422, valid precision: 0.876000, valid loss: 99.878615
epoch: 4872, train precision: 0.999044, train loss: 10.009298, valid precision: 0.871400, valid loss: 103.622528
epoch: 4873, train precision: 0.999422, train loss: 9.941923, valid precision: 0.872600, valid loss: 100.264460
epoch: 4874, train precision: 0.999311, train loss: 9.962097, valid precision: 0.876200, valid loss: 102.635518
epoch: 4875, train precision: 0.998467, train loss: 10.143417, valid precision: 0.876800, valid loss: 101.503677
epoch: 4876, train precision: 0.998978, train loss: 10.037251, valid precision: 0.872000, valid loss: 103.400986
epoch: 4877, train precision: 0.999067, train loss: 10.029125, valid precision: 0.874800, valid loss: 102.432897
epoch: 4878, train precision: 0.999156, train loss: 10.024671, valid precision: 0.876600, valid loss: 101.547603
epoch: 4879, train precision: 0.999333, train loss: 9.928436, valid precision: 0.876000, valid loss: 100.807789
epoch: 4880, train precision: 0.999089, train loss: 9.973833, valid precision: 0.877000, valid loss: 102.299806
epoch: 4881, train precision: 0.999133, train loss: 9.985279, valid precision: 0.874400, valid loss: 103.794151
epoch: 4882, train precision: 0.999267, train loss: 9.959036, valid precision: 0.874600, valid loss: 99.203604
epoch: 4883, train precision: 0.999000, train loss: 10.006309, valid precision: 0.878400, valid loss: 102.310567
epoch: 4884, train precision: 0.999067, train loss: 9.997728, valid precision: 0.875400, valid loss: 101.634324
epoch: 4885, train precision: 0.999111, train loss: 10.052110, valid precision: 0.872200, valid loss: 100.432978
epoch: 4886, train precision: 0.999289, train loss: 9.997738, valid precision: 0.874000, valid loss: 100.301768
epoch: 4887, train precision: 0.999267, train loss: 9.955750, valid precision: 0.874400, valid loss: 100.576781
epoch: 4888, train precision: 0.999022, train loss: 10.017579, valid precision: 0.870600, valid loss: 105.606308
epoch: 4889, train precision: 0.998933, train loss: 10.049104, valid precision: 0.874400, valid loss: 101.741183
epoch: 4890, train precision: 0.998844, train loss: 10.054789, valid precision: 0.871400, valid loss: 104.387476
epoch: 4891, train precision: 0.999156, train loss: 9.986907, valid precision: 0.871600, valid loss: 101.277214
epoch: 4892, train precision: 0.999378, train loss: 9.889553, valid precision: 0.874400, valid loss: 103.089228
epoch: 4893, train precision: 0.999111, train loss: 9.964478, valid precision: 0.873400, valid loss: 101.575526
epoch: 4894, train precision: 0.998911, train loss: 10.091484, valid precision: 0.873600, valid loss: 103.860660
epoch: 4895, train precision: 0.998978, train loss: 10.034239, valid precision: 0.874600, valid loss: 104.556463
epoch: 4896, train precision: 0.999156, train loss: 10.041689, valid precision: 0.875000, valid loss: 103.142543
epoch: 4897, train precision: 0.999556, train loss: 9.843175, valid precision: 0.876400, valid loss: 104.611408
epoch: 4898, train precision: 0.999000, train loss: 9.975554, valid precision: 0.870600, valid loss: 102.594107
epoch: 4899, train precision: 0.999400, train loss: 9.888129, valid precision: 0.875400, valid loss: 103.511002
epoch: 4900, train precision: 0.999222, train loss: 9.997285, valid precision: 0.872800, valid loss: 104.135858
epoch: 4901, train precision: 0.999156, train loss: 9.958103, valid precision: 0.871600, valid loss: 101.793915
epoch: 4902, train precision: 0.999311, train loss: 9.936868, valid precision: 0.872000, valid loss: 103.591465
epoch: 4903, train precision: 0.999311, train loss: 9.940102, valid precision: 0.873400, valid loss: 99.767418
epoch: 4904, train precision: 0.998911, train loss: 10.047063, valid precision: 0.871400, valid loss: 103.718220
epoch: 4905, train precision: 0.999044, train loss: 10.064352, valid precision: 0.870200, valid loss: 100.385602
epoch: 4906, train precision: 0.999222, train loss: 9.959998, valid precision: 0.873000, valid loss: 99.522443
epoch: 4907, train precision: 0.999044, train loss: 10.039760, valid precision: 0.871800, valid loss: 100.813033
epoch: 4908, train precision: 0.998978, train loss: 10.092424, valid precision: 0.873000, valid loss: 100.427268
epoch: 4909, train precision: 0.999067, train loss: 9.945484, valid precision: 0.873400, valid loss: 101.629710
epoch: 4910, train precision: 0.998644, train loss: 10.094502, valid precision: 0.871600, valid loss: 104.436368
epoch: 4911, train precision: 0.999133, train loss: 9.971127, valid precision: 0.874400, valid loss: 98.753153
epoch: 4912, train precision: 0.999222, train loss: 9.993381, valid precision: 0.871400, valid loss: 102.562468
epoch: 4913, train precision: 0.999311, train loss: 9.906616, valid precision: 0.872800, valid loss: 103.401843
epoch: 4914, train precision: 0.999267, train loss: 9.927868, valid precision: 0.875600, valid loss: 102.914384
epoch: 4915, train precision: 0.998911, train loss: 10.010766, valid precision: 0.870000, valid loss: 104.724911
epoch: 4916, train precision: 0.999200, train loss: 9.914752, valid precision: 0.873200, valid loss: 100.448434
epoch: 4917, train precision: 0.999133, train loss: 9.967074, valid precision: 0.874600, valid loss: 100.683374
epoch: 4918, train precision: 0.999044, train loss: 9.959633, valid precision: 0.876200, valid loss: 102.152860
epoch: 4919, train precision: 0.998978, train loss: 10.073779, valid precision: 0.872000, valid loss: 102.774170
epoch: 4920, train precision: 0.999111, train loss: 9.996303, valid precision: 0.878800, valid loss: 102.247284
epoch: 4921, train precision: 0.999044, train loss: 10.000105, valid precision: 0.873200, valid loss: 102.909156
epoch: 4922, train precision: 0.999267, train loss: 9.946163, valid precision: 0.872000, valid loss: 103.118449
epoch: 4923, train precision: 0.999000, train loss: 10.027621, valid precision: 0.874200, valid loss: 101.227492
epoch: 4924, train precision: 0.999111, train loss: 10.009258, valid precision: 0.874200, valid loss: 99.619893
epoch: 4925, train precision: 0.998689, train loss: 10.164141, valid precision: 0.872800, valid loss: 103.239631
epoch: 4926, train precision: 0.999311, train loss: 9.978257, valid precision: 0.873800, valid loss: 99.262479
epoch: 4927, train precision: 0.998711, train loss: 10.172930, valid precision: 0.869400, valid loss: 101.922602
epoch: 4928, train precision: 0.999133, train loss: 9.979601, valid precision: 0.874800, valid loss: 100.299328
epoch: 4929, train precision: 0.999333, train loss: 9.921623, valid precision: 0.876800, valid loss: 98.882354
epoch: 4930, train precision: 0.999222, train loss: 9.921093, valid precision: 0.875400, valid loss: 100.380544
epoch: 4931, train precision: 0.998600, train loss: 10.122378, valid precision: 0.872600, valid loss: 100.479718
epoch: 4932, train precision: 0.998889, train loss: 10.060440, valid precision: 0.877600, valid loss: 99.241533
epoch: 4933, train precision: 0.999044, train loss: 9.960035, valid precision: 0.877400, valid loss: 100.868583
epoch: 4934, train precision: 0.999000, train loss: 10.069424, valid precision: 0.874800, valid loss: 102.376481
epoch: 4935, train precision: 0.999067, train loss: 10.015456, valid precision: 0.875200, valid loss: 100.578786
epoch: 4936, train precision: 0.998911, train loss: 10.038475, valid precision: 0.873800, valid loss: 99.670723
epoch: 4937, train precision: 0.999178, train loss: 9.977292, valid precision: 0.878000, valid loss: 99.953920
epoch: 4938, train precision: 0.999222, train loss: 9.982640, valid precision: 0.879000, valid loss: 98.976250
epoch: 4939, train precision: 0.999356, train loss: 9.911045, valid precision: 0.876000, valid loss: 100.245009
epoch: 4940, train precision: 0.999000, train loss: 9.979805, valid precision: 0.874800, valid loss: 100.708497
epoch: 4941, train precision: 0.999378, train loss: 9.918883, valid precision: 0.874600, valid loss: 98.484213
epoch: 4942, train precision: 0.999289, train loss: 9.958739, valid precision: 0.874000, valid loss: 99.187223
epoch: 4943, train precision: 0.999267, train loss: 9.972701, valid precision: 0.875200, valid loss: 98.597341
epoch: 4944, train precision: 0.999089, train loss: 9.973652, valid precision: 0.875200, valid loss: 98.149696
epoch: 4945, train precision: 0.999133, train loss: 9.987623, valid precision: 0.872800, valid loss: 100.071631
epoch: 4946, train precision: 0.999311, train loss: 9.952666, valid precision: 0.878400, valid loss: 96.455681
epoch: 4947, train precision: 0.999178, train loss: 9.921756, valid precision: 0.873800, valid loss: 100.820219
epoch: 4948, train precision: 0.999044, train loss: 10.031808, valid precision: 0.872400, valid loss: 101.670543
epoch: 4949, train precision: 0.999289, train loss: 9.899651, valid precision: 0.873400, valid loss: 98.807402
epoch: 4950, train precision: 0.999178, train loss: 9.909736, valid precision: 0.873200, valid loss: 100.782445
epoch: 4951, train precision: 0.999178, train loss: 9.965152, valid precision: 0.870600, valid loss: 100.748395
epoch: 4952, train precision: 0.999000, train loss: 10.001633, valid precision: 0.872600, valid loss: 104.033519
epoch: 4953, train precision: 0.999022, train loss: 10.025514, valid precision: 0.874600, valid loss: 100.903280
epoch: 4954, train precision: 0.999267, train loss: 9.952260, valid precision: 0.874200, valid loss: 100.912238
epoch: 4955, train precision: 0.999022, train loss: 10.042954, valid precision: 0.872000, valid loss: 100.759038
epoch: 4956, train precision: 0.999022, train loss: 10.029999, valid precision: 0.873200, valid loss: 101.008489
epoch: 4957, train precision: 0.999067, train loss: 10.025772, valid precision: 0.870400, valid loss: 103.872016
epoch: 4958, train precision: 0.998867, train loss: 10.052350, valid precision: 0.872600, valid loss: 101.974635
epoch: 4959, train precision: 0.999044, train loss: 10.017222, valid precision: 0.872200, valid loss: 103.094870
epoch: 4960, train precision: 0.998578, train loss: 10.145415, valid precision: 0.871600, valid loss: 102.071838
epoch: 4961, train precision: 0.999133, train loss: 9.982949, valid precision: 0.878600, valid loss: 99.857488
epoch: 4962, train precision: 0.998978, train loss: 9.982863, valid precision: 0.879400, valid loss: 99.225404
epoch: 4963, train precision: 0.999156, train loss: 9.988868, valid precision: 0.875600, valid loss: 99.300180
epoch: 4964, train precision: 0.999067, train loss: 9.991465, valid precision: 0.875200, valid loss: 100.413252
epoch: 4965, train precision: 0.998844, train loss: 10.107584, valid precision: 0.880200, valid loss: 97.345811
epoch: 4966, train precision: 0.999311, train loss: 9.896928, valid precision: 0.877600, valid loss: 99.633477
epoch: 4967, train precision: 0.999244, train loss: 9.919561, valid precision: 0.875000, valid loss: 98.944385
epoch: 4968, train precision: 0.998956, train loss: 10.080446, valid precision: 0.874800, valid loss: 96.963963
epoch: 4969, train precision: 0.999267, train loss: 9.940129, valid precision: 0.877000, valid loss: 97.924878
epoch: 4970, train precision: 0.999067, train loss: 10.012831, valid precision: 0.869400, valid loss: 101.974578
epoch: 4971, train precision: 0.998889, train loss: 10.030972, valid precision: 0.871200, valid loss: 100.533203
epoch: 4972, train precision: 0.998867, train loss: 10.059203, valid precision: 0.875200, valid loss: 99.633810
epoch: 4973, train precision: 0.998911, train loss: 10.049125, valid precision: 0.869400, valid loss: 101.828352
epoch: 4974, train precision: 0.999289, train loss: 9.943842, valid precision: 0.875600, valid loss: 101.192933
epoch: 4975, train precision: 0.998978, train loss: 10.021229, valid precision: 0.875600, valid loss: 101.549749
epoch: 4976, train precision: 0.998778, train loss: 10.112612, valid precision: 0.877800, valid loss: 100.995985
epoch: 4977, train precision: 0.999111, train loss: 10.016572, valid precision: 0.880400, valid loss: 100.193469
epoch: 4978, train precision: 0.998978, train loss: 10.016585, valid precision: 0.879200, valid loss: 101.403650
epoch: 4979, train precision: 0.998800, train loss: 10.107570, valid precision: 0.873200, valid loss: 100.361459
epoch: 4980, train precision: 0.999311, train loss: 9.948114, valid precision: 0.880000, valid loss: 99.051283
epoch: 4981, train precision: 0.999356, train loss: 9.964493, valid precision: 0.875200, valid loss: 98.857388
epoch: 4982, train precision: 0.999222, train loss: 9.985581, valid precision: 0.873200, valid loss: 101.176686
epoch: 4983, train precision: 0.999178, train loss: 9.964476, valid precision: 0.873600, valid loss: 99.114497
epoch: 4984, train precision: 0.999022, train loss: 10.004189, valid precision: 0.872800, valid loss: 102.798457
epoch: 4985, train precision: 0.998822, train loss: 10.099010, valid precision: 0.872200, valid loss: 104.798355
epoch: 4986, train precision: 0.999267, train loss: 9.987861, valid precision: 0.877200, valid loss: 100.568369
epoch: 4987, train precision: 0.999022, train loss: 10.054215, valid precision: 0.874800, valid loss: 98.475742
epoch: 4988, train precision: 0.998933, train loss: 10.031472, valid precision: 0.872800, valid loss: 101.244005
epoch: 4989, train precision: 0.999067, train loss: 10.016041, valid precision: 0.874200, valid loss: 100.470621
epoch: 4990, train precision: 0.998867, train loss: 10.043644, valid precision: 0.873000, valid loss: 100.204935
epoch: 4991, train precision: 0.999333, train loss: 9.916076, valid precision: 0.875400, valid loss: 100.396228
epoch: 4992, train precision: 0.999400, train loss: 9.856865, valid precision: 0.878400, valid loss: 97.503184
epoch: 4993, train precision: 0.999044, train loss: 9.999203, valid precision: 0.875000, valid loss: 101.747188
epoch: 4994, train precision: 0.999111, train loss: 9.963900, valid precision: 0.877600, valid loss: 96.704659
epoch: 4995, train precision: 0.998933, train loss: 10.043272, valid precision: 0.874400, valid loss: 99.525395
epoch: 4996, train precision: 0.998933, train loss: 10.045466, valid precision: 0.874400, valid loss: 97.550735
epoch: 4997, train precision: 0.999200, train loss: 9.960719, valid precision: 0.878200, valid loss: 96.715813
epoch: 4998, train precision: 0.999333, train loss: 9.915492, valid precision: 0.878000, valid loss: 94.002534
epoch: 4999, train precision: 0.998800, train loss: 10.099451, valid precision: 0.875600, valid loss: 96.526944
epoch: 5000, train precision: 0.998822, train loss: 10.113018, valid precision: 0.878200, valid loss: 96.750120
