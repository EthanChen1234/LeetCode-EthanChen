nohup: ignoring input
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:02:00.0
Total memory: 11.90GiB
Free memory: 6.76GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0)
epoch: 0, train precision: 0.591178, train loss: 165.828884, valid precision: 0.606200, valid loss: 161.205688
epoch: 1, train precision: 0.669044, train loss: 135.146415, valid precision: 0.675600, valid loss: 131.782451
epoch: 2, train precision: 0.720422, train loss: 114.561645, valid precision: 0.720200, valid loss: 112.902497
epoch: 3, train precision: 0.755356, train loss: 100.353768, valid precision: 0.750600, valid loss: 101.482738
epoch: 4, train precision: 0.777222, train loss: 90.843918, valid precision: 0.758000, valid loss: 94.712639
epoch: 5, train precision: 0.791444, train loss: 84.317604, valid precision: 0.777800, valid loss: 89.135103
epoch: 6, train precision: 0.797133, train loss: 81.304261, valid precision: 0.772800, valid loss: 87.529231
epoch: 7, train precision: 0.822578, train loss: 72.947290, valid precision: 0.785000, valid loss: 81.347575
epoch: 8, train precision: 0.826489, train loss: 70.295006, valid precision: 0.797000, valid loss: 78.687832
epoch: 9, train precision: 0.835622, train loss: 66.318782, valid precision: 0.794200, valid loss: 76.428543
epoch: 10, train precision: 0.854022, train loss: 60.396441, valid precision: 0.815400, valid loss: 71.773138
epoch: 11, train precision: 0.857956, train loss: 58.831598, valid precision: 0.813800, valid loss: 71.597704
epoch: 12, train precision: 0.864667, train loss: 55.761705, valid precision: 0.814200, valid loss: 69.637164
epoch: 13, train precision: 0.866911, train loss: 54.403364, valid precision: 0.822800, valid loss: 69.360605
epoch: 14, train precision: 0.876756, train loss: 50.989423, valid precision: 0.822800, valid loss: 67.939261
epoch: 15, train precision: 0.884022, train loss: 48.713151, valid precision: 0.826800, valid loss: 65.319515
epoch: 16, train precision: 0.884867, train loss: 47.774813, valid precision: 0.826000, valid loss: 66.166112
epoch: 17, train precision: 0.889533, train loss: 46.193442, valid precision: 0.825400, valid loss: 65.369189
epoch: 18, train precision: 0.897289, train loss: 43.551277, valid precision: 0.831000, valid loss: 63.881966
epoch: 19, train precision: 0.898044, train loss: 43.139087, valid precision: 0.833000, valid loss: 63.537688
epoch: 20, train precision: 0.905467, train loss: 40.663555, valid precision: 0.835000, valid loss: 61.216253
epoch: 21, train precision: 0.907800, train loss: 39.505786, valid precision: 0.836200, valid loss: 61.721974
epoch: 22, train precision: 0.906578, train loss: 39.491206, valid precision: 0.837800, valid loss: 62.747715
epoch: 23, train precision: 0.917222, train loss: 36.128835, valid precision: 0.840400, valid loss: 60.573812
epoch: 24, train precision: 0.921333, train loss: 34.990896, valid precision: 0.841200, valid loss: 60.134585
epoch: 25, train precision: 0.926733, train loss: 33.170433, valid precision: 0.839400, valid loss: 60.054458
epoch: 26, train precision: 0.927556, train loss: 32.604929, valid precision: 0.845400, valid loss: 59.992546
epoch: 27, train precision: 0.927222, train loss: 32.823976, valid precision: 0.845600, valid loss: 59.280285
epoch: 28, train precision: 0.926467, train loss: 32.954716, valid precision: 0.844600, valid loss: 61.161928
epoch: 29, train precision: 0.932511, train loss: 30.864500, valid precision: 0.844200, valid loss: 59.275098
epoch: 30, train precision: 0.939467, train loss: 28.943248, valid precision: 0.847400, valid loss: 59.594354
epoch: 31, train precision: 0.940022, train loss: 28.176395, valid precision: 0.844600, valid loss: 58.931168
epoch: 32, train precision: 0.941400, train loss: 27.525993, valid precision: 0.845400, valid loss: 59.028950
epoch: 33, train precision: 0.944089, train loss: 26.964498, valid precision: 0.847000, valid loss: 58.322444
epoch: 34, train precision: 0.943733, train loss: 26.845550, valid precision: 0.846800, valid loss: 57.459771
epoch: 35, train precision: 0.940400, train loss: 27.129394, valid precision: 0.846000, valid loss: 60.390893
epoch: 36, train precision: 0.942911, train loss: 26.868337, valid precision: 0.850800, valid loss: 58.348904
epoch: 37, train precision: 0.946533, train loss: 25.479435, valid precision: 0.853600, valid loss: 56.834108
epoch: 38, train precision: 0.949622, train loss: 24.744142, valid precision: 0.848600, valid loss: 58.963585
epoch: 39, train precision: 0.952422, train loss: 23.809358, valid precision: 0.848200, valid loss: 59.844100
epoch: 40, train precision: 0.955311, train loss: 22.932919, valid precision: 0.850400, valid loss: 58.440894
epoch: 41, train precision: 0.960467, train loss: 21.337929, valid precision: 0.857200, valid loss: 57.181421
epoch: 42, train precision: 0.950533, train loss: 23.673590, valid precision: 0.854800, valid loss: 59.261665
epoch: 43, train precision: 0.960667, train loss: 20.737455, valid precision: 0.855400, valid loss: 56.751872
epoch: 44, train precision: 0.958822, train loss: 21.140747, valid precision: 0.854800, valid loss: 58.230679
epoch: 45, train precision: 0.959489, train loss: 21.021761, valid precision: 0.859200, valid loss: 58.535711
epoch: 46, train precision: 0.963600, train loss: 20.024628, valid precision: 0.852800, valid loss: 57.541292
epoch: 47, train precision: 0.962022, train loss: 20.435119, valid precision: 0.859400, valid loss: 57.695137
epoch: 48, train precision: 0.965778, train loss: 19.035810, valid precision: 0.861200, valid loss: 55.941233
epoch: 49, train precision: 0.963600, train loss: 19.367421, valid precision: 0.852400, valid loss: 59.245032
epoch: 50, train precision: 0.964178, train loss: 19.531398, valid precision: 0.850000, valid loss: 58.798205
epoch: 51, train precision: 0.967044, train loss: 18.450606, valid precision: 0.860000, valid loss: 58.777123
epoch: 52, train precision: 0.964200, train loss: 18.722816, valid precision: 0.852400, valid loss: 59.813544
epoch: 53, train precision: 0.968911, train loss: 17.885895, valid precision: 0.859200, valid loss: 56.891787
epoch: 54, train precision: 0.969156, train loss: 17.682798, valid precision: 0.860400, valid loss: 57.507274
epoch: 55, train precision: 0.970067, train loss: 17.286618, valid precision: 0.855600, valid loss: 58.325712
epoch: 56, train precision: 0.967622, train loss: 17.981791, valid precision: 0.856000, valid loss: 60.350696
epoch: 57, train precision: 0.972267, train loss: 16.636918, valid precision: 0.859200, valid loss: 58.676726
epoch: 58, train precision: 0.974400, train loss: 15.912341, valid precision: 0.861200, valid loss: 58.161881
epoch: 59, train precision: 0.969267, train loss: 17.470848, valid precision: 0.858200, valid loss: 60.635231
epoch: 60, train precision: 0.973578, train loss: 16.331793, valid precision: 0.863000, valid loss: 58.787089
epoch: 61, train precision: 0.974644, train loss: 15.536664, valid precision: 0.864600, valid loss: 57.588399
epoch: 62, train precision: 0.975133, train loss: 15.531726, valid precision: 0.860600, valid loss: 58.474692
epoch: 63, train precision: 0.974600, train loss: 15.649255, valid precision: 0.858000, valid loss: 59.397690
epoch: 64, train precision: 0.975756, train loss: 15.212613, valid precision: 0.860400, valid loss: 58.465771
epoch: 65, train precision: 0.976378, train loss: 14.913408, valid precision: 0.868000, valid loss: 58.662787
epoch: 66, train precision: 0.974556, train loss: 15.464260, valid precision: 0.858000, valid loss: 60.955828
epoch: 67, train precision: 0.975444, train loss: 15.129197, valid precision: 0.861800, valid loss: 59.949513
epoch: 68, train precision: 0.975267, train loss: 15.241869, valid precision: 0.855200, valid loss: 60.909102
epoch: 69, train precision: 0.980111, train loss: 13.843840, valid precision: 0.858800, valid loss: 59.915643
epoch: 70, train precision: 0.976756, train loss: 14.532312, valid precision: 0.862200, valid loss: 60.421458
epoch: 71, train precision: 0.977978, train loss: 14.613206, valid precision: 0.859200, valid loss: 61.836792
epoch: 72, train precision: 0.978156, train loss: 14.324861, valid precision: 0.858800, valid loss: 60.413816
epoch: 73, train precision: 0.981444, train loss: 13.274198, valid precision: 0.860200, valid loss: 59.366176
epoch: 74, train precision: 0.982578, train loss: 13.039623, valid precision: 0.859400, valid loss: 60.386046
epoch: 75, train precision: 0.981711, train loss: 13.376081, valid precision: 0.861200, valid loss: 60.687929
epoch: 76, train precision: 0.979244, train loss: 13.810324, valid precision: 0.864000, valid loss: 59.419970
epoch: 77, train precision: 0.981089, train loss: 13.210243, valid precision: 0.860400, valid loss: 60.707853
epoch: 78, train precision: 0.982533, train loss: 12.876025, valid precision: 0.862200, valid loss: 61.240564
epoch: 79, train precision: 0.981867, train loss: 12.868985, valid precision: 0.862800, valid loss: 59.988837
epoch: 80, train precision: 0.982044, train loss: 12.966192, valid precision: 0.862600, valid loss: 61.095251
epoch: 81, train precision: 0.982578, train loss: 12.900432, valid precision: 0.856600, valid loss: 62.525262
epoch: 82, train precision: 0.982911, train loss: 12.408767, valid precision: 0.858400, valid loss: 62.820794
epoch: 83, train precision: 0.984267, train loss: 12.423923, valid precision: 0.861600, valid loss: 61.946459
epoch: 84, train precision: 0.985089, train loss: 12.066582, valid precision: 0.862600, valid loss: 61.263543
epoch: 85, train precision: 0.983133, train loss: 12.601923, valid precision: 0.862800, valid loss: 60.489592
epoch: 86, train precision: 0.983467, train loss: 12.703939, valid precision: 0.861400, valid loss: 62.522731
epoch: 87, train precision: 0.982533, train loss: 12.793237, valid precision: 0.864200, valid loss: 61.712752
epoch: 88, train precision: 0.982933, train loss: 12.416409, valid precision: 0.856400, valid loss: 61.652053
epoch: 89, train precision: 0.986689, train loss: 11.534935, valid precision: 0.862400, valid loss: 61.314617
epoch: 90, train precision: 0.984333, train loss: 12.156990, valid precision: 0.861200, valid loss: 61.952321
epoch: 91, train precision: 0.984178, train loss: 11.979732, valid precision: 0.864200, valid loss: 61.234869
epoch: 92, train precision: 0.985867, train loss: 11.724656, valid precision: 0.863400, valid loss: 59.476403
epoch: 93, train precision: 0.985178, train loss: 11.771652, valid precision: 0.862200, valid loss: 60.729613
epoch: 94, train precision: 0.985022, train loss: 11.954820, valid precision: 0.868000, valid loss: 60.789696
epoch: 95, train precision: 0.986044, train loss: 11.623309, valid precision: 0.867800, valid loss: 61.468172
epoch: 96, train precision: 0.987689, train loss: 11.033113, valid precision: 0.860800, valid loss: 62.657137
epoch: 97, train precision: 0.985133, train loss: 11.894524, valid precision: 0.860600, valid loss: 62.833585
epoch: 98, train precision: 0.987844, train loss: 11.027808, valid precision: 0.864600, valid loss: 62.878452
epoch: 99, train precision: 0.986022, train loss: 11.633822, valid precision: 0.857400, valid loss: 63.274764
epoch: 100, train precision: 0.985711, train loss: 11.702849, valid precision: 0.865800, valid loss: 63.740196
epoch: 101, train precision: 0.988956, train loss: 10.714200, valid precision: 0.868000, valid loss: 61.757586
epoch: 102, train precision: 0.988178, train loss: 11.024666, valid precision: 0.862600, valid loss: 63.646260
epoch: 103, train precision: 0.986000, train loss: 11.643479, valid precision: 0.863000, valid loss: 64.539901
epoch: 104, train precision: 0.989022, train loss: 10.766688, valid precision: 0.862200, valid loss: 62.601537
epoch: 105, train precision: 0.988778, train loss: 10.867963, valid precision: 0.862600, valid loss: 63.094819
epoch: 106, train precision: 0.984422, train loss: 12.153474, valid precision: 0.858800, valid loss: 64.246959
epoch: 107, train precision: 0.986067, train loss: 11.314645, valid precision: 0.860200, valid loss: 65.404558
epoch: 108, train precision: 0.989422, train loss: 10.570312, valid precision: 0.867000, valid loss: 63.206364
epoch: 109, train precision: 0.987467, train loss: 10.977071, valid precision: 0.863000, valid loss: 65.575736
epoch: 110, train precision: 0.987467, train loss: 11.218355, valid precision: 0.860400, valid loss: 66.145490
epoch: 111, train precision: 0.989178, train loss: 10.624628, valid precision: 0.865600, valid loss: 64.129635
epoch: 112, train precision: 0.990022, train loss: 10.460222, valid precision: 0.861400, valid loss: 63.571479
epoch: 113, train precision: 0.987400, train loss: 11.267024, valid precision: 0.859600, valid loss: 66.146655
epoch: 114, train precision: 0.989356, train loss: 10.414169, valid precision: 0.865800, valid loss: 63.311561
epoch: 115, train precision: 0.990867, train loss: 10.149587, valid precision: 0.869600, valid loss: 63.294020
epoch: 116, train precision: 0.990933, train loss: 10.228789, valid precision: 0.866800, valid loss: 62.993406
epoch: 117, train precision: 0.989378, train loss: 10.591168, valid precision: 0.864200, valid loss: 67.295398
epoch: 118, train precision: 0.986533, train loss: 11.360761, valid precision: 0.856000, valid loss: 67.396058
epoch: 119, train precision: 0.987667, train loss: 10.968993, valid precision: 0.857000, valid loss: 69.023387
epoch: 120, train precision: 0.990156, train loss: 10.306437, valid precision: 0.862000, valid loss: 64.784777
epoch: 121, train precision: 0.990311, train loss: 10.363150, valid precision: 0.858000, valid loss: 67.083748
epoch: 122, train precision: 0.991178, train loss: 10.162112, valid precision: 0.860200, valid loss: 66.793837
epoch: 123, train precision: 0.988867, train loss: 10.812128, valid precision: 0.864600, valid loss: 65.652446
epoch: 124, train precision: 0.990467, train loss: 10.371267, valid precision: 0.870000, valid loss: 64.537499
epoch: 125, train precision: 0.989333, train loss: 10.543401, valid precision: 0.869000, valid loss: 64.804884
epoch: 126, train precision: 0.987644, train loss: 11.352658, valid precision: 0.862000, valid loss: 67.641259
epoch: 127, train precision: 0.991400, train loss: 10.052026, valid precision: 0.861800, valid loss: 66.030105
epoch: 128, train precision: 0.991378, train loss: 10.068241, valid precision: 0.862800, valid loss: 66.374464
epoch: 129, train precision: 0.989400, train loss: 10.554970, valid precision: 0.863200, valid loss: 68.103859
epoch: 130, train precision: 0.990356, train loss: 10.352117, valid precision: 0.863000, valid loss: 67.403826
epoch: 131, train precision: 0.988867, train loss: 10.820631, valid precision: 0.862000, valid loss: 68.256332
epoch: 132, train precision: 0.992133, train loss: 9.791583, valid precision: 0.862200, valid loss: 66.413616
epoch: 133, train precision: 0.990978, train loss: 10.143574, valid precision: 0.863600, valid loss: 66.087354
epoch: 134, train precision: 0.991333, train loss: 9.956899, valid precision: 0.864200, valid loss: 66.416772
epoch: 135, train precision: 0.991222, train loss: 10.085644, valid precision: 0.866800, valid loss: 66.414733
epoch: 136, train precision: 0.990733, train loss: 10.422606, valid precision: 0.866600, valid loss: 66.412372
epoch: 137, train precision: 0.990156, train loss: 10.505127, valid precision: 0.865000, valid loss: 67.482471
epoch: 138, train precision: 0.991800, train loss: 9.858231, valid precision: 0.868400, valid loss: 65.966193
epoch: 139, train precision: 0.992133, train loss: 9.813507, valid precision: 0.866000, valid loss: 66.268537
epoch: 140, train precision: 0.991622, train loss: 10.129480, valid precision: 0.861800, valid loss: 65.272405
epoch: 141, train precision: 0.992000, train loss: 9.969371, valid precision: 0.865200, valid loss: 66.492590
epoch: 142, train precision: 0.990222, train loss: 10.553532, valid precision: 0.864400, valid loss: 67.738185
epoch: 143, train precision: 0.989244, train loss: 10.671749, valid precision: 0.864400, valid loss: 65.417725
epoch: 144, train precision: 0.992222, train loss: 9.789461, valid precision: 0.869800, valid loss: 65.106232
epoch: 145, train precision: 0.991578, train loss: 10.283462, valid precision: 0.861400, valid loss: 67.665242
epoch: 146, train precision: 0.991489, train loss: 10.218300, valid precision: 0.861400, valid loss: 68.208900
epoch: 147, train precision: 0.992756, train loss: 9.906895, valid precision: 0.868200, valid loss: 66.753733
epoch: 148, train precision: 0.991578, train loss: 10.120929, valid precision: 0.861200, valid loss: 68.508060
epoch: 149, train precision: 0.992489, train loss: 9.820777, valid precision: 0.867200, valid loss: 66.190337
epoch: 150, train precision: 0.990000, train loss: 10.521383, valid precision: 0.864400, valid loss: 69.593194
epoch: 151, train precision: 0.992867, train loss: 9.759711, valid precision: 0.869000, valid loss: 66.830448
epoch: 152, train precision: 0.992689, train loss: 9.786209, valid precision: 0.868000, valid loss: 68.103181
epoch: 153, train precision: 0.991333, train loss: 10.353518, valid precision: 0.866600, valid loss: 70.117982
epoch: 154, train precision: 0.993644, train loss: 9.728384, valid precision: 0.868200, valid loss: 66.023401
epoch: 155, train precision: 0.990444, train loss: 10.593932, valid precision: 0.864400, valid loss: 69.268002
epoch: 156, train precision: 0.994711, train loss: 9.316825, valid precision: 0.866200, valid loss: 68.056865
epoch: 157, train precision: 0.993511, train loss: 9.791620, valid precision: 0.865400, valid loss: 68.080011
epoch: 158, train precision: 0.991844, train loss: 10.190661, valid precision: 0.866200, valid loss: 69.006582
epoch: 159, train precision: 0.993733, train loss: 9.520605, valid precision: 0.870400, valid loss: 68.666730
epoch: 160, train precision: 0.992911, train loss: 9.744329, valid precision: 0.868000, valid loss: 67.504839
epoch: 161, train precision: 0.993556, train loss: 9.775646, valid precision: 0.867200, valid loss: 68.058352
epoch: 162, train precision: 0.992978, train loss: 9.907670, valid precision: 0.866800, valid loss: 68.746110
epoch: 163, train precision: 0.993556, train loss: 9.743728, valid precision: 0.869400, valid loss: 68.963734
epoch: 164, train precision: 0.993400, train loss: 9.666282, valid precision: 0.867800, valid loss: 70.098330
epoch: 165, train precision: 0.993000, train loss: 9.947408, valid precision: 0.868800, valid loss: 69.269726
epoch: 166, train precision: 0.993556, train loss: 9.848696, valid precision: 0.868200, valid loss: 68.963399
epoch: 167, train precision: 0.992867, train loss: 9.970330, valid precision: 0.864800, valid loss: 69.881331
epoch: 168, train precision: 0.993911, train loss: 9.660493, valid precision: 0.866400, valid loss: 70.205120
epoch: 169, train precision: 0.992711, train loss: 9.889501, valid precision: 0.866000, valid loss: 69.954097
epoch: 170, train precision: 0.992556, train loss: 10.238198, valid precision: 0.864800, valid loss: 70.787234
epoch: 171, train precision: 0.993156, train loss: 9.917965, valid precision: 0.865000, valid loss: 71.364147
epoch: 172, train precision: 0.993089, train loss: 9.902966, valid precision: 0.865000, valid loss: 70.861220
epoch: 173, train precision: 0.994289, train loss: 9.545291, valid precision: 0.865800, valid loss: 70.541325
epoch: 174, train precision: 0.992778, train loss: 10.039960, valid precision: 0.861400, valid loss: 70.982107
epoch: 175, train precision: 0.993244, train loss: 10.018595, valid precision: 0.865200, valid loss: 69.756598
epoch: 176, train precision: 0.994956, train loss: 9.375658, valid precision: 0.866400, valid loss: 69.470098
epoch: 177, train precision: 0.992533, train loss: 10.162886, valid precision: 0.864800, valid loss: 69.874574
epoch: 178, train precision: 0.993356, train loss: 9.930798, valid precision: 0.867600, valid loss: 70.210605
epoch: 179, train precision: 0.992667, train loss: 10.287679, valid precision: 0.864400, valid loss: 70.482634
epoch: 180, train precision: 0.994267, train loss: 9.649721, valid precision: 0.871800, valid loss: 68.618105
epoch: 181, train precision: 0.995133, train loss: 9.436159, valid precision: 0.866400, valid loss: 69.319370
epoch: 182, train precision: 0.993311, train loss: 9.873885, valid precision: 0.862800, valid loss: 69.673897
epoch: 183, train precision: 0.995333, train loss: 9.342014, valid precision: 0.872200, valid loss: 68.809637
epoch: 184, train precision: 0.994511, train loss: 9.610397, valid precision: 0.867200, valid loss: 69.175812
epoch: 185, train precision: 0.994644, train loss: 9.612199, valid precision: 0.866800, valid loss: 70.348290
epoch: 186, train precision: 0.994600, train loss: 9.635504, valid precision: 0.870600, valid loss: 69.587301
epoch: 187, train precision: 0.994467, train loss: 9.727463, valid precision: 0.863800, valid loss: 71.845642
epoch: 188, train precision: 0.994644, train loss: 9.611770, valid precision: 0.868000, valid loss: 68.902307
epoch: 189, train precision: 0.993400, train loss: 9.928157, valid precision: 0.867800, valid loss: 70.470952
epoch: 190, train precision: 0.993156, train loss: 9.993766, valid precision: 0.869000, valid loss: 69.744053
epoch: 191, train precision: 0.993489, train loss: 10.010681, valid precision: 0.870200, valid loss: 69.595365
epoch: 192, train precision: 0.993556, train loss: 10.070124, valid precision: 0.869200, valid loss: 71.235690
epoch: 193, train precision: 0.994289, train loss: 9.780639, valid precision: 0.868800, valid loss: 70.294277
epoch: 194, train precision: 0.994444, train loss: 9.779977, valid precision: 0.870200, valid loss: 69.428692
epoch: 195, train precision: 0.993511, train loss: 9.972359, valid precision: 0.870200, valid loss: 69.730404
epoch: 196, train precision: 0.995511, train loss: 9.481954, valid precision: 0.869600, valid loss: 69.639859
epoch: 197, train precision: 0.992022, train loss: 10.674274, valid precision: 0.869200, valid loss: 71.113163
epoch: 198, train precision: 0.994400, train loss: 9.708426, valid precision: 0.870200, valid loss: 69.389599
epoch: 199, train precision: 0.994356, train loss: 9.913825, valid precision: 0.867000, valid loss: 71.921368
epoch: 200, train precision: 0.993844, train loss: 9.886135, valid precision: 0.867400, valid loss: 73.400418
epoch: 201, train precision: 0.995578, train loss: 9.556317, valid precision: 0.868400, valid loss: 73.994901
epoch: 202, train precision: 0.993578, train loss: 10.092439, valid precision: 0.868000, valid loss: 73.641364
epoch: 203, train precision: 0.992889, train loss: 10.285010, valid precision: 0.864800, valid loss: 74.098394
epoch: 204, train precision: 0.995311, train loss: 9.590873, valid precision: 0.869400, valid loss: 71.967046
epoch: 205, train precision: 0.995267, train loss: 9.569346, valid precision: 0.869400, valid loss: 70.332754
epoch: 206, train precision: 0.995444, train loss: 9.638826, valid precision: 0.867200, valid loss: 71.775144
epoch: 207, train precision: 0.994267, train loss: 9.959947, valid precision: 0.866600, valid loss: 73.955966
epoch: 208, train precision: 0.994844, train loss: 9.725673, valid precision: 0.871600, valid loss: 69.702729
epoch: 209, train precision: 0.992467, train loss: 10.629566, valid precision: 0.870200, valid loss: 71.676019
epoch: 210, train precision: 0.995000, train loss: 9.606880, valid precision: 0.865600, valid loss: 70.807749
epoch: 211, train precision: 0.994244, train loss: 10.002967, valid precision: 0.872200, valid loss: 74.123644
epoch: 212, train precision: 0.994978, train loss: 9.745451, valid precision: 0.869000, valid loss: 71.802255
epoch: 213, train precision: 0.992667, train loss: 10.510318, valid precision: 0.868600, valid loss: 72.110758
epoch: 214, train precision: 0.995844, train loss: 9.520258, valid precision: 0.870800, valid loss: 71.812161
epoch: 215, train precision: 0.995133, train loss: 9.691166, valid precision: 0.875000, valid loss: 71.345183
epoch: 216, train precision: 0.995400, train loss: 9.685442, valid precision: 0.872600, valid loss: 69.750348
epoch: 217, train precision: 0.996333, train loss: 9.358365, valid precision: 0.876600, valid loss: 70.768770
epoch: 218, train precision: 0.994178, train loss: 10.035686, valid precision: 0.869200, valid loss: 71.621638
epoch: 219, train precision: 0.995600, train loss: 9.622756, valid precision: 0.874800, valid loss: 68.556364
epoch: 220, train precision: 0.994978, train loss: 9.818915, valid precision: 0.876000, valid loss: 72.233155
epoch: 221, train precision: 0.995822, train loss: 9.609941, valid precision: 0.877000, valid loss: 70.643133
epoch: 222, train precision: 0.994578, train loss: 10.018562, valid precision: 0.873000, valid loss: 70.550446
epoch: 223, train precision: 0.994933, train loss: 9.864957, valid precision: 0.869200, valid loss: 72.055485
epoch: 224, train precision: 0.996244, train loss: 9.452718, valid precision: 0.870200, valid loss: 72.496715
epoch: 225, train precision: 0.994889, train loss: 9.813235, valid precision: 0.868200, valid loss: 72.591371
epoch: 226, train precision: 0.995778, train loss: 9.642933, valid precision: 0.870400, valid loss: 74.102127
epoch: 227, train precision: 0.995533, train loss: 9.708557, valid precision: 0.866600, valid loss: 73.541323
epoch: 228, train precision: 0.995267, train loss: 9.754864, valid precision: 0.872600, valid loss: 72.715965
epoch: 229, train precision: 0.995689, train loss: 9.676457, valid precision: 0.870200, valid loss: 72.467396
epoch: 230, train precision: 0.996222, train loss: 9.558685, valid precision: 0.868000, valid loss: 72.862723
epoch: 231, train precision: 0.994844, train loss: 9.920951, valid precision: 0.866200, valid loss: 73.251256
epoch: 232, train precision: 0.995622, train loss: 9.753715, valid precision: 0.866000, valid loss: 74.355175
epoch: 233, train precision: 0.995311, train loss: 9.862298, valid precision: 0.870400, valid loss: 74.633266
epoch: 234, train precision: 0.995644, train loss: 9.724824, valid precision: 0.870600, valid loss: 73.260215
epoch: 235, train precision: 0.996133, train loss: 9.693673, valid precision: 0.867200, valid loss: 73.574378
epoch: 236, train precision: 0.995244, train loss: 9.955754, valid precision: 0.870000, valid loss: 73.745822
epoch: 237, train precision: 0.996356, train loss: 9.590735, valid precision: 0.867400, valid loss: 73.062365
epoch: 238, train precision: 0.994933, train loss: 10.054047, valid precision: 0.868400, valid loss: 74.183343
epoch: 239, train precision: 0.995933, train loss: 9.683958, valid precision: 0.870200, valid loss: 74.541240
epoch: 240, train precision: 0.995267, train loss: 10.061006, valid precision: 0.866800, valid loss: 73.333013
epoch: 241, train precision: 0.995822, train loss: 9.703362, valid precision: 0.869200, valid loss: 74.591613
epoch: 242, train precision: 0.996267, train loss: 9.654171, valid precision: 0.869600, valid loss: 73.467390
epoch: 243, train precision: 0.995156, train loss: 9.911486, valid precision: 0.868600, valid loss: 73.584212
epoch: 244, train precision: 0.995689, train loss: 9.871126, valid precision: 0.868800, valid loss: 72.056547
epoch: 245, train precision: 0.994733, train loss: 10.079228, valid precision: 0.874800, valid loss: 73.668043
epoch: 246, train precision: 0.995978, train loss: 9.730667, valid precision: 0.870600, valid loss: 72.080854
epoch: 247, train precision: 0.996400, train loss: 9.742831, valid precision: 0.873200, valid loss: 73.143934
epoch: 248, train precision: 0.996400, train loss: 9.695034, valid precision: 0.865600, valid loss: 73.185735
epoch: 249, train precision: 0.996667, train loss: 9.614756, valid precision: 0.869200, valid loss: 72.260907
epoch: 250, train precision: 0.994933, train loss: 9.985953, valid precision: 0.870600, valid loss: 74.410512
epoch: 251, train precision: 0.996133, train loss: 9.794771, valid precision: 0.872000, valid loss: 72.069353
epoch: 252, train precision: 0.995933, train loss: 9.917212, valid precision: 0.871800, valid loss: 74.210913
epoch: 253, train precision: 0.996333, train loss: 9.673912, valid precision: 0.875400, valid loss: 72.725732
epoch: 254, train precision: 0.995778, train loss: 9.861231, valid precision: 0.872000, valid loss: 73.533240
epoch: 255, train precision: 0.996333, train loss: 9.719699, valid precision: 0.875600, valid loss: 70.972412
epoch: 256, train precision: 0.995756, train loss: 10.051567, valid precision: 0.871800, valid loss: 73.713423
epoch: 257, train precision: 0.997000, train loss: 9.609613, valid precision: 0.872200, valid loss: 71.217891
epoch: 258, train precision: 0.996156, train loss: 9.787788, valid precision: 0.868800, valid loss: 72.897754
epoch: 259, train precision: 0.996578, train loss: 9.721784, valid precision: 0.864600, valid loss: 73.446326
epoch: 260, train precision: 0.996689, train loss: 9.730227, valid precision: 0.870400, valid loss: 73.307547
epoch: 261, train precision: 0.996267, train loss: 9.778493, valid precision: 0.868600, valid loss: 74.371395
epoch: 262, train precision: 0.995622, train loss: 10.022762, valid precision: 0.867200, valid loss: 73.396093
epoch: 263, train precision: 0.996756, train loss: 9.638290, valid precision: 0.869000, valid loss: 73.866609
epoch: 264, train precision: 0.996956, train loss: 9.501828, valid precision: 0.870200, valid loss: 72.685952
epoch: 265, train precision: 0.996200, train loss: 9.803954, valid precision: 0.868800, valid loss: 75.571881
epoch: 266, train precision: 0.996200, train loss: 9.846643, valid precision: 0.871000, valid loss: 74.184328
epoch: 267, train precision: 0.997311, train loss: 9.514266, valid precision: 0.867600, valid loss: 74.763868
epoch: 268, train precision: 0.995756, train loss: 10.019506, valid precision: 0.868600, valid loss: 75.954361
epoch: 269, train precision: 0.996089, train loss: 10.036957, valid precision: 0.865000, valid loss: 74.564887
epoch: 270, train precision: 0.996778, train loss: 9.798646, valid precision: 0.872800, valid loss: 74.621251
epoch: 271, train precision: 0.995933, train loss: 9.999721, valid precision: 0.871200, valid loss: 75.143899
epoch: 272, train precision: 0.996711, train loss: 9.841981, valid precision: 0.872400, valid loss: 75.953738
epoch: 273, train precision: 0.996422, train loss: 10.029958, valid precision: 0.869400, valid loss: 75.947415
epoch: 274, train precision: 0.997356, train loss: 9.593933, valid precision: 0.871200, valid loss: 73.328075
epoch: 275, train precision: 0.996911, train loss: 9.740409, valid precision: 0.873400, valid loss: 72.753484
epoch: 276, train precision: 0.997244, train loss: 9.782902, valid precision: 0.871200, valid loss: 73.512179
epoch: 277, train precision: 0.996889, train loss: 9.714318, valid precision: 0.871600, valid loss: 75.649338
epoch: 278, train precision: 0.995511, train loss: 10.124668, valid precision: 0.868000, valid loss: 73.824176
epoch: 279, train precision: 0.996600, train loss: 9.918210, valid precision: 0.871000, valid loss: 74.253650
epoch: 280, train precision: 0.996644, train loss: 9.860607, valid precision: 0.870200, valid loss: 75.044236
epoch: 281, train precision: 0.996622, train loss: 9.788809, valid precision: 0.872000, valid loss: 74.161792
epoch: 282, train precision: 0.996778, train loss: 9.803379, valid precision: 0.870200, valid loss: 74.882289
epoch: 283, train precision: 0.996689, train loss: 9.836277, valid precision: 0.869400, valid loss: 75.245384
epoch: 284, train precision: 0.995600, train loss: 10.207493, valid precision: 0.868600, valid loss: 74.512674
epoch: 285, train precision: 0.996311, train loss: 10.025397, valid precision: 0.868800, valid loss: 75.374813
epoch: 286, train precision: 0.996667, train loss: 9.901039, valid precision: 0.870200, valid loss: 73.657357
epoch: 287, train precision: 0.997378, train loss: 9.625727, valid precision: 0.874000, valid loss: 73.726397
epoch: 288, train precision: 0.996733, train loss: 9.850672, valid precision: 0.873200, valid loss: 72.097233
epoch: 289, train precision: 0.997000, train loss: 9.834947, valid precision: 0.868400, valid loss: 73.288452
epoch: 290, train precision: 0.996444, train loss: 10.019311, valid precision: 0.870400, valid loss: 73.067259
epoch: 291, train precision: 0.996600, train loss: 9.888470, valid precision: 0.869200, valid loss: 74.073840
epoch: 292, train precision: 0.997156, train loss: 9.820462, valid precision: 0.873800, valid loss: 73.484159
epoch: 293, train precision: 0.996756, train loss: 9.930435, valid precision: 0.873600, valid loss: 75.970164
epoch: 294, train precision: 0.997000, train loss: 9.770175, valid precision: 0.874400, valid loss: 73.658965
epoch: 295, train precision: 0.996356, train loss: 9.996030, valid precision: 0.872000, valid loss: 74.281917
epoch: 296, train precision: 0.996578, train loss: 10.070362, valid precision: 0.870800, valid loss: 75.575193
epoch: 297, train precision: 0.996844, train loss: 9.965827, valid precision: 0.871800, valid loss: 74.632549
epoch: 298, train precision: 0.997267, train loss: 9.811218, valid precision: 0.871400, valid loss: 76.434469
epoch: 299, train precision: 0.997467, train loss: 9.755104, valid precision: 0.869200, valid loss: 76.516916
epoch: 300, train precision: 0.996244, train loss: 10.080723, valid precision: 0.869400, valid loss: 79.187782
epoch: 301, train precision: 0.996644, train loss: 10.002043, valid precision: 0.869800, valid loss: 76.523270
epoch: 302, train precision: 0.997111, train loss: 9.843416, valid precision: 0.873000, valid loss: 76.609045
epoch: 303, train precision: 0.996489, train loss: 10.099270, valid precision: 0.869200, valid loss: 75.885228
epoch: 304, train precision: 0.996622, train loss: 9.979773, valid precision: 0.873800, valid loss: 76.830471
epoch: 305, train precision: 0.996756, train loss: 9.987223, valid precision: 0.873400, valid loss: 75.220354
epoch: 306, train precision: 0.996756, train loss: 9.936217, valid precision: 0.871000, valid loss: 75.352219
epoch: 307, train precision: 0.997689, train loss: 9.775420, valid precision: 0.873200, valid loss: 74.957925
epoch: 308, train precision: 0.997022, train loss: 9.946515, valid precision: 0.871400, valid loss: 76.807771
epoch: 309, train precision: 0.996444, train loss: 10.067056, valid precision: 0.873400, valid loss: 77.133683
epoch: 310, train precision: 0.996778, train loss: 9.947137, valid precision: 0.873000, valid loss: 75.100330
epoch: 311, train precision: 0.997600, train loss: 9.796290, valid precision: 0.874600, valid loss: 73.843105
epoch: 312, train precision: 0.997022, train loss: 10.013644, valid precision: 0.874800, valid loss: 75.806448
epoch: 313, train precision: 0.996289, train loss: 10.231602, valid precision: 0.867400, valid loss: 75.307298
epoch: 314, train precision: 0.997067, train loss: 9.932124, valid precision: 0.872400, valid loss: 76.849642
epoch: 315, train precision: 0.997067, train loss: 9.924278, valid precision: 0.876400, valid loss: 74.732821
epoch: 316, train precision: 0.996622, train loss: 10.067778, valid precision: 0.871800, valid loss: 77.183519
epoch: 317, train precision: 0.997267, train loss: 9.973617, valid precision: 0.872600, valid loss: 76.215721
epoch: 318, train precision: 0.996889, train loss: 10.048272, valid precision: 0.867800, valid loss: 75.950159
epoch: 319, train precision: 0.997267, train loss: 9.973169, valid precision: 0.875400, valid loss: 74.737131
epoch: 320, train precision: 0.997356, train loss: 9.895780, valid precision: 0.875000, valid loss: 76.700486
epoch: 321, train precision: 0.996978, train loss: 10.066432, valid precision: 0.872200, valid loss: 79.070688
epoch: 322, train precision: 0.996822, train loss: 10.076811, valid precision: 0.872800, valid loss: 76.530283
epoch: 323, train precision: 0.996044, train loss: 10.418557, valid precision: 0.869800, valid loss: 77.174423
epoch: 324, train precision: 0.997400, train loss: 9.896428, valid precision: 0.876400, valid loss: 75.347320
epoch: 325, train precision: 0.997311, train loss: 9.933996, valid precision: 0.876200, valid loss: 74.447874
epoch: 326, train precision: 0.997622, train loss: 9.886145, valid precision: 0.874400, valid loss: 76.695311
epoch: 327, train precision: 0.997244, train loss: 9.963515, valid precision: 0.874200, valid loss: 74.079389
epoch: 328, train precision: 0.996733, train loss: 10.059322, valid precision: 0.870400, valid loss: 75.714343
epoch: 329, train precision: 0.996533, train loss: 10.211811, valid precision: 0.866200, valid loss: 76.764614
epoch: 330, train precision: 0.997533, train loss: 9.956969, valid precision: 0.868600, valid loss: 76.456776
epoch: 331, train precision: 0.996556, train loss: 10.326957, valid precision: 0.870600, valid loss: 77.225929
epoch: 332, train precision: 0.996956, train loss: 10.087749, valid precision: 0.872400, valid loss: 75.233529
epoch: 333, train precision: 0.997578, train loss: 10.030923, valid precision: 0.869200, valid loss: 76.949859
epoch: 334, train precision: 0.997156, train loss: 10.055221, valid precision: 0.869400, valid loss: 76.514791
epoch: 335, train precision: 0.997444, train loss: 10.018613, valid precision: 0.870800, valid loss: 76.606432
epoch: 336, train precision: 0.996889, train loss: 10.118278, valid precision: 0.875800, valid loss: 76.319477
epoch: 337, train precision: 0.997356, train loss: 10.030331, valid precision: 0.876800, valid loss: 75.615338
epoch: 338, train precision: 0.996889, train loss: 10.167193, valid precision: 0.874400, valid loss: 76.332575
epoch: 339, train precision: 0.996889, train loss: 10.172121, valid precision: 0.873600, valid loss: 75.938260
epoch: 340, train precision: 0.997111, train loss: 10.078803, valid precision: 0.870000, valid loss: 75.931607
epoch: 341, train precision: 0.997089, train loss: 10.141527, valid precision: 0.868400, valid loss: 77.156489
epoch: 342, train precision: 0.996444, train loss: 10.355240, valid precision: 0.869400, valid loss: 78.488507
epoch: 343, train precision: 0.997356, train loss: 10.103897, valid precision: 0.872600, valid loss: 76.967722
epoch: 344, train precision: 0.996800, train loss: 10.170021, valid precision: 0.875200, valid loss: 76.697557
epoch: 345, train precision: 0.996356, train loss: 10.323941, valid precision: 0.871600, valid loss: 76.688429
epoch: 346, train precision: 0.997022, train loss: 10.230192, valid precision: 0.877400, valid loss: 76.749093
epoch: 347, train precision: 0.996867, train loss: 10.176712, valid precision: 0.873000, valid loss: 77.937324
epoch: 348, train precision: 0.997467, train loss: 9.934631, valid precision: 0.871800, valid loss: 77.675552
epoch: 349, train precision: 0.997511, train loss: 10.030231, valid precision: 0.873000, valid loss: 75.872408
epoch: 350, train precision: 0.997578, train loss: 10.035708, valid precision: 0.876200, valid loss: 76.172129
epoch: 351, train precision: 0.997556, train loss: 10.089898, valid precision: 0.867200, valid loss: 80.824279
epoch: 352, train precision: 0.996778, train loss: 10.344156, valid precision: 0.867800, valid loss: 78.500916
epoch: 353, train precision: 0.997400, train loss: 10.181224, valid precision: 0.873200, valid loss: 76.618716
epoch: 354, train precision: 0.997400, train loss: 10.107436, valid precision: 0.871200, valid loss: 76.484528
epoch: 355, train precision: 0.997822, train loss: 9.911306, valid precision: 0.873200, valid loss: 76.514302
epoch: 356, train precision: 0.997822, train loss: 9.940092, valid precision: 0.873400, valid loss: 77.991902
epoch: 357, train precision: 0.996956, train loss: 10.143710, valid precision: 0.873600, valid loss: 77.288281
epoch: 358, train precision: 0.997111, train loss: 10.233611, valid precision: 0.872200, valid loss: 77.383054
epoch: 359, train precision: 0.997267, train loss: 10.095811, valid precision: 0.874400, valid loss: 76.624972
epoch: 360, train precision: 0.997400, train loss: 10.169806, valid precision: 0.873600, valid loss: 75.629030
epoch: 361, train precision: 0.997333, train loss: 10.090662, valid precision: 0.874400, valid loss: 75.620620
epoch: 362, train precision: 0.997311, train loss: 10.143984, valid precision: 0.872200, valid loss: 77.476357
epoch: 363, train precision: 0.997178, train loss: 10.120649, valid precision: 0.865400, valid loss: 78.244596
epoch: 364, train precision: 0.997178, train loss: 10.224868, valid precision: 0.871200, valid loss: 79.103909
epoch: 365, train precision: 0.997333, train loss: 10.231327, valid precision: 0.873200, valid loss: 76.823832
epoch: 366, train precision: 0.997822, train loss: 10.064665, valid precision: 0.872800, valid loss: 77.796975
epoch: 367, train precision: 0.996822, train loss: 10.311122, valid precision: 0.871000, valid loss: 78.990886
epoch: 368, train precision: 0.997289, train loss: 10.256824, valid precision: 0.872600, valid loss: 77.123550
epoch: 369, train precision: 0.996778, train loss: 10.260231, valid precision: 0.871800, valid loss: 78.143207
epoch: 370, train precision: 0.996933, train loss: 10.265261, valid precision: 0.869800, valid loss: 77.227433
epoch: 371, train precision: 0.997156, train loss: 10.254657, valid precision: 0.874000, valid loss: 78.870966
epoch: 372, train precision: 0.997067, train loss: 10.287540, valid precision: 0.872400, valid loss: 80.096685
epoch: 373, train precision: 0.996022, train loss: 10.563899, valid precision: 0.871600, valid loss: 79.087130
epoch: 374, train precision: 0.997467, train loss: 10.108026, valid precision: 0.874800, valid loss: 77.613042
epoch: 375, train precision: 0.997378, train loss: 10.182544, valid precision: 0.875200, valid loss: 77.357053
epoch: 376, train precision: 0.997356, train loss: 10.188560, valid precision: 0.878200, valid loss: 77.459775
epoch: 377, train precision: 0.997578, train loss: 10.056714, valid precision: 0.878800, valid loss: 76.578618
epoch: 378, train precision: 0.997311, train loss: 10.236459, valid precision: 0.878000, valid loss: 75.852451
epoch: 379, train precision: 0.997311, train loss: 10.242343, valid precision: 0.876800, valid loss: 75.708145
epoch: 380, train precision: 0.997644, train loss: 10.145633, valid precision: 0.878400, valid loss: 76.653192
epoch: 381, train precision: 0.997311, train loss: 10.177291, valid precision: 0.873200, valid loss: 77.509322
epoch: 382, train precision: 0.997267, train loss: 10.244904, valid precision: 0.875800, valid loss: 77.915530
epoch: 383, train precision: 0.997533, train loss: 10.133065, valid precision: 0.875200, valid loss: 77.717393
epoch: 384, train precision: 0.997111, train loss: 10.309235, valid precision: 0.877200, valid loss: 77.064326
epoch: 385, train precision: 0.997711, train loss: 10.112305, valid precision: 0.874800, valid loss: 77.184770
epoch: 386, train precision: 0.997444, train loss: 10.233497, valid precision: 0.874000, valid loss: 76.196352
epoch: 387, train precision: 0.997200, train loss: 10.250140, valid precision: 0.875400, valid loss: 75.956845
epoch: 388, train precision: 0.996844, train loss: 10.424653, valid precision: 0.873800, valid loss: 76.165630
epoch: 389, train precision: 0.997533, train loss: 10.185094, valid precision: 0.876000, valid loss: 75.762145
epoch: 390, train precision: 0.997267, train loss: 10.275828, valid precision: 0.876800, valid loss: 76.460181
epoch: 391, train precision: 0.997400, train loss: 10.219183, valid precision: 0.874400, valid loss: 78.167190
epoch: 392, train precision: 0.997467, train loss: 10.297920, valid precision: 0.874200, valid loss: 78.150227
epoch: 393, train precision: 0.997622, train loss: 10.272341, valid precision: 0.867600, valid loss: 79.361111
epoch: 394, train precision: 0.997378, train loss: 10.223964, valid precision: 0.876400, valid loss: 75.796364
epoch: 395, train precision: 0.997578, train loss: 10.207252, valid precision: 0.878800, valid loss: 74.374905
epoch: 396, train precision: 0.997489, train loss: 10.249005, valid precision: 0.873600, valid loss: 75.751543
epoch: 397, train precision: 0.996822, train loss: 10.365860, valid precision: 0.879200, valid loss: 75.709814
epoch: 398, train precision: 0.997556, train loss: 10.223302, valid precision: 0.878200, valid loss: 74.959881
epoch: 399, train precision: 0.997400, train loss: 10.340873, valid precision: 0.876200, valid loss: 76.266547
epoch: 400, train precision: 0.997133, train loss: 10.421071, valid precision: 0.872800, valid loss: 79.023898
epoch: 401, train precision: 0.996978, train loss: 10.479081, valid precision: 0.875000, valid loss: 76.238937
epoch: 402, train precision: 0.996978, train loss: 10.408428, valid precision: 0.874600, valid loss: 78.342461
epoch: 403, train precision: 0.997067, train loss: 10.410214, valid precision: 0.873400, valid loss: 77.324106
epoch: 404, train precision: 0.997533, train loss: 10.336347, valid precision: 0.879400, valid loss: 74.063702
epoch: 405, train precision: 0.997822, train loss: 10.200552, valid precision: 0.878400, valid loss: 72.804324
epoch: 406, train precision: 0.997444, train loss: 10.328897, valid precision: 0.876200, valid loss: 74.832061
epoch: 407, train precision: 0.997867, train loss: 10.234228, valid precision: 0.872400, valid loss: 74.906022
epoch: 408, train precision: 0.997022, train loss: 10.372089, valid precision: 0.870800, valid loss: 78.693281
epoch: 409, train precision: 0.997289, train loss: 10.368906, valid precision: 0.877000, valid loss: 76.611357
epoch: 410, train precision: 0.998200, train loss: 10.145382, valid precision: 0.877400, valid loss: 74.800435
epoch: 411, train precision: 0.997000, train loss: 10.546544, valid precision: 0.877200, valid loss: 77.102657
epoch: 412, train precision: 0.997444, train loss: 10.354325, valid precision: 0.879200, valid loss: 75.202929
epoch: 413, train precision: 0.997644, train loss: 10.368182, valid precision: 0.874800, valid loss: 74.716866
epoch: 414, train precision: 0.997644, train loss: 10.346513, valid precision: 0.875200, valid loss: 76.854421
epoch: 415, train precision: 0.998222, train loss: 10.096574, valid precision: 0.875200, valid loss: 75.205184
epoch: 416, train precision: 0.997756, train loss: 10.257975, valid precision: 0.877600, valid loss: 75.807660
epoch: 417, train precision: 0.997356, train loss: 10.315258, valid precision: 0.875200, valid loss: 77.012560
epoch: 418, train precision: 0.997533, train loss: 10.327572, valid precision: 0.872600, valid loss: 78.326198
epoch: 419, train precision: 0.997444, train loss: 10.313439, valid precision: 0.877000, valid loss: 76.318403
epoch: 420, train precision: 0.998089, train loss: 10.131642, valid precision: 0.875600, valid loss: 76.850321
epoch: 421, train precision: 0.997867, train loss: 10.163145, valid precision: 0.875200, valid loss: 78.706144
epoch: 422, train precision: 0.997089, train loss: 10.501147, valid precision: 0.873000, valid loss: 79.053290
epoch: 423, train precision: 0.997889, train loss: 10.343303, valid precision: 0.877600, valid loss: 76.456516
epoch: 424, train precision: 0.997733, train loss: 10.302417, valid precision: 0.874600, valid loss: 76.416348
epoch: 425, train precision: 0.997289, train loss: 10.376687, valid precision: 0.875200, valid loss: 78.260627
epoch: 426, train precision: 0.998022, train loss: 10.209101, valid precision: 0.873400, valid loss: 79.520941
epoch: 427, train precision: 0.997644, train loss: 10.265908, valid precision: 0.875000, valid loss: 79.228588
epoch: 428, train precision: 0.997689, train loss: 10.317225, valid precision: 0.879200, valid loss: 78.351355
epoch: 429, train precision: 0.997889, train loss: 10.357569, valid precision: 0.871800, valid loss: 80.394289
epoch: 430, train precision: 0.997111, train loss: 10.533112, valid precision: 0.872600, valid loss: 77.817229
epoch: 431, train precision: 0.998000, train loss: 10.259495, valid precision: 0.877200, valid loss: 76.874334
epoch: 432, train precision: 0.997289, train loss: 10.396847, valid precision: 0.875600, valid loss: 78.017703
epoch: 433, train precision: 0.997622, train loss: 10.299741, valid precision: 0.877400, valid loss: 78.299132
epoch: 434, train precision: 0.997244, train loss: 10.387038, valid precision: 0.878400, valid loss: 77.147189
epoch: 435, train precision: 0.996267, train loss: 10.681774, valid precision: 0.876800, valid loss: 79.187674
epoch: 436, train precision: 0.997956, train loss: 10.214020, valid precision: 0.877400, valid loss: 77.249917
epoch: 437, train precision: 0.997867, train loss: 10.268011, valid precision: 0.876800, valid loss: 79.343098
epoch: 438, train precision: 0.997267, train loss: 10.454899, valid precision: 0.879000, valid loss: 79.341494
epoch: 439, train precision: 0.997978, train loss: 10.217881, valid precision: 0.879400, valid loss: 78.113104
epoch: 440, train precision: 0.997533, train loss: 10.307727, valid precision: 0.873200, valid loss: 79.401608
epoch: 441, train precision: 0.997756, train loss: 10.244620, valid precision: 0.875400, valid loss: 79.204253
epoch: 442, train precision: 0.997311, train loss: 10.463925, valid precision: 0.879400, valid loss: 78.787568
epoch: 443, train precision: 0.998044, train loss: 10.216731, valid precision: 0.876000, valid loss: 77.616650
epoch: 444, train precision: 0.997844, train loss: 10.328802, valid precision: 0.877600, valid loss: 79.826085
epoch: 445, train precision: 0.997822, train loss: 10.318118, valid precision: 0.871600, valid loss: 79.684313
epoch: 446, train precision: 0.997800, train loss: 10.374483, valid precision: 0.876400, valid loss: 80.368120
epoch: 447, train precision: 0.997756, train loss: 10.351707, valid precision: 0.875000, valid loss: 78.087341
epoch: 448, train precision: 0.998200, train loss: 10.189103, valid precision: 0.874800, valid loss: 77.885268
epoch: 449, train precision: 0.997422, train loss: 10.412265, valid precision: 0.878200, valid loss: 78.237557
epoch: 450, train precision: 0.997333, train loss: 10.517682, valid precision: 0.874800, valid loss: 80.087490
epoch: 451, train precision: 0.997933, train loss: 10.366787, valid precision: 0.875600, valid loss: 79.062750
epoch: 452, train precision: 0.996667, train loss: 10.648753, valid precision: 0.870200, valid loss: 82.091671
epoch: 453, train precision: 0.997911, train loss: 10.308756, valid precision: 0.874200, valid loss: 78.233613
epoch: 454, train precision: 0.996933, train loss: 10.625531, valid precision: 0.876000, valid loss: 80.720432
epoch: 455, train precision: 0.997889, train loss: 10.305244, valid precision: 0.875000, valid loss: 79.771504
epoch: 456, train precision: 0.998000, train loss: 10.328907, valid precision: 0.871600, valid loss: 81.116628
epoch: 457, train precision: 0.998156, train loss: 10.216945, valid precision: 0.875400, valid loss: 79.427691
epoch: 458, train precision: 0.997889, train loss: 10.347212, valid precision: 0.873400, valid loss: 80.403238
epoch: 459, train precision: 0.998311, train loss: 10.269843, valid precision: 0.876000, valid loss: 80.079094
epoch: 460, train precision: 0.997889, train loss: 10.417026, valid precision: 0.873600, valid loss: 81.047877
epoch: 461, train precision: 0.997800, train loss: 10.418391, valid precision: 0.873400, valid loss: 80.352568
epoch: 462, train precision: 0.997689, train loss: 10.446562, valid precision: 0.879400, valid loss: 78.598681
epoch: 463, train precision: 0.997600, train loss: 10.440560, valid precision: 0.873000, valid loss: 78.624743
epoch: 464, train precision: 0.997578, train loss: 10.397823, valid precision: 0.875400, valid loss: 80.673715
epoch: 465, train precision: 0.998000, train loss: 10.399878, valid precision: 0.872400, valid loss: 79.437245
epoch: 466, train precision: 0.998133, train loss: 10.304169, valid precision: 0.873600, valid loss: 80.262399
epoch: 467, train precision: 0.997200, train loss: 10.569488, valid precision: 0.872200, valid loss: 81.533461
epoch: 468, train precision: 0.998422, train loss: 10.189419, valid precision: 0.873000, valid loss: 82.068285
epoch: 469, train precision: 0.997489, train loss: 10.375326, valid precision: 0.870600, valid loss: 81.493850
epoch: 470, train precision: 0.997956, train loss: 10.349581, valid precision: 0.876800, valid loss: 79.455670
epoch: 471, train precision: 0.997867, train loss: 10.270540, valid precision: 0.876200, valid loss: 79.448318
epoch: 472, train precision: 0.998133, train loss: 10.323536, valid precision: 0.877200, valid loss: 78.934197
epoch: 473, train precision: 0.998156, train loss: 10.370842, valid precision: 0.873600, valid loss: 79.635392
epoch: 474, train precision: 0.997733, train loss: 10.441691, valid precision: 0.873400, valid loss: 81.048411
epoch: 475, train precision: 0.997778, train loss: 10.425351, valid precision: 0.870800, valid loss: 82.407175
epoch: 476, train precision: 0.997956, train loss: 10.420968, valid precision: 0.872400, valid loss: 81.779786
epoch: 477, train precision: 0.998000, train loss: 10.390138, valid precision: 0.879000, valid loss: 81.762128
epoch: 478, train precision: 0.997933, train loss: 10.380249, valid precision: 0.873400, valid loss: 81.103533
epoch: 479, train precision: 0.997689, train loss: 10.429975, valid precision: 0.872200, valid loss: 81.391819
epoch: 480, train precision: 0.997356, train loss: 10.571370, valid precision: 0.872000, valid loss: 82.038395
epoch: 481, train precision: 0.997600, train loss: 10.504047, valid precision: 0.875600, valid loss: 80.693985
epoch: 482, train precision: 0.998156, train loss: 10.304746, valid precision: 0.873000, valid loss: 82.073558
epoch: 483, train precision: 0.998378, train loss: 10.289184, valid precision: 0.878600, valid loss: 79.671487
epoch: 484, train precision: 0.997689, train loss: 10.522208, valid precision: 0.869800, valid loss: 80.715730
epoch: 485, train precision: 0.997800, train loss: 10.424668, valid precision: 0.875400, valid loss: 79.215719
epoch: 486, train precision: 0.998311, train loss: 10.317479, valid precision: 0.871400, valid loss: 82.304362
epoch: 487, train precision: 0.998356, train loss: 10.405053, valid precision: 0.874000, valid loss: 82.948424
epoch: 488, train precision: 0.997822, train loss: 10.497199, valid precision: 0.874400, valid loss: 80.796171
epoch: 489, train precision: 0.998467, train loss: 10.210484, valid precision: 0.876400, valid loss: 82.190699
epoch: 490, train precision: 0.997689, train loss: 10.473212, valid precision: 0.873600, valid loss: 80.342422
epoch: 491, train precision: 0.998111, train loss: 10.375687, valid precision: 0.875800, valid loss: 81.391722
epoch: 492, train precision: 0.997311, train loss: 10.639115, valid precision: 0.877800, valid loss: 81.269772
epoch: 493, train precision: 0.996733, train loss: 10.863035, valid precision: 0.873200, valid loss: 82.874673
epoch: 494, train precision: 0.998378, train loss: 10.306860, valid precision: 0.879800, valid loss: 79.131885
epoch: 495, train precision: 0.998289, train loss: 10.354220, valid precision: 0.877200, valid loss: 78.582237
epoch: 496, train precision: 0.998022, train loss: 10.395278, valid precision: 0.878400, valid loss: 80.346078
epoch: 497, train precision: 0.998000, train loss: 10.412787, valid precision: 0.877600, valid loss: 81.739855
epoch: 498, train precision: 0.998422, train loss: 10.336863, valid precision: 0.874600, valid loss: 81.241094
epoch: 499, train precision: 0.998089, train loss: 10.361553, valid precision: 0.876200, valid loss: 80.681702
epoch: 500, train precision: 0.998178, train loss: 10.332802, valid precision: 0.876200, valid loss: 78.424797
epoch: 501, train precision: 0.998222, train loss: 10.328560, valid precision: 0.876600, valid loss: 80.811555
epoch: 502, train precision: 0.997556, train loss: 10.548785, valid precision: 0.873800, valid loss: 81.334276
epoch: 503, train precision: 0.997933, train loss: 10.484240, valid precision: 0.872800, valid loss: 84.237260
epoch: 504, train precision: 0.998444, train loss: 10.306561, valid precision: 0.874200, valid loss: 80.665087
epoch: 505, train precision: 0.997978, train loss: 10.393282, valid precision: 0.875800, valid loss: 82.074012
epoch: 506, train precision: 0.997778, train loss: 10.603197, valid precision: 0.877000, valid loss: 80.534437
epoch: 507, train precision: 0.998156, train loss: 10.424560, valid precision: 0.874000, valid loss: 81.006246
epoch: 508, train precision: 0.998533, train loss: 10.209530, valid precision: 0.876600, valid loss: 81.665705
epoch: 509, train precision: 0.997756, train loss: 10.523750, valid precision: 0.875800, valid loss: 81.041542
epoch: 510, train precision: 0.997156, train loss: 10.662796, valid precision: 0.872400, valid loss: 80.173157
epoch: 511, train precision: 0.997822, train loss: 10.482304, valid precision: 0.878800, valid loss: 78.493557
epoch: 512, train precision: 0.998356, train loss: 10.341967, valid precision: 0.875800, valid loss: 79.202895
epoch: 513, train precision: 0.998600, train loss: 10.283299, valid precision: 0.878000, valid loss: 80.467664
epoch: 514, train precision: 0.998067, train loss: 10.541851, valid precision: 0.875200, valid loss: 82.231927
epoch: 515, train precision: 0.998333, train loss: 10.393214, valid precision: 0.876800, valid loss: 79.255517
epoch: 516, train precision: 0.998089, train loss: 10.454116, valid precision: 0.876000, valid loss: 81.527570
epoch: 517, train precision: 0.998133, train loss: 10.395387, valid precision: 0.880000, valid loss: 81.115453
epoch: 518, train precision: 0.997156, train loss: 10.712519, valid precision: 0.874800, valid loss: 80.902548
epoch: 519, train precision: 0.998044, train loss: 10.507330, valid precision: 0.881200, valid loss: 79.119381
epoch: 520, train precision: 0.997889, train loss: 10.392815, valid precision: 0.876800, valid loss: 82.515352
epoch: 521, train precision: 0.998156, train loss: 10.449128, valid precision: 0.872200, valid loss: 82.300019
epoch: 522, train precision: 0.997600, train loss: 10.597629, valid precision: 0.875200, valid loss: 80.511204
epoch: 523, train precision: 0.997933, train loss: 10.524768, valid precision: 0.872600, valid loss: 81.183816
epoch: 524, train precision: 0.998311, train loss: 10.463095, valid precision: 0.876800, valid loss: 81.213876
epoch: 525, train precision: 0.997911, train loss: 10.506561, valid precision: 0.877000, valid loss: 83.108262
epoch: 526, train precision: 0.998356, train loss: 10.384842, valid precision: 0.875200, valid loss: 80.434371
epoch: 527, train precision: 0.998422, train loss: 10.390743, valid precision: 0.874600, valid loss: 79.932169
epoch: 528, train precision: 0.998200, train loss: 10.447089, valid precision: 0.875200, valid loss: 82.926625
epoch: 529, train precision: 0.998533, train loss: 10.273085, valid precision: 0.874800, valid loss: 81.660104
epoch: 530, train precision: 0.998333, train loss: 10.401804, valid precision: 0.876600, valid loss: 78.740684
epoch: 531, train precision: 0.998089, train loss: 10.463351, valid precision: 0.878200, valid loss: 81.866938
epoch: 532, train precision: 0.997511, train loss: 10.638498, valid precision: 0.877800, valid loss: 81.391841
epoch: 533, train precision: 0.998200, train loss: 10.498043, valid precision: 0.875200, valid loss: 82.030461
epoch: 534, train precision: 0.998578, train loss: 10.338603, valid precision: 0.880800, valid loss: 79.119109
epoch: 535, train precision: 0.998044, train loss: 10.483260, valid precision: 0.878200, valid loss: 81.866832
epoch: 536, train precision: 0.998000, train loss: 10.529485, valid precision: 0.879000, valid loss: 78.091079
epoch: 537, train precision: 0.998000, train loss: 10.482936, valid precision: 0.876400, valid loss: 81.621100
epoch: 538, train precision: 0.997400, train loss: 10.655837, valid precision: 0.876200, valid loss: 83.395657
epoch: 539, train precision: 0.998422, train loss: 10.398007, valid precision: 0.876000, valid loss: 80.587524
epoch: 540, train precision: 0.998556, train loss: 10.400026, valid precision: 0.874200, valid loss: 80.760703
epoch: 541, train precision: 0.998533, train loss: 10.342998, valid precision: 0.876800, valid loss: 82.106244
epoch: 542, train precision: 0.998000, train loss: 10.603418, valid precision: 0.874600, valid loss: 81.383712
epoch: 543, train precision: 0.998111, train loss: 10.498530, valid precision: 0.874200, valid loss: 82.276372
epoch: 544, train precision: 0.998667, train loss: 10.353466, valid precision: 0.876600, valid loss: 82.851958
epoch: 545, train precision: 0.997511, train loss: 10.686742, valid precision: 0.876000, valid loss: 82.001963
epoch: 546, train precision: 0.998311, train loss: 10.428780, valid precision: 0.879000, valid loss: 81.473665
epoch: 547, train precision: 0.997978, train loss: 10.455116, valid precision: 0.874800, valid loss: 81.764089
epoch: 548, train precision: 0.997911, train loss: 10.600118, valid precision: 0.873800, valid loss: 81.778780
epoch: 549, train precision: 0.997689, train loss: 10.585900, valid precision: 0.878200, valid loss: 82.017867
epoch: 550, train precision: 0.998111, train loss: 10.460610, valid precision: 0.875800, valid loss: 83.091481
epoch: 551, train precision: 0.998244, train loss: 10.476965, valid precision: 0.873600, valid loss: 83.603658
epoch: 552, train precision: 0.997533, train loss: 10.628222, valid precision: 0.876600, valid loss: 83.187456
epoch: 553, train precision: 0.998600, train loss: 10.389386, valid precision: 0.877200, valid loss: 82.848065
epoch: 554, train precision: 0.998178, train loss: 10.441037, valid precision: 0.871800, valid loss: 86.576987
epoch: 555, train precision: 0.997578, train loss: 10.606124, valid precision: 0.873600, valid loss: 84.881186
epoch: 556, train precision: 0.997733, train loss: 10.618627, valid precision: 0.879000, valid loss: 83.778455
epoch: 557, train precision: 0.998400, train loss: 10.459953, valid precision: 0.878000, valid loss: 81.210294
epoch: 558, train precision: 0.998267, train loss: 10.422752, valid precision: 0.881400, valid loss: 83.062486
epoch: 559, train precision: 0.998200, train loss: 10.457921, valid precision: 0.879400, valid loss: 82.305592
epoch: 560, train precision: 0.998289, train loss: 10.446558, valid precision: 0.875600, valid loss: 83.686375
epoch: 561, train precision: 0.997822, train loss: 10.587216, valid precision: 0.875800, valid loss: 83.150553
epoch: 562, train precision: 0.998489, train loss: 10.355474, valid precision: 0.875400, valid loss: 81.666770
epoch: 563, train precision: 0.997711, train loss: 10.601636, valid precision: 0.873000, valid loss: 83.546341
epoch: 564, train precision: 0.997956, train loss: 10.539157, valid precision: 0.873400, valid loss: 83.302287
epoch: 565, train precision: 0.998267, train loss: 10.416160, valid precision: 0.875200, valid loss: 84.085209
epoch: 566, train precision: 0.997267, train loss: 10.740986, valid precision: 0.871000, valid loss: 82.508194
epoch: 567, train precision: 0.997644, train loss: 10.683732, valid precision: 0.872800, valid loss: 83.809690
epoch: 568, train precision: 0.997911, train loss: 10.589121, valid precision: 0.872800, valid loss: 84.314193
epoch: 569, train precision: 0.998178, train loss: 10.562488, valid precision: 0.877400, valid loss: 81.148205
epoch: 570, train precision: 0.998489, train loss: 10.370036, valid precision: 0.877800, valid loss: 80.613154
epoch: 571, train precision: 0.998467, train loss: 10.423660, valid precision: 0.880400, valid loss: 80.457770
epoch: 572, train precision: 0.998133, train loss: 10.632176, valid precision: 0.878000, valid loss: 79.036180
epoch: 573, train precision: 0.996933, train loss: 10.876163, valid precision: 0.869200, valid loss: 82.676779
epoch: 574, train precision: 0.998111, train loss: 10.543398, valid precision: 0.879000, valid loss: 80.235155
epoch: 575, train precision: 0.997956, train loss: 10.593548, valid precision: 0.874600, valid loss: 80.130525
epoch: 576, train precision: 0.997822, train loss: 10.600909, valid precision: 0.875600, valid loss: 80.749196
epoch: 577, train precision: 0.997956, train loss: 10.523302, valid precision: 0.877800, valid loss: 81.583770
epoch: 578, train precision: 0.998067, train loss: 10.590514, valid precision: 0.880200, valid loss: 82.106220
epoch: 579, train precision: 0.998067, train loss: 10.569833, valid precision: 0.877600, valid loss: 81.292676
epoch: 580, train precision: 0.998089, train loss: 10.510932, valid precision: 0.878800, valid loss: 81.123712
epoch: 581, train precision: 0.998644, train loss: 10.408813, valid precision: 0.872600, valid loss: 83.206886
epoch: 582, train precision: 0.998200, train loss: 10.487028, valid precision: 0.880600, valid loss: 80.761866
epoch: 583, train precision: 0.997600, train loss: 10.721235, valid precision: 0.875800, valid loss: 82.334590
epoch: 584, train precision: 0.998111, train loss: 10.619821, valid precision: 0.879600, valid loss: 79.092461
epoch: 585, train precision: 0.997933, train loss: 10.746360, valid precision: 0.874000, valid loss: 84.349610
epoch: 586, train precision: 0.998489, train loss: 10.483767, valid precision: 0.880800, valid loss: 79.816624
epoch: 587, train precision: 0.998622, train loss: 10.448696, valid precision: 0.879600, valid loss: 78.863668
epoch: 588, train precision: 0.998067, train loss: 10.557525, valid precision: 0.878600, valid loss: 80.550486
epoch: 589, train precision: 0.998222, train loss: 10.560429, valid precision: 0.873600, valid loss: 83.665862
epoch: 590, train precision: 0.998556, train loss: 10.410575, valid precision: 0.877400, valid loss: 80.694240
epoch: 591, train precision: 0.998089, train loss: 10.555307, valid precision: 0.872000, valid loss: 82.222132
epoch: 592, train precision: 0.998000, train loss: 10.629613, valid precision: 0.871800, valid loss: 81.644940
epoch: 593, train precision: 0.998244, train loss: 10.565947, valid precision: 0.875400, valid loss: 79.955745
epoch: 594, train precision: 0.998422, train loss: 10.450686, valid precision: 0.874600, valid loss: 80.924126
epoch: 595, train precision: 0.998422, train loss: 10.448679, valid precision: 0.875600, valid loss: 81.859253
epoch: 596, train precision: 0.998111, train loss: 10.573391, valid precision: 0.876000, valid loss: 81.226393
epoch: 597, train precision: 0.998533, train loss: 10.413862, valid precision: 0.875200, valid loss: 81.714245
epoch: 598, train precision: 0.998200, train loss: 10.535669, valid precision: 0.876000, valid loss: 82.588681
epoch: 599, train precision: 0.998311, train loss: 10.543845, valid precision: 0.874000, valid loss: 82.812600
epoch: 600, train precision: 0.998778, train loss: 10.368815, valid precision: 0.877600, valid loss: 80.682094
epoch: 601, train precision: 0.998133, train loss: 10.651425, valid precision: 0.878000, valid loss: 80.221601
epoch: 602, train precision: 0.997533, train loss: 10.740206, valid precision: 0.879600, valid loss: 81.691050
epoch: 603, train precision: 0.998311, train loss: 10.474466, valid precision: 0.877400, valid loss: 80.689399
epoch: 604, train precision: 0.997978, train loss: 10.609315, valid precision: 0.875400, valid loss: 82.033757
epoch: 605, train precision: 0.998178, train loss: 10.613586, valid precision: 0.874400, valid loss: 79.280444
epoch: 606, train precision: 0.998311, train loss: 10.522654, valid precision: 0.874800, valid loss: 79.743165
epoch: 607, train precision: 0.998333, train loss: 10.534900, valid precision: 0.880000, valid loss: 78.708518
epoch: 608, train precision: 0.998089, train loss: 10.636704, valid precision: 0.877800, valid loss: 80.179306
epoch: 609, train precision: 0.998200, train loss: 10.555012, valid precision: 0.875800, valid loss: 81.497498
epoch: 610, train precision: 0.998489, train loss: 10.451614, valid precision: 0.875400, valid loss: 82.185689
epoch: 611, train precision: 0.998111, train loss: 10.579065, valid precision: 0.874600, valid loss: 80.759428
epoch: 612, train precision: 0.997933, train loss: 10.753214, valid precision: 0.875800, valid loss: 81.523286
epoch: 613, train precision: 0.998489, train loss: 10.529061, valid precision: 0.878000, valid loss: 80.994143
epoch: 614, train precision: 0.997867, train loss: 10.683341, valid precision: 0.873800, valid loss: 81.391854
epoch: 615, train precision: 0.997622, train loss: 10.786208, valid precision: 0.876800, valid loss: 80.625751
epoch: 616, train precision: 0.998156, train loss: 10.594757, valid precision: 0.873600, valid loss: 80.395071
epoch: 617, train precision: 0.998644, train loss: 10.482105, valid precision: 0.880600, valid loss: 82.088635
epoch: 618, train precision: 0.998422, train loss: 10.522516, valid precision: 0.879200, valid loss: 79.058658
epoch: 619, train precision: 0.997822, train loss: 10.669472, valid precision: 0.878200, valid loss: 79.462303
epoch: 620, train precision: 0.998400, train loss: 10.524250, valid precision: 0.874800, valid loss: 80.954241
epoch: 621, train precision: 0.998067, train loss: 10.598133, valid precision: 0.878800, valid loss: 82.994171
epoch: 622, train precision: 0.998467, train loss: 10.489371, valid precision: 0.879000, valid loss: 78.307637
epoch: 623, train precision: 0.998356, train loss: 10.512708, valid precision: 0.877400, valid loss: 81.656520
epoch: 624, train precision: 0.998533, train loss: 10.523625, valid precision: 0.876600, valid loss: 82.119938
epoch: 625, train precision: 0.998178, train loss: 10.609651, valid precision: 0.874400, valid loss: 79.530879
epoch: 626, train precision: 0.997267, train loss: 10.930404, valid precision: 0.873600, valid loss: 82.693750
epoch: 627, train precision: 0.997400, train loss: 10.855862, valid precision: 0.875800, valid loss: 84.445056
epoch: 628, train precision: 0.998089, train loss: 10.667784, valid precision: 0.875200, valid loss: 84.167027
epoch: 629, train precision: 0.997933, train loss: 10.595167, valid precision: 0.874800, valid loss: 82.489929
epoch: 630, train precision: 0.998244, train loss: 10.622066, valid precision: 0.876200, valid loss: 82.736834
epoch: 631, train precision: 0.998467, train loss: 10.502125, valid precision: 0.874200, valid loss: 81.350984
epoch: 632, train precision: 0.997956, train loss: 10.659951, valid precision: 0.876400, valid loss: 80.139455
epoch: 633, train precision: 0.998489, train loss: 10.500578, valid precision: 0.876800, valid loss: 80.922033
epoch: 634, train precision: 0.998000, train loss: 10.624689, valid precision: 0.877600, valid loss: 81.964828
epoch: 635, train precision: 0.997822, train loss: 10.692965, valid precision: 0.877400, valid loss: 82.029172
epoch: 636, train precision: 0.998089, train loss: 10.687244, valid precision: 0.879800, valid loss: 80.988446
epoch: 637, train precision: 0.997756, train loss: 10.763317, valid precision: 0.878000, valid loss: 82.279525
epoch: 638, train precision: 0.997978, train loss: 10.617309, valid precision: 0.879000, valid loss: 82.018423
epoch: 639, train precision: 0.998244, train loss: 10.633252, valid precision: 0.878200, valid loss: 80.756610
epoch: 640, train precision: 0.998000, train loss: 10.681347, valid precision: 0.875000, valid loss: 80.576579
epoch: 641, train precision: 0.998356, train loss: 10.516928, valid precision: 0.877000, valid loss: 81.076257
epoch: 642, train precision: 0.998733, train loss: 10.511365, valid precision: 0.876200, valid loss: 79.606301
epoch: 643, train precision: 0.998244, train loss: 10.583873, valid precision: 0.879600, valid loss: 80.194171
epoch: 644, train precision: 0.998044, train loss: 10.686173, valid precision: 0.877200, valid loss: 81.269065
epoch: 645, train precision: 0.998489, train loss: 10.437040, valid precision: 0.876600, valid loss: 81.612485
epoch: 646, train precision: 0.997156, train loss: 10.907640, valid precision: 0.871400, valid loss: 82.622160
epoch: 647, train precision: 0.998156, train loss: 10.638429, valid precision: 0.877600, valid loss: 80.332544
epoch: 648, train precision: 0.998844, train loss: 10.496812, valid precision: 0.882400, valid loss: 79.165909
epoch: 649, train precision: 0.998689, train loss: 10.544578, valid precision: 0.879800, valid loss: 79.836445
epoch: 650, train precision: 0.998067, train loss: 10.712979, valid precision: 0.881400, valid loss: 78.560598
epoch: 651, train precision: 0.998200, train loss: 10.544599, valid precision: 0.876800, valid loss: 79.722629
epoch: 652, train precision: 0.998378, train loss: 10.601642, valid precision: 0.880600, valid loss: 77.890337
epoch: 653, train precision: 0.998667, train loss: 10.441888, valid precision: 0.879800, valid loss: 79.420821
epoch: 654, train precision: 0.998178, train loss: 10.613504, valid precision: 0.875800, valid loss: 79.565586
epoch: 655, train precision: 0.998800, train loss: 10.522053, valid precision: 0.879800, valid loss: 78.580452
epoch: 656, train precision: 0.998489, train loss: 10.535245, valid precision: 0.883200, valid loss: 80.541771
epoch: 657, train precision: 0.998778, train loss: 10.513786, valid precision: 0.880000, valid loss: 78.453987
epoch: 658, train precision: 0.998356, train loss: 10.590694, valid precision: 0.873400, valid loss: 79.466658
epoch: 659, train precision: 0.998067, train loss: 10.626420, valid precision: 0.877200, valid loss: 80.623265
epoch: 660, train precision: 0.998378, train loss: 10.555144, valid precision: 0.878400, valid loss: 79.352966
epoch: 661, train precision: 0.998267, train loss: 10.612226, valid precision: 0.874400, valid loss: 82.944497
epoch: 662, train precision: 0.998267, train loss: 10.615546, valid precision: 0.877800, valid loss: 79.049296
epoch: 663, train precision: 0.998222, train loss: 10.597238, valid precision: 0.878600, valid loss: 78.388898
epoch: 664, train precision: 0.997978, train loss: 10.705600, valid precision: 0.875800, valid loss: 79.790616
epoch: 665, train precision: 0.998533, train loss: 10.484913, valid precision: 0.882400, valid loss: 79.516840
epoch: 666, train precision: 0.998400, train loss: 10.568595, valid precision: 0.877800, valid loss: 79.086198
epoch: 667, train precision: 0.998311, train loss: 10.648963, valid precision: 0.878200, valid loss: 80.599840
epoch: 668, train precision: 0.998267, train loss: 10.565524, valid precision: 0.876000, valid loss: 80.279190
epoch: 669, train precision: 0.998956, train loss: 10.508054, valid precision: 0.882400, valid loss: 79.838769
epoch: 670, train precision: 0.998400, train loss: 10.610357, valid precision: 0.878400, valid loss: 81.143413
epoch: 671, train precision: 0.998244, train loss: 10.652704, valid precision: 0.878400, valid loss: 80.506159
epoch: 672, train precision: 0.997711, train loss: 10.803878, valid precision: 0.879800, valid loss: 80.327828
epoch: 673, train precision: 0.999089, train loss: 10.386324, valid precision: 0.879400, valid loss: 79.492845
epoch: 674, train precision: 0.998467, train loss: 10.503944, valid precision: 0.876800, valid loss: 80.593990
epoch: 675, train precision: 0.998756, train loss: 10.576511, valid precision: 0.874600, valid loss: 82.104817
epoch: 676, train precision: 0.997978, train loss: 10.834231, valid precision: 0.874600, valid loss: 84.325197
epoch: 677, train precision: 0.998000, train loss: 10.764091, valid precision: 0.877000, valid loss: 82.913941
epoch: 678, train precision: 0.998289, train loss: 10.589033, valid precision: 0.877600, valid loss: 80.710914
epoch: 679, train precision: 0.998578, train loss: 10.586139, valid precision: 0.879200, valid loss: 80.056751
epoch: 680, train precision: 0.998644, train loss: 10.498598, valid precision: 0.878200, valid loss: 78.446405
epoch: 681, train precision: 0.997800, train loss: 10.794777, valid precision: 0.872400, valid loss: 83.137589
epoch: 682, train precision: 0.998222, train loss: 10.586452, valid precision: 0.872800, valid loss: 80.494686
epoch: 683, train precision: 0.998578, train loss: 10.580568, valid precision: 0.877400, valid loss: 79.731503
epoch: 684, train precision: 0.998244, train loss: 10.664272, valid precision: 0.877800, valid loss: 80.656557
epoch: 685, train precision: 0.998378, train loss: 10.645140, valid precision: 0.883400, valid loss: 79.788272
epoch: 686, train precision: 0.998244, train loss: 10.633518, valid precision: 0.877400, valid loss: 81.674824
epoch: 687, train precision: 0.998822, train loss: 10.471717, valid precision: 0.879400, valid loss: 79.944328
epoch: 688, train precision: 0.998422, train loss: 10.504120, valid precision: 0.876400, valid loss: 80.944925
epoch: 689, train precision: 0.998089, train loss: 10.711690, valid precision: 0.880600, valid loss: 81.452960
epoch: 690, train precision: 0.998467, train loss: 10.628993, valid precision: 0.879800, valid loss: 80.260053
epoch: 691, train precision: 0.998378, train loss: 10.637189, valid precision: 0.879400, valid loss: 82.903934
epoch: 692, train precision: 0.998267, train loss: 10.685649, valid precision: 0.876400, valid loss: 80.755503
epoch: 693, train precision: 0.998578, train loss: 10.475765, valid precision: 0.875800, valid loss: 82.157674
epoch: 694, train precision: 0.998756, train loss: 10.537556, valid precision: 0.879000, valid loss: 80.527252
epoch: 695, train precision: 0.998289, train loss: 10.648963, valid precision: 0.876600, valid loss: 81.180220
epoch: 696, train precision: 0.998111, train loss: 10.774007, valid precision: 0.878000, valid loss: 81.741043
epoch: 697, train precision: 0.998289, train loss: 10.594383, valid precision: 0.881400, valid loss: 81.119905
epoch: 698, train precision: 0.998311, train loss: 10.614931, valid precision: 0.883200, valid loss: 81.005077
epoch: 699, train precision: 0.998356, train loss: 10.749437, valid precision: 0.879400, valid loss: 79.689453
epoch: 700, train precision: 0.998511, train loss: 10.624765, valid precision: 0.876600, valid loss: 79.772440
epoch: 701, train precision: 0.997756, train loss: 10.821858, valid precision: 0.879000, valid loss: 79.893263
epoch: 702, train precision: 0.998511, train loss: 10.596796, valid precision: 0.877800, valid loss: 79.017015
epoch: 703, train precision: 0.998467, train loss: 10.579890, valid precision: 0.879600, valid loss: 81.206831
epoch: 704, train precision: 0.998467, train loss: 10.632604, valid precision: 0.873600, valid loss: 81.499974
epoch: 705, train precision: 0.998267, train loss: 10.758947, valid precision: 0.876200, valid loss: 84.416673
epoch: 706, train precision: 0.998422, train loss: 10.625483, valid precision: 0.876200, valid loss: 81.081311
epoch: 707, train precision: 0.998844, train loss: 10.476583, valid precision: 0.879600, valid loss: 79.003431
epoch: 708, train precision: 0.998333, train loss: 10.627024, valid precision: 0.877200, valid loss: 81.195685
epoch: 709, train precision: 0.998667, train loss: 10.605685, valid precision: 0.876600, valid loss: 77.909641
epoch: 710, train precision: 0.998267, train loss: 10.626367, valid precision: 0.878600, valid loss: 80.206417
epoch: 711, train precision: 0.998444, train loss: 10.587979, valid precision: 0.875000, valid loss: 79.986616
epoch: 712, train precision: 0.998400, train loss: 10.605172, valid precision: 0.874800, valid loss: 80.073482
epoch: 713, train precision: 0.998489, train loss: 10.579003, valid precision: 0.877400, valid loss: 81.334759
epoch: 714, train precision: 0.998556, train loss: 10.655914, valid precision: 0.876200, valid loss: 82.218004
epoch: 715, train precision: 0.998533, train loss: 10.597980, valid precision: 0.876000, valid loss: 80.900957
epoch: 716, train precision: 0.998400, train loss: 10.701146, valid precision: 0.872800, valid loss: 82.717694
epoch: 717, train precision: 0.998689, train loss: 10.537672, valid precision: 0.876000, valid loss: 80.852746
epoch: 718, train precision: 0.998489, train loss: 10.538263, valid precision: 0.876400, valid loss: 80.699036
epoch: 719, train precision: 0.998089, train loss: 10.718790, valid precision: 0.878800, valid loss: 80.589771
epoch: 720, train precision: 0.998711, train loss: 10.580004, valid precision: 0.875400, valid loss: 81.187374
epoch: 721, train precision: 0.998667, train loss: 10.617709, valid precision: 0.877200, valid loss: 81.362826
epoch: 722, train precision: 0.998600, train loss: 10.547477, valid precision: 0.876000, valid loss: 82.850695
epoch: 723, train precision: 0.998622, train loss: 10.530615, valid precision: 0.880000, valid loss: 80.835384
epoch: 724, train precision: 0.998378, train loss: 10.641384, valid precision: 0.881000, valid loss: 79.340844
epoch: 725, train precision: 0.998289, train loss: 10.642509, valid precision: 0.878400, valid loss: 82.170732
epoch: 726, train precision: 0.998244, train loss: 10.619141, valid precision: 0.875800, valid loss: 82.630427
epoch: 727, train precision: 0.998556, train loss: 10.524386, valid precision: 0.877600, valid loss: 81.709451
epoch: 728, train precision: 0.998556, train loss: 10.593918, valid precision: 0.879400, valid loss: 80.536236
epoch: 729, train precision: 0.997978, train loss: 10.725270, valid precision: 0.872400, valid loss: 81.959781
epoch: 730, train precision: 0.998800, train loss: 10.516384, valid precision: 0.878200, valid loss: 82.091399
epoch: 731, train precision: 0.998578, train loss: 10.653280, valid precision: 0.876600, valid loss: 80.546357
epoch: 732, train precision: 0.998511, train loss: 10.645046, valid precision: 0.877200, valid loss: 82.047064
epoch: 733, train precision: 0.998800, train loss: 10.554928, valid precision: 0.881000, valid loss: 80.063511
epoch: 734, train precision: 0.998244, train loss: 10.695431, valid precision: 0.877800, valid loss: 80.253490
epoch: 735, train precision: 0.998889, train loss: 10.493846, valid precision: 0.878200, valid loss: 81.691370
epoch: 736, train precision: 0.998911, train loss: 10.459288, valid precision: 0.878000, valid loss: 80.532910
epoch: 737, train precision: 0.998733, train loss: 10.580747, valid precision: 0.877400, valid loss: 80.221092
epoch: 738, train precision: 0.998689, train loss: 10.536194, valid precision: 0.881800, valid loss: 81.723604
epoch: 739, train precision: 0.998267, train loss: 10.632783, valid precision: 0.878400, valid loss: 81.312139
epoch: 740, train precision: 0.998089, train loss: 10.633028, valid precision: 0.878000, valid loss: 83.683727
epoch: 741, train precision: 0.998022, train loss: 10.751023, valid precision: 0.878200, valid loss: 81.172647
epoch: 742, train precision: 0.998200, train loss: 10.761812, valid precision: 0.875600, valid loss: 81.398544
epoch: 743, train precision: 0.998533, train loss: 10.568530, valid precision: 0.877200, valid loss: 83.794451
epoch: 744, train precision: 0.998244, train loss: 10.636968, valid precision: 0.875600, valid loss: 86.316345
epoch: 745, train precision: 0.998689, train loss: 10.535172, valid precision: 0.876800, valid loss: 82.377818
epoch: 746, train precision: 0.997756, train loss: 10.778192, valid precision: 0.874800, valid loss: 84.415693
epoch: 747, train precision: 0.998489, train loss: 10.619652, valid precision: 0.878400, valid loss: 82.990637
epoch: 748, train precision: 0.998600, train loss: 10.626534, valid precision: 0.877200, valid loss: 83.934426
epoch: 749, train precision: 0.997489, train loss: 10.919729, valid precision: 0.870800, valid loss: 83.495828
epoch: 750, train precision: 0.998689, train loss: 10.498708, valid precision: 0.877400, valid loss: 81.598293
epoch: 751, train precision: 0.998556, train loss: 10.597809, valid precision: 0.876000, valid loss: 81.207622
epoch: 752, train precision: 0.998533, train loss: 10.552644, valid precision: 0.878400, valid loss: 84.530439
epoch: 753, train precision: 0.998378, train loss: 10.725615, valid precision: 0.874600, valid loss: 83.497170
epoch: 754, train precision: 0.997933, train loss: 10.798797, valid precision: 0.878800, valid loss: 81.774371
epoch: 755, train precision: 0.997933, train loss: 10.801045, valid precision: 0.875200, valid loss: 82.418943
epoch: 756, train precision: 0.998311, train loss: 10.701281, valid precision: 0.876400, valid loss: 81.894864
epoch: 757, train precision: 0.998800, train loss: 10.537270, valid precision: 0.878000, valid loss: 83.182177
epoch: 758, train precision: 0.998844, train loss: 10.522466, valid precision: 0.875800, valid loss: 84.319212
epoch: 759, train precision: 0.998556, train loss: 10.650152, valid precision: 0.873200, valid loss: 85.459993
epoch: 760, train precision: 0.998911, train loss: 10.513612, valid precision: 0.876600, valid loss: 84.303588
epoch: 761, train precision: 0.998356, train loss: 10.583989, valid precision: 0.876600, valid loss: 85.027568
epoch: 762, train precision: 0.998467, train loss: 10.672627, valid precision: 0.875000, valid loss: 84.205487
epoch: 763, train precision: 0.998667, train loss: 10.613110, valid precision: 0.880200, valid loss: 81.638912
epoch: 764, train precision: 0.998022, train loss: 10.748801, valid precision: 0.878000, valid loss: 83.335155
epoch: 765, train precision: 0.998600, train loss: 10.619505, valid precision: 0.873400, valid loss: 83.548616
epoch: 766, train precision: 0.998800, train loss: 10.521633, valid precision: 0.884200, valid loss: 81.401272
epoch: 767, train precision: 0.998600, train loss: 10.499317, valid precision: 0.878200, valid loss: 82.543696
epoch: 768, train precision: 0.998244, train loss: 10.734628, valid precision: 0.879400, valid loss: 83.213212
epoch: 769, train precision: 0.998667, train loss: 10.702718, valid precision: 0.881800, valid loss: 79.051708
epoch: 770, train precision: 0.998467, train loss: 10.604268, valid precision: 0.879800, valid loss: 78.768787
epoch: 771, train precision: 0.998644, train loss: 10.620189, valid precision: 0.875200, valid loss: 79.817538
epoch: 772, train precision: 0.998533, train loss: 10.693285, valid precision: 0.877400, valid loss: 80.956976
epoch: 773, train precision: 0.998644, train loss: 10.581141, valid precision: 0.874600, valid loss: 83.709067
epoch: 774, train precision: 0.998289, train loss: 10.678609, valid precision: 0.879600, valid loss: 81.337899
epoch: 775, train precision: 0.998689, train loss: 10.576228, valid precision: 0.882600, valid loss: 80.600901
epoch: 776, train precision: 0.998578, train loss: 10.573369, valid precision: 0.884000, valid loss: 78.830471
epoch: 777, train precision: 0.998689, train loss: 10.592413, valid precision: 0.876400, valid loss: 80.420366
epoch: 778, train precision: 0.997956, train loss: 10.777202, valid precision: 0.879800, valid loss: 81.222250
epoch: 779, train precision: 0.998600, train loss: 10.567442, valid precision: 0.878800, valid loss: 80.130136
epoch: 780, train precision: 0.998511, train loss: 10.536972, valid precision: 0.879400, valid loss: 81.230740
epoch: 781, train precision: 0.998044, train loss: 10.824835, valid precision: 0.875600, valid loss: 80.491741
epoch: 782, train precision: 0.998444, train loss: 10.662802, valid precision: 0.878600, valid loss: 79.971209
epoch: 783, train precision: 0.998533, train loss: 10.718752, valid precision: 0.876800, valid loss: 82.374577
epoch: 784, train precision: 0.998644, train loss: 10.558252, valid precision: 0.879000, valid loss: 82.789557
epoch: 785, train precision: 0.998867, train loss: 10.556857, valid precision: 0.878000, valid loss: 81.130008
epoch: 786, train precision: 0.998644, train loss: 10.639146, valid precision: 0.875800, valid loss: 81.385465
epoch: 787, train precision: 0.998022, train loss: 10.726988, valid precision: 0.876200, valid loss: 81.906335
epoch: 788, train precision: 0.998267, train loss: 10.761230, valid precision: 0.878400, valid loss: 82.383901
epoch: 789, train precision: 0.998644, train loss: 10.580751, valid precision: 0.876400, valid loss: 82.576762
epoch: 790, train precision: 0.998644, train loss: 10.645002, valid precision: 0.880400, valid loss: 82.820676
epoch: 791, train precision: 0.998222, train loss: 10.729075, valid precision: 0.878000, valid loss: 83.258964
epoch: 792, train precision: 0.998889, train loss: 10.481366, valid precision: 0.878600, valid loss: 82.428553
epoch: 793, train precision: 0.998356, train loss: 10.688022, valid precision: 0.873200, valid loss: 83.493931
epoch: 794, train precision: 0.998111, train loss: 10.713980, valid precision: 0.872200, valid loss: 84.637268
epoch: 795, train precision: 0.998311, train loss: 10.636362, valid precision: 0.878600, valid loss: 81.400360
epoch: 796, train precision: 0.997956, train loss: 10.797404, valid precision: 0.874000, valid loss: 83.027990
epoch: 797, train precision: 0.998556, train loss: 10.662161, valid precision: 0.880000, valid loss: 80.126722
epoch: 798, train precision: 0.998622, train loss: 10.581997, valid precision: 0.877400, valid loss: 80.829567
epoch: 799, train precision: 0.998467, train loss: 10.632526, valid precision: 0.874400, valid loss: 81.922038
epoch: 800, train precision: 0.997933, train loss: 10.915706, valid precision: 0.875200, valid loss: 83.611799
epoch: 801, train precision: 0.998800, train loss: 10.583300, valid precision: 0.879600, valid loss: 82.255075
epoch: 802, train precision: 0.998644, train loss: 10.526272, valid precision: 0.877200, valid loss: 82.797543
epoch: 803, train precision: 0.998044, train loss: 10.781332, valid precision: 0.876400, valid loss: 83.262005
epoch: 804, train precision: 0.998600, train loss: 10.643944, valid precision: 0.881000, valid loss: 78.617151
epoch: 805, train precision: 0.998178, train loss: 10.668004, valid precision: 0.876800, valid loss: 82.188727
epoch: 806, train precision: 0.998578, train loss: 10.710240, valid precision: 0.877000, valid loss: 83.507420
epoch: 807, train precision: 0.997978, train loss: 10.794621, valid precision: 0.872800, valid loss: 84.688918
epoch: 808, train precision: 0.998156, train loss: 10.756858, valid precision: 0.871800, valid loss: 82.871798
epoch: 809, train precision: 0.998222, train loss: 10.718675, valid precision: 0.874800, valid loss: 82.572269
epoch: 810, train precision: 0.998733, train loss: 10.539121, valid precision: 0.874800, valid loss: 81.245443
epoch: 811, train precision: 0.998511, train loss: 10.765076, valid precision: 0.877200, valid loss: 83.204001
epoch: 812, train precision: 0.999156, train loss: 10.457816, valid precision: 0.876600, valid loss: 82.431741
epoch: 813, train precision: 0.997978, train loss: 10.860935, valid precision: 0.876400, valid loss: 81.596138
epoch: 814, train precision: 0.998156, train loss: 10.826642, valid precision: 0.871600, valid loss: 84.462984
epoch: 815, train precision: 0.998600, train loss: 10.637316, valid precision: 0.881400, valid loss: 83.155024
epoch: 816, train precision: 0.998244, train loss: 10.679343, valid precision: 0.877800, valid loss: 81.384598
epoch: 817, train precision: 0.998400, train loss: 10.688904, valid precision: 0.876600, valid loss: 80.533326
epoch: 818, train precision: 0.997956, train loss: 10.888061, valid precision: 0.876600, valid loss: 82.795037
epoch: 819, train precision: 0.998400, train loss: 10.671645, valid precision: 0.877000, valid loss: 80.634273
epoch: 820, train precision: 0.998600, train loss: 10.646731, valid precision: 0.878800, valid loss: 81.898156
epoch: 821, train precision: 0.998956, train loss: 10.514978, valid precision: 0.876600, valid loss: 81.888125
epoch: 822, train precision: 0.998511, train loss: 10.619989, valid precision: 0.881200, valid loss: 80.471019
epoch: 823, train precision: 0.998511, train loss: 10.644441, valid precision: 0.878400, valid loss: 79.679900
epoch: 824, train precision: 0.998400, train loss: 10.729181, valid precision: 0.877800, valid loss: 81.888210
epoch: 825, train precision: 0.998600, train loss: 10.630808, valid precision: 0.879400, valid loss: 83.327362
epoch: 826, train precision: 0.998289, train loss: 10.694808, valid precision: 0.882800, valid loss: 80.577059
epoch: 827, train precision: 0.998867, train loss: 10.635334, valid precision: 0.878200, valid loss: 81.572028
epoch: 828, train precision: 0.998733, train loss: 10.593840, valid precision: 0.879400, valid loss: 81.060771
epoch: 829, train precision: 0.998978, train loss: 10.599205, valid precision: 0.878000, valid loss: 82.129202
epoch: 830, train precision: 0.998867, train loss: 10.555942, valid precision: 0.874600, valid loss: 82.384250
epoch: 831, train precision: 0.998244, train loss: 10.817406, valid precision: 0.872000, valid loss: 84.975770
epoch: 832, train precision: 0.998467, train loss: 10.664391, valid precision: 0.875000, valid loss: 80.257243
epoch: 833, train precision: 0.998911, train loss: 10.573087, valid precision: 0.876400, valid loss: 81.041426
epoch: 834, train precision: 0.998711, train loss: 10.573782, valid precision: 0.879000, valid loss: 83.359164
epoch: 835, train precision: 0.998511, train loss: 10.732869, valid precision: 0.874200, valid loss: 84.812200
epoch: 836, train precision: 0.998533, train loss: 10.676590, valid precision: 0.872800, valid loss: 82.848541
epoch: 837, train precision: 0.998933, train loss: 10.549039, valid precision: 0.877600, valid loss: 81.595736
epoch: 838, train precision: 0.998422, train loss: 10.723242, valid precision: 0.874400, valid loss: 83.552892
epoch: 839, train precision: 0.998800, train loss: 10.602568, valid precision: 0.878600, valid loss: 83.007390
epoch: 840, train precision: 0.998733, train loss: 10.572064, valid precision: 0.877400, valid loss: 84.909322
epoch: 841, train precision: 0.998200, train loss: 10.737749, valid precision: 0.871600, valid loss: 85.335073
epoch: 842, train precision: 0.998622, train loss: 10.683752, valid precision: 0.879600, valid loss: 84.222288
epoch: 843, train precision: 0.998778, train loss: 10.588028, valid precision: 0.874600, valid loss: 80.574845
epoch: 844, train precision: 0.998711, train loss: 10.629470, valid precision: 0.878000, valid loss: 82.682516
epoch: 845, train precision: 0.998978, train loss: 10.516370, valid precision: 0.875000, valid loss: 84.425942
epoch: 846, train precision: 0.998689, train loss: 10.678597, valid precision: 0.878400, valid loss: 83.171801
epoch: 847, train precision: 0.998244, train loss: 10.782007, valid precision: 0.874600, valid loss: 84.170336
epoch: 848, train precision: 0.998467, train loss: 10.682654, valid precision: 0.875400, valid loss: 82.101693
epoch: 849, train precision: 0.998711, train loss: 10.663337, valid precision: 0.872800, valid loss: 82.518942
epoch: 850, train precision: 0.998467, train loss: 10.751556, valid precision: 0.871600, valid loss: 85.074417
epoch: 851, train precision: 0.998622, train loss: 10.653215, valid precision: 0.876600, valid loss: 83.965060
epoch: 852, train precision: 0.998867, train loss: 10.543799, valid precision: 0.877400, valid loss: 82.833622
epoch: 853, train precision: 0.998400, train loss: 10.688346, valid precision: 0.873600, valid loss: 84.515939
epoch: 854, train precision: 0.998467, train loss: 10.720105, valid precision: 0.875400, valid loss: 84.397183
epoch: 855, train precision: 0.998467, train loss: 10.688987, valid precision: 0.874200, valid loss: 83.129115
epoch: 856, train precision: 0.998800, train loss: 10.609248, valid precision: 0.872000, valid loss: 83.432149
epoch: 857, train precision: 0.998378, train loss: 10.772628, valid precision: 0.875400, valid loss: 82.992865
epoch: 858, train precision: 0.998556, train loss: 10.688186, valid precision: 0.875600, valid loss: 82.330995
epoch: 859, train precision: 0.998778, train loss: 10.652117, valid precision: 0.878800, valid loss: 81.128550
epoch: 860, train precision: 0.998556, train loss: 10.714601, valid precision: 0.876000, valid loss: 82.091963
epoch: 861, train precision: 0.998378, train loss: 10.708358, valid precision: 0.875400, valid loss: 81.630316
epoch: 862, train precision: 0.998778, train loss: 10.533799, valid precision: 0.876800, valid loss: 82.030561
epoch: 863, train precision: 0.998733, train loss: 10.628170, valid precision: 0.873000, valid loss: 82.711990
epoch: 864, train precision: 0.998578, train loss: 10.661362, valid precision: 0.877000, valid loss: 81.038806
epoch: 865, train precision: 0.998778, train loss: 10.578805, valid precision: 0.882600, valid loss: 79.257870
epoch: 866, train precision: 0.998711, train loss: 10.673232, valid precision: 0.880400, valid loss: 80.608153
epoch: 867, train precision: 0.998000, train loss: 10.832032, valid precision: 0.874600, valid loss: 82.827248
epoch: 868, train precision: 0.998311, train loss: 10.838747, valid precision: 0.876600, valid loss: 81.832813
epoch: 869, train precision: 0.998756, train loss: 10.667822, valid precision: 0.873800, valid loss: 83.698375
epoch: 870, train precision: 0.998756, train loss: 10.663154, valid precision: 0.874800, valid loss: 82.204542
epoch: 871, train precision: 0.998511, train loss: 10.680201, valid precision: 0.876000, valid loss: 81.629125
epoch: 872, train precision: 0.998444, train loss: 10.696362, valid precision: 0.874200, valid loss: 83.698960
epoch: 873, train precision: 0.998800, train loss: 10.631976, valid precision: 0.878200, valid loss: 84.801099
epoch: 874, train precision: 0.998378, train loss: 10.734767, valid precision: 0.874200, valid loss: 82.521856
epoch: 875, train precision: 0.998311, train loss: 10.776139, valid precision: 0.875200, valid loss: 82.280644
epoch: 876, train precision: 0.998733, train loss: 10.666887, valid precision: 0.879400, valid loss: 81.645351
epoch: 877, train precision: 0.998844, train loss: 10.586160, valid precision: 0.881600, valid loss: 80.758457
epoch: 878, train precision: 0.999000, train loss: 10.607545, valid precision: 0.875200, valid loss: 81.785026
epoch: 879, train precision: 0.998578, train loss: 10.653583, valid precision: 0.880000, valid loss: 82.217842
epoch: 880, train precision: 0.998356, train loss: 10.732704, valid precision: 0.883200, valid loss: 82.581484
epoch: 881, train precision: 0.998311, train loss: 10.702813, valid precision: 0.883200, valid loss: 82.483659
epoch: 882, train precision: 0.998267, train loss: 10.738615, valid precision: 0.876800, valid loss: 83.875923
epoch: 883, train precision: 0.998044, train loss: 10.858000, valid precision: 0.874800, valid loss: 87.215054
epoch: 884, train precision: 0.998800, train loss: 10.596947, valid precision: 0.877800, valid loss: 83.695542
epoch: 885, train precision: 0.998444, train loss: 10.743118, valid precision: 0.881000, valid loss: 83.586114
epoch: 886, train precision: 0.998756, train loss: 10.614954, valid precision: 0.878600, valid loss: 82.454468
epoch: 887, train precision: 0.998711, train loss: 10.563308, valid precision: 0.881200, valid loss: 81.220489
epoch: 888, train precision: 0.998400, train loss: 10.663885, valid precision: 0.880600, valid loss: 81.131048
epoch: 889, train precision: 0.998711, train loss: 10.600325, valid precision: 0.879200, valid loss: 80.773236
epoch: 890, train precision: 0.998467, train loss: 10.753105, valid precision: 0.881000, valid loss: 80.056551
epoch: 891, train precision: 0.998956, train loss: 10.613243, valid precision: 0.880000, valid loss: 79.987411
epoch: 892, train precision: 0.998956, train loss: 10.572899, valid precision: 0.879400, valid loss: 78.991689
epoch: 893, train precision: 0.998044, train loss: 10.810974, valid precision: 0.877200, valid loss: 80.745068
epoch: 894, train precision: 0.998689, train loss: 10.616143, valid precision: 0.883600, valid loss: 79.985301
epoch: 895, train precision: 0.998978, train loss: 10.665374, valid precision: 0.882200, valid loss: 80.325529
epoch: 896, train precision: 0.998911, train loss: 10.628221, valid precision: 0.883200, valid loss: 79.732775
epoch: 897, train precision: 0.999022, train loss: 10.556537, valid precision: 0.883000, valid loss: 78.659449
epoch: 898, train precision: 0.998822, train loss: 10.632929, valid precision: 0.881400, valid loss: 81.445285
epoch: 899, train precision: 0.998156, train loss: 10.888403, valid precision: 0.876600, valid loss: 81.926103
epoch: 900, train precision: 0.998600, train loss: 10.691074, valid precision: 0.878200, valid loss: 79.794153
epoch: 901, train precision: 0.998822, train loss: 10.637852, valid precision: 0.879800, valid loss: 82.084429
epoch: 902, train precision: 0.998911, train loss: 10.616090, valid precision: 0.880000, valid loss: 79.804455
epoch: 903, train precision: 0.998978, train loss: 10.515160, valid precision: 0.880000, valid loss: 81.751027
epoch: 904, train precision: 0.998667, train loss: 10.688871, valid precision: 0.881800, valid loss: 83.668191
epoch: 905, train precision: 0.998556, train loss: 10.665472, valid precision: 0.876200, valid loss: 81.636503
epoch: 906, train precision: 0.998689, train loss: 10.690411, valid precision: 0.880600, valid loss: 80.236586
epoch: 907, train precision: 0.999067, train loss: 10.535388, valid precision: 0.883200, valid loss: 80.761613
epoch: 908, train precision: 0.998378, train loss: 10.742850, valid precision: 0.880400, valid loss: 82.692226
epoch: 909, train precision: 0.998289, train loss: 10.738027, valid precision: 0.876600, valid loss: 83.284103
epoch: 910, train precision: 0.998800, train loss: 10.607687, valid precision: 0.881600, valid loss: 81.058627
epoch: 911, train precision: 0.998244, train loss: 10.705388, valid precision: 0.880600, valid loss: 80.467121
epoch: 912, train precision: 0.999244, train loss: 10.544757, valid precision: 0.881400, valid loss: 80.421197
epoch: 913, train precision: 0.998200, train loss: 10.801604, valid precision: 0.877400, valid loss: 83.114247
epoch: 914, train precision: 0.998578, train loss: 10.682931, valid precision: 0.877400, valid loss: 82.863203
epoch: 915, train precision: 0.998444, train loss: 10.690225, valid precision: 0.877200, valid loss: 82.370663
epoch: 916, train precision: 0.998733, train loss: 10.604143, valid precision: 0.877200, valid loss: 82.318007
epoch: 917, train precision: 0.998711, train loss: 10.623841, valid precision: 0.874600, valid loss: 85.652184
epoch: 918, train precision: 0.998600, train loss: 10.702195, valid precision: 0.879800, valid loss: 83.404598
epoch: 919, train precision: 0.998467, train loss: 10.714159, valid precision: 0.878800, valid loss: 82.909489
epoch: 920, train precision: 0.998911, train loss: 10.585043, valid precision: 0.879800, valid loss: 82.688851
epoch: 921, train precision: 0.999089, train loss: 10.499465, valid precision: 0.880600, valid loss: 83.564957
epoch: 922, train precision: 0.998333, train loss: 10.667632, valid precision: 0.880600, valid loss: 83.195988
epoch: 923, train precision: 0.998378, train loss: 10.728185, valid precision: 0.878000, valid loss: 84.418037
epoch: 924, train precision: 0.998733, train loss: 10.621327, valid precision: 0.878000, valid loss: 84.366928
epoch: 925, train precision: 0.999067, train loss: 10.498721, valid precision: 0.880600, valid loss: 81.402024
epoch: 926, train precision: 0.998556, train loss: 10.664233, valid precision: 0.880200, valid loss: 84.516791
epoch: 927, train precision: 0.998711, train loss: 10.628897, valid precision: 0.878000, valid loss: 83.949041
epoch: 928, train precision: 0.998822, train loss: 10.605481, valid precision: 0.879800, valid loss: 81.738642
epoch: 929, train precision: 0.998800, train loss: 10.626913, valid precision: 0.876400, valid loss: 83.070056
epoch: 930, train precision: 0.998622, train loss: 10.723896, valid precision: 0.879400, valid loss: 83.429516
epoch: 931, train precision: 0.998711, train loss: 10.622402, valid precision: 0.878800, valid loss: 82.433436
epoch: 932, train precision: 0.998622, train loss: 10.784595, valid precision: 0.871400, valid loss: 84.337289
epoch: 933, train precision: 0.998422, train loss: 10.754671, valid precision: 0.881200, valid loss: 82.926024
epoch: 934, train precision: 0.998644, train loss: 10.668729, valid precision: 0.876000, valid loss: 84.639149
epoch: 935, train precision: 0.997933, train loss: 10.886644, valid precision: 0.876000, valid loss: 83.458843
epoch: 936, train precision: 0.998644, train loss: 10.635576, valid precision: 0.877600, valid loss: 83.052373
epoch: 937, train precision: 0.998889, train loss: 10.564895, valid precision: 0.878200, valid loss: 83.827827
epoch: 938, train precision: 0.998711, train loss: 10.634497, valid precision: 0.876200, valid loss: 85.047542
epoch: 939, train precision: 0.998622, train loss: 10.715475, valid precision: 0.877400, valid loss: 84.789377
epoch: 940, train precision: 0.998400, train loss: 10.753886, valid precision: 0.880000, valid loss: 83.256305
epoch: 941, train precision: 0.998622, train loss: 10.649701, valid precision: 0.879000, valid loss: 85.184922
epoch: 942, train precision: 0.999022, train loss: 10.548674, valid precision: 0.881200, valid loss: 83.548681
epoch: 943, train precision: 0.998822, train loss: 10.609613, valid precision: 0.876200, valid loss: 82.517485
epoch: 944, train precision: 0.998622, train loss: 10.596671, valid precision: 0.877200, valid loss: 82.978555
epoch: 945, train precision: 0.998778, train loss: 10.590807, valid precision: 0.877600, valid loss: 83.640074
epoch: 946, train precision: 0.998689, train loss: 10.604362, valid precision: 0.875200, valid loss: 82.736075
epoch: 947, train precision: 0.998667, train loss: 10.592884, valid precision: 0.878400, valid loss: 83.420084
epoch: 948, train precision: 0.999089, train loss: 10.528558, valid precision: 0.881000, valid loss: 84.668016
epoch: 949, train precision: 0.998444, train loss: 10.730691, valid precision: 0.876800, valid loss: 84.465476
epoch: 950, train precision: 0.998778, train loss: 10.621258, valid precision: 0.876400, valid loss: 84.506234
epoch: 951, train precision: 0.998333, train loss: 10.734295, valid precision: 0.873400, valid loss: 86.907722
epoch: 952, train precision: 0.998711, train loss: 10.650146, valid precision: 0.879400, valid loss: 82.745422
epoch: 953, train precision: 0.998622, train loss: 10.646100, valid precision: 0.877000, valid loss: 85.376057
epoch: 954, train precision: 0.998822, train loss: 10.645571, valid precision: 0.879200, valid loss: 83.877970
epoch: 955, train precision: 0.998667, train loss: 10.724418, valid precision: 0.874200, valid loss: 83.585412
epoch: 956, train precision: 0.998733, train loss: 10.631406, valid precision: 0.877800, valid loss: 85.962368
epoch: 957, train precision: 0.999200, train loss: 10.533590, valid precision: 0.881000, valid loss: 83.613388
epoch: 958, train precision: 0.998644, train loss: 10.623974, valid precision: 0.881200, valid loss: 82.516493
epoch: 959, train precision: 0.997778, train loss: 10.982388, valid precision: 0.876400, valid loss: 85.215689
epoch: 960, train precision: 0.998556, train loss: 10.693395, valid precision: 0.876600, valid loss: 82.129437
epoch: 961, train precision: 0.998311, train loss: 10.794577, valid precision: 0.880400, valid loss: 79.746877
epoch: 962, train precision: 0.998889, train loss: 10.592624, valid precision: 0.878600, valid loss: 81.254676
epoch: 963, train precision: 0.998400, train loss: 10.746525, valid precision: 0.878000, valid loss: 82.295426
epoch: 964, train precision: 0.999022, train loss: 10.573131, valid precision: 0.878000, valid loss: 83.579435
epoch: 965, train precision: 0.998667, train loss: 10.647650, valid precision: 0.879800, valid loss: 82.173444
epoch: 966, train precision: 0.998111, train loss: 10.861550, valid precision: 0.877400, valid loss: 82.776489
epoch: 967, train precision: 0.998844, train loss: 10.668523, valid precision: 0.877400, valid loss: 84.762452
epoch: 968, train precision: 0.998911, train loss: 10.561810, valid precision: 0.878000, valid loss: 83.642586
epoch: 969, train precision: 0.999267, train loss: 10.471850, valid precision: 0.875000, valid loss: 84.119773
epoch: 970, train precision: 0.998556, train loss: 10.678996, valid precision: 0.877400, valid loss: 84.723447
epoch: 971, train precision: 0.998533, train loss: 10.730347, valid precision: 0.873400, valid loss: 85.065009
epoch: 972, train precision: 0.998622, train loss: 10.694594, valid precision: 0.875800, valid loss: 85.213389
epoch: 973, train precision: 0.998578, train loss: 10.721407, valid precision: 0.874800, valid loss: 83.668951
epoch: 974, train precision: 0.998467, train loss: 10.641650, valid precision: 0.881600, valid loss: 81.996511
epoch: 975, train precision: 0.998378, train loss: 10.748333, valid precision: 0.877000, valid loss: 84.292136
epoch: 976, train precision: 0.998511, train loss: 10.715074, valid precision: 0.875600, valid loss: 82.703669
epoch: 977, train precision: 0.998800, train loss: 10.609702, valid precision: 0.878000, valid loss: 81.898557
epoch: 978, train precision: 0.998667, train loss: 10.632334, valid precision: 0.875800, valid loss: 83.709780
epoch: 979, train precision: 0.998644, train loss: 10.703000, valid precision: 0.877800, valid loss: 81.927146
epoch: 980, train precision: 0.998978, train loss: 10.502048, valid precision: 0.877000, valid loss: 84.804388
epoch: 981, train precision: 0.998511, train loss: 10.682780, valid precision: 0.874000, valid loss: 85.124060
epoch: 982, train precision: 0.998844, train loss: 10.582207, valid precision: 0.875600, valid loss: 84.184616
epoch: 983, train precision: 0.998622, train loss: 10.690080, valid precision: 0.877600, valid loss: 85.548572
epoch: 984, train precision: 0.998222, train loss: 10.838456, valid precision: 0.876800, valid loss: 85.433031
epoch: 985, train precision: 0.999044, train loss: 10.586336, valid precision: 0.877400, valid loss: 82.985251
epoch: 986, train precision: 0.998378, train loss: 10.742161, valid precision: 0.877600, valid loss: 83.572003
epoch: 987, train precision: 0.998689, train loss: 10.649915, valid precision: 0.877800, valid loss: 83.956743
epoch: 988, train precision: 0.998711, train loss: 10.668246, valid precision: 0.876400, valid loss: 84.406896
epoch: 989, train precision: 0.998533, train loss: 10.668272, valid precision: 0.879400, valid loss: 83.597779
epoch: 990, train precision: 0.998067, train loss: 10.849951, valid precision: 0.874600, valid loss: 85.008317
epoch: 991, train precision: 0.998667, train loss: 10.699254, valid precision: 0.875000, valid loss: 85.410646
epoch: 992, train precision: 0.998956, train loss: 10.598989, valid precision: 0.878200, valid loss: 83.551820
epoch: 993, train precision: 0.998422, train loss: 10.711779, valid precision: 0.880400, valid loss: 83.386866
epoch: 994, train precision: 0.998778, train loss: 10.604065, valid precision: 0.879400, valid loss: 81.645483
epoch: 995, train precision: 0.998867, train loss: 10.657731, valid precision: 0.876600, valid loss: 84.158778
epoch: 996, train precision: 0.998533, train loss: 10.790742, valid precision: 0.878400, valid loss: 84.019669
epoch: 997, train precision: 0.998311, train loss: 10.797882, valid precision: 0.877200, valid loss: 84.939169
epoch: 998, train precision: 0.998933, train loss: 10.602785, valid precision: 0.879800, valid loss: 86.208073
epoch: 999, train precision: 0.998844, train loss: 10.651377, valid precision: 0.880200, valid loss: 85.348029
epoch: 1000, train precision: 0.998267, train loss: 10.764545, valid precision: 0.878600, valid loss: 85.772606
epoch: 1001, train precision: 0.998267, train loss: 10.863165, valid precision: 0.878600, valid loss: 82.998939
epoch: 1002, train precision: 0.998511, train loss: 10.690872, valid precision: 0.880000, valid loss: 82.926233
epoch: 1003, train precision: 0.998222, train loss: 10.839521, valid precision: 0.882000, valid loss: 84.970767
epoch: 1004, train precision: 0.998844, train loss: 10.585134, valid precision: 0.878600, valid loss: 82.343090
epoch: 1005, train precision: 0.998400, train loss: 10.774814, valid precision: 0.878400, valid loss: 84.534487
epoch: 1006, train precision: 0.999356, train loss: 10.449798, valid precision: 0.882200, valid loss: 81.914176
epoch: 1007, train precision: 0.998711, train loss: 10.618288, valid precision: 0.878400, valid loss: 84.937240
epoch: 1008, train precision: 0.998711, train loss: 10.642878, valid precision: 0.878400, valid loss: 82.224193
epoch: 1009, train precision: 0.998667, train loss: 10.621803, valid precision: 0.880800, valid loss: 81.607693
epoch: 1010, train precision: 0.998933, train loss: 10.652582, valid precision: 0.877200, valid loss: 83.181728
epoch: 1011, train precision: 0.998267, train loss: 10.832982, valid precision: 0.880200, valid loss: 85.384115
epoch: 1012, train precision: 0.998889, train loss: 10.646973, valid precision: 0.874200, valid loss: 85.974675
epoch: 1013, train precision: 0.998489, train loss: 10.690317, valid precision: 0.878200, valid loss: 84.389063
epoch: 1014, train precision: 0.998733, train loss: 10.674346, valid precision: 0.875600, valid loss: 84.032601
epoch: 1015, train precision: 0.998978, train loss: 10.583343, valid precision: 0.880000, valid loss: 82.939227
epoch: 1016, train precision: 0.998489, train loss: 10.727251, valid precision: 0.881000, valid loss: 82.939068
epoch: 1017, train precision: 0.998733, train loss: 10.686059, valid precision: 0.879800, valid loss: 83.622434
epoch: 1018, train precision: 0.998533, train loss: 10.666632, valid precision: 0.878400, valid loss: 85.354977
epoch: 1019, train precision: 0.998689, train loss: 10.637792, valid precision: 0.877200, valid loss: 84.019780
epoch: 1020, train precision: 0.998356, train loss: 10.722229, valid precision: 0.879400, valid loss: 84.366524
epoch: 1021, train precision: 0.999067, train loss: 10.643568, valid precision: 0.879000, valid loss: 85.034252
epoch: 1022, train precision: 0.999089, train loss: 10.517166, valid precision: 0.881000, valid loss: 82.160012
epoch: 1023, train precision: 0.998867, train loss: 10.614775, valid precision: 0.881000, valid loss: 83.500915
epoch: 1024, train precision: 0.998444, train loss: 10.742567, valid precision: 0.879000, valid loss: 85.604314
epoch: 1025, train precision: 0.998644, train loss: 10.694771, valid precision: 0.879200, valid loss: 84.940487
epoch: 1026, train precision: 0.998400, train loss: 10.726576, valid precision: 0.879000, valid loss: 86.599004
epoch: 1027, train precision: 0.998644, train loss: 10.707801, valid precision: 0.880800, valid loss: 83.828327
epoch: 1028, train precision: 0.998978, train loss: 10.544642, valid precision: 0.882800, valid loss: 81.582381
epoch: 1029, train precision: 0.998378, train loss: 10.781159, valid precision: 0.880200, valid loss: 83.293882
epoch: 1030, train precision: 0.998844, train loss: 10.631698, valid precision: 0.879000, valid loss: 83.837306
epoch: 1031, train precision: 0.998533, train loss: 10.706148, valid precision: 0.879600, valid loss: 83.453300
epoch: 1032, train precision: 0.998822, train loss: 10.590611, valid precision: 0.879600, valid loss: 81.940711
epoch: 1033, train precision: 0.999022, train loss: 10.555873, valid precision: 0.876400, valid loss: 83.710188
epoch: 1034, train precision: 0.998356, train loss: 10.739075, valid precision: 0.881600, valid loss: 82.745482
epoch: 1035, train precision: 0.998267, train loss: 10.781227, valid precision: 0.873400, valid loss: 84.043809
epoch: 1036, train precision: 0.999156, train loss: 10.586936, valid precision: 0.875200, valid loss: 83.609327
epoch: 1037, train precision: 0.998378, train loss: 10.713806, valid precision: 0.877200, valid loss: 84.497249
epoch: 1038, train precision: 0.998733, train loss: 10.636141, valid precision: 0.879600, valid loss: 82.954622
epoch: 1039, train precision: 0.998644, train loss: 10.634797, valid precision: 0.874000, valid loss: 84.409813
epoch: 1040, train precision: 0.998667, train loss: 10.633046, valid precision: 0.878000, valid loss: 83.604020
epoch: 1041, train precision: 0.998844, train loss: 10.604107, valid precision: 0.876600, valid loss: 86.058797
epoch: 1042, train precision: 0.999133, train loss: 10.541733, valid precision: 0.875800, valid loss: 86.664187
epoch: 1043, train precision: 0.998822, train loss: 10.629156, valid precision: 0.878600, valid loss: 83.010736
epoch: 1044, train precision: 0.998822, train loss: 10.718017, valid precision: 0.878800, valid loss: 84.122829
epoch: 1045, train precision: 0.998800, train loss: 10.629588, valid precision: 0.877600, valid loss: 84.986674
epoch: 1046, train precision: 0.999089, train loss: 10.527618, valid precision: 0.880400, valid loss: 85.071497
epoch: 1047, train precision: 0.998822, train loss: 10.660538, valid precision: 0.874800, valid loss: 85.627685
epoch: 1048, train precision: 0.998733, train loss: 10.670018, valid precision: 0.874200, valid loss: 85.614356
epoch: 1049, train precision: 0.998378, train loss: 10.706276, valid precision: 0.873000, valid loss: 86.444626
epoch: 1050, train precision: 0.998733, train loss: 10.667002, valid precision: 0.872000, valid loss: 86.538222
epoch: 1051, train precision: 0.999089, train loss: 10.549576, valid precision: 0.874000, valid loss: 85.243107
epoch: 1052, train precision: 0.998600, train loss: 10.724310, valid precision: 0.874400, valid loss: 85.239857
epoch: 1053, train precision: 0.998800, train loss: 10.602703, valid precision: 0.874600, valid loss: 86.238304
epoch: 1054, train precision: 0.998733, train loss: 10.673014, valid precision: 0.875400, valid loss: 83.864597
epoch: 1055, train precision: 0.998889, train loss: 10.550881, valid precision: 0.869400, valid loss: 88.364109
epoch: 1056, train precision: 0.998822, train loss: 10.641502, valid precision: 0.874600, valid loss: 85.348707
epoch: 1057, train precision: 0.998533, train loss: 10.680720, valid precision: 0.875000, valid loss: 84.169208
epoch: 1058, train precision: 0.999000, train loss: 10.622091, valid precision: 0.873600, valid loss: 83.950584
epoch: 1059, train precision: 0.998889, train loss: 10.614879, valid precision: 0.877000, valid loss: 84.579413
epoch: 1060, train precision: 0.998533, train loss: 10.698411, valid precision: 0.872800, valid loss: 85.557790
epoch: 1061, train precision: 0.998822, train loss: 10.607390, valid precision: 0.873800, valid loss: 84.856733
epoch: 1062, train precision: 0.998889, train loss: 10.625798, valid precision: 0.871000, valid loss: 87.136585
epoch: 1063, train precision: 0.998800, train loss: 10.602152, valid precision: 0.874600, valid loss: 85.195889
epoch: 1064, train precision: 0.999022, train loss: 10.549994, valid precision: 0.877400, valid loss: 85.428709
epoch: 1065, train precision: 0.999000, train loss: 10.632685, valid precision: 0.874800, valid loss: 83.735586
epoch: 1066, train precision: 0.998533, train loss: 10.655175, valid precision: 0.874800, valid loss: 84.441616
epoch: 1067, train precision: 0.998778, train loss: 10.620676, valid precision: 0.875200, valid loss: 85.790390
epoch: 1068, train precision: 0.998622, train loss: 10.668325, valid precision: 0.871400, valid loss: 86.781146
epoch: 1069, train precision: 0.999022, train loss: 10.572051, valid precision: 0.878000, valid loss: 82.228172
epoch: 1070, train precision: 0.998733, train loss: 10.600511, valid precision: 0.875800, valid loss: 84.530037
epoch: 1071, train precision: 0.998756, train loss: 10.665121, valid precision: 0.874400, valid loss: 85.132373
epoch: 1072, train precision: 0.998800, train loss: 10.622705, valid precision: 0.872000, valid loss: 84.935097
epoch: 1073, train precision: 0.998178, train loss: 10.833006, valid precision: 0.874400, valid loss: 86.490187
epoch: 1074, train precision: 0.998400, train loss: 10.654186, valid precision: 0.878400, valid loss: 85.893785
epoch: 1075, train precision: 0.998356, train loss: 10.738369, valid precision: 0.875600, valid loss: 83.445103
epoch: 1076, train precision: 0.998556, train loss: 10.736449, valid precision: 0.872200, valid loss: 86.553796
epoch: 1077, train precision: 0.998533, train loss: 10.747048, valid precision: 0.878000, valid loss: 85.265677
epoch: 1078, train precision: 0.998800, train loss: 10.604605, valid precision: 0.879200, valid loss: 84.695166
epoch: 1079, train precision: 0.998444, train loss: 10.732466, valid precision: 0.877000, valid loss: 86.645031
epoch: 1080, train precision: 0.998956, train loss: 10.597636, valid precision: 0.878600, valid loss: 83.702403
epoch: 1081, train precision: 0.998622, train loss: 10.736881, valid precision: 0.875800, valid loss: 86.366859
epoch: 1082, train precision: 0.999067, train loss: 10.600908, valid precision: 0.882600, valid loss: 84.536123
epoch: 1083, train precision: 0.999067, train loss: 10.616779, valid precision: 0.875600, valid loss: 85.737429
epoch: 1084, train precision: 0.998489, train loss: 10.704255, valid precision: 0.877200, valid loss: 86.221805
epoch: 1085, train precision: 0.998867, train loss: 10.681632, valid precision: 0.876400, valid loss: 85.345605
epoch: 1086, train precision: 0.999244, train loss: 10.564982, valid precision: 0.873400, valid loss: 85.422259
epoch: 1087, train precision: 0.998978, train loss: 10.611960, valid precision: 0.879600, valid loss: 83.123472
epoch: 1088, train precision: 0.998422, train loss: 10.819572, valid precision: 0.878800, valid loss: 86.373751
epoch: 1089, train precision: 0.998356, train loss: 10.871643, valid precision: 0.871200, valid loss: 86.655548
epoch: 1090, train precision: 0.998978, train loss: 10.595228, valid precision: 0.877600, valid loss: 83.907264
epoch: 1091, train precision: 0.998644, train loss: 10.691952, valid precision: 0.877000, valid loss: 84.374645
epoch: 1092, train precision: 0.998911, train loss: 10.667257, valid precision: 0.877400, valid loss: 84.146204
epoch: 1093, train precision: 0.998622, train loss: 10.737216, valid precision: 0.876800, valid loss: 85.742222
epoch: 1094, train precision: 0.998489, train loss: 10.750841, valid precision: 0.876800, valid loss: 84.207493
epoch: 1095, train precision: 0.998733, train loss: 10.664167, valid precision: 0.878600, valid loss: 81.790251
epoch: 1096, train precision: 0.998733, train loss: 10.692477, valid precision: 0.878400, valid loss: 84.732687
epoch: 1097, train precision: 0.998667, train loss: 10.664697, valid precision: 0.875400, valid loss: 84.703295
epoch: 1098, train precision: 0.998378, train loss: 10.742510, valid precision: 0.877200, valid loss: 84.637449
epoch: 1099, train precision: 0.998778, train loss: 10.649240, valid precision: 0.878400, valid loss: 81.916644
epoch: 1100, train precision: 0.998933, train loss: 10.626793, valid precision: 0.878200, valid loss: 80.629418
epoch: 1101, train precision: 0.998889, train loss: 10.580508, valid precision: 0.881400, valid loss: 81.904270
epoch: 1102, train precision: 0.998889, train loss: 10.617531, valid precision: 0.877200, valid loss: 81.297458
epoch: 1103, train precision: 0.999000, train loss: 10.596982, valid precision: 0.876400, valid loss: 82.833240
epoch: 1104, train precision: 0.998889, train loss: 10.623348, valid precision: 0.876400, valid loss: 82.222594
epoch: 1105, train precision: 0.998689, train loss: 10.657906, valid precision: 0.881400, valid loss: 84.403402
epoch: 1106, train precision: 0.998356, train loss: 10.715285, valid precision: 0.881200, valid loss: 82.501019
epoch: 1107, train precision: 0.998444, train loss: 10.754830, valid precision: 0.878000, valid loss: 82.346877
epoch: 1108, train precision: 0.998956, train loss: 10.660122, valid precision: 0.880400, valid loss: 84.194855
epoch: 1109, train precision: 0.998356, train loss: 10.792319, valid precision: 0.874600, valid loss: 85.520783
epoch: 1110, train precision: 0.998600, train loss: 10.702517, valid precision: 0.877800, valid loss: 84.384715
epoch: 1111, train precision: 0.998600, train loss: 10.695394, valid precision: 0.876000, valid loss: 85.691443
epoch: 1112, train precision: 0.998733, train loss: 10.608537, valid precision: 0.876800, valid loss: 84.493107
epoch: 1113, train precision: 0.998889, train loss: 10.643630, valid precision: 0.878600, valid loss: 83.762742
epoch: 1114, train precision: 0.998889, train loss: 10.679241, valid precision: 0.877600, valid loss: 84.650534
epoch: 1115, train precision: 0.998356, train loss: 10.745768, valid precision: 0.879400, valid loss: 84.552730
epoch: 1116, train precision: 0.999044, train loss: 10.585536, valid precision: 0.881400, valid loss: 82.748656
epoch: 1117, train precision: 0.998933, train loss: 10.595762, valid precision: 0.880800, valid loss: 82.289665
epoch: 1118, train precision: 0.998800, train loss: 10.673815, valid precision: 0.878600, valid loss: 83.327281
epoch: 1119, train precision: 0.998844, train loss: 10.625223, valid precision: 0.879400, valid loss: 82.067889
epoch: 1120, train precision: 0.999089, train loss: 10.581553, valid precision: 0.877800, valid loss: 82.216768
epoch: 1121, train precision: 0.998778, train loss: 10.634255, valid precision: 0.881400, valid loss: 82.595745
epoch: 1122, train precision: 0.998822, train loss: 10.644199, valid precision: 0.880200, valid loss: 81.866429
epoch: 1123, train precision: 0.999000, train loss: 10.636689, valid precision: 0.883000, valid loss: 81.434463
epoch: 1124, train precision: 0.998756, train loss: 10.591438, valid precision: 0.879600, valid loss: 82.509102
epoch: 1125, train precision: 0.998667, train loss: 10.684678, valid precision: 0.878400, valid loss: 83.508207
epoch: 1126, train precision: 0.998889, train loss: 10.551720, valid precision: 0.883800, valid loss: 81.468254
epoch: 1127, train precision: 0.998556, train loss: 10.690060, valid precision: 0.878000, valid loss: 82.240642
epoch: 1128, train precision: 0.998622, train loss: 10.717620, valid precision: 0.876600, valid loss: 83.396193
epoch: 1129, train precision: 0.999022, train loss: 10.568806, valid precision: 0.877000, valid loss: 82.484168
epoch: 1130, train precision: 0.999022, train loss: 10.651858, valid precision: 0.878800, valid loss: 83.016195
epoch: 1131, train precision: 0.998467, train loss: 10.746973, valid precision: 0.880800, valid loss: 83.065662
epoch: 1132, train precision: 0.999000, train loss: 10.592200, valid precision: 0.877800, valid loss: 84.118797
epoch: 1133, train precision: 0.998911, train loss: 10.575826, valid precision: 0.880600, valid loss: 82.238318
epoch: 1134, train precision: 0.998667, train loss: 10.722570, valid precision: 0.879600, valid loss: 81.308438
epoch: 1135, train precision: 0.998422, train loss: 10.846341, valid precision: 0.878600, valid loss: 82.926358
epoch: 1136, train precision: 0.998889, train loss: 10.655660, valid precision: 0.879200, valid loss: 81.417388
epoch: 1137, train precision: 0.998956, train loss: 10.572227, valid precision: 0.880600, valid loss: 81.687536
epoch: 1138, train precision: 0.998222, train loss: 10.866401, valid precision: 0.876400, valid loss: 83.399003
epoch: 1139, train precision: 0.998822, train loss: 10.651629, valid precision: 0.879800, valid loss: 83.798512
epoch: 1140, train precision: 0.998867, train loss: 10.658569, valid precision: 0.878000, valid loss: 82.200387
epoch: 1141, train precision: 0.998822, train loss: 10.692914, valid precision: 0.881600, valid loss: 82.156591
epoch: 1142, train precision: 0.998933, train loss: 10.656773, valid precision: 0.881800, valid loss: 81.342582
epoch: 1143, train precision: 0.999000, train loss: 10.600573, valid precision: 0.881000, valid loss: 82.422394
epoch: 1144, train precision: 0.998778, train loss: 10.688494, valid precision: 0.882000, valid loss: 85.137116
epoch: 1145, train precision: 0.999089, train loss: 10.539195, valid precision: 0.879800, valid loss: 83.455566
epoch: 1146, train precision: 0.998911, train loss: 10.693174, valid precision: 0.879800, valid loss: 83.745323
epoch: 1147, train precision: 0.998733, train loss: 10.777865, valid precision: 0.880800, valid loss: 83.441004
epoch: 1148, train precision: 0.999244, train loss: 10.566401, valid precision: 0.886000, valid loss: 83.125671
epoch: 1149, train precision: 0.998444, train loss: 10.768926, valid precision: 0.880800, valid loss: 84.168822
epoch: 1150, train precision: 0.998422, train loss: 10.751240, valid precision: 0.875400, valid loss: 84.089633
epoch: 1151, train precision: 0.998822, train loss: 10.593670, valid precision: 0.877800, valid loss: 84.751748
epoch: 1152, train precision: 0.998822, train loss: 10.674408, valid precision: 0.878800, valid loss: 87.153276
epoch: 1153, train precision: 0.998244, train loss: 10.919874, valid precision: 0.881400, valid loss: 86.287757
epoch: 1154, train precision: 0.999133, train loss: 10.654281, valid precision: 0.883800, valid loss: 82.787444
epoch: 1155, train precision: 0.998667, train loss: 10.680573, valid precision: 0.879200, valid loss: 83.213130
epoch: 1156, train precision: 0.998600, train loss: 10.776639, valid precision: 0.878200, valid loss: 83.251938
epoch: 1157, train precision: 0.998978, train loss: 10.662161, valid precision: 0.882000, valid loss: 81.637386
epoch: 1158, train precision: 0.998978, train loss: 10.592116, valid precision: 0.878600, valid loss: 81.992785
epoch: 1159, train precision: 0.997822, train loss: 10.901029, valid precision: 0.878600, valid loss: 83.553447
epoch: 1160, train precision: 0.998556, train loss: 10.694403, valid precision: 0.878600, valid loss: 82.020600
epoch: 1161, train precision: 0.998244, train loss: 10.835188, valid precision: 0.880000, valid loss: 80.909105
epoch: 1162, train precision: 0.999044, train loss: 10.634590, valid precision: 0.881600, valid loss: 82.094627
epoch: 1163, train precision: 0.998600, train loss: 10.678235, valid precision: 0.881800, valid loss: 83.115482
epoch: 1164, train precision: 0.998689, train loss: 10.805259, valid precision: 0.878200, valid loss: 83.028533
epoch: 1165, train precision: 0.998200, train loss: 10.804049, valid precision: 0.880200, valid loss: 84.001028
epoch: 1166, train precision: 0.998356, train loss: 10.895074, valid precision: 0.879600, valid loss: 84.809986
epoch: 1167, train precision: 0.998556, train loss: 10.679869, valid precision: 0.881800, valid loss: 84.516412
epoch: 1168, train precision: 0.998800, train loss: 10.721147, valid precision: 0.885000, valid loss: 82.236628
epoch: 1169, train precision: 0.998733, train loss: 10.691711, valid precision: 0.881400, valid loss: 84.402395
epoch: 1170, train precision: 0.998733, train loss: 10.706093, valid precision: 0.876600, valid loss: 83.658226
epoch: 1171, train precision: 0.998844, train loss: 10.635664, valid precision: 0.878800, valid loss: 82.538727
epoch: 1172, train precision: 0.999022, train loss: 10.639828, valid precision: 0.880000, valid loss: 83.580979
epoch: 1173, train precision: 0.998378, train loss: 10.823944, valid precision: 0.878400, valid loss: 85.389105
epoch: 1174, train precision: 0.998644, train loss: 10.661425, valid precision: 0.876800, valid loss: 84.479832
epoch: 1175, train precision: 0.998689, train loss: 10.767016, valid precision: 0.877600, valid loss: 83.203485
epoch: 1176, train precision: 0.999044, train loss: 10.619141, valid precision: 0.877400, valid loss: 83.381403
epoch: 1177, train precision: 0.998933, train loss: 10.616365, valid precision: 0.878800, valid loss: 83.582086
epoch: 1178, train precision: 0.998644, train loss: 10.669930, valid precision: 0.875800, valid loss: 83.969000
epoch: 1179, train precision: 0.998489, train loss: 10.673469, valid precision: 0.875400, valid loss: 85.932275
epoch: 1180, train precision: 0.998600, train loss: 10.712052, valid precision: 0.876400, valid loss: 85.508442
epoch: 1181, train precision: 0.998444, train loss: 10.760982, valid precision: 0.875800, valid loss: 87.403156
epoch: 1182, train precision: 0.998711, train loss: 10.738435, valid precision: 0.873000, valid loss: 85.084704
epoch: 1183, train precision: 0.999067, train loss: 10.588743, valid precision: 0.881800, valid loss: 85.598862
epoch: 1184, train precision: 0.999022, train loss: 10.585048, valid precision: 0.878600, valid loss: 85.947893
epoch: 1185, train precision: 0.998533, train loss: 10.710225, valid precision: 0.878200, valid loss: 84.095424
epoch: 1186, train precision: 0.999200, train loss: 10.534357, valid precision: 0.876600, valid loss: 87.713429
epoch: 1187, train precision: 0.999000, train loss: 10.589061, valid precision: 0.878000, valid loss: 83.265441
epoch: 1188, train precision: 0.998533, train loss: 10.804145, valid precision: 0.878200, valid loss: 86.440408
epoch: 1189, train precision: 0.999156, train loss: 10.533799, valid precision: 0.880600, valid loss: 81.979221
epoch: 1190, train precision: 0.998778, train loss: 10.704808, valid precision: 0.881200, valid loss: 84.294190
epoch: 1191, train precision: 0.999178, train loss: 10.550192, valid precision: 0.880600, valid loss: 81.815323
epoch: 1192, train precision: 0.998889, train loss: 10.581348, valid precision: 0.879000, valid loss: 82.950189
epoch: 1193, train precision: 0.998756, train loss: 10.613107, valid precision: 0.877400, valid loss: 85.797828
epoch: 1194, train precision: 0.999156, train loss: 10.569086, valid precision: 0.878600, valid loss: 82.127762
epoch: 1195, train precision: 0.998667, train loss: 10.666706, valid precision: 0.875800, valid loss: 86.357587
epoch: 1196, train precision: 0.999000, train loss: 10.636982, valid precision: 0.879400, valid loss: 82.533800
epoch: 1197, train precision: 0.998422, train loss: 10.686010, valid precision: 0.878200, valid loss: 83.354443
epoch: 1198, train precision: 0.999133, train loss: 10.604111, valid precision: 0.880600, valid loss: 84.025758
epoch: 1199, train precision: 0.999000, train loss: 10.613319, valid precision: 0.879600, valid loss: 83.482637
epoch: 1200, train precision: 0.998667, train loss: 10.699816, valid precision: 0.879600, valid loss: 83.287819
epoch: 1201, train precision: 0.998822, train loss: 10.654682, valid precision: 0.877600, valid loss: 85.178396
epoch: 1202, train precision: 0.998911, train loss: 10.644026, valid precision: 0.880600, valid loss: 82.589782
epoch: 1203, train precision: 0.998422, train loss: 10.812166, valid precision: 0.878800, valid loss: 85.841693
epoch: 1204, train precision: 0.998867, train loss: 10.651297, valid precision: 0.881200, valid loss: 83.922128
epoch: 1205, train precision: 0.998711, train loss: 10.712117, valid precision: 0.878200, valid loss: 84.687388
epoch: 1206, train precision: 0.999111, train loss: 10.552106, valid precision: 0.880000, valid loss: 85.823415
epoch: 1207, train precision: 0.998533, train loss: 10.747399, valid precision: 0.878400, valid loss: 87.119828
epoch: 1208, train precision: 0.998711, train loss: 10.703800, valid precision: 0.873000, valid loss: 88.038430
epoch: 1209, train precision: 0.998756, train loss: 10.688514, valid precision: 0.877400, valid loss: 85.874079
epoch: 1210, train precision: 0.998844, train loss: 10.675791, valid precision: 0.879600, valid loss: 84.962492
epoch: 1211, train precision: 0.998622, train loss: 10.742547, valid precision: 0.875000, valid loss: 87.394273
epoch: 1212, train precision: 0.998844, train loss: 10.658680, valid precision: 0.878400, valid loss: 85.143701
epoch: 1213, train precision: 0.999244, train loss: 10.532481, valid precision: 0.882800, valid loss: 84.442099
epoch: 1214, train precision: 0.998733, train loss: 10.702380, valid precision: 0.880400, valid loss: 83.872517
epoch: 1215, train precision: 0.999067, train loss: 10.617971, valid precision: 0.880800, valid loss: 87.458011
epoch: 1216, train precision: 0.998933, train loss: 10.605866, valid precision: 0.878800, valid loss: 86.531066
epoch: 1217, train precision: 0.998867, train loss: 10.679973, valid precision: 0.879200, valid loss: 85.498975
epoch: 1218, train precision: 0.998578, train loss: 10.762325, valid precision: 0.881800, valid loss: 85.497114
epoch: 1219, train precision: 0.998644, train loss: 10.699209, valid precision: 0.881400, valid loss: 83.999794
epoch: 1220, train precision: 0.998911, train loss: 10.650170, valid precision: 0.881400, valid loss: 84.124133
epoch: 1221, train precision: 0.998911, train loss: 10.633616, valid precision: 0.877600, valid loss: 84.654337
epoch: 1222, train precision: 0.998511, train loss: 10.774509, valid precision: 0.883000, valid loss: 81.773352
epoch: 1223, train precision: 0.999022, train loss: 10.668957, valid precision: 0.874400, valid loss: 84.378077
epoch: 1224, train precision: 0.998867, train loss: 10.703908, valid precision: 0.879000, valid loss: 84.099475
epoch: 1225, train precision: 0.998889, train loss: 10.692415, valid precision: 0.881200, valid loss: 84.596405
epoch: 1226, train precision: 0.998933, train loss: 10.655786, valid precision: 0.879400, valid loss: 82.792854
epoch: 1227, train precision: 0.998911, train loss: 10.650067, valid precision: 0.879400, valid loss: 82.541277
epoch: 1228, train precision: 0.998444, train loss: 10.840659, valid precision: 0.880200, valid loss: 84.199004
epoch: 1229, train precision: 0.998978, train loss: 10.570372, valid precision: 0.884600, valid loss: 85.431002
epoch: 1230, train precision: 0.998333, train loss: 10.839332, valid precision: 0.877600, valid loss: 85.524100
epoch: 1231, train precision: 0.998978, train loss: 10.576448, valid precision: 0.880400, valid loss: 84.676106
epoch: 1232, train precision: 0.999000, train loss: 10.596810, valid precision: 0.882400, valid loss: 82.602858
epoch: 1233, train precision: 0.998756, train loss: 10.725536, valid precision: 0.880200, valid loss: 85.329573
epoch: 1234, train precision: 0.998667, train loss: 10.689600, valid precision: 0.879600, valid loss: 84.367715
epoch: 1235, train precision: 0.999044, train loss: 10.625668, valid precision: 0.877000, valid loss: 84.143682
epoch: 1236, train precision: 0.998867, train loss: 10.684149, valid precision: 0.874000, valid loss: 85.587432
epoch: 1237, train precision: 0.998289, train loss: 10.821926, valid precision: 0.877200, valid loss: 84.838374
epoch: 1238, train precision: 0.998844, train loss: 10.686334, valid precision: 0.880600, valid loss: 83.822733
epoch: 1239, train precision: 0.998800, train loss: 10.692544, valid precision: 0.878200, valid loss: 84.448010
epoch: 1240, train precision: 0.998400, train loss: 10.782948, valid precision: 0.878600, valid loss: 84.281829
epoch: 1241, train precision: 0.998467, train loss: 10.736901, valid precision: 0.879200, valid loss: 83.324202
epoch: 1242, train precision: 0.998689, train loss: 10.695867, valid precision: 0.878200, valid loss: 84.253421
epoch: 1243, train precision: 0.998622, train loss: 10.710589, valid precision: 0.879200, valid loss: 84.719781
epoch: 1244, train precision: 0.998756, train loss: 10.704615, valid precision: 0.877600, valid loss: 85.672500
epoch: 1245, train precision: 0.998844, train loss: 10.654191, valid precision: 0.880600, valid loss: 83.994092
epoch: 1246, train precision: 0.998511, train loss: 10.741446, valid precision: 0.875800, valid loss: 85.771143
epoch: 1247, train precision: 0.998511, train loss: 10.691647, valid precision: 0.879400, valid loss: 84.888720
epoch: 1248, train precision: 0.998822, train loss: 10.631616, valid precision: 0.877200, valid loss: 84.805436
epoch: 1249, train precision: 0.998733, train loss: 10.713323, valid precision: 0.878000, valid loss: 87.279173
epoch: 1250, train precision: 0.998244, train loss: 10.857165, valid precision: 0.874000, valid loss: 85.127163
epoch: 1251, train precision: 0.999089, train loss: 10.626590, valid precision: 0.880400, valid loss: 84.096957
epoch: 1252, train precision: 0.998889, train loss: 10.595436, valid precision: 0.878400, valid loss: 85.780872
epoch: 1253, train precision: 0.999022, train loss: 10.575556, valid precision: 0.876400, valid loss: 86.612454
epoch: 1254, train precision: 0.998644, train loss: 10.710039, valid precision: 0.877000, valid loss: 87.927688
epoch: 1255, train precision: 0.998933, train loss: 10.632489, valid precision: 0.880200, valid loss: 83.873847
epoch: 1256, train precision: 0.998644, train loss: 10.678394, valid precision: 0.872600, valid loss: 85.896298
epoch: 1257, train precision: 0.998689, train loss: 10.652868, valid precision: 0.882600, valid loss: 85.860538
epoch: 1258, train precision: 0.998689, train loss: 10.665125, valid precision: 0.875600, valid loss: 85.335248
epoch: 1259, train precision: 0.998511, train loss: 10.751819, valid precision: 0.879800, valid loss: 83.750828
epoch: 1260, train precision: 0.998622, train loss: 10.676568, valid precision: 0.875200, valid loss: 85.576267
epoch: 1261, train precision: 0.998600, train loss: 10.715300, valid precision: 0.878000, valid loss: 84.098297
epoch: 1262, train precision: 0.998800, train loss: 10.702065, valid precision: 0.874400, valid loss: 85.776670
epoch: 1263, train precision: 0.998667, train loss: 10.667361, valid precision: 0.874800, valid loss: 86.856334
epoch: 1264, train precision: 0.998889, train loss: 10.694249, valid precision: 0.876000, valid loss: 86.278847
epoch: 1265, train precision: 0.998933, train loss: 10.612865, valid precision: 0.876200, valid loss: 84.110336
epoch: 1266, train precision: 0.998889, train loss: 10.598184, valid precision: 0.878000, valid loss: 85.921731
epoch: 1267, train precision: 0.998956, train loss: 10.650282, valid precision: 0.876800, valid loss: 84.183692
epoch: 1268, train precision: 0.998733, train loss: 10.693962, valid precision: 0.878800, valid loss: 86.877168
epoch: 1269, train precision: 0.998689, train loss: 10.658524, valid precision: 0.877600, valid loss: 84.889835
epoch: 1270, train precision: 0.998889, train loss: 10.593337, valid precision: 0.876400, valid loss: 84.557198
epoch: 1271, train precision: 0.998889, train loss: 10.649025, valid precision: 0.875400, valid loss: 86.049552
epoch: 1272, train precision: 0.998844, train loss: 10.632879, valid precision: 0.875200, valid loss: 86.791911
epoch: 1273, train precision: 0.998600, train loss: 10.731375, valid precision: 0.875800, valid loss: 86.996122
epoch: 1274, train precision: 0.998978, train loss: 10.598939, valid precision: 0.875200, valid loss: 87.548327
epoch: 1275, train precision: 0.998511, train loss: 10.746332, valid precision: 0.873800, valid loss: 87.054316
epoch: 1276, train precision: 0.998622, train loss: 10.683613, valid precision: 0.880200, valid loss: 84.882564
epoch: 1277, train precision: 0.998622, train loss: 10.623631, valid precision: 0.877400, valid loss: 85.688941
epoch: 1278, train precision: 0.999000, train loss: 10.605016, valid precision: 0.878200, valid loss: 87.117342
epoch: 1279, train precision: 0.998778, train loss: 10.633715, valid precision: 0.878400, valid loss: 84.895772
epoch: 1280, train precision: 0.998889, train loss: 10.596762, valid precision: 0.876200, valid loss: 87.046592
epoch: 1281, train precision: 0.998600, train loss: 10.717048, valid precision: 0.877800, valid loss: 87.405825
epoch: 1282, train precision: 0.998933, train loss: 10.611819, valid precision: 0.877600, valid loss: 85.088776
epoch: 1283, train precision: 0.999022, train loss: 10.634794, valid precision: 0.879600, valid loss: 84.863611
epoch: 1284, train precision: 0.998667, train loss: 10.660872, valid precision: 0.877800, valid loss: 85.476209
epoch: 1285, train precision: 0.999089, train loss: 10.582893, valid precision: 0.879200, valid loss: 84.551034
epoch: 1286, train precision: 0.998644, train loss: 10.752238, valid precision: 0.876600, valid loss: 86.245241
epoch: 1287, train precision: 0.998600, train loss: 10.737014, valid precision: 0.877600, valid loss: 86.919958
epoch: 1288, train precision: 0.998956, train loss: 10.592734, valid precision: 0.876600, valid loss: 86.502214
epoch: 1289, train precision: 0.998756, train loss: 10.612546, valid precision: 0.878400, valid loss: 86.350270
epoch: 1290, train precision: 0.998622, train loss: 10.640780, valid precision: 0.875600, valid loss: 86.901411
epoch: 1291, train precision: 0.999133, train loss: 10.596220, valid precision: 0.879200, valid loss: 85.667708
epoch: 1292, train precision: 0.998733, train loss: 10.723807, valid precision: 0.879400, valid loss: 86.257785
epoch: 1293, train precision: 0.998533, train loss: 10.738955, valid precision: 0.880800, valid loss: 83.647135
epoch: 1294, train precision: 0.998800, train loss: 10.656890, valid precision: 0.877800, valid loss: 82.328543
epoch: 1295, train precision: 0.998622, train loss: 10.715119, valid precision: 0.876800, valid loss: 85.020510
epoch: 1296, train precision: 0.998467, train loss: 10.707168, valid precision: 0.875000, valid loss: 85.199242
epoch: 1297, train precision: 0.999089, train loss: 10.596395, valid precision: 0.877800, valid loss: 84.125392
epoch: 1298, train precision: 0.998689, train loss: 10.699545, valid precision: 0.877000, valid loss: 85.638687
epoch: 1299, train precision: 0.998600, train loss: 10.714455, valid precision: 0.878600, valid loss: 86.610822
epoch: 1300, train precision: 0.998378, train loss: 10.788860, valid precision: 0.872400, valid loss: 87.837538
epoch: 1301, train precision: 0.998733, train loss: 10.647741, valid precision: 0.879800, valid loss: 83.307230
epoch: 1302, train precision: 0.999022, train loss: 10.576935, valid precision: 0.879000, valid loss: 82.064054
epoch: 1303, train precision: 0.998378, train loss: 10.807251, valid precision: 0.879800, valid loss: 84.822466
epoch: 1304, train precision: 0.999022, train loss: 10.603507, valid precision: 0.877800, valid loss: 86.935671
epoch: 1305, train precision: 0.998822, train loss: 10.720452, valid precision: 0.878200, valid loss: 85.330316
epoch: 1306, train precision: 0.998911, train loss: 10.607026, valid precision: 0.878800, valid loss: 85.111027
epoch: 1307, train precision: 0.998689, train loss: 10.709546, valid precision: 0.876800, valid loss: 85.867669
epoch: 1308, train precision: 0.998911, train loss: 10.611702, valid precision: 0.883000, valid loss: 84.375735
epoch: 1309, train precision: 0.999089, train loss: 10.603874, valid precision: 0.879800, valid loss: 83.351344
epoch: 1310, train precision: 0.998533, train loss: 10.799572, valid precision: 0.876400, valid loss: 84.084422
epoch: 1311, train precision: 0.998956, train loss: 10.675380, valid precision: 0.878800, valid loss: 84.493226
epoch: 1312, train precision: 0.998556, train loss: 10.691031, valid precision: 0.878800, valid loss: 85.853604
epoch: 1313, train precision: 0.998844, train loss: 10.622010, valid precision: 0.882200, valid loss: 83.798985
epoch: 1314, train precision: 0.999044, train loss: 10.602438, valid precision: 0.879000, valid loss: 83.393838
epoch: 1315, train precision: 0.998644, train loss: 10.746306, valid precision: 0.877400, valid loss: 84.563820
epoch: 1316, train precision: 0.999067, train loss: 10.576476, valid precision: 0.880800, valid loss: 83.013199
epoch: 1317, train precision: 0.998489, train loss: 10.789679, valid precision: 0.876600, valid loss: 86.524322
epoch: 1318, train precision: 0.998511, train loss: 10.732199, valid precision: 0.877200, valid loss: 83.439502
epoch: 1319, train precision: 0.999067, train loss: 10.599978, valid precision: 0.880600, valid loss: 82.599984
epoch: 1320, train precision: 0.998711, train loss: 10.708315, valid precision: 0.878600, valid loss: 85.754822
epoch: 1321, train precision: 0.998667, train loss: 10.756798, valid precision: 0.874200, valid loss: 87.028308
epoch: 1322, train precision: 0.999133, train loss: 10.580721, valid precision: 0.880000, valid loss: 83.604029
epoch: 1323, train precision: 0.998600, train loss: 10.708016, valid precision: 0.880200, valid loss: 85.446613
epoch: 1324, train precision: 0.998444, train loss: 10.769678, valid precision: 0.877400, valid loss: 86.250384
epoch: 1325, train precision: 0.998978, train loss: 10.615244, valid precision: 0.875400, valid loss: 87.023249
epoch: 1326, train precision: 0.998933, train loss: 10.667300, valid precision: 0.879200, valid loss: 83.200595
epoch: 1327, train precision: 0.998711, train loss: 10.668162, valid precision: 0.876200, valid loss: 86.589335
epoch: 1328, train precision: 0.999022, train loss: 10.644107, valid precision: 0.877000, valid loss: 84.952770
epoch: 1329, train precision: 0.998867, train loss: 10.692879, valid precision: 0.877200, valid loss: 84.562222
epoch: 1330, train precision: 0.999000, train loss: 10.667071, valid precision: 0.873200, valid loss: 88.177673
epoch: 1331, train precision: 0.999133, train loss: 10.527208, valid precision: 0.878600, valid loss: 84.607181
epoch: 1332, train precision: 0.998689, train loss: 10.685307, valid precision: 0.874400, valid loss: 85.838986
epoch: 1333, train precision: 0.998911, train loss: 10.640123, valid precision: 0.877800, valid loss: 85.780644
epoch: 1334, train precision: 0.999044, train loss: 10.612236, valid precision: 0.880000, valid loss: 83.807568
epoch: 1335, train precision: 0.998889, train loss: 10.558158, valid precision: 0.876400, valid loss: 87.010952
epoch: 1336, train precision: 0.999022, train loss: 10.597064, valid precision: 0.877200, valid loss: 86.631368
epoch: 1337, train precision: 0.998489, train loss: 10.738022, valid precision: 0.877200, valid loss: 86.093752
epoch: 1338, train precision: 0.998889, train loss: 10.630787, valid precision: 0.876600, valid loss: 85.953463
epoch: 1339, train precision: 0.998822, train loss: 10.745797, valid precision: 0.879200, valid loss: 83.982604
epoch: 1340, train precision: 0.998800, train loss: 10.678348, valid precision: 0.880400, valid loss: 87.338955
epoch: 1341, train precision: 0.998956, train loss: 10.648577, valid precision: 0.879200, valid loss: 84.211290
epoch: 1342, train precision: 0.998933, train loss: 10.595333, valid precision: 0.876400, valid loss: 86.143210
epoch: 1343, train precision: 0.999089, train loss: 10.610828, valid precision: 0.874000, valid loss: 85.359535
epoch: 1344, train precision: 0.998933, train loss: 10.600008, valid precision: 0.880000, valid loss: 82.919759
epoch: 1345, train precision: 0.998822, train loss: 10.602848, valid precision: 0.878800, valid loss: 84.232593
epoch: 1346, train precision: 0.998733, train loss: 10.654139, valid precision: 0.879000, valid loss: 83.618530
epoch: 1347, train precision: 0.998978, train loss: 10.656290, valid precision: 0.877600, valid loss: 85.874700
epoch: 1348, train precision: 0.998400, train loss: 10.795664, valid precision: 0.880400, valid loss: 82.754867
epoch: 1349, train precision: 0.998622, train loss: 10.696405, valid precision: 0.876400, valid loss: 83.688145
epoch: 1350, train precision: 0.998867, train loss: 10.648745, valid precision: 0.882000, valid loss: 85.940499
epoch: 1351, train precision: 0.998778, train loss: 10.654851, valid precision: 0.880000, valid loss: 84.735379
epoch: 1352, train precision: 0.998200, train loss: 10.817669, valid precision: 0.876200, valid loss: 85.167383
epoch: 1353, train precision: 0.999022, train loss: 10.670327, valid precision: 0.877600, valid loss: 87.816565
epoch: 1354, train precision: 0.998956, train loss: 10.678081, valid precision: 0.877600, valid loss: 86.211926
epoch: 1355, train precision: 0.998800, train loss: 10.663833, valid precision: 0.875200, valid loss: 87.521438
epoch: 1356, train precision: 0.998600, train loss: 10.704825, valid precision: 0.874200, valid loss: 83.962148
epoch: 1357, train precision: 0.998267, train loss: 10.787160, valid precision: 0.876600, valid loss: 88.176195
epoch: 1358, train precision: 0.998444, train loss: 10.818613, valid precision: 0.879200, valid loss: 85.154789
epoch: 1359, train precision: 0.998889, train loss: 10.680898, valid precision: 0.875200, valid loss: 85.296406
epoch: 1360, train precision: 0.998911, train loss: 10.635525, valid precision: 0.879600, valid loss: 86.649472
epoch: 1361, train precision: 0.999067, train loss: 10.662878, valid precision: 0.872600, valid loss: 86.556417
epoch: 1362, train precision: 0.998844, train loss: 10.660028, valid precision: 0.877800, valid loss: 84.058304
epoch: 1363, train precision: 0.998444, train loss: 10.725521, valid precision: 0.878800, valid loss: 83.551127
epoch: 1364, train precision: 0.999111, train loss: 10.600340, valid precision: 0.878800, valid loss: 82.864744
epoch: 1365, train precision: 0.999089, train loss: 10.560888, valid precision: 0.879600, valid loss: 82.458354
epoch: 1366, train precision: 0.998956, train loss: 10.596651, valid precision: 0.876200, valid loss: 85.170343
epoch: 1367, train precision: 0.998911, train loss: 10.654323, valid precision: 0.877200, valid loss: 83.027504
epoch: 1368, train precision: 0.998733, train loss: 10.651372, valid precision: 0.880600, valid loss: 83.303877
epoch: 1369, train precision: 0.999044, train loss: 10.547249, valid precision: 0.882600, valid loss: 83.288025
epoch: 1370, train precision: 0.998800, train loss: 10.612408, valid precision: 0.879400, valid loss: 86.869464
epoch: 1371, train precision: 0.998689, train loss: 10.754384, valid precision: 0.874600, valid loss: 85.984149
epoch: 1372, train precision: 0.998578, train loss: 10.749644, valid precision: 0.875800, valid loss: 85.320573
epoch: 1373, train precision: 0.998667, train loss: 10.655278, valid precision: 0.877600, valid loss: 83.955120
epoch: 1374, train precision: 0.998933, train loss: 10.666632, valid precision: 0.878200, valid loss: 84.773045
epoch: 1375, train precision: 0.998511, train loss: 10.759690, valid precision: 0.879200, valid loss: 85.819308
epoch: 1376, train precision: 0.999133, train loss: 10.588231, valid precision: 0.881200, valid loss: 82.765720
epoch: 1377, train precision: 0.998844, train loss: 10.601452, valid precision: 0.879400, valid loss: 84.358469
epoch: 1378, train precision: 0.999067, train loss: 10.662486, valid precision: 0.880600, valid loss: 83.179971
epoch: 1379, train precision: 0.999022, train loss: 10.543799, valid precision: 0.881600, valid loss: 84.306797
epoch: 1380, train precision: 0.998689, train loss: 10.736957, valid precision: 0.880200, valid loss: 85.626421
epoch: 1381, train precision: 0.998711, train loss: 10.641138, valid precision: 0.878000, valid loss: 84.540414
epoch: 1382, train precision: 0.999044, train loss: 10.564322, valid precision: 0.878200, valid loss: 85.748237
epoch: 1383, train precision: 0.998867, train loss: 10.651929, valid precision: 0.880000, valid loss: 84.392890
epoch: 1384, train precision: 0.998978, train loss: 10.567110, valid precision: 0.875200, valid loss: 86.127541
epoch: 1385, train precision: 0.998911, train loss: 10.603600, valid precision: 0.877600, valid loss: 85.857798
epoch: 1386, train precision: 0.998133, train loss: 10.865934, valid precision: 0.877000, valid loss: 86.711096
epoch: 1387, train precision: 0.998711, train loss: 10.691742, valid precision: 0.878800, valid loss: 84.829483
epoch: 1388, train precision: 0.999111, train loss: 10.571018, valid precision: 0.879000, valid loss: 84.935764
epoch: 1389, train precision: 0.999067, train loss: 10.565442, valid precision: 0.881400, valid loss: 83.865834
epoch: 1390, train precision: 0.999111, train loss: 10.586154, valid precision: 0.879600, valid loss: 86.480986
epoch: 1391, train precision: 0.998667, train loss: 10.684487, valid precision: 0.880800, valid loss: 85.811914
epoch: 1392, train precision: 0.998800, train loss: 10.722232, valid precision: 0.877600, valid loss: 86.696991
epoch: 1393, train precision: 0.998911, train loss: 10.623907, valid precision: 0.879200, valid loss: 85.720257
epoch: 1394, train precision: 0.999244, train loss: 10.539508, valid precision: 0.880400, valid loss: 85.562705
epoch: 1395, train precision: 0.998689, train loss: 10.684133, valid precision: 0.882000, valid loss: 89.192651
epoch: 1396, train precision: 0.998956, train loss: 10.597570, valid precision: 0.879200, valid loss: 88.672638
epoch: 1397, train precision: 0.998578, train loss: 10.683740, valid precision: 0.880400, valid loss: 87.951763
epoch: 1398, train precision: 0.998867, train loss: 10.665232, valid precision: 0.878400, valid loss: 88.388821
epoch: 1399, train precision: 0.998822, train loss: 10.587483, valid precision: 0.879800, valid loss: 86.182243
epoch: 1400, train precision: 0.998956, train loss: 10.590340, valid precision: 0.877400, valid loss: 88.914509
epoch: 1401, train precision: 0.998511, train loss: 10.727396, valid precision: 0.880600, valid loss: 87.658177
epoch: 1402, train precision: 0.998911, train loss: 10.672577, valid precision: 0.878200, valid loss: 86.768985
epoch: 1403, train precision: 0.999022, train loss: 10.577667, valid precision: 0.880800, valid loss: 85.106179
epoch: 1404, train precision: 0.998911, train loss: 10.593334, valid precision: 0.879600, valid loss: 85.451166
epoch: 1405, train precision: 0.998933, train loss: 10.622273, valid precision: 0.876200, valid loss: 87.684582
epoch: 1406, train precision: 0.998756, train loss: 10.653312, valid precision: 0.877800, valid loss: 85.371374
epoch: 1407, train precision: 0.998578, train loss: 10.745805, valid precision: 0.877400, valid loss: 87.784893
epoch: 1408, train precision: 0.998956, train loss: 10.698384, valid precision: 0.882400, valid loss: 85.340371
epoch: 1409, train precision: 0.998511, train loss: 10.706178, valid precision: 0.881200, valid loss: 83.752166
epoch: 1410, train precision: 0.998400, train loss: 10.814900, valid precision: 0.881200, valid loss: 85.482300
epoch: 1411, train precision: 0.998844, train loss: 10.667321, valid precision: 0.875800, valid loss: 85.567218
epoch: 1412, train precision: 0.999022, train loss: 10.673260, valid precision: 0.876400, valid loss: 87.104693
epoch: 1413, train precision: 0.999044, train loss: 10.601719, valid precision: 0.878800, valid loss: 84.517332
epoch: 1414, train precision: 0.998644, train loss: 10.716383, valid precision: 0.881000, valid loss: 85.911746
epoch: 1415, train precision: 0.998644, train loss: 10.688146, valid precision: 0.879400, valid loss: 86.687156
epoch: 1416, train precision: 0.998978, train loss: 10.603037, valid precision: 0.875600, valid loss: 86.723973
epoch: 1417, train precision: 0.999089, train loss: 10.563181, valid precision: 0.879000, valid loss: 83.652022
epoch: 1418, train precision: 0.999156, train loss: 10.503318, valid precision: 0.876800, valid loss: 86.435801
epoch: 1419, train precision: 0.999133, train loss: 10.598686, valid precision: 0.879400, valid loss: 85.999756
epoch: 1420, train precision: 0.999111, train loss: 10.558741, valid precision: 0.884200, valid loss: 85.701354
epoch: 1421, train precision: 0.999067, train loss: 10.591500, valid precision: 0.879000, valid loss: 83.866597
epoch: 1422, train precision: 0.998644, train loss: 10.652355, valid precision: 0.881000, valid loss: 87.979907
epoch: 1423, train precision: 0.999111, train loss: 10.580058, valid precision: 0.877000, valid loss: 87.659114
epoch: 1424, train precision: 0.999044, train loss: 10.548047, valid precision: 0.879200, valid loss: 87.595425
epoch: 1425, train precision: 0.999111, train loss: 10.603032, valid precision: 0.881200, valid loss: 85.541120
epoch: 1426, train precision: 0.998644, train loss: 10.651357, valid precision: 0.881400, valid loss: 85.556427
epoch: 1427, train precision: 0.999133, train loss: 10.534216, valid precision: 0.881800, valid loss: 86.369926
epoch: 1428, train precision: 0.999311, train loss: 10.542392, valid precision: 0.882600, valid loss: 83.789929
epoch: 1429, train precision: 0.998822, train loss: 10.597033, valid precision: 0.878800, valid loss: 84.065484
epoch: 1430, train precision: 0.999200, train loss: 10.545081, valid precision: 0.877000, valid loss: 86.245404
epoch: 1431, train precision: 0.998933, train loss: 10.601237, valid precision: 0.878000, valid loss: 87.138829
epoch: 1432, train precision: 0.999067, train loss: 10.598451, valid precision: 0.876200, valid loss: 87.136037
epoch: 1433, train precision: 0.999200, train loss: 10.572634, valid precision: 0.879000, valid loss: 86.196677
epoch: 1434, train precision: 0.999044, train loss: 10.581312, valid precision: 0.879600, valid loss: 85.832879
epoch: 1435, train precision: 0.998756, train loss: 10.607314, valid precision: 0.880200, valid loss: 86.566122
epoch: 1436, train precision: 0.998844, train loss: 10.643197, valid precision: 0.881000, valid loss: 86.862396
epoch: 1437, train precision: 0.999311, train loss: 10.506305, valid precision: 0.880200, valid loss: 87.051602
epoch: 1438, train precision: 0.998844, train loss: 10.618101, valid precision: 0.880000, valid loss: 87.002621
epoch: 1439, train precision: 0.998711, train loss: 10.647697, valid precision: 0.880600, valid loss: 85.158071
epoch: 1440, train precision: 0.998889, train loss: 10.642297, valid precision: 0.881600, valid loss: 84.311370
epoch: 1441, train precision: 0.998800, train loss: 10.650714, valid precision: 0.880600, valid loss: 83.434485
epoch: 1442, train precision: 0.999089, train loss: 10.549584, valid precision: 0.880600, valid loss: 85.844073
epoch: 1443, train precision: 0.998756, train loss: 10.682321, valid precision: 0.875800, valid loss: 85.557336
epoch: 1444, train precision: 0.998956, train loss: 10.651015, valid precision: 0.877000, valid loss: 86.811144
epoch: 1445, train precision: 0.998778, train loss: 10.622190, valid precision: 0.882000, valid loss: 84.120697
epoch: 1446, train precision: 0.998844, train loss: 10.618717, valid precision: 0.883600, valid loss: 83.241039
epoch: 1447, train precision: 0.998822, train loss: 10.622331, valid precision: 0.878600, valid loss: 84.854228
epoch: 1448, train precision: 0.999044, train loss: 10.580699, valid precision: 0.878400, valid loss: 85.878001
epoch: 1449, train precision: 0.999044, train loss: 10.587270, valid precision: 0.883000, valid loss: 85.144201
epoch: 1450, train precision: 0.999244, train loss: 10.471674, valid precision: 0.877000, valid loss: 86.727550
epoch: 1451, train precision: 0.998556, train loss: 10.688120, valid precision: 0.875600, valid loss: 87.251353
epoch: 1452, train precision: 0.999156, train loss: 10.592215, valid precision: 0.877800, valid loss: 86.058390
epoch: 1453, train precision: 0.998778, train loss: 10.654114, valid precision: 0.880400, valid loss: 88.560306
epoch: 1454, train precision: 0.998933, train loss: 10.565502, valid precision: 0.881000, valid loss: 85.890263
epoch: 1455, train precision: 0.998956, train loss: 10.581541, valid precision: 0.876400, valid loss: 87.053015
epoch: 1456, train precision: 0.998733, train loss: 10.624356, valid precision: 0.871800, valid loss: 88.714127
epoch: 1457, train precision: 0.999133, train loss: 10.581093, valid precision: 0.877800, valid loss: 86.219745
epoch: 1458, train precision: 0.998889, train loss: 10.644482, valid precision: 0.877000, valid loss: 88.710438
epoch: 1459, train precision: 0.998733, train loss: 10.645481, valid precision: 0.873800, valid loss: 88.302087
epoch: 1460, train precision: 0.998578, train loss: 10.635994, valid precision: 0.878200, valid loss: 90.158977
epoch: 1461, train precision: 0.998533, train loss: 10.719425, valid precision: 0.875800, valid loss: 86.477892
epoch: 1462, train precision: 0.998733, train loss: 10.590290, valid precision: 0.875000, valid loss: 87.457923
epoch: 1463, train precision: 0.998733, train loss: 10.690979, valid precision: 0.880200, valid loss: 87.814140
epoch: 1464, train precision: 0.998800, train loss: 10.662164, valid precision: 0.878400, valid loss: 86.745343
epoch: 1465, train precision: 0.998733, train loss: 10.685183, valid precision: 0.877200, valid loss: 85.812152
epoch: 1466, train precision: 0.998889, train loss: 10.615492, valid precision: 0.877200, valid loss: 86.066191
epoch: 1467, train precision: 0.998667, train loss: 10.668513, valid precision: 0.876200, valid loss: 88.040292
epoch: 1468, train precision: 0.998667, train loss: 10.669006, valid precision: 0.878000, valid loss: 86.872882
epoch: 1469, train precision: 0.998933, train loss: 10.609867, valid precision: 0.881000, valid loss: 86.631633
epoch: 1470, train precision: 0.999222, train loss: 10.528676, valid precision: 0.881200, valid loss: 85.569764
epoch: 1471, train precision: 0.999289, train loss: 10.518024, valid precision: 0.879800, valid loss: 86.250741
epoch: 1472, train precision: 0.998667, train loss: 10.701569, valid precision: 0.877000, valid loss: 86.855942
epoch: 1473, train precision: 0.998978, train loss: 10.654794, valid precision: 0.869600, valid loss: 87.612720
epoch: 1474, train precision: 0.998911, train loss: 10.616056, valid precision: 0.875000, valid loss: 88.538537
epoch: 1475, train precision: 0.998800, train loss: 10.660237, valid precision: 0.875000, valid loss: 88.157013
epoch: 1476, train precision: 0.998822, train loss: 10.743578, valid precision: 0.872800, valid loss: 89.264343
epoch: 1477, train precision: 0.998844, train loss: 10.588770, valid precision: 0.875400, valid loss: 87.371939
epoch: 1478, train precision: 0.998778, train loss: 10.704142, valid precision: 0.880000, valid loss: 84.675047
epoch: 1479, train precision: 0.999156, train loss: 10.556069, valid precision: 0.880400, valid loss: 85.445777
epoch: 1480, train precision: 0.999022, train loss: 10.574815, valid precision: 0.874000, valid loss: 87.401243
epoch: 1481, train precision: 0.998889, train loss: 10.545650, valid precision: 0.881400, valid loss: 85.790383
epoch: 1482, train precision: 0.998956, train loss: 10.635631, valid precision: 0.878600, valid loss: 86.671305
epoch: 1483, train precision: 0.998844, train loss: 10.563129, valid precision: 0.876000, valid loss: 85.927837
epoch: 1484, train precision: 0.998978, train loss: 10.591502, valid precision: 0.879400, valid loss: 86.896034
epoch: 1485, train precision: 0.998844, train loss: 10.581068, valid precision: 0.880400, valid loss: 86.371783
epoch: 1486, train precision: 0.998578, train loss: 10.678496, valid precision: 0.880000, valid loss: 87.445434
epoch: 1487, train precision: 0.999222, train loss: 10.525644, valid precision: 0.882000, valid loss: 84.534550
epoch: 1488, train precision: 0.998911, train loss: 10.667927, valid precision: 0.878400, valid loss: 84.365553
epoch: 1489, train precision: 0.998711, train loss: 10.638869, valid precision: 0.879400, valid loss: 85.597740
epoch: 1490, train precision: 0.998644, train loss: 10.715482, valid precision: 0.880200, valid loss: 84.413338
epoch: 1491, train precision: 0.998822, train loss: 10.695186, valid precision: 0.880600, valid loss: 82.584811
epoch: 1492, train precision: 0.999089, train loss: 10.595208, valid precision: 0.879800, valid loss: 82.238428
epoch: 1493, train precision: 0.998311, train loss: 10.751649, valid precision: 0.877200, valid loss: 83.668103
epoch: 1494, train precision: 0.999156, train loss: 10.556086, valid precision: 0.880000, valid loss: 83.894159
epoch: 1495, train precision: 0.998933, train loss: 10.606765, valid precision: 0.877600, valid loss: 86.980670
epoch: 1496, train precision: 0.999178, train loss: 10.606739, valid precision: 0.879200, valid loss: 85.497737
epoch: 1497, train precision: 0.999000, train loss: 10.538682, valid precision: 0.878000, valid loss: 86.120802
epoch: 1498, train precision: 0.999156, train loss: 10.625345, valid precision: 0.880000, valid loss: 82.201363
epoch: 1499, train precision: 0.999311, train loss: 10.537303, valid precision: 0.877800, valid loss: 83.841254
epoch: 1500, train precision: 0.999156, train loss: 10.573740, valid precision: 0.879600, valid loss: 83.982313
epoch: 1501, train precision: 0.998622, train loss: 10.699326, valid precision: 0.879800, valid loss: 83.397685
epoch: 1502, train precision: 0.998511, train loss: 10.707021, valid precision: 0.879400, valid loss: 83.073944
epoch: 1503, train precision: 0.998911, train loss: 10.650301, valid precision: 0.880600, valid loss: 84.149459
epoch: 1504, train precision: 0.999000, train loss: 10.551299, valid precision: 0.880600, valid loss: 84.641242
epoch: 1505, train precision: 0.999022, train loss: 10.630219, valid precision: 0.879000, valid loss: 85.364830
epoch: 1506, train precision: 0.998800, train loss: 10.649142, valid precision: 0.882400, valid loss: 83.615502
epoch: 1507, train precision: 0.998244, train loss: 10.768645, valid precision: 0.882400, valid loss: 85.132054
epoch: 1508, train precision: 0.999067, train loss: 10.598730, valid precision: 0.883200, valid loss: 84.470587
epoch: 1509, train precision: 0.999000, train loss: 10.567133, valid precision: 0.879000, valid loss: 84.995961
epoch: 1510, train precision: 0.998444, train loss: 10.671660, valid precision: 0.879800, valid loss: 83.891979
epoch: 1511, train precision: 0.999022, train loss: 10.561001, valid precision: 0.881000, valid loss: 83.904223
epoch: 1512, train precision: 0.998867, train loss: 10.600046, valid precision: 0.880400, valid loss: 84.672683
epoch: 1513, train precision: 0.998667, train loss: 10.577352, valid precision: 0.881000, valid loss: 87.060282
epoch: 1514, train precision: 0.999311, train loss: 10.520079, valid precision: 0.876800, valid loss: 87.544003
epoch: 1515, train precision: 0.999111, train loss: 10.502849, valid precision: 0.878400, valid loss: 87.153805
epoch: 1516, train precision: 0.998600, train loss: 10.689539, valid precision: 0.877800, valid loss: 85.669658
epoch: 1517, train precision: 0.999044, train loss: 10.575309, valid precision: 0.882400, valid loss: 84.270578
epoch: 1518, train precision: 0.998956, train loss: 10.575504, valid precision: 0.879000, valid loss: 86.733503
epoch: 1519, train precision: 0.998933, train loss: 10.590639, valid precision: 0.881800, valid loss: 85.673833
epoch: 1520, train precision: 0.998622, train loss: 10.719629, valid precision: 0.880800, valid loss: 86.434083
epoch: 1521, train precision: 0.998778, train loss: 10.657064, valid precision: 0.881800, valid loss: 84.741335
epoch: 1522, train precision: 0.999022, train loss: 10.621615, valid precision: 0.881800, valid loss: 84.210073
epoch: 1523, train precision: 0.998711, train loss: 10.744173, valid precision: 0.880400, valid loss: 83.500610
epoch: 1524, train precision: 0.998711, train loss: 10.689496, valid precision: 0.881600, valid loss: 83.954788
epoch: 1525, train precision: 0.998911, train loss: 10.560012, valid precision: 0.880200, valid loss: 85.613067
epoch: 1526, train precision: 0.998444, train loss: 10.697613, valid precision: 0.880400, valid loss: 86.887610
epoch: 1527, train precision: 0.998533, train loss: 10.682016, valid precision: 0.882400, valid loss: 85.124986
epoch: 1528, train precision: 0.998956, train loss: 10.617389, valid precision: 0.877600, valid loss: 86.223677
epoch: 1529, train precision: 0.998933, train loss: 10.611082, valid precision: 0.876200, valid loss: 85.505905
epoch: 1530, train precision: 0.999000, train loss: 10.574633, valid precision: 0.874800, valid loss: 84.873140
epoch: 1531, train precision: 0.998622, train loss: 10.671657, valid precision: 0.876400, valid loss: 85.853978
epoch: 1532, train precision: 0.999156, train loss: 10.577276, valid precision: 0.878800, valid loss: 84.746689
epoch: 1533, train precision: 0.999133, train loss: 10.588063, valid precision: 0.874800, valid loss: 90.363295
epoch: 1534, train precision: 0.998978, train loss: 10.576021, valid precision: 0.876600, valid loss: 88.840984
epoch: 1535, train precision: 0.999267, train loss: 10.541161, valid precision: 0.877400, valid loss: 84.204231
epoch: 1536, train precision: 0.998933, train loss: 10.592550, valid precision: 0.878400, valid loss: 83.000054
epoch: 1537, train precision: 0.999067, train loss: 10.575954, valid precision: 0.879600, valid loss: 85.857716
epoch: 1538, train precision: 0.999067, train loss: 10.563831, valid precision: 0.881600, valid loss: 83.055752
epoch: 1539, train precision: 0.999244, train loss: 10.478246, valid precision: 0.877600, valid loss: 86.455998
epoch: 1540, train precision: 0.998622, train loss: 10.692234, valid precision: 0.876400, valid loss: 85.829413
epoch: 1541, train precision: 0.998889, train loss: 10.656950, valid precision: 0.879200, valid loss: 86.427814
epoch: 1542, train precision: 0.998822, train loss: 10.621788, valid precision: 0.880400, valid loss: 87.052555
epoch: 1543, train precision: 0.998689, train loss: 10.736056, valid precision: 0.878000, valid loss: 87.720454
epoch: 1544, train precision: 0.998956, train loss: 10.596257, valid precision: 0.878400, valid loss: 84.273439
epoch: 1545, train precision: 0.999200, train loss: 10.508065, valid precision: 0.878200, valid loss: 84.488609
epoch: 1546, train precision: 0.998756, train loss: 10.618571, valid precision: 0.878000, valid loss: 88.053468
epoch: 1547, train precision: 0.999000, train loss: 10.590324, valid precision: 0.879400, valid loss: 85.782095
epoch: 1548, train precision: 0.998778, train loss: 10.697982, valid precision: 0.880800, valid loss: 87.842735
epoch: 1549, train precision: 0.999111, train loss: 10.580352, valid precision: 0.876400, valid loss: 86.355631
epoch: 1550, train precision: 0.998689, train loss: 10.673281, valid precision: 0.882000, valid loss: 86.196885
epoch: 1551, train precision: 0.998467, train loss: 10.801404, valid precision: 0.879400, valid loss: 87.723997
epoch: 1552, train precision: 0.998800, train loss: 10.642192, valid precision: 0.882400, valid loss: 85.490973
epoch: 1553, train precision: 0.999200, train loss: 10.552257, valid precision: 0.882600, valid loss: 84.035205
epoch: 1554, train precision: 0.998800, train loss: 10.699386, valid precision: 0.879800, valid loss: 84.171311
epoch: 1555, train precision: 0.999022, train loss: 10.605174, valid precision: 0.879600, valid loss: 83.449320
epoch: 1556, train precision: 0.999311, train loss: 10.547918, valid precision: 0.879200, valid loss: 83.257588
epoch: 1557, train precision: 0.999000, train loss: 10.614247, valid precision: 0.881400, valid loss: 85.239626
epoch: 1558, train precision: 0.998844, train loss: 10.613588, valid precision: 0.877200, valid loss: 85.717582
epoch: 1559, train precision: 0.998578, train loss: 10.743687, valid precision: 0.878200, valid loss: 86.014760
epoch: 1560, train precision: 0.999022, train loss: 10.526718, valid precision: 0.882600, valid loss: 84.332414
epoch: 1561, train precision: 0.999000, train loss: 10.575151, valid precision: 0.878200, valid loss: 83.584761
epoch: 1562, train precision: 0.998756, train loss: 10.742261, valid precision: 0.878400, valid loss: 87.735834
epoch: 1563, train precision: 0.999044, train loss: 10.583686, valid precision: 0.883400, valid loss: 84.901854
epoch: 1564, train precision: 0.999022, train loss: 10.623266, valid precision: 0.881800, valid loss: 83.606359
epoch: 1565, train precision: 0.999067, train loss: 10.568120, valid precision: 0.878600, valid loss: 86.518599
epoch: 1566, train precision: 0.998844, train loss: 10.589438, valid precision: 0.880000, valid loss: 84.010067
epoch: 1567, train precision: 0.999044, train loss: 10.569873, valid precision: 0.880800, valid loss: 86.516250
epoch: 1568, train precision: 0.998867, train loss: 10.627174, valid precision: 0.876200, valid loss: 87.885863
epoch: 1569, train precision: 0.998800, train loss: 10.663846, valid precision: 0.874000, valid loss: 86.602292
epoch: 1570, train precision: 0.998867, train loss: 10.614122, valid precision: 0.879400, valid loss: 84.419790
epoch: 1571, train precision: 0.998778, train loss: 10.668157, valid precision: 0.877000, valid loss: 86.960098
epoch: 1572, train precision: 0.999111, train loss: 10.560208, valid precision: 0.878400, valid loss: 85.730592
epoch: 1573, train precision: 0.998756, train loss: 10.599668, valid precision: 0.878000, valid loss: 85.209449
epoch: 1574, train precision: 0.998978, train loss: 10.612913, valid precision: 0.880600, valid loss: 85.366325
epoch: 1575, train precision: 0.998467, train loss: 10.717209, valid precision: 0.876800, valid loss: 87.138084
epoch: 1576, train precision: 0.998756, train loss: 10.647538, valid precision: 0.876600, valid loss: 88.567659
epoch: 1577, train precision: 0.998444, train loss: 10.712998, valid precision: 0.875400, valid loss: 87.250988
epoch: 1578, train precision: 0.999067, train loss: 10.593496, valid precision: 0.876200, valid loss: 87.125058
epoch: 1579, train precision: 0.998978, train loss: 10.603256, valid precision: 0.873200, valid loss: 86.484654
epoch: 1580, train precision: 0.998689, train loss: 10.640201, valid precision: 0.880600, valid loss: 85.471697
epoch: 1581, train precision: 0.998889, train loss: 10.608168, valid precision: 0.876600, valid loss: 86.604840
epoch: 1582, train precision: 0.999156, train loss: 10.534760, valid precision: 0.880400, valid loss: 85.673584
epoch: 1583, train precision: 0.998800, train loss: 10.595157, valid precision: 0.878600, valid loss: 86.049371
epoch: 1584, train precision: 0.998867, train loss: 10.662483, valid precision: 0.877200, valid loss: 88.406493
epoch: 1585, train precision: 0.998933, train loss: 10.575304, valid precision: 0.880200, valid loss: 86.709625
epoch: 1586, train precision: 0.999044, train loss: 10.535246, valid precision: 0.879200, valid loss: 84.815333
epoch: 1587, train precision: 0.998689, train loss: 10.677580, valid precision: 0.883800, valid loss: 83.975098
epoch: 1588, train precision: 0.999133, train loss: 10.591796, valid precision: 0.881200, valid loss: 84.200379
epoch: 1589, train precision: 0.998822, train loss: 10.669975, valid precision: 0.881800, valid loss: 83.354145
epoch: 1590, train precision: 0.998622, train loss: 10.700948, valid precision: 0.878400, valid loss: 85.521714
epoch: 1591, train precision: 0.998667, train loss: 10.632147, valid precision: 0.882600, valid loss: 84.887306
epoch: 1592, train precision: 0.998711, train loss: 10.598213, valid precision: 0.881600, valid loss: 84.508675
epoch: 1593, train precision: 0.998578, train loss: 10.697761, valid precision: 0.879800, valid loss: 86.893412
epoch: 1594, train precision: 0.998844, train loss: 10.591529, valid precision: 0.879600, valid loss: 84.895589
epoch: 1595, train precision: 0.999089, train loss: 10.547759, valid precision: 0.875800, valid loss: 83.561412
epoch: 1596, train precision: 0.999067, train loss: 10.560948, valid precision: 0.878200, valid loss: 85.852607
epoch: 1597, train precision: 0.998756, train loss: 10.704233, valid precision: 0.877400, valid loss: 85.812776
epoch: 1598, train precision: 0.998956, train loss: 10.560574, valid precision: 0.881400, valid loss: 85.003448
epoch: 1599, train precision: 0.999156, train loss: 10.514407, valid precision: 0.877800, valid loss: 85.895336
epoch: 1600, train precision: 0.998778, train loss: 10.622472, valid precision: 0.879000, valid loss: 85.849671
epoch: 1601, train precision: 0.998911, train loss: 10.668946, valid precision: 0.872600, valid loss: 89.203978
epoch: 1602, train precision: 0.998956, train loss: 10.579292, valid precision: 0.874200, valid loss: 88.222641
epoch: 1603, train precision: 0.998844, train loss: 10.577952, valid precision: 0.874800, valid loss: 87.210644
epoch: 1604, train precision: 0.998956, train loss: 10.603804, valid precision: 0.874600, valid loss: 87.742739
epoch: 1605, train precision: 0.998622, train loss: 10.655500, valid precision: 0.873000, valid loss: 87.361605
epoch: 1606, train precision: 0.999133, train loss: 10.522488, valid precision: 0.875200, valid loss: 85.229857
epoch: 1607, train precision: 0.998889, train loss: 10.557742, valid precision: 0.876600, valid loss: 86.290767
epoch: 1608, train precision: 0.998933, train loss: 10.621990, valid precision: 0.877000, valid loss: 87.164140
epoch: 1609, train precision: 0.999000, train loss: 10.585707, valid precision: 0.870400, valid loss: 85.807083
epoch: 1610, train precision: 0.998511, train loss: 10.694813, valid precision: 0.875200, valid loss: 88.215292
epoch: 1611, train precision: 0.999000, train loss: 10.547274, valid precision: 0.879200, valid loss: 86.235559
epoch: 1612, train precision: 0.998978, train loss: 10.590538, valid precision: 0.876400, valid loss: 86.776592
epoch: 1613, train precision: 0.999089, train loss: 10.547972, valid precision: 0.877200, valid loss: 86.214189
epoch: 1614, train precision: 0.999133, train loss: 10.592078, valid precision: 0.874600, valid loss: 84.514489
epoch: 1615, train precision: 0.999178, train loss: 10.525696, valid precision: 0.878400, valid loss: 84.917084
epoch: 1616, train precision: 0.999489, train loss: 10.498118, valid precision: 0.880200, valid loss: 84.083169
epoch: 1617, train precision: 0.999178, train loss: 10.499903, valid precision: 0.878400, valid loss: 84.159881
epoch: 1618, train precision: 0.998689, train loss: 10.591312, valid precision: 0.878800, valid loss: 82.372743
epoch: 1619, train precision: 0.998911, train loss: 10.572648, valid precision: 0.879200, valid loss: 84.693340
epoch: 1620, train precision: 0.998778, train loss: 10.715415, valid precision: 0.878200, valid loss: 84.685048
epoch: 1621, train precision: 0.999156, train loss: 10.540443, valid precision: 0.879800, valid loss: 85.071014
epoch: 1622, train precision: 0.999067, train loss: 10.534742, valid precision: 0.878400, valid loss: 84.002598
epoch: 1623, train precision: 0.998956, train loss: 10.580176, valid precision: 0.877800, valid loss: 84.692041
epoch: 1624, train precision: 0.998822, train loss: 10.602067, valid precision: 0.879600, valid loss: 83.155841
epoch: 1625, train precision: 0.999244, train loss: 10.512053, valid precision: 0.879000, valid loss: 83.001047
epoch: 1626, train precision: 0.999044, train loss: 10.524527, valid precision: 0.877600, valid loss: 85.553621
epoch: 1627, train precision: 0.998489, train loss: 10.710365, valid precision: 0.877200, valid loss: 85.014966
epoch: 1628, train precision: 0.998911, train loss: 10.565762, valid precision: 0.876800, valid loss: 84.913378
epoch: 1629, train precision: 0.998911, train loss: 10.576022, valid precision: 0.879400, valid loss: 83.413115
epoch: 1630, train precision: 0.998933, train loss: 10.563555, valid precision: 0.878600, valid loss: 84.283742
epoch: 1631, train precision: 0.998667, train loss: 10.576651, valid precision: 0.878200, valid loss: 83.824381
epoch: 1632, train precision: 0.998867, train loss: 10.585065, valid precision: 0.879800, valid loss: 83.815031
epoch: 1633, train precision: 0.998711, train loss: 10.651682, valid precision: 0.878000, valid loss: 83.710615
epoch: 1634, train precision: 0.998933, train loss: 10.542774, valid precision: 0.877200, valid loss: 86.272077
epoch: 1635, train precision: 0.998511, train loss: 10.619657, valid precision: 0.879200, valid loss: 83.789607
epoch: 1636, train precision: 0.999244, train loss: 10.454916, valid precision: 0.876200, valid loss: 85.260149
epoch: 1637, train precision: 0.999111, train loss: 10.474509, valid precision: 0.877000, valid loss: 86.875511
epoch: 1638, train precision: 0.998644, train loss: 10.708614, valid precision: 0.876000, valid loss: 86.207153
epoch: 1639, train precision: 0.998756, train loss: 10.622148, valid precision: 0.878400, valid loss: 84.185570
epoch: 1640, train precision: 0.998889, train loss: 10.576149, valid precision: 0.876200, valid loss: 87.104280
epoch: 1641, train precision: 0.998600, train loss: 10.589691, valid precision: 0.875600, valid loss: 88.103510
epoch: 1642, train precision: 0.998911, train loss: 10.603651, valid precision: 0.876400, valid loss: 87.361879
epoch: 1643, train precision: 0.998422, train loss: 10.733618, valid precision: 0.875800, valid loss: 87.774017
epoch: 1644, train precision: 0.998889, train loss: 10.626721, valid precision: 0.873200, valid loss: 86.984925
epoch: 1645, train precision: 0.999133, train loss: 10.560827, valid precision: 0.878200, valid loss: 86.067389
epoch: 1646, train precision: 0.998978, train loss: 10.592849, valid precision: 0.875200, valid loss: 88.153753
epoch: 1647, train precision: 0.998800, train loss: 10.588592, valid precision: 0.872400, valid loss: 86.810479
epoch: 1648, train precision: 0.998644, train loss: 10.638140, valid precision: 0.876400, valid loss: 86.538005
epoch: 1649, train precision: 0.998711, train loss: 10.723336, valid precision: 0.873200, valid loss: 87.186166
epoch: 1650, train precision: 0.999156, train loss: 10.512278, valid precision: 0.873600, valid loss: 85.351323
epoch: 1651, train precision: 0.998978, train loss: 10.559243, valid precision: 0.878000, valid loss: 85.366906
epoch: 1652, train precision: 0.998356, train loss: 10.651743, valid precision: 0.877000, valid loss: 86.715786
epoch: 1653, train precision: 0.998778, train loss: 10.616339, valid precision: 0.872800, valid loss: 86.368416
epoch: 1654, train precision: 0.998800, train loss: 10.534943, valid precision: 0.876600, valid loss: 87.437166
epoch: 1655, train precision: 0.999022, train loss: 10.545687, valid precision: 0.876200, valid loss: 85.394148
epoch: 1656, train precision: 0.999133, train loss: 10.571952, valid precision: 0.878600, valid loss: 85.195039
epoch: 1657, train precision: 0.999178, train loss: 10.524904, valid precision: 0.879800, valid loss: 82.602085
epoch: 1658, train precision: 0.998711, train loss: 10.621934, valid precision: 0.872000, valid loss: 83.991832
epoch: 1659, train precision: 0.999067, train loss: 10.478233, valid precision: 0.876600, valid loss: 84.111111
epoch: 1660, train precision: 0.998956, train loss: 10.580837, valid precision: 0.876800, valid loss: 83.700126
epoch: 1661, train precision: 0.998844, train loss: 10.603308, valid precision: 0.868200, valid loss: 86.765742
epoch: 1662, train precision: 0.999267, train loss: 10.441673, valid precision: 0.875600, valid loss: 87.599437
epoch: 1663, train precision: 0.998778, train loss: 10.586258, valid precision: 0.877000, valid loss: 85.693943
epoch: 1664, train precision: 0.999044, train loss: 10.592229, valid precision: 0.879200, valid loss: 83.513034
epoch: 1665, train precision: 0.998867, train loss: 10.599277, valid precision: 0.877200, valid loss: 82.604266
epoch: 1666, train precision: 0.998911, train loss: 10.583988, valid precision: 0.874000, valid loss: 84.132468
epoch: 1667, train precision: 0.998822, train loss: 10.597868, valid precision: 0.879000, valid loss: 85.156154
epoch: 1668, train precision: 0.998933, train loss: 10.538217, valid precision: 0.876600, valid loss: 85.306758
epoch: 1669, train precision: 0.998822, train loss: 10.571252, valid precision: 0.872200, valid loss: 84.514543
epoch: 1670, train precision: 0.999244, train loss: 10.431890, valid precision: 0.875600, valid loss: 84.601055
epoch: 1671, train precision: 0.998800, train loss: 10.640680, valid precision: 0.875400, valid loss: 85.591346
epoch: 1672, train precision: 0.999089, train loss: 10.473564, valid precision: 0.879600, valid loss: 84.104503
epoch: 1673, train precision: 0.998911, train loss: 10.519248, valid precision: 0.875800, valid loss: 85.699583
epoch: 1674, train precision: 0.998822, train loss: 10.482181, valid precision: 0.874800, valid loss: 86.342156
epoch: 1675, train precision: 0.998956, train loss: 10.656437, valid precision: 0.874000, valid loss: 86.227123
epoch: 1676, train precision: 0.999156, train loss: 10.493939, valid precision: 0.876200, valid loss: 87.503148
epoch: 1677, train precision: 0.998978, train loss: 10.570294, valid precision: 0.878200, valid loss: 86.314613
epoch: 1678, train precision: 0.998644, train loss: 10.674448, valid precision: 0.877400, valid loss: 86.813066
epoch: 1679, train precision: 0.998844, train loss: 10.583347, valid precision: 0.877200, valid loss: 84.305270
epoch: 1680, train precision: 0.998622, train loss: 10.637824, valid precision: 0.875600, valid loss: 88.487348
epoch: 1681, train precision: 0.998733, train loss: 10.544595, valid precision: 0.877000, valid loss: 86.459540
epoch: 1682, train precision: 0.999067, train loss: 10.506627, valid precision: 0.876000, valid loss: 88.336812
epoch: 1683, train precision: 0.999178, train loss: 10.532616, valid precision: 0.883000, valid loss: 84.135562
epoch: 1684, train precision: 0.998733, train loss: 10.599901, valid precision: 0.875600, valid loss: 84.819834
epoch: 1685, train precision: 0.998911, train loss: 10.544879, valid precision: 0.880800, valid loss: 84.774926
epoch: 1686, train precision: 0.999067, train loss: 10.560204, valid precision: 0.877800, valid loss: 83.243800
epoch: 1687, train precision: 0.998822, train loss: 10.553197, valid precision: 0.876200, valid loss: 86.285332
epoch: 1688, train precision: 0.998844, train loss: 10.568993, valid precision: 0.878200, valid loss: 86.561595
epoch: 1689, train precision: 0.998689, train loss: 10.637758, valid precision: 0.877000, valid loss: 86.683842
epoch: 1690, train precision: 0.999022, train loss: 10.565171, valid precision: 0.876800, valid loss: 84.442240
epoch: 1691, train precision: 0.998756, train loss: 10.615539, valid precision: 0.871800, valid loss: 86.763215
epoch: 1692, train precision: 0.998867, train loss: 10.531001, valid precision: 0.873600, valid loss: 89.310231
epoch: 1693, train precision: 0.998689, train loss: 10.663453, valid precision: 0.877800, valid loss: 89.068349
epoch: 1694, train precision: 0.999133, train loss: 10.492644, valid precision: 0.879200, valid loss: 85.782063
epoch: 1695, train precision: 0.998978, train loss: 10.482177, valid precision: 0.878600, valid loss: 87.773297
epoch: 1696, train precision: 0.999044, train loss: 10.477025, valid precision: 0.875200, valid loss: 87.268395
epoch: 1697, train precision: 0.998822, train loss: 10.654705, valid precision: 0.876200, valid loss: 87.544084
epoch: 1698, train precision: 0.999156, train loss: 10.484539, valid precision: 0.876400, valid loss: 86.824066
epoch: 1699, train precision: 0.999089, train loss: 10.529399, valid precision: 0.879800, valid loss: 86.568347
epoch: 1700, train precision: 0.999089, train loss: 10.455307, valid precision: 0.876200, valid loss: 90.815343
epoch: 1701, train precision: 0.999022, train loss: 10.567392, valid precision: 0.876000, valid loss: 91.136573
epoch: 1702, train precision: 0.998978, train loss: 10.517828, valid precision: 0.878800, valid loss: 89.908575
epoch: 1703, train precision: 0.999156, train loss: 10.492339, valid precision: 0.878200, valid loss: 90.137350
epoch: 1704, train precision: 0.998933, train loss: 10.607903, valid precision: 0.879400, valid loss: 86.037789
epoch: 1705, train precision: 0.999111, train loss: 10.535620, valid precision: 0.875000, valid loss: 88.642222
epoch: 1706, train precision: 0.998978, train loss: 10.547226, valid precision: 0.878000, valid loss: 87.122851
epoch: 1707, train precision: 0.999067, train loss: 10.521445, valid precision: 0.875200, valid loss: 92.691869
epoch: 1708, train precision: 0.998644, train loss: 10.567036, valid precision: 0.875400, valid loss: 89.918332
epoch: 1709, train precision: 0.998956, train loss: 10.567537, valid precision: 0.877600, valid loss: 87.841209
epoch: 1710, train precision: 0.999044, train loss: 10.543298, valid precision: 0.878800, valid loss: 89.178295
epoch: 1711, train precision: 0.998800, train loss: 10.614129, valid precision: 0.878600, valid loss: 88.260277
epoch: 1712, train precision: 0.999089, train loss: 10.466200, valid precision: 0.880800, valid loss: 89.217439
epoch: 1713, train precision: 0.998378, train loss: 10.727069, valid precision: 0.878200, valid loss: 88.214835
epoch: 1714, train precision: 0.998733, train loss: 10.600861, valid precision: 0.878200, valid loss: 86.544518
epoch: 1715, train precision: 0.999244, train loss: 10.473708, valid precision: 0.877400, valid loss: 86.786042
epoch: 1716, train precision: 0.998844, train loss: 10.587565, valid precision: 0.879200, valid loss: 86.070989
epoch: 1717, train precision: 0.998711, train loss: 10.585811, valid precision: 0.871400, valid loss: 87.749460
epoch: 1718, train precision: 0.998933, train loss: 10.538262, valid precision: 0.876200, valid loss: 86.582006
epoch: 1719, train precision: 0.998689, train loss: 10.652523, valid precision: 0.877600, valid loss: 83.165860
epoch: 1720, train precision: 0.999000, train loss: 10.571872, valid precision: 0.880800, valid loss: 85.229137
epoch: 1721, train precision: 0.998689, train loss: 10.554831, valid precision: 0.878800, valid loss: 86.438552
epoch: 1722, train precision: 0.999089, train loss: 10.470537, valid precision: 0.875000, valid loss: 86.379079
epoch: 1723, train precision: 0.999089, train loss: 10.507249, valid precision: 0.873800, valid loss: 85.372953
epoch: 1724, train precision: 0.998933, train loss: 10.606530, valid precision: 0.876600, valid loss: 85.735171
epoch: 1725, train precision: 0.998956, train loss: 10.521138, valid precision: 0.876600, valid loss: 88.345707
epoch: 1726, train precision: 0.999133, train loss: 10.528197, valid precision: 0.875600, valid loss: 85.344748
epoch: 1727, train precision: 0.999067, train loss: 10.471575, valid precision: 0.879600, valid loss: 83.958509
epoch: 1728, train precision: 0.998622, train loss: 10.667305, valid precision: 0.878600, valid loss: 83.626808
epoch: 1729, train precision: 0.999044, train loss: 10.511536, valid precision: 0.876800, valid loss: 85.460010
epoch: 1730, train precision: 0.999156, train loss: 10.519031, valid precision: 0.880000, valid loss: 85.346292
epoch: 1731, train precision: 0.998822, train loss: 10.542316, valid precision: 0.879000, valid loss: 87.222684
epoch: 1732, train precision: 0.998867, train loss: 10.594210, valid precision: 0.878600, valid loss: 88.128781
epoch: 1733, train precision: 0.999244, train loss: 10.486761, valid precision: 0.881400, valid loss: 86.883094
epoch: 1734, train precision: 0.999044, train loss: 10.467858, valid precision: 0.878400, valid loss: 89.256935
epoch: 1735, train precision: 0.998911, train loss: 10.563027, valid precision: 0.877600, valid loss: 87.942908
epoch: 1736, train precision: 0.999244, train loss: 10.452673, valid precision: 0.876200, valid loss: 87.102105
epoch: 1737, train precision: 0.998867, train loss: 10.490108, valid precision: 0.879400, valid loss: 85.840649
epoch: 1738, train precision: 0.999044, train loss: 10.480460, valid precision: 0.877600, valid loss: 85.565040
epoch: 1739, train precision: 0.998756, train loss: 10.597877, valid precision: 0.877200, valid loss: 87.737539
epoch: 1740, train precision: 0.998822, train loss: 10.629447, valid precision: 0.878200, valid loss: 88.524774
epoch: 1741, train precision: 0.999133, train loss: 10.544345, valid precision: 0.876600, valid loss: 88.467272
epoch: 1742, train precision: 0.998889, train loss: 10.532906, valid precision: 0.879600, valid loss: 86.754089
epoch: 1743, train precision: 0.998578, train loss: 10.589789, valid precision: 0.880600, valid loss: 87.678301
epoch: 1744, train precision: 0.998800, train loss: 10.585896, valid precision: 0.879800, valid loss: 86.847228
epoch: 1745, train precision: 0.999067, train loss: 10.449938, valid precision: 0.879400, valid loss: 89.214832
epoch: 1746, train precision: 0.998733, train loss: 10.645799, valid precision: 0.882600, valid loss: 85.459453
epoch: 1747, train precision: 0.998956, train loss: 10.605570, valid precision: 0.877800, valid loss: 86.164203
epoch: 1748, train precision: 0.999289, train loss: 10.427270, valid precision: 0.878000, valid loss: 86.529603
epoch: 1749, train precision: 0.999133, train loss: 10.475797, valid precision: 0.876400, valid loss: 88.904259
epoch: 1750, train precision: 0.999133, train loss: 10.512290, valid precision: 0.877000, valid loss: 88.651099
epoch: 1751, train precision: 0.999200, train loss: 10.505454, valid precision: 0.876000, valid loss: 90.715833
epoch: 1752, train precision: 0.998378, train loss: 10.752843, valid precision: 0.879200, valid loss: 88.536154
epoch: 1753, train precision: 0.999089, train loss: 10.543469, valid precision: 0.877200, valid loss: 88.753137
epoch: 1754, train precision: 0.998800, train loss: 10.566020, valid precision: 0.878600, valid loss: 88.489157
epoch: 1755, train precision: 0.998711, train loss: 10.615250, valid precision: 0.874600, valid loss: 92.337148
epoch: 1756, train precision: 0.998956, train loss: 10.577962, valid precision: 0.878200, valid loss: 86.572204
epoch: 1757, train precision: 0.998444, train loss: 10.716842, valid precision: 0.871800, valid loss: 91.447577
epoch: 1758, train precision: 0.998889, train loss: 10.601425, valid precision: 0.879200, valid loss: 86.045302
epoch: 1759, train precision: 0.998689, train loss: 10.588420, valid precision: 0.879000, valid loss: 88.126926
epoch: 1760, train precision: 0.999178, train loss: 10.498246, valid precision: 0.879600, valid loss: 86.030133
epoch: 1761, train precision: 0.998822, train loss: 10.588178, valid precision: 0.877000, valid loss: 88.704620
epoch: 1762, train precision: 0.998800, train loss: 10.566823, valid precision: 0.877600, valid loss: 87.907202
epoch: 1763, train precision: 0.998911, train loss: 10.573597, valid precision: 0.876200, valid loss: 88.164885
epoch: 1764, train precision: 0.998889, train loss: 10.543159, valid precision: 0.872800, valid loss: 90.419349
epoch: 1765, train precision: 0.998800, train loss: 10.536955, valid precision: 0.873600, valid loss: 88.942836
epoch: 1766, train precision: 0.999222, train loss: 10.513103, valid precision: 0.875800, valid loss: 89.736641
epoch: 1767, train precision: 0.998756, train loss: 10.570375, valid precision: 0.876000, valid loss: 88.561187
epoch: 1768, train precision: 0.998867, train loss: 10.573104, valid precision: 0.877600, valid loss: 88.526851
epoch: 1769, train precision: 0.998600, train loss: 10.710057, valid precision: 0.877000, valid loss: 88.133626
epoch: 1770, train precision: 0.998600, train loss: 10.610241, valid precision: 0.882000, valid loss: 89.387401
epoch: 1771, train precision: 0.999133, train loss: 10.494046, valid precision: 0.876000, valid loss: 88.535013
epoch: 1772, train precision: 0.999133, train loss: 10.457668, valid precision: 0.875600, valid loss: 89.290535
epoch: 1773, train precision: 0.999178, train loss: 10.420485, valid precision: 0.876400, valid loss: 88.978315
epoch: 1774, train precision: 0.998756, train loss: 10.608510, valid precision: 0.875400, valid loss: 88.695696
epoch: 1775, train precision: 0.999044, train loss: 10.458489, valid precision: 0.880000, valid loss: 85.293705
epoch: 1776, train precision: 0.998911, train loss: 10.495962, valid precision: 0.875200, valid loss: 86.920123
epoch: 1777, train precision: 0.998822, train loss: 10.587176, valid precision: 0.876200, valid loss: 86.018556
epoch: 1778, train precision: 0.999089, train loss: 10.534753, valid precision: 0.882800, valid loss: 88.251791
epoch: 1779, train precision: 0.998867, train loss: 10.556012, valid precision: 0.876200, valid loss: 89.907445
epoch: 1780, train precision: 0.998800, train loss: 10.591439, valid precision: 0.875800, valid loss: 91.401196
epoch: 1781, train precision: 0.998911, train loss: 10.564703, valid precision: 0.878200, valid loss: 90.124787
epoch: 1782, train precision: 0.998778, train loss: 10.610129, valid precision: 0.875600, valid loss: 89.691607
epoch: 1783, train precision: 0.998600, train loss: 10.634753, valid precision: 0.875000, valid loss: 92.430914
epoch: 1784, train precision: 0.999200, train loss: 10.500951, valid precision: 0.878800, valid loss: 89.086439
epoch: 1785, train precision: 0.999067, train loss: 10.496826, valid precision: 0.876200, valid loss: 90.819490
epoch: 1786, train precision: 0.999267, train loss: 10.478988, valid precision: 0.879200, valid loss: 89.238606
epoch: 1787, train precision: 0.998822, train loss: 10.589020, valid precision: 0.873400, valid loss: 90.201558
epoch: 1788, train precision: 0.999133, train loss: 10.544297, valid precision: 0.877800, valid loss: 89.532379
epoch: 1789, train precision: 0.998911, train loss: 10.599376, valid precision: 0.877800, valid loss: 89.487377
epoch: 1790, train precision: 0.999356, train loss: 10.422670, valid precision: 0.876600, valid loss: 87.557699
epoch: 1791, train precision: 0.999022, train loss: 10.552873, valid precision: 0.874600, valid loss: 92.439583
epoch: 1792, train precision: 0.998911, train loss: 10.564382, valid precision: 0.876000, valid loss: 91.067632
epoch: 1793, train precision: 0.999022, train loss: 10.473489, valid precision: 0.875600, valid loss: 88.646994
epoch: 1794, train precision: 0.999133, train loss: 10.466830, valid precision: 0.877000, valid loss: 90.504649
epoch: 1795, train precision: 0.998933, train loss: 10.518725, valid precision: 0.876400, valid loss: 89.849627
epoch: 1796, train precision: 0.999156, train loss: 10.513168, valid precision: 0.875600, valid loss: 90.687179
epoch: 1797, train precision: 0.998867, train loss: 10.558522, valid precision: 0.873600, valid loss: 90.632533
epoch: 1798, train precision: 0.999022, train loss: 10.490602, valid precision: 0.874600, valid loss: 90.969717
epoch: 1799, train precision: 0.998956, train loss: 10.527258, valid precision: 0.880600, valid loss: 90.236202
epoch: 1800, train precision: 0.999067, train loss: 10.443274, valid precision: 0.875000, valid loss: 90.636574
epoch: 1801, train precision: 0.999222, train loss: 10.500569, valid precision: 0.877400, valid loss: 90.437085
epoch: 1802, train precision: 0.999000, train loss: 10.527486, valid precision: 0.872200, valid loss: 91.097862
epoch: 1803, train precision: 0.998956, train loss: 10.570080, valid precision: 0.875400, valid loss: 90.928406
epoch: 1804, train precision: 0.998400, train loss: 10.745639, valid precision: 0.874200, valid loss: 89.496013
epoch: 1805, train precision: 0.998844, train loss: 10.545770, valid precision: 0.879200, valid loss: 87.692231
epoch: 1806, train precision: 0.999378, train loss: 10.488298, valid precision: 0.877200, valid loss: 90.177513
epoch: 1807, train precision: 0.999089, train loss: 10.508234, valid precision: 0.879200, valid loss: 87.396008
epoch: 1808, train precision: 0.998933, train loss: 10.542216, valid precision: 0.880000, valid loss: 88.520288
epoch: 1809, train precision: 0.998911, train loss: 10.508860, valid precision: 0.874200, valid loss: 90.900851
epoch: 1810, train precision: 0.999022, train loss: 10.587782, valid precision: 0.877600, valid loss: 90.191329
epoch: 1811, train precision: 0.998733, train loss: 10.595167, valid precision: 0.879400, valid loss: 90.820964
epoch: 1812, train precision: 0.998822, train loss: 10.562758, valid precision: 0.878600, valid loss: 88.553256
epoch: 1813, train precision: 0.999156, train loss: 10.522915, valid precision: 0.879600, valid loss: 87.106422
epoch: 1814, train precision: 0.998778, train loss: 10.605228, valid precision: 0.877400, valid loss: 87.552490
epoch: 1815, train precision: 0.999267, train loss: 10.420816, valid precision: 0.879800, valid loss: 88.288950
epoch: 1816, train precision: 0.998733, train loss: 10.596988, valid precision: 0.877200, valid loss: 88.423592
epoch: 1817, train precision: 0.999067, train loss: 10.543808, valid precision: 0.882000, valid loss: 89.376994
epoch: 1818, train precision: 0.999178, train loss: 10.483309, valid precision: 0.879000, valid loss: 86.987689
epoch: 1819, train precision: 0.998733, train loss: 10.614696, valid precision: 0.878400, valid loss: 86.914802
epoch: 1820, train precision: 0.999244, train loss: 10.495757, valid precision: 0.877400, valid loss: 88.157326
epoch: 1821, train precision: 0.999333, train loss: 10.475135, valid precision: 0.878400, valid loss: 87.359522
epoch: 1822, train precision: 0.998489, train loss: 10.682265, valid precision: 0.877400, valid loss: 88.378663
epoch: 1823, train precision: 0.999156, train loss: 10.521076, valid precision: 0.880600, valid loss: 86.761272
epoch: 1824, train precision: 0.999267, train loss: 10.487376, valid precision: 0.882200, valid loss: 86.040180
epoch: 1825, train precision: 0.999000, train loss: 10.535985, valid precision: 0.882200, valid loss: 87.650084
epoch: 1826, train precision: 0.999000, train loss: 10.560458, valid precision: 0.878000, valid loss: 88.798746
epoch: 1827, train precision: 0.999000, train loss: 10.468221, valid precision: 0.876800, valid loss: 86.027786
epoch: 1828, train precision: 0.999178, train loss: 10.486763, valid precision: 0.878400, valid loss: 89.263662
epoch: 1829, train precision: 0.998578, train loss: 10.676112, valid precision: 0.873400, valid loss: 88.380822
epoch: 1830, train precision: 0.998911, train loss: 10.541647, valid precision: 0.879800, valid loss: 85.533680
epoch: 1831, train precision: 0.999133, train loss: 10.478349, valid precision: 0.876200, valid loss: 87.044595
epoch: 1832, train precision: 0.998822, train loss: 10.557514, valid precision: 0.876000, valid loss: 88.322617
epoch: 1833, train precision: 0.998667, train loss: 10.635291, valid precision: 0.874000, valid loss: 89.266850
epoch: 1834, train precision: 0.999000, train loss: 10.560110, valid precision: 0.878600, valid loss: 85.947490
epoch: 1835, train precision: 0.998889, train loss: 10.517681, valid precision: 0.877000, valid loss: 87.454379
epoch: 1836, train precision: 0.999000, train loss: 10.513278, valid precision: 0.880000, valid loss: 88.189783
epoch: 1837, train precision: 0.998800, train loss: 10.520863, valid precision: 0.882000, valid loss: 90.362186
epoch: 1838, train precision: 0.998444, train loss: 10.616811, valid precision: 0.876200, valid loss: 89.204766
epoch: 1839, train precision: 0.998756, train loss: 10.615712, valid precision: 0.876200, valid loss: 89.874397
epoch: 1840, train precision: 0.999067, train loss: 10.490777, valid precision: 0.876600, valid loss: 90.128393
epoch: 1841, train precision: 0.998933, train loss: 10.571035, valid precision: 0.876800, valid loss: 89.187818
epoch: 1842, train precision: 0.998911, train loss: 10.533249, valid precision: 0.878800, valid loss: 87.191346
epoch: 1843, train precision: 0.999044, train loss: 10.470742, valid precision: 0.877000, valid loss: 88.614430
epoch: 1844, train precision: 0.999178, train loss: 10.460318, valid precision: 0.880600, valid loss: 85.310380
epoch: 1845, train precision: 0.998800, train loss: 10.533888, valid precision: 0.879400, valid loss: 87.823656
epoch: 1846, train precision: 0.998844, train loss: 10.592281, valid precision: 0.883200, valid loss: 89.492170
epoch: 1847, train precision: 0.998778, train loss: 10.570957, valid precision: 0.881400, valid loss: 87.341284
epoch: 1848, train precision: 0.999067, train loss: 10.509782, valid precision: 0.879400, valid loss: 85.729008
epoch: 1849, train precision: 0.998933, train loss: 10.521829, valid precision: 0.879000, valid loss: 86.586519
epoch: 1850, train precision: 0.998844, train loss: 10.594282, valid precision: 0.877800, valid loss: 89.921233
epoch: 1851, train precision: 0.999067, train loss: 10.503943, valid precision: 0.878600, valid loss: 88.063057
epoch: 1852, train precision: 0.998600, train loss: 10.674971, valid precision: 0.876000, valid loss: 90.170011
epoch: 1853, train precision: 0.999089, train loss: 10.487077, valid precision: 0.874600, valid loss: 88.063498
epoch: 1854, train precision: 0.998778, train loss: 10.583225, valid precision: 0.879000, valid loss: 89.231392
epoch: 1855, train precision: 0.999022, train loss: 10.507176, valid precision: 0.879200, valid loss: 89.802734
epoch: 1856, train precision: 0.998889, train loss: 10.580851, valid precision: 0.877600, valid loss: 88.240579
epoch: 1857, train precision: 0.999111, train loss: 10.512411, valid precision: 0.878200, valid loss: 86.635112
epoch: 1858, train precision: 0.998889, train loss: 10.582374, valid precision: 0.877200, valid loss: 88.674613
epoch: 1859, train precision: 0.998978, train loss: 10.517874, valid precision: 0.879800, valid loss: 88.226926
epoch: 1860, train precision: 0.999067, train loss: 10.494641, valid precision: 0.878600, valid loss: 86.783454
epoch: 1861, train precision: 0.999267, train loss: 10.404699, valid precision: 0.879000, valid loss: 86.838382
epoch: 1862, train precision: 0.998422, train loss: 10.665794, valid precision: 0.877800, valid loss: 88.059632
epoch: 1863, train precision: 0.999067, train loss: 10.503962, valid precision: 0.875400, valid loss: 90.252794
epoch: 1864, train precision: 0.999022, train loss: 10.486975, valid precision: 0.876600, valid loss: 87.449556
epoch: 1865, train precision: 0.999067, train loss: 10.512257, valid precision: 0.878600, valid loss: 89.464370
epoch: 1866, train precision: 0.998533, train loss: 10.731042, valid precision: 0.872400, valid loss: 92.484312
epoch: 1867, train precision: 0.999000, train loss: 10.543897, valid precision: 0.874000, valid loss: 92.246156
epoch: 1868, train precision: 0.999289, train loss: 10.504432, valid precision: 0.881200, valid loss: 88.880834
epoch: 1869, train precision: 0.998556, train loss: 10.662946, valid precision: 0.878000, valid loss: 89.264343
epoch: 1870, train precision: 0.998911, train loss: 10.547395, valid precision: 0.880200, valid loss: 88.863347
epoch: 1871, train precision: 0.999022, train loss: 10.548912, valid precision: 0.880000, valid loss: 88.285239
epoch: 1872, train precision: 0.998733, train loss: 10.618864, valid precision: 0.876000, valid loss: 89.948120
epoch: 1873, train precision: 0.999111, train loss: 10.505353, valid precision: 0.876800, valid loss: 89.974527
epoch: 1874, train precision: 0.999044, train loss: 10.602695, valid precision: 0.880400, valid loss: 87.349822
epoch: 1875, train precision: 0.998911, train loss: 10.526194, valid precision: 0.877000, valid loss: 90.076556
epoch: 1876, train precision: 0.999089, train loss: 10.473315, valid precision: 0.881000, valid loss: 90.594666
epoch: 1877, train precision: 0.999267, train loss: 10.469803, valid precision: 0.881600, valid loss: 88.438795
epoch: 1878, train precision: 0.998711, train loss: 10.563432, valid precision: 0.882400, valid loss: 90.686440
epoch: 1879, train precision: 0.998911, train loss: 10.539864, valid precision: 0.877800, valid loss: 90.114362
epoch: 1880, train precision: 0.998956, train loss: 10.502158, valid precision: 0.877400, valid loss: 91.928983
epoch: 1881, train precision: 0.998800, train loss: 10.559353, valid precision: 0.881000, valid loss: 92.199872
epoch: 1882, train precision: 0.999067, train loss: 10.570354, valid precision: 0.876800, valid loss: 90.588704
epoch: 1883, train precision: 0.998933, train loss: 10.505394, valid precision: 0.879200, valid loss: 88.763217
epoch: 1884, train precision: 0.999156, train loss: 10.513456, valid precision: 0.878200, valid loss: 88.048552
epoch: 1885, train precision: 0.998956, train loss: 10.545466, valid precision: 0.880200, valid loss: 89.420268
epoch: 1886, train precision: 0.998689, train loss: 10.643910, valid precision: 0.878600, valid loss: 91.477705
epoch: 1887, train precision: 0.999000, train loss: 10.488853, valid precision: 0.877800, valid loss: 91.913194
epoch: 1888, train precision: 0.999022, train loss: 10.510203, valid precision: 0.876400, valid loss: 90.327568
epoch: 1889, train precision: 0.998889, train loss: 10.544182, valid precision: 0.875200, valid loss: 89.961732
epoch: 1890, train precision: 0.999244, train loss: 10.478783, valid precision: 0.876800, valid loss: 88.296737
epoch: 1891, train precision: 0.999067, train loss: 10.487059, valid precision: 0.882400, valid loss: 88.739969
epoch: 1892, train precision: 0.999000, train loss: 10.553759, valid precision: 0.877400, valid loss: 89.402541
epoch: 1893, train precision: 0.998889, train loss: 10.529542, valid precision: 0.880800, valid loss: 87.208382
epoch: 1894, train precision: 0.998822, train loss: 10.573208, valid precision: 0.875200, valid loss: 88.136256
epoch: 1895, train precision: 0.999222, train loss: 10.428363, valid precision: 0.875600, valid loss: 88.425977
epoch: 1896, train precision: 0.999044, train loss: 10.521644, valid precision: 0.876400, valid loss: 87.817432
epoch: 1897, train precision: 0.999200, train loss: 10.486723, valid precision: 0.875600, valid loss: 88.963209
epoch: 1898, train precision: 0.999111, train loss: 10.510686, valid precision: 0.873600, valid loss: 88.074658
epoch: 1899, train precision: 0.998911, train loss: 10.533324, valid precision: 0.875600, valid loss: 90.382508
epoch: 1900, train precision: 0.998889, train loss: 10.571224, valid precision: 0.878200, valid loss: 89.676876
epoch: 1901, train precision: 0.999000, train loss: 10.523775, valid precision: 0.876400, valid loss: 89.699725
epoch: 1902, train precision: 0.999044, train loss: 10.488695, valid precision: 0.878400, valid loss: 89.180094
epoch: 1903, train precision: 0.998911, train loss: 10.468581, valid precision: 0.876400, valid loss: 91.582349
epoch: 1904, train precision: 0.998800, train loss: 10.573034, valid precision: 0.875200, valid loss: 89.805531
epoch: 1905, train precision: 0.998689, train loss: 10.582042, valid precision: 0.875200, valid loss: 89.517829
epoch: 1906, train precision: 0.998578, train loss: 10.649606, valid precision: 0.871800, valid loss: 88.274094
epoch: 1907, train precision: 0.999022, train loss: 10.487905, valid precision: 0.878200, valid loss: 88.099648
epoch: 1908, train precision: 0.998822, train loss: 10.551231, valid precision: 0.875200, valid loss: 89.193994
epoch: 1909, train precision: 0.999000, train loss: 10.520972, valid precision: 0.878400, valid loss: 88.000292
epoch: 1910, train precision: 0.999133, train loss: 10.476623, valid precision: 0.875600, valid loss: 85.783595
epoch: 1911, train precision: 0.999089, train loss: 10.524675, valid precision: 0.878400, valid loss: 85.313181
epoch: 1912, train precision: 0.999000, train loss: 10.539723, valid precision: 0.877400, valid loss: 89.276191
epoch: 1913, train precision: 0.998600, train loss: 10.658093, valid precision: 0.875200, valid loss: 89.322730
epoch: 1914, train precision: 0.999156, train loss: 10.463596, valid precision: 0.879000, valid loss: 87.733635
epoch: 1915, train precision: 0.999022, train loss: 10.526281, valid precision: 0.879800, valid loss: 86.108958
epoch: 1916, train precision: 0.999022, train loss: 10.486065, valid precision: 0.877000, valid loss: 87.222536
epoch: 1917, train precision: 0.998800, train loss: 10.562927, valid precision: 0.876800, valid loss: 88.117101
epoch: 1918, train precision: 0.999089, train loss: 10.441902, valid precision: 0.878400, valid loss: 85.814923
epoch: 1919, train precision: 0.998844, train loss: 10.578513, valid precision: 0.876400, valid loss: 87.198313
epoch: 1920, train precision: 0.998978, train loss: 10.473864, valid precision: 0.878400, valid loss: 85.585949
epoch: 1921, train precision: 0.998822, train loss: 10.557094, valid precision: 0.875400, valid loss: 85.561463
epoch: 1922, train precision: 0.999133, train loss: 10.511812, valid precision: 0.878400, valid loss: 90.097537
epoch: 1923, train precision: 0.999111, train loss: 10.483823, valid precision: 0.877200, valid loss: 89.697325
epoch: 1924, train precision: 0.998644, train loss: 10.617365, valid precision: 0.875000, valid loss: 87.835802
epoch: 1925, train precision: 0.999111, train loss: 10.473334, valid precision: 0.875400, valid loss: 87.418667
epoch: 1926, train precision: 0.999467, train loss: 10.433538, valid precision: 0.874200, valid loss: 87.463595
epoch: 1927, train precision: 0.999178, train loss: 10.449125, valid precision: 0.878400, valid loss: 88.357986
epoch: 1928, train precision: 0.998622, train loss: 10.667139, valid precision: 0.878400, valid loss: 91.071604
epoch: 1929, train precision: 0.999089, train loss: 10.428128, valid precision: 0.877800, valid loss: 87.124089
epoch: 1930, train precision: 0.998889, train loss: 10.541324, valid precision: 0.877400, valid loss: 87.771352
epoch: 1931, train precision: 0.998978, train loss: 10.476606, valid precision: 0.877400, valid loss: 87.349920
epoch: 1932, train precision: 0.998378, train loss: 10.636935, valid precision: 0.877200, valid loss: 86.373947
epoch: 1933, train precision: 0.999044, train loss: 10.469550, valid precision: 0.876000, valid loss: 88.139858
epoch: 1934, train precision: 0.999022, train loss: 10.604987, valid precision: 0.875200, valid loss: 90.011163
epoch: 1935, train precision: 0.998556, train loss: 10.715396, valid precision: 0.877400, valid loss: 88.313914
epoch: 1936, train precision: 0.998800, train loss: 10.587667, valid precision: 0.874000, valid loss: 87.791749
epoch: 1937, train precision: 0.998689, train loss: 10.621133, valid precision: 0.878000, valid loss: 87.385740
epoch: 1938, train precision: 0.999067, train loss: 10.431611, valid precision: 0.881200, valid loss: 86.384222
epoch: 1939, train precision: 0.998933, train loss: 10.484337, valid precision: 0.880600, valid loss: 86.933492
epoch: 1940, train precision: 0.998733, train loss: 10.658084, valid precision: 0.875200, valid loss: 88.265863
epoch: 1941, train precision: 0.998511, train loss: 10.696412, valid precision: 0.875800, valid loss: 88.049211
epoch: 1942, train precision: 0.999022, train loss: 10.473991, valid precision: 0.880600, valid loss: 87.382794
epoch: 1943, train precision: 0.999067, train loss: 10.511539, valid precision: 0.878000, valid loss: 87.654127
epoch: 1944, train precision: 0.999089, train loss: 10.467523, valid precision: 0.876400, valid loss: 90.289156
epoch: 1945, train precision: 0.998733, train loss: 10.568210, valid precision: 0.877000, valid loss: 89.273733
epoch: 1946, train precision: 0.999156, train loss: 10.452594, valid precision: 0.873200, valid loss: 88.053258
epoch: 1947, train precision: 0.999289, train loss: 10.422964, valid precision: 0.879200, valid loss: 88.366997
epoch: 1948, train precision: 0.998978, train loss: 10.519188, valid precision: 0.876000, valid loss: 90.714712
epoch: 1949, train precision: 0.999022, train loss: 10.455669, valid precision: 0.878600, valid loss: 86.975268
epoch: 1950, train precision: 0.998978, train loss: 10.501392, valid precision: 0.875600, valid loss: 89.451019
epoch: 1951, train precision: 0.999000, train loss: 10.533952, valid precision: 0.876600, valid loss: 90.078790
epoch: 1952, train precision: 0.999200, train loss: 10.423951, valid precision: 0.875800, valid loss: 90.261311
epoch: 1953, train precision: 0.998911, train loss: 10.496054, valid precision: 0.873400, valid loss: 90.037444
epoch: 1954, train precision: 0.999044, train loss: 10.511198, valid precision: 0.876800, valid loss: 87.913445
epoch: 1955, train precision: 0.998956, train loss: 10.451402, valid precision: 0.877600, valid loss: 86.398564
epoch: 1956, train precision: 0.999067, train loss: 10.463996, valid precision: 0.878000, valid loss: 89.117605
epoch: 1957, train precision: 0.998889, train loss: 10.517971, valid precision: 0.877800, valid loss: 89.120810
epoch: 1958, train precision: 0.998844, train loss: 10.514578, valid precision: 0.876800, valid loss: 89.759795
epoch: 1959, train precision: 0.998711, train loss: 10.520410, valid precision: 0.877200, valid loss: 90.003022
epoch: 1960, train precision: 0.998644, train loss: 10.597478, valid precision: 0.871000, valid loss: 93.293600
epoch: 1961, train precision: 0.999000, train loss: 10.503171, valid precision: 0.874200, valid loss: 89.507067
epoch: 1962, train precision: 0.998622, train loss: 10.592514, valid precision: 0.872400, valid loss: 90.635452
epoch: 1963, train precision: 0.999111, train loss: 10.465423, valid precision: 0.879400, valid loss: 87.497120
epoch: 1964, train precision: 0.999000, train loss: 10.411046, valid precision: 0.875600, valid loss: 88.238109
epoch: 1965, train precision: 0.998622, train loss: 10.532599, valid precision: 0.874200, valid loss: 91.781675
epoch: 1966, train precision: 0.999022, train loss: 10.566516, valid precision: 0.877600, valid loss: 89.392332
epoch: 1967, train precision: 0.998711, train loss: 10.563528, valid precision: 0.878400, valid loss: 88.669884
epoch: 1968, train precision: 0.998956, train loss: 10.549288, valid precision: 0.877400, valid loss: 89.510806
epoch: 1969, train precision: 0.999000, train loss: 10.502060, valid precision: 0.871800, valid loss: 88.786839
epoch: 1970, train precision: 0.998933, train loss: 10.539018, valid precision: 0.876400, valid loss: 89.677143
epoch: 1971, train precision: 0.999044, train loss: 10.461743, valid precision: 0.877200, valid loss: 87.866766
epoch: 1972, train precision: 0.998867, train loss: 10.520357, valid precision: 0.881200, valid loss: 88.230003
epoch: 1973, train precision: 0.998689, train loss: 10.559960, valid precision: 0.879200, valid loss: 87.960312
epoch: 1974, train precision: 0.999000, train loss: 10.474358, valid precision: 0.878400, valid loss: 88.420484
epoch: 1975, train precision: 0.998733, train loss: 10.596386, valid precision: 0.874200, valid loss: 89.356880
epoch: 1976, train precision: 0.999333, train loss: 10.396801, valid precision: 0.878800, valid loss: 87.395983
epoch: 1977, train precision: 0.999067, train loss: 10.506738, valid precision: 0.875800, valid loss: 86.706397
epoch: 1978, train precision: 0.999133, train loss: 10.425955, valid precision: 0.876200, valid loss: 88.505191
epoch: 1979, train precision: 0.999178, train loss: 10.425686, valid precision: 0.879200, valid loss: 87.364777
epoch: 1980, train precision: 0.999244, train loss: 10.442031, valid precision: 0.876400, valid loss: 87.852329
epoch: 1981, train precision: 0.998956, train loss: 10.511136, valid precision: 0.875600, valid loss: 88.219510
epoch: 1982, train precision: 0.999067, train loss: 10.495533, valid precision: 0.879200, valid loss: 87.001088
epoch: 1983, train precision: 0.998889, train loss: 10.501307, valid precision: 0.877000, valid loss: 87.447526
epoch: 1984, train precision: 0.999111, train loss: 10.480578, valid precision: 0.872200, valid loss: 90.929384
epoch: 1985, train precision: 0.998800, train loss: 10.552269, valid precision: 0.873800, valid loss: 90.621521
epoch: 1986, train precision: 0.999400, train loss: 10.358379, valid precision: 0.879000, valid loss: 90.986471
epoch: 1987, train precision: 0.999089, train loss: 10.492769, valid precision: 0.879600, valid loss: 90.074442
epoch: 1988, train precision: 0.998733, train loss: 10.531738, valid precision: 0.874600, valid loss: 89.860899
epoch: 1989, train precision: 0.999044, train loss: 10.404757, valid precision: 0.879400, valid loss: 88.454185
epoch: 1990, train precision: 0.999044, train loss: 10.474528, valid precision: 0.877000, valid loss: 89.609573
epoch: 1991, train precision: 0.998800, train loss: 10.553864, valid precision: 0.872600, valid loss: 92.242315
epoch: 1992, train precision: 0.999289, train loss: 10.401671, valid precision: 0.872800, valid loss: 88.918354
epoch: 1993, train precision: 0.998889, train loss: 10.509880, valid precision: 0.878000, valid loss: 88.865142
epoch: 1994, train precision: 0.999356, train loss: 10.391576, valid precision: 0.877400, valid loss: 86.131968
epoch: 1995, train precision: 0.998889, train loss: 10.470891, valid precision: 0.876400, valid loss: 88.557499
epoch: 1996, train precision: 0.999267, train loss: 10.405651, valid precision: 0.877000, valid loss: 88.467322
epoch: 1997, train precision: 0.998644, train loss: 10.671437, valid precision: 0.875400, valid loss: 88.756814
epoch: 1998, train precision: 0.999222, train loss: 10.425719, valid precision: 0.879200, valid loss: 87.018867
epoch: 1999, train precision: 0.998844, train loss: 10.571248, valid precision: 0.878600, valid loss: 87.500293
epoch: 2000, train precision: 0.998778, train loss: 10.552527, valid precision: 0.872800, valid loss: 89.366719
epoch: 2001, train precision: 0.998978, train loss: 10.477848, valid precision: 0.875400, valid loss: 88.139234
epoch: 2002, train precision: 0.999333, train loss: 10.424804, valid precision: 0.877400, valid loss: 88.534865
epoch: 2003, train precision: 0.998844, train loss: 10.524928, valid precision: 0.876400, valid loss: 86.831385
epoch: 2004, train precision: 0.999222, train loss: 10.454611, valid precision: 0.881600, valid loss: 86.551848
epoch: 2005, train precision: 0.998644, train loss: 10.548984, valid precision: 0.880600, valid loss: 85.465306
epoch: 2006, train precision: 0.999067, train loss: 10.456695, valid precision: 0.879600, valid loss: 87.144680
epoch: 2007, train precision: 0.999000, train loss: 10.508536, valid precision: 0.879000, valid loss: 87.661007
epoch: 2008, train precision: 0.998822, train loss: 10.530181, valid precision: 0.878600, valid loss: 87.007613
epoch: 2009, train precision: 0.998933, train loss: 10.523669, valid precision: 0.878600, valid loss: 86.989436
epoch: 2010, train precision: 0.999178, train loss: 10.408775, valid precision: 0.878800, valid loss: 87.228380
epoch: 2011, train precision: 0.998978, train loss: 10.460979, valid precision: 0.881800, valid loss: 88.835153
epoch: 2012, train precision: 0.999022, train loss: 10.477716, valid precision: 0.879400, valid loss: 88.880185
epoch: 2013, train precision: 0.999089, train loss: 10.457263, valid precision: 0.877200, valid loss: 88.024944
epoch: 2014, train precision: 0.999222, train loss: 10.357201, valid precision: 0.877200, valid loss: 89.142075
epoch: 2015, train precision: 0.999111, train loss: 10.391008, valid precision: 0.877000, valid loss: 89.106245
epoch: 2016, train precision: 0.998733, train loss: 10.524354, valid precision: 0.880400, valid loss: 90.040041
epoch: 2017, train precision: 0.999200, train loss: 10.375167, valid precision: 0.881400, valid loss: 88.796773
epoch: 2018, train precision: 0.999000, train loss: 10.483902, valid precision: 0.878200, valid loss: 91.058098
epoch: 2019, train precision: 0.998400, train loss: 10.681624, valid precision: 0.877200, valid loss: 88.635268
epoch: 2020, train precision: 0.999000, train loss: 10.547992, valid precision: 0.878600, valid loss: 88.417845
epoch: 2021, train precision: 0.998956, train loss: 10.532024, valid precision: 0.876400, valid loss: 87.964649
epoch: 2022, train precision: 0.999111, train loss: 10.519954, valid precision: 0.880000, valid loss: 87.030348
epoch: 2023, train precision: 0.998933, train loss: 10.509804, valid precision: 0.879800, valid loss: 88.072779
epoch: 2024, train precision: 0.999022, train loss: 10.485844, valid precision: 0.877200, valid loss: 87.552619
epoch: 2025, train precision: 0.999244, train loss: 10.406054, valid precision: 0.880000, valid loss: 87.405171
epoch: 2026, train precision: 0.998867, train loss: 10.475964, valid precision: 0.883000, valid loss: 86.440435
epoch: 2027, train precision: 0.999244, train loss: 10.403055, valid precision: 0.879600, valid loss: 86.782885
epoch: 2028, train precision: 0.999000, train loss: 10.467656, valid precision: 0.878400, valid loss: 87.351962
epoch: 2029, train precision: 0.998711, train loss: 10.561573, valid precision: 0.881000, valid loss: 86.357592
epoch: 2030, train precision: 0.999067, train loss: 10.459509, valid precision: 0.881200, valid loss: 87.118917
epoch: 2031, train precision: 0.999156, train loss: 10.475757, valid precision: 0.877200, valid loss: 89.609482
epoch: 2032, train precision: 0.998889, train loss: 10.508929, valid precision: 0.877200, valid loss: 89.736813
epoch: 2033, train precision: 0.998711, train loss: 10.600292, valid precision: 0.878200, valid loss: 92.275578
epoch: 2034, train precision: 0.999222, train loss: 10.451114, valid precision: 0.873600, valid loss: 93.161446
epoch: 2035, train precision: 0.999111, train loss: 10.469666, valid precision: 0.877800, valid loss: 90.461255
epoch: 2036, train precision: 0.999089, train loss: 10.437570, valid precision: 0.878200, valid loss: 90.247867
epoch: 2037, train precision: 0.998978, train loss: 10.516615, valid precision: 0.877000, valid loss: 91.127514
epoch: 2038, train precision: 0.998956, train loss: 10.514597, valid precision: 0.875200, valid loss: 93.176782
epoch: 2039, train precision: 0.998667, train loss: 10.595262, valid precision: 0.876800, valid loss: 94.995769
epoch: 2040, train precision: 0.998489, train loss: 10.659339, valid precision: 0.877400, valid loss: 93.626760
epoch: 2041, train precision: 0.998867, train loss: 10.538729, valid precision: 0.880000, valid loss: 88.931405
epoch: 2042, train precision: 0.998867, train loss: 10.478559, valid precision: 0.881400, valid loss: 89.538365
epoch: 2043, train precision: 0.999133, train loss: 10.437747, valid precision: 0.878400, valid loss: 88.530703
epoch: 2044, train precision: 0.999044, train loss: 10.464181, valid precision: 0.879400, valid loss: 89.340153
epoch: 2045, train precision: 0.999133, train loss: 10.456964, valid precision: 0.876400, valid loss: 93.022405
epoch: 2046, train precision: 0.998578, train loss: 10.587849, valid precision: 0.877000, valid loss: 92.313489
epoch: 2047, train precision: 0.999222, train loss: 10.376461, valid precision: 0.878600, valid loss: 91.651071
epoch: 2048, train precision: 0.999111, train loss: 10.466101, valid precision: 0.878400, valid loss: 88.700491
epoch: 2049, train precision: 0.999044, train loss: 10.485591, valid precision: 0.878800, valid loss: 87.953153
epoch: 2050, train precision: 0.998867, train loss: 10.536699, valid precision: 0.881400, valid loss: 88.560662
epoch: 2051, train precision: 0.998378, train loss: 10.676341, valid precision: 0.875000, valid loss: 90.543433
epoch: 2052, train precision: 0.999000, train loss: 10.471234, valid precision: 0.882200, valid loss: 88.111773
epoch: 2053, train precision: 0.998978, train loss: 10.526706, valid precision: 0.877000, valid loss: 89.090562
epoch: 2054, train precision: 0.999156, train loss: 10.410000, valid precision: 0.878000, valid loss: 88.581746
epoch: 2055, train precision: 0.999289, train loss: 10.359988, valid precision: 0.876200, valid loss: 91.420584
epoch: 2056, train precision: 0.998956, train loss: 10.476714, valid precision: 0.876800, valid loss: 91.618643
epoch: 2057, train precision: 0.998822, train loss: 10.533810, valid precision: 0.875800, valid loss: 89.635905
epoch: 2058, train precision: 0.999111, train loss: 10.476405, valid precision: 0.873200, valid loss: 90.116534
epoch: 2059, train precision: 0.999133, train loss: 10.491548, valid precision: 0.877800, valid loss: 88.808423
epoch: 2060, train precision: 0.999222, train loss: 10.441678, valid precision: 0.880000, valid loss: 88.419503
epoch: 2061, train precision: 0.999267, train loss: 10.438537, valid precision: 0.881400, valid loss: 87.306117
epoch: 2062, train precision: 0.999178, train loss: 10.388773, valid precision: 0.881000, valid loss: 85.880832
epoch: 2063, train precision: 0.999178, train loss: 10.414863, valid precision: 0.882200, valid loss: 88.450200
epoch: 2064, train precision: 0.999000, train loss: 10.467344, valid precision: 0.880400, valid loss: 86.842654
epoch: 2065, train precision: 0.998800, train loss: 10.580293, valid precision: 0.877800, valid loss: 88.980468
epoch: 2066, train precision: 0.998956, train loss: 10.451046, valid precision: 0.878800, valid loss: 87.759298
epoch: 2067, train precision: 0.999111, train loss: 10.432699, valid precision: 0.876200, valid loss: 86.602330
epoch: 2068, train precision: 0.999000, train loss: 10.509983, valid precision: 0.874800, valid loss: 87.758364
epoch: 2069, train precision: 0.998444, train loss: 10.639266, valid precision: 0.876600, valid loss: 87.894894
epoch: 2070, train precision: 0.999000, train loss: 10.460932, valid precision: 0.880400, valid loss: 85.676658
epoch: 2071, train precision: 0.998978, train loss: 10.490657, valid precision: 0.878000, valid loss: 86.944429
epoch: 2072, train precision: 0.998756, train loss: 10.623771, valid precision: 0.877000, valid loss: 88.583440
epoch: 2073, train precision: 0.999022, train loss: 10.455021, valid precision: 0.876200, valid loss: 88.332821
epoch: 2074, train precision: 0.998933, train loss: 10.498161, valid precision: 0.874400, valid loss: 88.410291
epoch: 2075, train precision: 0.998756, train loss: 10.553860, valid precision: 0.875000, valid loss: 88.945707
epoch: 2076, train precision: 0.999111, train loss: 10.474220, valid precision: 0.880600, valid loss: 87.497392
epoch: 2077, train precision: 0.999133, train loss: 10.442036, valid precision: 0.878000, valid loss: 88.460604
epoch: 2078, train precision: 0.999089, train loss: 10.473651, valid precision: 0.878600, valid loss: 85.435695
epoch: 2079, train precision: 0.998956, train loss: 10.540512, valid precision: 0.877000, valid loss: 88.918829
epoch: 2080, train precision: 0.999356, train loss: 10.326038, valid precision: 0.877800, valid loss: 85.582603
epoch: 2081, train precision: 0.998667, train loss: 10.580394, valid precision: 0.878600, valid loss: 88.794146
epoch: 2082, train precision: 0.999156, train loss: 10.436896, valid precision: 0.883600, valid loss: 86.562520
epoch: 2083, train precision: 0.998889, train loss: 10.489232, valid precision: 0.879600, valid loss: 86.991929
epoch: 2084, train precision: 0.998756, train loss: 10.497970, valid precision: 0.877600, valid loss: 85.491923
epoch: 2085, train precision: 0.999089, train loss: 10.450821, valid precision: 0.876000, valid loss: 88.866656
epoch: 2086, train precision: 0.999022, train loss: 10.513257, valid precision: 0.876600, valid loss: 85.598114
epoch: 2087, train precision: 0.998911, train loss: 10.510902, valid precision: 0.876800, valid loss: 88.546460
epoch: 2088, train precision: 0.999156, train loss: 10.450439, valid precision: 0.876600, valid loss: 88.482416
epoch: 2089, train precision: 0.998844, train loss: 10.552508, valid precision: 0.874400, valid loss: 87.457177
epoch: 2090, train precision: 0.999022, train loss: 10.464964, valid precision: 0.877400, valid loss: 86.906755
epoch: 2091, train precision: 0.998778, train loss: 10.555484, valid precision: 0.874000, valid loss: 87.913865
epoch: 2092, train precision: 0.999067, train loss: 10.452915, valid precision: 0.875600, valid loss: 86.963584
epoch: 2093, train precision: 0.998956, train loss: 10.436064, valid precision: 0.875400, valid loss: 87.459513
epoch: 2094, train precision: 0.998978, train loss: 10.448778, valid precision: 0.876000, valid loss: 87.211164
epoch: 2095, train precision: 0.998978, train loss: 10.472236, valid precision: 0.876000, valid loss: 87.157334
epoch: 2096, train precision: 0.999111, train loss: 10.453170, valid precision: 0.879200, valid loss: 86.266852
epoch: 2097, train precision: 0.999356, train loss: 10.402571, valid precision: 0.878800, valid loss: 84.313963
epoch: 2098, train precision: 0.998800, train loss: 10.509933, valid precision: 0.877400, valid loss: 88.734202
epoch: 2099, train precision: 0.998800, train loss: 10.546470, valid precision: 0.876200, valid loss: 88.306492
epoch: 2100, train precision: 0.998889, train loss: 10.545099, valid precision: 0.879600, valid loss: 90.010821
epoch: 2101, train precision: 0.998756, train loss: 10.508694, valid precision: 0.878600, valid loss: 90.938625
epoch: 2102, train precision: 0.998556, train loss: 10.582319, valid precision: 0.875600, valid loss: 89.908972
epoch: 2103, train precision: 0.999000, train loss: 10.486577, valid precision: 0.875400, valid loss: 90.783402
epoch: 2104, train precision: 0.998911, train loss: 10.519591, valid precision: 0.872600, valid loss: 90.862240
epoch: 2105, train precision: 0.999067, train loss: 10.435563, valid precision: 0.875800, valid loss: 87.772749
epoch: 2106, train precision: 0.999156, train loss: 10.456502, valid precision: 0.873800, valid loss: 89.757522
epoch: 2107, train precision: 0.999111, train loss: 10.540976, valid precision: 0.877000, valid loss: 89.956594
epoch: 2108, train precision: 0.999356, train loss: 10.354510, valid precision: 0.876800, valid loss: 89.142552
epoch: 2109, train precision: 0.999000, train loss: 10.453968, valid precision: 0.878000, valid loss: 87.791954
epoch: 2110, train precision: 0.999000, train loss: 10.518196, valid precision: 0.876000, valid loss: 88.358338
epoch: 2111, train precision: 0.999044, train loss: 10.443229, valid precision: 0.879000, valid loss: 87.924883
epoch: 2112, train precision: 0.999000, train loss: 10.424421, valid precision: 0.873800, valid loss: 89.605335
epoch: 2113, train precision: 0.998511, train loss: 10.701297, valid precision: 0.880000, valid loss: 85.227831
epoch: 2114, train precision: 0.999133, train loss: 10.466361, valid precision: 0.875800, valid loss: 88.556457
epoch: 2115, train precision: 0.998622, train loss: 10.584536, valid precision: 0.877600, valid loss: 87.156823
epoch: 2116, train precision: 0.998822, train loss: 10.491911, valid precision: 0.878400, valid loss: 85.538858
epoch: 2117, train precision: 0.999156, train loss: 10.433489, valid precision: 0.882600, valid loss: 84.401772
epoch: 2118, train precision: 0.998978, train loss: 10.443691, valid precision: 0.880200, valid loss: 86.973519
epoch: 2119, train precision: 0.998867, train loss: 10.572692, valid precision: 0.877000, valid loss: 88.834125
epoch: 2120, train precision: 0.999111, train loss: 10.420329, valid precision: 0.879600, valid loss: 90.803019
epoch: 2121, train precision: 0.999044, train loss: 10.410590, valid precision: 0.877400, valid loss: 88.429700
epoch: 2122, train precision: 0.999333, train loss: 10.387146, valid precision: 0.877200, valid loss: 88.556397
epoch: 2123, train precision: 0.998733, train loss: 10.541675, valid precision: 0.874400, valid loss: 91.025563
epoch: 2124, train precision: 0.999178, train loss: 10.408118, valid precision: 0.877200, valid loss: 88.657961
epoch: 2125, train precision: 0.998756, train loss: 10.540936, valid precision: 0.877600, valid loss: 88.499632
epoch: 2126, train precision: 0.998444, train loss: 10.621523, valid precision: 0.879800, valid loss: 86.836688
epoch: 2127, train precision: 0.999044, train loss: 10.486880, valid precision: 0.876200, valid loss: 86.935639
epoch: 2128, train precision: 0.998733, train loss: 10.522253, valid precision: 0.880200, valid loss: 88.253963
epoch: 2129, train precision: 0.999222, train loss: 10.410370, valid precision: 0.879400, valid loss: 87.195810
epoch: 2130, train precision: 0.999200, train loss: 10.418110, valid precision: 0.877200, valid loss: 86.212873
epoch: 2131, train precision: 0.998533, train loss: 10.551590, valid precision: 0.877600, valid loss: 88.865358
epoch: 2132, train precision: 0.999400, train loss: 10.332059, valid precision: 0.879600, valid loss: 86.994753
epoch: 2133, train precision: 0.998667, train loss: 10.609730, valid precision: 0.878200, valid loss: 88.435554
epoch: 2134, train precision: 0.998911, train loss: 10.512940, valid precision: 0.878800, valid loss: 88.982022
epoch: 2135, train precision: 0.998911, train loss: 10.498840, valid precision: 0.880800, valid loss: 87.664691
epoch: 2136, train precision: 0.999200, train loss: 10.442294, valid precision: 0.879600, valid loss: 87.417819
epoch: 2137, train precision: 0.998600, train loss: 10.537246, valid precision: 0.876000, valid loss: 87.741605
epoch: 2138, train precision: 0.998956, train loss: 10.477817, valid precision: 0.878600, valid loss: 86.236123
epoch: 2139, train precision: 0.999067, train loss: 10.456712, valid precision: 0.876600, valid loss: 88.490665
epoch: 2140, train precision: 0.998956, train loss: 10.483838, valid precision: 0.882400, valid loss: 87.421553
epoch: 2141, train precision: 0.998622, train loss: 10.538096, valid precision: 0.879400, valid loss: 86.860493
epoch: 2142, train precision: 0.998889, train loss: 10.487783, valid precision: 0.878000, valid loss: 87.129968
epoch: 2143, train precision: 0.998667, train loss: 10.561077, valid precision: 0.877200, valid loss: 87.178745
epoch: 2144, train precision: 0.999000, train loss: 10.454241, valid precision: 0.874000, valid loss: 86.433188
epoch: 2145, train precision: 0.998844, train loss: 10.530014, valid precision: 0.877400, valid loss: 86.208829
epoch: 2146, train precision: 0.999000, train loss: 10.479363, valid precision: 0.876200, valid loss: 86.852779
epoch: 2147, train precision: 0.998889, train loss: 10.546607, valid precision: 0.878400, valid loss: 89.432121
epoch: 2148, train precision: 0.998778, train loss: 10.500804, valid precision: 0.877600, valid loss: 87.871235
epoch: 2149, train precision: 0.998600, train loss: 10.582715, valid precision: 0.873000, valid loss: 88.508991
epoch: 2150, train precision: 0.998978, train loss: 10.416453, valid precision: 0.877600, valid loss: 89.761174
epoch: 2151, train precision: 0.998511, train loss: 10.619389, valid precision: 0.877600, valid loss: 90.479330
epoch: 2152, train precision: 0.998756, train loss: 10.515256, valid precision: 0.877200, valid loss: 89.125931
epoch: 2153, train precision: 0.999067, train loss: 10.468912, valid precision: 0.877000, valid loss: 89.137368
epoch: 2154, train precision: 0.999089, train loss: 10.437051, valid precision: 0.874400, valid loss: 87.293660
epoch: 2155, train precision: 0.999244, train loss: 10.470478, valid precision: 0.877400, valid loss: 89.507200
epoch: 2156, train precision: 0.999089, train loss: 10.397259, valid precision: 0.879000, valid loss: 89.759459
epoch: 2157, train precision: 0.998644, train loss: 10.573086, valid precision: 0.877200, valid loss: 89.435000
epoch: 2158, train precision: 0.999178, train loss: 10.389018, valid precision: 0.876000, valid loss: 90.078190
epoch: 2159, train precision: 0.998711, train loss: 10.547748, valid precision: 0.878200, valid loss: 88.617117
epoch: 2160, train precision: 0.999089, train loss: 10.431594, valid precision: 0.875800, valid loss: 90.463586
epoch: 2161, train precision: 0.998689, train loss: 10.536307, valid precision: 0.875000, valid loss: 91.897700
epoch: 2162, train precision: 0.999133, train loss: 10.468054, valid precision: 0.875400, valid loss: 89.689349
epoch: 2163, train precision: 0.998978, train loss: 10.394023, valid precision: 0.878400, valid loss: 88.303661
epoch: 2164, train precision: 0.999222, train loss: 10.380825, valid precision: 0.882800, valid loss: 86.533398
epoch: 2165, train precision: 0.998756, train loss: 10.454496, valid precision: 0.877400, valid loss: 90.296828
epoch: 2166, train precision: 0.999222, train loss: 10.380772, valid precision: 0.872800, valid loss: 89.918082
epoch: 2167, train precision: 0.999067, train loss: 10.463735, valid precision: 0.875200, valid loss: 89.266669
epoch: 2168, train precision: 0.999044, train loss: 10.412870, valid precision: 0.877400, valid loss: 91.763935
epoch: 2169, train precision: 0.999111, train loss: 10.395626, valid precision: 0.875800, valid loss: 90.774576
epoch: 2170, train precision: 0.999156, train loss: 10.403445, valid precision: 0.877000, valid loss: 90.613738
epoch: 2171, train precision: 0.998956, train loss: 10.502988, valid precision: 0.873800, valid loss: 93.122434
epoch: 2172, train precision: 0.998778, train loss: 10.560434, valid precision: 0.877800, valid loss: 90.875839
epoch: 2173, train precision: 0.998956, train loss: 10.428696, valid precision: 0.877400, valid loss: 88.855490
epoch: 2174, train precision: 0.999111, train loss: 10.449965, valid precision: 0.881200, valid loss: 88.788261
epoch: 2175, train precision: 0.998911, train loss: 10.491125, valid precision: 0.877000, valid loss: 87.397890
epoch: 2176, train precision: 0.999244, train loss: 10.414573, valid precision: 0.874600, valid loss: 89.627063
epoch: 2177, train precision: 0.999089, train loss: 10.461107, valid precision: 0.881400, valid loss: 87.819756
epoch: 2178, train precision: 0.998778, train loss: 10.505002, valid precision: 0.876000, valid loss: 88.982221
epoch: 2179, train precision: 0.999022, train loss: 10.503983, valid precision: 0.878800, valid loss: 87.192478
epoch: 2180, train precision: 0.998822, train loss: 10.475254, valid precision: 0.879000, valid loss: 89.653342
epoch: 2181, train precision: 0.999244, train loss: 10.369472, valid precision: 0.877800, valid loss: 89.009950
epoch: 2182, train precision: 0.998844, train loss: 10.460323, valid precision: 0.876800, valid loss: 89.704360
epoch: 2183, train precision: 0.998933, train loss: 10.481497, valid precision: 0.875200, valid loss: 90.544084
epoch: 2184, train precision: 0.998956, train loss: 10.445984, valid precision: 0.880800, valid loss: 88.880556
epoch: 2185, train precision: 0.999178, train loss: 10.414597, valid precision: 0.878800, valid loss: 87.021350
epoch: 2186, train precision: 0.998822, train loss: 10.440601, valid precision: 0.878200, valid loss: 88.292777
epoch: 2187, train precision: 0.999133, train loss: 10.383516, valid precision: 0.880000, valid loss: 86.781880
epoch: 2188, train precision: 0.998822, train loss: 10.476207, valid precision: 0.880200, valid loss: 86.492984
epoch: 2189, train precision: 0.998711, train loss: 10.508121, valid precision: 0.884400, valid loss: 87.832983
epoch: 2190, train precision: 0.998911, train loss: 10.492702, valid precision: 0.879000, valid loss: 87.389077
epoch: 2191, train precision: 0.998467, train loss: 10.540963, valid precision: 0.876800, valid loss: 89.947483
epoch: 2192, train precision: 0.999156, train loss: 10.389785, valid precision: 0.880600, valid loss: 85.460244
epoch: 2193, train precision: 0.998778, train loss: 10.506090, valid precision: 0.876600, valid loss: 89.370781
epoch: 2194, train precision: 0.999311, train loss: 10.361713, valid precision: 0.873200, valid loss: 89.802253
epoch: 2195, train precision: 0.999222, train loss: 10.358570, valid precision: 0.879600, valid loss: 87.753918
epoch: 2196, train precision: 0.999089, train loss: 10.464298, valid precision: 0.876200, valid loss: 87.652762
epoch: 2197, train precision: 0.998756, train loss: 10.549359, valid precision: 0.875200, valid loss: 88.826471
epoch: 2198, train precision: 0.998911, train loss: 10.440547, valid precision: 0.876800, valid loss: 89.104989
epoch: 2199, train precision: 0.999267, train loss: 10.413160, valid precision: 0.876400, valid loss: 86.506624
epoch: 2200, train precision: 0.999289, train loss: 10.309608, valid precision: 0.877600, valid loss: 87.817455
epoch: 2201, train precision: 0.999200, train loss: 10.388378, valid precision: 0.880000, valid loss: 88.209234
epoch: 2202, train precision: 0.999022, train loss: 10.421569, valid precision: 0.876600, valid loss: 86.495281
epoch: 2203, train precision: 0.999178, train loss: 10.385067, valid precision: 0.876000, valid loss: 88.122590
epoch: 2204, train precision: 0.999067, train loss: 10.422760, valid precision: 0.873800, valid loss: 90.083946
epoch: 2205, train precision: 0.998711, train loss: 10.538400, valid precision: 0.878400, valid loss: 89.338141
epoch: 2206, train precision: 0.998333, train loss: 10.626015, valid precision: 0.873400, valid loss: 91.175448
epoch: 2207, train precision: 0.999400, train loss: 10.360468, valid precision: 0.877400, valid loss: 85.770196
epoch: 2208, train precision: 0.998933, train loss: 10.427207, valid precision: 0.879200, valid loss: 85.843345
epoch: 2209, train precision: 0.998733, train loss: 10.572177, valid precision: 0.879400, valid loss: 87.393035
epoch: 2210, train precision: 0.998956, train loss: 10.427151, valid precision: 0.877600, valid loss: 88.630888
epoch: 2211, train precision: 0.999022, train loss: 10.395976, valid precision: 0.878000, valid loss: 87.121303
epoch: 2212, train precision: 0.999311, train loss: 10.338722, valid precision: 0.878400, valid loss: 89.429189
epoch: 2213, train precision: 0.999089, train loss: 10.415271, valid precision: 0.877000, valid loss: 89.521249
epoch: 2214, train precision: 0.998556, train loss: 10.549561, valid precision: 0.874600, valid loss: 89.275832
epoch: 2215, train precision: 0.998867, train loss: 10.429429, valid precision: 0.879800, valid loss: 90.134854
epoch: 2216, train precision: 0.999111, train loss: 10.380272, valid precision: 0.879800, valid loss: 89.000557
epoch: 2217, train precision: 0.999000, train loss: 10.469205, valid precision: 0.878000, valid loss: 89.471738
epoch: 2218, train precision: 0.999111, train loss: 10.373648, valid precision: 0.876000, valid loss: 87.816435
epoch: 2219, train precision: 0.999067, train loss: 10.380194, valid precision: 0.879200, valid loss: 87.868355
epoch: 2220, train precision: 0.999133, train loss: 10.434366, valid precision: 0.879400, valid loss: 88.399119
epoch: 2221, train precision: 0.998933, train loss: 10.455452, valid precision: 0.874400, valid loss: 90.827170
epoch: 2222, train precision: 0.998911, train loss: 10.443939, valid precision: 0.876800, valid loss: 87.212210
epoch: 2223, train precision: 0.998400, train loss: 10.595457, valid precision: 0.881000, valid loss: 87.813627
epoch: 2224, train precision: 0.999244, train loss: 10.373070, valid precision: 0.879800, valid loss: 86.245063
epoch: 2225, train precision: 0.999222, train loss: 10.368328, valid precision: 0.878800, valid loss: 86.233582
epoch: 2226, train precision: 0.999044, train loss: 10.389878, valid precision: 0.875800, valid loss: 87.806244
epoch: 2227, train precision: 0.998956, train loss: 10.505717, valid precision: 0.880000, valid loss: 88.824977
epoch: 2228, train precision: 0.999378, train loss: 10.286167, valid precision: 0.879400, valid loss: 87.911049
epoch: 2229, train precision: 0.998978, train loss: 10.413833, valid precision: 0.878800, valid loss: 88.007550
epoch: 2230, train precision: 0.998778, train loss: 10.521428, valid precision: 0.878800, valid loss: 90.018319
epoch: 2231, train precision: 0.999044, train loss: 10.442679, valid precision: 0.876400, valid loss: 87.430013
epoch: 2232, train precision: 0.999067, train loss: 10.403480, valid precision: 0.880200, valid loss: 88.068586
epoch: 2233, train precision: 0.998778, train loss: 10.471740, valid precision: 0.876200, valid loss: 90.627357
epoch: 2234, train precision: 0.999333, train loss: 10.317260, valid precision: 0.879600, valid loss: 88.982604
epoch: 2235, train precision: 0.999000, train loss: 10.456644, valid precision: 0.880800, valid loss: 90.139489
epoch: 2236, train precision: 0.998889, train loss: 10.509307, valid precision: 0.879200, valid loss: 88.419193
epoch: 2237, train precision: 0.999178, train loss: 10.420595, valid precision: 0.880600, valid loss: 87.118711
epoch: 2238, train precision: 0.998622, train loss: 10.564465, valid precision: 0.876000, valid loss: 89.747235
epoch: 2239, train precision: 0.999000, train loss: 10.543348, valid precision: 0.874400, valid loss: 88.818794
epoch: 2240, train precision: 0.998733, train loss: 10.505808, valid precision: 0.877000, valid loss: 91.706028
epoch: 2241, train precision: 0.998911, train loss: 10.503741, valid precision: 0.875200, valid loss: 88.306296
epoch: 2242, train precision: 0.999244, train loss: 10.327909, valid precision: 0.878600, valid loss: 88.518995
epoch: 2243, train precision: 0.998778, train loss: 10.482483, valid precision: 0.879000, valid loss: 88.910964
epoch: 2244, train precision: 0.998867, train loss: 10.451017, valid precision: 0.873200, valid loss: 90.143383
epoch: 2245, train precision: 0.998778, train loss: 10.459529, valid precision: 0.877200, valid loss: 87.778156
epoch: 2246, train precision: 0.998956, train loss: 10.439417, valid precision: 0.878200, valid loss: 90.659461
epoch: 2247, train precision: 0.999311, train loss: 10.370754, valid precision: 0.880600, valid loss: 87.787360
epoch: 2248, train precision: 0.998689, train loss: 10.488444, valid precision: 0.877200, valid loss: 90.626781
epoch: 2249, train precision: 0.998933, train loss: 10.476746, valid precision: 0.874000, valid loss: 92.118884
epoch: 2250, train precision: 0.999133, train loss: 10.351396, valid precision: 0.878800, valid loss: 91.616693
epoch: 2251, train precision: 0.998778, train loss: 10.451445, valid precision: 0.873800, valid loss: 92.039386
epoch: 2252, train precision: 0.999044, train loss: 10.369044, valid precision: 0.876000, valid loss: 91.286245
epoch: 2253, train precision: 0.998778, train loss: 10.467496, valid precision: 0.874800, valid loss: 93.406305
epoch: 2254, train precision: 0.999533, train loss: 10.277334, valid precision: 0.874600, valid loss: 89.469332
epoch: 2255, train precision: 0.998933, train loss: 10.465053, valid precision: 0.875200, valid loss: 90.975331
epoch: 2256, train precision: 0.999244, train loss: 10.388045, valid precision: 0.878400, valid loss: 89.320839
epoch: 2257, train precision: 0.999111, train loss: 10.397880, valid precision: 0.874200, valid loss: 90.926345
epoch: 2258, train precision: 0.998733, train loss: 10.501371, valid precision: 0.879800, valid loss: 88.627260
epoch: 2259, train precision: 0.998956, train loss: 10.429130, valid precision: 0.874600, valid loss: 90.807893
epoch: 2260, train precision: 0.999222, train loss: 10.373006, valid precision: 0.880000, valid loss: 90.837819
epoch: 2261, train precision: 0.999044, train loss: 10.431030, valid precision: 0.880000, valid loss: 91.827614
epoch: 2262, train precision: 0.998933, train loss: 10.387412, valid precision: 0.881200, valid loss: 90.599966
epoch: 2263, train precision: 0.998956, train loss: 10.432962, valid precision: 0.881200, valid loss: 92.195012
epoch: 2264, train precision: 0.998911, train loss: 10.473549, valid precision: 0.876200, valid loss: 90.341928
epoch: 2265, train precision: 0.998889, train loss: 10.416838, valid precision: 0.878800, valid loss: 90.882610
epoch: 2266, train precision: 0.998844, train loss: 10.433051, valid precision: 0.879400, valid loss: 90.549556
epoch: 2267, train precision: 0.999267, train loss: 10.313204, valid precision: 0.877200, valid loss: 90.008658
epoch: 2268, train precision: 0.998889, train loss: 10.433179, valid precision: 0.876000, valid loss: 94.646692
epoch: 2269, train precision: 0.999089, train loss: 10.370965, valid precision: 0.874000, valid loss: 93.504373
epoch: 2270, train precision: 0.998978, train loss: 10.467837, valid precision: 0.879800, valid loss: 90.299908
epoch: 2271, train precision: 0.999044, train loss: 10.414232, valid precision: 0.877200, valid loss: 93.018102
epoch: 2272, train precision: 0.998933, train loss: 10.478408, valid precision: 0.876400, valid loss: 90.592924
epoch: 2273, train precision: 0.998956, train loss: 10.415449, valid precision: 0.873200, valid loss: 90.500099
epoch: 2274, train precision: 0.998956, train loss: 10.415010, valid precision: 0.880400, valid loss: 89.136886
epoch: 2275, train precision: 0.998867, train loss: 10.484049, valid precision: 0.875600, valid loss: 92.857514
epoch: 2276, train precision: 0.999133, train loss: 10.387464, valid precision: 0.877200, valid loss: 88.631365
epoch: 2277, train precision: 0.999111, train loss: 10.392033, valid precision: 0.882200, valid loss: 88.666046
epoch: 2278, train precision: 0.999200, train loss: 10.344149, valid precision: 0.881000, valid loss: 89.031727
epoch: 2279, train precision: 0.998644, train loss: 10.514580, valid precision: 0.881800, valid loss: 87.362623
epoch: 2280, train precision: 0.998956, train loss: 10.421393, valid precision: 0.879400, valid loss: 88.600292
epoch: 2281, train precision: 0.998489, train loss: 10.529207, valid precision: 0.881600, valid loss: 88.875808
epoch: 2282, train precision: 0.999178, train loss: 10.398567, valid precision: 0.881000, valid loss: 85.113594
epoch: 2283, train precision: 0.999089, train loss: 10.355100, valid precision: 0.879800, valid loss: 86.991878
epoch: 2284, train precision: 0.999200, train loss: 10.347428, valid precision: 0.879400, valid loss: 87.794513
epoch: 2285, train precision: 0.999089, train loss: 10.332800, valid precision: 0.879800, valid loss: 89.878499
epoch: 2286, train precision: 0.998956, train loss: 10.465941, valid precision: 0.880000, valid loss: 89.725716
epoch: 2287, train precision: 0.999000, train loss: 10.383053, valid precision: 0.879600, valid loss: 89.237426
epoch: 2288, train precision: 0.999067, train loss: 10.430541, valid precision: 0.875200, valid loss: 90.026161
epoch: 2289, train precision: 0.999178, train loss: 10.379374, valid precision: 0.876200, valid loss: 90.200889
epoch: 2290, train precision: 0.999044, train loss: 10.339822, valid precision: 0.879400, valid loss: 89.042207
epoch: 2291, train precision: 0.998800, train loss: 10.472571, valid precision: 0.877400, valid loss: 87.958999
epoch: 2292, train precision: 0.999133, train loss: 10.401880, valid precision: 0.880600, valid loss: 89.393820
epoch: 2293, train precision: 0.999044, train loss: 10.372134, valid precision: 0.879600, valid loss: 89.607234
epoch: 2294, train precision: 0.999000, train loss: 10.423028, valid precision: 0.879600, valid loss: 90.254335
epoch: 2295, train precision: 0.999222, train loss: 10.382980, valid precision: 0.877400, valid loss: 91.246042
epoch: 2296, train precision: 0.998822, train loss: 10.482234, valid precision: 0.876000, valid loss: 91.886580
epoch: 2297, train precision: 0.999156, train loss: 10.393185, valid precision: 0.878200, valid loss: 88.867446
epoch: 2298, train precision: 0.999200, train loss: 10.368830, valid precision: 0.879800, valid loss: 87.298305
epoch: 2299, train precision: 0.999400, train loss: 10.305323, valid precision: 0.881000, valid loss: 86.956742
epoch: 2300, train precision: 0.998978, train loss: 10.475002, valid precision: 0.879000, valid loss: 88.727902
epoch: 2301, train precision: 0.999000, train loss: 10.410103, valid precision: 0.879800, valid loss: 86.296200
epoch: 2302, train precision: 0.998844, train loss: 10.475613, valid precision: 0.879600, valid loss: 89.666461
epoch: 2303, train precision: 0.999156, train loss: 10.367138, valid precision: 0.879600, valid loss: 86.906974
epoch: 2304, train precision: 0.998822, train loss: 10.430426, valid precision: 0.877600, valid loss: 89.767068
epoch: 2305, train precision: 0.999267, train loss: 10.337527, valid precision: 0.875600, valid loss: 89.502266
epoch: 2306, train precision: 0.999022, train loss: 10.395820, valid precision: 0.877200, valid loss: 91.111188
epoch: 2307, train precision: 0.999178, train loss: 10.341239, valid precision: 0.876200, valid loss: 91.121984
epoch: 2308, train precision: 0.998844, train loss: 10.496272, valid precision: 0.881200, valid loss: 85.683265
epoch: 2309, train precision: 0.998911, train loss: 10.410950, valid precision: 0.880600, valid loss: 87.455486
epoch: 2310, train precision: 0.999111, train loss: 10.354701, valid precision: 0.878200, valid loss: 88.720454
epoch: 2311, train precision: 0.998733, train loss: 10.500273, valid precision: 0.880000, valid loss: 89.209755
epoch: 2312, train precision: 0.999156, train loss: 10.357656, valid precision: 0.881200, valid loss: 88.901291
epoch: 2313, train precision: 0.998356, train loss: 10.625852, valid precision: 0.878400, valid loss: 90.748032
epoch: 2314, train precision: 0.998822, train loss: 10.477376, valid precision: 0.882800, valid loss: 88.519759
epoch: 2315, train precision: 0.999356, train loss: 10.341215, valid precision: 0.879600, valid loss: 91.417873
epoch: 2316, train precision: 0.999244, train loss: 10.366159, valid precision: 0.876600, valid loss: 89.139536
epoch: 2317, train precision: 0.999200, train loss: 10.387049, valid precision: 0.876800, valid loss: 90.684966
epoch: 2318, train precision: 0.999133, train loss: 10.350480, valid precision: 0.877600, valid loss: 89.609535
epoch: 2319, train precision: 0.998978, train loss: 10.387126, valid precision: 0.874800, valid loss: 88.798869
epoch: 2320, train precision: 0.998600, train loss: 10.536503, valid precision: 0.881000, valid loss: 89.914821
epoch: 2321, train precision: 0.999044, train loss: 10.366657, valid precision: 0.879800, valid loss: 89.563715
epoch: 2322, train precision: 0.998822, train loss: 10.434997, valid precision: 0.879600, valid loss: 87.971206
epoch: 2323, train precision: 0.999444, train loss: 10.294547, valid precision: 0.881200, valid loss: 87.250729
epoch: 2324, train precision: 0.999244, train loss: 10.331185, valid precision: 0.879400, valid loss: 88.721263
epoch: 2325, train precision: 0.999111, train loss: 10.369491, valid precision: 0.874800, valid loss: 90.357255
epoch: 2326, train precision: 0.998978, train loss: 10.502398, valid precision: 0.876200, valid loss: 91.681850
epoch: 2327, train precision: 0.998911, train loss: 10.462633, valid precision: 0.877400, valid loss: 90.369871
epoch: 2328, train precision: 0.999022, train loss: 10.361336, valid precision: 0.876000, valid loss: 89.143003
epoch: 2329, train precision: 0.998822, train loss: 10.469901, valid precision: 0.876400, valid loss: 91.665326
epoch: 2330, train precision: 0.998867, train loss: 10.432644, valid precision: 0.877600, valid loss: 91.858357
epoch: 2331, train precision: 0.999089, train loss: 10.355411, valid precision: 0.875600, valid loss: 93.424131
epoch: 2332, train precision: 0.999200, train loss: 10.381971, valid precision: 0.875600, valid loss: 90.153213
epoch: 2333, train precision: 0.998867, train loss: 10.478417, valid precision: 0.873600, valid loss: 93.108840
epoch: 2334, train precision: 0.999111, train loss: 10.379235, valid precision: 0.875600, valid loss: 91.490506
epoch: 2335, train precision: 0.998867, train loss: 10.421989, valid precision: 0.876200, valid loss: 91.273487
epoch: 2336, train precision: 0.999333, train loss: 10.337678, valid precision: 0.877000, valid loss: 89.802661
epoch: 2337, train precision: 0.998933, train loss: 10.402298, valid precision: 0.873000, valid loss: 89.508725
epoch: 2338, train precision: 0.999156, train loss: 10.356831, valid precision: 0.878800, valid loss: 88.268378
epoch: 2339, train precision: 0.998956, train loss: 10.367120, valid precision: 0.879400, valid loss: 89.438904
epoch: 2340, train precision: 0.999356, train loss: 10.297739, valid precision: 0.875400, valid loss: 93.555039
epoch: 2341, train precision: 0.999111, train loss: 10.428492, valid precision: 0.878000, valid loss: 92.280668
epoch: 2342, train precision: 0.999178, train loss: 10.303390, valid precision: 0.881000, valid loss: 93.043604
epoch: 2343, train precision: 0.998867, train loss: 10.409696, valid precision: 0.877200, valid loss: 90.973552
epoch: 2344, train precision: 0.999378, train loss: 10.332577, valid precision: 0.880200, valid loss: 90.530453
epoch: 2345, train precision: 0.999378, train loss: 10.305400, valid precision: 0.874800, valid loss: 91.327048
epoch: 2346, train precision: 0.998667, train loss: 10.570320, valid precision: 0.874000, valid loss: 92.269795
epoch: 2347, train precision: 0.998600, train loss: 10.542827, valid precision: 0.871000, valid loss: 95.061823
epoch: 2348, train precision: 0.999000, train loss: 10.399781, valid precision: 0.873600, valid loss: 93.150555
epoch: 2349, train precision: 0.999222, train loss: 10.346308, valid precision: 0.876800, valid loss: 91.864075
epoch: 2350, train precision: 0.998800, train loss: 10.439415, valid precision: 0.875200, valid loss: 94.320027
epoch: 2351, train precision: 0.998844, train loss: 10.464358, valid precision: 0.874800, valid loss: 94.079174
epoch: 2352, train precision: 0.999022, train loss: 10.380638, valid precision: 0.876200, valid loss: 95.469940
epoch: 2353, train precision: 0.999311, train loss: 10.371062, valid precision: 0.873200, valid loss: 93.584680
epoch: 2354, train precision: 0.998711, train loss: 10.457363, valid precision: 0.873800, valid loss: 91.873369
epoch: 2355, train precision: 0.998844, train loss: 10.490257, valid precision: 0.878600, valid loss: 91.896274
epoch: 2356, train precision: 0.998756, train loss: 10.471069, valid precision: 0.876000, valid loss: 91.028865
epoch: 2357, train precision: 0.999289, train loss: 10.332499, valid precision: 0.878600, valid loss: 91.648143
epoch: 2358, train precision: 0.999044, train loss: 10.389117, valid precision: 0.876200, valid loss: 92.100037
epoch: 2359, train precision: 0.999133, train loss: 10.335114, valid precision: 0.873200, valid loss: 92.294025
epoch: 2360, train precision: 0.999200, train loss: 10.430707, valid precision: 0.875000, valid loss: 92.036469
epoch: 2361, train precision: 0.999289, train loss: 10.342909, valid precision: 0.878000, valid loss: 91.998053
epoch: 2362, train precision: 0.999133, train loss: 10.344267, valid precision: 0.877400, valid loss: 90.642191
epoch: 2363, train precision: 0.998911, train loss: 10.381171, valid precision: 0.881200, valid loss: 92.290821
epoch: 2364, train precision: 0.999200, train loss: 10.324226, valid precision: 0.882000, valid loss: 87.399036
epoch: 2365, train precision: 0.999156, train loss: 10.339063, valid precision: 0.882800, valid loss: 88.236289
epoch: 2366, train precision: 0.999244, train loss: 10.379498, valid precision: 0.875400, valid loss: 91.458385
epoch: 2367, train precision: 0.998533, train loss: 10.535263, valid precision: 0.875200, valid loss: 88.857413
epoch: 2368, train precision: 0.998778, train loss: 10.476576, valid precision: 0.878400, valid loss: 87.913367
epoch: 2369, train precision: 0.999133, train loss: 10.405291, valid precision: 0.881200, valid loss: 88.174919
epoch: 2370, train precision: 0.999067, train loss: 10.368284, valid precision: 0.877400, valid loss: 89.553091
epoch: 2371, train precision: 0.998889, train loss: 10.418534, valid precision: 0.876000, valid loss: 89.293292
epoch: 2372, train precision: 0.998756, train loss: 10.484280, valid precision: 0.879600, valid loss: 87.104050
epoch: 2373, train precision: 0.999200, train loss: 10.391134, valid precision: 0.875600, valid loss: 87.350199
epoch: 2374, train precision: 0.999111, train loss: 10.346667, valid precision: 0.877600, valid loss: 90.147313
epoch: 2375, train precision: 0.998956, train loss: 10.425688, valid precision: 0.878800, valid loss: 88.389971
epoch: 2376, train precision: 0.999178, train loss: 10.357796, valid precision: 0.883800, valid loss: 88.270311
epoch: 2377, train precision: 0.998889, train loss: 10.436646, valid precision: 0.877000, valid loss: 91.174138
epoch: 2378, train precision: 0.999111, train loss: 10.374305, valid precision: 0.875400, valid loss: 91.582444
epoch: 2379, train precision: 0.999378, train loss: 10.263939, valid precision: 0.882000, valid loss: 89.675823
epoch: 2380, train precision: 0.999222, train loss: 10.305641, valid precision: 0.880400, valid loss: 90.277561
epoch: 2381, train precision: 0.998800, train loss: 10.408489, valid precision: 0.875800, valid loss: 92.518506
epoch: 2382, train precision: 0.999000, train loss: 10.422587, valid precision: 0.880400, valid loss: 91.109976
epoch: 2383, train precision: 0.998644, train loss: 10.485205, valid precision: 0.881400, valid loss: 91.209112
epoch: 2384, train precision: 0.998822, train loss: 10.398666, valid precision: 0.877200, valid loss: 89.808037
epoch: 2385, train precision: 0.999222, train loss: 10.327888, valid precision: 0.876200, valid loss: 89.057521
epoch: 2386, train precision: 0.999178, train loss: 10.362679, valid precision: 0.880000, valid loss: 91.874728
epoch: 2387, train precision: 0.998956, train loss: 10.423041, valid precision: 0.875600, valid loss: 92.752955
epoch: 2388, train precision: 0.998822, train loss: 10.482591, valid precision: 0.878000, valid loss: 89.978627
epoch: 2389, train precision: 0.999222, train loss: 10.346520, valid precision: 0.876400, valid loss: 89.334565
epoch: 2390, train precision: 0.999333, train loss: 10.315207, valid precision: 0.879400, valid loss: 88.948544
epoch: 2391, train precision: 0.998956, train loss: 10.429203, valid precision: 0.876200, valid loss: 89.597370
epoch: 2392, train precision: 0.999378, train loss: 10.313226, valid precision: 0.877200, valid loss: 89.834884
epoch: 2393, train precision: 0.999067, train loss: 10.362833, valid precision: 0.873800, valid loss: 90.698371
epoch: 2394, train precision: 0.999222, train loss: 10.328789, valid precision: 0.872800, valid loss: 90.796374
epoch: 2395, train precision: 0.999333, train loss: 10.304474, valid precision: 0.873600, valid loss: 92.192729
epoch: 2396, train precision: 0.998956, train loss: 10.430693, valid precision: 0.881000, valid loss: 89.300343
epoch: 2397, train precision: 0.999111, train loss: 10.317145, valid precision: 0.876200, valid loss: 91.174029
epoch: 2398, train precision: 0.998489, train loss: 10.470869, valid precision: 0.877400, valid loss: 93.111466
epoch: 2399, train precision: 0.998778, train loss: 10.432904, valid precision: 0.877600, valid loss: 92.501538
epoch: 2400, train precision: 0.998489, train loss: 10.530590, valid precision: 0.874400, valid loss: 91.551363
epoch: 2401, train precision: 0.999333, train loss: 10.376811, valid precision: 0.875600, valid loss: 90.782988
epoch: 2402, train precision: 0.999244, train loss: 10.353804, valid precision: 0.877000, valid loss: 91.616013
epoch: 2403, train precision: 0.999000, train loss: 10.427096, valid precision: 0.874400, valid loss: 91.924091
epoch: 2404, train precision: 0.999333, train loss: 10.339284, valid precision: 0.874200, valid loss: 91.202349
epoch: 2405, train precision: 0.999089, train loss: 10.373101, valid precision: 0.875200, valid loss: 92.049304
epoch: 2406, train precision: 0.999244, train loss: 10.304137, valid precision: 0.872800, valid loss: 90.964088
epoch: 2407, train precision: 0.999422, train loss: 10.260799, valid precision: 0.875600, valid loss: 90.808378
epoch: 2408, train precision: 0.999178, train loss: 10.293821, valid precision: 0.877400, valid loss: 91.182253
epoch: 2409, train precision: 0.998956, train loss: 10.448478, valid precision: 0.875200, valid loss: 90.760544
epoch: 2410, train precision: 0.999156, train loss: 10.366975, valid precision: 0.874800, valid loss: 87.988944
epoch: 2411, train precision: 0.998689, train loss: 10.518522, valid precision: 0.876400, valid loss: 89.908966
epoch: 2412, train precision: 0.998911, train loss: 10.435027, valid precision: 0.877400, valid loss: 90.395650
epoch: 2413, train precision: 0.999000, train loss: 10.419627, valid precision: 0.878600, valid loss: 90.086247
epoch: 2414, train precision: 0.999089, train loss: 10.374564, valid precision: 0.876200, valid loss: 89.343430
epoch: 2415, train precision: 0.999178, train loss: 10.309952, valid precision: 0.875200, valid loss: 89.403011
epoch: 2416, train precision: 0.998956, train loss: 10.454197, valid precision: 0.875400, valid loss: 90.101917
epoch: 2417, train precision: 0.999422, train loss: 10.246723, valid precision: 0.877400, valid loss: 91.443056
epoch: 2418, train precision: 0.999044, train loss: 10.363577, valid precision: 0.873800, valid loss: 94.586391
epoch: 2419, train precision: 0.998889, train loss: 10.403737, valid precision: 0.875400, valid loss: 92.745945
epoch: 2420, train precision: 0.998533, train loss: 10.557478, valid precision: 0.875200, valid loss: 93.008312
epoch: 2421, train precision: 0.999244, train loss: 10.349848, valid precision: 0.878400, valid loss: 90.545738
epoch: 2422, train precision: 0.998667, train loss: 10.469587, valid precision: 0.877600, valid loss: 90.878178
epoch: 2423, train precision: 0.999289, train loss: 10.256665, valid precision: 0.876600, valid loss: 89.904959
epoch: 2424, train precision: 0.999133, train loss: 10.319982, valid precision: 0.877600, valid loss: 90.971285
epoch: 2425, train precision: 0.999200, train loss: 10.362301, valid precision: 0.873400, valid loss: 87.146401
epoch: 2426, train precision: 0.998978, train loss: 10.381320, valid precision: 0.879400, valid loss: 87.046584
epoch: 2427, train precision: 0.998844, train loss: 10.450045, valid precision: 0.874800, valid loss: 89.894032
epoch: 2428, train precision: 0.999111, train loss: 10.380960, valid precision: 0.874400, valid loss: 89.448107
epoch: 2429, train precision: 0.998844, train loss: 10.436986, valid precision: 0.873400, valid loss: 92.686747
epoch: 2430, train precision: 0.998956, train loss: 10.387831, valid precision: 0.874600, valid loss: 92.885021
epoch: 2431, train precision: 0.998867, train loss: 10.481155, valid precision: 0.876800, valid loss: 90.895673
epoch: 2432, train precision: 0.999156, train loss: 10.352084, valid precision: 0.875200, valid loss: 92.849435
epoch: 2433, train precision: 0.998956, train loss: 10.395798, valid precision: 0.875000, valid loss: 92.125111
epoch: 2434, train precision: 0.999044, train loss: 10.296820, valid precision: 0.872600, valid loss: 91.656452
epoch: 2435, train precision: 0.999000, train loss: 10.417991, valid precision: 0.873200, valid loss: 92.331808
epoch: 2436, train precision: 0.999200, train loss: 10.301281, valid precision: 0.876800, valid loss: 93.161263
epoch: 2437, train precision: 0.998556, train loss: 10.517177, valid precision: 0.875600, valid loss: 92.080841
epoch: 2438, train precision: 0.998800, train loss: 10.411069, valid precision: 0.875600, valid loss: 90.086560
epoch: 2439, train precision: 0.999133, train loss: 10.377804, valid precision: 0.874600, valid loss: 90.723544
epoch: 2440, train precision: 0.999089, train loss: 10.343924, valid precision: 0.878400, valid loss: 89.326351
epoch: 2441, train precision: 0.998978, train loss: 10.344469, valid precision: 0.874600, valid loss: 92.998779
epoch: 2442, train precision: 0.998511, train loss: 10.578464, valid precision: 0.873200, valid loss: 93.072700
epoch: 2443, train precision: 0.999289, train loss: 10.245547, valid precision: 0.873200, valid loss: 91.927338
epoch: 2444, train precision: 0.999089, train loss: 10.331526, valid precision: 0.875200, valid loss: 90.111263
epoch: 2445, train precision: 0.999000, train loss: 10.324646, valid precision: 0.873400, valid loss: 93.832002
epoch: 2446, train precision: 0.999067, train loss: 10.336721, valid precision: 0.876000, valid loss: 92.216225
epoch: 2447, train precision: 0.998533, train loss: 10.530646, valid precision: 0.873200, valid loss: 93.508560
epoch: 2448, train precision: 0.999044, train loss: 10.332629, valid precision: 0.874400, valid loss: 91.982754
epoch: 2449, train precision: 0.999067, train loss: 10.386930, valid precision: 0.875400, valid loss: 91.028415
epoch: 2450, train precision: 0.998956, train loss: 10.401633, valid precision: 0.869200, valid loss: 93.248867
epoch: 2451, train precision: 0.998600, train loss: 10.455885, valid precision: 0.877000, valid loss: 92.578612
epoch: 2452, train precision: 0.998889, train loss: 10.374417, valid precision: 0.878800, valid loss: 90.615521
epoch: 2453, train precision: 0.999044, train loss: 10.348854, valid precision: 0.877200, valid loss: 91.747034
epoch: 2454, train precision: 0.999267, train loss: 10.294390, valid precision: 0.880000, valid loss: 88.674617
epoch: 2455, train precision: 0.999356, train loss: 10.282474, valid precision: 0.878600, valid loss: 90.435953
epoch: 2456, train precision: 0.999133, train loss: 10.335292, valid precision: 0.876800, valid loss: 89.514323
epoch: 2457, train precision: 0.999022, train loss: 10.373938, valid precision: 0.876400, valid loss: 90.638776
epoch: 2458, train precision: 0.999267, train loss: 10.319498, valid precision: 0.875800, valid loss: 90.566609
epoch: 2459, train precision: 0.998867, train loss: 10.484437, valid precision: 0.876800, valid loss: 90.057851
epoch: 2460, train precision: 0.999178, train loss: 10.348095, valid precision: 0.874800, valid loss: 90.768578
epoch: 2461, train precision: 0.999022, train loss: 10.283530, valid precision: 0.879600, valid loss: 88.825737
epoch: 2462, train precision: 0.999022, train loss: 10.359384, valid precision: 0.877800, valid loss: 89.834783
epoch: 2463, train precision: 0.999000, train loss: 10.324543, valid precision: 0.881000, valid loss: 91.135816
epoch: 2464, train precision: 0.998978, train loss: 10.412025, valid precision: 0.879400, valid loss: 92.338260
epoch: 2465, train precision: 0.999244, train loss: 10.330548, valid precision: 0.880000, valid loss: 90.117345
epoch: 2466, train precision: 0.998889, train loss: 10.366916, valid precision: 0.883400, valid loss: 88.439893
epoch: 2467, train precision: 0.998844, train loss: 10.457511, valid precision: 0.877600, valid loss: 88.476357
epoch: 2468, train precision: 0.999000, train loss: 10.372561, valid precision: 0.876800, valid loss: 88.125783
epoch: 2469, train precision: 0.999111, train loss: 10.348607, valid precision: 0.875600, valid loss: 89.956058
epoch: 2470, train precision: 0.999000, train loss: 10.447748, valid precision: 0.878800, valid loss: 88.128357
epoch: 2471, train precision: 0.998933, train loss: 10.342608, valid precision: 0.877800, valid loss: 91.600155
epoch: 2472, train precision: 0.999200, train loss: 10.343993, valid precision: 0.877400, valid loss: 88.978905
epoch: 2473, train precision: 0.999222, train loss: 10.296703, valid precision: 0.875600, valid loss: 91.442492
epoch: 2474, train precision: 0.999200, train loss: 10.285331, valid precision: 0.876000, valid loss: 90.267804
epoch: 2475, train precision: 0.998956, train loss: 10.296302, valid precision: 0.872800, valid loss: 91.000310
epoch: 2476, train precision: 0.998956, train loss: 10.336537, valid precision: 0.872200, valid loss: 91.099188
epoch: 2477, train precision: 0.998889, train loss: 10.370913, valid precision: 0.878000, valid loss: 88.330000
epoch: 2478, train precision: 0.999067, train loss: 10.279304, valid precision: 0.871800, valid loss: 91.243909
epoch: 2479, train precision: 0.999044, train loss: 10.369690, valid precision: 0.875600, valid loss: 89.715199
epoch: 2480, train precision: 0.999244, train loss: 10.306024, valid precision: 0.871800, valid loss: 90.496060
epoch: 2481, train precision: 0.999044, train loss: 10.391691, valid precision: 0.875400, valid loss: 89.768425
epoch: 2482, train precision: 0.998867, train loss: 10.464215, valid precision: 0.874400, valid loss: 90.224104
epoch: 2483, train precision: 0.999289, train loss: 10.251122, valid precision: 0.873600, valid loss: 90.843749
epoch: 2484, train precision: 0.999400, train loss: 10.279448, valid precision: 0.878800, valid loss: 87.800294
epoch: 2485, train precision: 0.998978, train loss: 10.399140, valid precision: 0.878200, valid loss: 90.204423
epoch: 2486, train precision: 0.999267, train loss: 10.259050, valid precision: 0.881400, valid loss: 91.443487
epoch: 2487, train precision: 0.999178, train loss: 10.380921, valid precision: 0.877800, valid loss: 88.593804
epoch: 2488, train precision: 0.998756, train loss: 10.475104, valid precision: 0.873000, valid loss: 89.905655
epoch: 2489, train precision: 0.998933, train loss: 10.379846, valid precision: 0.880600, valid loss: 90.169367
epoch: 2490, train precision: 0.999178, train loss: 10.328982, valid precision: 0.878800, valid loss: 88.800618
epoch: 2491, train precision: 0.999200, train loss: 10.253705, valid precision: 0.878400, valid loss: 90.912172
epoch: 2492, train precision: 0.999133, train loss: 10.301179, valid precision: 0.880800, valid loss: 89.792818
epoch: 2493, train precision: 0.999022, train loss: 10.318427, valid precision: 0.877600, valid loss: 90.497081
epoch: 2494, train precision: 0.999289, train loss: 10.285092, valid precision: 0.878600, valid loss: 89.102277
epoch: 2495, train precision: 0.999089, train loss: 10.342969, valid precision: 0.875600, valid loss: 92.830834
epoch: 2496, train precision: 0.999111, train loss: 10.339900, valid precision: 0.873200, valid loss: 93.865925
epoch: 2497, train precision: 0.998756, train loss: 10.487554, valid precision: 0.875800, valid loss: 89.927985
epoch: 2498, train precision: 0.999400, train loss: 10.249167, valid precision: 0.880800, valid loss: 88.001585
epoch: 2499, train precision: 0.998578, train loss: 10.488036, valid precision: 0.879800, valid loss: 88.520476
epoch: 2500, train precision: 0.998978, train loss: 10.365820, valid precision: 0.877600, valid loss: 87.841056
epoch: 2501, train precision: 0.998911, train loss: 10.336482, valid precision: 0.879200, valid loss: 88.606758
epoch: 2502, train precision: 0.999289, train loss: 10.294303, valid precision: 0.880800, valid loss: 87.033681
epoch: 2503, train precision: 0.999378, train loss: 10.266083, valid precision: 0.878400, valid loss: 88.737441
epoch: 2504, train precision: 0.999133, train loss: 10.364360, valid precision: 0.877600, valid loss: 87.558811
epoch: 2505, train precision: 0.998800, train loss: 10.373723, valid precision: 0.876400, valid loss: 89.224892
epoch: 2506, train precision: 0.999089, train loss: 10.346171, valid precision: 0.878200, valid loss: 90.546781
epoch: 2507, train precision: 0.998911, train loss: 10.375547, valid precision: 0.878400, valid loss: 90.570816
epoch: 2508, train precision: 0.999133, train loss: 10.259874, valid precision: 0.880800, valid loss: 91.373510
epoch: 2509, train precision: 0.998978, train loss: 10.357458, valid precision: 0.880600, valid loss: 90.263291
epoch: 2510, train precision: 0.999111, train loss: 10.356740, valid precision: 0.880800, valid loss: 90.266996
epoch: 2511, train precision: 0.999267, train loss: 10.326111, valid precision: 0.881000, valid loss: 89.239928
epoch: 2512, train precision: 0.999044, train loss: 10.346273, valid precision: 0.880000, valid loss: 92.280916
epoch: 2513, train precision: 0.998733, train loss: 10.405331, valid precision: 0.875200, valid loss: 91.305814
epoch: 2514, train precision: 0.998800, train loss: 10.425961, valid precision: 0.878400, valid loss: 89.625286
epoch: 2515, train precision: 0.999111, train loss: 10.293804, valid precision: 0.872600, valid loss: 87.263713
epoch: 2516, train precision: 0.999111, train loss: 10.352152, valid precision: 0.878400, valid loss: 86.980533
epoch: 2517, train precision: 0.999156, train loss: 10.287841, valid precision: 0.874800, valid loss: 88.118091
epoch: 2518, train precision: 0.998711, train loss: 10.470783, valid precision: 0.874800, valid loss: 92.293154
epoch: 2519, train precision: 0.999356, train loss: 10.284832, valid precision: 0.875400, valid loss: 92.729592
epoch: 2520, train precision: 0.999156, train loss: 10.330637, valid precision: 0.880800, valid loss: 88.550411
epoch: 2521, train precision: 0.999000, train loss: 10.342846, valid precision: 0.874600, valid loss: 91.138437
epoch: 2522, train precision: 0.998333, train loss: 10.468494, valid precision: 0.879600, valid loss: 89.378598
epoch: 2523, train precision: 0.998911, train loss: 10.406085, valid precision: 0.874600, valid loss: 89.088312
epoch: 2524, train precision: 0.999067, train loss: 10.359703, valid precision: 0.876600, valid loss: 90.075921
epoch: 2525, train precision: 0.999356, train loss: 10.242948, valid precision: 0.876400, valid loss: 87.824852
epoch: 2526, train precision: 0.999111, train loss: 10.361945, valid precision: 0.878000, valid loss: 90.854917
epoch: 2527, train precision: 0.999289, train loss: 10.364490, valid precision: 0.873600, valid loss: 92.055156
epoch: 2528, train precision: 0.998956, train loss: 10.370276, valid precision: 0.878400, valid loss: 90.406719
epoch: 2529, train precision: 0.999444, train loss: 10.227749, valid precision: 0.879200, valid loss: 88.762932
epoch: 2530, train precision: 0.998956, train loss: 10.347672, valid precision: 0.879200, valid loss: 90.623507
epoch: 2531, train precision: 0.998822, train loss: 10.418032, valid precision: 0.875800, valid loss: 90.531070
epoch: 2532, train precision: 0.999022, train loss: 10.342424, valid precision: 0.877400, valid loss: 87.988962
epoch: 2533, train precision: 0.998800, train loss: 10.366908, valid precision: 0.876800, valid loss: 91.940515
epoch: 2534, train precision: 0.998978, train loss: 10.389206, valid precision: 0.877800, valid loss: 89.738265
epoch: 2535, train precision: 0.998911, train loss: 10.343419, valid precision: 0.877000, valid loss: 92.933770
epoch: 2536, train precision: 0.999178, train loss: 10.293465, valid precision: 0.877800, valid loss: 92.002864
epoch: 2537, train precision: 0.999333, train loss: 10.234001, valid precision: 0.880400, valid loss: 90.695357
epoch: 2538, train precision: 0.999067, train loss: 10.374932, valid precision: 0.881000, valid loss: 89.550501
epoch: 2539, train precision: 0.998578, train loss: 10.417785, valid precision: 0.880600, valid loss: 89.983805
epoch: 2540, train precision: 0.999178, train loss: 10.273663, valid precision: 0.873800, valid loss: 91.865978
epoch: 2541, train precision: 0.998711, train loss: 10.452478, valid precision: 0.876600, valid loss: 92.775243
epoch: 2542, train precision: 0.999000, train loss: 10.299625, valid precision: 0.882200, valid loss: 91.305300
epoch: 2543, train precision: 0.998933, train loss: 10.363064, valid precision: 0.877800, valid loss: 92.318676
epoch: 2544, train precision: 0.998867, train loss: 10.392990, valid precision: 0.878400, valid loss: 90.183623
epoch: 2545, train precision: 0.998733, train loss: 10.430758, valid precision: 0.881000, valid loss: 92.029666
epoch: 2546, train precision: 0.998978, train loss: 10.390742, valid precision: 0.877200, valid loss: 89.793309
epoch: 2547, train precision: 0.998911, train loss: 10.397493, valid precision: 0.877400, valid loss: 89.906280
epoch: 2548, train precision: 0.998978, train loss: 10.345074, valid precision: 0.880200, valid loss: 88.238804
epoch: 2549, train precision: 0.999000, train loss: 10.384356, valid precision: 0.876200, valid loss: 88.347218
epoch: 2550, train precision: 0.999289, train loss: 10.286796, valid precision: 0.881400, valid loss: 87.979838
epoch: 2551, train precision: 0.998889, train loss: 10.390590, valid precision: 0.877600, valid loss: 89.463766
epoch: 2552, train precision: 0.998800, train loss: 10.421738, valid precision: 0.880000, valid loss: 86.239091
epoch: 2553, train precision: 0.999067, train loss: 10.324359, valid precision: 0.880800, valid loss: 89.147661
epoch: 2554, train precision: 0.999378, train loss: 10.302043, valid precision: 0.879800, valid loss: 87.400708
epoch: 2555, train precision: 0.999378, train loss: 10.273410, valid precision: 0.876600, valid loss: 89.031331
epoch: 2556, train precision: 0.999244, train loss: 10.352056, valid precision: 0.875000, valid loss: 89.084998
epoch: 2557, train precision: 0.999178, train loss: 10.308348, valid precision: 0.878000, valid loss: 88.898670
epoch: 2558, train precision: 0.999356, train loss: 10.250148, valid precision: 0.881000, valid loss: 87.564003
epoch: 2559, train precision: 0.999000, train loss: 10.380073, valid precision: 0.881200, valid loss: 86.392922
epoch: 2560, train precision: 0.998956, train loss: 10.365689, valid precision: 0.876600, valid loss: 89.810278
epoch: 2561, train precision: 0.999000, train loss: 10.324325, valid precision: 0.878200, valid loss: 89.587657
epoch: 2562, train precision: 0.999244, train loss: 10.291015, valid precision: 0.879400, valid loss: 89.322146
epoch: 2563, train precision: 0.999200, train loss: 10.240641, valid precision: 0.876600, valid loss: 88.951575
epoch: 2564, train precision: 0.999022, train loss: 10.414175, valid precision: 0.877800, valid loss: 88.622719
epoch: 2565, train precision: 0.998956, train loss: 10.362412, valid precision: 0.882400, valid loss: 88.295518
epoch: 2566, train precision: 0.998978, train loss: 10.330684, valid precision: 0.881400, valid loss: 87.677868
epoch: 2567, train precision: 0.999022, train loss: 10.374428, valid precision: 0.881600, valid loss: 87.621789
epoch: 2568, train precision: 0.998844, train loss: 10.426492, valid precision: 0.878200, valid loss: 88.275118
epoch: 2569, train precision: 0.999200, train loss: 10.313026, valid precision: 0.877400, valid loss: 88.440192
epoch: 2570, train precision: 0.999200, train loss: 10.211573, valid precision: 0.878200, valid loss: 91.289917
epoch: 2571, train precision: 0.998578, train loss: 10.500644, valid precision: 0.879600, valid loss: 89.949778
epoch: 2572, train precision: 0.999244, train loss: 10.209991, valid precision: 0.879200, valid loss: 89.629414
epoch: 2573, train precision: 0.999111, train loss: 10.341818, valid precision: 0.881600, valid loss: 88.392950
epoch: 2574, train precision: 0.998933, train loss: 10.394004, valid precision: 0.879400, valid loss: 89.509901
epoch: 2575, train precision: 0.998889, train loss: 10.408944, valid precision: 0.879000, valid loss: 91.318082
epoch: 2576, train precision: 0.998844, train loss: 10.356282, valid precision: 0.879600, valid loss: 89.813868
epoch: 2577, train precision: 0.999067, train loss: 10.343226, valid precision: 0.882000, valid loss: 88.810813
epoch: 2578, train precision: 0.999178, train loss: 10.302716, valid precision: 0.880400, valid loss: 88.872752
epoch: 2579, train precision: 0.999244, train loss: 10.262896, valid precision: 0.881600, valid loss: 87.566041
epoch: 2580, train precision: 0.999333, train loss: 10.258970, valid precision: 0.883400, valid loss: 87.566138
epoch: 2581, train precision: 0.999089, train loss: 10.334252, valid precision: 0.877400, valid loss: 89.909845
epoch: 2582, train precision: 0.998622, train loss: 10.498954, valid precision: 0.882000, valid loss: 88.986183
epoch: 2583, train precision: 0.998511, train loss: 10.491266, valid precision: 0.876800, valid loss: 88.414407
epoch: 2584, train precision: 0.999000, train loss: 10.332393, valid precision: 0.883600, valid loss: 86.521343
epoch: 2585, train precision: 0.999133, train loss: 10.331469, valid precision: 0.880200, valid loss: 88.408287
epoch: 2586, train precision: 0.999044, train loss: 10.374709, valid precision: 0.880200, valid loss: 88.315552
epoch: 2587, train precision: 0.999089, train loss: 10.387262, valid precision: 0.881800, valid loss: 87.209448
epoch: 2588, train precision: 0.999044, train loss: 10.397441, valid precision: 0.879600, valid loss: 87.463581
epoch: 2589, train precision: 0.999289, train loss: 10.261689, valid precision: 0.881400, valid loss: 86.933818
epoch: 2590, train precision: 0.998822, train loss: 10.384682, valid precision: 0.880800, valid loss: 91.341991
epoch: 2591, train precision: 0.998644, train loss: 10.468081, valid precision: 0.879600, valid loss: 92.002433
epoch: 2592, train precision: 0.999200, train loss: 10.264054, valid precision: 0.880200, valid loss: 88.651613
epoch: 2593, train precision: 0.999289, train loss: 10.255773, valid precision: 0.880200, valid loss: 88.019290
epoch: 2594, train precision: 0.998822, train loss: 10.391777, valid precision: 0.882200, valid loss: 86.289175
epoch: 2595, train precision: 0.999289, train loss: 10.283911, valid precision: 0.878600, valid loss: 90.879348
epoch: 2596, train precision: 0.998822, train loss: 10.413607, valid precision: 0.877000, valid loss: 90.142962
epoch: 2597, train precision: 0.998800, train loss: 10.482140, valid precision: 0.878200, valid loss: 89.636612
epoch: 2598, train precision: 0.998889, train loss: 10.372141, valid precision: 0.882600, valid loss: 88.659278
epoch: 2599, train precision: 0.999111, train loss: 10.371174, valid precision: 0.878000, valid loss: 89.760820
epoch: 2600, train precision: 0.998644, train loss: 10.373837, valid precision: 0.878600, valid loss: 88.285406
epoch: 2601, train precision: 0.998467, train loss: 10.515339, valid precision: 0.877800, valid loss: 89.839155
epoch: 2602, train precision: 0.999200, train loss: 10.350398, valid precision: 0.877600, valid loss: 89.600786
epoch: 2603, train precision: 0.999022, train loss: 10.347924, valid precision: 0.880000, valid loss: 89.304554
epoch: 2604, train precision: 0.999289, train loss: 10.303055, valid precision: 0.880400, valid loss: 90.186176
epoch: 2605, train precision: 0.999311, train loss: 10.302862, valid precision: 0.879000, valid loss: 89.118739
epoch: 2606, train precision: 0.998756, train loss: 10.471481, valid precision: 0.879400, valid loss: 92.197594
epoch: 2607, train precision: 0.999244, train loss: 10.334210, valid precision: 0.883800, valid loss: 87.174136
epoch: 2608, train precision: 0.999178, train loss: 10.294545, valid precision: 0.878400, valid loss: 87.509609
epoch: 2609, train precision: 0.998889, train loss: 10.400301, valid precision: 0.880400, valid loss: 90.700955
epoch: 2610, train precision: 0.999178, train loss: 10.304846, valid precision: 0.879600, valid loss: 88.665724
epoch: 2611, train precision: 0.999000, train loss: 10.376223, valid precision: 0.881600, valid loss: 89.394604
epoch: 2612, train precision: 0.999044, train loss: 10.302819, valid precision: 0.879600, valid loss: 91.817726
epoch: 2613, train precision: 0.999044, train loss: 10.365106, valid precision: 0.881800, valid loss: 91.056041
epoch: 2614, train precision: 0.999067, train loss: 10.292491, valid precision: 0.880600, valid loss: 91.166763
epoch: 2615, train precision: 0.998978, train loss: 10.314567, valid precision: 0.880800, valid loss: 93.588961
epoch: 2616, train precision: 0.998756, train loss: 10.384734, valid precision: 0.880600, valid loss: 90.130764
epoch: 2617, train precision: 0.998933, train loss: 10.342152, valid precision: 0.883200, valid loss: 92.370959
epoch: 2618, train precision: 0.998956, train loss: 10.335105, valid precision: 0.882600, valid loss: 91.344290
epoch: 2619, train precision: 0.999067, train loss: 10.341253, valid precision: 0.882200, valid loss: 90.480356
epoch: 2620, train precision: 0.998689, train loss: 10.466769, valid precision: 0.881600, valid loss: 91.217792
epoch: 2621, train precision: 0.998844, train loss: 10.384831, valid precision: 0.879400, valid loss: 91.342425
epoch: 2622, train precision: 0.998711, train loss: 10.405607, valid precision: 0.883600, valid loss: 89.634620
epoch: 2623, train precision: 0.998689, train loss: 10.460589, valid precision: 0.882600, valid loss: 89.146532
epoch: 2624, train precision: 0.999378, train loss: 10.191523, valid precision: 0.883200, valid loss: 89.895940
epoch: 2625, train precision: 0.998644, train loss: 10.470110, valid precision: 0.879000, valid loss: 87.881792
epoch: 2626, train precision: 0.998956, train loss: 10.368935, valid precision: 0.880400, valid loss: 91.475735
epoch: 2627, train precision: 0.999044, train loss: 10.347472, valid precision: 0.877400, valid loss: 88.979077
epoch: 2628, train precision: 0.998978, train loss: 10.308933, valid precision: 0.881400, valid loss: 92.481585
epoch: 2629, train precision: 0.999000, train loss: 10.339235, valid precision: 0.880200, valid loss: 88.952785
epoch: 2630, train precision: 0.999156, train loss: 10.231747, valid precision: 0.882200, valid loss: 89.552770
epoch: 2631, train precision: 0.999133, train loss: 10.302299, valid precision: 0.881200, valid loss: 91.801994
epoch: 2632, train precision: 0.999111, train loss: 10.274638, valid precision: 0.880200, valid loss: 91.000276
epoch: 2633, train precision: 0.998889, train loss: 10.344891, valid precision: 0.878800, valid loss: 88.472256
epoch: 2634, train precision: 0.998911, train loss: 10.324447, valid precision: 0.884000, valid loss: 91.638013
epoch: 2635, train precision: 0.999200, train loss: 10.323145, valid precision: 0.883400, valid loss: 87.967593
epoch: 2636, train precision: 0.999267, train loss: 10.254995, valid precision: 0.879200, valid loss: 90.484148
epoch: 2637, train precision: 0.999067, train loss: 10.344165, valid precision: 0.880200, valid loss: 92.424179
epoch: 2638, train precision: 0.998911, train loss: 10.394164, valid precision: 0.883200, valid loss: 90.034181
epoch: 2639, train precision: 0.999333, train loss: 10.268236, valid precision: 0.877400, valid loss: 89.909499
epoch: 2640, train precision: 0.999067, train loss: 10.400735, valid precision: 0.881000, valid loss: 87.801563
epoch: 2641, train precision: 0.999200, train loss: 10.270989, valid precision: 0.884600, valid loss: 89.788136
epoch: 2642, train precision: 0.999044, train loss: 10.300824, valid precision: 0.884000, valid loss: 87.623423
epoch: 2643, train precision: 0.998333, train loss: 10.485467, valid precision: 0.881400, valid loss: 90.448628
epoch: 2644, train precision: 0.998911, train loss: 10.342310, valid precision: 0.879800, valid loss: 89.289720
epoch: 2645, train precision: 0.998733, train loss: 10.393350, valid precision: 0.877800, valid loss: 92.173256
epoch: 2646, train precision: 0.998956, train loss: 10.322683, valid precision: 0.884400, valid loss: 88.412222
epoch: 2647, train precision: 0.999111, train loss: 10.276581, valid precision: 0.885800, valid loss: 90.841967
epoch: 2648, train precision: 0.999178, train loss: 10.259459, valid precision: 0.882800, valid loss: 90.265701
epoch: 2649, train precision: 0.998733, train loss: 10.409042, valid precision: 0.880000, valid loss: 88.538215
epoch: 2650, train precision: 0.999000, train loss: 10.314434, valid precision: 0.882400, valid loss: 89.319759
epoch: 2651, train precision: 0.999067, train loss: 10.312149, valid precision: 0.877800, valid loss: 91.963748
epoch: 2652, train precision: 0.999089, train loss: 10.301497, valid precision: 0.876600, valid loss: 91.208064
epoch: 2653, train precision: 0.998711, train loss: 10.411925, valid precision: 0.879200, valid loss: 91.030499
epoch: 2654, train precision: 0.999244, train loss: 10.291394, valid precision: 0.881800, valid loss: 90.056980
epoch: 2655, train precision: 0.999222, train loss: 10.318152, valid precision: 0.878600, valid loss: 91.671765
epoch: 2656, train precision: 0.999022, train loss: 10.324909, valid precision: 0.884200, valid loss: 89.021598
epoch: 2657, train precision: 0.999044, train loss: 10.287509, valid precision: 0.883600, valid loss: 89.149055
epoch: 2658, train precision: 0.999044, train loss: 10.284693, valid precision: 0.883000, valid loss: 90.292989
epoch: 2659, train precision: 0.999022, train loss: 10.358898, valid precision: 0.886400, valid loss: 89.665409
epoch: 2660, train precision: 0.999067, train loss: 10.321019, valid precision: 0.881800, valid loss: 90.547645
epoch: 2661, train precision: 0.999044, train loss: 10.277613, valid precision: 0.876600, valid loss: 92.494550
epoch: 2662, train precision: 0.998933, train loss: 10.319812, valid precision: 0.882200, valid loss: 90.783662
epoch: 2663, train precision: 0.999178, train loss: 10.286020, valid precision: 0.882000, valid loss: 89.913052
epoch: 2664, train precision: 0.999022, train loss: 10.281218, valid precision: 0.882400, valid loss: 87.953770
epoch: 2665, train precision: 0.999178, train loss: 10.264478, valid precision: 0.881200, valid loss: 87.468747
epoch: 2666, train precision: 0.998756, train loss: 10.404766, valid precision: 0.885600, valid loss: 87.276674
epoch: 2667, train precision: 0.999133, train loss: 10.242061, valid precision: 0.879400, valid loss: 87.479125
epoch: 2668, train precision: 0.998956, train loss: 10.338789, valid precision: 0.880000, valid loss: 88.097281
epoch: 2669, train precision: 0.999089, train loss: 10.321217, valid precision: 0.882600, valid loss: 87.125271
epoch: 2670, train precision: 0.999311, train loss: 10.258336, valid precision: 0.885000, valid loss: 86.851732
epoch: 2671, train precision: 0.999022, train loss: 10.324355, valid precision: 0.882800, valid loss: 88.076696
epoch: 2672, train precision: 0.999089, train loss: 10.275221, valid precision: 0.880600, valid loss: 89.155008
epoch: 2673, train precision: 0.998844, train loss: 10.372419, valid precision: 0.882000, valid loss: 89.058434
epoch: 2674, train precision: 0.999378, train loss: 10.226117, valid precision: 0.881600, valid loss: 86.953167
epoch: 2675, train precision: 0.998978, train loss: 10.368127, valid precision: 0.879000, valid loss: 90.460725
epoch: 2676, train precision: 0.998911, train loss: 10.374728, valid precision: 0.878800, valid loss: 89.741381
epoch: 2677, train precision: 0.999222, train loss: 10.256544, valid precision: 0.883000, valid loss: 87.842242
epoch: 2678, train precision: 0.999222, train loss: 10.288134, valid precision: 0.881000, valid loss: 86.783134
epoch: 2679, train precision: 0.999444, train loss: 10.204564, valid precision: 0.880200, valid loss: 88.581615
epoch: 2680, train precision: 0.999067, train loss: 10.270401, valid precision: 0.878000, valid loss: 89.209708
epoch: 2681, train precision: 0.999089, train loss: 10.296169, valid precision: 0.880200, valid loss: 88.572774
epoch: 2682, train precision: 0.999222, train loss: 10.239526, valid precision: 0.877000, valid loss: 90.753274
epoch: 2683, train precision: 0.998867, train loss: 10.390133, valid precision: 0.879000, valid loss: 90.119099
epoch: 2684, train precision: 0.998911, train loss: 10.335545, valid precision: 0.882600, valid loss: 89.165151
epoch: 2685, train precision: 0.998978, train loss: 10.328117, valid precision: 0.885000, valid loss: 86.918916
epoch: 2686, train precision: 0.999067, train loss: 10.279036, valid precision: 0.883200, valid loss: 87.232832
epoch: 2687, train precision: 0.999244, train loss: 10.285882, valid precision: 0.881000, valid loss: 87.625679
epoch: 2688, train precision: 0.999333, train loss: 10.225735, valid precision: 0.886200, valid loss: 89.119565
epoch: 2689, train precision: 0.999200, train loss: 10.240837, valid precision: 0.883200, valid loss: 88.330700
epoch: 2690, train precision: 0.999289, train loss: 10.322118, valid precision: 0.883400, valid loss: 89.593031
epoch: 2691, train precision: 0.999422, train loss: 10.229077, valid precision: 0.887000, valid loss: 87.707164
epoch: 2692, train precision: 0.999222, train loss: 10.278419, valid precision: 0.883200, valid loss: 89.020956
epoch: 2693, train precision: 0.998956, train loss: 10.311817, valid precision: 0.881000, valid loss: 89.035135
epoch: 2694, train precision: 0.998778, train loss: 10.365189, valid precision: 0.879600, valid loss: 89.834509
epoch: 2695, train precision: 0.998956, train loss: 10.415261, valid precision: 0.883600, valid loss: 89.422571
epoch: 2696, train precision: 0.998733, train loss: 10.429612, valid precision: 0.881200, valid loss: 90.909534
epoch: 2697, train precision: 0.999156, train loss: 10.253819, valid precision: 0.882400, valid loss: 89.206098
epoch: 2698, train precision: 0.999200, train loss: 10.268701, valid precision: 0.882600, valid loss: 88.289044
epoch: 2699, train precision: 0.998933, train loss: 10.370249, valid precision: 0.880000, valid loss: 89.453409
epoch: 2700, train precision: 0.999133, train loss: 10.278550, valid precision: 0.882400, valid loss: 88.934268
epoch: 2701, train precision: 0.998978, train loss: 10.262335, valid precision: 0.880600, valid loss: 91.482838
epoch: 2702, train precision: 0.999267, train loss: 10.251678, valid precision: 0.879800, valid loss: 88.346451
epoch: 2703, train precision: 0.998733, train loss: 10.385004, valid precision: 0.880800, valid loss: 91.347086
epoch: 2704, train precision: 0.998689, train loss: 10.443753, valid precision: 0.881000, valid loss: 90.388688
epoch: 2705, train precision: 0.999156, train loss: 10.312255, valid precision: 0.881400, valid loss: 89.123159
epoch: 2706, train precision: 0.998911, train loss: 10.349435, valid precision: 0.882600, valid loss: 88.471420
epoch: 2707, train precision: 0.999311, train loss: 10.231804, valid precision: 0.879800, valid loss: 87.966353
epoch: 2708, train precision: 0.999067, train loss: 10.300136, valid precision: 0.884200, valid loss: 88.041362
epoch: 2709, train precision: 0.999378, train loss: 10.235741, valid precision: 0.879400, valid loss: 91.077183
epoch: 2710, train precision: 0.998511, train loss: 10.458602, valid precision: 0.885400, valid loss: 91.075533
epoch: 2711, train precision: 0.999200, train loss: 10.240758, valid precision: 0.885400, valid loss: 88.231820
epoch: 2712, train precision: 0.999156, train loss: 10.333727, valid precision: 0.881400, valid loss: 89.076239
epoch: 2713, train precision: 0.999289, train loss: 10.295917, valid precision: 0.877400, valid loss: 88.937574
epoch: 2714, train precision: 0.999333, train loss: 10.264169, valid precision: 0.881400, valid loss: 87.996666
epoch: 2715, train precision: 0.999000, train loss: 10.261513, valid precision: 0.882400, valid loss: 89.077192
epoch: 2716, train precision: 0.999378, train loss: 10.172008, valid precision: 0.882000, valid loss: 88.054560
epoch: 2717, train precision: 0.998756, train loss: 10.340994, valid precision: 0.885800, valid loss: 89.029569
epoch: 2718, train precision: 0.999244, train loss: 10.272551, valid precision: 0.885000, valid loss: 89.538873
epoch: 2719, train precision: 0.998933, train loss: 10.312291, valid precision: 0.880000, valid loss: 91.580434
epoch: 2720, train precision: 0.999022, train loss: 10.333016, valid precision: 0.882200, valid loss: 91.536418
epoch: 2721, train precision: 0.998956, train loss: 10.321287, valid precision: 0.881200, valid loss: 90.986552
epoch: 2722, train precision: 0.999178, train loss: 10.265098, valid precision: 0.881400, valid loss: 89.236101
epoch: 2723, train precision: 0.998733, train loss: 10.375445, valid precision: 0.881200, valid loss: 89.767230
epoch: 2724, train precision: 0.999200, train loss: 10.242191, valid precision: 0.879800, valid loss: 90.311094
epoch: 2725, train precision: 0.998711, train loss: 10.381080, valid precision: 0.880400, valid loss: 91.177585
epoch: 2726, train precision: 0.999200, train loss: 10.289785, valid precision: 0.879600, valid loss: 92.586731
epoch: 2727, train precision: 0.999444, train loss: 10.213434, valid precision: 0.882600, valid loss: 89.946331
epoch: 2728, train precision: 0.999267, train loss: 10.221267, valid precision: 0.880800, valid loss: 91.243012
epoch: 2729, train precision: 0.999156, train loss: 10.264972, valid precision: 0.884400, valid loss: 90.843417
epoch: 2730, train precision: 0.999044, train loss: 10.269057, valid precision: 0.879800, valid loss: 90.698095
epoch: 2731, train precision: 0.998956, train loss: 10.318845, valid precision: 0.881400, valid loss: 89.380136
epoch: 2732, train precision: 0.998956, train loss: 10.322267, valid precision: 0.877400, valid loss: 90.852896
epoch: 2733, train precision: 0.998778, train loss: 10.409316, valid precision: 0.882400, valid loss: 90.035595
epoch: 2734, train precision: 0.998889, train loss: 10.275315, valid precision: 0.882600, valid loss: 89.776115
epoch: 2735, train precision: 0.999044, train loss: 10.307185, valid precision: 0.884200, valid loss: 90.410657
epoch: 2736, train precision: 0.998711, train loss: 10.435667, valid precision: 0.879000, valid loss: 91.603490
epoch: 2737, train precision: 0.999311, train loss: 10.211682, valid precision: 0.879000, valid loss: 89.647811
epoch: 2738, train precision: 0.998822, train loss: 10.321124, valid precision: 0.880800, valid loss: 91.831381
epoch: 2739, train precision: 0.998667, train loss: 10.431603, valid precision: 0.881800, valid loss: 90.468890
epoch: 2740, train precision: 0.999267, train loss: 10.229460, valid precision: 0.885800, valid loss: 88.796011
epoch: 2741, train precision: 0.998778, train loss: 10.333984, valid precision: 0.880800, valid loss: 91.107177
epoch: 2742, train precision: 0.998978, train loss: 10.299792, valid precision: 0.878600, valid loss: 93.786603
epoch: 2743, train precision: 0.999156, train loss: 10.198207, valid precision: 0.880800, valid loss: 91.058536
epoch: 2744, train precision: 0.998756, train loss: 10.388745, valid precision: 0.882000, valid loss: 90.684389
epoch: 2745, train precision: 0.999133, train loss: 10.265885, valid precision: 0.885200, valid loss: 90.695730
epoch: 2746, train precision: 0.999400, train loss: 10.230807, valid precision: 0.882200, valid loss: 89.432685
epoch: 2747, train precision: 0.999156, train loss: 10.279350, valid precision: 0.882800, valid loss: 89.571570
epoch: 2748, train precision: 0.999156, train loss: 10.287189, valid precision: 0.883000, valid loss: 89.250888
epoch: 2749, train precision: 0.999222, train loss: 10.241710, valid precision: 0.880000, valid loss: 88.555863
epoch: 2750, train precision: 0.998956, train loss: 10.307609, valid precision: 0.882000, valid loss: 90.007109
epoch: 2751, train precision: 0.998956, train loss: 10.290327, valid precision: 0.881400, valid loss: 89.004634
epoch: 2752, train precision: 0.998978, train loss: 10.287372, valid precision: 0.880400, valid loss: 89.476043
epoch: 2753, train precision: 0.998600, train loss: 10.457678, valid precision: 0.880800, valid loss: 93.325934
epoch: 2754, train precision: 0.998600, train loss: 10.485703, valid precision: 0.879200, valid loss: 91.677719
epoch: 2755, train precision: 0.999000, train loss: 10.260667, valid precision: 0.879800, valid loss: 92.624016
epoch: 2756, train precision: 0.999178, train loss: 10.244377, valid precision: 0.882400, valid loss: 90.244160
epoch: 2757, train precision: 0.999000, train loss: 10.290923, valid precision: 0.880600, valid loss: 91.573915
epoch: 2758, train precision: 0.999000, train loss: 10.272270, valid precision: 0.884400, valid loss: 90.057151
epoch: 2759, train precision: 0.999111, train loss: 10.294417, valid precision: 0.880200, valid loss: 88.675678
epoch: 2760, train precision: 0.999111, train loss: 10.390427, valid precision: 0.880400, valid loss: 92.070989
epoch: 2761, train precision: 0.999156, train loss: 10.236085, valid precision: 0.880000, valid loss: 88.047529
epoch: 2762, train precision: 0.998956, train loss: 10.403828, valid precision: 0.880800, valid loss: 91.070784
epoch: 2763, train precision: 0.999267, train loss: 10.230213, valid precision: 0.883600, valid loss: 89.244444
epoch: 2764, train precision: 0.998978, train loss: 10.280100, valid precision: 0.882200, valid loss: 90.380617
epoch: 2765, train precision: 0.998578, train loss: 10.468017, valid precision: 0.883800, valid loss: 89.073740
epoch: 2766, train precision: 0.999089, train loss: 10.297834, valid precision: 0.883400, valid loss: 88.045513
epoch: 2767, train precision: 0.999267, train loss: 10.223731, valid precision: 0.882000, valid loss: 90.621124
epoch: 2768, train precision: 0.998667, train loss: 10.391377, valid precision: 0.883800, valid loss: 88.927776
epoch: 2769, train precision: 0.998911, train loss: 10.369773, valid precision: 0.879400, valid loss: 89.416727
epoch: 2770, train precision: 0.998978, train loss: 10.302967, valid precision: 0.877800, valid loss: 88.725819
epoch: 2771, train precision: 0.999133, train loss: 10.266036, valid precision: 0.883800, valid loss: 86.526762
epoch: 2772, train precision: 0.999267, train loss: 10.219172, valid precision: 0.881600, valid loss: 88.002102
epoch: 2773, train precision: 0.998800, train loss: 10.390407, valid precision: 0.880400, valid loss: 91.721482
epoch: 2774, train precision: 0.998822, train loss: 10.372381, valid precision: 0.881600, valid loss: 88.513203
epoch: 2775, train precision: 0.999200, train loss: 10.223803, valid precision: 0.884600, valid loss: 88.947694
epoch: 2776, train precision: 0.998311, train loss: 10.483210, valid precision: 0.883800, valid loss: 88.376079
epoch: 2777, train precision: 0.998956, train loss: 10.313433, valid precision: 0.884600, valid loss: 88.943926
epoch: 2778, train precision: 0.998889, train loss: 10.392767, valid precision: 0.883400, valid loss: 88.499007
epoch: 2779, train precision: 0.999156, train loss: 10.313905, valid precision: 0.882600, valid loss: 89.280465
epoch: 2780, train precision: 0.999400, train loss: 10.211970, valid precision: 0.884400, valid loss: 88.534307
epoch: 2781, train precision: 0.998844, train loss: 10.417830, valid precision: 0.882400, valid loss: 90.341352
epoch: 2782, train precision: 0.999089, train loss: 10.256785, valid precision: 0.882800, valid loss: 88.881143
epoch: 2783, train precision: 0.999156, train loss: 10.257919, valid precision: 0.883600, valid loss: 91.204268
epoch: 2784, train precision: 0.999156, train loss: 10.264607, valid precision: 0.881200, valid loss: 91.461761
epoch: 2785, train precision: 0.999156, train loss: 10.258266, valid precision: 0.880000, valid loss: 90.080514
epoch: 2786, train precision: 0.998911, train loss: 10.333994, valid precision: 0.880200, valid loss: 91.426840
epoch: 2787, train precision: 0.998844, train loss: 10.341824, valid precision: 0.882000, valid loss: 91.791250
epoch: 2788, train precision: 0.999200, train loss: 10.287786, valid precision: 0.881000, valid loss: 90.372585
epoch: 2789, train precision: 0.999000, train loss: 10.314009, valid precision: 0.880800, valid loss: 91.570240
epoch: 2790, train precision: 0.998956, train loss: 10.283304, valid precision: 0.884600, valid loss: 90.562083
epoch: 2791, train precision: 0.998978, train loss: 10.328875, valid precision: 0.886400, valid loss: 91.344887
epoch: 2792, train precision: 0.998822, train loss: 10.316719, valid precision: 0.881400, valid loss: 87.870680
epoch: 2793, train precision: 0.998933, train loss: 10.355503, valid precision: 0.880000, valid loss: 88.646270
epoch: 2794, train precision: 0.999133, train loss: 10.285293, valid precision: 0.879600, valid loss: 88.795257
epoch: 2795, train precision: 0.999200, train loss: 10.238307, valid precision: 0.881600, valid loss: 89.639240
epoch: 2796, train precision: 0.998844, train loss: 10.389588, valid precision: 0.883400, valid loss: 92.432628
epoch: 2797, train precision: 0.999111, train loss: 10.266325, valid precision: 0.885800, valid loss: 88.271717
epoch: 2798, train precision: 0.998911, train loss: 10.339162, valid precision: 0.885800, valid loss: 88.251192
epoch: 2799, train precision: 0.999111, train loss: 10.261337, valid precision: 0.883800, valid loss: 91.260956
epoch: 2800, train precision: 0.999244, train loss: 10.216742, valid precision: 0.882000, valid loss: 89.850476
epoch: 2801, train precision: 0.999244, train loss: 10.245387, valid precision: 0.882400, valid loss: 89.365291
epoch: 2802, train precision: 0.998911, train loss: 10.360043, valid precision: 0.881000, valid loss: 85.109910
epoch: 2803, train precision: 0.998933, train loss: 10.301840, valid precision: 0.883000, valid loss: 89.091600
epoch: 2804, train precision: 0.998911, train loss: 10.334685, valid precision: 0.882000, valid loss: 88.467354
epoch: 2805, train precision: 0.998978, train loss: 10.305282, valid precision: 0.881200, valid loss: 88.637394
epoch: 2806, train precision: 0.999133, train loss: 10.243958, valid precision: 0.882600, valid loss: 90.277760
epoch: 2807, train precision: 0.999222, train loss: 10.223396, valid precision: 0.884000, valid loss: 91.555988
epoch: 2808, train precision: 0.999000, train loss: 10.259725, valid precision: 0.883000, valid loss: 89.621813
epoch: 2809, train precision: 0.999156, train loss: 10.336804, valid precision: 0.883800, valid loss: 88.742915
epoch: 2810, train precision: 0.998778, train loss: 10.356816, valid precision: 0.883000, valid loss: 87.913664
epoch: 2811, train precision: 0.999022, train loss: 10.293328, valid precision: 0.882000, valid loss: 90.009087
epoch: 2812, train precision: 0.999222, train loss: 10.268615, valid precision: 0.882600, valid loss: 89.962968
epoch: 2813, train precision: 0.999178, train loss: 10.250180, valid precision: 0.881600, valid loss: 88.225862
epoch: 2814, train precision: 0.999089, train loss: 10.329913, valid precision: 0.883600, valid loss: 88.351157
epoch: 2815, train precision: 0.999178, train loss: 10.258462, valid precision: 0.882600, valid loss: 88.294737
epoch: 2816, train precision: 0.999289, train loss: 10.213736, valid precision: 0.885000, valid loss: 86.706789
epoch: 2817, train precision: 0.998978, train loss: 10.285260, valid precision: 0.887200, valid loss: 86.430398
epoch: 2818, train precision: 0.999222, train loss: 10.260738, valid precision: 0.885200, valid loss: 86.664007
epoch: 2819, train precision: 0.999022, train loss: 10.293765, valid precision: 0.879200, valid loss: 88.908749
epoch: 2820, train precision: 0.999067, train loss: 10.253900, valid precision: 0.881000, valid loss: 90.273219
epoch: 2821, train precision: 0.998978, train loss: 10.265893, valid precision: 0.883200, valid loss: 88.264049
epoch: 2822, train precision: 0.999156, train loss: 10.224779, valid precision: 0.882400, valid loss: 88.046222
epoch: 2823, train precision: 0.999044, train loss: 10.284570, valid precision: 0.885400, valid loss: 87.658006
epoch: 2824, train precision: 0.999133, train loss: 10.270021, valid precision: 0.883000, valid loss: 86.589928
epoch: 2825, train precision: 0.998933, train loss: 10.305431, valid precision: 0.881200, valid loss: 89.152546
epoch: 2826, train precision: 0.999000, train loss: 10.355033, valid precision: 0.883000, valid loss: 86.864758
epoch: 2827, train precision: 0.998978, train loss: 10.252315, valid precision: 0.878200, valid loss: 90.780856
epoch: 2828, train precision: 0.999311, train loss: 10.231234, valid precision: 0.881000, valid loss: 90.141822
epoch: 2829, train precision: 0.999356, train loss: 10.198691, valid precision: 0.882800, valid loss: 87.716481
epoch: 2830, train precision: 0.999156, train loss: 10.270107, valid precision: 0.881200, valid loss: 89.028783
epoch: 2831, train precision: 0.998911, train loss: 10.303692, valid precision: 0.877200, valid loss: 91.577198
epoch: 2832, train precision: 0.999400, train loss: 10.179804, valid precision: 0.878600, valid loss: 89.060404
epoch: 2833, train precision: 0.999289, train loss: 10.256662, valid precision: 0.882200, valid loss: 87.062296
epoch: 2834, train precision: 0.999111, train loss: 10.255840, valid precision: 0.885200, valid loss: 86.662427
epoch: 2835, train precision: 0.998689, train loss: 10.392596, valid precision: 0.880200, valid loss: 88.071202
epoch: 2836, train precision: 0.998822, train loss: 10.328427, valid precision: 0.880800, valid loss: 88.874463
epoch: 2837, train precision: 0.999178, train loss: 10.206775, valid precision: 0.880200, valid loss: 88.592786
epoch: 2838, train precision: 0.999067, train loss: 10.270553, valid precision: 0.879400, valid loss: 88.824435
epoch: 2839, train precision: 0.999000, train loss: 10.343336, valid precision: 0.879800, valid loss: 90.000358
epoch: 2840, train precision: 0.999111, train loss: 10.238579, valid precision: 0.880200, valid loss: 87.060664
epoch: 2841, train precision: 0.999111, train loss: 10.203119, valid precision: 0.877800, valid loss: 89.161588
epoch: 2842, train precision: 0.998956, train loss: 10.383718, valid precision: 0.881600, valid loss: 89.929745
epoch: 2843, train precision: 0.999089, train loss: 10.258404, valid precision: 0.882200, valid loss: 87.604063
epoch: 2844, train precision: 0.999044, train loss: 10.259219, valid precision: 0.881600, valid loss: 91.220333
epoch: 2845, train precision: 0.998733, train loss: 10.325212, valid precision: 0.883000, valid loss: 91.670871
epoch: 2846, train precision: 0.999022, train loss: 10.298979, valid precision: 0.879000, valid loss: 91.869320
epoch: 2847, train precision: 0.999244, train loss: 10.262480, valid precision: 0.885200, valid loss: 90.114546
epoch: 2848, train precision: 0.999067, train loss: 10.252312, valid precision: 0.883800, valid loss: 89.583173
epoch: 2849, train precision: 0.998822, train loss: 10.268215, valid precision: 0.881000, valid loss: 89.362301
epoch: 2850, train precision: 0.999244, train loss: 10.276401, valid precision: 0.881800, valid loss: 90.304437
epoch: 2851, train precision: 0.999022, train loss: 10.260988, valid precision: 0.877400, valid loss: 91.455467
epoch: 2852, train precision: 0.999044, train loss: 10.283845, valid precision: 0.879600, valid loss: 88.687475
epoch: 2853, train precision: 0.998844, train loss: 10.370652, valid precision: 0.880800, valid loss: 88.910208
epoch: 2854, train precision: 0.999333, train loss: 10.162577, valid precision: 0.879000, valid loss: 90.561413
epoch: 2855, train precision: 0.999067, train loss: 10.305182, valid precision: 0.883000, valid loss: 87.297733
epoch: 2856, train precision: 0.998956, train loss: 10.298829, valid precision: 0.884400, valid loss: 87.672878
epoch: 2857, train precision: 0.999222, train loss: 10.248196, valid precision: 0.879800, valid loss: 89.406844
epoch: 2858, train precision: 0.999022, train loss: 10.259564, valid precision: 0.880400, valid loss: 89.426566
epoch: 2859, train precision: 0.998711, train loss: 10.353416, valid precision: 0.881600, valid loss: 91.745294
epoch: 2860, train precision: 0.999333, train loss: 10.188712, valid precision: 0.877200, valid loss: 90.579633
epoch: 2861, train precision: 0.999311, train loss: 10.229604, valid precision: 0.880400, valid loss: 89.447826
epoch: 2862, train precision: 0.998822, train loss: 10.333923, valid precision: 0.880600, valid loss: 90.335003
epoch: 2863, train precision: 0.998978, train loss: 10.345623, valid precision: 0.879800, valid loss: 91.283046
epoch: 2864, train precision: 0.998667, train loss: 10.408813, valid precision: 0.874400, valid loss: 91.878925
epoch: 2865, train precision: 0.998800, train loss: 10.334301, valid precision: 0.880600, valid loss: 89.042682
epoch: 2866, train precision: 0.999178, train loss: 10.239593, valid precision: 0.878800, valid loss: 91.649108
epoch: 2867, train precision: 0.999022, train loss: 10.235599, valid precision: 0.874800, valid loss: 91.510038
epoch: 2868, train precision: 0.999133, train loss: 10.277039, valid precision: 0.878600, valid loss: 92.233129
epoch: 2869, train precision: 0.998911, train loss: 10.271715, valid precision: 0.879600, valid loss: 91.081519
epoch: 2870, train precision: 0.998978, train loss: 10.321647, valid precision: 0.880000, valid loss: 92.739664
epoch: 2871, train precision: 0.999133, train loss: 10.285878, valid precision: 0.880800, valid loss: 89.892158
epoch: 2872, train precision: 0.998889, train loss: 10.332851, valid precision: 0.880200, valid loss: 87.973925
epoch: 2873, train precision: 0.999289, train loss: 10.169929, valid precision: 0.878200, valid loss: 87.813770
epoch: 2874, train precision: 0.998689, train loss: 10.340136, valid precision: 0.880600, valid loss: 88.429465
epoch: 2875, train precision: 0.998600, train loss: 10.375941, valid precision: 0.879800, valid loss: 89.708914
epoch: 2876, train precision: 0.998956, train loss: 10.407826, valid precision: 0.880600, valid loss: 90.135769
epoch: 2877, train precision: 0.999022, train loss: 10.311262, valid precision: 0.880200, valid loss: 89.201237
epoch: 2878, train precision: 0.998978, train loss: 10.300643, valid precision: 0.881000, valid loss: 88.794739
epoch: 2879, train precision: 0.999178, train loss: 10.222937, valid precision: 0.881400, valid loss: 91.727164
epoch: 2880, train precision: 0.999044, train loss: 10.262346, valid precision: 0.881800, valid loss: 88.352831
epoch: 2881, train precision: 0.998667, train loss: 10.332276, valid precision: 0.883200, valid loss: 90.359626
epoch: 2882, train precision: 0.999244, train loss: 10.175151, valid precision: 0.877400, valid loss: 91.526947
epoch: 2883, train precision: 0.999178, train loss: 10.173216, valid precision: 0.881200, valid loss: 91.530405
epoch: 2884, train precision: 0.999244, train loss: 10.210531, valid precision: 0.881400, valid loss: 91.511199
epoch: 2885, train precision: 0.998556, train loss: 10.370266, valid precision: 0.878200, valid loss: 91.981579
epoch: 2886, train precision: 0.998978, train loss: 10.277698, valid precision: 0.879400, valid loss: 92.799684
epoch: 2887, train precision: 0.999156, train loss: 10.217438, valid precision: 0.882200, valid loss: 91.242197
epoch: 2888, train precision: 0.999133, train loss: 10.265281, valid precision: 0.880800, valid loss: 92.911498
epoch: 2889, train precision: 0.999333, train loss: 10.178744, valid precision: 0.882600, valid loss: 88.411074
epoch: 2890, train precision: 0.998956, train loss: 10.258386, valid precision: 0.879600, valid loss: 91.788984
epoch: 2891, train precision: 0.999178, train loss: 10.250907, valid precision: 0.882200, valid loss: 89.066498
epoch: 2892, train precision: 0.999222, train loss: 10.225062, valid precision: 0.882400, valid loss: 87.479437
epoch: 2893, train precision: 0.999022, train loss: 10.277488, valid precision: 0.880600, valid loss: 88.193505
epoch: 2894, train precision: 0.999400, train loss: 10.194529, valid precision: 0.886400, valid loss: 86.714676
epoch: 2895, train precision: 0.998911, train loss: 10.357933, valid precision: 0.881200, valid loss: 88.986857
epoch: 2896, train precision: 0.998800, train loss: 10.316223, valid precision: 0.881200, valid loss: 89.554082
epoch: 2897, train precision: 0.999133, train loss: 10.216405, valid precision: 0.883000, valid loss: 89.757425
epoch: 2898, train precision: 0.998711, train loss: 10.379633, valid precision: 0.883400, valid loss: 90.023555
epoch: 2899, train precision: 0.998711, train loss: 10.329771, valid precision: 0.879400, valid loss: 94.261585
epoch: 2900, train precision: 0.999022, train loss: 10.275480, valid precision: 0.877200, valid loss: 93.309194
epoch: 2901, train precision: 0.999267, train loss: 10.193747, valid precision: 0.882600, valid loss: 90.277065
epoch: 2902, train precision: 0.999222, train loss: 10.286598, valid precision: 0.885200, valid loss: 89.686385
epoch: 2903, train precision: 0.998978, train loss: 10.261372, valid precision: 0.881600, valid loss: 89.763617
epoch: 2904, train precision: 0.999356, train loss: 10.207768, valid precision: 0.880200, valid loss: 87.190013
epoch: 2905, train precision: 0.998933, train loss: 10.255740, valid precision: 0.880400, valid loss: 88.867781
epoch: 2906, train precision: 0.999111, train loss: 10.280225, valid precision: 0.876400, valid loss: 89.197132
epoch: 2907, train precision: 0.999267, train loss: 10.259823, valid precision: 0.877200, valid loss: 89.569640
epoch: 2908, train precision: 0.999089, train loss: 10.238520, valid precision: 0.877200, valid loss: 89.702951
epoch: 2909, train precision: 0.998956, train loss: 10.361984, valid precision: 0.880400, valid loss: 89.422376
epoch: 2910, train precision: 0.999200, train loss: 10.249925, valid precision: 0.884600, valid loss: 89.095255
epoch: 2911, train precision: 0.998911, train loss: 10.316787, valid precision: 0.878600, valid loss: 88.581946
epoch: 2912, train precision: 0.999222, train loss: 10.186262, valid precision: 0.880600, valid loss: 89.970611
epoch: 2913, train precision: 0.999200, train loss: 10.227940, valid precision: 0.880800, valid loss: 87.182207
epoch: 2914, train precision: 0.998911, train loss: 10.310058, valid precision: 0.877800, valid loss: 89.593672
epoch: 2915, train precision: 0.999111, train loss: 10.250881, valid precision: 0.882400, valid loss: 86.945850
epoch: 2916, train precision: 0.999156, train loss: 10.221200, valid precision: 0.883400, valid loss: 89.307215
epoch: 2917, train precision: 0.999156, train loss: 10.217691, valid precision: 0.881800, valid loss: 90.379546
epoch: 2918, train precision: 0.998756, train loss: 10.379425, valid precision: 0.878200, valid loss: 90.671150
epoch: 2919, train precision: 0.998756, train loss: 10.394409, valid precision: 0.873000, valid loss: 92.309068
epoch: 2920, train precision: 0.998533, train loss: 10.421631, valid precision: 0.878600, valid loss: 91.236147
epoch: 2921, train precision: 0.999244, train loss: 10.237211, valid precision: 0.881200, valid loss: 90.159164
epoch: 2922, train precision: 0.999311, train loss: 10.258618, valid precision: 0.881000, valid loss: 87.938093
epoch: 2923, train precision: 0.998800, train loss: 10.336990, valid precision: 0.877400, valid loss: 91.180500
epoch: 2924, train precision: 0.999111, train loss: 10.225689, valid precision: 0.875400, valid loss: 90.982061
epoch: 2925, train precision: 0.998978, train loss: 10.291017, valid precision: 0.875400, valid loss: 91.160715
epoch: 2926, train precision: 0.999156, train loss: 10.291526, valid precision: 0.878400, valid loss: 89.939004
epoch: 2927, train precision: 0.998889, train loss: 10.357973, valid precision: 0.882600, valid loss: 89.956277
epoch: 2928, train precision: 0.999067, train loss: 10.278372, valid precision: 0.879200, valid loss: 87.799692
epoch: 2929, train precision: 0.999333, train loss: 10.179413, valid precision: 0.881200, valid loss: 88.204213
epoch: 2930, train precision: 0.999289, train loss: 10.198317, valid precision: 0.880000, valid loss: 86.866338
epoch: 2931, train precision: 0.998911, train loss: 10.360395, valid precision: 0.878000, valid loss: 88.270887
epoch: 2932, train precision: 0.999067, train loss: 10.322830, valid precision: 0.883000, valid loss: 88.303404
epoch: 2933, train precision: 0.999378, train loss: 10.151182, valid precision: 0.879400, valid loss: 89.754835
epoch: 2934, train precision: 0.998667, train loss: 10.352996, valid precision: 0.880400, valid loss: 90.400673
epoch: 2935, train precision: 0.999378, train loss: 10.174655, valid precision: 0.882800, valid loss: 91.357343
epoch: 2936, train precision: 0.998778, train loss: 10.336668, valid precision: 0.878400, valid loss: 89.082469
epoch: 2937, train precision: 0.999089, train loss: 10.248945, valid precision: 0.880600, valid loss: 88.131828
epoch: 2938, train precision: 0.999044, train loss: 10.258050, valid precision: 0.877400, valid loss: 86.805904
epoch: 2939, train precision: 0.999044, train loss: 10.298684, valid precision: 0.881400, valid loss: 89.019679
epoch: 2940, train precision: 0.999044, train loss: 10.239747, valid precision: 0.880800, valid loss: 88.988419
epoch: 2941, train precision: 0.998933, train loss: 10.251873, valid precision: 0.881800, valid loss: 85.849989
epoch: 2942, train precision: 0.999067, train loss: 10.246097, valid precision: 0.879400, valid loss: 86.351528
epoch: 2943, train precision: 0.999222, train loss: 10.238386, valid precision: 0.879200, valid loss: 85.946634
epoch: 2944, train precision: 0.999267, train loss: 10.151595, valid precision: 0.879400, valid loss: 89.550299
epoch: 2945, train precision: 0.998911, train loss: 10.264326, valid precision: 0.879400, valid loss: 90.087700
epoch: 2946, train precision: 0.998800, train loss: 10.307173, valid precision: 0.877600, valid loss: 89.641911
epoch: 2947, train precision: 0.999000, train loss: 10.242525, valid precision: 0.882600, valid loss: 90.030373
epoch: 2948, train precision: 0.999178, train loss: 10.189813, valid precision: 0.884000, valid loss: 88.738653
epoch: 2949, train precision: 0.999067, train loss: 10.321408, valid precision: 0.880000, valid loss: 86.866459
epoch: 2950, train precision: 0.998844, train loss: 10.298396, valid precision: 0.878400, valid loss: 88.005180
epoch: 2951, train precision: 0.999156, train loss: 10.204973, valid precision: 0.883000, valid loss: 87.177518
epoch: 2952, train precision: 0.999044, train loss: 10.263480, valid precision: 0.885400, valid loss: 87.662628
epoch: 2953, train precision: 0.999044, train loss: 10.244558, valid precision: 0.881000, valid loss: 89.315502
epoch: 2954, train precision: 0.999067, train loss: 10.256613, valid precision: 0.879600, valid loss: 89.840794
epoch: 2955, train precision: 0.999467, train loss: 10.165713, valid precision: 0.884000, valid loss: 86.319469
epoch: 2956, train precision: 0.999022, train loss: 10.185001, valid precision: 0.878400, valid loss: 89.570757
epoch: 2957, train precision: 0.999178, train loss: 10.209217, valid precision: 0.883600, valid loss: 87.268608
epoch: 2958, train precision: 0.999022, train loss: 10.284460, valid precision: 0.879000, valid loss: 87.903363
epoch: 2959, train precision: 0.999311, train loss: 10.171389, valid precision: 0.882400, valid loss: 88.349633
epoch: 2960, train precision: 0.999200, train loss: 10.153238, valid precision: 0.879400, valid loss: 87.113466
epoch: 2961, train precision: 0.999178, train loss: 10.211030, valid precision: 0.879600, valid loss: 89.638190
epoch: 2962, train precision: 0.999311, train loss: 10.185076, valid precision: 0.883200, valid loss: 86.900676
epoch: 2963, train precision: 0.999133, train loss: 10.229448, valid precision: 0.880600, valid loss: 87.966200
epoch: 2964, train precision: 0.999089, train loss: 10.227467, valid precision: 0.883400, valid loss: 86.942502
epoch: 2965, train precision: 0.999089, train loss: 10.236453, valid precision: 0.884600, valid loss: 87.205822
epoch: 2966, train precision: 0.999044, train loss: 10.198521, valid precision: 0.879200, valid loss: 87.296431
epoch: 2967, train precision: 0.999333, train loss: 10.159953, valid precision: 0.878000, valid loss: 84.646642
epoch: 2968, train precision: 0.999089, train loss: 10.281533, valid precision: 0.882600, valid loss: 85.210519
epoch: 2969, train precision: 0.999111, train loss: 10.238523, valid precision: 0.877800, valid loss: 87.293569
epoch: 2970, train precision: 0.999156, train loss: 10.224501, valid precision: 0.881200, valid loss: 88.235844
epoch: 2971, train precision: 0.998978, train loss: 10.238792, valid precision: 0.879600, valid loss: 88.446366
epoch: 2972, train precision: 0.998889, train loss: 10.321603, valid precision: 0.880800, valid loss: 87.840324
epoch: 2973, train precision: 0.998889, train loss: 10.287475, valid precision: 0.876800, valid loss: 89.740599
epoch: 2974, train precision: 0.999267, train loss: 10.172349, valid precision: 0.879600, valid loss: 87.610792
epoch: 2975, train precision: 0.998711, train loss: 10.300478, valid precision: 0.881000, valid loss: 89.000344
epoch: 2976, train precision: 0.999178, train loss: 10.245238, valid precision: 0.879800, valid loss: 90.272361
epoch: 2977, train precision: 0.998956, train loss: 10.332453, valid precision: 0.882600, valid loss: 91.318016
epoch: 2978, train precision: 0.999400, train loss: 10.123782, valid precision: 0.888200, valid loss: 88.040081
epoch: 2979, train precision: 0.998178, train loss: 10.528846, valid precision: 0.878400, valid loss: 92.349057
epoch: 2980, train precision: 0.998933, train loss: 10.255048, valid precision: 0.884800, valid loss: 88.487373
epoch: 2981, train precision: 0.998867, train loss: 10.265414, valid precision: 0.881000, valid loss: 87.974191
epoch: 2982, train precision: 0.998889, train loss: 10.295305, valid precision: 0.880200, valid loss: 88.859657
epoch: 2983, train precision: 0.999044, train loss: 10.245811, valid precision: 0.876600, valid loss: 89.421255
epoch: 2984, train precision: 0.999356, train loss: 10.180038, valid precision: 0.879000, valid loss: 88.591329
epoch: 2985, train precision: 0.999156, train loss: 10.272904, valid precision: 0.878800, valid loss: 89.336272
epoch: 2986, train precision: 0.999378, train loss: 10.154163, valid precision: 0.876800, valid loss: 92.484597
epoch: 2987, train precision: 0.998911, train loss: 10.273691, valid precision: 0.880200, valid loss: 89.764784
epoch: 2988, train precision: 0.998933, train loss: 10.290232, valid precision: 0.879400, valid loss: 88.908090
epoch: 2989, train precision: 0.999067, train loss: 10.295594, valid precision: 0.881200, valid loss: 89.891836
epoch: 2990, train precision: 0.999222, train loss: 10.155323, valid precision: 0.880800, valid loss: 89.719004
epoch: 2991, train precision: 0.998956, train loss: 10.345124, valid precision: 0.882000, valid loss: 87.716048
epoch: 2992, train precision: 0.999200, train loss: 10.213444, valid precision: 0.881600, valid loss: 89.781343
epoch: 2993, train precision: 0.999111, train loss: 10.204307, valid precision: 0.880400, valid loss: 90.235259
epoch: 2994, train precision: 0.998889, train loss: 10.280821, valid precision: 0.879400, valid loss: 92.262834
epoch: 2995, train precision: 0.998911, train loss: 10.242516, valid precision: 0.881200, valid loss: 89.334584
epoch: 2996, train precision: 0.998733, train loss: 10.334741, valid precision: 0.880600, valid loss: 87.857103
epoch: 2997, train precision: 0.999311, train loss: 10.179365, valid precision: 0.884600, valid loss: 88.591621
epoch: 2998, train precision: 0.998933, train loss: 10.313423, valid precision: 0.881600, valid loss: 89.468014
epoch: 2999, train precision: 0.999267, train loss: 10.172641, valid precision: 0.882400, valid loss: 88.828365
epoch: 3000, train precision: 0.999244, train loss: 10.219016, valid precision: 0.881800, valid loss: 87.613389
epoch: 3001, train precision: 0.999111, train loss: 10.247957, valid precision: 0.883000, valid loss: 89.245705
epoch: 3002, train precision: 0.998644, train loss: 10.358228, valid precision: 0.881800, valid loss: 90.110206
epoch: 3003, train precision: 0.998933, train loss: 10.242225, valid precision: 0.881400, valid loss: 88.985791
epoch: 3004, train precision: 0.999044, train loss: 10.271640, valid precision: 0.882000, valid loss: 89.629384
epoch: 3005, train precision: 0.998911, train loss: 10.323336, valid precision: 0.884200, valid loss: 89.262392
epoch: 3006, train precision: 0.998778, train loss: 10.368684, valid precision: 0.884800, valid loss: 85.180478
epoch: 3007, train precision: 0.999044, train loss: 10.250761, valid precision: 0.882800, valid loss: 87.359745
epoch: 3008, train precision: 0.999111, train loss: 10.209468, valid precision: 0.882200, valid loss: 87.721069
epoch: 3009, train precision: 0.998756, train loss: 10.281045, valid precision: 0.883200, valid loss: 88.806551
epoch: 3010, train precision: 0.999156, train loss: 10.193091, valid precision: 0.881400, valid loss: 87.767851
epoch: 3011, train precision: 0.999156, train loss: 10.185921, valid precision: 0.885400, valid loss: 89.719842
epoch: 3012, train precision: 0.999067, train loss: 10.248407, valid precision: 0.881800, valid loss: 91.801486
epoch: 3013, train precision: 0.998733, train loss: 10.378468, valid precision: 0.879400, valid loss: 93.675027
epoch: 3014, train precision: 0.998822, train loss: 10.356725, valid precision: 0.881600, valid loss: 90.975461
epoch: 3015, train precision: 0.999111, train loss: 10.186339, valid precision: 0.883800, valid loss: 88.742229
epoch: 3016, train precision: 0.999178, train loss: 10.173590, valid precision: 0.881600, valid loss: 89.665289
epoch: 3017, train precision: 0.999067, train loss: 10.245928, valid precision: 0.877400, valid loss: 92.392378
epoch: 3018, train precision: 0.999089, train loss: 10.252486, valid precision: 0.883800, valid loss: 89.384746
epoch: 3019, train precision: 0.999200, train loss: 10.190429, valid precision: 0.883600, valid loss: 88.175587
epoch: 3020, train precision: 0.999200, train loss: 10.144120, valid precision: 0.882400, valid loss: 88.318345
epoch: 3021, train precision: 0.999178, train loss: 10.245426, valid precision: 0.883600, valid loss: 89.438635
epoch: 3022, train precision: 0.999022, train loss: 10.222776, valid precision: 0.883000, valid loss: 91.798595
epoch: 3023, train precision: 0.999067, train loss: 10.270254, valid precision: 0.879800, valid loss: 90.887471
epoch: 3024, train precision: 0.999467, train loss: 10.120501, valid precision: 0.880600, valid loss: 89.749804
epoch: 3025, train precision: 0.999022, train loss: 10.225888, valid precision: 0.880400, valid loss: 92.565748
epoch: 3026, train precision: 0.999578, train loss: 10.087782, valid precision: 0.883600, valid loss: 87.675617
epoch: 3027, train precision: 0.998956, train loss: 10.268099, valid precision: 0.880200, valid loss: 87.730212
epoch: 3028, train precision: 0.999089, train loss: 10.244349, valid precision: 0.877600, valid loss: 89.517854
epoch: 3029, train precision: 0.999044, train loss: 10.214293, valid precision: 0.880000, valid loss: 86.968219
epoch: 3030, train precision: 0.998933, train loss: 10.280477, valid precision: 0.881400, valid loss: 85.531084
epoch: 3031, train precision: 0.999178, train loss: 10.202371, valid precision: 0.882000, valid loss: 88.259598
epoch: 3032, train precision: 0.999378, train loss: 10.132275, valid precision: 0.882800, valid loss: 86.611224
epoch: 3033, train precision: 0.999111, train loss: 10.236686, valid precision: 0.882000, valid loss: 89.716555
epoch: 3034, train precision: 0.998978, train loss: 10.255137, valid precision: 0.884200, valid loss: 88.919469
epoch: 3035, train precision: 0.998733, train loss: 10.382296, valid precision: 0.880600, valid loss: 90.997690
epoch: 3036, train precision: 0.998756, train loss: 10.287366, valid precision: 0.875200, valid loss: 91.506012
epoch: 3037, train precision: 0.999289, train loss: 10.143333, valid precision: 0.883400, valid loss: 90.232103
epoch: 3038, train precision: 0.998844, train loss: 10.271592, valid precision: 0.878400, valid loss: 90.466480
epoch: 3039, train precision: 0.998733, train loss: 10.295408, valid precision: 0.877400, valid loss: 94.917185
epoch: 3040, train precision: 0.999000, train loss: 10.256823, valid precision: 0.873200, valid loss: 91.555204
epoch: 3041, train precision: 0.999111, train loss: 10.231043, valid precision: 0.874000, valid loss: 91.102052
epoch: 3042, train precision: 0.999333, train loss: 10.133563, valid precision: 0.879200, valid loss: 91.276196
epoch: 3043, train precision: 0.999289, train loss: 10.172380, valid precision: 0.879400, valid loss: 89.928952
epoch: 3044, train precision: 0.999089, train loss: 10.131019, valid precision: 0.877400, valid loss: 94.120352
epoch: 3045, train precision: 0.999244, train loss: 10.189632, valid precision: 0.878800, valid loss: 93.875486
epoch: 3046, train precision: 0.999267, train loss: 10.124557, valid precision: 0.878800, valid loss: 92.533793
epoch: 3047, train precision: 0.999289, train loss: 10.141724, valid precision: 0.882600, valid loss: 92.758036
epoch: 3048, train precision: 0.999133, train loss: 10.200397, valid precision: 0.881400, valid loss: 90.833427
epoch: 3049, train precision: 0.999067, train loss: 10.247619, valid precision: 0.882800, valid loss: 90.235173
epoch: 3050, train precision: 0.999311, train loss: 10.114753, valid precision: 0.883800, valid loss: 88.899672
epoch: 3051, train precision: 0.998911, train loss: 10.294873, valid precision: 0.881400, valid loss: 89.308352
epoch: 3052, train precision: 0.999067, train loss: 10.193079, valid precision: 0.879400, valid loss: 92.057830
epoch: 3053, train precision: 0.999022, train loss: 10.257664, valid precision: 0.883200, valid loss: 90.600662
epoch: 3054, train precision: 0.999089, train loss: 10.227099, valid precision: 0.882400, valid loss: 92.017079
epoch: 3055, train precision: 0.999044, train loss: 10.199177, valid precision: 0.884400, valid loss: 88.056552
epoch: 3056, train precision: 0.999533, train loss: 10.065090, valid precision: 0.884400, valid loss: 89.951205
epoch: 3057, train precision: 0.998578, train loss: 10.406310, valid precision: 0.877200, valid loss: 93.066557
epoch: 3058, train precision: 0.998889, train loss: 10.213866, valid precision: 0.883800, valid loss: 92.227131
epoch: 3059, train precision: 0.998978, train loss: 10.194222, valid precision: 0.882800, valid loss: 90.684099
epoch: 3060, train precision: 0.999067, train loss: 10.226099, valid precision: 0.880600, valid loss: 90.650568
epoch: 3061, train precision: 0.998889, train loss: 10.259685, valid precision: 0.876000, valid loss: 90.579489
epoch: 3062, train precision: 0.999156, train loss: 10.189816, valid precision: 0.880000, valid loss: 92.043706
epoch: 3063, train precision: 0.998711, train loss: 10.345630, valid precision: 0.880000, valid loss: 93.066973
epoch: 3064, train precision: 0.999356, train loss: 10.143782, valid precision: 0.882200, valid loss: 92.080125
epoch: 3065, train precision: 0.999044, train loss: 10.221430, valid precision: 0.881400, valid loss: 91.502302
epoch: 3066, train precision: 0.999133, train loss: 10.232044, valid precision: 0.881000, valid loss: 90.144947
epoch: 3067, train precision: 0.998800, train loss: 10.282400, valid precision: 0.880600, valid loss: 91.122794
epoch: 3068, train precision: 0.999133, train loss: 10.197698, valid precision: 0.879600, valid loss: 90.339210
epoch: 3069, train precision: 0.999111, train loss: 10.188609, valid precision: 0.881600, valid loss: 90.732301
epoch: 3070, train precision: 0.998511, train loss: 10.307461, valid precision: 0.881000, valid loss: 92.167112
epoch: 3071, train precision: 0.999000, train loss: 10.228059, valid precision: 0.882600, valid loss: 91.773170
epoch: 3072, train precision: 0.999244, train loss: 10.159743, valid precision: 0.882000, valid loss: 91.466731
epoch: 3073, train precision: 0.999289, train loss: 10.156114, valid precision: 0.877800, valid loss: 92.992980
epoch: 3074, train precision: 0.999067, train loss: 10.214812, valid precision: 0.882200, valid loss: 92.182054
epoch: 3075, train precision: 0.998822, train loss: 10.278576, valid precision: 0.874400, valid loss: 94.449026
epoch: 3076, train precision: 0.998911, train loss: 10.245051, valid precision: 0.879400, valid loss: 92.496977
epoch: 3077, train precision: 0.998578, train loss: 10.367027, valid precision: 0.880600, valid loss: 94.064285
epoch: 3078, train precision: 0.999067, train loss: 10.183573, valid precision: 0.878000, valid loss: 90.564629
epoch: 3079, train precision: 0.999022, train loss: 10.228597, valid precision: 0.878400, valid loss: 91.112332
epoch: 3080, train precision: 0.999133, train loss: 10.246899, valid precision: 0.882800, valid loss: 90.361314
epoch: 3081, train precision: 0.998978, train loss: 10.247164, valid precision: 0.879600, valid loss: 90.748020
epoch: 3082, train precision: 0.999089, train loss: 10.191936, valid precision: 0.876800, valid loss: 93.535158
epoch: 3083, train precision: 0.999111, train loss: 10.230055, valid precision: 0.879400, valid loss: 92.369147
epoch: 3084, train precision: 0.998844, train loss: 10.251769, valid precision: 0.881800, valid loss: 91.972500
epoch: 3085, train precision: 0.998800, train loss: 10.333646, valid precision: 0.879800, valid loss: 93.874788
epoch: 3086, train precision: 0.998956, train loss: 10.226828, valid precision: 0.879400, valid loss: 91.173154
epoch: 3087, train precision: 0.999422, train loss: 10.137337, valid precision: 0.884800, valid loss: 89.136451
epoch: 3088, train precision: 0.999178, train loss: 10.177040, valid precision: 0.882400, valid loss: 89.789781
epoch: 3089, train precision: 0.998911, train loss: 10.251855, valid precision: 0.877800, valid loss: 92.446812
epoch: 3090, train precision: 0.999089, train loss: 10.228536, valid precision: 0.879400, valid loss: 93.301557
epoch: 3091, train precision: 0.999378, train loss: 10.164721, valid precision: 0.881400, valid loss: 89.033986
epoch: 3092, train precision: 0.998867, train loss: 10.249761, valid precision: 0.875800, valid loss: 92.799484
epoch: 3093, train precision: 0.998956, train loss: 10.262571, valid precision: 0.880400, valid loss: 91.027157
epoch: 3094, train precision: 0.998933, train loss: 10.252280, valid precision: 0.879800, valid loss: 91.107866
epoch: 3095, train precision: 0.998933, train loss: 10.268361, valid precision: 0.879400, valid loss: 91.253679
epoch: 3096, train precision: 0.999244, train loss: 10.146997, valid precision: 0.877600, valid loss: 90.504800
epoch: 3097, train precision: 0.998822, train loss: 10.290241, valid precision: 0.880400, valid loss: 90.012413
epoch: 3098, train precision: 0.999111, train loss: 10.253866, valid precision: 0.878800, valid loss: 91.356632
epoch: 3099, train precision: 0.999178, train loss: 10.149853, valid precision: 0.877600, valid loss: 91.773077
epoch: 3100, train precision: 0.999000, train loss: 10.239883, valid precision: 0.880400, valid loss: 89.656578
epoch: 3101, train precision: 0.998889, train loss: 10.263895, valid precision: 0.874200, valid loss: 91.754416
epoch: 3102, train precision: 0.998911, train loss: 10.274137, valid precision: 0.873000, valid loss: 95.975039
epoch: 3103, train precision: 0.999400, train loss: 10.130265, valid precision: 0.873800, valid loss: 91.269946
epoch: 3104, train precision: 0.999000, train loss: 10.214960, valid precision: 0.873000, valid loss: 91.069137
epoch: 3105, train precision: 0.999133, train loss: 10.138078, valid precision: 0.879000, valid loss: 93.402804
epoch: 3106, train precision: 0.999133, train loss: 10.227178, valid precision: 0.880400, valid loss: 90.999122
epoch: 3107, train precision: 0.998644, train loss: 10.325850, valid precision: 0.879200, valid loss: 87.309250
epoch: 3108, train precision: 0.999311, train loss: 10.152140, valid precision: 0.875000, valid loss: 92.550357
epoch: 3109, train precision: 0.998978, train loss: 10.250330, valid precision: 0.876000, valid loss: 91.216847
epoch: 3110, train precision: 0.998800, train loss: 10.307140, valid precision: 0.875000, valid loss: 92.443369
epoch: 3111, train precision: 0.998533, train loss: 10.484827, valid precision: 0.878400, valid loss: 88.989533
epoch: 3112, train precision: 0.999267, train loss: 10.147169, valid precision: 0.878400, valid loss: 91.920797
epoch: 3113, train precision: 0.998978, train loss: 10.275625, valid precision: 0.878400, valid loss: 91.383612
epoch: 3114, train precision: 0.998867, train loss: 10.251182, valid precision: 0.878200, valid loss: 89.434779
epoch: 3115, train precision: 0.999444, train loss: 10.145157, valid precision: 0.880200, valid loss: 89.084779
epoch: 3116, train precision: 0.999089, train loss: 10.214471, valid precision: 0.881400, valid loss: 87.467281
epoch: 3117, train precision: 0.999200, train loss: 10.176704, valid precision: 0.880200, valid loss: 88.447216
epoch: 3118, train precision: 0.998933, train loss: 10.272822, valid precision: 0.881200, valid loss: 88.494499
epoch: 3119, train precision: 0.999111, train loss: 10.255279, valid precision: 0.880600, valid loss: 89.443538
epoch: 3120, train precision: 0.998644, train loss: 10.354474, valid precision: 0.878000, valid loss: 89.063165
epoch: 3121, train precision: 0.998933, train loss: 10.189354, valid precision: 0.881000, valid loss: 88.490987
epoch: 3122, train precision: 0.999156, train loss: 10.167650, valid precision: 0.880400, valid loss: 88.861833
epoch: 3123, train precision: 0.999044, train loss: 10.195604, valid precision: 0.880800, valid loss: 87.413330
epoch: 3124, train precision: 0.999044, train loss: 10.231104, valid precision: 0.881000, valid loss: 89.293372
epoch: 3125, train precision: 0.998822, train loss: 10.265451, valid precision: 0.883000, valid loss: 89.370011
epoch: 3126, train precision: 0.999244, train loss: 10.191232, valid precision: 0.880600, valid loss: 87.490637
epoch: 3127, train precision: 0.998822, train loss: 10.315793, valid precision: 0.880000, valid loss: 88.613015
epoch: 3128, train precision: 0.999222, train loss: 10.181112, valid precision: 0.881800, valid loss: 86.697648
epoch: 3129, train precision: 0.998822, train loss: 10.270624, valid precision: 0.879200, valid loss: 87.668076
epoch: 3130, train precision: 0.999444, train loss: 10.141916, valid precision: 0.880400, valid loss: 88.459183
epoch: 3131, train precision: 0.998956, train loss: 10.295066, valid precision: 0.880000, valid loss: 90.744393
epoch: 3132, train precision: 0.998756, train loss: 10.279807, valid precision: 0.876200, valid loss: 90.680957
epoch: 3133, train precision: 0.998600, train loss: 10.303272, valid precision: 0.878800, valid loss: 89.656507
epoch: 3134, train precision: 0.999333, train loss: 10.100218, valid precision: 0.883400, valid loss: 88.453740
epoch: 3135, train precision: 0.999067, train loss: 10.155929, valid precision: 0.881000, valid loss: 88.997833
epoch: 3136, train precision: 0.999067, train loss: 10.192547, valid precision: 0.886400, valid loss: 88.464016
epoch: 3137, train precision: 0.999244, train loss: 10.116643, valid precision: 0.880400, valid loss: 90.002034
epoch: 3138, train precision: 0.998889, train loss: 10.284111, valid precision: 0.881200, valid loss: 90.760239
epoch: 3139, train precision: 0.999356, train loss: 10.154200, valid precision: 0.881000, valid loss: 89.569837
epoch: 3140, train precision: 0.998756, train loss: 10.344729, valid precision: 0.880600, valid loss: 88.993079
epoch: 3141, train precision: 0.999044, train loss: 10.257635, valid precision: 0.880200, valid loss: 86.297658
epoch: 3142, train precision: 0.998956, train loss: 10.213120, valid precision: 0.878200, valid loss: 88.021080
epoch: 3143, train precision: 0.999044, train loss: 10.178546, valid precision: 0.882200, valid loss: 90.795712
epoch: 3144, train precision: 0.999400, train loss: 10.098731, valid precision: 0.881000, valid loss: 88.267700
epoch: 3145, train precision: 0.998822, train loss: 10.309482, valid precision: 0.881200, valid loss: 91.085442
epoch: 3146, train precision: 0.998933, train loss: 10.221701, valid precision: 0.880200, valid loss: 89.867084
epoch: 3147, train precision: 0.998911, train loss: 10.296533, valid precision: 0.878800, valid loss: 91.644269
epoch: 3148, train precision: 0.999311, train loss: 10.169781, valid precision: 0.880800, valid loss: 88.338052
epoch: 3149, train precision: 0.999178, train loss: 10.181275, valid precision: 0.878400, valid loss: 89.847958
epoch: 3150, train precision: 0.999222, train loss: 10.133095, valid precision: 0.877600, valid loss: 89.696321
epoch: 3151, train precision: 0.999111, train loss: 10.137055, valid precision: 0.880200, valid loss: 90.851674
epoch: 3152, train precision: 0.998956, train loss: 10.240921, valid precision: 0.878000, valid loss: 93.111548
epoch: 3153, train precision: 0.998933, train loss: 10.277263, valid precision: 0.878600, valid loss: 90.884579
epoch: 3154, train precision: 0.999289, train loss: 10.151315, valid precision: 0.880600, valid loss: 92.316962
epoch: 3155, train precision: 0.999089, train loss: 10.229111, valid precision: 0.877400, valid loss: 91.382423
epoch: 3156, train precision: 0.999222, train loss: 10.108338, valid precision: 0.882000, valid loss: 89.868695
epoch: 3157, train precision: 0.998978, train loss: 10.209581, valid precision: 0.881000, valid loss: 90.604539
epoch: 3158, train precision: 0.999111, train loss: 10.254379, valid precision: 0.877600, valid loss: 93.801887
epoch: 3159, train precision: 0.999267, train loss: 10.177048, valid precision: 0.881600, valid loss: 90.221509
epoch: 3160, train precision: 0.998889, train loss: 10.287740, valid precision: 0.884600, valid loss: 88.239623
epoch: 3161, train precision: 0.999311, train loss: 10.127289, valid precision: 0.877800, valid loss: 88.944713
epoch: 3162, train precision: 0.999022, train loss: 10.227546, valid precision: 0.881600, valid loss: 88.479004
epoch: 3163, train precision: 0.998956, train loss: 10.239797, valid precision: 0.882800, valid loss: 90.931191
epoch: 3164, train precision: 0.999111, train loss: 10.202072, valid precision: 0.882400, valid loss: 90.978166
epoch: 3165, train precision: 0.998978, train loss: 10.241099, valid precision: 0.881800, valid loss: 88.686623
epoch: 3166, train precision: 0.999000, train loss: 10.229023, valid precision: 0.879200, valid loss: 90.391026
epoch: 3167, train precision: 0.999022, train loss: 10.179256, valid precision: 0.876800, valid loss: 90.052643
epoch: 3168, train precision: 0.998822, train loss: 10.283441, valid precision: 0.877200, valid loss: 89.240357
epoch: 3169, train precision: 0.998911, train loss: 10.229301, valid precision: 0.880600, valid loss: 89.233123
epoch: 3170, train precision: 0.998978, train loss: 10.224014, valid precision: 0.882200, valid loss: 92.414249
epoch: 3171, train precision: 0.999244, train loss: 10.140235, valid precision: 0.882600, valid loss: 88.463165
epoch: 3172, train precision: 0.999133, train loss: 10.167978, valid precision: 0.880200, valid loss: 89.525822
epoch: 3173, train precision: 0.999000, train loss: 10.206700, valid precision: 0.885000, valid loss: 89.885456
epoch: 3174, train precision: 0.998844, train loss: 10.281631, valid precision: 0.881400, valid loss: 90.367978
epoch: 3175, train precision: 0.999111, train loss: 10.136340, valid precision: 0.882600, valid loss: 92.426048
epoch: 3176, train precision: 0.999022, train loss: 10.207956, valid precision: 0.883800, valid loss: 91.042910
epoch: 3177, train precision: 0.999333, train loss: 10.097964, valid precision: 0.884400, valid loss: 91.131904
epoch: 3178, train precision: 0.998733, train loss: 10.293378, valid precision: 0.878600, valid loss: 88.369573
epoch: 3179, train precision: 0.999333, train loss: 10.107596, valid precision: 0.883600, valid loss: 90.913201
epoch: 3180, train precision: 0.998889, train loss: 10.247280, valid precision: 0.879600, valid loss: 90.142117
epoch: 3181, train precision: 0.999022, train loss: 10.212083, valid precision: 0.881400, valid loss: 91.292417
epoch: 3182, train precision: 0.999067, train loss: 10.179731, valid precision: 0.882800, valid loss: 91.072639
epoch: 3183, train precision: 0.999089, train loss: 10.144009, valid precision: 0.884400, valid loss: 92.110235
epoch: 3184, train precision: 0.999044, train loss: 10.168502, valid precision: 0.881200, valid loss: 92.504610
epoch: 3185, train precision: 0.999067, train loss: 10.190668, valid precision: 0.881400, valid loss: 90.761267
epoch: 3186, train precision: 0.998978, train loss: 10.204004, valid precision: 0.879000, valid loss: 90.867495
epoch: 3187, train precision: 0.998556, train loss: 10.372511, valid precision: 0.877600, valid loss: 94.354656
epoch: 3188, train precision: 0.999400, train loss: 10.138982, valid precision: 0.883400, valid loss: 89.688017
epoch: 3189, train precision: 0.999089, train loss: 10.174275, valid precision: 0.880200, valid loss: 90.327286
epoch: 3190, train precision: 0.998689, train loss: 10.346057, valid precision: 0.879200, valid loss: 92.727610
epoch: 3191, train precision: 0.998911, train loss: 10.235697, valid precision: 0.880600, valid loss: 89.478805
epoch: 3192, train precision: 0.999200, train loss: 10.169026, valid precision: 0.879800, valid loss: 91.255174
epoch: 3193, train precision: 0.999489, train loss: 10.108637, valid precision: 0.880000, valid loss: 90.441685
epoch: 3194, train precision: 0.999067, train loss: 10.254662, valid precision: 0.880400, valid loss: 89.980241
epoch: 3195, train precision: 0.999089, train loss: 10.177729, valid precision: 0.883400, valid loss: 91.099433
epoch: 3196, train precision: 0.998711, train loss: 10.321564, valid precision: 0.879800, valid loss: 91.855269
epoch: 3197, train precision: 0.998667, train loss: 10.280335, valid precision: 0.881200, valid loss: 93.408442
epoch: 3198, train precision: 0.999178, train loss: 10.119026, valid precision: 0.880400, valid loss: 93.797488
epoch: 3199, train precision: 0.999378, train loss: 10.060590, valid precision: 0.880000, valid loss: 91.900789
epoch: 3200, train precision: 0.999044, train loss: 10.186439, valid precision: 0.883800, valid loss: 91.380120
epoch: 3201, train precision: 0.999111, train loss: 10.176593, valid precision: 0.878800, valid loss: 90.848001
epoch: 3202, train precision: 0.998800, train loss: 10.247808, valid precision: 0.877800, valid loss: 93.145172
epoch: 3203, train precision: 0.999289, train loss: 10.140939, valid precision: 0.880800, valid loss: 92.604547
epoch: 3204, train precision: 0.999289, train loss: 10.152707, valid precision: 0.882200, valid loss: 91.090301
epoch: 3205, train precision: 0.999222, train loss: 10.191781, valid precision: 0.880600, valid loss: 87.603957
epoch: 3206, train precision: 0.999089, train loss: 10.182841, valid precision: 0.879800, valid loss: 88.351965
epoch: 3207, train precision: 0.999267, train loss: 10.125286, valid precision: 0.881800, valid loss: 91.112555
epoch: 3208, train precision: 0.998933, train loss: 10.298256, valid precision: 0.878200, valid loss: 88.766241
epoch: 3209, train precision: 0.998933, train loss: 10.234411, valid precision: 0.876800, valid loss: 94.231652
epoch: 3210, train precision: 0.999089, train loss: 10.183187, valid precision: 0.875800, valid loss: 93.210110
epoch: 3211, train precision: 0.998978, train loss: 10.224974, valid precision: 0.878600, valid loss: 93.659733
epoch: 3212, train precision: 0.998978, train loss: 10.232293, valid precision: 0.878400, valid loss: 91.246659
epoch: 3213, train precision: 0.998911, train loss: 10.266925, valid precision: 0.877200, valid loss: 90.155386
epoch: 3214, train precision: 0.999000, train loss: 10.274756, valid precision: 0.882800, valid loss: 91.953763
epoch: 3215, train precision: 0.999044, train loss: 10.236861, valid precision: 0.878800, valid loss: 91.104353
epoch: 3216, train precision: 0.998978, train loss: 10.234879, valid precision: 0.877400, valid loss: 89.522926
epoch: 3217, train precision: 0.999000, train loss: 10.244657, valid precision: 0.884800, valid loss: 87.934740
epoch: 3218, train precision: 0.999222, train loss: 10.143773, valid precision: 0.877000, valid loss: 88.566915
epoch: 3219, train precision: 0.999244, train loss: 10.190220, valid precision: 0.883600, valid loss: 86.558209
epoch: 3220, train precision: 0.999489, train loss: 10.091338, valid precision: 0.874400, valid loss: 88.480380
epoch: 3221, train precision: 0.999378, train loss: 10.092882, valid precision: 0.880600, valid loss: 91.028030
epoch: 3222, train precision: 0.999111, train loss: 10.195680, valid precision: 0.875400, valid loss: 89.710710
epoch: 3223, train precision: 0.999000, train loss: 10.213547, valid precision: 0.878200, valid loss: 89.960748
epoch: 3224, train precision: 0.998600, train loss: 10.314088, valid precision: 0.874200, valid loss: 90.248267
epoch: 3225, train precision: 0.999333, train loss: 10.123821, valid precision: 0.876200, valid loss: 89.063942
epoch: 3226, train precision: 0.999333, train loss: 10.100546, valid precision: 0.882400, valid loss: 87.322379
epoch: 3227, train precision: 0.999133, train loss: 10.204982, valid precision: 0.879400, valid loss: 87.474931
epoch: 3228, train precision: 0.999000, train loss: 10.208504, valid precision: 0.881200, valid loss: 90.648842
epoch: 3229, train precision: 0.999311, train loss: 10.132467, valid precision: 0.879400, valid loss: 90.736980
epoch: 3230, train precision: 0.999267, train loss: 10.103023, valid precision: 0.879200, valid loss: 89.287540
epoch: 3231, train precision: 0.999400, train loss: 10.041103, valid precision: 0.877400, valid loss: 90.279193
epoch: 3232, train precision: 0.998867, train loss: 10.179483, valid precision: 0.882200, valid loss: 89.841134
epoch: 3233, train precision: 0.999000, train loss: 10.183775, valid precision: 0.884000, valid loss: 88.292910
epoch: 3234, train precision: 0.998933, train loss: 10.208099, valid precision: 0.880000, valid loss: 90.966018
epoch: 3235, train precision: 0.999444, train loss: 10.066423, valid precision: 0.880000, valid loss: 92.218838
epoch: 3236, train precision: 0.999222, train loss: 10.144739, valid precision: 0.882600, valid loss: 90.064579
epoch: 3237, train precision: 0.999156, train loss: 10.155109, valid precision: 0.879600, valid loss: 91.062840
epoch: 3238, train precision: 0.998911, train loss: 10.201911, valid precision: 0.882800, valid loss: 91.981278
epoch: 3239, train precision: 0.998956, train loss: 10.208704, valid precision: 0.879200, valid loss: 92.007395
epoch: 3240, train precision: 0.999222, train loss: 10.144698, valid precision: 0.878000, valid loss: 90.506495
epoch: 3241, train precision: 0.999200, train loss: 10.097077, valid precision: 0.880600, valid loss: 91.606543
epoch: 3242, train precision: 0.999200, train loss: 10.126371, valid precision: 0.881400, valid loss: 91.561646
epoch: 3243, train precision: 0.999489, train loss: 10.045622, valid precision: 0.881800, valid loss: 92.350080
epoch: 3244, train precision: 0.998956, train loss: 10.214949, valid precision: 0.877800, valid loss: 91.388463
epoch: 3245, train precision: 0.999111, train loss: 10.209155, valid precision: 0.878200, valid loss: 93.419638
epoch: 3246, train precision: 0.998956, train loss: 10.199391, valid precision: 0.882600, valid loss: 92.199916
epoch: 3247, train precision: 0.999044, train loss: 10.155011, valid precision: 0.876000, valid loss: 94.888995
epoch: 3248, train precision: 0.999244, train loss: 10.157298, valid precision: 0.879200, valid loss: 91.743038
epoch: 3249, train precision: 0.999222, train loss: 10.165487, valid precision: 0.881600, valid loss: 92.473290
epoch: 3250, train precision: 0.999000, train loss: 10.183000, valid precision: 0.881000, valid loss: 90.649325
epoch: 3251, train precision: 0.999022, train loss: 10.200412, valid precision: 0.876400, valid loss: 93.117881
epoch: 3252, train precision: 0.999244, train loss: 10.134780, valid precision: 0.881800, valid loss: 93.622819
epoch: 3253, train precision: 0.999022, train loss: 10.177144, valid precision: 0.879200, valid loss: 94.958048
epoch: 3254, train precision: 0.999178, train loss: 10.176595, valid precision: 0.879800, valid loss: 94.065582
epoch: 3255, train precision: 0.999267, train loss: 10.097449, valid precision: 0.878600, valid loss: 97.545526
epoch: 3256, train precision: 0.999044, train loss: 10.165638, valid precision: 0.877200, valid loss: 94.560924
epoch: 3257, train precision: 0.999356, train loss: 10.111961, valid precision: 0.880600, valid loss: 94.182869
epoch: 3258, train precision: 0.998844, train loss: 10.238813, valid precision: 0.879600, valid loss: 92.386309
epoch: 3259, train precision: 0.999156, train loss: 10.189570, valid precision: 0.876800, valid loss: 94.183193
epoch: 3260, train precision: 0.998822, train loss: 10.194243, valid precision: 0.877600, valid loss: 93.877054
epoch: 3261, train precision: 0.999089, train loss: 10.179043, valid precision: 0.875800, valid loss: 91.507578
epoch: 3262, train precision: 0.998689, train loss: 10.239323, valid precision: 0.879200, valid loss: 94.387487
epoch: 3263, train precision: 0.999156, train loss: 10.176157, valid precision: 0.879600, valid loss: 92.207333
epoch: 3264, train precision: 0.999244, train loss: 10.102213, valid precision: 0.880400, valid loss: 93.240649
epoch: 3265, train precision: 0.999178, train loss: 10.101919, valid precision: 0.880600, valid loss: 91.910966
epoch: 3266, train precision: 0.999356, train loss: 10.064642, valid precision: 0.881200, valid loss: 90.853967
epoch: 3267, train precision: 0.999311, train loss: 10.072604, valid precision: 0.879600, valid loss: 93.044338
epoch: 3268, train precision: 0.999133, train loss: 10.153929, valid precision: 0.879200, valid loss: 92.680178
epoch: 3269, train precision: 0.998911, train loss: 10.193089, valid precision: 0.878200, valid loss: 90.606073
epoch: 3270, train precision: 0.998911, train loss: 10.187107, valid precision: 0.878000, valid loss: 91.399697
epoch: 3271, train precision: 0.999089, train loss: 10.095691, valid precision: 0.880800, valid loss: 90.650191
epoch: 3272, train precision: 0.999533, train loss: 10.053865, valid precision: 0.878800, valid loss: 89.526102
epoch: 3273, train precision: 0.999289, train loss: 10.155983, valid precision: 0.875600, valid loss: 91.000129
epoch: 3274, train precision: 0.998933, train loss: 10.183203, valid precision: 0.877400, valid loss: 91.346744
epoch: 3275, train precision: 0.999178, train loss: 10.186477, valid precision: 0.878800, valid loss: 93.070435
epoch: 3276, train precision: 0.999378, train loss: 10.077985, valid precision: 0.882800, valid loss: 90.383705
epoch: 3277, train precision: 0.999133, train loss: 10.165290, valid precision: 0.881200, valid loss: 91.010541
epoch: 3278, train precision: 0.998889, train loss: 10.239697, valid precision: 0.876200, valid loss: 93.473749
epoch: 3279, train precision: 0.999133, train loss: 10.183596, valid precision: 0.874200, valid loss: 96.852441
epoch: 3280, train precision: 0.999267, train loss: 10.092767, valid precision: 0.880200, valid loss: 94.505706
epoch: 3281, train precision: 0.999156, train loss: 10.078424, valid precision: 0.878800, valid loss: 93.946928
epoch: 3282, train precision: 0.999200, train loss: 10.129585, valid precision: 0.874400, valid loss: 93.091963
epoch: 3283, train precision: 0.999200, train loss: 10.133495, valid precision: 0.874400, valid loss: 95.749688
epoch: 3284, train precision: 0.998933, train loss: 10.212542, valid precision: 0.881000, valid loss: 92.949591
epoch: 3285, train precision: 0.999333, train loss: 10.146214, valid precision: 0.882200, valid loss: 92.528524
epoch: 3286, train precision: 0.998667, train loss: 10.254421, valid precision: 0.877400, valid loss: 94.523247
epoch: 3287, train precision: 0.999244, train loss: 10.085907, valid precision: 0.878200, valid loss: 93.586851
epoch: 3288, train precision: 0.999133, train loss: 10.171734, valid precision: 0.878200, valid loss: 93.608640
epoch: 3289, train precision: 0.998956, train loss: 10.202755, valid precision: 0.879000, valid loss: 94.136308
epoch: 3290, train precision: 0.998867, train loss: 10.182996, valid precision: 0.875800, valid loss: 93.837691
epoch: 3291, train precision: 0.999111, train loss: 10.154906, valid precision: 0.875200, valid loss: 94.743547
epoch: 3292, train precision: 0.998911, train loss: 10.210688, valid precision: 0.874800, valid loss: 94.792080
epoch: 3293, train precision: 0.998956, train loss: 10.172541, valid precision: 0.877200, valid loss: 94.005479
epoch: 3294, train precision: 0.999200, train loss: 10.157674, valid precision: 0.880000, valid loss: 90.292083
epoch: 3295, train precision: 0.999156, train loss: 10.174207, valid precision: 0.879200, valid loss: 91.188643
epoch: 3296, train precision: 0.999289, train loss: 10.188116, valid precision: 0.878000, valid loss: 92.267088
epoch: 3297, train precision: 0.999133, train loss: 10.114090, valid precision: 0.883600, valid loss: 92.492419
epoch: 3298, train precision: 0.998978, train loss: 10.177136, valid precision: 0.880800, valid loss: 90.894923
epoch: 3299, train precision: 0.998867, train loss: 10.193754, valid precision: 0.883400, valid loss: 92.401855
epoch: 3300, train precision: 0.999111, train loss: 10.170910, valid precision: 0.880600, valid loss: 92.660448
epoch: 3301, train precision: 0.999200, train loss: 10.089622, valid precision: 0.879800, valid loss: 92.042872
epoch: 3302, train precision: 0.999067, train loss: 10.195015, valid precision: 0.876400, valid loss: 94.917769
epoch: 3303, train precision: 0.999022, train loss: 10.200646, valid precision: 0.876000, valid loss: 94.293249
epoch: 3304, train precision: 0.999022, train loss: 10.194762, valid precision: 0.878000, valid loss: 93.628394
epoch: 3305, train precision: 0.999222, train loss: 10.123896, valid precision: 0.875200, valid loss: 96.184163
epoch: 3306, train precision: 0.998756, train loss: 10.221963, valid precision: 0.881400, valid loss: 94.011665
epoch: 3307, train precision: 0.999022, train loss: 10.133381, valid precision: 0.879000, valid loss: 93.004912
epoch: 3308, train precision: 0.999311, train loss: 10.094871, valid precision: 0.878400, valid loss: 94.557597
epoch: 3309, train precision: 0.999467, train loss: 10.108611, valid precision: 0.878400, valid loss: 93.839704
epoch: 3310, train precision: 0.999200, train loss: 10.107928, valid precision: 0.877400, valid loss: 91.908708
epoch: 3311, train precision: 0.999133, train loss: 10.153496, valid precision: 0.881000, valid loss: 91.131398
epoch: 3312, train precision: 0.999111, train loss: 10.150622, valid precision: 0.877600, valid loss: 92.142986
epoch: 3313, train precision: 0.998689, train loss: 10.264315, valid precision: 0.874200, valid loss: 94.399406
epoch: 3314, train precision: 0.998911, train loss: 10.241858, valid precision: 0.875400, valid loss: 92.825949
epoch: 3315, train precision: 0.998778, train loss: 10.259683, valid precision: 0.873600, valid loss: 91.529545
epoch: 3316, train precision: 0.999111, train loss: 10.187700, valid precision: 0.871400, valid loss: 91.751749
epoch: 3317, train precision: 0.999156, train loss: 10.145107, valid precision: 0.877400, valid loss: 90.988609
epoch: 3318, train precision: 0.999356, train loss: 10.089842, valid precision: 0.881000, valid loss: 90.292599
epoch: 3319, train precision: 0.999044, train loss: 10.143750, valid precision: 0.876000, valid loss: 92.261649
epoch: 3320, train precision: 0.999244, train loss: 10.109072, valid precision: 0.878400, valid loss: 91.082707
epoch: 3321, train precision: 0.998911, train loss: 10.196720, valid precision: 0.877000, valid loss: 94.678003
epoch: 3322, train precision: 0.999000, train loss: 10.259721, valid precision: 0.877200, valid loss: 90.854708
epoch: 3323, train precision: 0.999178, train loss: 10.171085, valid precision: 0.876800, valid loss: 90.216107
epoch: 3324, train precision: 0.998889, train loss: 10.223807, valid precision: 0.879200, valid loss: 90.965001
epoch: 3325, train precision: 0.998800, train loss: 10.246692, valid precision: 0.875600, valid loss: 90.295917
epoch: 3326, train precision: 0.999089, train loss: 10.119596, valid precision: 0.876600, valid loss: 90.299457
epoch: 3327, train precision: 0.999000, train loss: 10.157091, valid precision: 0.880000, valid loss: 91.195088
epoch: 3328, train precision: 0.999022, train loss: 10.174494, valid precision: 0.879200, valid loss: 90.187664
epoch: 3329, train precision: 0.999222, train loss: 10.204477, valid precision: 0.877600, valid loss: 88.319607
epoch: 3330, train precision: 0.999200, train loss: 10.161090, valid precision: 0.877400, valid loss: 88.897359
epoch: 3331, train precision: 0.999178, train loss: 10.141140, valid precision: 0.878400, valid loss: 91.703671
epoch: 3332, train precision: 0.999222, train loss: 10.160653, valid precision: 0.875400, valid loss: 91.676807
epoch: 3333, train precision: 0.999178, train loss: 10.109158, valid precision: 0.878200, valid loss: 92.181198
epoch: 3334, train precision: 0.999089, train loss: 10.118185, valid precision: 0.877000, valid loss: 91.601652
epoch: 3335, train precision: 0.999200, train loss: 10.172577, valid precision: 0.876800, valid loss: 91.722818
epoch: 3336, train precision: 0.998956, train loss: 10.219074, valid precision: 0.882000, valid loss: 88.613405
epoch: 3337, train precision: 0.999200, train loss: 10.125346, valid precision: 0.878200, valid loss: 89.138228
epoch: 3338, train precision: 0.999244, train loss: 10.071906, valid precision: 0.881000, valid loss: 90.141156
epoch: 3339, train precision: 0.998978, train loss: 10.200769, valid precision: 0.883800, valid loss: 90.521928
epoch: 3340, train precision: 0.999289, train loss: 10.128963, valid precision: 0.882000, valid loss: 92.733039
epoch: 3341, train precision: 0.998711, train loss: 10.232093, valid precision: 0.879400, valid loss: 90.587956
epoch: 3342, train precision: 0.999333, train loss: 10.113938, valid precision: 0.881000, valid loss: 89.019245
epoch: 3343, train precision: 0.999178, train loss: 10.093869, valid precision: 0.878600, valid loss: 90.993390
epoch: 3344, train precision: 0.998867, train loss: 10.170014, valid precision: 0.877200, valid loss: 92.058172
epoch: 3345, train precision: 0.999044, train loss: 10.211369, valid precision: 0.879200, valid loss: 89.037624
epoch: 3346, train precision: 0.998889, train loss: 10.253325, valid precision: 0.882600, valid loss: 88.560871
epoch: 3347, train precision: 0.999333, train loss: 10.066453, valid precision: 0.881800, valid loss: 87.588004
epoch: 3348, train precision: 0.998933, train loss: 10.147267, valid precision: 0.879200, valid loss: 89.692321
epoch: 3349, train precision: 0.998800, train loss: 10.230961, valid precision: 0.879400, valid loss: 91.685463
epoch: 3350, train precision: 0.999333, train loss: 10.095730, valid precision: 0.878800, valid loss: 90.730883
epoch: 3351, train precision: 0.999111, train loss: 10.119465, valid precision: 0.877000, valid loss: 90.553798
epoch: 3352, train precision: 0.999267, train loss: 10.093847, valid precision: 0.880000, valid loss: 91.552136
epoch: 3353, train precision: 0.998711, train loss: 10.282181, valid precision: 0.877400, valid loss: 91.857655
epoch: 3354, train precision: 0.999533, train loss: 10.053237, valid precision: 0.880200, valid loss: 90.162337
epoch: 3355, train precision: 0.999111, train loss: 10.156636, valid precision: 0.876400, valid loss: 91.852935
epoch: 3356, train precision: 0.999111, train loss: 10.160461, valid precision: 0.875000, valid loss: 92.294711
epoch: 3357, train precision: 0.999289, train loss: 10.137304, valid precision: 0.877400, valid loss: 91.915990
epoch: 3358, train precision: 0.999467, train loss: 9.954769, valid precision: 0.879600, valid loss: 90.444003
epoch: 3359, train precision: 0.998933, train loss: 10.139274, valid precision: 0.879200, valid loss: 92.712011
epoch: 3360, train precision: 0.998978, train loss: 10.230774, valid precision: 0.879200, valid loss: 93.024247
epoch: 3361, train precision: 0.999467, train loss: 10.065732, valid precision: 0.877000, valid loss: 91.187514
epoch: 3362, train precision: 0.999178, train loss: 10.122925, valid precision: 0.878000, valid loss: 90.074774
epoch: 3363, train precision: 0.998911, train loss: 10.187092, valid precision: 0.879000, valid loss: 90.350825
epoch: 3364, train precision: 0.999289, train loss: 10.102803, valid precision: 0.879200, valid loss: 91.974970
epoch: 3365, train precision: 0.999333, train loss: 10.043089, valid precision: 0.875600, valid loss: 91.639051
epoch: 3366, train precision: 0.999156, train loss: 10.135084, valid precision: 0.876600, valid loss: 89.091913
epoch: 3367, train precision: 0.998600, train loss: 10.341788, valid precision: 0.877000, valid loss: 92.220475
epoch: 3368, train precision: 0.999244, train loss: 10.103546, valid precision: 0.878800, valid loss: 93.499341
epoch: 3369, train precision: 0.999022, train loss: 10.122295, valid precision: 0.882400, valid loss: 89.258947
epoch: 3370, train precision: 0.998889, train loss: 10.168003, valid precision: 0.880400, valid loss: 89.514778
epoch: 3371, train precision: 0.999044, train loss: 10.107280, valid precision: 0.880000, valid loss: 90.008045
epoch: 3372, train precision: 0.998844, train loss: 10.220878, valid precision: 0.880000, valid loss: 89.403964
epoch: 3373, train precision: 0.998867, train loss: 10.202562, valid precision: 0.874200, valid loss: 92.752251
epoch: 3374, train precision: 0.998867, train loss: 10.202396, valid precision: 0.875600, valid loss: 90.146869
epoch: 3375, train precision: 0.999156, train loss: 10.115805, valid precision: 0.877600, valid loss: 91.796991
epoch: 3376, train precision: 0.999133, train loss: 10.109720, valid precision: 0.880600, valid loss: 91.191519
epoch: 3377, train precision: 0.999222, train loss: 10.115117, valid precision: 0.877400, valid loss: 91.092460
epoch: 3378, train precision: 0.999111, train loss: 10.090920, valid precision: 0.877800, valid loss: 90.416842
epoch: 3379, train precision: 0.998956, train loss: 10.210046, valid precision: 0.879400, valid loss: 90.971340
epoch: 3380, train precision: 0.999156, train loss: 10.185559, valid precision: 0.878200, valid loss: 92.063918
epoch: 3381, train precision: 0.998867, train loss: 10.213074, valid precision: 0.879200, valid loss: 93.617580
epoch: 3382, train precision: 0.999111, train loss: 10.146637, valid precision: 0.875400, valid loss: 92.570045
epoch: 3383, train precision: 0.999289, train loss: 10.120446, valid precision: 0.877800, valid loss: 94.092091
epoch: 3384, train precision: 0.998600, train loss: 10.298737, valid precision: 0.875600, valid loss: 90.771859
epoch: 3385, train precision: 0.999156, train loss: 10.082156, valid precision: 0.877000, valid loss: 92.515417
epoch: 3386, train precision: 0.999156, train loss: 10.099978, valid precision: 0.879800, valid loss: 91.469360
epoch: 3387, train precision: 0.999200, train loss: 10.103555, valid precision: 0.882000, valid loss: 91.293467
epoch: 3388, train precision: 0.999089, train loss: 10.146661, valid precision: 0.879600, valid loss: 90.435031
epoch: 3389, train precision: 0.999133, train loss: 10.149567, valid precision: 0.883800, valid loss: 88.161258
epoch: 3390, train precision: 0.999156, train loss: 10.124754, valid precision: 0.882400, valid loss: 87.979125
epoch: 3391, train precision: 0.999244, train loss: 10.101084, valid precision: 0.883000, valid loss: 86.965133
epoch: 3392, train precision: 0.999089, train loss: 10.144854, valid precision: 0.879600, valid loss: 89.134443
epoch: 3393, train precision: 0.999067, train loss: 10.173777, valid precision: 0.876800, valid loss: 91.215488
epoch: 3394, train precision: 0.998756, train loss: 10.273091, valid precision: 0.874400, valid loss: 89.073418
epoch: 3395, train precision: 0.999200, train loss: 10.104107, valid precision: 0.877400, valid loss: 90.739135
epoch: 3396, train precision: 0.998844, train loss: 10.216374, valid precision: 0.880200, valid loss: 90.108417
epoch: 3397, train precision: 0.999111, train loss: 10.193820, valid precision: 0.879400, valid loss: 91.163949
epoch: 3398, train precision: 0.998911, train loss: 10.141258, valid precision: 0.875200, valid loss: 92.051815
epoch: 3399, train precision: 0.998933, train loss: 10.169835, valid precision: 0.878600, valid loss: 89.221318
epoch: 3400, train precision: 0.999200, train loss: 10.130383, valid precision: 0.880800, valid loss: 90.849194
epoch: 3401, train precision: 0.998956, train loss: 10.193318, valid precision: 0.880800, valid loss: 89.773117
epoch: 3402, train precision: 0.999067, train loss: 10.204144, valid precision: 0.880000, valid loss: 90.281115
epoch: 3403, train precision: 0.999222, train loss: 10.069574, valid precision: 0.880600, valid loss: 91.747935
epoch: 3404, train precision: 0.999089, train loss: 10.099116, valid precision: 0.879600, valid loss: 94.275954
epoch: 3405, train precision: 0.999244, train loss: 10.072813, valid precision: 0.882800, valid loss: 96.154744
epoch: 3406, train precision: 0.999156, train loss: 10.106638, valid precision: 0.877600, valid loss: 91.912980
epoch: 3407, train precision: 0.999156, train loss: 10.131578, valid precision: 0.881800, valid loss: 91.727646
epoch: 3408, train precision: 0.999267, train loss: 10.111135, valid precision: 0.884400, valid loss: 88.512811
epoch: 3409, train precision: 0.999267, train loss: 10.085615, valid precision: 0.879000, valid loss: 90.590141
epoch: 3410, train precision: 0.999111, train loss: 10.127628, valid precision: 0.877000, valid loss: 92.452505
epoch: 3411, train precision: 0.999356, train loss: 10.065853, valid precision: 0.882000, valid loss: 91.314011
epoch: 3412, train precision: 0.999089, train loss: 10.095050, valid precision: 0.882600, valid loss: 90.729401
epoch: 3413, train precision: 0.999044, train loss: 10.187826, valid precision: 0.879800, valid loss: 91.144103
epoch: 3414, train precision: 0.999200, train loss: 10.141528, valid precision: 0.877400, valid loss: 90.493200
epoch: 3415, train precision: 0.999311, train loss: 10.049420, valid precision: 0.877800, valid loss: 92.636855
epoch: 3416, train precision: 0.999222, train loss: 10.087576, valid precision: 0.881600, valid loss: 93.376368
epoch: 3417, train precision: 0.999444, train loss: 10.029361, valid precision: 0.881600, valid loss: 91.207098
epoch: 3418, train precision: 0.999289, train loss: 10.090361, valid precision: 0.878400, valid loss: 92.034328
epoch: 3419, train precision: 0.999089, train loss: 10.114310, valid precision: 0.882000, valid loss: 91.235311
epoch: 3420, train precision: 0.999111, train loss: 10.100748, valid precision: 0.878000, valid loss: 91.720915
epoch: 3421, train precision: 0.999133, train loss: 10.070470, valid precision: 0.880600, valid loss: 91.576037
epoch: 3422, train precision: 0.999000, train loss: 10.177010, valid precision: 0.880600, valid loss: 90.945069
epoch: 3423, train precision: 0.999111, train loss: 10.073982, valid precision: 0.880000, valid loss: 91.084987
epoch: 3424, train precision: 0.999289, train loss: 10.092715, valid precision: 0.879400, valid loss: 92.498618
epoch: 3425, train precision: 0.999022, train loss: 10.172156, valid precision: 0.877800, valid loss: 91.528876
epoch: 3426, train precision: 0.999244, train loss: 10.100030, valid precision: 0.878800, valid loss: 92.652472
epoch: 3427, train precision: 0.999289, train loss: 10.070578, valid precision: 0.879400, valid loss: 90.854444
epoch: 3428, train precision: 0.998956, train loss: 10.233372, valid precision: 0.877200, valid loss: 92.868145
epoch: 3429, train precision: 0.999333, train loss: 10.049036, valid precision: 0.879000, valid loss: 93.079171
epoch: 3430, train precision: 0.999022, train loss: 10.159166, valid precision: 0.878200, valid loss: 91.811677
epoch: 3431, train precision: 0.999111, train loss: 10.128383, valid precision: 0.877600, valid loss: 94.254688
epoch: 3432, train precision: 0.999156, train loss: 10.143685, valid precision: 0.879200, valid loss: 91.426897
epoch: 3433, train precision: 0.999267, train loss: 10.051582, valid precision: 0.875000, valid loss: 94.598824
epoch: 3434, train precision: 0.999178, train loss: 10.099129, valid precision: 0.876000, valid loss: 94.677255
epoch: 3435, train precision: 0.998844, train loss: 10.156327, valid precision: 0.876400, valid loss: 94.668175
epoch: 3436, train precision: 0.998733, train loss: 10.197349, valid precision: 0.876200, valid loss: 93.902382
epoch: 3437, train precision: 0.999111, train loss: 10.138637, valid precision: 0.876800, valid loss: 93.645237
epoch: 3438, train precision: 0.999222, train loss: 10.087335, valid precision: 0.878000, valid loss: 93.217166
epoch: 3439, train precision: 0.999111, train loss: 10.157122, valid precision: 0.876400, valid loss: 93.903913
epoch: 3440, train precision: 0.998978, train loss: 10.186542, valid precision: 0.880400, valid loss: 90.947165
epoch: 3441, train precision: 0.999467, train loss: 10.022173, valid precision: 0.878600, valid loss: 92.573146
epoch: 3442, train precision: 0.999200, train loss: 10.115827, valid precision: 0.879200, valid loss: 90.952092
epoch: 3443, train precision: 0.999111, train loss: 10.146343, valid precision: 0.881400, valid loss: 89.720423
epoch: 3444, train precision: 0.999178, train loss: 10.173634, valid precision: 0.878200, valid loss: 92.117906
epoch: 3445, train precision: 0.999289, train loss: 10.071258, valid precision: 0.879800, valid loss: 90.423982
epoch: 3446, train precision: 0.998756, train loss: 10.247444, valid precision: 0.877800, valid loss: 92.520694
epoch: 3447, train precision: 0.999044, train loss: 10.130415, valid precision: 0.878400, valid loss: 93.873866
epoch: 3448, train precision: 0.999244, train loss: 10.055105, valid precision: 0.875000, valid loss: 99.584985
epoch: 3449, train precision: 0.999067, train loss: 10.123779, valid precision: 0.878000, valid loss: 94.585349
epoch: 3450, train precision: 0.999422, train loss: 9.991138, valid precision: 0.879800, valid loss: 95.142939
epoch: 3451, train precision: 0.999000, train loss: 10.126133, valid precision: 0.877600, valid loss: 94.640912
epoch: 3452, train precision: 0.999356, train loss: 10.055893, valid precision: 0.877800, valid loss: 95.051310
epoch: 3453, train precision: 0.998889, train loss: 10.250014, valid precision: 0.876000, valid loss: 94.914871
epoch: 3454, train precision: 0.998622, train loss: 10.247779, valid precision: 0.869800, valid loss: 96.728641
epoch: 3455, train precision: 0.998911, train loss: 10.112811, valid precision: 0.877000, valid loss: 94.802541
epoch: 3456, train precision: 0.999111, train loss: 10.151635, valid precision: 0.879600, valid loss: 95.347003
epoch: 3457, train precision: 0.999089, train loss: 10.072261, valid precision: 0.878600, valid loss: 93.815922
epoch: 3458, train precision: 0.999178, train loss: 10.131619, valid precision: 0.874800, valid loss: 94.090063
epoch: 3459, train precision: 0.999044, train loss: 10.100001, valid precision: 0.877400, valid loss: 97.245223
epoch: 3460, train precision: 0.999000, train loss: 10.144670, valid precision: 0.875800, valid loss: 95.749918
epoch: 3461, train precision: 0.998889, train loss: 10.158397, valid precision: 0.875400, valid loss: 94.328373
epoch: 3462, train precision: 0.998867, train loss: 10.241224, valid precision: 0.876400, valid loss: 93.807363
epoch: 3463, train precision: 0.999156, train loss: 10.092210, valid precision: 0.877600, valid loss: 91.005618
epoch: 3464, train precision: 0.999244, train loss: 10.073054, valid precision: 0.882000, valid loss: 90.497929
epoch: 3465, train precision: 0.999156, train loss: 10.086380, valid precision: 0.879600, valid loss: 91.960045
epoch: 3466, train precision: 0.998733, train loss: 10.186750, valid precision: 0.874800, valid loss: 95.938764
epoch: 3467, train precision: 0.998733, train loss: 10.214093, valid precision: 0.876200, valid loss: 94.201592
epoch: 3468, train precision: 0.999044, train loss: 10.164571, valid precision: 0.876200, valid loss: 93.938304
epoch: 3469, train precision: 0.999156, train loss: 10.147950, valid precision: 0.876800, valid loss: 92.882200
epoch: 3470, train precision: 0.999467, train loss: 10.023820, valid precision: 0.879800, valid loss: 90.007539
epoch: 3471, train precision: 0.999178, train loss: 10.134570, valid precision: 0.875200, valid loss: 95.103815
epoch: 3472, train precision: 0.999489, train loss: 10.007538, valid precision: 0.877400, valid loss: 92.704840
epoch: 3473, train precision: 0.998844, train loss: 10.190506, valid precision: 0.875200, valid loss: 94.728895
epoch: 3474, train precision: 0.999156, train loss: 10.171756, valid precision: 0.874600, valid loss: 94.621210
epoch: 3475, train precision: 0.999289, train loss: 10.088655, valid precision: 0.880000, valid loss: 93.416762
epoch: 3476, train precision: 0.998978, train loss: 10.180769, valid precision: 0.879400, valid loss: 94.660231
epoch: 3477, train precision: 0.998778, train loss: 10.179573, valid precision: 0.878800, valid loss: 95.914529
epoch: 3478, train precision: 0.999022, train loss: 10.193150, valid precision: 0.871800, valid loss: 95.689520
epoch: 3479, train precision: 0.999311, train loss: 10.071579, valid precision: 0.876200, valid loss: 95.557948
epoch: 3480, train precision: 0.999156, train loss: 10.113621, valid precision: 0.880200, valid loss: 92.556889
epoch: 3481, train precision: 0.999267, train loss: 10.082881, valid precision: 0.874400, valid loss: 93.500331
epoch: 3482, train precision: 0.999289, train loss: 10.045236, valid precision: 0.874400, valid loss: 94.904862
epoch: 3483, train precision: 0.999067, train loss: 10.137873, valid precision: 0.877000, valid loss: 94.123520
epoch: 3484, train precision: 0.999333, train loss: 10.079502, valid precision: 0.877800, valid loss: 92.679739
epoch: 3485, train precision: 0.999244, train loss: 10.060907, valid precision: 0.876400, valid loss: 91.525972
epoch: 3486, train precision: 0.999067, train loss: 10.139567, valid precision: 0.873200, valid loss: 95.235760
epoch: 3487, train precision: 0.999622, train loss: 9.990642, valid precision: 0.877200, valid loss: 94.643229
epoch: 3488, train precision: 0.998933, train loss: 10.125420, valid precision: 0.877200, valid loss: 95.235436
epoch: 3489, train precision: 0.999289, train loss: 10.038974, valid precision: 0.875200, valid loss: 96.593221
epoch: 3490, train precision: 0.999089, train loss: 10.079745, valid precision: 0.880000, valid loss: 96.196703
epoch: 3491, train precision: 0.999044, train loss: 10.153019, valid precision: 0.878800, valid loss: 95.484423
epoch: 3492, train precision: 0.998422, train loss: 10.402102, valid precision: 0.876200, valid loss: 94.208086
epoch: 3493, train precision: 0.999044, train loss: 10.141461, valid precision: 0.876800, valid loss: 94.944175
epoch: 3494, train precision: 0.999178, train loss: 10.145138, valid precision: 0.880000, valid loss: 93.804162
epoch: 3495, train precision: 0.999200, train loss: 10.038765, valid precision: 0.879200, valid loss: 94.086170
epoch: 3496, train precision: 0.998889, train loss: 10.186783, valid precision: 0.879000, valid loss: 96.875527
epoch: 3497, train precision: 0.999222, train loss: 10.054801, valid precision: 0.877000, valid loss: 96.442375
epoch: 3498, train precision: 0.998778, train loss: 10.253561, valid precision: 0.880200, valid loss: 95.304517
epoch: 3499, train precision: 0.998822, train loss: 10.143194, valid precision: 0.877800, valid loss: 92.833003
epoch: 3500, train precision: 0.999000, train loss: 10.181628, valid precision: 0.878000, valid loss: 92.138022
epoch: 3501, train precision: 0.999156, train loss: 10.105019, valid precision: 0.881800, valid loss: 93.384039
epoch: 3502, train precision: 0.999022, train loss: 10.082153, valid precision: 0.881800, valid loss: 91.356066
epoch: 3503, train precision: 0.999511, train loss: 9.975264, valid precision: 0.882800, valid loss: 90.132976
epoch: 3504, train precision: 0.999289, train loss: 10.081522, valid precision: 0.875800, valid loss: 91.614224
epoch: 3505, train precision: 0.999022, train loss: 10.158477, valid precision: 0.873600, valid loss: 96.300560
epoch: 3506, train precision: 0.999289, train loss: 10.065364, valid precision: 0.875200, valid loss: 94.430862
epoch: 3507, train precision: 0.998867, train loss: 10.177011, valid precision: 0.874200, valid loss: 97.967115
epoch: 3508, train precision: 0.998800, train loss: 10.127801, valid precision: 0.872600, valid loss: 96.566838
epoch: 3509, train precision: 0.999422, train loss: 10.043165, valid precision: 0.877400, valid loss: 93.160185
epoch: 3510, train precision: 0.999444, train loss: 10.002397, valid precision: 0.875800, valid loss: 96.221627
epoch: 3511, train precision: 0.999222, train loss: 10.052268, valid precision: 0.876800, valid loss: 93.276586
epoch: 3512, train precision: 0.999200, train loss: 10.063315, valid precision: 0.875200, valid loss: 96.498719
epoch: 3513, train precision: 0.999200, train loss: 10.090507, valid precision: 0.878800, valid loss: 92.856928
epoch: 3514, train precision: 0.999067, train loss: 10.100904, valid precision: 0.878200, valid loss: 93.879775
epoch: 3515, train precision: 0.999244, train loss: 10.109738, valid precision: 0.873800, valid loss: 92.755943
epoch: 3516, train precision: 0.999222, train loss: 10.083152, valid precision: 0.875400, valid loss: 93.233932
epoch: 3517, train precision: 0.999022, train loss: 10.071434, valid precision: 0.874800, valid loss: 94.799688
epoch: 3518, train precision: 0.999356, train loss: 10.049935, valid precision: 0.877800, valid loss: 91.629933
epoch: 3519, train precision: 0.998889, train loss: 10.112624, valid precision: 0.873600, valid loss: 93.813708
epoch: 3520, train precision: 0.998889, train loss: 10.181122, valid precision: 0.871000, valid loss: 93.911863
epoch: 3521, train precision: 0.999000, train loss: 10.180096, valid precision: 0.877000, valid loss: 94.248784
epoch: 3522, train precision: 0.999089, train loss: 10.195147, valid precision: 0.875600, valid loss: 93.019449
epoch: 3523, train precision: 0.999200, train loss: 10.082126, valid precision: 0.875800, valid loss: 92.822479
epoch: 3524, train precision: 0.998978, train loss: 10.133273, valid precision: 0.876200, valid loss: 93.397456
epoch: 3525, train precision: 0.999222, train loss: 10.070258, valid precision: 0.879000, valid loss: 91.189021
epoch: 3526, train precision: 0.999111, train loss: 10.084988, valid precision: 0.873400, valid loss: 92.181204
epoch: 3527, train precision: 0.999311, train loss: 10.055578, valid precision: 0.877000, valid loss: 90.669491
epoch: 3528, train precision: 0.999133, train loss: 10.076788, valid precision: 0.878600, valid loss: 91.768046
epoch: 3529, train precision: 0.999444, train loss: 9.994318, valid precision: 0.877600, valid loss: 92.001405
epoch: 3530, train precision: 0.999444, train loss: 10.001998, valid precision: 0.879400, valid loss: 93.231112
epoch: 3531, train precision: 0.998667, train loss: 10.148306, valid precision: 0.880000, valid loss: 95.192018
epoch: 3532, train precision: 0.998778, train loss: 10.209040, valid precision: 0.880800, valid loss: 91.995303
epoch: 3533, train precision: 0.999000, train loss: 10.134005, valid precision: 0.877800, valid loss: 94.293640
epoch: 3534, train precision: 0.999378, train loss: 10.056429, valid precision: 0.882200, valid loss: 92.726611
epoch: 3535, train precision: 0.999133, train loss: 10.096260, valid precision: 0.878200, valid loss: 92.901545
epoch: 3536, train precision: 0.998800, train loss: 10.197283, valid precision: 0.881000, valid loss: 91.356288
epoch: 3537, train precision: 0.998956, train loss: 10.176412, valid precision: 0.881000, valid loss: 89.785753
epoch: 3538, train precision: 0.999156, train loss: 10.071466, valid precision: 0.884000, valid loss: 90.417204
epoch: 3539, train precision: 0.999133, train loss: 10.114993, valid precision: 0.878200, valid loss: 91.967859
epoch: 3540, train precision: 0.998933, train loss: 10.150281, valid precision: 0.874800, valid loss: 94.453547
epoch: 3541, train precision: 0.999133, train loss: 10.089091, valid precision: 0.880400, valid loss: 91.232775
epoch: 3542, train precision: 0.999044, train loss: 10.186094, valid precision: 0.880000, valid loss: 91.663436
epoch: 3543, train precision: 0.998933, train loss: 10.155560, valid precision: 0.877800, valid loss: 91.985861
epoch: 3544, train precision: 0.999333, train loss: 10.018388, valid precision: 0.879400, valid loss: 90.939405
epoch: 3545, train precision: 0.998956, train loss: 10.108471, valid precision: 0.879600, valid loss: 91.742807
epoch: 3546, train precision: 0.998800, train loss: 10.227459, valid precision: 0.879800, valid loss: 93.134721
epoch: 3547, train precision: 0.999289, train loss: 10.089920, valid precision: 0.878400, valid loss: 90.834304
epoch: 3548, train precision: 0.999089, train loss: 10.080440, valid precision: 0.882200, valid loss: 88.463628
epoch: 3549, train precision: 0.999200, train loss: 10.066322, valid precision: 0.879400, valid loss: 91.694102
epoch: 3550, train precision: 0.999267, train loss: 10.042036, valid precision: 0.880000, valid loss: 91.765127
epoch: 3551, train precision: 0.999156, train loss: 10.137505, valid precision: 0.880200, valid loss: 93.576638
epoch: 3552, train precision: 0.999178, train loss: 10.121044, valid precision: 0.881800, valid loss: 90.980618
epoch: 3553, train precision: 0.998822, train loss: 10.167929, valid precision: 0.881200, valid loss: 92.337258
epoch: 3554, train precision: 0.999222, train loss: 10.099798, valid precision: 0.885600, valid loss: 89.410935
epoch: 3555, train precision: 0.999000, train loss: 10.110762, valid precision: 0.883200, valid loss: 92.220780
epoch: 3556, train precision: 0.999000, train loss: 10.096263, valid precision: 0.884600, valid loss: 94.209041
epoch: 3557, train precision: 0.999289, train loss: 10.047862, valid precision: 0.884200, valid loss: 94.196233
epoch: 3558, train precision: 0.999044, train loss: 10.110071, valid precision: 0.881400, valid loss: 93.129499
epoch: 3559, train precision: 0.998578, train loss: 10.244866, valid precision: 0.876000, valid loss: 94.996434
epoch: 3560, train precision: 0.999178, train loss: 10.159286, valid precision: 0.881600, valid loss: 93.165567
epoch: 3561, train precision: 0.998844, train loss: 10.187735, valid precision: 0.881200, valid loss: 93.042916
epoch: 3562, train precision: 0.998956, train loss: 10.172356, valid precision: 0.877800, valid loss: 93.212404
epoch: 3563, train precision: 0.999133, train loss: 10.058679, valid precision: 0.878400, valid loss: 94.067214
epoch: 3564, train precision: 0.998756, train loss: 10.174965, valid precision: 0.880400, valid loss: 95.739321
epoch: 3565, train precision: 0.999133, train loss: 10.106455, valid precision: 0.875600, valid loss: 94.064852
epoch: 3566, train precision: 0.998578, train loss: 10.227860, valid precision: 0.880000, valid loss: 93.801145
epoch: 3567, train precision: 0.998978, train loss: 10.162989, valid precision: 0.879400, valid loss: 94.948416
epoch: 3568, train precision: 0.999378, train loss: 10.037342, valid precision: 0.881000, valid loss: 93.266876
epoch: 3569, train precision: 0.998956, train loss: 10.109799, valid precision: 0.876800, valid loss: 94.403659
epoch: 3570, train precision: 0.999111, train loss: 10.124204, valid precision: 0.878200, valid loss: 95.101684
epoch: 3571, train precision: 0.999000, train loss: 10.136435, valid precision: 0.879400, valid loss: 94.470505
epoch: 3572, train precision: 0.999067, train loss: 10.127388, valid precision: 0.880400, valid loss: 93.430602
epoch: 3573, train precision: 0.999467, train loss: 10.007832, valid precision: 0.881200, valid loss: 91.361480
epoch: 3574, train precision: 0.999156, train loss: 10.067569, valid precision: 0.879000, valid loss: 92.791271
epoch: 3575, train precision: 0.998689, train loss: 10.254083, valid precision: 0.878600, valid loss: 93.535936
epoch: 3576, train precision: 0.998800, train loss: 10.203717, valid precision: 0.879600, valid loss: 91.479160
epoch: 3577, train precision: 0.999267, train loss: 10.051605, valid precision: 0.880200, valid loss: 90.517529
epoch: 3578, train precision: 0.998756, train loss: 10.231348, valid precision: 0.877000, valid loss: 93.096029
epoch: 3579, train precision: 0.999111, train loss: 10.099806, valid precision: 0.874800, valid loss: 95.644335
epoch: 3580, train precision: 0.999222, train loss: 10.102783, valid precision: 0.878600, valid loss: 96.287415
epoch: 3581, train precision: 0.999356, train loss: 10.028412, valid precision: 0.878200, valid loss: 93.156631
epoch: 3582, train precision: 0.999044, train loss: 10.181000, valid precision: 0.878600, valid loss: 93.470516
epoch: 3583, train precision: 0.999067, train loss: 10.140376, valid precision: 0.879600, valid loss: 92.370390
epoch: 3584, train precision: 0.999156, train loss: 10.081150, valid precision: 0.879400, valid loss: 92.535311
epoch: 3585, train precision: 0.998822, train loss: 10.202817, valid precision: 0.877200, valid loss: 92.422995
epoch: 3586, train precision: 0.999156, train loss: 10.062606, valid precision: 0.878200, valid loss: 95.167346
epoch: 3587, train precision: 0.998867, train loss: 10.155111, valid precision: 0.877800, valid loss: 93.226921
epoch: 3588, train precision: 0.998578, train loss: 10.306523, valid precision: 0.874600, valid loss: 94.908818
epoch: 3589, train precision: 0.998889, train loss: 10.171194, valid precision: 0.877000, valid loss: 92.520764
epoch: 3590, train precision: 0.999422, train loss: 10.018557, valid precision: 0.880800, valid loss: 92.628022
epoch: 3591, train precision: 0.999289, train loss: 10.041415, valid precision: 0.877000, valid loss: 93.524728
epoch: 3592, train precision: 0.998978, train loss: 10.103841, valid precision: 0.878000, valid loss: 94.558873
epoch: 3593, train precision: 0.999089, train loss: 10.123009, valid precision: 0.874400, valid loss: 94.847264
epoch: 3594, train precision: 0.999156, train loss: 10.134797, valid precision: 0.875200, valid loss: 94.848937
epoch: 3595, train precision: 0.999356, train loss: 10.083439, valid precision: 0.875800, valid loss: 93.571583
epoch: 3596, train precision: 0.999311, train loss: 10.047113, valid precision: 0.876800, valid loss: 96.034614
epoch: 3597, train precision: 0.998933, train loss: 10.160826, valid precision: 0.877600, valid loss: 95.030141
epoch: 3598, train precision: 0.999222, train loss: 10.060633, valid precision: 0.876000, valid loss: 96.599741
epoch: 3599, train precision: 0.999133, train loss: 10.063556, valid precision: 0.877200, valid loss: 96.318715
epoch: 3600, train precision: 0.998800, train loss: 10.181050, valid precision: 0.877800, valid loss: 94.979465
epoch: 3601, train precision: 0.999289, train loss: 10.019045, valid precision: 0.878000, valid loss: 94.896346
epoch: 3602, train precision: 0.998622, train loss: 10.270571, valid precision: 0.875600, valid loss: 96.369809
epoch: 3603, train precision: 0.999267, train loss: 10.074257, valid precision: 0.877600, valid loss: 95.874330
epoch: 3604, train precision: 0.999378, train loss: 9.983243, valid precision: 0.876800, valid loss: 94.327368
epoch: 3605, train precision: 0.998978, train loss: 10.152929, valid precision: 0.881000, valid loss: 95.754863
epoch: 3606, train precision: 0.998822, train loss: 10.257302, valid precision: 0.878600, valid loss: 92.254251
epoch: 3607, train precision: 0.999289, train loss: 10.050844, valid precision: 0.877400, valid loss: 93.157058
epoch: 3608, train precision: 0.999111, train loss: 10.079001, valid precision: 0.875200, valid loss: 94.347826
epoch: 3609, train precision: 0.999067, train loss: 10.109020, valid precision: 0.877600, valid loss: 94.585596
epoch: 3610, train precision: 0.998978, train loss: 10.092984, valid precision: 0.871400, valid loss: 96.175926
epoch: 3611, train precision: 0.999089, train loss: 10.057979, valid precision: 0.876000, valid loss: 96.848295
epoch: 3612, train precision: 0.999289, train loss: 10.078144, valid precision: 0.876800, valid loss: 96.673399
epoch: 3613, train precision: 0.999200, train loss: 10.049201, valid precision: 0.876600, valid loss: 97.257868
epoch: 3614, train precision: 0.998867, train loss: 10.139053, valid precision: 0.876600, valid loss: 94.982270
epoch: 3615, train precision: 0.999356, train loss: 10.003640, valid precision: 0.876400, valid loss: 94.189081
epoch: 3616, train precision: 0.998889, train loss: 10.090375, valid precision: 0.877600, valid loss: 94.585496
epoch: 3617, train precision: 0.999267, train loss: 10.096960, valid precision: 0.877200, valid loss: 92.684894
epoch: 3618, train precision: 0.999111, train loss: 10.099768, valid precision: 0.878400, valid loss: 90.776416
epoch: 3619, train precision: 0.999333, train loss: 10.023990, valid precision: 0.878800, valid loss: 91.814258
epoch: 3620, train precision: 0.998911, train loss: 10.076678, valid precision: 0.878200, valid loss: 92.611349
epoch: 3621, train precision: 0.999156, train loss: 10.036942, valid precision: 0.880600, valid loss: 92.201469
epoch: 3622, train precision: 0.998756, train loss: 10.172523, valid precision: 0.878000, valid loss: 94.357310
epoch: 3623, train precision: 0.998911, train loss: 10.144667, valid precision: 0.875800, valid loss: 93.711574
epoch: 3624, train precision: 0.999267, train loss: 10.047388, valid precision: 0.877000, valid loss: 98.070482
epoch: 3625, train precision: 0.998756, train loss: 10.201366, valid precision: 0.874800, valid loss: 98.301062
epoch: 3626, train precision: 0.999200, train loss: 10.104737, valid precision: 0.877600, valid loss: 97.146423
epoch: 3627, train precision: 0.999133, train loss: 10.074480, valid precision: 0.882000, valid loss: 93.535297
epoch: 3628, train precision: 0.999044, train loss: 10.098457, valid precision: 0.881200, valid loss: 90.837684
epoch: 3629, train precision: 0.999089, train loss: 10.164538, valid precision: 0.879400, valid loss: 91.896121
epoch: 3630, train precision: 0.999022, train loss: 10.112346, valid precision: 0.873200, valid loss: 89.818722
epoch: 3631, train precision: 0.999067, train loss: 10.157115, valid precision: 0.881000, valid loss: 90.076737
epoch: 3632, train precision: 0.999378, train loss: 9.984774, valid precision: 0.879600, valid loss: 90.616818
epoch: 3633, train precision: 0.999133, train loss: 10.035137, valid precision: 0.877000, valid loss: 91.627289
epoch: 3634, train precision: 0.999044, train loss: 10.078317, valid precision: 0.877200, valid loss: 93.608658
epoch: 3635, train precision: 0.999178, train loss: 10.062703, valid precision: 0.881000, valid loss: 90.213218
epoch: 3636, train precision: 0.998956, train loss: 10.078653, valid precision: 0.876600, valid loss: 93.143353
epoch: 3637, train precision: 0.999044, train loss: 10.088370, valid precision: 0.877000, valid loss: 96.293130
epoch: 3638, train precision: 0.998933, train loss: 10.083110, valid precision: 0.876000, valid loss: 95.238126
epoch: 3639, train precision: 0.999311, train loss: 10.033535, valid precision: 0.877800, valid loss: 92.470921
epoch: 3640, train precision: 0.998933, train loss: 10.108440, valid precision: 0.879000, valid loss: 94.866943
epoch: 3641, train precision: 0.999111, train loss: 10.088601, valid precision: 0.880800, valid loss: 92.050919
epoch: 3642, train precision: 0.999244, train loss: 10.081092, valid precision: 0.879000, valid loss: 92.900327
epoch: 3643, train precision: 0.999067, train loss: 10.008054, valid precision: 0.880400, valid loss: 92.266658
epoch: 3644, train precision: 0.999200, train loss: 10.095771, valid precision: 0.878200, valid loss: 89.822684
epoch: 3645, train precision: 0.999356, train loss: 10.031219, valid precision: 0.883400, valid loss: 91.122569
epoch: 3646, train precision: 0.999222, train loss: 10.093809, valid precision: 0.880400, valid loss: 91.658130
epoch: 3647, train precision: 0.999178, train loss: 10.075406, valid precision: 0.881800, valid loss: 91.115478
epoch: 3648, train precision: 0.999022, train loss: 10.173972, valid precision: 0.883000, valid loss: 91.769779
epoch: 3649, train precision: 0.999111, train loss: 10.086830, valid precision: 0.883400, valid loss: 93.247122
epoch: 3650, train precision: 0.999133, train loss: 10.087472, valid precision: 0.878800, valid loss: 92.464236
epoch: 3651, train precision: 0.999067, train loss: 10.085430, valid precision: 0.877400, valid loss: 92.137197
epoch: 3652, train precision: 0.999333, train loss: 10.008670, valid precision: 0.882800, valid loss: 92.950775
epoch: 3653, train precision: 0.999333, train loss: 10.060628, valid precision: 0.879200, valid loss: 89.989000
epoch: 3654, train precision: 0.999289, train loss: 10.009516, valid precision: 0.879200, valid loss: 90.995811
epoch: 3655, train precision: 0.999311, train loss: 9.998393, valid precision: 0.879800, valid loss: 91.931067
epoch: 3656, train precision: 0.998933, train loss: 10.184031, valid precision: 0.880800, valid loss: 94.666770
epoch: 3657, train precision: 0.998422, train loss: 10.231025, valid precision: 0.877800, valid loss: 93.548057
epoch: 3658, train precision: 0.999000, train loss: 10.095042, valid precision: 0.876800, valid loss: 94.412527
epoch: 3659, train precision: 0.998911, train loss: 10.097533, valid precision: 0.877400, valid loss: 93.483552
epoch: 3660, train precision: 0.998956, train loss: 10.090901, valid precision: 0.877400, valid loss: 91.925971
epoch: 3661, train precision: 0.999044, train loss: 10.077888, valid precision: 0.879200, valid loss: 94.061554
epoch: 3662, train precision: 0.999133, train loss: 10.083621, valid precision: 0.875600, valid loss: 96.587651
epoch: 3663, train precision: 0.998800, train loss: 10.178073, valid precision: 0.875000, valid loss: 92.683518
epoch: 3664, train precision: 0.999244, train loss: 10.040741, valid precision: 0.875600, valid loss: 92.629945
epoch: 3665, train precision: 0.999111, train loss: 10.086421, valid precision: 0.880200, valid loss: 93.599661
epoch: 3666, train precision: 0.999089, train loss: 10.094152, valid precision: 0.880000, valid loss: 92.966229
epoch: 3667, train precision: 0.999444, train loss: 10.025419, valid precision: 0.880400, valid loss: 91.680403
epoch: 3668, train precision: 0.999178, train loss: 10.075913, valid precision: 0.878800, valid loss: 91.318262
epoch: 3669, train precision: 0.999267, train loss: 10.043302, valid precision: 0.880400, valid loss: 90.668816
epoch: 3670, train precision: 0.998978, train loss: 10.087263, valid precision: 0.878000, valid loss: 92.025362
epoch: 3671, train precision: 0.999311, train loss: 10.038038, valid precision: 0.878600, valid loss: 92.008521
epoch: 3672, train precision: 0.999222, train loss: 10.034983, valid precision: 0.881000, valid loss: 91.896107
epoch: 3673, train precision: 0.999356, train loss: 9.969951, valid precision: 0.879600, valid loss: 92.425879
epoch: 3674, train precision: 0.999244, train loss: 10.036179, valid precision: 0.876600, valid loss: 93.411031
epoch: 3675, train precision: 0.999289, train loss: 10.088109, valid precision: 0.877000, valid loss: 93.592068
epoch: 3676, train precision: 0.998933, train loss: 10.156126, valid precision: 0.877200, valid loss: 95.000167
epoch: 3677, train precision: 0.999400, train loss: 9.997871, valid precision: 0.877600, valid loss: 92.157392
epoch: 3678, train precision: 0.999178, train loss: 10.065665, valid precision: 0.882000, valid loss: 92.068015
epoch: 3679, train precision: 0.999289, train loss: 10.009423, valid precision: 0.881600, valid loss: 92.294069
epoch: 3680, train precision: 0.998800, train loss: 10.155688, valid precision: 0.880800, valid loss: 94.823240
epoch: 3681, train precision: 0.998867, train loss: 10.159067, valid precision: 0.878600, valid loss: 90.645814
epoch: 3682, train precision: 0.999356, train loss: 10.017643, valid precision: 0.880200, valid loss: 92.038447
epoch: 3683, train precision: 0.998889, train loss: 10.147502, valid precision: 0.878600, valid loss: 91.027549
epoch: 3684, train precision: 0.999022, train loss: 10.102065, valid precision: 0.877800, valid loss: 91.917296
epoch: 3685, train precision: 0.999178, train loss: 10.060641, valid precision: 0.882800, valid loss: 92.609772
epoch: 3686, train precision: 0.998889, train loss: 10.156256, valid precision: 0.881800, valid loss: 91.602033
epoch: 3687, train precision: 0.999200, train loss: 10.092620, valid precision: 0.879200, valid loss: 91.372790
epoch: 3688, train precision: 0.999111, train loss: 10.087263, valid precision: 0.881200, valid loss: 92.515569
epoch: 3689, train precision: 0.999178, train loss: 10.108855, valid precision: 0.880600, valid loss: 91.413706
epoch: 3690, train precision: 0.999267, train loss: 10.079924, valid precision: 0.878800, valid loss: 91.395982
epoch: 3691, train precision: 0.999089, train loss: 10.112597, valid precision: 0.880200, valid loss: 90.720050
epoch: 3692, train precision: 0.999289, train loss: 10.018252, valid precision: 0.880800, valid loss: 90.859901
epoch: 3693, train precision: 0.999267, train loss: 10.050578, valid precision: 0.880200, valid loss: 93.466615
epoch: 3694, train precision: 0.998867, train loss: 10.120607, valid precision: 0.877200, valid loss: 90.174526
epoch: 3695, train precision: 0.999511, train loss: 9.997320, valid precision: 0.878600, valid loss: 91.281445
epoch: 3696, train precision: 0.998978, train loss: 10.100669, valid precision: 0.875400, valid loss: 93.963053
epoch: 3697, train precision: 0.998933, train loss: 10.098008, valid precision: 0.880200, valid loss: 90.698153
epoch: 3698, train precision: 0.999133, train loss: 10.083843, valid precision: 0.879800, valid loss: 90.319467
epoch: 3699, train precision: 0.999511, train loss: 9.971765, valid precision: 0.880000, valid loss: 92.000416
epoch: 3700, train precision: 0.999244, train loss: 10.016563, valid precision: 0.882600, valid loss: 91.583598
epoch: 3701, train precision: 0.999022, train loss: 10.080632, valid precision: 0.876200, valid loss: 94.519437
epoch: 3702, train precision: 0.999533, train loss: 9.939803, valid precision: 0.880800, valid loss: 90.226365
epoch: 3703, train precision: 0.999289, train loss: 10.031266, valid precision: 0.878800, valid loss: 91.011644
epoch: 3704, train precision: 0.999111, train loss: 10.069703, valid precision: 0.878800, valid loss: 90.805420
epoch: 3705, train precision: 0.999289, train loss: 10.001982, valid precision: 0.881800, valid loss: 90.343057
epoch: 3706, train precision: 0.999089, train loss: 10.067345, valid precision: 0.879400, valid loss: 90.580916
epoch: 3707, train precision: 0.998956, train loss: 10.085010, valid precision: 0.878400, valid loss: 91.497142
epoch: 3708, train precision: 0.999244, train loss: 10.027027, valid precision: 0.879600, valid loss: 94.923969
epoch: 3709, train precision: 0.999267, train loss: 10.038837, valid precision: 0.879200, valid loss: 93.297306
epoch: 3710, train precision: 0.998467, train loss: 10.275234, valid precision: 0.877000, valid loss: 95.816438
epoch: 3711, train precision: 0.999333, train loss: 10.008756, valid precision: 0.878600, valid loss: 93.011941
epoch: 3712, train precision: 0.999067, train loss: 10.123205, valid precision: 0.878600, valid loss: 93.902393
epoch: 3713, train precision: 0.998978, train loss: 10.074123, valid precision: 0.877000, valid loss: 93.223358
epoch: 3714, train precision: 0.999267, train loss: 10.072950, valid precision: 0.880200, valid loss: 93.519028
epoch: 3715, train precision: 0.998822, train loss: 10.175567, valid precision: 0.875400, valid loss: 95.353219
epoch: 3716, train precision: 0.999044, train loss: 10.080829, valid precision: 0.879200, valid loss: 94.231794
epoch: 3717, train precision: 0.999089, train loss: 10.107663, valid precision: 0.876200, valid loss: 95.569187
epoch: 3718, train precision: 0.999111, train loss: 10.013418, valid precision: 0.875800, valid loss: 92.726252
epoch: 3719, train precision: 0.999333, train loss: 10.029461, valid precision: 0.880200, valid loss: 93.275484
epoch: 3720, train precision: 0.999200, train loss: 10.044815, valid precision: 0.873200, valid loss: 94.547666
epoch: 3721, train precision: 0.999044, train loss: 10.085183, valid precision: 0.873800, valid loss: 93.846583
epoch: 3722, train precision: 0.999178, train loss: 10.034757, valid precision: 0.878200, valid loss: 93.123399
epoch: 3723, train precision: 0.999044, train loss: 10.066682, valid precision: 0.879000, valid loss: 93.370602
epoch: 3724, train precision: 0.999111, train loss: 10.025317, valid precision: 0.877400, valid loss: 93.517051
epoch: 3725, train precision: 0.998844, train loss: 10.156417, valid precision: 0.878000, valid loss: 94.056614
epoch: 3726, train precision: 0.999000, train loss: 10.062831, valid precision: 0.876600, valid loss: 94.309112
epoch: 3727, train precision: 0.998911, train loss: 10.112900, valid precision: 0.875000, valid loss: 98.056508
epoch: 3728, train precision: 0.999422, train loss: 9.982379, valid precision: 0.880200, valid loss: 93.056074
epoch: 3729, train precision: 0.999156, train loss: 10.089839, valid precision: 0.876800, valid loss: 93.869629
epoch: 3730, train precision: 0.999333, train loss: 10.023132, valid precision: 0.878600, valid loss: 92.507493
epoch: 3731, train precision: 0.998800, train loss: 10.215243, valid precision: 0.878200, valid loss: 92.292071
epoch: 3732, train precision: 0.998889, train loss: 10.116176, valid precision: 0.882400, valid loss: 90.892731
epoch: 3733, train precision: 0.999333, train loss: 9.988636, valid precision: 0.877200, valid loss: 92.890004
epoch: 3734, train precision: 0.999378, train loss: 10.029445, valid precision: 0.879600, valid loss: 94.629877
epoch: 3735, train precision: 0.999111, train loss: 10.031995, valid precision: 0.879200, valid loss: 92.758082
epoch: 3736, train precision: 0.999133, train loss: 10.075223, valid precision: 0.881800, valid loss: 94.751757
epoch: 3737, train precision: 0.999000, train loss: 10.092566, valid precision: 0.878200, valid loss: 95.853186
epoch: 3738, train precision: 0.999311, train loss: 10.031125, valid precision: 0.877800, valid loss: 93.921200
epoch: 3739, train precision: 0.998733, train loss: 10.199705, valid precision: 0.879000, valid loss: 94.151932
epoch: 3740, train precision: 0.999089, train loss: 10.094071, valid precision: 0.875000, valid loss: 94.848067
epoch: 3741, train precision: 0.999200, train loss: 10.093409, valid precision: 0.874400, valid loss: 94.004014
epoch: 3742, train precision: 0.999200, train loss: 10.078024, valid precision: 0.876400, valid loss: 95.262685
epoch: 3743, train precision: 0.999044, train loss: 10.019512, valid precision: 0.874400, valid loss: 93.976483
epoch: 3744, train precision: 0.999089, train loss: 10.070600, valid precision: 0.875600, valid loss: 91.263447
epoch: 3745, train precision: 0.999222, train loss: 10.066870, valid precision: 0.877200, valid loss: 92.721430
epoch: 3746, train precision: 0.999111, train loss: 10.012966, valid precision: 0.876600, valid loss: 92.163336
epoch: 3747, train precision: 0.999289, train loss: 9.994661, valid precision: 0.878000, valid loss: 91.327721
epoch: 3748, train precision: 0.999289, train loss: 10.006215, valid precision: 0.879800, valid loss: 90.772026
epoch: 3749, train precision: 0.999222, train loss: 10.027038, valid precision: 0.877800, valid loss: 91.739620
epoch: 3750, train precision: 0.999244, train loss: 10.039902, valid precision: 0.878600, valid loss: 93.229197
epoch: 3751, train precision: 0.999356, train loss: 10.000429, valid precision: 0.882800, valid loss: 90.073406
epoch: 3752, train precision: 0.999244, train loss: 10.078342, valid precision: 0.876600, valid loss: 93.703538
epoch: 3753, train precision: 0.999111, train loss: 10.056954, valid precision: 0.877800, valid loss: 91.454395
epoch: 3754, train precision: 0.998578, train loss: 10.189732, valid precision: 0.875600, valid loss: 91.684955
epoch: 3755, train precision: 0.999067, train loss: 10.040070, valid precision: 0.875600, valid loss: 91.582950
epoch: 3756, train precision: 0.998911, train loss: 10.037561, valid precision: 0.878800, valid loss: 91.676741
epoch: 3757, train precision: 0.998933, train loss: 10.092137, valid precision: 0.877400, valid loss: 91.317126
epoch: 3758, train precision: 0.999267, train loss: 10.032391, valid precision: 0.879800, valid loss: 91.164001
epoch: 3759, train precision: 0.999400, train loss: 10.032116, valid precision: 0.877200, valid loss: 92.343307
epoch: 3760, train precision: 0.999178, train loss: 10.061974, valid precision: 0.876400, valid loss: 90.224689
epoch: 3761, train precision: 0.999022, train loss: 10.104325, valid precision: 0.877800, valid loss: 93.836649
epoch: 3762, train precision: 0.998978, train loss: 10.087420, valid precision: 0.877800, valid loss: 92.264345
epoch: 3763, train precision: 0.998956, train loss: 10.107755, valid precision: 0.874800, valid loss: 91.567508
epoch: 3764, train precision: 0.999156, train loss: 10.050376, valid precision: 0.874400, valid loss: 94.799292
epoch: 3765, train precision: 0.998956, train loss: 10.117015, valid precision: 0.877800, valid loss: 93.030625
epoch: 3766, train precision: 0.999533, train loss: 9.912792, valid precision: 0.878200, valid loss: 94.296009
epoch: 3767, train precision: 0.999200, train loss: 10.036404, valid precision: 0.872800, valid loss: 95.834180
epoch: 3768, train precision: 0.998867, train loss: 10.090546, valid precision: 0.874200, valid loss: 95.228211
epoch: 3769, train precision: 0.999111, train loss: 10.069249, valid precision: 0.877200, valid loss: 96.121513
epoch: 3770, train precision: 0.999133, train loss: 10.033979, valid precision: 0.877200, valid loss: 93.626061
epoch: 3771, train precision: 0.999289, train loss: 9.966228, valid precision: 0.878200, valid loss: 94.855521
epoch: 3772, train precision: 0.998844, train loss: 10.073389, valid precision: 0.877200, valid loss: 98.489069
epoch: 3773, train precision: 0.998889, train loss: 10.103516, valid precision: 0.877800, valid loss: 96.567323
epoch: 3774, train precision: 0.998933, train loss: 10.105683, valid precision: 0.880400, valid loss: 96.207158
epoch: 3775, train precision: 0.998911, train loss: 10.135376, valid precision: 0.881800, valid loss: 96.475363
epoch: 3776, train precision: 0.998733, train loss: 10.199080, valid precision: 0.878400, valid loss: 96.894452
epoch: 3777, train precision: 0.999067, train loss: 10.033258, valid precision: 0.879000, valid loss: 92.779702
epoch: 3778, train precision: 0.999267, train loss: 9.994957, valid precision: 0.877000, valid loss: 94.564984
epoch: 3779, train precision: 0.999156, train loss: 10.028372, valid precision: 0.878400, valid loss: 95.414569
epoch: 3780, train precision: 0.999422, train loss: 9.981694, valid precision: 0.878600, valid loss: 95.621808
epoch: 3781, train precision: 0.999333, train loss: 9.992474, valid precision: 0.879200, valid loss: 94.255222
epoch: 3782, train precision: 0.999067, train loss: 10.111712, valid precision: 0.873000, valid loss: 98.826363
epoch: 3783, train precision: 0.999178, train loss: 10.037491, valid precision: 0.876800, valid loss: 94.769125
epoch: 3784, train precision: 0.998911, train loss: 10.093739, valid precision: 0.878000, valid loss: 95.056991
epoch: 3785, train precision: 0.998844, train loss: 10.075656, valid precision: 0.878600, valid loss: 96.866763
epoch: 3786, train precision: 0.999022, train loss: 10.100887, valid precision: 0.876200, valid loss: 93.161294
epoch: 3787, train precision: 0.998911, train loss: 10.097666, valid precision: 0.875200, valid loss: 96.444859
epoch: 3788, train precision: 0.998867, train loss: 10.131400, valid precision: 0.875200, valid loss: 97.453249
epoch: 3789, train precision: 0.999222, train loss: 10.028567, valid precision: 0.875000, valid loss: 95.090550
epoch: 3790, train precision: 0.998533, train loss: 10.244841, valid precision: 0.877200, valid loss: 95.180427
epoch: 3791, train precision: 0.999000, train loss: 10.019045, valid precision: 0.877400, valid loss: 94.289204
epoch: 3792, train precision: 0.999156, train loss: 10.048274, valid precision: 0.878200, valid loss: 94.533256
epoch: 3793, train precision: 0.999022, train loss: 10.052235, valid precision: 0.878000, valid loss: 94.898204
epoch: 3794, train precision: 0.999133, train loss: 10.087777, valid precision: 0.874000, valid loss: 97.434566
epoch: 3795, train precision: 0.999289, train loss: 10.018288, valid precision: 0.874200, valid loss: 96.268993
epoch: 3796, train precision: 0.999333, train loss: 10.029175, valid precision: 0.874200, valid loss: 95.481122
epoch: 3797, train precision: 0.999000, train loss: 10.067177, valid precision: 0.876600, valid loss: 96.982736
epoch: 3798, train precision: 0.999356, train loss: 9.972530, valid precision: 0.877600, valid loss: 93.975740
epoch: 3799, train precision: 0.999067, train loss: 10.033967, valid precision: 0.880000, valid loss: 94.015137
epoch: 3800, train precision: 0.999289, train loss: 9.978368, valid precision: 0.880000, valid loss: 90.951838
epoch: 3801, train precision: 0.998867, train loss: 10.126921, valid precision: 0.878000, valid loss: 94.359525
epoch: 3802, train precision: 0.999200, train loss: 9.995520, valid precision: 0.878600, valid loss: 94.106278
epoch: 3803, train precision: 0.999133, train loss: 9.994426, valid precision: 0.875000, valid loss: 94.497214
epoch: 3804, train precision: 0.999422, train loss: 9.939502, valid precision: 0.876000, valid loss: 96.200259
epoch: 3805, train precision: 0.999111, train loss: 10.090943, valid precision: 0.874800, valid loss: 95.480650
epoch: 3806, train precision: 0.999378, train loss: 9.962295, valid precision: 0.879600, valid loss: 94.227007
epoch: 3807, train precision: 0.999289, train loss: 9.960523, valid precision: 0.874600, valid loss: 95.876383
epoch: 3808, train precision: 0.999133, train loss: 10.034003, valid precision: 0.874800, valid loss: 93.831589
epoch: 3809, train precision: 0.998956, train loss: 10.081932, valid precision: 0.880600, valid loss: 91.562098
epoch: 3810, train precision: 0.999111, train loss: 10.027212, valid precision: 0.877600, valid loss: 95.033115
epoch: 3811, train precision: 0.999422, train loss: 9.973637, valid precision: 0.881000, valid loss: 97.175882
epoch: 3812, train precision: 0.999111, train loss: 10.105875, valid precision: 0.878200, valid loss: 95.847954
epoch: 3813, train precision: 0.999267, train loss: 10.024745, valid precision: 0.878400, valid loss: 95.025969
epoch: 3814, train precision: 0.998911, train loss: 10.125127, valid precision: 0.876200, valid loss: 95.559998
epoch: 3815, train precision: 0.999467, train loss: 9.973982, valid precision: 0.870800, valid loss: 96.880055
epoch: 3816, train precision: 0.999022, train loss: 10.074652, valid precision: 0.875800, valid loss: 98.243149
epoch: 3817, train precision: 0.998956, train loss: 10.113144, valid precision: 0.874000, valid loss: 100.152190
epoch: 3818, train precision: 0.999133, train loss: 10.050586, valid precision: 0.875800, valid loss: 96.174646
epoch: 3819, train precision: 0.999533, train loss: 9.923191, valid precision: 0.878400, valid loss: 95.854826
epoch: 3820, train precision: 0.999400, train loss: 9.943487, valid precision: 0.875600, valid loss: 97.822432
epoch: 3821, train precision: 0.999200, train loss: 10.045680, valid precision: 0.878800, valid loss: 97.369814
epoch: 3822, train precision: 0.999289, train loss: 10.025793, valid precision: 0.874000, valid loss: 95.844325
epoch: 3823, train precision: 0.999200, train loss: 9.992618, valid precision: 0.875400, valid loss: 98.045089
epoch: 3824, train precision: 0.999067, train loss: 10.023649, valid precision: 0.875400, valid loss: 93.827176
epoch: 3825, train precision: 0.999089, train loss: 10.030230, valid precision: 0.876000, valid loss: 94.050175
epoch: 3826, train precision: 0.999422, train loss: 9.951891, valid precision: 0.879200, valid loss: 94.332202
epoch: 3827, train precision: 0.999111, train loss: 10.047856, valid precision: 0.877000, valid loss: 96.466859
epoch: 3828, train precision: 0.998978, train loss: 10.006164, valid precision: 0.876000, valid loss: 98.902489
epoch: 3829, train precision: 0.998956, train loss: 10.074952, valid precision: 0.873200, valid loss: 96.994079
epoch: 3830, train precision: 0.999267, train loss: 9.973124, valid precision: 0.877400, valid loss: 95.528522
epoch: 3831, train precision: 0.999156, train loss: 10.030066, valid precision: 0.872400, valid loss: 99.362469
epoch: 3832, train precision: 0.999111, train loss: 10.026768, valid precision: 0.878400, valid loss: 95.355056
epoch: 3833, train precision: 0.999156, train loss: 10.044879, valid precision: 0.877800, valid loss: 96.554278
epoch: 3834, train precision: 0.999022, train loss: 10.056708, valid precision: 0.876800, valid loss: 95.340907
epoch: 3835, train precision: 0.999000, train loss: 10.096045, valid precision: 0.880600, valid loss: 95.815831
epoch: 3836, train precision: 0.999133, train loss: 10.049506, valid precision: 0.873400, valid loss: 96.433693
epoch: 3837, train precision: 0.998778, train loss: 10.046869, valid precision: 0.875200, valid loss: 95.911949
epoch: 3838, train precision: 0.999156, train loss: 9.996792, valid precision: 0.872800, valid loss: 95.447121
epoch: 3839, train precision: 0.998778, train loss: 10.088666, valid precision: 0.877000, valid loss: 94.165509
epoch: 3840, train precision: 0.999200, train loss: 10.034243, valid precision: 0.877800, valid loss: 94.501847
epoch: 3841, train precision: 0.998911, train loss: 10.091671, valid precision: 0.875800, valid loss: 95.318877
epoch: 3842, train precision: 0.999022, train loss: 10.052690, valid precision: 0.875200, valid loss: 95.163951
epoch: 3843, train precision: 0.999267, train loss: 9.983514, valid precision: 0.878000, valid loss: 94.394710
epoch: 3844, train precision: 0.999311, train loss: 10.000180, valid precision: 0.877400, valid loss: 92.408844
epoch: 3845, train precision: 0.998800, train loss: 10.130056, valid precision: 0.875200, valid loss: 92.215048
epoch: 3846, train precision: 0.999111, train loss: 10.064282, valid precision: 0.879800, valid loss: 91.571691
epoch: 3847, train precision: 0.999178, train loss: 10.081375, valid precision: 0.880000, valid loss: 92.364647
epoch: 3848, train precision: 0.999267, train loss: 10.011752, valid precision: 0.877600, valid loss: 90.341168
epoch: 3849, train precision: 0.999022, train loss: 10.038463, valid precision: 0.876200, valid loss: 97.192057
epoch: 3850, train precision: 0.998978, train loss: 10.049170, valid precision: 0.876400, valid loss: 96.379898
epoch: 3851, train precision: 0.998756, train loss: 10.115872, valid precision: 0.876600, valid loss: 95.038455
epoch: 3852, train precision: 0.999244, train loss: 9.995525, valid precision: 0.875400, valid loss: 96.607551
epoch: 3853, train precision: 0.999178, train loss: 9.999453, valid precision: 0.877200, valid loss: 94.621825
epoch: 3854, train precision: 0.999022, train loss: 10.050939, valid precision: 0.879000, valid loss: 94.213767
epoch: 3855, train precision: 0.999289, train loss: 9.982302, valid precision: 0.877000, valid loss: 95.294474
epoch: 3856, train precision: 0.999244, train loss: 10.034053, valid precision: 0.878400, valid loss: 93.553453
epoch: 3857, train precision: 0.999311, train loss: 10.039455, valid precision: 0.879400, valid loss: 95.869452
epoch: 3858, train precision: 0.999244, train loss: 10.024033, valid precision: 0.879600, valid loss: 92.042665
epoch: 3859, train precision: 0.999467, train loss: 9.929265, valid precision: 0.879600, valid loss: 94.489543
epoch: 3860, train precision: 0.998733, train loss: 10.189802, valid precision: 0.872200, valid loss: 96.492834
epoch: 3861, train precision: 0.999400, train loss: 9.951340, valid precision: 0.878600, valid loss: 93.864541
epoch: 3862, train precision: 0.999044, train loss: 10.048682, valid precision: 0.878400, valid loss: 91.489643
epoch: 3863, train precision: 0.999067, train loss: 10.043569, valid precision: 0.875200, valid loss: 93.071676
epoch: 3864, train precision: 0.998978, train loss: 10.079686, valid precision: 0.874000, valid loss: 99.227202
epoch: 3865, train precision: 0.999333, train loss: 9.941930, valid precision: 0.877200, valid loss: 97.029342
epoch: 3866, train precision: 0.999444, train loss: 9.952468, valid precision: 0.879200, valid loss: 92.490727
epoch: 3867, train precision: 0.999111, train loss: 10.038958, valid precision: 0.877200, valid loss: 91.861522
epoch: 3868, train precision: 0.999022, train loss: 10.019122, valid precision: 0.879800, valid loss: 94.277475
epoch: 3869, train precision: 0.999089, train loss: 10.007229, valid precision: 0.880400, valid loss: 93.595478
epoch: 3870, train precision: 0.998911, train loss: 10.027772, valid precision: 0.878000, valid loss: 96.543344
epoch: 3871, train precision: 0.998622, train loss: 10.169771, valid precision: 0.876400, valid loss: 94.803109
epoch: 3872, train precision: 0.999156, train loss: 10.034395, valid precision: 0.880200, valid loss: 93.938347
epoch: 3873, train precision: 0.999200, train loss: 9.987082, valid precision: 0.880200, valid loss: 95.313677
epoch: 3874, train precision: 0.999178, train loss: 9.975551, valid precision: 0.881200, valid loss: 95.564285
epoch: 3875, train precision: 0.999400, train loss: 9.930503, valid precision: 0.880600, valid loss: 95.758830
epoch: 3876, train precision: 0.998667, train loss: 10.138670, valid precision: 0.876800, valid loss: 95.157476
epoch: 3877, train precision: 0.999156, train loss: 10.049645, valid precision: 0.877600, valid loss: 95.369916
epoch: 3878, train precision: 0.998889, train loss: 10.059592, valid precision: 0.878000, valid loss: 91.491651
epoch: 3879, train precision: 0.998933, train loss: 10.038558, valid precision: 0.877200, valid loss: 93.005524
epoch: 3880, train precision: 0.999022, train loss: 10.116456, valid precision: 0.879200, valid loss: 93.708410
epoch: 3881, train precision: 0.999133, train loss: 10.004484, valid precision: 0.880200, valid loss: 91.308212
epoch: 3882, train precision: 0.998978, train loss: 10.030011, valid precision: 0.882000, valid loss: 94.164230
epoch: 3883, train precision: 0.999022, train loss: 10.026202, valid precision: 0.881400, valid loss: 92.233827
epoch: 3884, train precision: 0.998844, train loss: 10.134341, valid precision: 0.877400, valid loss: 94.249598
epoch: 3885, train precision: 0.999089, train loss: 10.008206, valid precision: 0.882800, valid loss: 92.176854
epoch: 3886, train precision: 0.999289, train loss: 9.949698, valid precision: 0.878000, valid loss: 91.950422
epoch: 3887, train precision: 0.999089, train loss: 10.042330, valid precision: 0.878800, valid loss: 93.622494
epoch: 3888, train precision: 0.998978, train loss: 10.036462, valid precision: 0.880800, valid loss: 93.125738
epoch: 3889, train precision: 0.999089, train loss: 10.051017, valid precision: 0.878600, valid loss: 95.976122
epoch: 3890, train precision: 0.999244, train loss: 9.962060, valid precision: 0.880200, valid loss: 93.231745
epoch: 3891, train precision: 0.999267, train loss: 9.911430, valid precision: 0.881400, valid loss: 95.858410
epoch: 3892, train precision: 0.999222, train loss: 9.996110, valid precision: 0.877600, valid loss: 93.588533
epoch: 3893, train precision: 0.999067, train loss: 10.026778, valid precision: 0.877000, valid loss: 94.511689
epoch: 3894, train precision: 0.999067, train loss: 10.013980, valid precision: 0.876800, valid loss: 96.548150
epoch: 3895, train precision: 0.999089, train loss: 9.995423, valid precision: 0.876600, valid loss: 95.630103
epoch: 3896, train precision: 0.999333, train loss: 9.949589, valid precision: 0.877800, valid loss: 95.416047
epoch: 3897, train precision: 0.999044, train loss: 10.090232, valid precision: 0.877800, valid loss: 94.053423
epoch: 3898, train precision: 0.999067, train loss: 10.049714, valid precision: 0.879200, valid loss: 97.027890
epoch: 3899, train precision: 0.998800, train loss: 10.042776, valid precision: 0.879000, valid loss: 95.731089
epoch: 3900, train precision: 0.998844, train loss: 10.131724, valid precision: 0.877200, valid loss: 95.421181
epoch: 3901, train precision: 0.998978, train loss: 10.129209, valid precision: 0.876800, valid loss: 97.084537
epoch: 3902, train precision: 0.999178, train loss: 10.009730, valid precision: 0.881800, valid loss: 94.021683
epoch: 3903, train precision: 0.999022, train loss: 10.032589, valid precision: 0.879400, valid loss: 98.715184
epoch: 3904, train precision: 0.999133, train loss: 10.002926, valid precision: 0.878800, valid loss: 99.103555
epoch: 3905, train precision: 0.999133, train loss: 9.996648, valid precision: 0.878600, valid loss: 98.133589
epoch: 3906, train precision: 0.999000, train loss: 10.091375, valid precision: 0.881200, valid loss: 97.575543
epoch: 3907, train precision: 0.999244, train loss: 10.023125, valid precision: 0.880000, valid loss: 94.888801
epoch: 3908, train precision: 0.999178, train loss: 10.004935, valid precision: 0.879000, valid loss: 97.819124
epoch: 3909, train precision: 0.998822, train loss: 10.133607, valid precision: 0.880200, valid loss: 95.280341
epoch: 3910, train precision: 0.999422, train loss: 9.927083, valid precision: 0.878200, valid loss: 95.433118
epoch: 3911, train precision: 0.998978, train loss: 10.056773, valid precision: 0.877400, valid loss: 94.277269
epoch: 3912, train precision: 0.998933, train loss: 10.088074, valid precision: 0.875200, valid loss: 93.855441
epoch: 3913, train precision: 0.999000, train loss: 10.067982, valid precision: 0.880000, valid loss: 92.360251
epoch: 3914, train precision: 0.998911, train loss: 10.064007, valid precision: 0.875200, valid loss: 97.509974
epoch: 3915, train precision: 0.999089, train loss: 10.030709, valid precision: 0.875800, valid loss: 96.523891
epoch: 3916, train precision: 0.999422, train loss: 9.931011, valid precision: 0.880200, valid loss: 95.129377
epoch: 3917, train precision: 0.999133, train loss: 10.022186, valid precision: 0.881000, valid loss: 91.811162
epoch: 3918, train precision: 0.998911, train loss: 10.039711, valid precision: 0.878600, valid loss: 95.550536
epoch: 3919, train precision: 0.999044, train loss: 10.018622, valid precision: 0.878400, valid loss: 93.321071
epoch: 3920, train precision: 0.999267, train loss: 9.949448, valid precision: 0.879600, valid loss: 93.510739
epoch: 3921, train precision: 0.999133, train loss: 10.010659, valid precision: 0.880000, valid loss: 95.412632
epoch: 3922, train precision: 0.999133, train loss: 9.997275, valid precision: 0.877200, valid loss: 95.500243
epoch: 3923, train precision: 0.999044, train loss: 10.086316, valid precision: 0.875400, valid loss: 95.553374
epoch: 3924, train precision: 0.999067, train loss: 10.045873, valid precision: 0.878600, valid loss: 95.581728
epoch: 3925, train precision: 0.999244, train loss: 9.961792, valid precision: 0.877400, valid loss: 96.238872
epoch: 3926, train precision: 0.999089, train loss: 10.001435, valid precision: 0.878400, valid loss: 93.222107
epoch: 3927, train precision: 0.999000, train loss: 10.087728, valid precision: 0.877600, valid loss: 94.903303
epoch: 3928, train precision: 0.999311, train loss: 9.938381, valid precision: 0.877800, valid loss: 94.647546
epoch: 3929, train precision: 0.999422, train loss: 9.909028, valid precision: 0.878400, valid loss: 95.034792
epoch: 3930, train precision: 0.999089, train loss: 10.032777, valid precision: 0.876800, valid loss: 97.338678
epoch: 3931, train precision: 0.998978, train loss: 10.074299, valid precision: 0.874800, valid loss: 97.815215
epoch: 3932, train precision: 0.999022, train loss: 10.030960, valid precision: 0.876400, valid loss: 98.777473
epoch: 3933, train precision: 0.999244, train loss: 9.985577, valid precision: 0.882000, valid loss: 93.807915
epoch: 3934, train precision: 0.999267, train loss: 9.927479, valid precision: 0.881600, valid loss: 95.653327
epoch: 3935, train precision: 0.999133, train loss: 10.027133, valid precision: 0.881800, valid loss: 93.545498
epoch: 3936, train precision: 0.999356, train loss: 9.951204, valid precision: 0.876200, valid loss: 93.734631
epoch: 3937, train precision: 0.999200, train loss: 9.969873, valid precision: 0.881200, valid loss: 95.755444
epoch: 3938, train precision: 0.998978, train loss: 10.087186, valid precision: 0.880000, valid loss: 97.685825
epoch: 3939, train precision: 0.998756, train loss: 10.168019, valid precision: 0.880000, valid loss: 94.005000
epoch: 3940, train precision: 0.999267, train loss: 9.997099, valid precision: 0.875000, valid loss: 95.335022
epoch: 3941, train precision: 0.998822, train loss: 10.121874, valid precision: 0.873600, valid loss: 96.341962
epoch: 3942, train precision: 0.998978, train loss: 10.045598, valid precision: 0.873800, valid loss: 96.281871
epoch: 3943, train precision: 0.999267, train loss: 9.987036, valid precision: 0.876800, valid loss: 95.466638
epoch: 3944, train precision: 0.999022, train loss: 10.011055, valid precision: 0.881600, valid loss: 93.287690
epoch: 3945, train precision: 0.999222, train loss: 10.002553, valid precision: 0.878600, valid loss: 94.896152
epoch: 3946, train precision: 0.999356, train loss: 9.927549, valid precision: 0.877400, valid loss: 95.213202
epoch: 3947, train precision: 0.998822, train loss: 10.113203, valid precision: 0.878600, valid loss: 95.060612
epoch: 3948, train precision: 0.998911, train loss: 10.072575, valid precision: 0.884000, valid loss: 92.678526
epoch: 3949, train precision: 0.998533, train loss: 10.146707, valid precision: 0.885600, valid loss: 93.115703
epoch: 3950, train precision: 0.999222, train loss: 9.975459, valid precision: 0.882400, valid loss: 93.878851
epoch: 3951, train precision: 0.999400, train loss: 9.943350, valid precision: 0.879000, valid loss: 93.930986
epoch: 3952, train precision: 0.999044, train loss: 9.993677, valid precision: 0.881200, valid loss: 93.308422
epoch: 3953, train precision: 0.998778, train loss: 10.178048, valid precision: 0.881400, valid loss: 92.365647
epoch: 3954, train precision: 0.999089, train loss: 10.030603, valid precision: 0.879000, valid loss: 92.381167
epoch: 3955, train precision: 0.999000, train loss: 10.033001, valid precision: 0.879200, valid loss: 90.531922
epoch: 3956, train precision: 0.999311, train loss: 9.910470, valid precision: 0.880800, valid loss: 91.570382
epoch: 3957, train precision: 0.999244, train loss: 9.982720, valid precision: 0.882800, valid loss: 91.222355
epoch: 3958, train precision: 0.999067, train loss: 10.028875, valid precision: 0.882200, valid loss: 92.606946
epoch: 3959, train precision: 0.999067, train loss: 10.041137, valid precision: 0.881600, valid loss: 92.341898
epoch: 3960, train precision: 0.999222, train loss: 9.991138, valid precision: 0.880000, valid loss: 94.269502
epoch: 3961, train precision: 0.998911, train loss: 10.043516, valid precision: 0.879000, valid loss: 93.429001
epoch: 3962, train precision: 0.999244, train loss: 9.940114, valid precision: 0.875200, valid loss: 94.575415
epoch: 3963, train precision: 0.999067, train loss: 10.012504, valid precision: 0.878000, valid loss: 93.991618
epoch: 3964, train precision: 0.998667, train loss: 10.137751, valid precision: 0.876600, valid loss: 92.706093
epoch: 3965, train precision: 0.999244, train loss: 9.955295, valid precision: 0.877800, valid loss: 92.540602
epoch: 3966, train precision: 0.998956, train loss: 10.027893, valid precision: 0.878400, valid loss: 94.768944
epoch: 3967, train precision: 0.999200, train loss: 9.993698, valid precision: 0.876000, valid loss: 94.686589
epoch: 3968, train precision: 0.999067, train loss: 10.036639, valid precision: 0.881000, valid loss: 92.548217
epoch: 3969, train precision: 0.999378, train loss: 9.936835, valid precision: 0.879000, valid loss: 94.371889
epoch: 3970, train precision: 0.999089, train loss: 10.004105, valid precision: 0.877000, valid loss: 95.292307
epoch: 3971, train precision: 0.998778, train loss: 10.146721, valid precision: 0.880000, valid loss: 93.984033
epoch: 3972, train precision: 0.999022, train loss: 10.069359, valid precision: 0.876600, valid loss: 91.884457
epoch: 3973, train precision: 0.998844, train loss: 10.137315, valid precision: 0.878800, valid loss: 94.512594
epoch: 3974, train precision: 0.999022, train loss: 10.012601, valid precision: 0.879800, valid loss: 94.238010
epoch: 3975, train precision: 0.999200, train loss: 9.968154, valid precision: 0.874600, valid loss: 95.143942
epoch: 3976, train precision: 0.999133, train loss: 9.967563, valid precision: 0.877600, valid loss: 94.646213
epoch: 3977, train precision: 0.998756, train loss: 10.054517, valid precision: 0.881400, valid loss: 93.136748
epoch: 3978, train precision: 0.999444, train loss: 9.893337, valid precision: 0.877800, valid loss: 92.488387
epoch: 3979, train precision: 0.999178, train loss: 9.966312, valid precision: 0.880600, valid loss: 90.564221
epoch: 3980, train precision: 0.999333, train loss: 9.965875, valid precision: 0.873800, valid loss: 93.897460
epoch: 3981, train precision: 0.999200, train loss: 10.042021, valid precision: 0.878400, valid loss: 90.659904
epoch: 3982, train precision: 0.999178, train loss: 9.991987, valid precision: 0.879400, valid loss: 93.176342
epoch: 3983, train precision: 0.998800, train loss: 10.066135, valid precision: 0.879200, valid loss: 95.008187
epoch: 3984, train precision: 0.999378, train loss: 9.996335, valid precision: 0.878800, valid loss: 90.297956
epoch: 3985, train precision: 0.999022, train loss: 10.050377, valid precision: 0.880000, valid loss: 90.225932
epoch: 3986, train precision: 0.999178, train loss: 9.965628, valid precision: 0.880000, valid loss: 90.219638
epoch: 3987, train precision: 0.999244, train loss: 10.016077, valid precision: 0.873600, valid loss: 93.561711
epoch: 3988, train precision: 0.999133, train loss: 9.961403, valid precision: 0.875800, valid loss: 93.218431
epoch: 3989, train precision: 0.999244, train loss: 9.935257, valid precision: 0.880000, valid loss: 90.907264
epoch: 3990, train precision: 0.999044, train loss: 10.012808, valid precision: 0.879400, valid loss: 92.698783
epoch: 3991, train precision: 0.999133, train loss: 9.996431, valid precision: 0.876200, valid loss: 95.063976
epoch: 3992, train precision: 0.999000, train loss: 10.008463, valid precision: 0.877400, valid loss: 95.001705
epoch: 3993, train precision: 0.999067, train loss: 10.014923, valid precision: 0.880200, valid loss: 97.056799
epoch: 3994, train precision: 0.999022, train loss: 10.022414, valid precision: 0.878000, valid loss: 94.017834
epoch: 3995, train precision: 0.998978, train loss: 10.087600, valid precision: 0.875600, valid loss: 98.302021
epoch: 3996, train precision: 0.998778, train loss: 10.023619, valid precision: 0.874000, valid loss: 98.043115
epoch: 3997, train precision: 0.999400, train loss: 9.962021, valid precision: 0.881200, valid loss: 94.012563
epoch: 3998, train precision: 0.999222, train loss: 9.984694, valid precision: 0.880200, valid loss: 94.954702
epoch: 3999, train precision: 0.999178, train loss: 9.999421, valid precision: 0.871600, valid loss: 95.557900
epoch: 4000, train precision: 0.999000, train loss: 10.021297, valid precision: 0.879400, valid loss: 93.176680
epoch: 4001, train precision: 0.999178, train loss: 10.002033, valid precision: 0.878800, valid loss: 92.386929
epoch: 4002, train precision: 0.999022, train loss: 10.016885, valid precision: 0.878200, valid loss: 94.538204
epoch: 4003, train precision: 0.998911, train loss: 10.022299, valid precision: 0.878200, valid loss: 94.094250
epoch: 4004, train precision: 0.999000, train loss: 10.073588, valid precision: 0.875600, valid loss: 92.598110
epoch: 4005, train precision: 0.999200, train loss: 9.966075, valid precision: 0.880400, valid loss: 91.493150
epoch: 4006, train precision: 0.999333, train loss: 9.969205, valid precision: 0.875600, valid loss: 93.316240
epoch: 4007, train precision: 0.999244, train loss: 9.940324, valid precision: 0.877800, valid loss: 94.349166
epoch: 4008, train precision: 0.999289, train loss: 9.953065, valid precision: 0.873200, valid loss: 98.531831
epoch: 4009, train precision: 0.999200, train loss: 9.941367, valid precision: 0.878400, valid loss: 94.690999
epoch: 4010, train precision: 0.998889, train loss: 10.054849, valid precision: 0.876200, valid loss: 95.328736
epoch: 4011, train precision: 0.999400, train loss: 9.951374, valid precision: 0.875000, valid loss: 97.284932
epoch: 4012, train precision: 0.999311, train loss: 9.969741, valid precision: 0.875200, valid loss: 94.883486
epoch: 4013, train precision: 0.999156, train loss: 10.000011, valid precision: 0.876400, valid loss: 93.743937
epoch: 4014, train precision: 0.998978, train loss: 10.069616, valid precision: 0.877600, valid loss: 96.864637
epoch: 4015, train precision: 0.998844, train loss: 10.107759, valid precision: 0.880000, valid loss: 93.500382
epoch: 4016, train precision: 0.999022, train loss: 10.007174, valid precision: 0.874200, valid loss: 95.939466
epoch: 4017, train precision: 0.999089, train loss: 10.083869, valid precision: 0.874000, valid loss: 92.692590
epoch: 4018, train precision: 0.999244, train loss: 9.974661, valid precision: 0.876800, valid loss: 94.182803
epoch: 4019, train precision: 0.998689, train loss: 10.064891, valid precision: 0.881800, valid loss: 92.921411
epoch: 4020, train precision: 0.998978, train loss: 9.992369, valid precision: 0.879600, valid loss: 93.109088
epoch: 4021, train precision: 0.999022, train loss: 10.006270, valid precision: 0.879400, valid loss: 94.414266
epoch: 4022, train precision: 0.999089, train loss: 10.008809, valid precision: 0.877400, valid loss: 93.278445
epoch: 4023, train precision: 0.999133, train loss: 10.013424, valid precision: 0.880000, valid loss: 92.112159
epoch: 4024, train precision: 0.999311, train loss: 9.945786, valid precision: 0.880600, valid loss: 94.627905
epoch: 4025, train precision: 0.999289, train loss: 9.956099, valid precision: 0.882000, valid loss: 94.804334
epoch: 4026, train precision: 0.999111, train loss: 10.057650, valid precision: 0.880200, valid loss: 91.966548
epoch: 4027, train precision: 0.998667, train loss: 10.116241, valid precision: 0.873800, valid loss: 93.866618
epoch: 4028, train precision: 0.999444, train loss: 9.905393, valid precision: 0.876400, valid loss: 93.112025
epoch: 4029, train precision: 0.999067, train loss: 9.987750, valid precision: 0.877200, valid loss: 94.138025
epoch: 4030, train precision: 0.999422, train loss: 9.911680, valid precision: 0.874000, valid loss: 96.090355
epoch: 4031, train precision: 0.998956, train loss: 10.017886, valid precision: 0.876600, valid loss: 95.859423
epoch: 4032, train precision: 0.999000, train loss: 10.089606, valid precision: 0.876600, valid loss: 94.780505
epoch: 4033, train precision: 0.998844, train loss: 10.035477, valid precision: 0.877400, valid loss: 94.963848
epoch: 4034, train precision: 0.999044, train loss: 10.004635, valid precision: 0.872800, valid loss: 96.427155
epoch: 4035, train precision: 0.999000, train loss: 10.012632, valid precision: 0.875800, valid loss: 94.955189
epoch: 4036, train precision: 0.999467, train loss: 9.919112, valid precision: 0.876600, valid loss: 94.721687
epoch: 4037, train precision: 0.999356, train loss: 9.904996, valid precision: 0.874800, valid loss: 96.677646
epoch: 4038, train precision: 0.999489, train loss: 9.907846, valid precision: 0.877200, valid loss: 95.032014
epoch: 4039, train precision: 0.999111, train loss: 9.939021, valid precision: 0.875000, valid loss: 95.879637
epoch: 4040, train precision: 0.999222, train loss: 9.930493, valid precision: 0.876600, valid loss: 97.229915
epoch: 4041, train precision: 0.999156, train loss: 10.017699, valid precision: 0.880600, valid loss: 95.827241
epoch: 4042, train precision: 0.999111, train loss: 9.984697, valid precision: 0.878200, valid loss: 95.871195
epoch: 4043, train precision: 0.999222, train loss: 9.908048, valid precision: 0.879800, valid loss: 93.811008
epoch: 4044, train precision: 0.999289, train loss: 9.975765, valid precision: 0.879400, valid loss: 94.047660
epoch: 4045, train precision: 0.998867, train loss: 10.057408, valid precision: 0.879000, valid loss: 95.422919
epoch: 4046, train precision: 0.999178, train loss: 9.954013, valid precision: 0.875600, valid loss: 96.756511
epoch: 4047, train precision: 0.999156, train loss: 9.993321, valid precision: 0.877400, valid loss: 94.535059
epoch: 4048, train precision: 0.999178, train loss: 10.006488, valid precision: 0.877600, valid loss: 94.666222
epoch: 4049, train precision: 0.998889, train loss: 10.073149, valid precision: 0.875800, valid loss: 94.493934
epoch: 4050, train precision: 0.999200, train loss: 10.030837, valid precision: 0.877600, valid loss: 94.412010
epoch: 4051, train precision: 0.999333, train loss: 9.937549, valid precision: 0.880400, valid loss: 93.253958
epoch: 4052, train precision: 0.999378, train loss: 9.916736, valid precision: 0.878200, valid loss: 93.103162
epoch: 4053, train precision: 0.999067, train loss: 10.006006, valid precision: 0.881400, valid loss: 92.804737
epoch: 4054, train precision: 0.999222, train loss: 9.943693, valid precision: 0.880400, valid loss: 92.913306
epoch: 4055, train precision: 0.998956, train loss: 10.075161, valid precision: 0.881400, valid loss: 91.927838
epoch: 4056, train precision: 0.999356, train loss: 9.879434, valid precision: 0.882800, valid loss: 91.828660
epoch: 4057, train precision: 0.999244, train loss: 10.014546, valid precision: 0.878400, valid loss: 91.960865
epoch: 4058, train precision: 0.998867, train loss: 10.096942, valid precision: 0.876200, valid loss: 93.708378
epoch: 4059, train precision: 0.998844, train loss: 10.065498, valid precision: 0.878000, valid loss: 93.786718
epoch: 4060, train precision: 0.999089, train loss: 10.015551, valid precision: 0.880600, valid loss: 92.936388
epoch: 4061, train precision: 0.999222, train loss: 9.957452, valid precision: 0.881800, valid loss: 90.922914
epoch: 4062, train precision: 0.999311, train loss: 9.909453, valid precision: 0.877800, valid loss: 94.658342
epoch: 4063, train precision: 0.999311, train loss: 9.914012, valid precision: 0.878200, valid loss: 94.586237
epoch: 4064, train precision: 0.999444, train loss: 9.905836, valid precision: 0.876400, valid loss: 93.503711
epoch: 4065, train precision: 0.999311, train loss: 9.901952, valid precision: 0.875400, valid loss: 94.983858
epoch: 4066, train precision: 0.998733, train loss: 10.060097, valid precision: 0.875000, valid loss: 96.204696
epoch: 4067, train precision: 0.999378, train loss: 9.934385, valid precision: 0.876000, valid loss: 94.091338
epoch: 4068, train precision: 0.998933, train loss: 10.013276, valid precision: 0.875400, valid loss: 96.132850
epoch: 4069, train precision: 0.999089, train loss: 9.989213, valid precision: 0.879200, valid loss: 93.997883
epoch: 4070, train precision: 0.998689, train loss: 10.148226, valid precision: 0.878800, valid loss: 91.736159
epoch: 4071, train precision: 0.999311, train loss: 9.960663, valid precision: 0.875400, valid loss: 93.367227
epoch: 4072, train precision: 0.998733, train loss: 10.055421, valid precision: 0.881000, valid loss: 93.383357
epoch: 4073, train precision: 0.999422, train loss: 9.880352, valid precision: 0.877000, valid loss: 94.081065
epoch: 4074, train precision: 0.999067, train loss: 10.004377, valid precision: 0.880000, valid loss: 90.267001
epoch: 4075, train precision: 0.999311, train loss: 9.980544, valid precision: 0.881200, valid loss: 91.519378
epoch: 4076, train precision: 0.999022, train loss: 10.022899, valid precision: 0.876200, valid loss: 93.073990
epoch: 4077, train precision: 0.998667, train loss: 10.109045, valid precision: 0.878200, valid loss: 91.887245
epoch: 4078, train precision: 0.999000, train loss: 10.065331, valid precision: 0.877800, valid loss: 91.155451
epoch: 4079, train precision: 0.999156, train loss: 9.983601, valid precision: 0.877000, valid loss: 91.827780
epoch: 4080, train precision: 0.998978, train loss: 10.050268, valid precision: 0.880200, valid loss: 92.431618
epoch: 4081, train precision: 0.999222, train loss: 9.910156, valid precision: 0.878200, valid loss: 91.603737
epoch: 4082, train precision: 0.998556, train loss: 10.116552, valid precision: 0.882600, valid loss: 92.585673
epoch: 4083, train precision: 0.999467, train loss: 9.906918, valid precision: 0.881600, valid loss: 92.961652
epoch: 4084, train precision: 0.999133, train loss: 9.978269, valid precision: 0.879600, valid loss: 91.535089
epoch: 4085, train precision: 0.999067, train loss: 10.024610, valid precision: 0.880000, valid loss: 92.188410
epoch: 4086, train precision: 0.999133, train loss: 9.990042, valid precision: 0.878600, valid loss: 92.376051
epoch: 4087, train precision: 0.999067, train loss: 10.055167, valid precision: 0.880200, valid loss: 92.580057
epoch: 4088, train precision: 0.999378, train loss: 9.942268, valid precision: 0.874400, valid loss: 93.778879
epoch: 4089, train precision: 0.999222, train loss: 9.947630, valid precision: 0.879600, valid loss: 94.111614
epoch: 4090, train precision: 0.999289, train loss: 9.954007, valid precision: 0.878600, valid loss: 94.267526
epoch: 4091, train precision: 0.999000, train loss: 10.019353, valid precision: 0.876800, valid loss: 94.452689
epoch: 4092, train precision: 0.998911, train loss: 10.040671, valid precision: 0.880000, valid loss: 96.041000
epoch: 4093, train precision: 0.999378, train loss: 9.954914, valid precision: 0.879600, valid loss: 92.055748
epoch: 4094, train precision: 0.999111, train loss: 9.973501, valid precision: 0.877400, valid loss: 92.680910
epoch: 4095, train precision: 0.999133, train loss: 9.973488, valid precision: 0.877200, valid loss: 93.696335
epoch: 4096, train precision: 0.999311, train loss: 9.963408, valid precision: 0.874400, valid loss: 93.007604
epoch: 4097, train precision: 0.999644, train loss: 9.861951, valid precision: 0.880800, valid loss: 92.356455
epoch: 4098, train precision: 0.998756, train loss: 10.107254, valid precision: 0.879000, valid loss: 91.918276
epoch: 4099, train precision: 0.999178, train loss: 9.953051, valid precision: 0.876800, valid loss: 94.161235
epoch: 4100, train precision: 0.999200, train loss: 9.976429, valid precision: 0.879000, valid loss: 91.955019
epoch: 4101, train precision: 0.999200, train loss: 10.021811, valid precision: 0.877600, valid loss: 93.174140
epoch: 4102, train precision: 0.999067, train loss: 9.995580, valid precision: 0.874000, valid loss: 93.160233
epoch: 4103, train precision: 0.999622, train loss: 9.852420, valid precision: 0.880600, valid loss: 93.627831
epoch: 4104, train precision: 0.998911, train loss: 10.002058, valid precision: 0.877800, valid loss: 91.862655
epoch: 4105, train precision: 0.999178, train loss: 9.989865, valid precision: 0.878200, valid loss: 94.734084
epoch: 4106, train precision: 0.999178, train loss: 9.991001, valid precision: 0.881600, valid loss: 92.621369
epoch: 4107, train precision: 0.999244, train loss: 9.951145, valid precision: 0.879000, valid loss: 91.205168
epoch: 4108, train precision: 0.998978, train loss: 10.016658, valid precision: 0.881800, valid loss: 94.389051
epoch: 4109, train precision: 0.999022, train loss: 9.989437, valid precision: 0.881400, valid loss: 93.967073
epoch: 4110, train precision: 0.999222, train loss: 9.924110, valid precision: 0.882600, valid loss: 92.493857
epoch: 4111, train precision: 0.999289, train loss: 9.931256, valid precision: 0.876800, valid loss: 94.108222
epoch: 4112, train precision: 0.999022, train loss: 9.986084, valid precision: 0.875400, valid loss: 92.008967
epoch: 4113, train precision: 0.999422, train loss: 9.944861, valid precision: 0.880400, valid loss: 91.635000
epoch: 4114, train precision: 0.999044, train loss: 10.011401, valid precision: 0.878800, valid loss: 93.350136
epoch: 4115, train precision: 0.999222, train loss: 9.947476, valid precision: 0.882000, valid loss: 92.278500
epoch: 4116, train precision: 0.999333, train loss: 9.936228, valid precision: 0.876600, valid loss: 93.763416
epoch: 4117, train precision: 0.999200, train loss: 9.951816, valid precision: 0.876800, valid loss: 93.099307
epoch: 4118, train precision: 0.999333, train loss: 9.914847, valid precision: 0.884000, valid loss: 92.594255
epoch: 4119, train precision: 0.999333, train loss: 9.925112, valid precision: 0.880800, valid loss: 94.507077
epoch: 4120, train precision: 0.999089, train loss: 9.987874, valid precision: 0.876600, valid loss: 95.557977
epoch: 4121, train precision: 0.999111, train loss: 10.001279, valid precision: 0.882000, valid loss: 91.993625
epoch: 4122, train precision: 0.999133, train loss: 9.978443, valid precision: 0.879600, valid loss: 93.429720
epoch: 4123, train precision: 0.998667, train loss: 10.075364, valid precision: 0.880000, valid loss: 92.975726
epoch: 4124, train precision: 0.998889, train loss: 9.999430, valid precision: 0.879400, valid loss: 91.608083
epoch: 4125, train precision: 0.998933, train loss: 10.048128, valid precision: 0.875000, valid loss: 92.430555
epoch: 4126, train precision: 0.999200, train loss: 9.934030, valid precision: 0.875400, valid loss: 92.062358
epoch: 4127, train precision: 0.998800, train loss: 10.064079, valid precision: 0.876200, valid loss: 93.803352
epoch: 4128, train precision: 0.999422, train loss: 9.918145, valid precision: 0.876000, valid loss: 92.592932
epoch: 4129, train precision: 0.999244, train loss: 9.912555, valid precision: 0.877000, valid loss: 94.468093
epoch: 4130, train precision: 0.999000, train loss: 10.030420, valid precision: 0.875800, valid loss: 94.267754
epoch: 4131, train precision: 0.999111, train loss: 9.990833, valid precision: 0.877200, valid loss: 92.158449
epoch: 4132, train precision: 0.999356, train loss: 9.969143, valid precision: 0.877200, valid loss: 94.278165
epoch: 4133, train precision: 0.999022, train loss: 10.006900, valid precision: 0.878000, valid loss: 89.061753
epoch: 4134, train precision: 0.999067, train loss: 10.066252, valid precision: 0.880200, valid loss: 89.786933
epoch: 4135, train precision: 0.999067, train loss: 10.019821, valid precision: 0.880800, valid loss: 89.083334
epoch: 4136, train precision: 0.998889, train loss: 10.062818, valid precision: 0.880400, valid loss: 91.708829
epoch: 4137, train precision: 0.999044, train loss: 10.021389, valid precision: 0.882200, valid loss: 92.034596
epoch: 4138, train precision: 0.998867, train loss: 10.025124, valid precision: 0.881200, valid loss: 92.867718
epoch: 4139, train precision: 0.999244, train loss: 9.987068, valid precision: 0.883400, valid loss: 91.965811
epoch: 4140, train precision: 0.999267, train loss: 9.982489, valid precision: 0.880800, valid loss: 92.581471
epoch: 4141, train precision: 0.999378, train loss: 9.876305, valid precision: 0.879400, valid loss: 93.887034
epoch: 4142, train precision: 0.998778, train loss: 10.112645, valid precision: 0.877000, valid loss: 91.843327
epoch: 4143, train precision: 0.999200, train loss: 9.971332, valid precision: 0.878200, valid loss: 92.111440
epoch: 4144, train precision: 0.999000, train loss: 9.999318, valid precision: 0.880000, valid loss: 94.655497
epoch: 4145, train precision: 0.999467, train loss: 9.875892, valid precision: 0.876200, valid loss: 94.320926
epoch: 4146, train precision: 0.999267, train loss: 9.937139, valid precision: 0.884800, valid loss: 92.752690
epoch: 4147, train precision: 0.998711, train loss: 10.003992, valid precision: 0.879000, valid loss: 94.960241
epoch: 4148, train precision: 0.999089, train loss: 9.989877, valid precision: 0.879400, valid loss: 91.953629
epoch: 4149, train precision: 0.999111, train loss: 9.910398, valid precision: 0.881800, valid loss: 96.078759
epoch: 4150, train precision: 0.999022, train loss: 10.020682, valid precision: 0.882200, valid loss: 92.752423
epoch: 4151, train precision: 0.998556, train loss: 10.114000, valid precision: 0.877800, valid loss: 92.225585
epoch: 4152, train precision: 0.999133, train loss: 9.931829, valid precision: 0.881800, valid loss: 92.074885
epoch: 4153, train precision: 0.999044, train loss: 10.025451, valid precision: 0.879200, valid loss: 93.254917
epoch: 4154, train precision: 0.999133, train loss: 10.043790, valid precision: 0.880600, valid loss: 90.791899
epoch: 4155, train precision: 0.999378, train loss: 9.916064, valid precision: 0.880800, valid loss: 91.817407
epoch: 4156, train precision: 0.999089, train loss: 9.994449, valid precision: 0.881200, valid loss: 90.417516
epoch: 4157, train precision: 0.999044, train loss: 9.969725, valid precision: 0.878000, valid loss: 91.542653
epoch: 4158, train precision: 0.999356, train loss: 9.893290, valid precision: 0.877600, valid loss: 93.949128
epoch: 4159, train precision: 0.998867, train loss: 10.021794, valid precision: 0.876200, valid loss: 95.220183
epoch: 4160, train precision: 0.999156, train loss: 10.004932, valid precision: 0.875200, valid loss: 93.405880
epoch: 4161, train precision: 0.999000, train loss: 10.036461, valid precision: 0.877000, valid loss: 90.769457
epoch: 4162, train precision: 0.998978, train loss: 10.003254, valid precision: 0.883600, valid loss: 91.880131
epoch: 4163, train precision: 0.999222, train loss: 9.923291, valid precision: 0.880600, valid loss: 93.521661
epoch: 4164, train precision: 0.998644, train loss: 10.085737, valid precision: 0.877400, valid loss: 93.547918
epoch: 4165, train precision: 0.999022, train loss: 9.973961, valid precision: 0.880800, valid loss: 92.201207
epoch: 4166, train precision: 0.999378, train loss: 9.922357, valid precision: 0.880600, valid loss: 90.450530
epoch: 4167, train precision: 0.999022, train loss: 9.942309, valid precision: 0.879600, valid loss: 91.566936
epoch: 4168, train precision: 0.999200, train loss: 9.952051, valid precision: 0.882200, valid loss: 91.639517
epoch: 4169, train precision: 0.998933, train loss: 10.043728, valid precision: 0.883600, valid loss: 90.625938
epoch: 4170, train precision: 0.999200, train loss: 9.953318, valid precision: 0.882400, valid loss: 89.153850
epoch: 4171, train precision: 0.999422, train loss: 9.867669, valid precision: 0.881600, valid loss: 88.663346
epoch: 4172, train precision: 0.998911, train loss: 10.056963, valid precision: 0.880200, valid loss: 90.798973
epoch: 4173, train precision: 0.998978, train loss: 10.055978, valid precision: 0.881200, valid loss: 89.534262
epoch: 4174, train precision: 0.998956, train loss: 9.971209, valid precision: 0.881400, valid loss: 88.359030
epoch: 4175, train precision: 0.999244, train loss: 9.945110, valid precision: 0.880200, valid loss: 92.450069
epoch: 4176, train precision: 0.999111, train loss: 9.952609, valid precision: 0.881200, valid loss: 89.379517
epoch: 4177, train precision: 0.999178, train loss: 9.934731, valid precision: 0.872200, valid loss: 92.649793
epoch: 4178, train precision: 0.999111, train loss: 10.018045, valid precision: 0.875200, valid loss: 92.529742
epoch: 4179, train precision: 0.999133, train loss: 9.962638, valid precision: 0.880000, valid loss: 90.582527
epoch: 4180, train precision: 0.999156, train loss: 9.973687, valid precision: 0.876200, valid loss: 91.148887
epoch: 4181, train precision: 0.999400, train loss: 9.933428, valid precision: 0.876800, valid loss: 90.688681
epoch: 4182, train precision: 0.999378, train loss: 9.902633, valid precision: 0.883000, valid loss: 90.076391
epoch: 4183, train precision: 0.999067, train loss: 10.061941, valid precision: 0.879400, valid loss: 91.013896
epoch: 4184, train precision: 0.999422, train loss: 9.874851, valid precision: 0.884400, valid loss: 90.093924
epoch: 4185, train precision: 0.999000, train loss: 9.998723, valid precision: 0.883400, valid loss: 90.854878
epoch: 4186, train precision: 0.999267, train loss: 9.955344, valid precision: 0.881200, valid loss: 92.497503
epoch: 4187, train precision: 0.999467, train loss: 9.887562, valid precision: 0.882000, valid loss: 89.534437
epoch: 4188, train precision: 0.998644, train loss: 10.126179, valid precision: 0.878400, valid loss: 90.614709
epoch: 4189, train precision: 0.999356, train loss: 9.890097, valid precision: 0.881600, valid loss: 90.486298
epoch: 4190, train precision: 0.999244, train loss: 9.955363, valid precision: 0.878800, valid loss: 91.283060
epoch: 4191, train precision: 0.998844, train loss: 9.981809, valid precision: 0.878800, valid loss: 94.091296
epoch: 4192, train precision: 0.999044, train loss: 10.007316, valid precision: 0.879600, valid loss: 89.441846
epoch: 4193, train precision: 0.999000, train loss: 10.002572, valid precision: 0.882200, valid loss: 89.950479
epoch: 4194, train precision: 0.999533, train loss: 9.857419, valid precision: 0.880800, valid loss: 91.201907
epoch: 4195, train precision: 0.998911, train loss: 10.037876, valid precision: 0.880200, valid loss: 89.970642
epoch: 4196, train precision: 0.998822, train loss: 10.016692, valid precision: 0.876600, valid loss: 94.206122
epoch: 4197, train precision: 0.998644, train loss: 10.193389, valid precision: 0.881600, valid loss: 91.669165
epoch: 4198, train precision: 0.998711, train loss: 10.127924, valid precision: 0.880800, valid loss: 92.872316
epoch: 4199, train precision: 0.999111, train loss: 9.951736, valid precision: 0.876800, valid loss: 91.833833
epoch: 4200, train precision: 0.998889, train loss: 9.951326, valid precision: 0.883000, valid loss: 91.248157
epoch: 4201, train precision: 0.999511, train loss: 9.862917, valid precision: 0.876800, valid loss: 93.854666
epoch: 4202, train precision: 0.998978, train loss: 9.975390, valid precision: 0.879600, valid loss: 92.572540
epoch: 4203, train precision: 0.999533, train loss: 9.851658, valid precision: 0.881600, valid loss: 93.930613
epoch: 4204, train precision: 0.998689, train loss: 10.116830, valid precision: 0.873200, valid loss: 96.488031
epoch: 4205, train precision: 0.998600, train loss: 10.098550, valid precision: 0.879200, valid loss: 93.505705
epoch: 4206, train precision: 0.999244, train loss: 9.878335, valid precision: 0.879400, valid loss: 92.247815
epoch: 4207, train precision: 0.999067, train loss: 10.039615, valid precision: 0.882000, valid loss: 90.857959
epoch: 4208, train precision: 0.999178, train loss: 9.934100, valid precision: 0.879600, valid loss: 93.487898
epoch: 4209, train precision: 0.999022, train loss: 9.997175, valid precision: 0.881800, valid loss: 93.581048
epoch: 4210, train precision: 0.999267, train loss: 9.958904, valid precision: 0.881200, valid loss: 91.818740
epoch: 4211, train precision: 0.998956, train loss: 10.053213, valid precision: 0.883800, valid loss: 90.636983
epoch: 4212, train precision: 0.999022, train loss: 9.959080, valid precision: 0.882000, valid loss: 89.546704
epoch: 4213, train precision: 0.998889, train loss: 9.976629, valid precision: 0.879200, valid loss: 92.870471
epoch: 4214, train precision: 0.999111, train loss: 9.990889, valid precision: 0.876600, valid loss: 93.578638
epoch: 4215, train precision: 0.999222, train loss: 9.974610, valid precision: 0.878000, valid loss: 92.014375
epoch: 4216, train precision: 0.999111, train loss: 10.004941, valid precision: 0.876800, valid loss: 93.724917
epoch: 4217, train precision: 0.999022, train loss: 9.935803, valid precision: 0.872400, valid loss: 96.977853
epoch: 4218, train precision: 0.999178, train loss: 9.943657, valid precision: 0.880000, valid loss: 93.398438
epoch: 4219, train precision: 0.999156, train loss: 9.946032, valid precision: 0.877800, valid loss: 93.344642
epoch: 4220, train precision: 0.999178, train loss: 9.961405, valid precision: 0.876800, valid loss: 94.770962
epoch: 4221, train precision: 0.999133, train loss: 9.908473, valid precision: 0.877200, valid loss: 97.802160
epoch: 4222, train precision: 0.998956, train loss: 9.973221, valid precision: 0.873200, valid loss: 97.515129
epoch: 4223, train precision: 0.999378, train loss: 9.898394, valid precision: 0.877800, valid loss: 96.524054
epoch: 4224, train precision: 0.999067, train loss: 10.008136, valid precision: 0.873600, valid loss: 96.865485
epoch: 4225, train precision: 0.999311, train loss: 9.927832, valid precision: 0.880200, valid loss: 92.981782
epoch: 4226, train precision: 0.999111, train loss: 9.932673, valid precision: 0.878000, valid loss: 93.525922
epoch: 4227, train precision: 0.998978, train loss: 9.984490, valid precision: 0.879000, valid loss: 93.573470
epoch: 4228, train precision: 0.999089, train loss: 9.980345, valid precision: 0.883400, valid loss: 92.187231
epoch: 4229, train precision: 0.999067, train loss: 9.957991, valid precision: 0.880000, valid loss: 94.495201
epoch: 4230, train precision: 0.998889, train loss: 10.024556, valid precision: 0.879000, valid loss: 93.339808
epoch: 4231, train precision: 0.998889, train loss: 9.976943, valid precision: 0.878800, valid loss: 91.959892
epoch: 4232, train precision: 0.999000, train loss: 10.034125, valid precision: 0.879600, valid loss: 95.315337
epoch: 4233, train precision: 0.999489, train loss: 9.855501, valid precision: 0.875200, valid loss: 93.905107
epoch: 4234, train precision: 0.999044, train loss: 10.053590, valid precision: 0.881000, valid loss: 92.902234
epoch: 4235, train precision: 0.998889, train loss: 9.988542, valid precision: 0.880600, valid loss: 95.252738
epoch: 4236, train precision: 0.999222, train loss: 9.900073, valid precision: 0.881200, valid loss: 95.107876
epoch: 4237, train precision: 0.998867, train loss: 10.021446, valid precision: 0.877200, valid loss: 94.659509
epoch: 4238, train precision: 0.998933, train loss: 9.981918, valid precision: 0.879800, valid loss: 95.929381
epoch: 4239, train precision: 0.999111, train loss: 9.949100, valid precision: 0.879200, valid loss: 96.145668
epoch: 4240, train precision: 0.999111, train loss: 9.935677, valid precision: 0.877800, valid loss: 94.484693
epoch: 4241, train precision: 0.999244, train loss: 9.914300, valid precision: 0.878000, valid loss: 96.841076
epoch: 4242, train precision: 0.998933, train loss: 9.984414, valid precision: 0.881600, valid loss: 90.639208
epoch: 4243, train precision: 0.999400, train loss: 9.918285, valid precision: 0.878200, valid loss: 94.915498
epoch: 4244, train precision: 0.999111, train loss: 9.941557, valid precision: 0.876600, valid loss: 93.418079
epoch: 4245, train precision: 0.999267, train loss: 9.917762, valid precision: 0.873800, valid loss: 92.983582
epoch: 4246, train precision: 0.998733, train loss: 10.005710, valid precision: 0.875800, valid loss: 94.939261
epoch: 4247, train precision: 0.999111, train loss: 9.974594, valid precision: 0.876400, valid loss: 95.303256
epoch: 4248, train precision: 0.999356, train loss: 9.891714, valid precision: 0.873600, valid loss: 96.172024
epoch: 4249, train precision: 0.998933, train loss: 9.956103, valid precision: 0.873000, valid loss: 96.298136
epoch: 4250, train precision: 0.999067, train loss: 9.957791, valid precision: 0.875000, valid loss: 98.421285
epoch: 4251, train precision: 0.999289, train loss: 9.895516, valid precision: 0.878200, valid loss: 95.223721
epoch: 4252, train precision: 0.998689, train loss: 10.111737, valid precision: 0.874200, valid loss: 96.627702
epoch: 4253, train precision: 0.999289, train loss: 9.955475, valid precision: 0.873200, valid loss: 97.113629
epoch: 4254, train precision: 0.998978, train loss: 10.040037, valid precision: 0.869600, valid loss: 98.496503
epoch: 4255, train precision: 0.999111, train loss: 9.968755, valid precision: 0.875000, valid loss: 95.685091
epoch: 4256, train precision: 0.999333, train loss: 9.879249, valid precision: 0.874400, valid loss: 95.543407
epoch: 4257, train precision: 0.999333, train loss: 9.898878, valid precision: 0.880200, valid loss: 94.353467
epoch: 4258, train precision: 0.998756, train loss: 10.021071, valid precision: 0.874600, valid loss: 94.534352
epoch: 4259, train precision: 0.999356, train loss: 9.976272, valid precision: 0.876000, valid loss: 90.194538
epoch: 4260, train precision: 0.999222, train loss: 9.913917, valid precision: 0.879600, valid loss: 91.774999
epoch: 4261, train precision: 0.998956, train loss: 9.973607, valid precision: 0.878000, valid loss: 93.077819
epoch: 4262, train precision: 0.999222, train loss: 9.937747, valid precision: 0.879400, valid loss: 95.049717
epoch: 4263, train precision: 0.999178, train loss: 9.943832, valid precision: 0.878200, valid loss: 92.344298
epoch: 4264, train precision: 0.998933, train loss: 9.938670, valid precision: 0.880400, valid loss: 92.721367
epoch: 4265, train precision: 0.999000, train loss: 10.031583, valid precision: 0.880800, valid loss: 92.990160
epoch: 4266, train precision: 0.998667, train loss: 10.076385, valid precision: 0.880200, valid loss: 93.575768
epoch: 4267, train precision: 0.999178, train loss: 10.001584, valid precision: 0.879200, valid loss: 91.066358
epoch: 4268, train precision: 0.999422, train loss: 9.831300, valid precision: 0.878400, valid loss: 94.043625
epoch: 4269, train precision: 0.998822, train loss: 9.970293, valid precision: 0.879800, valid loss: 94.043796
epoch: 4270, train precision: 0.999022, train loss: 9.991928, valid precision: 0.880600, valid loss: 91.009336
epoch: 4271, train precision: 0.999044, train loss: 10.000805, valid precision: 0.876800, valid loss: 93.761572
epoch: 4272, train precision: 0.999289, train loss: 9.882604, valid precision: 0.882200, valid loss: 92.451697
epoch: 4273, train precision: 0.998956, train loss: 9.981730, valid precision: 0.878200, valid loss: 93.691130
epoch: 4274, train precision: 0.999067, train loss: 9.896810, valid precision: 0.881000, valid loss: 93.717951
epoch: 4275, train precision: 0.999200, train loss: 9.964396, valid precision: 0.879200, valid loss: 93.187368
epoch: 4276, train precision: 0.999022, train loss: 10.049349, valid precision: 0.879000, valid loss: 93.092766
epoch: 4277, train precision: 0.999044, train loss: 9.956022, valid precision: 0.877800, valid loss: 93.052461
epoch: 4278, train precision: 0.999156, train loss: 9.914855, valid precision: 0.878400, valid loss: 91.902357
epoch: 4279, train precision: 0.998800, train loss: 10.045932, valid precision: 0.878800, valid loss: 92.639664
epoch: 4280, train precision: 0.998911, train loss: 10.018518, valid precision: 0.877400, valid loss: 92.617786
epoch: 4281, train precision: 0.999156, train loss: 9.929992, valid precision: 0.880200, valid loss: 93.085310
epoch: 4282, train precision: 0.999111, train loss: 9.964437, valid precision: 0.875200, valid loss: 94.922057
epoch: 4283, train precision: 0.999200, train loss: 9.937551, valid precision: 0.877400, valid loss: 95.168176
epoch: 4284, train precision: 0.999133, train loss: 10.005927, valid precision: 0.877600, valid loss: 94.191853
epoch: 4285, train precision: 0.998778, train loss: 10.006841, valid precision: 0.878600, valid loss: 93.444739
epoch: 4286, train precision: 0.999178, train loss: 9.954575, valid precision: 0.878200, valid loss: 93.514019
epoch: 4287, train precision: 0.999244, train loss: 9.926838, valid precision: 0.878000, valid loss: 93.666205
epoch: 4288, train precision: 0.999044, train loss: 9.930287, valid precision: 0.877800, valid loss: 95.322016
epoch: 4289, train precision: 0.999044, train loss: 10.038770, valid precision: 0.878000, valid loss: 93.176325
epoch: 4290, train precision: 0.998978, train loss: 9.975817, valid precision: 0.874200, valid loss: 93.385715
epoch: 4291, train precision: 0.999333, train loss: 9.924308, valid precision: 0.880600, valid loss: 94.439601
epoch: 4292, train precision: 0.999022, train loss: 10.008472, valid precision: 0.878200, valid loss: 94.723077
epoch: 4293, train precision: 0.998933, train loss: 10.000821, valid precision: 0.876800, valid loss: 95.181013
epoch: 4294, train precision: 0.999022, train loss: 9.947040, valid precision: 0.874200, valid loss: 95.486046
epoch: 4295, train precision: 0.999311, train loss: 9.918296, valid precision: 0.880800, valid loss: 95.990857
epoch: 4296, train precision: 0.999133, train loss: 9.979208, valid precision: 0.876400, valid loss: 93.702071
epoch: 4297, train precision: 0.999044, train loss: 10.001490, valid precision: 0.878800, valid loss: 95.811318
epoch: 4298, train precision: 0.999244, train loss: 9.908057, valid precision: 0.884000, valid loss: 93.868341
epoch: 4299, train precision: 0.999311, train loss: 9.912803, valid precision: 0.879200, valid loss: 92.052113
epoch: 4300, train precision: 0.999156, train loss: 9.960561, valid precision: 0.878600, valid loss: 92.203318
epoch: 4301, train precision: 0.999422, train loss: 9.873768, valid precision: 0.880400, valid loss: 92.487369
epoch: 4302, train precision: 0.998978, train loss: 10.041444, valid precision: 0.878200, valid loss: 92.774128
epoch: 4303, train precision: 0.999244, train loss: 9.877617, valid precision: 0.879200, valid loss: 94.955851
epoch: 4304, train precision: 0.999378, train loss: 9.860358, valid precision: 0.877600, valid loss: 92.541500
epoch: 4305, train precision: 0.999000, train loss: 9.992612, valid precision: 0.879200, valid loss: 93.290433
epoch: 4306, train precision: 0.998956, train loss: 9.977401, valid precision: 0.876600, valid loss: 96.342118
epoch: 4307, train precision: 0.999044, train loss: 10.007637, valid precision: 0.876200, valid loss: 97.266850
epoch: 4308, train precision: 0.998911, train loss: 9.997280, valid precision: 0.876200, valid loss: 95.384786
epoch: 4309, train precision: 0.999133, train loss: 9.907445, valid precision: 0.877600, valid loss: 94.075100
epoch: 4310, train precision: 0.999089, train loss: 9.967569, valid precision: 0.882600, valid loss: 91.373156
epoch: 4311, train precision: 0.999244, train loss: 9.897736, valid precision: 0.879400, valid loss: 92.909281
epoch: 4312, train precision: 0.999356, train loss: 9.906061, valid precision: 0.879400, valid loss: 91.029748
epoch: 4313, train precision: 0.999111, train loss: 9.969161, valid precision: 0.875800, valid loss: 95.209947
epoch: 4314, train precision: 0.999289, train loss: 9.886400, valid precision: 0.873400, valid loss: 96.757910
epoch: 4315, train precision: 0.998978, train loss: 9.981153, valid precision: 0.875600, valid loss: 96.419375
epoch: 4316, train precision: 0.999022, train loss: 9.968764, valid precision: 0.875800, valid loss: 95.368731
epoch: 4317, train precision: 0.999156, train loss: 9.929504, valid precision: 0.875600, valid loss: 94.321099
epoch: 4318, train precision: 0.999111, train loss: 9.939318, valid precision: 0.873600, valid loss: 97.674666
epoch: 4319, train precision: 0.999178, train loss: 9.872502, valid precision: 0.875000, valid loss: 96.665740
epoch: 4320, train precision: 0.998622, train loss: 10.168515, valid precision: 0.875400, valid loss: 94.487291
epoch: 4321, train precision: 0.999156, train loss: 9.935301, valid precision: 0.875600, valid loss: 94.226227
epoch: 4322, train precision: 0.998978, train loss: 9.989584, valid precision: 0.871800, valid loss: 95.032701
epoch: 4323, train precision: 0.999244, train loss: 9.912064, valid precision: 0.876400, valid loss: 95.850779
epoch: 4324, train precision: 0.998844, train loss: 10.038404, valid precision: 0.875200, valid loss: 94.066387
epoch: 4325, train precision: 0.999178, train loss: 9.945732, valid precision: 0.875800, valid loss: 93.013642
epoch: 4326, train precision: 0.999156, train loss: 9.904438, valid precision: 0.876400, valid loss: 94.237952
epoch: 4327, train precision: 0.999178, train loss: 9.970215, valid precision: 0.873000, valid loss: 96.450018
epoch: 4328, train precision: 0.999067, train loss: 9.952840, valid precision: 0.873600, valid loss: 98.181203
epoch: 4329, train precision: 0.999467, train loss: 9.835683, valid precision: 0.873400, valid loss: 94.047061
epoch: 4330, train precision: 0.999244, train loss: 9.923839, valid precision: 0.878000, valid loss: 95.553554
epoch: 4331, train precision: 0.999244, train loss: 9.914662, valid precision: 0.879200, valid loss: 94.792676
epoch: 4332, train precision: 0.999356, train loss: 9.867754, valid precision: 0.878600, valid loss: 94.727150
epoch: 4333, train precision: 0.999067, train loss: 10.040150, valid precision: 0.875000, valid loss: 97.670775
epoch: 4334, train precision: 0.999111, train loss: 9.949986, valid precision: 0.875400, valid loss: 95.395385
epoch: 4335, train precision: 0.999200, train loss: 9.909630, valid precision: 0.876800, valid loss: 93.188514
epoch: 4336, train precision: 0.999333, train loss: 9.863363, valid precision: 0.877000, valid loss: 94.879364
epoch: 4337, train precision: 0.999533, train loss: 9.879435, valid precision: 0.872000, valid loss: 94.227358
epoch: 4338, train precision: 0.999067, train loss: 9.957250, valid precision: 0.874600, valid loss: 94.468188
epoch: 4339, train precision: 0.999378, train loss: 9.853332, valid precision: 0.877400, valid loss: 93.657751
epoch: 4340, train precision: 0.998711, train loss: 10.029439, valid precision: 0.876600, valid loss: 96.980346
epoch: 4341, train precision: 0.999178, train loss: 9.929929, valid precision: 0.877400, valid loss: 94.793336
epoch: 4342, train precision: 0.998844, train loss: 10.071025, valid precision: 0.874400, valid loss: 94.594815
epoch: 4343, train precision: 0.999067, train loss: 10.002200, valid precision: 0.878200, valid loss: 93.813818
epoch: 4344, train precision: 0.999267, train loss: 9.888903, valid precision: 0.876400, valid loss: 93.850089
epoch: 4345, train precision: 0.999111, train loss: 9.924467, valid precision: 0.879200, valid loss: 94.319639
epoch: 4346, train precision: 0.999333, train loss: 9.869801, valid precision: 0.877800, valid loss: 93.885215
epoch: 4347, train precision: 0.998978, train loss: 9.991563, valid precision: 0.874600, valid loss: 96.003132
epoch: 4348, train precision: 0.999200, train loss: 9.911520, valid precision: 0.875800, valid loss: 94.544364
epoch: 4349, train precision: 0.999467, train loss: 9.874540, valid precision: 0.879000, valid loss: 94.201496
epoch: 4350, train precision: 0.999156, train loss: 10.009524, valid precision: 0.874600, valid loss: 94.214133
epoch: 4351, train precision: 0.999289, train loss: 9.849567, valid precision: 0.875200, valid loss: 98.371258
epoch: 4352, train precision: 0.999356, train loss: 9.870830, valid precision: 0.876400, valid loss: 95.559322
epoch: 4353, train precision: 0.999556, train loss: 9.831397, valid precision: 0.878000, valid loss: 94.181404
epoch: 4354, train precision: 0.999222, train loss: 9.922886, valid precision: 0.878800, valid loss: 95.310794
epoch: 4355, train precision: 0.999244, train loss: 9.945450, valid precision: 0.875000, valid loss: 95.537852
epoch: 4356, train precision: 0.999000, train loss: 9.943311, valid precision: 0.877000, valid loss: 98.642486
epoch: 4357, train precision: 0.998978, train loss: 9.947659, valid precision: 0.878000, valid loss: 96.237985
epoch: 4358, train precision: 0.998711, train loss: 10.057511, valid precision: 0.875800, valid loss: 94.835630
epoch: 4359, train precision: 0.999289, train loss: 9.956051, valid precision: 0.877200, valid loss: 96.348615
epoch: 4360, train precision: 0.999067, train loss: 9.950479, valid precision: 0.876000, valid loss: 97.691253
epoch: 4361, train precision: 0.999111, train loss: 9.924225, valid precision: 0.876200, valid loss: 94.545658
epoch: 4362, train precision: 0.998956, train loss: 9.963801, valid precision: 0.880400, valid loss: 93.031300
epoch: 4363, train precision: 0.998867, train loss: 9.979368, valid precision: 0.880600, valid loss: 94.219480
epoch: 4364, train precision: 0.998733, train loss: 10.009140, valid precision: 0.878000, valid loss: 93.396340
epoch: 4365, train precision: 0.998933, train loss: 9.948595, valid precision: 0.875400, valid loss: 93.661972
epoch: 4366, train precision: 0.999289, train loss: 9.963865, valid precision: 0.875200, valid loss: 92.912736
epoch: 4367, train precision: 0.999022, train loss: 9.956993, valid precision: 0.874400, valid loss: 92.223795
epoch: 4368, train precision: 0.999556, train loss: 9.850228, valid precision: 0.882400, valid loss: 89.374381
epoch: 4369, train precision: 0.999267, train loss: 9.922681, valid precision: 0.878600, valid loss: 93.154050
epoch: 4370, train precision: 0.999089, train loss: 9.983680, valid precision: 0.877800, valid loss: 93.547682
epoch: 4371, train precision: 0.999067, train loss: 9.889680, valid precision: 0.878400, valid loss: 92.270555
epoch: 4372, train precision: 0.999044, train loss: 9.986545, valid precision: 0.875400, valid loss: 94.086192
epoch: 4373, train precision: 0.999156, train loss: 9.993678, valid precision: 0.878400, valid loss: 91.592413
epoch: 4374, train precision: 0.999356, train loss: 9.859435, valid precision: 0.878200, valid loss: 91.817029
epoch: 4375, train precision: 0.998889, train loss: 9.998434, valid precision: 0.879800, valid loss: 92.435096
epoch: 4376, train precision: 0.999333, train loss: 9.897032, valid precision: 0.879800, valid loss: 90.788652
epoch: 4377, train precision: 0.999267, train loss: 9.889506, valid precision: 0.877400, valid loss: 89.465055
epoch: 4378, train precision: 0.999267, train loss: 9.867257, valid precision: 0.878400, valid loss: 93.089718
epoch: 4379, train precision: 0.999000, train loss: 9.951453, valid precision: 0.877800, valid loss: 92.378548
epoch: 4380, train precision: 0.998889, train loss: 9.987410, valid precision: 0.879800, valid loss: 93.411748
epoch: 4381, train precision: 0.998978, train loss: 10.029131, valid precision: 0.877200, valid loss: 89.781437
epoch: 4382, train precision: 0.998844, train loss: 10.020812, valid precision: 0.880800, valid loss: 93.162411
epoch: 4383, train precision: 0.999267, train loss: 9.885184, valid precision: 0.878400, valid loss: 91.096101
epoch: 4384, train precision: 0.999267, train loss: 9.927588, valid precision: 0.878200, valid loss: 90.231009
epoch: 4385, train precision: 0.999178, train loss: 9.999765, valid precision: 0.877200, valid loss: 91.267077
epoch: 4386, train precision: 0.999156, train loss: 9.939530, valid precision: 0.878000, valid loss: 90.058763
epoch: 4387, train precision: 0.999222, train loss: 9.907787, valid precision: 0.878400, valid loss: 92.036247
epoch: 4388, train precision: 0.999022, train loss: 9.978825, valid precision: 0.878000, valid loss: 92.643277
epoch: 4389, train precision: 0.999156, train loss: 9.951167, valid precision: 0.876800, valid loss: 91.370800
epoch: 4390, train precision: 0.999289, train loss: 9.877403, valid precision: 0.879600, valid loss: 91.157890
epoch: 4391, train precision: 0.999311, train loss: 9.908885, valid precision: 0.879200, valid loss: 91.192473
epoch: 4392, train precision: 0.999022, train loss: 9.938311, valid precision: 0.881800, valid loss: 91.294940
epoch: 4393, train precision: 0.999178, train loss: 9.872034, valid precision: 0.883800, valid loss: 91.577351
epoch: 4394, train precision: 0.999089, train loss: 9.949382, valid precision: 0.878600, valid loss: 92.158750
epoch: 4395, train precision: 0.998689, train loss: 10.015213, valid precision: 0.875200, valid loss: 93.230348
epoch: 4396, train precision: 0.999356, train loss: 9.828226, valid precision: 0.878000, valid loss: 92.605073
epoch: 4397, train precision: 0.999178, train loss: 9.951621, valid precision: 0.874800, valid loss: 92.780979
epoch: 4398, train precision: 0.998578, train loss: 10.102693, valid precision: 0.880200, valid loss: 92.525822
epoch: 4399, train precision: 0.999178, train loss: 9.930935, valid precision: 0.879800, valid loss: 90.793865
epoch: 4400, train precision: 0.999311, train loss: 9.891337, valid precision: 0.876600, valid loss: 91.102664
epoch: 4401, train precision: 0.999111, train loss: 9.923569, valid precision: 0.878600, valid loss: 91.824233
epoch: 4402, train precision: 0.998956, train loss: 10.025038, valid precision: 0.879000, valid loss: 92.601548
epoch: 4403, train precision: 0.999267, train loss: 9.892675, valid precision: 0.878200, valid loss: 90.691993
epoch: 4404, train precision: 0.999289, train loss: 9.861561, valid precision: 0.880400, valid loss: 91.921234
epoch: 4405, train precision: 0.999178, train loss: 9.918986, valid precision: 0.882200, valid loss: 89.251136
epoch: 4406, train precision: 0.999511, train loss: 9.817634, valid precision: 0.880000, valid loss: 90.230095
epoch: 4407, train precision: 0.999333, train loss: 9.896291, valid precision: 0.881000, valid loss: 89.632824
epoch: 4408, train precision: 0.999089, train loss: 9.963531, valid precision: 0.881200, valid loss: 91.679049
epoch: 4409, train precision: 0.999289, train loss: 9.812289, valid precision: 0.880600, valid loss: 91.534393
epoch: 4410, train precision: 0.999467, train loss: 9.803451, valid precision: 0.881600, valid loss: 92.128780
epoch: 4411, train precision: 0.999422, train loss: 9.793067, valid precision: 0.884400, valid loss: 89.466053
epoch: 4412, train precision: 0.999244, train loss: 9.855518, valid precision: 0.881200, valid loss: 93.215487
epoch: 4413, train precision: 0.998733, train loss: 10.016759, valid precision: 0.874600, valid loss: 94.271582
epoch: 4414, train precision: 0.999289, train loss: 9.909920, valid precision: 0.878400, valid loss: 91.794853
epoch: 4415, train precision: 0.999022, train loss: 9.933050, valid precision: 0.879000, valid loss: 91.629801
epoch: 4416, train precision: 0.999289, train loss: 9.893793, valid precision: 0.882000, valid loss: 92.675487
epoch: 4417, train precision: 0.998689, train loss: 10.088251, valid precision: 0.878200, valid loss: 91.280298
epoch: 4418, train precision: 0.998867, train loss: 10.052715, valid precision: 0.874400, valid loss: 91.468772
epoch: 4419, train precision: 0.999200, train loss: 9.903934, valid precision: 0.876200, valid loss: 90.266992
epoch: 4420, train precision: 0.999333, train loss: 9.891388, valid precision: 0.877200, valid loss: 93.416090
epoch: 4421, train precision: 0.999244, train loss: 9.867437, valid precision: 0.877600, valid loss: 92.069099
epoch: 4422, train precision: 0.999178, train loss: 9.917869, valid precision: 0.878000, valid loss: 92.255008
epoch: 4423, train precision: 0.999444, train loss: 9.825620, valid precision: 0.880400, valid loss: 91.614634
epoch: 4424, train precision: 0.999178, train loss: 9.939989, valid precision: 0.878400, valid loss: 93.750117
epoch: 4425, train precision: 0.999311, train loss: 9.835515, valid precision: 0.882200, valid loss: 91.493223
epoch: 4426, train precision: 0.998933, train loss: 9.931982, valid precision: 0.880800, valid loss: 90.578353
epoch: 4427, train precision: 0.998889, train loss: 10.000737, valid precision: 0.879600, valid loss: 90.201205
epoch: 4428, train precision: 0.999222, train loss: 9.943729, valid precision: 0.880400, valid loss: 89.803603
epoch: 4429, train precision: 0.999044, train loss: 9.917400, valid precision: 0.876600, valid loss: 94.393947
epoch: 4430, train precision: 0.999289, train loss: 9.926015, valid precision: 0.877800, valid loss: 93.225075
epoch: 4431, train precision: 0.999111, train loss: 9.951388, valid precision: 0.878400, valid loss: 96.074731
epoch: 4432, train precision: 0.999222, train loss: 9.886066, valid precision: 0.877200, valid loss: 94.162054
epoch: 4433, train precision: 0.998867, train loss: 9.992707, valid precision: 0.878800, valid loss: 96.159042
epoch: 4434, train precision: 0.998844, train loss: 9.983256, valid precision: 0.878400, valid loss: 91.859341
epoch: 4435, train precision: 0.999378, train loss: 9.886885, valid precision: 0.881200, valid loss: 90.103616
epoch: 4436, train precision: 0.999133, train loss: 9.885019, valid precision: 0.882800, valid loss: 90.941581
epoch: 4437, train precision: 0.999133, train loss: 9.913217, valid precision: 0.878800, valid loss: 91.634025
epoch: 4438, train precision: 0.999022, train loss: 9.927924, valid precision: 0.881600, valid loss: 93.013460
epoch: 4439, train precision: 0.999133, train loss: 10.009255, valid precision: 0.878400, valid loss: 91.161404
epoch: 4440, train precision: 0.999067, train loss: 9.946646, valid precision: 0.879400, valid loss: 90.929628
epoch: 4441, train precision: 0.999178, train loss: 9.932021, valid precision: 0.883000, valid loss: 89.626254
epoch: 4442, train precision: 0.999378, train loss: 9.850287, valid precision: 0.880200, valid loss: 90.573595
epoch: 4443, train precision: 0.999022, train loss: 9.957445, valid precision: 0.880400, valid loss: 91.630801
epoch: 4444, train precision: 0.998844, train loss: 10.011889, valid precision: 0.883400, valid loss: 87.777339
epoch: 4445, train precision: 0.999156, train loss: 9.953065, valid precision: 0.882800, valid loss: 90.935327
epoch: 4446, train precision: 0.999400, train loss: 9.867544, valid precision: 0.880800, valid loss: 90.410287
epoch: 4447, train precision: 0.999200, train loss: 9.915621, valid precision: 0.880800, valid loss: 91.587708
epoch: 4448, train precision: 0.999311, train loss: 9.842095, valid precision: 0.883400, valid loss: 90.186360
epoch: 4449, train precision: 0.998889, train loss: 9.961472, valid precision: 0.880600, valid loss: 91.259285
epoch: 4450, train precision: 0.999267, train loss: 9.835554, valid precision: 0.880600, valid loss: 90.304237
epoch: 4451, train precision: 0.999444, train loss: 9.839724, valid precision: 0.880800, valid loss: 88.522679
epoch: 4452, train precision: 0.999422, train loss: 9.875790, valid precision: 0.877600, valid loss: 88.144309
epoch: 4453, train precision: 0.999244, train loss: 9.933535, valid precision: 0.879400, valid loss: 89.214924
epoch: 4454, train precision: 0.999000, train loss: 9.999853, valid precision: 0.878000, valid loss: 91.285503
epoch: 4455, train precision: 0.999222, train loss: 9.916513, valid precision: 0.873200, valid loss: 92.986454
epoch: 4456, train precision: 0.998889, train loss: 10.000504, valid precision: 0.877200, valid loss: 91.031795
epoch: 4457, train precision: 0.999244, train loss: 9.908236, valid precision: 0.876800, valid loss: 91.840497
epoch: 4458, train precision: 0.999178, train loss: 9.914279, valid precision: 0.879400, valid loss: 91.061839
epoch: 4459, train precision: 0.998933, train loss: 10.032896, valid precision: 0.877400, valid loss: 90.984646
epoch: 4460, train precision: 0.999089, train loss: 9.925552, valid precision: 0.874400, valid loss: 92.999686
epoch: 4461, train precision: 0.999222, train loss: 9.850806, valid precision: 0.876000, valid loss: 95.101944
epoch: 4462, train precision: 0.999244, train loss: 9.874497, valid precision: 0.880000, valid loss: 92.129823
epoch: 4463, train precision: 0.998600, train loss: 10.012090, valid precision: 0.876600, valid loss: 98.705835
epoch: 4464, train precision: 0.999311, train loss: 9.861300, valid precision: 0.880200, valid loss: 91.849084
epoch: 4465, train precision: 0.999178, train loss: 9.907842, valid precision: 0.880400, valid loss: 91.999632
epoch: 4466, train precision: 0.999022, train loss: 9.903977, valid precision: 0.879000, valid loss: 93.175091
epoch: 4467, train precision: 0.999022, train loss: 10.001965, valid precision: 0.877600, valid loss: 92.056523
epoch: 4468, train precision: 0.998933, train loss: 10.056423, valid precision: 0.881000, valid loss: 92.180677
epoch: 4469, train precision: 0.999089, train loss: 9.904566, valid precision: 0.879400, valid loss: 92.679503
epoch: 4470, train precision: 0.999111, train loss: 10.004277, valid precision: 0.878400, valid loss: 93.033947
epoch: 4471, train precision: 0.999133, train loss: 9.946169, valid precision: 0.879600, valid loss: 91.985596
epoch: 4472, train precision: 0.999200, train loss: 9.933462, valid precision: 0.878600, valid loss: 92.137860
epoch: 4473, train precision: 0.999111, train loss: 9.890783, valid precision: 0.877600, valid loss: 92.619723
epoch: 4474, train precision: 0.999178, train loss: 9.882705, valid precision: 0.875800, valid loss: 94.548675
epoch: 4475, train precision: 0.998956, train loss: 9.949617, valid precision: 0.877000, valid loss: 93.542318
epoch: 4476, train precision: 0.999089, train loss: 9.945136, valid precision: 0.880600, valid loss: 92.128811
epoch: 4477, train precision: 0.999022, train loss: 9.923660, valid precision: 0.876200, valid loss: 92.238625
epoch: 4478, train precision: 0.998667, train loss: 10.049935, valid precision: 0.880000, valid loss: 92.481451
epoch: 4479, train precision: 0.998844, train loss: 10.032811, valid precision: 0.881400, valid loss: 92.076241
epoch: 4480, train precision: 0.999067, train loss: 9.926435, valid precision: 0.879800, valid loss: 87.531098
epoch: 4481, train precision: 0.999022, train loss: 9.925009, valid precision: 0.876200, valid loss: 93.131757
epoch: 4482, train precision: 0.999289, train loss: 9.916926, valid precision: 0.877600, valid loss: 95.349159
epoch: 4483, train precision: 0.998911, train loss: 10.058094, valid precision: 0.874600, valid loss: 91.867053
epoch: 4484, train precision: 0.999289, train loss: 9.906209, valid precision: 0.880000, valid loss: 92.810812
epoch: 4485, train precision: 0.999089, train loss: 9.939777, valid precision: 0.877000, valid loss: 95.207453
epoch: 4486, train precision: 0.999133, train loss: 9.899519, valid precision: 0.879800, valid loss: 94.482323
epoch: 4487, train precision: 0.999111, train loss: 9.913459, valid precision: 0.876600, valid loss: 92.631036
epoch: 4488, train precision: 0.998578, train loss: 10.097205, valid precision: 0.877400, valid loss: 96.237079
epoch: 4489, train precision: 0.999289, train loss: 9.955386, valid precision: 0.879600, valid loss: 93.071844
epoch: 4490, train precision: 0.998956, train loss: 9.928262, valid precision: 0.877200, valid loss: 98.362993
epoch: 4491, train precision: 0.999200, train loss: 9.930317, valid precision: 0.874000, valid loss: 95.182551
epoch: 4492, train precision: 0.999178, train loss: 9.952123, valid precision: 0.878800, valid loss: 92.985472
epoch: 4493, train precision: 0.999267, train loss: 9.923016, valid precision: 0.878800, valid loss: 91.317265
epoch: 4494, train precision: 0.999200, train loss: 9.916110, valid precision: 0.881200, valid loss: 92.891348
epoch: 4495, train precision: 0.999244, train loss: 9.887411, valid precision: 0.880600, valid loss: 93.196221
epoch: 4496, train precision: 0.999022, train loss: 9.957829, valid precision: 0.880200, valid loss: 94.685817
epoch: 4497, train precision: 0.999089, train loss: 9.904257, valid precision: 0.879600, valid loss: 96.522056
epoch: 4498, train precision: 0.998978, train loss: 9.970638, valid precision: 0.879000, valid loss: 94.621606
epoch: 4499, train precision: 0.999067, train loss: 9.985472, valid precision: 0.877400, valid loss: 94.159382
epoch: 4500, train precision: 0.999067, train loss: 9.975180, valid precision: 0.881800, valid loss: 96.508212
epoch: 4501, train precision: 0.999356, train loss: 9.882856, valid precision: 0.879600, valid loss: 93.384520
epoch: 4502, train precision: 0.999067, train loss: 9.944019, valid precision: 0.879000, valid loss: 92.530450
epoch: 4503, train precision: 0.999378, train loss: 9.898839, valid precision: 0.878400, valid loss: 93.969245
epoch: 4504, train precision: 0.999222, train loss: 9.889136, valid precision: 0.878800, valid loss: 93.912078
epoch: 4505, train precision: 0.999089, train loss: 9.961512, valid precision: 0.882800, valid loss: 90.877226
epoch: 4506, train precision: 0.999244, train loss: 9.931524, valid precision: 0.882800, valid loss: 91.501581
epoch: 4507, train precision: 0.999200, train loss: 9.946682, valid precision: 0.879400, valid loss: 90.566550
epoch: 4508, train precision: 0.999044, train loss: 9.923646, valid precision: 0.877200, valid loss: 92.568783
epoch: 4509, train precision: 0.998911, train loss: 10.012517, valid precision: 0.877400, valid loss: 91.625648
epoch: 4510, train precision: 0.998889, train loss: 9.996567, valid precision: 0.882200, valid loss: 89.425553
epoch: 4511, train precision: 0.999200, train loss: 9.896195, valid precision: 0.882200, valid loss: 92.190079
epoch: 4512, train precision: 0.999222, train loss: 9.863232, valid precision: 0.881200, valid loss: 91.126712
epoch: 4513, train precision: 0.998978, train loss: 9.953712, valid precision: 0.877800, valid loss: 90.404472
epoch: 4514, train precision: 0.998844, train loss: 9.992875, valid precision: 0.876600, valid loss: 93.181110
epoch: 4515, train precision: 0.998978, train loss: 10.010482, valid precision: 0.877800, valid loss: 92.297621
epoch: 4516, train precision: 0.999089, train loss: 9.932222, valid precision: 0.882600, valid loss: 92.534969
epoch: 4517, train precision: 0.999333, train loss: 9.851792, valid precision: 0.879600, valid loss: 90.552310
epoch: 4518, train precision: 0.999111, train loss: 9.938519, valid precision: 0.881200, valid loss: 92.731633
epoch: 4519, train precision: 0.999156, train loss: 9.892472, valid precision: 0.879400, valid loss: 92.067533
epoch: 4520, train precision: 0.999022, train loss: 9.966475, valid precision: 0.879200, valid loss: 92.341288
epoch: 4521, train precision: 0.999444, train loss: 9.878403, valid precision: 0.883400, valid loss: 89.438486
epoch: 4522, train precision: 0.998578, train loss: 10.092663, valid precision: 0.877000, valid loss: 92.631315
epoch: 4523, train precision: 0.999111, train loss: 9.948810, valid precision: 0.879400, valid loss: 90.537857
epoch: 4524, train precision: 0.999311, train loss: 9.868451, valid precision: 0.881400, valid loss: 90.262873
epoch: 4525, train precision: 0.999222, train loss: 9.908226, valid precision: 0.879200, valid loss: 92.516294
epoch: 4526, train precision: 0.999178, train loss: 9.874079, valid precision: 0.879800, valid loss: 89.800465
epoch: 4527, train precision: 0.999089, train loss: 9.938066, valid precision: 0.879400, valid loss: 90.843564
epoch: 4528, train precision: 0.999133, train loss: 9.959892, valid precision: 0.879600, valid loss: 93.281035
epoch: 4529, train precision: 0.999200, train loss: 9.910388, valid precision: 0.882800, valid loss: 91.690883
epoch: 4530, train precision: 0.999044, train loss: 9.903279, valid precision: 0.879200, valid loss: 90.051431
epoch: 4531, train precision: 0.999244, train loss: 9.895610, valid precision: 0.880000, valid loss: 92.710275
epoch: 4532, train precision: 0.999222, train loss: 9.894985, valid precision: 0.879400, valid loss: 91.697657
epoch: 4533, train precision: 0.999156, train loss: 9.916219, valid precision: 0.878600, valid loss: 94.984603
epoch: 4534, train precision: 0.999133, train loss: 9.898455, valid precision: 0.883800, valid loss: 92.800387
epoch: 4535, train precision: 0.999289, train loss: 9.873497, valid precision: 0.886000, valid loss: 91.624980
epoch: 4536, train precision: 0.999156, train loss: 9.903976, valid precision: 0.882000, valid loss: 90.781072
epoch: 4537, train precision: 0.998956, train loss: 9.932808, valid precision: 0.880600, valid loss: 91.028813
epoch: 4538, train precision: 0.998733, train loss: 10.070779, valid precision: 0.875400, valid loss: 92.136816
epoch: 4539, train precision: 0.999178, train loss: 9.944044, valid precision: 0.879800, valid loss: 90.007759
epoch: 4540, train precision: 0.999000, train loss: 9.958910, valid precision: 0.881200, valid loss: 92.816243
epoch: 4541, train precision: 0.999044, train loss: 9.914786, valid precision: 0.879000, valid loss: 93.573840
epoch: 4542, train precision: 0.999067, train loss: 9.875962, valid precision: 0.879200, valid loss: 92.953253
epoch: 4543, train precision: 0.998711, train loss: 10.080786, valid precision: 0.879600, valid loss: 93.701137
epoch: 4544, train precision: 0.999267, train loss: 9.868150, valid precision: 0.879800, valid loss: 93.545795
epoch: 4545, train precision: 0.999200, train loss: 9.883049, valid precision: 0.875400, valid loss: 93.979601
epoch: 4546, train precision: 0.998489, train loss: 10.151924, valid precision: 0.875400, valid loss: 95.726229
epoch: 4547, train precision: 0.999467, train loss: 9.839205, valid precision: 0.877200, valid loss: 93.759253
epoch: 4548, train precision: 0.999422, train loss: 9.806713, valid precision: 0.877800, valid loss: 96.093558
epoch: 4549, train precision: 0.999156, train loss: 9.876552, valid precision: 0.875800, valid loss: 95.671142
epoch: 4550, train precision: 0.999156, train loss: 9.899343, valid precision: 0.874600, valid loss: 93.182746
epoch: 4551, train precision: 0.999244, train loss: 9.897163, valid precision: 0.874000, valid loss: 95.267475
epoch: 4552, train precision: 0.998956, train loss: 9.941748, valid precision: 0.876800, valid loss: 93.014218
epoch: 4553, train precision: 0.999178, train loss: 9.913058, valid precision: 0.876600, valid loss: 91.995140
epoch: 4554, train precision: 0.999156, train loss: 9.922154, valid precision: 0.880800, valid loss: 90.385684
epoch: 4555, train precision: 0.999267, train loss: 9.884666, valid precision: 0.877400, valid loss: 92.577325
epoch: 4556, train precision: 0.998978, train loss: 9.969396, valid precision: 0.877800, valid loss: 92.742803
epoch: 4557, train precision: 0.999356, train loss: 9.831712, valid precision: 0.878600, valid loss: 92.364288
epoch: 4558, train precision: 0.999089, train loss: 9.963915, valid precision: 0.876000, valid loss: 93.077878
epoch: 4559, train precision: 0.998689, train loss: 10.039710, valid precision: 0.875600, valid loss: 91.559660
epoch: 4560, train precision: 0.999156, train loss: 9.852046, valid precision: 0.878400, valid loss: 92.256488
epoch: 4561, train precision: 0.998956, train loss: 9.963891, valid precision: 0.876200, valid loss: 92.943959
epoch: 4562, train precision: 0.999222, train loss: 9.909841, valid precision: 0.878800, valid loss: 91.660276
epoch: 4563, train precision: 0.999311, train loss: 9.873288, valid precision: 0.879200, valid loss: 89.561965
epoch: 4564, train precision: 0.999333, train loss: 9.943551, valid precision: 0.877800, valid loss: 91.742128
epoch: 4565, train precision: 0.999156, train loss: 9.899565, valid precision: 0.878400, valid loss: 90.165672
epoch: 4566, train precision: 0.999222, train loss: 9.874742, valid precision: 0.875200, valid loss: 91.223676
epoch: 4567, train precision: 0.999089, train loss: 9.943823, valid precision: 0.880600, valid loss: 89.566746
epoch: 4568, train precision: 0.999111, train loss: 9.936775, valid precision: 0.880000, valid loss: 91.755528
epoch: 4569, train precision: 0.998889, train loss: 9.987642, valid precision: 0.881200, valid loss: 89.867701
epoch: 4570, train precision: 0.999000, train loss: 10.013448, valid precision: 0.878000, valid loss: 94.405516
epoch: 4571, train precision: 0.999178, train loss: 9.905534, valid precision: 0.882600, valid loss: 91.044130
epoch: 4572, train precision: 0.999022, train loss: 9.959862, valid precision: 0.877600, valid loss: 95.764288
epoch: 4573, train precision: 0.999044, train loss: 9.915845, valid precision: 0.879600, valid loss: 93.832982
epoch: 4574, train precision: 0.999267, train loss: 9.917275, valid precision: 0.880000, valid loss: 89.906669
epoch: 4575, train precision: 0.999200, train loss: 9.969950, valid precision: 0.881400, valid loss: 89.788769
epoch: 4576, train precision: 0.999133, train loss: 9.945035, valid precision: 0.879000, valid loss: 91.820824
epoch: 4577, train precision: 0.999089, train loss: 9.948208, valid precision: 0.878000, valid loss: 91.146865
epoch: 4578, train precision: 0.999200, train loss: 9.907897, valid precision: 0.877000, valid loss: 92.279077
epoch: 4579, train precision: 0.998933, train loss: 10.000554, valid precision: 0.877200, valid loss: 92.197794
epoch: 4580, train precision: 0.999067, train loss: 9.926144, valid precision: 0.878000, valid loss: 93.486487
epoch: 4581, train precision: 0.999289, train loss: 9.859906, valid precision: 0.876800, valid loss: 89.931493
epoch: 4582, train precision: 0.999178, train loss: 9.884791, valid precision: 0.878000, valid loss: 93.045198
epoch: 4583, train precision: 0.999089, train loss: 9.891553, valid precision: 0.878400, valid loss: 92.373698
epoch: 4584, train precision: 0.998467, train loss: 10.018429, valid precision: 0.878800, valid loss: 91.456423
epoch: 4585, train precision: 0.999289, train loss: 9.829324, valid precision: 0.880200, valid loss: 88.749776
epoch: 4586, train precision: 0.999022, train loss: 9.913661, valid precision: 0.878600, valid loss: 92.393708
epoch: 4587, train precision: 0.998756, train loss: 10.032055, valid precision: 0.880400, valid loss: 90.902970
epoch: 4588, train precision: 0.999400, train loss: 9.839586, valid precision: 0.877800, valid loss: 91.456369
epoch: 4589, train precision: 0.998956, train loss: 9.977591, valid precision: 0.880400, valid loss: 88.662503
epoch: 4590, train precision: 0.998867, train loss: 9.989954, valid precision: 0.876800, valid loss: 89.110087
epoch: 4591, train precision: 0.999244, train loss: 9.862492, valid precision: 0.878600, valid loss: 90.465932
epoch: 4592, train precision: 0.998711, train loss: 9.997418, valid precision: 0.877400, valid loss: 91.114945
epoch: 4593, train precision: 0.998867, train loss: 9.978546, valid precision: 0.880800, valid loss: 91.008461
epoch: 4594, train precision: 0.999422, train loss: 9.828204, valid precision: 0.879800, valid loss: 91.244001
epoch: 4595, train precision: 0.999022, train loss: 9.984639, valid precision: 0.878600, valid loss: 90.220090
epoch: 4596, train precision: 0.999200, train loss: 9.881052, valid precision: 0.877800, valid loss: 90.133787
epoch: 4597, train precision: 0.999044, train loss: 9.926000, valid precision: 0.879000, valid loss: 88.391155
epoch: 4598, train precision: 0.999178, train loss: 9.921477, valid precision: 0.880800, valid loss: 89.798708
epoch: 4599, train precision: 0.999311, train loss: 9.920148, valid precision: 0.882600, valid loss: 88.461668
epoch: 4600, train precision: 0.999044, train loss: 9.970845, valid precision: 0.880400, valid loss: 90.743506
epoch: 4601, train precision: 0.999378, train loss: 9.820535, valid precision: 0.881600, valid loss: 90.454968
epoch: 4602, train precision: 0.999244, train loss: 9.883273, valid precision: 0.873800, valid loss: 93.527231
epoch: 4603, train precision: 0.999156, train loss: 9.930456, valid precision: 0.877400, valid loss: 94.612267
epoch: 4604, train precision: 0.999156, train loss: 9.920181, valid precision: 0.879000, valid loss: 91.073637
epoch: 4605, train precision: 0.999378, train loss: 9.872174, valid precision: 0.876000, valid loss: 92.476437
epoch: 4606, train precision: 0.999267, train loss: 9.894456, valid precision: 0.876000, valid loss: 92.122892
epoch: 4607, train precision: 0.999111, train loss: 9.896585, valid precision: 0.876000, valid loss: 89.793903
epoch: 4608, train precision: 0.998956, train loss: 9.876959, valid precision: 0.876800, valid loss: 92.230549
epoch: 4609, train precision: 0.999289, train loss: 9.860119, valid precision: 0.878600, valid loss: 91.149641
epoch: 4610, train precision: 0.999000, train loss: 9.920639, valid precision: 0.880400, valid loss: 91.437706
epoch: 4611, train precision: 0.999200, train loss: 9.888090, valid precision: 0.875600, valid loss: 90.392000
epoch: 4612, train precision: 0.999267, train loss: 9.818998, valid precision: 0.875800, valid loss: 92.762850
epoch: 4613, train precision: 0.999222, train loss: 9.868549, valid precision: 0.874800, valid loss: 95.385682
epoch: 4614, train precision: 0.999289, train loss: 9.888176, valid precision: 0.873800, valid loss: 95.873853
epoch: 4615, train precision: 0.999289, train loss: 9.854768, valid precision: 0.874600, valid loss: 95.317494
epoch: 4616, train precision: 0.999178, train loss: 9.918627, valid precision: 0.877400, valid loss: 95.138725
epoch: 4617, train precision: 0.998956, train loss: 9.931015, valid precision: 0.874400, valid loss: 94.117628
epoch: 4618, train precision: 0.999222, train loss: 9.896344, valid precision: 0.874800, valid loss: 92.985852
epoch: 4619, train precision: 0.999044, train loss: 9.901554, valid precision: 0.875800, valid loss: 95.056385
epoch: 4620, train precision: 0.999156, train loss: 9.937659, valid precision: 0.876000, valid loss: 94.513036
epoch: 4621, train precision: 0.999133, train loss: 9.966826, valid precision: 0.873600, valid loss: 93.984479
epoch: 4622, train precision: 0.999267, train loss: 9.951531, valid precision: 0.873000, valid loss: 94.291039
epoch: 4623, train precision: 0.998867, train loss: 9.934977, valid precision: 0.874200, valid loss: 95.048248
epoch: 4624, train precision: 0.999133, train loss: 9.935719, valid precision: 0.876000, valid loss: 92.989982
epoch: 4625, train precision: 0.998844, train loss: 9.987365, valid precision: 0.876400, valid loss: 93.567577
epoch: 4626, train precision: 0.999178, train loss: 9.945311, valid precision: 0.870000, valid loss: 95.492964
epoch: 4627, train precision: 0.999222, train loss: 9.957781, valid precision: 0.875800, valid loss: 92.543093
epoch: 4628, train precision: 0.999156, train loss: 9.970607, valid precision: 0.879600, valid loss: 94.030933
epoch: 4629, train precision: 0.999222, train loss: 9.859528, valid precision: 0.873800, valid loss: 93.116952
epoch: 4630, train precision: 0.999311, train loss: 9.870347, valid precision: 0.873600, valid loss: 93.134567
epoch: 4631, train precision: 0.999178, train loss: 9.836688, valid precision: 0.874200, valid loss: 92.936030
epoch: 4632, train precision: 0.999289, train loss: 9.867909, valid precision: 0.876000, valid loss: 97.108094
epoch: 4633, train precision: 0.999244, train loss: 9.778795, valid precision: 0.876400, valid loss: 95.873193
epoch: 4634, train precision: 0.999333, train loss: 9.852835, valid precision: 0.876600, valid loss: 95.144757
epoch: 4635, train precision: 0.999222, train loss: 9.836773, valid precision: 0.878800, valid loss: 94.726291
epoch: 4636, train precision: 0.999089, train loss: 9.904410, valid precision: 0.877200, valid loss: 93.711997
epoch: 4637, train precision: 0.999356, train loss: 9.833511, valid precision: 0.877400, valid loss: 93.245680
epoch: 4638, train precision: 0.999000, train loss: 9.896037, valid precision: 0.879600, valid loss: 94.245691
epoch: 4639, train precision: 0.998867, train loss: 9.880628, valid precision: 0.876400, valid loss: 94.461969
epoch: 4640, train precision: 0.999333, train loss: 9.872983, valid precision: 0.876000, valid loss: 95.324792
epoch: 4641, train precision: 0.999289, train loss: 9.885622, valid precision: 0.878200, valid loss: 90.615156
epoch: 4642, train precision: 0.999467, train loss: 9.766411, valid precision: 0.876600, valid loss: 92.761216
epoch: 4643, train precision: 0.999378, train loss: 9.846867, valid precision: 0.877800, valid loss: 91.142346
epoch: 4644, train precision: 0.998733, train loss: 10.029007, valid precision: 0.878200, valid loss: 94.097989
epoch: 4645, train precision: 0.999378, train loss: 9.850832, valid precision: 0.874400, valid loss: 94.591379
epoch: 4646, train precision: 0.998911, train loss: 9.947161, valid precision: 0.872800, valid loss: 95.392430
epoch: 4647, train precision: 0.999133, train loss: 9.891295, valid precision: 0.877800, valid loss: 93.682668
epoch: 4648, train precision: 0.999111, train loss: 9.922173, valid precision: 0.874600, valid loss: 93.887255
epoch: 4649, train precision: 0.999267, train loss: 9.848610, valid precision: 0.876000, valid loss: 96.235191
epoch: 4650, train precision: 0.998733, train loss: 9.996602, valid precision: 0.872600, valid loss: 98.199209
epoch: 4651, train precision: 0.999400, train loss: 9.874914, valid precision: 0.876800, valid loss: 94.036495
epoch: 4652, train precision: 0.998867, train loss: 9.952520, valid precision: 0.878200, valid loss: 93.531704
epoch: 4653, train precision: 0.999311, train loss: 9.860603, valid precision: 0.876000, valid loss: 94.425773
epoch: 4654, train precision: 0.999200, train loss: 9.896078, valid precision: 0.873200, valid loss: 95.446513
epoch: 4655, train precision: 0.999089, train loss: 9.922768, valid precision: 0.875000, valid loss: 93.873172
epoch: 4656, train precision: 0.998778, train loss: 10.004003, valid precision: 0.871600, valid loss: 96.558200
epoch: 4657, train precision: 0.999111, train loss: 9.866707, valid precision: 0.871800, valid loss: 96.662789
epoch: 4658, train precision: 0.999178, train loss: 9.818449, valid precision: 0.874800, valid loss: 93.858548
epoch: 4659, train precision: 0.999178, train loss: 9.984444, valid precision: 0.872600, valid loss: 98.143147
epoch: 4660, train precision: 0.998956, train loss: 9.957546, valid precision: 0.874200, valid loss: 96.904290
epoch: 4661, train precision: 0.999533, train loss: 9.817556, valid precision: 0.875600, valid loss: 96.821918
epoch: 4662, train precision: 0.999267, train loss: 9.858129, valid precision: 0.876200, valid loss: 93.503389
epoch: 4663, train precision: 0.999067, train loss: 9.913303, valid precision: 0.874400, valid loss: 93.416527
epoch: 4664, train precision: 0.999200, train loss: 9.924042, valid precision: 0.877400, valid loss: 95.452475
epoch: 4665, train precision: 0.999422, train loss: 9.844524, valid precision: 0.874200, valid loss: 95.221160
epoch: 4666, train precision: 0.999222, train loss: 9.930321, valid precision: 0.877200, valid loss: 95.221202
epoch: 4667, train precision: 0.999178, train loss: 9.897116, valid precision: 0.874800, valid loss: 95.271306
epoch: 4668, train precision: 0.999400, train loss: 9.819087, valid precision: 0.876600, valid loss: 94.975484
epoch: 4669, train precision: 0.999356, train loss: 9.838728, valid precision: 0.877200, valid loss: 95.389801
epoch: 4670, train precision: 0.998978, train loss: 9.907546, valid precision: 0.875600, valid loss: 92.731060
epoch: 4671, train precision: 0.999200, train loss: 9.824857, valid precision: 0.879000, valid loss: 93.943808
epoch: 4672, train precision: 0.999000, train loss: 9.901960, valid precision: 0.876600, valid loss: 96.252434
epoch: 4673, train precision: 0.999222, train loss: 9.871483, valid precision: 0.875200, valid loss: 95.491813
epoch: 4674, train precision: 0.999067, train loss: 9.932119, valid precision: 0.877200, valid loss: 92.241017
epoch: 4675, train precision: 0.998933, train loss: 9.924060, valid precision: 0.877600, valid loss: 95.824275
epoch: 4676, train precision: 0.998889, train loss: 9.978806, valid precision: 0.882000, valid loss: 93.918645
epoch: 4677, train precision: 0.999044, train loss: 9.902710, valid precision: 0.880400, valid loss: 93.128106
epoch: 4678, train precision: 0.999244, train loss: 9.856921, valid precision: 0.880600, valid loss: 92.204787
epoch: 4679, train precision: 0.999133, train loss: 9.942961, valid precision: 0.877400, valid loss: 91.745846
epoch: 4680, train precision: 0.999000, train loss: 9.893215, valid precision: 0.879800, valid loss: 93.841990
epoch: 4681, train precision: 0.999156, train loss: 9.898925, valid precision: 0.875600, valid loss: 94.013047
epoch: 4682, train precision: 0.999311, train loss: 9.840091, valid precision: 0.874200, valid loss: 93.730467
epoch: 4683, train precision: 0.999356, train loss: 9.857679, valid precision: 0.876800, valid loss: 92.026329
epoch: 4684, train precision: 0.999400, train loss: 9.823169, valid precision: 0.877800, valid loss: 93.380881
epoch: 4685, train precision: 0.998556, train loss: 10.064729, valid precision: 0.876800, valid loss: 95.174668
epoch: 4686, train precision: 0.999311, train loss: 9.849578, valid precision: 0.876800, valid loss: 95.846194
epoch: 4687, train precision: 0.999067, train loss: 9.925553, valid precision: 0.874400, valid loss: 95.664740
epoch: 4688, train precision: 0.999422, train loss: 9.792749, valid precision: 0.876000, valid loss: 93.176886
epoch: 4689, train precision: 0.999333, train loss: 9.800874, valid precision: 0.881800, valid loss: 90.715111
epoch: 4690, train precision: 0.999289, train loss: 9.859957, valid precision: 0.881600, valid loss: 94.726789
epoch: 4691, train precision: 0.999311, train loss: 9.841047, valid precision: 0.882000, valid loss: 92.364883
epoch: 4692, train precision: 0.999378, train loss: 9.803989, valid precision: 0.883000, valid loss: 94.813187
epoch: 4693, train precision: 0.999222, train loss: 9.848376, valid precision: 0.879800, valid loss: 93.224456
epoch: 4694, train precision: 0.998822, train loss: 9.946467, valid precision: 0.880800, valid loss: 94.397343
epoch: 4695, train precision: 0.999311, train loss: 9.844876, valid precision: 0.881200, valid loss: 93.424810
epoch: 4696, train precision: 0.999244, train loss: 9.850425, valid precision: 0.877200, valid loss: 92.967934
epoch: 4697, train precision: 0.999267, train loss: 9.873278, valid precision: 0.879600, valid loss: 94.734034
epoch: 4698, train precision: 0.999222, train loss: 9.881565, valid precision: 0.878600, valid loss: 94.869744
epoch: 4699, train precision: 0.999200, train loss: 9.916050, valid precision: 0.878000, valid loss: 90.221485
epoch: 4700, train precision: 0.999311, train loss: 9.793677, valid precision: 0.879000, valid loss: 95.370548
epoch: 4701, train precision: 0.999111, train loss: 9.835204, valid precision: 0.879400, valid loss: 96.420473
epoch: 4702, train precision: 0.998956, train loss: 9.941151, valid precision: 0.878200, valid loss: 96.213055
epoch: 4703, train precision: 0.998844, train loss: 9.983560, valid precision: 0.873400, valid loss: 95.588526
epoch: 4704, train precision: 0.998956, train loss: 9.933023, valid precision: 0.878000, valid loss: 96.194555
epoch: 4705, train precision: 0.999222, train loss: 9.859927, valid precision: 0.878200, valid loss: 95.864445
epoch: 4706, train precision: 0.999044, train loss: 9.911195, valid precision: 0.874600, valid loss: 97.574774
epoch: 4707, train precision: 0.999244, train loss: 9.874102, valid precision: 0.876800, valid loss: 95.648182
epoch: 4708, train precision: 0.999444, train loss: 9.814338, valid precision: 0.876800, valid loss: 94.754519
epoch: 4709, train precision: 0.999333, train loss: 9.868020, valid precision: 0.876400, valid loss: 94.810936
epoch: 4710, train precision: 0.998778, train loss: 9.972914, valid precision: 0.878400, valid loss: 92.627879
epoch: 4711, train precision: 0.999200, train loss: 9.908799, valid precision: 0.876200, valid loss: 94.118435
epoch: 4712, train precision: 0.999067, train loss: 9.860568, valid precision: 0.878400, valid loss: 97.169143
epoch: 4713, train precision: 0.998822, train loss: 9.972672, valid precision: 0.877200, valid loss: 97.297879
epoch: 4714, train precision: 0.999044, train loss: 9.920899, valid precision: 0.874400, valid loss: 96.394938
epoch: 4715, train precision: 0.998933, train loss: 9.982467, valid precision: 0.873600, valid loss: 95.774567
epoch: 4716, train precision: 0.998956, train loss: 9.875647, valid precision: 0.876000, valid loss: 96.033843
epoch: 4717, train precision: 0.999067, train loss: 9.928229, valid precision: 0.875600, valid loss: 96.288638
epoch: 4718, train precision: 0.999022, train loss: 9.887983, valid precision: 0.873000, valid loss: 96.315275
epoch: 4719, train precision: 0.999378, train loss: 9.835181, valid precision: 0.872400, valid loss: 94.294649
epoch: 4720, train precision: 0.998978, train loss: 9.907999, valid precision: 0.872800, valid loss: 96.625144
epoch: 4721, train precision: 0.999311, train loss: 9.828999, valid precision: 0.874200, valid loss: 97.451427
epoch: 4722, train precision: 0.998889, train loss: 9.987637, valid precision: 0.882200, valid loss: 95.039147
epoch: 4723, train precision: 0.999311, train loss: 9.851169, valid precision: 0.875800, valid loss: 93.985514
epoch: 4724, train precision: 0.999000, train loss: 9.938127, valid precision: 0.877000, valid loss: 92.660889
epoch: 4725, train precision: 0.999378, train loss: 9.800232, valid precision: 0.882200, valid loss: 91.754329
epoch: 4726, train precision: 0.998911, train loss: 9.901002, valid precision: 0.879200, valid loss: 95.232892
epoch: 4727, train precision: 0.999222, train loss: 9.845018, valid precision: 0.876600, valid loss: 95.248402
epoch: 4728, train precision: 0.998800, train loss: 9.978381, valid precision: 0.879400, valid loss: 94.650641
epoch: 4729, train precision: 0.998733, train loss: 9.978181, valid precision: 0.875000, valid loss: 97.078796
epoch: 4730, train precision: 0.999089, train loss: 9.864789, valid precision: 0.880400, valid loss: 92.349749
epoch: 4731, train precision: 0.998956, train loss: 9.931776, valid precision: 0.876000, valid loss: 94.148320
epoch: 4732, train precision: 0.999089, train loss: 9.858357, valid precision: 0.877400, valid loss: 95.290507
epoch: 4733, train precision: 0.999200, train loss: 9.868121, valid precision: 0.876200, valid loss: 92.509266
epoch: 4734, train precision: 0.999422, train loss: 9.819460, valid precision: 0.876600, valid loss: 91.139618
epoch: 4735, train precision: 0.999422, train loss: 9.786889, valid precision: 0.879600, valid loss: 94.271570
epoch: 4736, train precision: 0.999200, train loss: 9.873799, valid precision: 0.876200, valid loss: 95.804316
epoch: 4737, train precision: 0.999133, train loss: 9.906250, valid precision: 0.878200, valid loss: 95.917161
epoch: 4738, train precision: 0.999378, train loss: 9.778868, valid precision: 0.882600, valid loss: 92.679071
epoch: 4739, train precision: 0.998956, train loss: 9.932927, valid precision: 0.882000, valid loss: 94.977756
epoch: 4740, train precision: 0.999356, train loss: 9.800026, valid precision: 0.881000, valid loss: 93.293422
epoch: 4741, train precision: 0.999333, train loss: 9.835433, valid precision: 0.880200, valid loss: 92.945194
epoch: 4742, train precision: 0.999378, train loss: 9.792626, valid precision: 0.875200, valid loss: 95.570967
epoch: 4743, train precision: 0.999133, train loss: 9.856449, valid precision: 0.880800, valid loss: 93.732932
epoch: 4744, train precision: 0.999378, train loss: 9.814989, valid precision: 0.875800, valid loss: 94.966487
epoch: 4745, train precision: 0.998911, train loss: 10.010436, valid precision: 0.876000, valid loss: 94.244692
epoch: 4746, train precision: 0.998800, train loss: 9.970845, valid precision: 0.875000, valid loss: 95.073415
epoch: 4747, train precision: 0.999267, train loss: 9.843972, valid precision: 0.876400, valid loss: 95.959884
epoch: 4748, train precision: 0.998800, train loss: 10.017945, valid precision: 0.876600, valid loss: 94.042604
epoch: 4749, train precision: 0.999000, train loss: 9.898548, valid precision: 0.877000, valid loss: 94.943816
epoch: 4750, train precision: 0.999222, train loss: 9.843778, valid precision: 0.878200, valid loss: 97.183504
epoch: 4751, train precision: 0.999200, train loss: 9.845085, valid precision: 0.881800, valid loss: 95.069673
epoch: 4752, train precision: 0.999200, train loss: 9.864408, valid precision: 0.881200, valid loss: 90.255162
epoch: 4753, train precision: 0.999000, train loss: 9.886325, valid precision: 0.880200, valid loss: 90.663944
epoch: 4754, train precision: 0.999311, train loss: 9.829970, valid precision: 0.879200, valid loss: 91.518208
epoch: 4755, train precision: 0.999400, train loss: 9.833550, valid precision: 0.876800, valid loss: 90.052583
epoch: 4756, train precision: 0.998978, train loss: 9.925591, valid precision: 0.876200, valid loss: 92.541094
epoch: 4757, train precision: 0.999311, train loss: 9.843134, valid precision: 0.875800, valid loss: 90.718913
epoch: 4758, train precision: 0.999067, train loss: 9.920918, valid precision: 0.876600, valid loss: 93.816397
epoch: 4759, train precision: 0.999178, train loss: 9.822254, valid precision: 0.879000, valid loss: 93.473944
epoch: 4760, train precision: 0.999044, train loss: 9.882017, valid precision: 0.877400, valid loss: 93.723632
epoch: 4761, train precision: 0.999178, train loss: 9.850263, valid precision: 0.879000, valid loss: 94.485562
epoch: 4762, train precision: 0.999311, train loss: 9.844582, valid precision: 0.878600, valid loss: 91.921973
epoch: 4763, train precision: 0.999044, train loss: 9.916369, valid precision: 0.879400, valid loss: 90.913070
epoch: 4764, train precision: 0.998911, train loss: 9.960130, valid precision: 0.882600, valid loss: 93.217284
epoch: 4765, train precision: 0.999200, train loss: 9.903675, valid precision: 0.876000, valid loss: 93.215385
epoch: 4766, train precision: 0.999178, train loss: 9.849899, valid precision: 0.879400, valid loss: 93.427763
epoch: 4767, train precision: 0.998911, train loss: 9.907682, valid precision: 0.879400, valid loss: 90.105277
epoch: 4768, train precision: 0.999222, train loss: 9.899304, valid precision: 0.879200, valid loss: 90.692722
epoch: 4769, train precision: 0.999378, train loss: 9.799052, valid precision: 0.879400, valid loss: 89.615147
epoch: 4770, train precision: 0.999289, train loss: 9.881824, valid precision: 0.880000, valid loss: 90.712117
epoch: 4771, train precision: 0.998956, train loss: 9.891647, valid precision: 0.883200, valid loss: 92.611950
epoch: 4772, train precision: 0.999444, train loss: 9.844992, valid precision: 0.878000, valid loss: 92.603489
epoch: 4773, train precision: 0.999222, train loss: 9.852200, valid precision: 0.880000, valid loss: 90.839444
epoch: 4774, train precision: 0.999267, train loss: 9.837525, valid precision: 0.883000, valid loss: 90.689063
epoch: 4775, train precision: 0.998867, train loss: 9.906089, valid precision: 0.881400, valid loss: 91.999362
epoch: 4776, train precision: 0.998800, train loss: 9.923913, valid precision: 0.877000, valid loss: 94.426713
epoch: 4777, train precision: 0.999067, train loss: 9.863542, valid precision: 0.880600, valid loss: 91.354792
epoch: 4778, train precision: 0.998933, train loss: 9.894500, valid precision: 0.880000, valid loss: 91.217302
epoch: 4779, train precision: 0.999156, train loss: 9.803380, valid precision: 0.876800, valid loss: 93.754803
epoch: 4780, train precision: 0.999200, train loss: 9.863994, valid precision: 0.880600, valid loss: 92.269787
epoch: 4781, train precision: 0.998956, train loss: 9.973742, valid precision: 0.878400, valid loss: 90.267078
epoch: 4782, train precision: 0.998889, train loss: 9.959625, valid precision: 0.877000, valid loss: 89.876840
epoch: 4783, train precision: 0.999156, train loss: 9.877520, valid precision: 0.879000, valid loss: 91.818848
epoch: 4784, train precision: 0.999022, train loss: 9.940273, valid precision: 0.878200, valid loss: 89.249650
epoch: 4785, train precision: 0.999311, train loss: 9.816265, valid precision: 0.878000, valid loss: 90.408799
epoch: 4786, train precision: 0.999133, train loss: 9.857110, valid precision: 0.880000, valid loss: 91.606286
epoch: 4787, train precision: 0.999156, train loss: 9.931914, valid precision: 0.879800, valid loss: 91.658406
epoch: 4788, train precision: 0.999022, train loss: 9.857330, valid precision: 0.880400, valid loss: 90.890593
epoch: 4789, train precision: 0.999311, train loss: 9.837523, valid precision: 0.880000, valid loss: 89.830303
epoch: 4790, train precision: 0.998978, train loss: 9.877511, valid precision: 0.875000, valid loss: 94.114144
epoch: 4791, train precision: 0.999200, train loss: 9.884074, valid precision: 0.876000, valid loss: 92.559118
epoch: 4792, train precision: 0.999378, train loss: 9.838963, valid precision: 0.879200, valid loss: 91.427732
epoch: 4793, train precision: 0.999378, train loss: 9.822804, valid precision: 0.879600, valid loss: 89.878752
epoch: 4794, train precision: 0.999356, train loss: 9.767609, valid precision: 0.879400, valid loss: 90.312931
epoch: 4795, train precision: 0.998933, train loss: 9.991498, valid precision: 0.874400, valid loss: 93.119162
epoch: 4796, train precision: 0.999178, train loss: 9.847127, valid precision: 0.879400, valid loss: 89.012421
epoch: 4797, train precision: 0.999178, train loss: 9.843270, valid precision: 0.880800, valid loss: 89.206478
epoch: 4798, train precision: 0.998933, train loss: 9.881750, valid precision: 0.883000, valid loss: 90.074460
epoch: 4799, train precision: 0.999067, train loss: 9.849961, valid precision: 0.881000, valid loss: 92.522397
epoch: 4800, train precision: 0.998978, train loss: 9.954267, valid precision: 0.879800, valid loss: 91.588985
epoch: 4801, train precision: 0.999000, train loss: 9.878669, valid precision: 0.879800, valid loss: 93.017350
epoch: 4802, train precision: 0.999089, train loss: 9.854658, valid precision: 0.882200, valid loss: 90.356160
epoch: 4803, train precision: 0.999222, train loss: 9.821195, valid precision: 0.881400, valid loss: 93.665462
epoch: 4804, train precision: 0.999111, train loss: 9.887932, valid precision: 0.881000, valid loss: 92.769724
epoch: 4805, train precision: 0.998956, train loss: 9.946836, valid precision: 0.878200, valid loss: 90.964889
epoch: 4806, train precision: 0.999044, train loss: 9.941968, valid precision: 0.877800, valid loss: 92.891684
epoch: 4807, train precision: 0.998822, train loss: 9.957819, valid precision: 0.881600, valid loss: 91.537900
epoch: 4808, train precision: 0.999244, train loss: 9.847064, valid precision: 0.876800, valid loss: 92.633131
epoch: 4809, train precision: 0.999156, train loss: 9.833946, valid precision: 0.877800, valid loss: 92.034877
epoch: 4810, train precision: 0.999400, train loss: 9.823713, valid precision: 0.879200, valid loss: 91.719947
epoch: 4811, train precision: 0.999267, train loss: 9.807621, valid precision: 0.880000, valid loss: 93.185708
epoch: 4812, train precision: 0.999133, train loss: 9.842097, valid precision: 0.881000, valid loss: 92.579977
epoch: 4813, train precision: 0.999022, train loss: 9.882097, valid precision: 0.878600, valid loss: 95.051020
epoch: 4814, train precision: 0.999111, train loss: 9.864587, valid precision: 0.879200, valid loss: 93.310589
epoch: 4815, train precision: 0.999022, train loss: 9.872134, valid precision: 0.880200, valid loss: 92.654555
epoch: 4816, train precision: 0.999022, train loss: 9.872016, valid precision: 0.879400, valid loss: 92.578533
epoch: 4817, train precision: 0.999044, train loss: 9.863735, valid precision: 0.879000, valid loss: 93.298322
epoch: 4818, train precision: 0.999044, train loss: 9.913442, valid precision: 0.877600, valid loss: 93.321178
epoch: 4819, train precision: 0.998978, train loss: 9.894962, valid precision: 0.875600, valid loss: 92.966274
epoch: 4820, train precision: 0.999089, train loss: 9.886456, valid precision: 0.881400, valid loss: 91.073970
epoch: 4821, train precision: 0.998911, train loss: 9.973489, valid precision: 0.880000, valid loss: 91.250435
epoch: 4822, train precision: 0.999333, train loss: 9.810076, valid precision: 0.879600, valid loss: 91.587263
epoch: 4823, train precision: 0.999311, train loss: 9.817932, valid precision: 0.885000, valid loss: 89.671409
epoch: 4824, train precision: 0.998978, train loss: 9.952242, valid precision: 0.882200, valid loss: 89.148259
epoch: 4825, train precision: 0.999133, train loss: 9.906490, valid precision: 0.880200, valid loss: 91.794841
epoch: 4826, train precision: 0.999222, train loss: 9.853260, valid precision: 0.878400, valid loss: 92.657057
epoch: 4827, train precision: 0.999200, train loss: 9.833589, valid precision: 0.879400, valid loss: 91.763687
epoch: 4828, train precision: 0.999267, train loss: 9.846344, valid precision: 0.879200, valid loss: 94.620088
epoch: 4829, train precision: 0.999044, train loss: 9.868885, valid precision: 0.881600, valid loss: 91.857724
epoch: 4830, train precision: 0.999111, train loss: 9.876482, valid precision: 0.878000, valid loss: 93.323686
epoch: 4831, train precision: 0.998800, train loss: 9.952489, valid precision: 0.879400, valid loss: 93.510101
epoch: 4832, train precision: 0.999333, train loss: 9.822288, valid precision: 0.876200, valid loss: 91.809824
epoch: 4833, train precision: 0.999022, train loss: 9.950826, valid precision: 0.877000, valid loss: 92.494476
epoch: 4834, train precision: 0.998978, train loss: 9.888978, valid precision: 0.879400, valid loss: 93.005485
epoch: 4835, train precision: 0.999156, train loss: 9.841691, valid precision: 0.880000, valid loss: 95.649896
epoch: 4836, train precision: 0.999178, train loss: 9.837312, valid precision: 0.882000, valid loss: 94.336268
epoch: 4837, train precision: 0.999178, train loss: 9.842083, valid precision: 0.878800, valid loss: 92.941123
epoch: 4838, train precision: 0.998844, train loss: 10.027676, valid precision: 0.878000, valid loss: 93.008809
epoch: 4839, train precision: 0.999444, train loss: 9.776587, valid precision: 0.882000, valid loss: 91.670833
epoch: 4840, train precision: 0.998489, train loss: 10.085044, valid precision: 0.877400, valid loss: 94.172632
epoch: 4841, train precision: 0.998867, train loss: 9.926775, valid precision: 0.871600, valid loss: 95.005263
epoch: 4842, train precision: 0.999089, train loss: 9.883573, valid precision: 0.879400, valid loss: 94.816625
epoch: 4843, train precision: 0.999156, train loss: 9.851610, valid precision: 0.877000, valid loss: 93.153133
epoch: 4844, train precision: 0.998867, train loss: 9.946100, valid precision: 0.871600, valid loss: 94.082867
epoch: 4845, train precision: 0.999467, train loss: 9.810721, valid precision: 0.874600, valid loss: 94.384880
epoch: 4846, train precision: 0.999333, train loss: 9.785161, valid precision: 0.875400, valid loss: 93.427507
epoch: 4847, train precision: 0.999356, train loss: 9.796771, valid precision: 0.876800, valid loss: 92.844460
epoch: 4848, train precision: 0.999200, train loss: 9.868561, valid precision: 0.873400, valid loss: 92.065140
epoch: 4849, train precision: 0.999022, train loss: 9.904109, valid precision: 0.873600, valid loss: 90.867748
epoch: 4850, train precision: 0.999289, train loss: 9.820670, valid precision: 0.872200, valid loss: 95.763935
epoch: 4851, train precision: 0.999067, train loss: 9.883198, valid precision: 0.875400, valid loss: 94.152156
epoch: 4852, train precision: 0.999044, train loss: 9.878320, valid precision: 0.874600, valid loss: 92.984065
epoch: 4853, train precision: 0.999111, train loss: 9.847977, valid precision: 0.877600, valid loss: 92.181001
epoch: 4854, train precision: 0.999133, train loss: 9.857227, valid precision: 0.877400, valid loss: 93.899946
epoch: 4855, train precision: 0.999000, train loss: 9.890210, valid precision: 0.875800, valid loss: 93.920295
epoch: 4856, train precision: 0.999333, train loss: 9.807485, valid precision: 0.876000, valid loss: 94.723850
epoch: 4857, train precision: 0.999200, train loss: 9.848499, valid precision: 0.875800, valid loss: 94.129583
epoch: 4858, train precision: 0.999156, train loss: 9.822540, valid precision: 0.878200, valid loss: 93.200608
epoch: 4859, train precision: 0.999289, train loss: 9.818360, valid precision: 0.879800, valid loss: 91.458679
epoch: 4860, train precision: 0.998711, train loss: 10.015343, valid precision: 0.878400, valid loss: 94.243015
epoch: 4861, train precision: 0.999133, train loss: 9.887183, valid precision: 0.873400, valid loss: 95.512975
epoch: 4862, train precision: 0.999000, train loss: 9.916636, valid precision: 0.881600, valid loss: 94.042525
epoch: 4863, train precision: 0.999022, train loss: 9.894066, valid precision: 0.878400, valid loss: 93.252420
epoch: 4864, train precision: 0.998933, train loss: 9.910454, valid precision: 0.877800, valid loss: 90.659400
epoch: 4865, train precision: 0.999178, train loss: 9.848913, valid precision: 0.878000, valid loss: 90.451144
epoch: 4866, train precision: 0.999289, train loss: 9.860654, valid precision: 0.879000, valid loss: 92.421023
epoch: 4867, train precision: 0.999244, train loss: 9.818696, valid precision: 0.880200, valid loss: 94.327946
epoch: 4868, train precision: 0.999200, train loss: 9.823593, valid precision: 0.878000, valid loss: 93.936965
epoch: 4869, train precision: 0.998956, train loss: 9.931654, valid precision: 0.879000, valid loss: 94.986381
epoch: 4870, train precision: 0.999133, train loss: 9.836515, valid precision: 0.880400, valid loss: 94.788819
epoch: 4871, train precision: 0.999000, train loss: 9.903891, valid precision: 0.882800, valid loss: 93.869933
epoch: 4872, train precision: 0.998933, train loss: 9.916638, valid precision: 0.878800, valid loss: 96.367156
epoch: 4873, train precision: 0.999067, train loss: 9.866560, valid precision: 0.883200, valid loss: 93.937659
epoch: 4874, train precision: 0.999244, train loss: 9.800137, valid precision: 0.880200, valid loss: 94.226172
epoch: 4875, train precision: 0.999000, train loss: 9.930324, valid precision: 0.877600, valid loss: 93.750923
epoch: 4876, train precision: 0.999356, train loss: 9.849232, valid precision: 0.880200, valid loss: 92.182615
epoch: 4877, train precision: 0.998956, train loss: 9.921596, valid precision: 0.879800, valid loss: 92.233216
epoch: 4878, train precision: 0.999156, train loss: 9.814632, valid precision: 0.882600, valid loss: 92.406986
epoch: 4879, train precision: 0.998867, train loss: 9.951575, valid precision: 0.877800, valid loss: 93.692216
epoch: 4880, train precision: 0.999133, train loss: 9.911332, valid precision: 0.881000, valid loss: 89.599717
epoch: 4881, train precision: 0.999400, train loss: 9.818111, valid precision: 0.879600, valid loss: 90.709546
epoch: 4882, train precision: 0.999222, train loss: 9.816484, valid precision: 0.881000, valid loss: 95.031230
epoch: 4883, train precision: 0.998800, train loss: 9.924189, valid precision: 0.878400, valid loss: 93.876351
epoch: 4884, train precision: 0.998911, train loss: 9.870545, valid precision: 0.878400, valid loss: 97.300694
epoch: 4885, train precision: 0.999267, train loss: 9.870626, valid precision: 0.880000, valid loss: 93.847267
epoch: 4886, train precision: 0.999311, train loss: 9.794303, valid precision: 0.880200, valid loss: 93.541164
epoch: 4887, train precision: 0.998733, train loss: 9.985242, valid precision: 0.880000, valid loss: 92.556516
epoch: 4888, train precision: 0.999000, train loss: 9.934795, valid precision: 0.878000, valid loss: 92.029829
epoch: 4889, train precision: 0.998933, train loss: 9.899816, valid precision: 0.881400, valid loss: 94.498245
epoch: 4890, train precision: 0.999289, train loss: 9.813029, valid precision: 0.879000, valid loss: 95.297818
epoch: 4891, train precision: 0.998844, train loss: 9.889071, valid precision: 0.882600, valid loss: 94.237196
epoch: 4892, train precision: 0.998889, train loss: 9.923879, valid precision: 0.880000, valid loss: 94.090183
epoch: 4893, train precision: 0.999267, train loss: 9.826185, valid precision: 0.879000, valid loss: 92.465034
epoch: 4894, train precision: 0.999400, train loss: 9.815783, valid precision: 0.880200, valid loss: 93.482647
epoch: 4895, train precision: 0.999022, train loss: 9.937707, valid precision: 0.882600, valid loss: 91.838059
epoch: 4896, train precision: 0.998978, train loss: 9.888061, valid precision: 0.882400, valid loss: 94.658809
epoch: 4897, train precision: 0.999200, train loss: 9.878312, valid precision: 0.883800, valid loss: 90.796910
epoch: 4898, train precision: 0.999133, train loss: 9.842493, valid precision: 0.881800, valid loss: 93.616638
epoch: 4899, train precision: 0.999089, train loss: 9.902320, valid precision: 0.877800, valid loss: 94.237055
epoch: 4900, train precision: 0.999089, train loss: 9.986440, valid precision: 0.878400, valid loss: 92.834586
epoch: 4901, train precision: 0.999000, train loss: 9.911872, valid precision: 0.882400, valid loss: 92.460534
epoch: 4902, train precision: 0.999222, train loss: 9.813003, valid precision: 0.880800, valid loss: 93.708129
epoch: 4903, train precision: 0.999089, train loss: 9.907166, valid precision: 0.883400, valid loss: 91.133533
epoch: 4904, train precision: 0.999222, train loss: 9.794696, valid precision: 0.879000, valid loss: 93.610806
epoch: 4905, train precision: 0.999200, train loss: 9.814269, valid precision: 0.882800, valid loss: 94.115343
epoch: 4906, train precision: 0.999178, train loss: 9.844489, valid precision: 0.877000, valid loss: 93.158809
epoch: 4907, train precision: 0.998933, train loss: 9.867262, valid precision: 0.881000, valid loss: 94.065989
epoch: 4908, train precision: 0.998800, train loss: 9.971257, valid precision: 0.880800, valid loss: 95.813413
epoch: 4909, train precision: 0.999289, train loss: 9.830072, valid precision: 0.878800, valid loss: 95.725841
epoch: 4910, train precision: 0.999111, train loss: 9.806604, valid precision: 0.880400, valid loss: 97.237294
epoch: 4911, train precision: 0.999378, train loss: 9.821260, valid precision: 0.878200, valid loss: 94.771687
epoch: 4912, train precision: 0.998889, train loss: 9.901823, valid precision: 0.880200, valid loss: 94.611872
epoch: 4913, train precision: 0.999289, train loss: 9.833101, valid precision: 0.877000, valid loss: 93.020795
epoch: 4914, train precision: 0.999244, train loss: 9.842117, valid precision: 0.879000, valid loss: 94.301839
epoch: 4915, train precision: 0.999022, train loss: 9.878151, valid precision: 0.879800, valid loss: 96.424616
epoch: 4916, train precision: 0.999089, train loss: 9.881386, valid precision: 0.876600, valid loss: 95.199659
epoch: 4917, train precision: 0.999467, train loss: 9.748931, valid precision: 0.877800, valid loss: 95.407508
epoch: 4918, train precision: 0.999244, train loss: 9.942155, valid precision: 0.878200, valid loss: 95.127439
epoch: 4919, train precision: 0.999089, train loss: 9.911786, valid precision: 0.876400, valid loss: 94.589332
epoch: 4920, train precision: 0.999289, train loss: 9.788251, valid precision: 0.878800, valid loss: 94.649147
epoch: 4921, train precision: 0.999156, train loss: 9.826112, valid precision: 0.879000, valid loss: 97.103725
epoch: 4922, train precision: 0.999067, train loss: 9.873478, valid precision: 0.875000, valid loss: 96.394034
epoch: 4923, train precision: 0.999044, train loss: 9.895277, valid precision: 0.874800, valid loss: 95.493743
epoch: 4924, train precision: 0.999156, train loss: 9.831802, valid precision: 0.878200, valid loss: 97.647577
epoch: 4925, train precision: 0.999000, train loss: 9.924403, valid precision: 0.877400, valid loss: 96.047905
epoch: 4926, train precision: 0.999156, train loss: 9.897069, valid precision: 0.873600, valid loss: 97.937857
epoch: 4927, train precision: 0.998533, train loss: 10.052598, valid precision: 0.874600, valid loss: 99.482825
epoch: 4928, train precision: 0.999156, train loss: 9.819637, valid precision: 0.878600, valid loss: 96.588507
epoch: 4929, train precision: 0.999356, train loss: 9.784246, valid precision: 0.875600, valid loss: 96.919071
epoch: 4930, train precision: 0.999267, train loss: 9.758169, valid precision: 0.875400, valid loss: 96.535042
epoch: 4931, train precision: 0.999089, train loss: 9.947353, valid precision: 0.874600, valid loss: 96.843423
epoch: 4932, train precision: 0.999378, train loss: 9.805267, valid precision: 0.877600, valid loss: 93.639405
epoch: 4933, train precision: 0.999400, train loss: 9.756855, valid precision: 0.878200, valid loss: 95.981363
epoch: 4934, train precision: 0.999400, train loss: 9.760337, valid precision: 0.877800, valid loss: 94.788518
epoch: 4935, train precision: 0.999178, train loss: 9.814440, valid precision: 0.878000, valid loss: 94.585387
epoch: 4936, train precision: 0.999222, train loss: 9.798820, valid precision: 0.879200, valid loss: 96.458507
epoch: 4937, train precision: 0.999089, train loss: 9.860706, valid precision: 0.874400, valid loss: 97.273427
epoch: 4938, train precision: 0.999067, train loss: 9.857661, valid precision: 0.874200, valid loss: 95.835972
epoch: 4939, train precision: 0.999089, train loss: 9.913953, valid precision: 0.881000, valid loss: 93.439818
epoch: 4940, train precision: 0.998889, train loss: 9.882359, valid precision: 0.879000, valid loss: 94.644939
epoch: 4941, train precision: 0.999067, train loss: 9.857914, valid precision: 0.879000, valid loss: 91.296386
epoch: 4942, train precision: 0.999067, train loss: 9.868066, valid precision: 0.879400, valid loss: 91.300912
epoch: 4943, train precision: 0.999089, train loss: 9.877950, valid precision: 0.880000, valid loss: 92.319241
epoch: 4944, train precision: 0.999178, train loss: 9.832202, valid precision: 0.879400, valid loss: 92.891403
epoch: 4945, train precision: 0.999378, train loss: 9.796474, valid precision: 0.877000, valid loss: 91.284089
epoch: 4946, train precision: 0.999267, train loss: 9.810496, valid precision: 0.879600, valid loss: 91.032213
epoch: 4947, train precision: 0.998889, train loss: 9.875131, valid precision: 0.880000, valid loss: 93.958277
epoch: 4948, train precision: 0.999044, train loss: 9.865440, valid precision: 0.882200, valid loss: 95.436901
epoch: 4949, train precision: 0.998867, train loss: 9.901696, valid precision: 0.879400, valid loss: 93.603227
epoch: 4950, train precision: 0.998867, train loss: 9.894408, valid precision: 0.877000, valid loss: 94.847624
epoch: 4951, train precision: 0.998911, train loss: 9.832586, valid precision: 0.881200, valid loss: 96.163329
epoch: 4952, train precision: 0.999378, train loss: 9.748175, valid precision: 0.877000, valid loss: 98.557609
epoch: 4953, train precision: 0.998733, train loss: 9.915905, valid precision: 0.876400, valid loss: 98.157485
epoch: 4954, train precision: 0.998889, train loss: 9.903230, valid precision: 0.879600, valid loss: 94.428188
epoch: 4955, train precision: 0.999289, train loss: 9.829098, valid precision: 0.881000, valid loss: 94.787451
epoch: 4956, train precision: 0.999400, train loss: 9.775229, valid precision: 0.880000, valid loss: 95.003487
epoch: 4957, train precision: 0.999400, train loss: 9.805300, valid precision: 0.874200, valid loss: 94.981295
epoch: 4958, train precision: 0.999244, train loss: 9.790131, valid precision: 0.879200, valid loss: 97.586641
epoch: 4959, train precision: 0.999267, train loss: 9.848600, valid precision: 0.880600, valid loss: 92.896771
epoch: 4960, train precision: 0.999222, train loss: 9.796260, valid precision: 0.878200, valid loss: 97.817722
epoch: 4961, train precision: 0.999067, train loss: 9.872660, valid precision: 0.877200, valid loss: 95.147894
epoch: 4962, train precision: 0.998756, train loss: 10.050880, valid precision: 0.873400, valid loss: 95.903238
epoch: 4963, train precision: 0.999356, train loss: 9.814708, valid precision: 0.875600, valid loss: 94.938284
epoch: 4964, train precision: 0.999089, train loss: 9.884887, valid precision: 0.875200, valid loss: 96.342991
epoch: 4965, train precision: 0.999333, train loss: 9.822074, valid precision: 0.879600, valid loss: 94.774577
epoch: 4966, train precision: 0.999044, train loss: 9.874448, valid precision: 0.876000, valid loss: 94.547584
epoch: 4967, train precision: 0.999178, train loss: 9.790787, valid precision: 0.881400, valid loss: 95.527613
epoch: 4968, train precision: 0.999467, train loss: 9.791644, valid precision: 0.878600, valid loss: 94.718856
epoch: 4969, train precision: 0.999222, train loss: 9.851184, valid precision: 0.875200, valid loss: 95.257103
epoch: 4970, train precision: 0.999244, train loss: 9.820456, valid precision: 0.878400, valid loss: 96.318582
epoch: 4971, train precision: 0.998978, train loss: 9.927453, valid precision: 0.876800, valid loss: 94.419088
epoch: 4972, train precision: 0.999289, train loss: 9.828002, valid precision: 0.877800, valid loss: 97.935486
epoch: 4973, train precision: 0.999511, train loss: 9.727125, valid precision: 0.875600, valid loss: 99.115066
epoch: 4974, train precision: 0.999333, train loss: 9.747637, valid precision: 0.878000, valid loss: 97.034443
epoch: 4975, train precision: 0.999289, train loss: 9.788878, valid precision: 0.881000, valid loss: 94.824056
epoch: 4976, train precision: 0.999178, train loss: 9.774295, valid precision: 0.878600, valid loss: 97.310643
epoch: 4977, train precision: 0.999511, train loss: 9.740670, valid precision: 0.879200, valid loss: 98.965778
epoch: 4978, train precision: 0.998844, train loss: 9.849798, valid precision: 0.874000, valid loss: 99.943800
epoch: 4979, train precision: 0.999022, train loss: 9.888134, valid precision: 0.875800, valid loss: 99.159833
epoch: 4980, train precision: 0.999178, train loss: 9.870041, valid precision: 0.880400, valid loss: 95.850915
epoch: 4981, train precision: 0.999222, train loss: 9.813337, valid precision: 0.876800, valid loss: 95.225167
epoch: 4982, train precision: 0.999111, train loss: 9.815125, valid precision: 0.875000, valid loss: 94.765812
epoch: 4983, train precision: 0.999200, train loss: 9.846733, valid precision: 0.876600, valid loss: 96.326657
epoch: 4984, train precision: 0.998844, train loss: 9.962140, valid precision: 0.875600, valid loss: 98.865769
epoch: 4985, train precision: 0.999244, train loss: 9.809212, valid precision: 0.875800, valid loss: 96.576089
epoch: 4986, train precision: 0.999000, train loss: 9.887799, valid precision: 0.875600, valid loss: 98.285449
epoch: 4987, train precision: 0.999200, train loss: 9.814250, valid precision: 0.878000, valid loss: 95.834631
epoch: 4988, train precision: 0.999022, train loss: 9.866649, valid precision: 0.875200, valid loss: 96.424755
epoch: 4989, train precision: 0.998800, train loss: 9.953907, valid precision: 0.876600, valid loss: 96.432405
epoch: 4990, train precision: 0.999311, train loss: 9.836753, valid precision: 0.879400, valid loss: 95.047276
epoch: 4991, train precision: 0.999067, train loss: 9.902828, valid precision: 0.880600, valid loss: 95.790041
epoch: 4992, train precision: 0.998622, train loss: 9.953084, valid precision: 0.878600, valid loss: 93.381735
epoch: 4993, train precision: 0.999422, train loss: 9.786748, valid precision: 0.877200, valid loss: 93.661537
epoch: 4994, train precision: 0.999200, train loss: 9.861032, valid precision: 0.878200, valid loss: 95.406414
epoch: 4995, train precision: 0.999444, train loss: 9.728872, valid precision: 0.880000, valid loss: 93.017035
epoch: 4996, train precision: 0.999222, train loss: 9.772426, valid precision: 0.877800, valid loss: 94.203224
epoch: 4997, train precision: 0.998889, train loss: 9.850534, valid precision: 0.881600, valid loss: 96.379638
epoch: 4998, train precision: 0.999244, train loss: 9.787450, valid precision: 0.878800, valid loss: 94.423598
epoch: 4999, train precision: 0.999333, train loss: 9.810726, valid precision: 0.878000, valid loss: 93.522387
epoch: 5000, train precision: 0.998911, train loss: 10.001127, valid precision: 0.879800, valid loss: 91.973776
